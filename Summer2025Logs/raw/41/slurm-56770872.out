I'm echoing to stdout
I'm echoing to stderr
My JobID is 56770872
I have 8 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.1303s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 2, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'parallel_dense_simp', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_all', 'num_eigs': 64, 'bias_mode': '', 'eigval_hidden_dim': 5, 'eigval_num_hidden_layer': 3, 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 1.0, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/zinc_train_rec_full.csv', 'test': 'supp_data/molecules/zinc_test_rec_full.csv', 'val': 'supp_data/molecules/zinc_val_rec_full.csv'}, 'fixMissingPhi1': False, 'extraOrtho': True, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [03:15<?, ?it/s, lr=0.001, test_MAE=1.47, time=196, train_MAE=1.02, train_loss=1.04, val_MAE=1.42, val_loss=1.44]Epoch 0:   0%|          | 1/1000 [03:15<54:20:02, 195.80s/it, lr=0.001, test_MAE=1.47, time=196, train_MAE=1.02, train_loss=1.04, val_MAE=1.42, val_loss=1.44]Epoch 1:   0%|          | 1/1000 [03:15<54:20:02, 195.80s/it, lr=0.001, test_MAE=1.47, time=196, train_MAE=1.02, train_loss=1.04, val_MAE=1.42, val_loss=1.44]Epoch 1:   0%|          | 1/1000 [04:06<54:20:02, 195.80s/it, lr=0.001, test_MAE=0.909, time=50.5, train_MAE=0.694, train_loss=0.717, val_MAE=0.873, val_loss=0.896]Epoch 1:   0%|          | 2/1000 [04:06<42:11:57, 152.22s/it, lr=0.001, test_MAE=0.909, time=50.5, train_MAE=0.694, train_loss=0.717, val_MAE=0.873, val_loss=0.896]Epoch 2:   0%|          | 2/1000 [04:06<42:11:57, 152.22s/it, lr=0.001, test_MAE=0.909, time=50.5, train_MAE=0.694, train_loss=0.717, val_MAE=0.873, val_loss=0.896]Epoch 2:   0%|          | 2/1000 [04:56<42:11:57, 152.22s/it, lr=0.001, test_MAE=0.825, time=50.3, train_MAE=0.653, train_loss=0.676, val_MAE=0.778, val_loss=0.8]  Epoch 2:   0%|          | 3/1000 [04:56<33:41:30, 121.66s/it, lr=0.001, test_MAE=0.825, time=50.3, train_MAE=0.653, train_loss=0.676, val_MAE=0.778, val_loss=0.8]Epoch 3:   0%|          | 3/1000 [04:56<33:41:30, 121.66s/it, lr=0.001, test_MAE=0.825, time=50.3, train_MAE=0.653, train_loss=0.676, val_MAE=0.778, val_loss=0.8]Epoch 3:   0%|          | 3/1000 [05:46<33:41:30, 121.66s/it, lr=0.001, test_MAE=0.715, time=50.2, train_MAE=0.631, train_loss=0.654, val_MAE=0.666, val_loss=0.689]Epoch 3:   0%|          | 4/1000 [05:46<27:43:51, 100.23s/it, lr=0.001, test_MAE=0.715, time=50.2, train_MAE=0.631, train_loss=0.654, val_MAE=0.666, val_loss=0.689]Epoch 4:   0%|          | 4/1000 [05:46<27:43:51, 100.23s/it, lr=0.001, test_MAE=0.715, time=50.2, train_MAE=0.631, train_loss=0.654, val_MAE=0.666, val_loss=0.689]Epoch 4:   0%|          | 4/1000 [06:37<27:43:51, 100.23s/it, lr=0.001, test_MAE=0.744, time=50.3, train_MAE=0.613, train_loss=0.636, val_MAE=0.685, val_loss=0.709]Epoch 4:   0%|          | 5/1000 [06:37<23:33:37, 85.24s/it, lr=0.001, test_MAE=0.744, time=50.3, train_MAE=0.613, train_loss=0.636, val_MAE=0.685, val_loss=0.709] Epoch 5:   0%|          | 5/1000 [06:37<23:33:37, 85.24s/it, lr=0.001, test_MAE=0.744, time=50.3, train_MAE=0.613, train_loss=0.636, val_MAE=0.685, val_loss=0.709]Epoch 5:   0%|          | 5/1000 [07:27<23:33:37, 85.24s/it, lr=0.001, test_MAE=0.742, time=50.2, train_MAE=0.609, train_loss=0.633, val_MAE=0.706, val_loss=0.731]Epoch 5:   1%|          | 6/1000 [07:27<20:38:14, 74.74s/it, lr=0.001, test_MAE=0.742, time=50.2, train_MAE=0.609, train_loss=0.633, val_MAE=0.706, val_loss=0.731]Epoch 6:   1%|          | 6/1000 [07:27<20:38:14, 74.74s/it, lr=0.001, test_MAE=0.742, time=50.2, train_MAE=0.609, train_loss=0.633, val_MAE=0.706, val_loss=0.731]Epoch 6:   1%|          | 6/1000 [08:17<20:38:14, 74.74s/it, lr=0.001, test_MAE=0.7, time=50.6, train_MAE=0.593, train_loss=0.619, val_MAE=0.649, val_loss=0.675]  Epoch 6:   1%|          | 7/1000 [08:18<18:36:58, 67.49s/it, lr=0.001, test_MAE=0.7, time=50.6, train_MAE=0.593, train_loss=0.619, val_MAE=0.649, val_loss=0.675]Epoch 7:   1%|          | 7/1000 [08:18<18:36:58, 67.49s/it, lr=0.001, test_MAE=0.7, time=50.6, train_MAE=0.593, train_loss=0.619, val_MAE=0.649, val_loss=0.675]Epoch 7:   1%|          | 7/1000 [09:08<18:36:58, 67.49s/it, lr=0.001, test_MAE=0.698, time=50.2, train_MAE=0.582, train_loss=0.609, val_MAE=0.63, val_loss=0.658]Epoch 7:   1%|          | 8/1000 [09:08<17:10:20, 62.32s/it, lr=0.001, test_MAE=0.698, time=50.2, train_MAE=0.582, train_loss=0.609, val_MAE=0.63, val_loss=0.658]Epoch 8:   1%|          | 8/1000 [09:08<17:10:20, 62.32s/it, lr=0.001, test_MAE=0.698, time=50.2, train_MAE=0.582, train_loss=0.609, val_MAE=0.63, val_loss=0.658]Epoch 8:   1%|          | 8/1000 [09:58<17:10:20, 62.32s/it, lr=0.001, test_MAE=0.694, time=50.2, train_MAE=0.576, train_loss=0.605, val_MAE=0.637, val_loss=0.666]Epoch 8:   1%|          | 9/1000 [09:58<16:09:11, 58.68s/it, lr=0.001, test_MAE=0.694, time=50.2, train_MAE=0.576, train_loss=0.605, val_MAE=0.637, val_loss=0.666]Epoch 9:   1%|          | 9/1000 [09:58<16:09:11, 58.68s/it, lr=0.001, test_MAE=0.694, time=50.2, train_MAE=0.576, train_loss=0.605, val_MAE=0.637, val_loss=0.666]Epoch 9:   1%|          | 9/1000 [10:48<16:09:11, 58.68s/it, lr=0.001, test_MAE=0.768, time=50.2, train_MAE=0.552, train_loss=0.582, val_MAE=0.699, val_loss=0.729]Epoch 9:   1%|          | 10/1000 [10:48<15:26:03, 56.12s/it, lr=0.001, test_MAE=0.768, time=50.2, train_MAE=0.552, train_loss=0.582, val_MAE=0.699, val_loss=0.729]Epoch 10:   1%|          | 10/1000 [10:48<15:26:03, 56.12s/it, lr=0.001, test_MAE=0.768, time=50.2, train_MAE=0.552, train_loss=0.582, val_MAE=0.699, val_loss=0.729]Epoch 10:   1%|          | 10/1000 [11:38<15:26:03, 56.12s/it, lr=0.001, test_MAE=0.669, time=49.7, train_MAE=0.559, train_loss=0.59, val_MAE=0.623, val_loss=0.655] Epoch 10:   1%|          | 11/1000 [11:38<14:53:31, 54.21s/it, lr=0.001, test_MAE=0.669, time=49.7, train_MAE=0.559, train_loss=0.59, val_MAE=0.623, val_loss=0.655]Epoch 11:   1%|          | 11/1000 [11:38<14:53:31, 54.21s/it, lr=0.001, test_MAE=0.669, time=49.7, train_MAE=0.559, train_loss=0.59, val_MAE=0.623, val_loss=0.655]Epoch 11:   1%|          | 11/1000 [12:27<14:53:31, 54.21s/it, lr=0.001, test_MAE=0.762, time=49.4, train_MAE=0.547, train_loss=0.58, val_MAE=0.727, val_loss=0.76] Epoch 11:   1%|          | 12/1000 [12:27<14:28:56, 52.77s/it, lr=0.001, test_MAE=0.762, time=49.4, train_MAE=0.547, train_loss=0.58, val_MAE=0.727, val_loss=0.76]Epoch 12:   1%|          | 12/1000 [12:27<14:28:56, 52.77s/it, lr=0.001, test_MAE=0.762, time=49.4, train_MAE=0.547, train_loss=0.58, val_MAE=0.727, val_loss=0.76]Epoch 12:   1%|          | 12/1000 [13:17<14:28:56, 52.77s/it, lr=0.001, test_MAE=0.68, time=50, train_MAE=0.538, train_loss=0.573, val_MAE=0.641, val_loss=0.675] Epoch 12:   1%|▏         | 13/1000 [13:17<14:14:24, 51.94s/it, lr=0.001, test_MAE=0.68, time=50, train_MAE=0.538, train_loss=0.573, val_MAE=0.641, val_loss=0.675]Epoch 13:   1%|▏         | 13/1000 [13:17<14:14:24, 51.94s/it, lr=0.001, test_MAE=0.68, time=50, train_MAE=0.538, train_loss=0.573, val_MAE=0.641, val_loss=0.675]Epoch 13:   1%|▏         | 13/1000 [14:07<14:14:24, 51.94s/it, lr=0.001, test_MAE=0.709, time=49.8, train_MAE=0.523, train_loss=0.558, val_MAE=0.673, val_loss=0.708]Epoch 13:   1%|▏         | 14/1000 [14:07<14:02:51, 51.29s/it, lr=0.001, test_MAE=0.709, time=49.8, train_MAE=0.523, train_loss=0.558, val_MAE=0.673, val_loss=0.708]Epoch 14:   1%|▏         | 14/1000 [14:07<14:02:51, 51.29s/it, lr=0.001, test_MAE=0.709, time=49.8, train_MAE=0.523, train_loss=0.558, val_MAE=0.673, val_loss=0.708]Epoch 14:   1%|▏         | 14/1000 [14:56<14:02:51, 51.29s/it, lr=0.001, test_MAE=0.796, time=49.4, train_MAE=0.519, train_loss=0.555, val_MAE=0.748, val_loss=0.786]Epoch 14:   2%|▏         | 15/1000 [14:56<13:52:43, 50.72s/it, lr=0.001, test_MAE=0.796, time=49.4, train_MAE=0.519, train_loss=0.555, val_MAE=0.748, val_loss=0.786]Epoch 15:   2%|▏         | 15/1000 [14:56<13:52:43, 50.72s/it, lr=0.001, test_MAE=0.796, time=49.4, train_MAE=0.519, train_loss=0.555, val_MAE=0.748, val_loss=0.786]Epoch 15:   2%|▏         | 15/1000 [15:46<13:52:43, 50.72s/it, lr=0.001, test_MAE=0.716, time=50, train_MAE=0.512, train_loss=0.549, val_MAE=0.661, val_loss=0.699]  Epoch 15:   2%|▏         | 16/1000 [15:46<13:48:24, 50.51s/it, lr=0.001, test_MAE=0.716, time=50, train_MAE=0.512, train_loss=0.549, val_MAE=0.661, val_loss=0.699]Epoch 16:   2%|▏         | 16/1000 [15:46<13:48:24, 50.51s/it, lr=0.001, test_MAE=0.716, time=50, train_MAE=0.512, train_loss=0.549, val_MAE=0.661, val_loss=0.699]Epoch 16:   2%|▏         | 16/1000 [16:36<13:48:24, 50.51s/it, lr=0.001, test_MAE=0.727, time=49.7, train_MAE=0.495, train_loss=0.534, val_MAE=0.705, val_loss=0.744]Epoch    17: reducing learning rate of group 0 to 5.0000e-04.
Epoch 16:   2%|▏         | 17/1000 [16:36<13:43:42, 50.28s/it, lr=0.001, test_MAE=0.727, time=49.7, train_MAE=0.495, train_loss=0.534, val_MAE=0.705, val_loss=0.744]Epoch 17:   2%|▏         | 17/1000 [16:36<13:43:42, 50.28s/it, lr=0.001, test_MAE=0.727, time=49.7, train_MAE=0.495, train_loss=0.534, val_MAE=0.705, val_loss=0.744]Epoch 17:   2%|▏         | 17/1000 [17:26<13:43:42, 50.28s/it, lr=0.0005, test_MAE=0.693, time=49.4, train_MAE=0.464, train_loss=0.503, val_MAE=0.65, val_loss=0.688]Epoch 17:   2%|▏         | 18/1000 [17:26<13:38:39, 50.02s/it, lr=0.0005, test_MAE=0.693, time=49.4, train_MAE=0.464, train_loss=0.503, val_MAE=0.65, val_loss=0.688]Epoch 18:   2%|▏         | 18/1000 [17:26<13:38:39, 50.02s/it, lr=0.0005, test_MAE=0.693, time=49.4, train_MAE=0.464, train_loss=0.503, val_MAE=0.65, val_loss=0.688]Epoch 18:   2%|▏         | 18/1000 [18:16<13:38:39, 50.02s/it, lr=0.0005, test_MAE=0.689, time=50.1, train_MAE=0.444, train_loss=0.481, val_MAE=0.648, val_loss=0.685]Epoch 18:   2%|▏         | 19/1000 [18:16<13:38:06, 50.04s/it, lr=0.0005, test_MAE=0.689, time=50.1, train_MAE=0.444, train_loss=0.481, val_MAE=0.648, val_loss=0.685]Epoch 19:   2%|▏         | 19/1000 [18:16<13:38:06, 50.04s/it, lr=0.0005, test_MAE=0.689, time=50.1, train_MAE=0.444, train_loss=0.481, val_MAE=0.648, val_loss=0.685]Epoch 19:   2%|▏         | 19/1000 [19:05<13:38:06, 50.04s/it, lr=0.0005, test_MAE=0.681, time=49.7, train_MAE=0.436, train_loss=0.474, val_MAE=0.637, val_loss=0.675]Epoch 19:   2%|▏         | 20/1000 [19:05<13:35:37, 49.94s/it, lr=0.0005, test_MAE=0.681, time=49.7, train_MAE=0.436, train_loss=0.474, val_MAE=0.637, val_loss=0.675]Epoch 20:   2%|▏         | 20/1000 [19:05<13:35:37, 49.94s/it, lr=0.0005, test_MAE=0.681, time=49.7, train_MAE=0.436, train_loss=0.474, val_MAE=0.637, val_loss=0.675]Epoch 20:   2%|▏         | 20/1000 [19:55<13:35:37, 49.94s/it, lr=0.0005, test_MAE=0.698, time=49.7, train_MAE=0.435, train_loss=0.473, val_MAE=0.68, val_loss=0.718] Epoch 20:   2%|▏         | 21/1000 [19:55<13:33:35, 49.86s/it, lr=0.0005, test_MAE=0.698, time=49.7, train_MAE=0.435, train_loss=0.473, val_MAE=0.68, val_loss=0.718]Epoch 21:   2%|▏         | 21/1000 [19:55<13:33:35, 49.86s/it, lr=0.0005, test_MAE=0.698, time=49.7, train_MAE=0.435, train_loss=0.473, val_MAE=0.68, val_loss=0.718]Epoch 21:   2%|▏         | 21/1000 [20:45<13:33:35, 49.86s/it, lr=0.0005, test_MAE=0.714, time=50, train_MAE=0.416, train_loss=0.455, val_MAE=0.695, val_loss=0.734] Epoch 21:   2%|▏         | 22/1000 [20:45<13:33:41, 49.92s/it, lr=0.0005, test_MAE=0.714, time=50, train_MAE=0.416, train_loss=0.455, val_MAE=0.695, val_loss=0.734]Epoch 22:   2%|▏         | 22/1000 [20:45<13:33:41, 49.92s/it, lr=0.0005, test_MAE=0.714, time=50, train_MAE=0.416, train_loss=0.455, val_MAE=0.695, val_loss=0.734]Epoch 22:   2%|▏         | 22/1000 [21:35<13:33:41, 49.92s/it, lr=0.0005, test_MAE=0.677, time=49.4, train_MAE=0.424, train_loss=0.463, val_MAE=0.65, val_loss=0.689]Epoch    23: reducing learning rate of group 0 to 2.5000e-04.
Epoch 22:   2%|▏         | 23/1000 [21:35<13:30:23, 49.77s/it, lr=0.0005, test_MAE=0.677, time=49.4, train_MAE=0.424, train_loss=0.463, val_MAE=0.65, val_loss=0.689]Epoch 23:   2%|▏         | 23/1000 [21:35<13:30:23, 49.77s/it, lr=0.0005, test_MAE=0.677, time=49.4, train_MAE=0.424, train_loss=0.463, val_MAE=0.65, val_loss=0.689]Epoch 23:   2%|▏         | 23/1000 [22:25<13:30:23, 49.77s/it, lr=0.00025, test_MAE=0.69, time=50, train_MAE=0.394, train_loss=0.432, val_MAE=0.656, val_loss=0.693] Epoch 23:   2%|▏         | 24/1000 [22:25<13:30:47, 49.84s/it, lr=0.00025, test_MAE=0.69, time=50, train_MAE=0.394, train_loss=0.432, val_MAE=0.656, val_loss=0.693]Epoch 24:   2%|▏         | 24/1000 [22:25<13:30:47, 49.84s/it, lr=0.00025, test_MAE=0.69, time=50, train_MAE=0.394, train_loss=0.432, val_MAE=0.656, val_loss=0.693]Epoch 24:   2%|▏         | 24/1000 [23:14<13:30:47, 49.84s/it, lr=0.00025, test_MAE=0.689, time=49.9, train_MAE=0.381, train_loss=0.418, val_MAE=0.647, val_loss=0.685]Epoch 24:   2%|▎         | 25/1000 [23:14<13:30:11, 49.86s/it, lr=0.00025, test_MAE=0.689, time=49.9, train_MAE=0.381, train_loss=0.418, val_MAE=0.647, val_loss=0.685]Epoch 25:   2%|▎         | 25/1000 [23:14<13:30:11, 49.86s/it, lr=0.00025, test_MAE=0.689, time=49.9, train_MAE=0.381, train_loss=0.418, val_MAE=0.647, val_loss=0.685]Epoch 25:   2%|▎         | 25/1000 [24:04<13:30:11, 49.86s/it, lr=0.00025, test_MAE=0.701, time=49.8, train_MAE=0.361, train_loss=0.398, val_MAE=0.664, val_loss=0.701]Epoch 25:   3%|▎         | 26/1000 [24:04<13:29:11, 49.85s/it, lr=0.00025, test_MAE=0.701, time=49.8, train_MAE=0.361, train_loss=0.398, val_MAE=0.664, val_loss=0.701]Epoch 26:   3%|▎         | 26/1000 [24:04<13:29:11, 49.85s/it, lr=0.00025, test_MAE=0.701, time=49.8, train_MAE=0.361, train_loss=0.398, val_MAE=0.664, val_loss=0.701]Epoch 26:   3%|▎         | 26/1000 [24:54<13:29:11, 49.85s/it, lr=0.00025, test_MAE=0.682, time=50.1, train_MAE=0.358, train_loss=0.395, val_MAE=0.655, val_loss=0.693]Epoch 26:   3%|▎         | 27/1000 [24:54<13:29:45, 49.93s/it, lr=0.00025, test_MAE=0.682, time=50.1, train_MAE=0.358, train_loss=0.395, val_MAE=0.655, val_loss=0.693]Epoch 27:   3%|▎         | 27/1000 [24:54<13:29:45, 49.93s/it, lr=0.00025, test_MAE=0.682, time=50.1, train_MAE=0.358, train_loss=0.395, val_MAE=0.655, val_loss=0.693]Epoch 27:   3%|▎         | 27/1000 [25:44<13:29:45, 49.93s/it, lr=0.00025, test_MAE=0.712, time=49.8, train_MAE=0.353, train_loss=0.391, val_MAE=0.677, val_loss=0.715]Epoch 27:   3%|▎         | 28/1000 [25:44<13:28:31, 49.91s/it, lr=0.00025, test_MAE=0.712, time=49.8, train_MAE=0.353, train_loss=0.391, val_MAE=0.677, val_loss=0.715]Epoch 28:   3%|▎         | 28/1000 [25:44<13:28:31, 49.91s/it, lr=0.00025, test_MAE=0.712, time=49.8, train_MAE=0.353, train_loss=0.391, val_MAE=0.677, val_loss=0.715]Epoch 28:   3%|▎         | 28/1000 [26:34<13:28:31, 49.91s/it, lr=0.00025, test_MAE=0.713, time=49.5, train_MAE=0.362, train_loss=0.4, val_MAE=0.685, val_loss=0.723]  Epoch    29: reducing learning rate of group 0 to 1.2500e-04.
Epoch 28:   3%|▎         | 29/1000 [26:34<13:25:59, 49.80s/it, lr=0.00025, test_MAE=0.713, time=49.5, train_MAE=0.362, train_loss=0.4, val_MAE=0.685, val_loss=0.723]Epoch 29:   3%|▎         | 29/1000 [26:34<13:25:59, 49.80s/it, lr=0.00025, test_MAE=0.713, time=49.5, train_MAE=0.362, train_loss=0.4, val_MAE=0.685, val_loss=0.723]Epoch 29:   3%|▎         | 29/1000 [27:24<13:25:59, 49.80s/it, lr=0.000125, test_MAE=0.692, time=50.4, train_MAE=0.343, train_loss=0.381, val_MAE=0.669, val_loss=0.706]Epoch 29:   3%|▎         | 30/1000 [27:24<13:28:18, 50.00s/it, lr=0.000125, test_MAE=0.692, time=50.4, train_MAE=0.343, train_loss=0.381, val_MAE=0.669, val_loss=0.706]Epoch 30:   3%|▎         | 30/1000 [27:24<13:28:18, 50.00s/it, lr=0.000125, test_MAE=0.692, time=50.4, train_MAE=0.343, train_loss=0.381, val_MAE=0.669, val_loss=0.706]Epoch 30:   3%|▎         | 30/1000 [28:14<13:28:18, 50.00s/it, lr=0.000125, test_MAE=0.706, time=49.8, train_MAE=0.323, train_loss=0.36, val_MAE=0.677, val_loss=0.713] Epoch 30:   3%|▎         | 31/1000 [28:14<13:26:38, 49.95s/it, lr=0.000125, test_MAE=0.706, time=49.8, train_MAE=0.323, train_loss=0.36, val_MAE=0.677, val_loss=0.713]Epoch 31:   3%|▎         | 31/1000 [28:14<13:26:38, 49.95s/it, lr=0.000125, test_MAE=0.706, time=49.8, train_MAE=0.323, train_loss=0.36, val_MAE=0.677, val_loss=0.713]Epoch 31:   3%|▎         | 31/1000 [29:04<13:26:38, 49.95s/it, lr=0.000125, test_MAE=0.715, time=49.5, train_MAE=0.333, train_loss=0.37, val_MAE=0.692, val_loss=0.729]Epoch 31:   3%|▎         | 32/1000 [29:04<13:23:44, 49.82s/it, lr=0.000125, test_MAE=0.715, time=49.5, train_MAE=0.333, train_loss=0.37, val_MAE=0.692, val_loss=0.729]Epoch 32:   3%|▎         | 32/1000 [29:04<13:23:44, 49.82s/it, lr=0.000125, test_MAE=0.715, time=49.5, train_MAE=0.333, train_loss=0.37, val_MAE=0.692, val_loss=0.729]Epoch 32:   3%|▎         | 32/1000 [29:54<13:23:44, 49.82s/it, lr=0.000125, test_MAE=0.701, time=50.1, train_MAE=0.334, train_loss=0.371, val_MAE=0.676, val_loss=0.713]Epoch 32:   3%|▎         | 33/1000 [29:54<13:24:25, 49.91s/it, lr=0.000125, test_MAE=0.701, time=50.1, train_MAE=0.334, train_loss=0.371, val_MAE=0.676, val_loss=0.713]Epoch 33:   3%|▎         | 33/1000 [29:54<13:24:25, 49.91s/it, lr=0.000125, test_MAE=0.701, time=50.1, train_MAE=0.334, train_loss=0.371, val_MAE=0.676, val_loss=0.713]Epoch 33:   3%|▎         | 33/1000 [30:44<13:24:25, 49.91s/it, lr=0.000125, test_MAE=0.709, time=49.8, train_MAE=0.32, train_loss=0.356, val_MAE=0.688, val_loss=0.725] Epoch 33:   3%|▎         | 34/1000 [30:44<13:23:18, 49.89s/it, lr=0.000125, test_MAE=0.709, time=49.8, train_MAE=0.32, train_loss=0.356, val_MAE=0.688, val_loss=0.725]Epoch 34:   3%|▎         | 34/1000 [30:44<13:23:18, 49.89s/it, lr=0.000125, test_MAE=0.709, time=49.8, train_MAE=0.32, train_loss=0.356, val_MAE=0.688, val_loss=0.725]Epoch 34:   3%|▎         | 34/1000 [31:33<13:23:18, 49.89s/it, lr=0.000125, test_MAE=0.711, time=49.5, train_MAE=0.318, train_loss=0.355, val_MAE=0.692, val_loss=0.728]Epoch    35: reducing learning rate of group 0 to 6.2500e-05.
Epoch 34:   4%|▎         | 35/1000 [31:33<13:20:48, 49.79s/it, lr=0.000125, test_MAE=0.711, time=49.5, train_MAE=0.318, train_loss=0.355, val_MAE=0.692, val_loss=0.728]Epoch 35:   4%|▎         | 35/1000 [31:33<13:20:48, 49.79s/it, lr=0.000125, test_MAE=0.711, time=49.5, train_MAE=0.318, train_loss=0.355, val_MAE=0.692, val_loss=0.728]Epoch 35:   4%|▎         | 35/1000 [32:23<13:20:48, 49.79s/it, lr=6.25e-5, test_MAE=0.703, time=50.1, train_MAE=0.303, train_loss=0.339, val_MAE=0.674, val_loss=0.71]  Epoch 35:   4%|▎         | 36/1000 [32:23<13:21:47, 49.90s/it, lr=6.25e-5, test_MAE=0.703, time=50.1, train_MAE=0.303, train_loss=0.339, val_MAE=0.674, val_loss=0.71]Epoch 36:   4%|▎         | 36/1000 [32:23<13:21:47, 49.90s/it, lr=6.25e-5, test_MAE=0.703, time=50.1, train_MAE=0.303, train_loss=0.339, val_MAE=0.674, val_loss=0.71]Epoch 36:   4%|▎         | 36/1000 [33:13<13:21:47, 49.90s/it, lr=6.25e-5, test_MAE=0.716, time=49.8, train_MAE=0.303, train_loss=0.339, val_MAE=0.696, val_loss=0.731]Epoch 36:   4%|▎         | 37/1000 [33:13<13:20:33, 49.88s/it, lr=6.25e-5, test_MAE=0.716, time=49.8, train_MAE=0.303, train_loss=0.339, val_MAE=0.696, val_loss=0.731]Epoch 37:   4%|▎         | 37/1000 [33:13<13:20:33, 49.88s/it, lr=6.25e-5, test_MAE=0.716, time=49.8, train_MAE=0.303, train_loss=0.339, val_MAE=0.696, val_loss=0.731]Epoch 37:   4%|▎         | 37/1000 [34:03<13:20:33, 49.88s/it, lr=6.25e-5, test_MAE=0.702, time=49.5, train_MAE=0.301, train_loss=0.337, val_MAE=0.671, val_loss=0.707]Epoch 37:   4%|▍         | 38/1000 [34:03<13:18:10, 49.78s/it, lr=6.25e-5, test_MAE=0.702, time=49.5, train_MAE=0.301, train_loss=0.337, val_MAE=0.671, val_loss=0.707]Epoch 38:   4%|▍         | 38/1000 [34:03<13:18:10, 49.78s/it, lr=6.25e-5, test_MAE=0.702, time=49.5, train_MAE=0.301, train_loss=0.337, val_MAE=0.671, val_loss=0.707]Epoch 38:   4%|▍         | 38/1000 [34:53<13:18:10, 49.78s/it, lr=6.25e-5, test_MAE=0.702, time=50.2, train_MAE=0.302, train_loss=0.337, val_MAE=0.677, val_loss=0.713]Epoch 38:   4%|▍         | 39/1000 [34:53<13:19:15, 49.90s/it, lr=6.25e-5, test_MAE=0.702, time=50.2, train_MAE=0.302, train_loss=0.337, val_MAE=0.677, val_loss=0.713]Epoch 39:   4%|▍         | 39/1000 [34:53<13:19:15, 49.90s/it, lr=6.25e-5, test_MAE=0.702, time=50.2, train_MAE=0.302, train_loss=0.337, val_MAE=0.677, val_loss=0.713]Epoch 39:   4%|▍         | 39/1000 [35:43<13:19:15, 49.90s/it, lr=6.25e-5, test_MAE=0.711, time=49.8, train_MAE=0.301, train_loss=0.337, val_MAE=0.68, val_loss=0.716] Epoch 39:   4%|▍         | 40/1000 [35:43<13:18:16, 49.89s/it, lr=6.25e-5, test_MAE=0.711, time=49.8, train_MAE=0.301, train_loss=0.337, val_MAE=0.68, val_loss=0.716]Epoch 40:   4%|▍         | 40/1000 [35:43<13:18:16, 49.89s/it, lr=6.25e-5, test_MAE=0.711, time=49.8, train_MAE=0.301, train_loss=0.337, val_MAE=0.68, val_loss=0.716]Epoch 40:   4%|▍         | 40/1000 [36:33<13:18:16, 49.89s/it, lr=6.25e-5, test_MAE=0.703, time=49.8, train_MAE=0.305, train_loss=0.34, val_MAE=0.675, val_loss=0.711]Epoch    41: reducing learning rate of group 0 to 3.1250e-05.
Epoch 40:   4%|▍         | 41/1000 [36:33<13:17:10, 49.88s/it, lr=6.25e-5, test_MAE=0.703, time=49.8, train_MAE=0.305, train_loss=0.34, val_MAE=0.675, val_loss=0.711]Epoch 41:   4%|▍         | 41/1000 [36:33<13:17:10, 49.88s/it, lr=6.25e-5, test_MAE=0.703, time=49.8, train_MAE=0.305, train_loss=0.34, val_MAE=0.675, val_loss=0.711]Epoch 41:   4%|▍         | 41/1000 [37:23<13:17:10, 49.88s/it, lr=3.13e-5, test_MAE=0.705, time=50.2, train_MAE=0.287, train_loss=0.323, val_MAE=0.68, val_loss=0.716]Epoch 41:   4%|▍         | 42/1000 [37:23<13:17:53, 49.97s/it, lr=3.13e-5, test_MAE=0.705, time=50.2, train_MAE=0.287, train_loss=0.323, val_MAE=0.68, val_loss=0.716]Epoch 42:   4%|▍         | 42/1000 [37:23<13:17:53, 49.97s/it, lr=3.13e-5, test_MAE=0.705, time=50.2, train_MAE=0.287, train_loss=0.323, val_MAE=0.68, val_loss=0.716]Epoch 42:   4%|▍         | 42/1000 [38:12<13:17:53, 49.97s/it, lr=3.13e-5, test_MAE=0.705, time=49.5, train_MAE=0.294, train_loss=0.33, val_MAE=0.675, val_loss=0.711]Epoch 42:   4%|▍         | 43/1000 [38:12<13:14:47, 49.83s/it, lr=3.13e-5, test_MAE=0.705, time=49.5, train_MAE=0.294, train_loss=0.33, val_MAE=0.675, val_loss=0.711]Epoch 43:   4%|▍         | 43/1000 [38:12<13:14:47, 49.83s/it, lr=3.13e-5, test_MAE=0.705, time=49.5, train_MAE=0.294, train_loss=0.33, val_MAE=0.675, val_loss=0.711]Epoch 43:   4%|▍         | 43/1000 [39:02<13:14:47, 49.83s/it, lr=3.13e-5, test_MAE=0.703, time=50.2, train_MAE=0.288, train_loss=0.324, val_MAE=0.677, val_loss=0.713]Epoch 43:   4%|▍         | 44/1000 [39:02<13:15:32, 49.93s/it, lr=3.13e-5, test_MAE=0.703, time=50.2, train_MAE=0.288, train_loss=0.324, val_MAE=0.677, val_loss=0.713]Epoch 44:   4%|▍         | 44/1000 [39:02<13:15:32, 49.93s/it, lr=3.13e-5, test_MAE=0.703, time=50.2, train_MAE=0.288, train_loss=0.324, val_MAE=0.677, val_loss=0.713]Epoch 44:   4%|▍         | 44/1000 [39:52<13:15:32, 49.93s/it, lr=3.13e-5, test_MAE=0.715, time=49.9, train_MAE=0.281, train_loss=0.317, val_MAE=0.691, val_loss=0.727]Epoch 44:   4%|▍         | 45/1000 [39:52<13:14:28, 49.92s/it, lr=3.13e-5, test_MAE=0.715, time=49.9, train_MAE=0.281, train_loss=0.317, val_MAE=0.691, val_loss=0.727]Epoch 45:   4%|▍         | 45/1000 [39:52<13:14:28, 49.92s/it, lr=3.13e-5, test_MAE=0.715, time=49.9, train_MAE=0.281, train_loss=0.317, val_MAE=0.691, val_loss=0.727]Epoch 45:   4%|▍         | 45/1000 [40:42<13:14:28, 49.92s/it, lr=3.13e-5, test_MAE=0.705, time=49.9, train_MAE=0.274, train_loss=0.31, val_MAE=0.68, val_loss=0.716]  Epoch 45:   5%|▍         | 46/1000 [40:42<13:13:27, 49.90s/it, lr=3.13e-5, test_MAE=0.705, time=49.9, train_MAE=0.274, train_loss=0.31, val_MAE=0.68, val_loss=0.716]Epoch 46:   5%|▍         | 46/1000 [40:42<13:13:27, 49.90s/it, lr=3.13e-5, test_MAE=0.705, time=49.9, train_MAE=0.274, train_loss=0.31, val_MAE=0.68, val_loss=0.716]Epoch 46:   5%|▍         | 46/1000 [41:32<13:13:27, 49.90s/it, lr=3.13e-5, test_MAE=0.713, time=50.1, train_MAE=0.28, train_loss=0.315, val_MAE=0.692, val_loss=0.727]Epoch    47: reducing learning rate of group 0 to 1.5625e-05.
Epoch 46:   5%|▍         | 47/1000 [41:32<13:13:47, 49.98s/it, lr=3.13e-5, test_MAE=0.713, time=50.1, train_MAE=0.28, train_loss=0.315, val_MAE=0.692, val_loss=0.727]Epoch 47:   5%|▍         | 47/1000 [41:32<13:13:47, 49.98s/it, lr=3.13e-5, test_MAE=0.713, time=50.1, train_MAE=0.28, train_loss=0.315, val_MAE=0.692, val_loss=0.727]Epoch 47:   5%|▍         | 47/1000 [42:22<13:13:47, 49.98s/it, lr=1.56e-5, test_MAE=0.711, time=49.9, train_MAE=0.276, train_loss=0.312, val_MAE=0.685, val_loss=0.72]Epoch 47:   5%|▍         | 48/1000 [42:22<13:12:30, 49.95s/it, lr=1.56e-5, test_MAE=0.711, time=49.9, train_MAE=0.276, train_loss=0.312, val_MAE=0.685, val_loss=0.72]Epoch 48:   5%|▍         | 48/1000 [42:22<13:12:30, 49.95s/it, lr=1.56e-5, test_MAE=0.711, time=49.9, train_MAE=0.276, train_loss=0.312, val_MAE=0.685, val_loss=0.72]Epoch 48:   5%|▍         | 48/1000 [43:12<13:12:30, 49.95s/it, lr=1.56e-5, test_MAE=0.719, time=49.5, train_MAE=0.284, train_loss=0.32, val_MAE=0.698, val_loss=0.734]Epoch 48:   5%|▍         | 49/1000 [43:12<13:09:49, 49.83s/it, lr=1.56e-5, test_MAE=0.719, time=49.5, train_MAE=0.284, train_loss=0.32, val_MAE=0.698, val_loss=0.734]Epoch 49:   5%|▍         | 49/1000 [43:12<13:09:49, 49.83s/it, lr=1.56e-5, test_MAE=0.719, time=49.5, train_MAE=0.284, train_loss=0.32, val_MAE=0.698, val_loss=0.734]Epoch 49:   5%|▍         | 49/1000 [44:02<13:09:49, 49.83s/it, lr=1.56e-5, test_MAE=0.708, time=50.4, train_MAE=0.27, train_loss=0.306, val_MAE=0.682, val_loss=0.718]Epoch 49:   5%|▌         | 50/1000 [44:02<13:12:04, 50.03s/it, lr=1.56e-5, test_MAE=0.708, time=50.4, train_MAE=0.27, train_loss=0.306, val_MAE=0.682, val_loss=0.718]Epoch 50:   5%|▌         | 50/1000 [44:02<13:12:04, 50.03s/it, lr=1.56e-5, test_MAE=0.708, time=50.4, train_MAE=0.27, train_loss=0.306, val_MAE=0.682, val_loss=0.718]Epoch 50:   5%|▌         | 50/1000 [44:52<13:12:04, 50.03s/it, lr=1.56e-5, test_MAE=0.709, time=49.8, train_MAE=0.278, train_loss=0.313, val_MAE=0.687, val_loss=0.722]Epoch 50:   5%|▌         | 51/1000 [44:52<13:10:25, 49.97s/it, lr=1.56e-5, test_MAE=0.709, time=49.8, train_MAE=0.278, train_loss=0.313, val_MAE=0.687, val_loss=0.722]Epoch 51:   5%|▌         | 51/1000 [44:52<13:10:25, 49.97s/it, lr=1.56e-5, test_MAE=0.709, time=49.8, train_MAE=0.278, train_loss=0.313, val_MAE=0.687, val_loss=0.722]Epoch 51:   5%|▌         | 51/1000 [45:42<13:10:25, 49.97s/it, lr=1.56e-5, test_MAE=0.712, time=49.5, train_MAE=0.274, train_loss=0.309, val_MAE=0.69, val_loss=0.726] Epoch 51:   5%|▌         | 52/1000 [45:42<13:07:26, 49.84s/it, lr=1.56e-5, test_MAE=0.712, time=49.5, train_MAE=0.274, train_loss=0.309, val_MAE=0.69, val_loss=0.726]Epoch 52:   5%|▌         | 52/1000 [45:42<13:07:26, 49.84s/it, lr=1.56e-5, test_MAE=0.712, time=49.5, train_MAE=0.274, train_loss=0.309, val_MAE=0.69, val_loss=0.726]Epoch 52:   5%|▌         | 52/1000 [46:32<13:07:26, 49.84s/it, lr=1.56e-5, test_MAE=0.709, time=50.2, train_MAE=0.272, train_loss=0.308, val_MAE=0.686, val_loss=0.721]Epoch    53: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 52:   5%|▌         | 52/1000 [46:32<14:08:26, 53.70s/it, lr=1.56e-5, test_MAE=0.709, time=50.2, train_MAE=0.272, train_loss=0.308, val_MAE=0.686, val_loss=0.721]
Test MAE: 0.7091
Train MAE: 0.2390
Convergence Time (Epochs): 52.0000
TOTAL TIME TAKEN: 2825.9858s
AVG TIME PER EPOCH: 52.6715s
