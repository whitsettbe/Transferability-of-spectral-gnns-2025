I'm echoing to stdout
I'm echoing to stderr
My JobID is 57650029
I have 8 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 4.9395s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 4, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'rational_vec', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_sub', 'num_eigs': 16, 'bias_mode': 'spatial', 'eigval_hidden_dim': 5, 'eigval_num_hidden_layer': 3, 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 0.0, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/aug07/zinc_train_rec.csv', 'test': 'supp_data/molecules/aug07/zinc_test_rec.csv', 'val': 'supp_data/molecules/aug07/zinc_val_rec.csv'}, 'fixMissingPhi1': False, 'extraOrtho': False, 'doublePrecision': True, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [03:22<?, ?it/s, lr=0.001, test_MAE=1.37, time=202, train_MAE=1.24, train_loss=1.24, val_MAE=1.3, val_loss=1.3]Epoch 0:   0%|          | 1/1000 [03:22<56:04:50, 202.09s/it, lr=0.001, test_MAE=1.37, time=202, train_MAE=1.24, train_loss=1.24, val_MAE=1.3, val_loss=1.3]Epoch 1:   0%|          | 1/1000 [03:22<56:04:50, 202.09s/it, lr=0.001, test_MAE=1.37, time=202, train_MAE=1.24, train_loss=1.24, val_MAE=1.3, val_loss=1.3]Epoch 1:   0%|          | 1/1000 [06:26<56:04:50, 202.09s/it, lr=0.001, test_MAE=1.29, time=185, train_MAE=0.842, train_loss=0.842, val_MAE=1.23, val_loss=1.23]Epoch 1:   0%|          | 2/1000 [06:26<54:34:42, 196.88s/it, lr=0.001, test_MAE=1.29, time=185, train_MAE=0.842, train_loss=0.842, val_MAE=1.23, val_loss=1.23]Epoch 2:   0%|          | 2/1000 [06:26<54:34:42, 196.88s/it, lr=0.001, test_MAE=1.29, time=185, train_MAE=0.842, train_loss=0.842, val_MAE=1.23, val_loss=1.23]Epoch 2:   0%|          | 2/1000 [09:31<54:34:42, 196.88s/it, lr=0.001, test_MAE=0.905, time=185, train_MAE=0.716, train_loss=0.716, val_MAE=0.837, val_loss=0.837]Epoch 2:   0%|          | 3/1000 [09:31<53:31:41, 193.28s/it, lr=0.001, test_MAE=0.905, time=185, train_MAE=0.716, train_loss=0.716, val_MAE=0.837, val_loss=0.837]Epoch 3:   0%|          | 3/1000 [09:31<53:31:41, 193.28s/it, lr=0.001, test_MAE=0.905, time=185, train_MAE=0.716, train_loss=0.716, val_MAE=0.837, val_loss=0.837]Epoch 3:   0%|          | 3/1000 [12:36<53:31:41, 193.28s/it, lr=0.001, test_MAE=0.819, time=185, train_MAE=0.67, train_loss=0.67, val_MAE=0.745, val_loss=0.745]  Epoch 3:   0%|          | 4/1000 [12:36<52:46:34, 190.76s/it, lr=0.001, test_MAE=0.819, time=185, train_MAE=0.67, train_loss=0.67, val_MAE=0.745, val_loss=0.745]Epoch 4:   0%|          | 4/1000 [12:36<52:46:34, 190.76s/it, lr=0.001, test_MAE=0.819, time=185, train_MAE=0.67, train_loss=0.67, val_MAE=0.745, val_loss=0.745]Epoch 4:   0%|          | 4/1000 [15:41<52:46:34, 190.76s/it, lr=0.001, test_MAE=0.895, time=185, train_MAE=0.655, train_loss=0.655, val_MAE=0.848, val_loss=0.848]Epoch 4:   0%|          | 5/1000 [15:41<52:14:54, 189.04s/it, lr=0.001, test_MAE=0.895, time=185, train_MAE=0.655, train_loss=0.655, val_MAE=0.848, val_loss=0.848]Epoch 5:   0%|          | 5/1000 [15:41<52:14:54, 189.04s/it, lr=0.001, test_MAE=0.895, time=185, train_MAE=0.655, train_loss=0.655, val_MAE=0.848, val_loss=0.848]Epoch 5:   0%|          | 5/1000 [18:46<52:14:54, 189.04s/it, lr=0.001, test_MAE=0.725, time=185, train_MAE=0.639, train_loss=0.639, val_MAE=0.669, val_loss=0.669]Epoch 5:   1%|          | 6/1000 [18:46<51:51:17, 187.80s/it, lr=0.001, test_MAE=0.725, time=185, train_MAE=0.639, train_loss=0.639, val_MAE=0.669, val_loss=0.669]Epoch 6:   1%|          | 6/1000 [18:46<51:51:17, 187.80s/it, lr=0.001, test_MAE=0.725, time=185, train_MAE=0.639, train_loss=0.639, val_MAE=0.669, val_loss=0.669]Epoch 6:   1%|          | 6/1000 [21:51<51:51:17, 187.80s/it, lr=0.001, test_MAE=0.806, time=185, train_MAE=0.625, train_loss=0.625, val_MAE=0.75, val_loss=0.75]  Epoch 6:   1%|          | 7/1000 [21:51<51:36:03, 187.07s/it, lr=0.001, test_MAE=0.806, time=185, train_MAE=0.625, train_loss=0.625, val_MAE=0.75, val_loss=0.75]Epoch 7:   1%|          | 7/1000 [21:51<51:36:03, 187.07s/it, lr=0.001, test_MAE=0.806, time=185, train_MAE=0.625, train_loss=0.625, val_MAE=0.75, val_loss=0.75]Epoch 7:   1%|          | 7/1000 [24:56<51:36:03, 187.07s/it, lr=0.001, test_MAE=0.822, time=185, train_MAE=0.63, train_loss=0.63, val_MAE=0.767, val_loss=0.767]Epoch 7:   1%|          | 8/1000 [24:56<51:22:47, 186.46s/it, lr=0.001, test_MAE=0.822, time=185, train_MAE=0.63, train_loss=0.63, val_MAE=0.767, val_loss=0.767]Epoch 8:   1%|          | 8/1000 [24:56<51:22:47, 186.46s/it, lr=0.001, test_MAE=0.822, time=185, train_MAE=0.63, train_loss=0.63, val_MAE=0.767, val_loss=0.767]Epoch 8:   1%|          | 8/1000 [28:01<51:22:47, 186.46s/it, lr=0.001, test_MAE=0.766, time=185, train_MAE=0.633, train_loss=0.633, val_MAE=0.72, val_loss=0.72]Epoch 8:   1%|          | 9/1000 [28:01<51:12:04, 186.00s/it, lr=0.001, test_MAE=0.766, time=185, train_MAE=0.633, train_loss=0.633, val_MAE=0.72, val_loss=0.72]Epoch 9:   1%|          | 9/1000 [28:01<51:12:04, 186.00s/it, lr=0.001, test_MAE=0.766, time=185, train_MAE=0.633, train_loss=0.633, val_MAE=0.72, val_loss=0.72]Epoch 9:   1%|          | 9/1000 [31:07<51:12:04, 186.00s/it, lr=0.001, test_MAE=1.88, time=185, train_MAE=0.615, train_loss=0.615, val_MAE=1.85, val_loss=1.85] Epoch 9:   1%|          | 10/1000 [31:07<51:06:10, 185.83s/it, lr=0.001, test_MAE=1.88, time=185, train_MAE=0.615, train_loss=0.615, val_MAE=1.85, val_loss=1.85]Epoch 10:   1%|          | 10/1000 [31:07<51:06:10, 185.83s/it, lr=0.001, test_MAE=1.88, time=185, train_MAE=0.615, train_loss=0.615, val_MAE=1.85, val_loss=1.85]Epoch 10:   1%|          | 10/1000 [34:12<51:06:10, 185.83s/it, lr=0.001, test_MAE=0.868, time=185, train_MAE=0.604, train_loss=0.604, val_MAE=0.799, val_loss=0.799]Epoch 10:   1%|          | 11/1000 [34:12<50:58:38, 185.56s/it, lr=0.001, test_MAE=0.868, time=185, train_MAE=0.604, train_loss=0.604, val_MAE=0.799, val_loss=0.799]Epoch 11:   1%|          | 11/1000 [34:12<50:58:38, 185.56s/it, lr=0.001, test_MAE=0.868, time=185, train_MAE=0.604, train_loss=0.604, val_MAE=0.799, val_loss=0.799]Epoch 11:   1%|          | 11/1000 [37:16<50:58:38, 185.56s/it, lr=0.001, test_MAE=0.793, time=185, train_MAE=0.602, train_loss=0.602, val_MAE=0.748, val_loss=0.748]Epoch    12: reducing learning rate of group 0 to 5.0000e-04.
Epoch 11:   1%|          | 12/1000 [37:16<50:50:32, 185.26s/it, lr=0.001, test_MAE=0.793, time=185, train_MAE=0.602, train_loss=0.602, val_MAE=0.748, val_loss=0.748]Epoch 12:   1%|          | 12/1000 [37:16<50:50:32, 185.26s/it, lr=0.001, test_MAE=0.793, time=185, train_MAE=0.602, train_loss=0.602, val_MAE=0.748, val_loss=0.748]Epoch 12:   1%|          | 12/1000 [40:21<50:50:32, 185.26s/it, lr=0.0005, test_MAE=0.683, time=185, train_MAE=0.587, train_loss=0.587, val_MAE=0.633, val_loss=0.633]Epoch 12:   1%|▏         | 13/1000 [40:21<50:47:25, 185.25s/it, lr=0.0005, test_MAE=0.683, time=185, train_MAE=0.587, train_loss=0.587, val_MAE=0.633, val_loss=0.633]Epoch 13:   1%|▏         | 13/1000 [40:21<50:47:25, 185.25s/it, lr=0.0005, test_MAE=0.683, time=185, train_MAE=0.587, train_loss=0.587, val_MAE=0.633, val_loss=0.633]Epoch 13:   1%|▏         | 13/1000 [43:26<50:47:25, 185.25s/it, lr=0.0005, test_MAE=7.2, time=185, train_MAE=0.584, train_loss=0.584, val_MAE=7.25, val_loss=7.25]    Epoch 13:   1%|▏         | 14/1000 [43:26<50:42:36, 185.15s/it, lr=0.0005, test_MAE=7.2, time=185, train_MAE=0.584, train_loss=0.584, val_MAE=7.25, val_loss=7.25]Epoch 14:   1%|▏         | 14/1000 [43:26<50:42:36, 185.15s/it, lr=0.0005, test_MAE=7.2, time=185, train_MAE=0.584, train_loss=0.584, val_MAE=7.25, val_loss=7.25]Epoch 14:   1%|▏         | 14/1000 [46:31<50:42:36, 185.15s/it, lr=0.0005, test_MAE=0.698, time=185, train_MAE=0.574, train_loss=0.574, val_MAE=0.655, val_loss=0.655]Epoch 14:   2%|▏         | 15/1000 [46:31<50:36:46, 184.98s/it, lr=0.0005, test_MAE=0.698, time=185, train_MAE=0.574, train_loss=0.574, val_MAE=0.655, val_loss=0.655]Epoch 15:   2%|▏         | 15/1000 [46:31<50:36:46, 184.98s/it, lr=0.0005, test_MAE=0.698, time=185, train_MAE=0.574, train_loss=0.574, val_MAE=0.655, val_loss=0.655]Epoch 15:   2%|▏         | 15/1000 [49:36<50:36:46, 184.98s/it, lr=0.0005, test_MAE=0.667, time=185, train_MAE=0.577, train_loss=0.577, val_MAE=0.622, val_loss=0.622]Epoch 15:   2%|▏         | 16/1000 [49:36<50:35:38, 185.10s/it, lr=0.0005, test_MAE=0.667, time=185, train_MAE=0.577, train_loss=0.577, val_MAE=0.622, val_loss=0.622]Epoch 16:   2%|▏         | 16/1000 [49:36<50:35:38, 185.10s/it, lr=0.0005, test_MAE=0.667, time=185, train_MAE=0.577, train_loss=0.577, val_MAE=0.622, val_loss=0.622]Epoch 16:   2%|▏         | 16/1000 [52:41<50:35:38, 185.10s/it, lr=0.0005, test_MAE=0.738, time=185, train_MAE=0.585, train_loss=0.585, val_MAE=0.718, val_loss=0.718]Epoch 16:   2%|▏         | 17/1000 [52:41<50:31:10, 185.02s/it, lr=0.0005, test_MAE=0.738, time=185, train_MAE=0.585, train_loss=0.585, val_MAE=0.718, val_loss=0.718]Epoch 17:   2%|▏         | 17/1000 [52:41<50:31:10, 185.02s/it, lr=0.0005, test_MAE=0.738, time=185, train_MAE=0.585, train_loss=0.585, val_MAE=0.718, val_loss=0.718]Epoch 17:   2%|▏         | 17/1000 [55:46<50:31:10, 185.02s/it, lr=0.0005, test_MAE=0.656, time=185, train_MAE=0.571, train_loss=0.571, val_MAE=0.617, val_loss=0.617]Epoch 17:   2%|▏         | 18/1000 [55:46<50:26:40, 184.93s/it, lr=0.0005, test_MAE=0.656, time=185, train_MAE=0.571, train_loss=0.571, val_MAE=0.617, val_loss=0.617]Epoch 18:   2%|▏         | 18/1000 [55:46<50:26:40, 184.93s/it, lr=0.0005, test_MAE=0.656, time=185, train_MAE=0.571, train_loss=0.571, val_MAE=0.617, val_loss=0.617]Epoch 18:   2%|▏         | 18/1000 [58:51<50:26:40, 184.93s/it, lr=0.0005, test_MAE=0.658, time=185, train_MAE=0.577, train_loss=0.577, val_MAE=0.624, val_loss=0.624]Epoch 18:   2%|▏         | 19/1000 [58:51<50:24:20, 184.98s/it, lr=0.0005, test_MAE=0.658, time=185, train_MAE=0.577, train_loss=0.577, val_MAE=0.624, val_loss=0.624]Epoch 19:   2%|▏         | 19/1000 [58:51<50:24:20, 184.98s/it, lr=0.0005, test_MAE=0.658, time=185, train_MAE=0.577, train_loss=0.577, val_MAE=0.624, val_loss=0.624]Epoch 19:   2%|▏         | 19/1000 [1:01:56<50:24:20, 184.98s/it, lr=0.0005, test_MAE=0.718, time=185, train_MAE=0.569, train_loss=0.569, val_MAE=0.679, val_loss=0.679]Epoch 19:   2%|▏         | 20/1000 [1:01:56<50:20:35, 184.93s/it, lr=0.0005, test_MAE=0.718, time=185, train_MAE=0.569, train_loss=0.569, val_MAE=0.679, val_loss=0.679]Epoch 20:   2%|▏         | 20/1000 [1:01:56<50:20:35, 184.93s/it, lr=0.0005, test_MAE=0.718, time=185, train_MAE=0.569, train_loss=0.569, val_MAE=0.679, val_loss=0.679]Epoch 20:   2%|▏         | 20/1000 [1:05:01<50:20:35, 184.93s/it, lr=0.0005, test_MAE=0.619, time=185, train_MAE=0.562, train_loss=0.562, val_MAE=0.585, val_loss=0.585]Epoch 20:   2%|▏         | 21/1000 [1:05:01<50:17:32, 184.94s/it, lr=0.0005, test_MAE=0.619, time=185, train_MAE=0.562, train_loss=0.562, val_MAE=0.585, val_loss=0.585]Epoch 21:   2%|▏         | 21/1000 [1:05:01<50:17:32, 184.94s/it, lr=0.0005, test_MAE=0.619, time=185, train_MAE=0.562, train_loss=0.562, val_MAE=0.585, val_loss=0.585]Epoch 21:   2%|▏         | 21/1000 [1:08:06<50:17:32, 184.94s/it, lr=0.0005, test_MAE=0.624, time=185, train_MAE=0.566, train_loss=0.566, val_MAE=0.603, val_loss=0.603]Epoch 21:   2%|▏         | 22/1000 [1:08:06<50:16:53, 185.09s/it, lr=0.0005, test_MAE=0.624, time=185, train_MAE=0.566, train_loss=0.566, val_MAE=0.603, val_loss=0.603]Epoch 22:   2%|▏         | 22/1000 [1:08:06<50:16:53, 185.09s/it, lr=0.0005, test_MAE=0.624, time=185, train_MAE=0.566, train_loss=0.566, val_MAE=0.603, val_loss=0.603]Epoch 22:   2%|▏         | 22/1000 [1:11:11<50:16:53, 185.09s/it, lr=0.0005, test_MAE=6.26, time=185, train_MAE=0.561, train_loss=0.561, val_MAE=6.3, val_loss=6.3]     Epoch 22:   2%|▏         | 23/1000 [1:11:11<50:12:01, 184.98s/it, lr=0.0005, test_MAE=6.26, time=185, train_MAE=0.561, train_loss=0.561, val_MAE=6.3, val_loss=6.3]Epoch 23:   2%|▏         | 23/1000 [1:11:11<50:12:01, 184.98s/it, lr=0.0005, test_MAE=6.26, time=185, train_MAE=0.561, train_loss=0.561, val_MAE=6.3, val_loss=6.3]Epoch 23:   2%|▏         | 23/1000 [1:14:16<50:12:01, 184.98s/it, lr=0.0005, test_MAE=0.638, time=185, train_MAE=0.562, train_loss=0.562, val_MAE=0.591, val_loss=0.591]Epoch 23:   2%|▏         | 24/1000 [1:14:16<50:10:37, 185.08s/it, lr=0.0005, test_MAE=0.638, time=185, train_MAE=0.562, train_loss=0.562, val_MAE=0.591, val_loss=0.591]Epoch 24:   2%|▏         | 24/1000 [1:14:16<50:10:37, 185.08s/it, lr=0.0005, test_MAE=0.638, time=185, train_MAE=0.562, train_loss=0.562, val_MAE=0.591, val_loss=0.591]Epoch 24:   2%|▏         | 24/1000 [1:17:21<50:10:37, 185.08s/it, lr=0.0005, test_MAE=0.633, time=185, train_MAE=0.555, train_loss=0.555, val_MAE=0.599, val_loss=0.599]Epoch 24:   2%|▎         | 25/1000 [1:17:21<50:06:18, 185.00s/it, lr=0.0005, test_MAE=0.633, time=185, train_MAE=0.555, train_loss=0.555, val_MAE=0.599, val_loss=0.599]Epoch 25:   2%|▎         | 25/1000 [1:17:21<50:06:18, 185.00s/it, lr=0.0005, test_MAE=0.633, time=185, train_MAE=0.555, train_loss=0.555, val_MAE=0.599, val_loss=0.599]Epoch 25:   2%|▎         | 25/1000 [1:20:26<50:06:18, 185.00s/it, lr=0.0005, test_MAE=0.636, time=185, train_MAE=0.558, train_loss=0.558, val_MAE=0.597, val_loss=0.597]Epoch 25:   3%|▎         | 26/1000 [1:20:26<50:04:04, 185.06s/it, lr=0.0005, test_MAE=0.636, time=185, train_MAE=0.558, train_loss=0.558, val_MAE=0.597, val_loss=0.597]Epoch 26:   3%|▎         | 26/1000 [1:20:26<50:04:04, 185.06s/it, lr=0.0005, test_MAE=0.636, time=185, train_MAE=0.558, train_loss=0.558, val_MAE=0.597, val_loss=0.597]Epoch 26:   3%|▎         | 26/1000 [1:23:32<50:04:04, 185.06s/it, lr=0.0005, test_MAE=0.671, time=185, train_MAE=0.561, train_loss=0.561, val_MAE=0.634, val_loss=0.634]Epoch    27: reducing learning rate of group 0 to 2.5000e-04.
Epoch 26:   3%|▎         | 27/1000 [1:23:32<50:02:40, 185.16s/it, lr=0.0005, test_MAE=0.671, time=185, train_MAE=0.561, train_loss=0.561, val_MAE=0.634, val_loss=0.634]Epoch 27:   3%|▎         | 27/1000 [1:23:32<50:02:40, 185.16s/it, lr=0.0005, test_MAE=0.671, time=185, train_MAE=0.561, train_loss=0.561, val_MAE=0.634, val_loss=0.634]Epoch 27:   3%|▎         | 27/1000 [1:26:36<50:02:40, 185.16s/it, lr=0.00025, test_MAE=0.81, time=185, train_MAE=0.541, train_loss=0.541, val_MAE=0.736, val_loss=0.736]Epoch 27:   3%|▎         | 28/1000 [1:26:36<49:57:55, 185.06s/it, lr=0.00025, test_MAE=0.81, time=185, train_MAE=0.541, train_loss=0.541, val_MAE=0.736, val_loss=0.736]Epoch 28:   3%|▎         | 28/1000 [1:26:36<49:57:55, 185.06s/it, lr=0.00025, test_MAE=0.81, time=185, train_MAE=0.541, train_loss=0.541, val_MAE=0.736, val_loss=0.736]Epoch 28:   3%|▎         | 28/1000 [1:29:41<49:57:55, 185.06s/it, lr=0.00025, test_MAE=0.625, time=185, train_MAE=0.533, train_loss=0.533, val_MAE=0.591, val_loss=0.591]Epoch 28:   3%|▎         | 29/1000 [1:29:41<49:52:27, 184.91s/it, lr=0.00025, test_MAE=0.625, time=185, train_MAE=0.533, train_loss=0.533, val_MAE=0.591, val_loss=0.591]Epoch 29:   3%|▎         | 29/1000 [1:29:41<49:52:27, 184.91s/it, lr=0.00025, test_MAE=0.625, time=185, train_MAE=0.533, train_loss=0.533, val_MAE=0.591, val_loss=0.591]Epoch 29:   3%|▎         | 29/1000 [1:32:47<49:52:27, 184.91s/it, lr=0.00025, test_MAE=0.605, time=186, train_MAE=0.535, train_loss=0.535, val_MAE=0.567, val_loss=0.567]Epoch 29:   3%|▎         | 30/1000 [1:32:47<49:52:56, 185.13s/it, lr=0.00025, test_MAE=0.605, time=186, train_MAE=0.535, train_loss=0.535, val_MAE=0.567, val_loss=0.567]Epoch 30:   3%|▎         | 30/1000 [1:32:47<49:52:56, 185.13s/it, lr=0.00025, test_MAE=0.605, time=186, train_MAE=0.535, train_loss=0.535, val_MAE=0.567, val_loss=0.567]Epoch 30:   3%|▎         | 30/1000 [1:35:52<49:52:56, 185.13s/it, lr=0.00025, test_MAE=0.609, time=185, train_MAE=0.53, train_loss=0.53, val_MAE=0.571, val_loss=0.571]  Epoch 30:   3%|▎         | 31/1000 [1:35:52<49:48:47, 185.06s/it, lr=0.00025, test_MAE=0.609, time=185, train_MAE=0.53, train_loss=0.53, val_MAE=0.571, val_loss=0.571]Epoch 31:   3%|▎         | 31/1000 [1:35:52<49:48:47, 185.06s/it, lr=0.00025, test_MAE=0.609, time=185, train_MAE=0.53, train_loss=0.53, val_MAE=0.571, val_loss=0.571]Epoch 31:   3%|▎         | 31/1000 [1:38:56<49:48:47, 185.06s/it, lr=0.00025, test_MAE=0.62, time=184, train_MAE=0.531, train_loss=0.531, val_MAE=0.597, val_loss=0.597]Epoch 31:   3%|▎         | 32/1000 [1:38:56<49:42:14, 184.85s/it, lr=0.00025, test_MAE=0.62, time=184, train_MAE=0.531, train_loss=0.531, val_MAE=0.597, val_loss=0.597]Epoch 32:   3%|▎         | 32/1000 [1:38:56<49:42:14, 184.85s/it, lr=0.00025, test_MAE=0.62, time=184, train_MAE=0.531, train_loss=0.531, val_MAE=0.597, val_loss=0.597]Epoch 32:   3%|▎         | 32/1000 [1:41:57<49:42:14, 184.85s/it, lr=0.00025, test_MAE=0.784, time=182, train_MAE=0.529, train_loss=0.529, val_MAE=0.753, val_loss=0.753]Epoch 32:   3%|▎         | 33/1000 [1:41:57<49:23:05, 183.85s/it, lr=0.00025, test_MAE=0.784, time=182, train_MAE=0.529, train_loss=0.529, val_MAE=0.753, val_loss=0.753]Epoch 33:   3%|▎         | 33/1000 [1:41:57<49:23:05, 183.85s/it, lr=0.00025, test_MAE=0.784, time=182, train_MAE=0.529, train_loss=0.529, val_MAE=0.753, val_loss=0.753]Epoch 33:   3%|▎         | 33/1000 [1:44:56<49:23:05, 183.85s/it, lr=0.00025, test_MAE=0.656, time=178, train_MAE=0.529, train_loss=0.529, val_MAE=0.627, val_loss=0.627]Epoch 33:   3%|▎         | 34/1000 [1:44:56<48:53:16, 182.19s/it, lr=0.00025, test_MAE=0.656, time=178, train_MAE=0.529, train_loss=0.529, val_MAE=0.627, val_loss=0.627]Epoch 34:   3%|▎         | 34/1000 [1:44:56<48:53:16, 182.19s/it, lr=0.00025, test_MAE=0.656, time=178, train_MAE=0.529, train_loss=0.529, val_MAE=0.627, val_loss=0.627]Epoch 34:   3%|▎         | 34/1000 [1:47:54<48:53:16, 182.19s/it, lr=0.00025, test_MAE=0.641, time=178, train_MAE=0.532, train_loss=0.532, val_MAE=0.608, val_loss=0.608]Epoch 34:   4%|▎         | 35/1000 [1:47:54<48:28:47, 180.86s/it, lr=0.00025, test_MAE=0.641, time=178, train_MAE=0.532, train_loss=0.532, val_MAE=0.608, val_loss=0.608]Epoch 35:   4%|▎         | 35/1000 [1:47:54<48:28:47, 180.86s/it, lr=0.00025, test_MAE=0.641, time=178, train_MAE=0.532, train_loss=0.532, val_MAE=0.608, val_loss=0.608]Epoch 35:   4%|▎         | 35/1000 [1:50:52<48:28:47, 180.86s/it, lr=0.00025, test_MAE=0.745, time=178, train_MAE=0.524, train_loss=0.524, val_MAE=0.723, val_loss=0.723]Epoch    36: reducing learning rate of group 0 to 1.2500e-04.
Epoch 35:   4%|▎         | 36/1000 [1:50:52<48:12:48, 180.05s/it, lr=0.00025, test_MAE=0.745, time=178, train_MAE=0.524, train_loss=0.524, val_MAE=0.723, val_loss=0.723]Epoch 36:   4%|▎         | 36/1000 [1:50:52<48:12:48, 180.05s/it, lr=0.00025, test_MAE=0.745, time=178, train_MAE=0.524, train_loss=0.524, val_MAE=0.723, val_loss=0.723]Epoch 36:   4%|▎         | 36/1000 [1:53:49<48:12:48, 180.05s/it, lr=0.000125, test_MAE=0.602, time=178, train_MAE=0.513, train_loss=0.513, val_MAE=0.563, val_loss=0.563]Epoch 36:   4%|▎         | 37/1000 [1:53:49<47:58:28, 179.34s/it, lr=0.000125, test_MAE=0.602, time=178, train_MAE=0.513, train_loss=0.513, val_MAE=0.563, val_loss=0.563]Epoch 37:   4%|▎         | 37/1000 [1:53:49<47:58:28, 179.34s/it, lr=0.000125, test_MAE=0.602, time=178, train_MAE=0.513, train_loss=0.513, val_MAE=0.563, val_loss=0.563]Epoch 37:   4%|▎         | 37/1000 [1:56:46<47:58:28, 179.34s/it, lr=0.000125, test_MAE=0.594, time=177, train_MAE=0.506, train_loss=0.506, val_MAE=0.549, val_loss=0.549]Epoch 37:   4%|▍         | 38/1000 [1:56:46<47:44:23, 178.65s/it, lr=0.000125, test_MAE=0.594, time=177, train_MAE=0.506, train_loss=0.506, val_MAE=0.549, val_loss=0.549]Epoch 38:   4%|▍         | 38/1000 [1:56:46<47:44:23, 178.65s/it, lr=0.000125, test_MAE=0.594, time=177, train_MAE=0.506, train_loss=0.506, val_MAE=0.549, val_loss=0.549]Epoch 38:   4%|▍         | 38/1000 [1:59:43<47:44:23, 178.65s/it, lr=0.000125, test_MAE=0.594, time=177, train_MAE=0.501, train_loss=0.501, val_MAE=0.559, val_loss=0.559]Epoch 38:   4%|▍         | 39/1000 [1:59:44<47:33:51, 178.18s/it, lr=0.000125, test_MAE=0.594, time=177, train_MAE=0.501, train_loss=0.501, val_MAE=0.559, val_loss=0.559]Epoch 39:   4%|▍         | 39/1000 [1:59:44<47:33:51, 178.18s/it, lr=0.000125, test_MAE=0.594, time=177, train_MAE=0.501, train_loss=0.501, val_MAE=0.559, val_loss=0.559]Epoch 39:   4%|▍         | 39/1000 [2:02:40<47:33:51, 178.18s/it, lr=0.000125, test_MAE=0.634, time=176, train_MAE=0.503, train_loss=0.503, val_MAE=0.599, val_loss=0.599]Epoch 39:   4%|▍         | 40/1000 [2:02:40<47:22:50, 177.68s/it, lr=0.000125, test_MAE=0.634, time=176, train_MAE=0.503, train_loss=0.503, val_MAE=0.599, val_loss=0.599]Epoch 40:   4%|▍         | 40/1000 [2:02:40<47:22:50, 177.68s/it, lr=0.000125, test_MAE=0.634, time=176, train_MAE=0.503, train_loss=0.503, val_MAE=0.599, val_loss=0.599]Epoch 40:   4%|▍         | 40/1000 [2:05:37<47:22:50, 177.68s/it, lr=0.000125, test_MAE=0.664, time=177, train_MAE=0.504, train_loss=0.504, val_MAE=0.635, val_loss=0.635]Epoch 40:   4%|▍         | 41/1000 [2:05:37<47:14:23, 177.33s/it, lr=0.000125, test_MAE=0.664, time=177, train_MAE=0.504, train_loss=0.504, val_MAE=0.635, val_loss=0.635]Epoch 41:   4%|▍         | 41/1000 [2:05:37<47:14:23, 177.33s/it, lr=0.000125, test_MAE=0.664, time=177, train_MAE=0.504, train_loss=0.504, val_MAE=0.635, val_loss=0.635]Epoch 41:   4%|▍         | 41/1000 [2:08:33<47:14:23, 177.33s/it, lr=0.000125, test_MAE=0.625, time=177, train_MAE=0.498, train_loss=0.498, val_MAE=0.588, val_loss=0.588]Epoch 41:   4%|▍         | 42/1000 [2:08:33<47:08:10, 177.13s/it, lr=0.000125, test_MAE=0.625, time=177, train_MAE=0.498, train_loss=0.498, val_MAE=0.588, val_loss=0.588]Epoch 42:   4%|▍         | 42/1000 [2:08:33<47:08:10, 177.13s/it, lr=0.000125, test_MAE=0.625, time=177, train_MAE=0.498, train_loss=0.498, val_MAE=0.588, val_loss=0.588]Epoch 42:   4%|▍         | 42/1000 [2:11:29<47:08:10, 177.13s/it, lr=0.000125, test_MAE=0.593, time=176, train_MAE=0.509, train_loss=0.509, val_MAE=0.559, val_loss=0.559]Epoch 42:   4%|▍         | 43/1000 [2:11:29<46:59:04, 176.74s/it, lr=0.000125, test_MAE=0.593, time=176, train_MAE=0.509, train_loss=0.509, val_MAE=0.559, val_loss=0.559]Epoch 43:   4%|▍         | 43/1000 [2:11:29<46:59:04, 176.74s/it, lr=0.000125, test_MAE=0.593, time=176, train_MAE=0.509, train_loss=0.509, val_MAE=0.559, val_loss=0.559]Epoch 43:   4%|▍         | 43/1000 [2:14:25<46:59:04, 176.74s/it, lr=0.000125, test_MAE=0.673, time=176, train_MAE=0.497, train_loss=0.497, val_MAE=0.613, val_loss=0.613]Epoch    44: reducing learning rate of group 0 to 6.2500e-05.
Epoch 43:   4%|▍         | 44/1000 [2:14:25<46:52:48, 176.54s/it, lr=0.000125, test_MAE=0.673, time=176, train_MAE=0.497, train_loss=0.497, val_MAE=0.613, val_loss=0.613]Epoch 44:   4%|▍         | 44/1000 [2:14:25<46:52:48, 176.54s/it, lr=0.000125, test_MAE=0.673, time=176, train_MAE=0.497, train_loss=0.497, val_MAE=0.613, val_loss=0.613]Epoch 44:   4%|▍         | 44/1000 [2:17:21<46:52:48, 176.54s/it, lr=6.25e-5, test_MAE=0.585, time=176, train_MAE=0.491, train_loss=0.491, val_MAE=0.551, val_loss=0.551] Epoch 44:   4%|▍         | 45/1000 [2:17:21<46:45:47, 176.28s/it, lr=6.25e-5, test_MAE=0.585, time=176, train_MAE=0.491, train_loss=0.491, val_MAE=0.551, val_loss=0.551]Epoch 45:   4%|▍         | 45/1000 [2:17:21<46:45:47, 176.28s/it, lr=6.25e-5, test_MAE=0.585, time=176, train_MAE=0.491, train_loss=0.491, val_MAE=0.551, val_loss=0.551]Epoch 45:   4%|▍         | 45/1000 [2:20:17<46:45:47, 176.28s/it, lr=6.25e-5, test_MAE=0.584, time=176, train_MAE=0.487, train_loss=0.487, val_MAE=0.549, val_loss=0.549]Epoch 45:   5%|▍         | 46/1000 [2:20:17<46:40:58, 176.16s/it, lr=6.25e-5, test_MAE=0.584, time=176, train_MAE=0.487, train_loss=0.487, val_MAE=0.549, val_loss=0.549]Epoch 46:   5%|▍         | 46/1000 [2:20:17<46:40:58, 176.16s/it, lr=6.25e-5, test_MAE=0.584, time=176, train_MAE=0.487, train_loss=0.487, val_MAE=0.549, val_loss=0.549]Epoch 46:   5%|▍         | 46/1000 [2:23:19<46:40:58, 176.16s/it, lr=6.25e-5, test_MAE=0.629, time=182, train_MAE=0.482, train_loss=0.482, val_MAE=0.577, val_loss=0.577]Epoch 46:   5%|▍         | 47/1000 [2:23:19<47:05:55, 177.92s/it, lr=6.25e-5, test_MAE=0.629, time=182, train_MAE=0.482, train_loss=0.482, val_MAE=0.577, val_loss=0.577]Epoch 47:   5%|▍         | 47/1000 [2:23:19<47:05:55, 177.92s/it, lr=6.25e-5, test_MAE=0.629, time=182, train_MAE=0.482, train_loss=0.482, val_MAE=0.577, val_loss=0.577]Epoch 47:   5%|▍         | 47/1000 [2:26:16<47:05:55, 177.92s/it, lr=6.25e-5, test_MAE=0.735, time=177, train_MAE=0.483, train_loss=0.483, val_MAE=0.696, val_loss=0.696]Epoch 47:   5%|▍         | 48/1000 [2:26:16<46:58:28, 177.64s/it, lr=6.25e-5, test_MAE=0.735, time=177, train_MAE=0.483, train_loss=0.483, val_MAE=0.696, val_loss=0.696]Epoch 48:   5%|▍         | 48/1000 [2:26:16<46:58:28, 177.64s/it, lr=6.25e-5, test_MAE=0.735, time=177, train_MAE=0.483, train_loss=0.483, val_MAE=0.696, val_loss=0.696]Epoch 48:   5%|▍         | 48/1000 [2:29:10<46:58:28, 177.64s/it, lr=6.25e-5, test_MAE=0.619, time=175, train_MAE=0.484, train_loss=0.484, val_MAE=0.587, val_loss=0.587]Epoch 48:   5%|▍         | 49/1000 [2:29:10<46:42:14, 176.80s/it, lr=6.25e-5, test_MAE=0.619, time=175, train_MAE=0.484, train_loss=0.484, val_MAE=0.587, val_loss=0.587]Epoch 49:   5%|▍         | 49/1000 [2:29:10<46:42:14, 176.80s/it, lr=6.25e-5, test_MAE=0.619, time=175, train_MAE=0.484, train_loss=0.484, val_MAE=0.587, val_loss=0.587]Epoch 49:   5%|▍         | 49/1000 [2:32:06<46:42:14, 176.80s/it, lr=6.25e-5, test_MAE=0.595, time=176, train_MAE=0.485, train_loss=0.485, val_MAE=0.567, val_loss=0.567]Epoch    50: reducing learning rate of group 0 to 3.1250e-05.
Epoch 49:   5%|▌         | 50/1000 [2:32:06<46:33:34, 176.44s/it, lr=6.25e-5, test_MAE=0.595, time=176, train_MAE=0.485, train_loss=0.485, val_MAE=0.567, val_loss=0.567]Epoch 50:   5%|▌         | 50/1000 [2:32:06<46:33:34, 176.44s/it, lr=6.25e-5, test_MAE=0.595, time=176, train_MAE=0.485, train_loss=0.485, val_MAE=0.567, val_loss=0.567]Epoch 50:   5%|▌         | 50/1000 [2:35:01<46:33:34, 176.44s/it, lr=3.13e-5, test_MAE=0.588, time=175, train_MAE=0.471, train_loss=0.471, val_MAE=0.555, val_loss=0.555]Epoch 50:   5%|▌         | 51/1000 [2:35:01<46:23:22, 175.98s/it, lr=3.13e-5, test_MAE=0.588, time=175, train_MAE=0.471, train_loss=0.471, val_MAE=0.555, val_loss=0.555]Epoch 51:   5%|▌         | 51/1000 [2:35:01<46:23:22, 175.98s/it, lr=3.13e-5, test_MAE=0.588, time=175, train_MAE=0.471, train_loss=0.471, val_MAE=0.555, val_loss=0.555]Epoch 51:   5%|▌         | 51/1000 [2:37:59<46:23:22, 175.98s/it, lr=3.13e-5, test_MAE=0.588, time=178, train_MAE=0.467, train_loss=0.467, val_MAE=0.551, val_loss=0.551]Epoch 51:   5%|▌         | 52/1000 [2:37:59<46:30:38, 176.62s/it, lr=3.13e-5, test_MAE=0.588, time=178, train_MAE=0.467, train_loss=0.467, val_MAE=0.551, val_loss=0.551]Epoch 52:   5%|▌         | 52/1000 [2:37:59<46:30:38, 176.62s/it, lr=3.13e-5, test_MAE=0.588, time=178, train_MAE=0.467, train_loss=0.467, val_MAE=0.551, val_loss=0.551]Epoch 52:   5%|▌         | 52/1000 [2:40:58<46:30:38, 176.62s/it, lr=3.13e-5, test_MAE=0.586, time=179, train_MAE=0.475, train_loss=0.475, val_MAE=0.553, val_loss=0.553]Epoch 52:   5%|▌         | 53/1000 [2:40:58<46:37:07, 177.22s/it, lr=3.13e-5, test_MAE=0.586, time=179, train_MAE=0.475, train_loss=0.475, val_MAE=0.553, val_loss=0.553]Epoch 53:   5%|▌         | 53/1000 [2:40:58<46:37:07, 177.22s/it, lr=3.13e-5, test_MAE=0.586, time=179, train_MAE=0.475, train_loss=0.475, val_MAE=0.553, val_loss=0.553]Epoch 53:   5%|▌         | 53/1000 [2:43:52<46:37:07, 177.22s/it, lr=3.13e-5, test_MAE=0.587, time=174, train_MAE=0.469, train_loss=0.469, val_MAE=0.554, val_loss=0.554]Epoch 53:   5%|▌         | 54/1000 [2:43:52<46:19:52, 176.31s/it, lr=3.13e-5, test_MAE=0.587, time=174, train_MAE=0.469, train_loss=0.469, val_MAE=0.554, val_loss=0.554]Epoch 54:   5%|▌         | 54/1000 [2:43:52<46:19:52, 176.31s/it, lr=3.13e-5, test_MAE=0.587, time=174, train_MAE=0.469, train_loss=0.469, val_MAE=0.554, val_loss=0.554]Epoch 54:   5%|▌         | 54/1000 [2:46:49<46:19:52, 176.31s/it, lr=3.13e-5, test_MAE=0.614, time=177, train_MAE=0.46, train_loss=0.46, val_MAE=0.572, val_loss=0.572]  Epoch 54:   6%|▌         | 55/1000 [2:46:49<46:20:56, 176.57s/it, lr=3.13e-5, test_MAE=0.614, time=177, train_MAE=0.46, train_loss=0.46, val_MAE=0.572, val_loss=0.572]Epoch 55:   6%|▌         | 55/1000 [2:46:49<46:20:56, 176.57s/it, lr=3.13e-5, test_MAE=0.614, time=177, train_MAE=0.46, train_loss=0.46, val_MAE=0.572, val_loss=0.572]Epoch 55:   6%|▌         | 55/1000 [2:49:50<46:20:56, 176.57s/it, lr=3.13e-5, test_MAE=0.675, time=181, train_MAE=0.464, train_loss=0.464, val_MAE=0.592, val_loss=0.592]Epoch    56: reducing learning rate of group 0 to 1.5625e-05.
Epoch 55:   6%|▌         | 56/1000 [2:49:50<46:38:24, 177.86s/it, lr=3.13e-5, test_MAE=0.675, time=181, train_MAE=0.464, train_loss=0.464, val_MAE=0.592, val_loss=0.592]Epoch 56:   6%|▌         | 56/1000 [2:49:50<46:38:24, 177.86s/it, lr=3.13e-5, test_MAE=0.675, time=181, train_MAE=0.464, train_loss=0.464, val_MAE=0.592, val_loss=0.592]Epoch 56:   6%|▌         | 56/1000 [2:52:43<46:38:24, 177.86s/it, lr=1.56e-5, test_MAE=0.581, time=173, train_MAE=0.456, train_loss=0.456, val_MAE=0.55, val_loss=0.55]  Epoch 56:   6%|▌         | 57/1000 [2:52:43<46:13:56, 176.50s/it, lr=1.56e-5, test_MAE=0.581, time=173, train_MAE=0.456, train_loss=0.456, val_MAE=0.55, val_loss=0.55]Epoch 57:   6%|▌         | 57/1000 [2:52:43<46:13:56, 176.50s/it, lr=1.56e-5, test_MAE=0.581, time=173, train_MAE=0.456, train_loss=0.456, val_MAE=0.55, val_loss=0.55]Epoch 57:   6%|▌         | 57/1000 [2:55:36<46:13:56, 176.50s/it, lr=1.56e-5, test_MAE=0.585, time=173, train_MAE=0.457, train_loss=0.457, val_MAE=0.56, val_loss=0.56]Epoch 57:   6%|▌         | 58/1000 [2:55:36<45:55:18, 175.50s/it, lr=1.56e-5, test_MAE=0.585, time=173, train_MAE=0.457, train_loss=0.457, val_MAE=0.56, val_loss=0.56]Epoch 58:   6%|▌         | 58/1000 [2:55:36<45:55:18, 175.50s/it, lr=1.56e-5, test_MAE=0.585, time=173, train_MAE=0.457, train_loss=0.457, val_MAE=0.56, val_loss=0.56]Epoch 58:   6%|▌         | 58/1000 [2:58:30<45:55:18, 175.50s/it, lr=1.56e-5, test_MAE=0.581, time=174, train_MAE=0.46, train_loss=0.46, val_MAE=0.555, val_loss=0.555]Epoch 58:   6%|▌         | 59/1000 [2:58:30<45:43:47, 174.95s/it, lr=1.56e-5, test_MAE=0.581, time=174, train_MAE=0.46, train_loss=0.46, val_MAE=0.555, val_loss=0.555]Epoch 59:   6%|▌         | 59/1000 [2:58:30<45:43:47, 174.95s/it, lr=1.56e-5, test_MAE=0.581, time=174, train_MAE=0.46, train_loss=0.46, val_MAE=0.555, val_loss=0.555]Epoch 59:   6%|▌         | 59/1000 [3:01:30<45:43:47, 174.95s/it, lr=1.56e-5, test_MAE=0.583, time=180, train_MAE=0.456, train_loss=0.456, val_MAE=0.549, val_loss=0.549]Epoch 59:   6%|▌         | 60/1000 [3:01:30<46:05:14, 176.50s/it, lr=1.56e-5, test_MAE=0.583, time=180, train_MAE=0.456, train_loss=0.456, val_MAE=0.549, val_loss=0.549]Epoch 60:   6%|▌         | 60/1000 [3:01:30<46:05:14, 176.50s/it, lr=1.56e-5, test_MAE=0.583, time=180, train_MAE=0.456, train_loss=0.456, val_MAE=0.549, val_loss=0.549]Epoch 60:   6%|▌         | 60/1000 [3:04:25<46:05:14, 176.50s/it, lr=1.56e-5, test_MAE=0.584, time=175, train_MAE=0.452, train_loss=0.452, val_MAE=0.553, val_loss=0.553]Epoch 60:   6%|▌         | 61/1000 [3:04:25<45:53:27, 175.94s/it, lr=1.56e-5, test_MAE=0.584, time=175, train_MAE=0.452, train_loss=0.452, val_MAE=0.553, val_loss=0.553]Epoch 61:   6%|▌         | 61/1000 [3:04:25<45:53:27, 175.94s/it, lr=1.56e-5, test_MAE=0.584, time=175, train_MAE=0.452, train_loss=0.452, val_MAE=0.553, val_loss=0.553]Epoch 61:   6%|▌         | 61/1000 [3:07:23<45:53:27, 175.94s/it, lr=1.56e-5, test_MAE=0.584, time=178, train_MAE=0.455, train_loss=0.455, val_MAE=0.548, val_loss=0.548]Epoch 61:   6%|▌         | 62/1000 [3:07:23<46:00:48, 176.60s/it, lr=1.56e-5, test_MAE=0.584, time=178, train_MAE=0.455, train_loss=0.455, val_MAE=0.548, val_loss=0.548]Epoch 62:   6%|▌         | 62/1000 [3:07:23<46:00:48, 176.60s/it, lr=1.56e-5, test_MAE=0.584, time=178, train_MAE=0.455, train_loss=0.455, val_MAE=0.548, val_loss=0.548]Epoch 62:   6%|▌         | 62/1000 [3:10:20<46:00:48, 176.60s/it, lr=1.56e-5, test_MAE=0.585, time=177, train_MAE=0.462, train_loss=0.462, val_MAE=0.558, val_loss=0.558]Epoch 62:   6%|▋         | 63/1000 [3:10:20<46:00:11, 176.75s/it, lr=1.56e-5, test_MAE=0.585, time=177, train_MAE=0.462, train_loss=0.462, val_MAE=0.558, val_loss=0.558]Epoch 63:   6%|▋         | 63/1000 [3:10:20<46:00:11, 176.75s/it, lr=1.56e-5, test_MAE=0.585, time=177, train_MAE=0.462, train_loss=0.462, val_MAE=0.558, val_loss=0.558]Epoch 63:   6%|▋         | 63/1000 [3:13:14<46:00:11, 176.75s/it, lr=1.56e-5, test_MAE=0.588, time=173, train_MAE=0.453, train_loss=0.453, val_MAE=0.551, val_loss=0.551]Epoch 63:   6%|▋         | 64/1000 [3:13:14<45:41:57, 175.77s/it, lr=1.56e-5, test_MAE=0.588, time=173, train_MAE=0.453, train_loss=0.453, val_MAE=0.551, val_loss=0.551]Epoch 64:   6%|▋         | 64/1000 [3:13:14<45:41:57, 175.77s/it, lr=1.56e-5, test_MAE=0.588, time=173, train_MAE=0.453, train_loss=0.453, val_MAE=0.551, val_loss=0.551]Epoch 64:   6%|▋         | 64/1000 [3:16:08<45:41:57, 175.77s/it, lr=1.56e-5, test_MAE=0.587, time=174, train_MAE=0.451, train_loss=0.451, val_MAE=0.551, val_loss=0.551]Epoch 64:   6%|▋         | 65/1000 [3:16:08<45:32:47, 175.37s/it, lr=1.56e-5, test_MAE=0.587, time=174, train_MAE=0.451, train_loss=0.451, val_MAE=0.551, val_loss=0.551]Epoch 65:   6%|▋         | 65/1000 [3:16:08<45:32:47, 175.37s/it, lr=1.56e-5, test_MAE=0.587, time=174, train_MAE=0.451, train_loss=0.451, val_MAE=0.551, val_loss=0.551]Epoch 65:   6%|▋         | 65/1000 [3:19:06<45:32:47, 175.37s/it, lr=1.56e-5, test_MAE=0.584, time=178, train_MAE=0.45, train_loss=0.45, val_MAE=0.549, val_loss=0.549]  Epoch 65:   7%|▋         | 66/1000 [3:19:06<45:41:57, 176.14s/it, lr=1.56e-5, test_MAE=0.584, time=178, train_MAE=0.45, train_loss=0.45, val_MAE=0.549, val_loss=0.549]Epoch 66:   7%|▋         | 66/1000 [3:19:06<45:41:57, 176.14s/it, lr=1.56e-5, test_MAE=0.584, time=178, train_MAE=0.45, train_loss=0.45, val_MAE=0.549, val_loss=0.549]Epoch 66:   7%|▋         | 66/1000 [3:22:03<45:41:57, 176.14s/it, lr=1.56e-5, test_MAE=0.592, time=177, train_MAE=0.458, train_loss=0.458, val_MAE=0.557, val_loss=0.557]Epoch 66:   7%|▋         | 67/1000 [3:22:03<45:44:55, 176.52s/it, lr=1.56e-5, test_MAE=0.592, time=177, train_MAE=0.458, train_loss=0.458, val_MAE=0.557, val_loss=0.557]Epoch 67:   7%|▋         | 67/1000 [3:22:03<45:44:55, 176.52s/it, lr=1.56e-5, test_MAE=0.592, time=177, train_MAE=0.458, train_loss=0.458, val_MAE=0.557, val_loss=0.557]Epoch 67:   7%|▋         | 67/1000 [3:25:00<45:44:55, 176.52s/it, lr=1.56e-5, test_MAE=0.589, time=177, train_MAE=0.456, train_loss=0.456, val_MAE=0.551, val_loss=0.551]Epoch    68: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 67:   7%|▋         | 67/1000 [3:25:00<47:34:53, 183.59s/it, lr=1.56e-5, test_MAE=0.589, time=177, train_MAE=0.456, train_loss=0.456, val_MAE=0.551, val_loss=0.551]
Test MAE: 0.5893
Train MAE: 0.4345
Convergence Time (Epochs): 67.0000
TOTAL TIME TAKEN: 12378.5199s
AVG TIME PER EPOCH: 180.8724s
