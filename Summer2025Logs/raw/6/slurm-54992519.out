I'm echoing to stdout
I'm echoing to stderr
My JobID is 54992519
I have 4 CPUs on node r108u25n01
Using backend: pytorch
WARNING:root:The OGB package is out of date. Your version is 1.2.3, while the latest version is 1.3.6.
Loading necessary files...
This might take a while.
Processing graphs...
  0%|          | 0/41127 [00:00<?, ?it/s] 18%|█▊        | 7419/41127 [00:00<00:00, 62468.59it/s] 52%|█████▏    | 21262/41127 [00:00<00:00, 74777.73it/s] 84%|████████▍ | 34569/41127 [00:00<00:00, 86089.83it/s]100%|██████████| 41127/41127 [00:00<00:00, 110763.04it/s]
Converting graphs into DGL objects...
  0%|          | 0/41127 [00:00<?, ?it/s]  2%|▏         | 644/41127 [00:00<00:06, 6431.89it/s]  3%|▎         | 1291/41127 [00:00<00:06, 6441.54it/s]  4%|▍         | 1843/41127 [00:00<00:07, 5412.26it/s]  6%|▌         | 2462/41127 [00:00<00:06, 5624.09it/s]  8%|▊         | 3105/41127 [00:00<00:06, 5842.67it/s]  9%|▉         | 3748/41127 [00:00<00:06, 6006.16it/s] 11%|█         | 4395/41127 [00:00<00:05, 6137.80it/s] 12%|█▏        | 4966/41127 [00:00<00:07, 4829.23it/s] 14%|█▎        | 5610/41127 [00:01<00:06, 5220.64it/s] 15%|█▌        | 6245/41127 [00:01<00:06, 5514.36it/s] 17%|█▋        | 6884/41127 [00:01<00:05, 5748.47it/s] 18%|█▊        | 7529/41127 [00:01<00:05, 5940.55it/s] 20%|█▉        | 8136/41127 [00:01<00:06, 4898.72it/s] 21%|██▏       | 8779/41127 [00:01<00:06, 5274.30it/s] 23%|██▎       | 9424/41127 [00:01<00:05, 5577.46it/s] 24%|██▍       | 10067/41127 [00:01<00:05, 5807.12it/s] 26%|██▌       | 10712/41127 [00:01<00:05, 5984.64it/s] 28%|██▊       | 11328/41127 [00:02<00:06, 4468.94it/s] 29%|██▉       | 11970/41127 [00:02<00:05, 4917.22it/s] 31%|███       | 12614/41127 [00:02<00:05, 5291.43it/s] 32%|███▏      | 13254/41127 [00:02<00:04, 5579.72it/s] 34%|███▍      | 13896/41127 [00:02<00:04, 5807.73it/s] 35%|███▌      | 14540/41127 [00:02<00:04, 5982.46it/s] 37%|███▋      | 15183/41127 [00:02<00:04, 6109.97it/s] 38%|███▊      | 15811/41127 [00:02<00:05, 4692.42it/s] 40%|████      | 16451/41127 [00:03<00:04, 5099.19it/s] 42%|████▏     | 17096/41127 [00:03<00:04, 5440.82it/s] 43%|████▎     | 17738/41127 [00:03<00:04, 5700.85it/s] 45%|████▍     | 18382/41127 [00:03<00:03, 5902.42it/s] 46%|████▋     | 19022/41127 [00:03<00:03, 6041.17it/s] 48%|████▊     | 19667/41127 [00:03<00:03, 6157.89it/s] 49%|████▉     | 20311/41127 [00:03<00:03, 6238.35it/s] 51%|█████     | 20945/41127 [00:03<00:04, 4498.45it/s] 52%|█████▏    | 21586/41127 [00:03<00:03, 4940.28it/s] 54%|█████▍    | 22210/41127 [00:04<00:03, 5268.42it/s] 56%|█████▌    | 22856/41127 [00:04<00:03, 5576.98it/s] 57%|█████▋    | 23500/41127 [00:04<00:03, 5809.31it/s] 59%|█████▊    | 24145/41127 [00:04<00:02, 5985.77it/s] 60%|██████    | 24788/41127 [00:04<00:02, 6109.97it/s] 62%|██████▏   | 25433/41127 [00:04<00:02, 6207.76it/s] 63%|██████▎   | 26077/41127 [00:04<00:02, 6273.53it/s] 65%|██████▍   | 26720/41127 [00:04<00:02, 6317.94it/s] 67%|██████▋   | 27359/41127 [00:05<00:03, 4108.41it/s] 68%|██████▊   | 28000/41127 [00:05<00:02, 4604.18it/s] 70%|██████▉   | 28623/41127 [00:05<00:02, 4994.22it/s] 71%|███████   | 29257/41127 [00:05<00:02, 5332.34it/s] 73%|███████▎  | 29898/41127 [00:05<00:02, 5613.44it/s] 74%|███████▍  | 30538/41127 [00:05<00:01, 5827.39it/s] 76%|███████▌  | 31180/41127 [00:05<00:01, 5991.17it/s] 77%|███████▋  | 31821/41127 [00:05<00:01, 6110.88it/s] 79%|███████▉  | 32464/41127 [00:05<00:01, 6202.20it/s] 80%|████████  | 33106/41127 [00:05<00:01, 6263.20it/s] 82%|████████▏ | 33749/41127 [00:06<00:01, 6311.10it/s] 84%|████████▎ | 34392/41127 [00:06<00:01, 6344.63it/s] 85%|████████▌ | 35032/41127 [00:06<00:01, 3908.13it/s] 87%|████████▋ | 35673/41127 [00:06<00:01, 4425.38it/s] 88%|████████▊ | 36313/41127 [00:06<00:00, 4876.73it/s] 90%|████████▉ | 36956/41127 [00:06<00:00, 5255.88it/s] 91%|█████████▏| 37596/41127 [00:06<00:00, 5553.56it/s] 93%|█████████▎| 38237/41127 [00:06<00:00, 5784.91it/s] 95%|█████████▍| 38879/41127 [00:07<00:00, 5960.22it/s] 96%|█████████▌| 39519/41127 [00:07<00:00, 6085.58it/s] 98%|█████████▊| 40161/41127 [00:07<00:00, 6181.27it/s] 99%|█████████▉| 40802/41127 [00:07<00:00, 6246.44it/s]100%|██████████| 41127/41127 [00:07<00:00, 5559.18it/s]
Saving...
/home/bsw38/.conda/envs/benchmark_gnn_2/lib/python3.7/site-packages/torch/cuda/__init__.py:125: UserWarning: 
NVIDIA A100-PCIE-40GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.
If you want to use the NVIDIA A100-PCIE-40GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/

  warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
GNN(
  (atom_encoder): AtomEncoder(
    (atom_embedding_list): ModuleList(
      (0): Embedding(119, 300)
      (1): Embedding(4, 300)
      (2): Embedding(12, 300)
      (3): Embedding(12, 300)
      (4): Embedding(10, 300)
      (5): Embedding(6, 300)
      (6): Embedding(6, 300)
      (7): Embedding(2, 300)
      (8): Embedding(2, 300)
    )
  )
  (bond_encoder): BondEncoder(
    (bond_embedding_list): ModuleList(
      (0): Embedding(5, 300)
      (1): Embedding(6, 300)
      (2): Embedding(2, 300)
    )
  )
  (layers): ModuleList(
    (0): ChebLayer(
      (batchnorm_h): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (dropout): Dropout(p=0.5, inplace=False)
      (linear): Linear(in_features=900, out_features=300, bias=True)
    )
    (1): ChebLayer(
      (batchnorm_h): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (dropout): Dropout(p=0.5, inplace=False)
      (linear): Linear(in_features=900, out_features=300, bias=True)
    )
    (2): ChebLayer(
      (batchnorm_h): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (dropout): Dropout(p=0.5, inplace=False)
      (linear): Linear(in_features=900, out_features=300, bias=True)
    )
    (3): ChebLayer(
      (batchnorm_h): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (dropout): Dropout(p=0.5, inplace=False)
      (linear): Linear(in_features=900, out_features=300, bias=True)
    )
    (4): ChebLayer(
      (batchnorm_h): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (dropout): Dropout(p=0.5, inplace=False)
      (linear): Linear(in_features=900, out_features=300, bias=True)
    )
  )
  (graph_pred_linear): MLPReadout(
    (FC_layers): ModuleList(
      (0): Linear(in_features=300, out_features=150, bias=True)
      (1): Linear(in_features=150, out_features=75, bias=True)
      (2): Linear(in_features=75, out_features=1, bias=True)
    )
  )
)
Total parameters: 1466851
=====Epoch 1
Training...
Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "main_dgl.py", line 180, in <module>
    main()
  File "main_dgl.py", line 136, in main
    train(model, device, train_loader, optimizer, dataset.task_type)
  File "main_dgl.py", line 25, in train
    pred = model(batch_graphs, batch_h, batch_e)
  File "/home/bsw38/.conda/envs/benchmark_gnn_2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/vast/palmer/home.mccleary/bsw38/GraphML/ChebNetGNNs/OGB/gnn_dgl.py", line 105, in forward
    h, e = conv(g, h, e)
  File "/home/bsw38/.conda/envs/benchmark_gnn_2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/vast/palmer/home.mccleary/bsw38/GraphML/ChebNetGNNs/OGB/gnn_dgl.py", line 148, in forward
    D_sqrt = torch.pow(g.in_degrees().float().clamp(
  File "/home/bsw38/.conda/envs/benchmark_gnn_2/lib/python3.7/site-packages/dgl/heterograph.py", line 3238, in in_degrees
    deg = self._graph.in_degrees(etid, v_tensor)
  File "/home/bsw38/.conda/envs/benchmark_gnn_2/lib/python3.7/site-packages/dgl/heterograph_index.py", line 577, in in_degrees
    self, int(etype), F.to_dgl_nd(v)))
  File "dgl/_ffi/_cython/./function.pxi", line 287, in dgl._ffi._cy3.core.FunctionBase.__call__
  File "dgl/_ffi/_cython/./function.pxi", line 222, in dgl._ffi._cy3.core.FuncCall
  File "dgl/_ffi/_cython/./function.pxi", line 211, in dgl._ffi._cy3.core.FuncCall3
  File "dgl/_ffi/_cython/./base.pxi", line 155, in dgl._ffi._cy3.core.CALL
dgl._ffi.base.DGLError: [10:54:52] /opt/dgl/src/array/cuda/coo_sort.cu:160: Check failed: e == cudaSuccess || e == cudaErrorCudartUnloading: CUDA kernel launch error: no kernel image is available for execution on the device
Stack trace:
  [bt] (0) /home/bsw38/.conda/envs/benchmark_gnn_2/lib/python3.7/site-packages/dgl/libdgl.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x4f) [0x152510e2aa4f]
  [bt] (1) /home/bsw38/.conda/envs/benchmark_gnn_2/lib/python3.7/site-packages/dgl/libdgl.so(std::pair<bool, bool> dgl::aten::impl::COOIsSorted<(DLDeviceType)2, long>(dgl::aten::COOMatrix)+0x252) [0x152511672b03]
  [bt] (2) /home/bsw38/.conda/envs/benchmark_gnn_2/lib/python3.7/site-packages/dgl/libdgl.so(dgl::aten::COOIsSorted(dgl::aten::COOMatrix)+0x1e3) [0x152510e0f653]
  [bt] (3) /home/bsw38/.conda/envs/benchmark_gnn_2/lib/python3.7/site-packages/dgl/libdgl.so(dgl::aten::CSRMatrix dgl::aten::impl::COOToCSR<(DLDeviceType)2, long>(dgl::aten::COOMatrix)+0xb4) [0x1525116701cf]
  [bt] (4) /home/bsw38/.conda/envs/benchmark_gnn_2/lib/python3.7/site-packages/dgl/libdgl.so(dgl::aten::COOToCSR(dgl::aten::COOMatrix)+0x3f3) [0x152510e0e313]
  [bt] (5) /home/bsw38/.conda/envs/benchmark_gnn_2/lib/python3.7/site-packages/dgl/libdgl.so(dgl::UnitGraph::GetInCSR(bool) const+0x300) [0x1525115f2840]
  [bt] (6) /home/bsw38/.conda/envs/benchmark_gnn_2/lib/python3.7/site-packages/dgl/libdgl.so(dgl::UnitGraph::GetFormat(dgl::SparseFormat) const+0x4d) [0x1525115f37bd]
  [bt] (7) /home/bsw38/.conda/envs/benchmark_gnn_2/lib/python3.7/site-packages/dgl/libdgl.so(dgl::UnitGraph::InDegrees(unsigned long, dgl::runtime::NDArray) const+0x36) [0x1525115f4cb6]
  [bt] (8) /home/bsw38/.conda/envs/benchmark_gnn_2/lib/python3.7/site-packages/dgl/libdgl.so(dgl::HeteroGraph::InDegrees(unsigned long, dgl::runtime::NDArray) const+0x46) [0x152511525d86]


