I'm echoing to stdout
I'm echoing to stderr
My JobID is 58043947
I have 4 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.0295s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 2, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'poly_mlp', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_all', 'num_eigs': 16, 'bias_mode': 'spatial', 'l1_reg': 1e-05, 'l2_reg': 0.0005, 'gen_reg': 0.0, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/aug07/zinc_train_rec.csv', 'test': 'supp_data/molecules/aug07/zinc_test_rec.csv', 'val': 'supp_data/molecules/aug07/zinc_val_rec.csv'}, 'fixMissingPhi1': False, 'extraOrtho': False, 'doublePrecision': True, 'eigval_hidden_dim': 100, 'eigval_num_hidden_layer': 0, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [01:22<?, ?it/s, lr=0.001, test_MAE=0.883, time=82.8, train_MAE=0.904, train_loss=1.05, val_MAE=0.832, val_loss=0.975]Epoch 0:   0%|          | 1/1000 [01:22<22:59:17, 82.84s/it, lr=0.001, test_MAE=0.883, time=82.8, train_MAE=0.904, train_loss=1.05, val_MAE=0.832, val_loss=0.975]Epoch 1:   0%|          | 1/1000 [01:22<22:59:17, 82.84s/it, lr=0.001, test_MAE=0.883, time=82.8, train_MAE=0.904, train_loss=1.05, val_MAE=0.832, val_loss=0.975]Epoch 1:   0%|          | 1/1000 [02:27<22:59:17, 82.84s/it, lr=0.001, test_MAE=0.779, time=64.9, train_MAE=0.669, train_loss=0.811, val_MAE=0.738, val_loss=0.878]Epoch 1:   0%|          | 2/1000 [02:27<21:28:33, 77.47s/it, lr=0.001, test_MAE=0.779, time=64.9, train_MAE=0.669, train_loss=0.811, val_MAE=0.738, val_loss=0.878]Epoch 2:   0%|          | 2/1000 [02:27<21:28:33, 77.47s/it, lr=0.001, test_MAE=0.779, time=64.9, train_MAE=0.669, train_loss=0.811, val_MAE=0.738, val_loss=0.878]Epoch 2:   0%|          | 2/1000 [03:32<21:28:33, 77.47s/it, lr=0.001, test_MAE=0.675, time=64.8, train_MAE=0.657, train_loss=0.795, val_MAE=0.633, val_loss=0.769]Epoch 2:   0%|          | 3/1000 [03:32<20:24:16, 73.68s/it, lr=0.001, test_MAE=0.675, time=64.8, train_MAE=0.657, train_loss=0.795, val_MAE=0.633, val_loss=0.769]Epoch 3:   0%|          | 3/1000 [03:32<20:24:16, 73.68s/it, lr=0.001, test_MAE=0.675, time=64.8, train_MAE=0.657, train_loss=0.795, val_MAE=0.633, val_loss=0.769]Epoch 3:   0%|          | 3/1000 [04:37<20:24:16, 73.68s/it, lr=0.001, test_MAE=0.935, time=64.8, train_MAE=0.664, train_loss=0.799, val_MAE=0.903, val_loss=1.04] Epoch 3:   0%|          | 4/1000 [04:37<19:39:11, 71.04s/it, lr=0.001, test_MAE=0.935, time=64.8, train_MAE=0.664, train_loss=0.799, val_MAE=0.903, val_loss=1.04]Epoch 4:   0%|          | 4/1000 [04:37<19:39:11, 71.04s/it, lr=0.001, test_MAE=0.935, time=64.8, train_MAE=0.664, train_loss=0.799, val_MAE=0.903, val_loss=1.04]Epoch 4:   0%|          | 4/1000 [05:42<19:39:11, 71.04s/it, lr=0.001, test_MAE=0.639, time=64.9, train_MAE=0.626, train_loss=0.759, val_MAE=0.605, val_loss=0.737]Epoch 4:   0%|          | 5/1000 [05:42<19:07:41, 69.21s/it, lr=0.001, test_MAE=0.639, time=64.9, train_MAE=0.626, train_loss=0.759, val_MAE=0.605, val_loss=0.737]Epoch 5:   0%|          | 5/1000 [05:42<19:07:41, 69.21s/it, lr=0.001, test_MAE=0.639, time=64.9, train_MAE=0.626, train_loss=0.759, val_MAE=0.605, val_loss=0.737]Epoch 5:   0%|          | 5/1000 [06:48<19:07:41, 69.21s/it, lr=0.001, test_MAE=0.658, time=65.6, train_MAE=0.623, train_loss=0.753, val_MAE=0.631, val_loss=0.76] Epoch 5:   1%|          | 6/1000 [06:48<18:48:51, 68.14s/it, lr=0.001, test_MAE=0.658, time=65.6, train_MAE=0.623, train_loss=0.753, val_MAE=0.631, val_loss=0.76]Epoch 6:   1%|          | 6/1000 [06:48<18:48:51, 68.14s/it, lr=0.001, test_MAE=0.658, time=65.6, train_MAE=0.623, train_loss=0.753, val_MAE=0.631, val_loss=0.76]Epoch 6:   1%|          | 6/1000 [07:53<18:48:51, 68.14s/it, lr=0.001, test_MAE=0.682, time=65.9, train_MAE=0.616, train_loss=0.745, val_MAE=0.643, val_loss=0.77]Epoch 6:   1%|          | 7/1000 [07:53<18:36:42, 67.48s/it, lr=0.001, test_MAE=0.682, time=65.9, train_MAE=0.616, train_loss=0.745, val_MAE=0.643, val_loss=0.77]Epoch 7:   1%|          | 7/1000 [07:53<18:36:42, 67.48s/it, lr=0.001, test_MAE=0.682, time=65.9, train_MAE=0.616, train_loss=0.745, val_MAE=0.643, val_loss=0.77]Epoch 7:   1%|          | 7/1000 [08:59<18:36:42, 67.48s/it, lr=0.001, test_MAE=0.92, time=65.7, train_MAE=0.61, train_loss=0.736, val_MAE=0.881, val_loss=1.01]  Epoch 7:   1%|          | 8/1000 [08:59<18:26:47, 66.94s/it, lr=0.001, test_MAE=0.92, time=65.7, train_MAE=0.61, train_loss=0.736, val_MAE=0.881, val_loss=1.01]Epoch 8:   1%|          | 8/1000 [08:59<18:26:47, 66.94s/it, lr=0.001, test_MAE=0.92, time=65.7, train_MAE=0.61, train_loss=0.736, val_MAE=0.881, val_loss=1.01]Epoch 8:   1%|          | 8/1000 [10:05<18:26:47, 66.94s/it, lr=0.001, test_MAE=0.67, time=65.6, train_MAE=0.614, train_loss=0.739, val_MAE=0.645, val_loss=0.769]Epoch 8:   1%|          | 9/1000 [10:05<18:19:17, 66.56s/it, lr=0.001, test_MAE=0.67, time=65.6, train_MAE=0.614, train_loss=0.739, val_MAE=0.645, val_loss=0.769]Epoch 9:   1%|          | 9/1000 [10:05<18:19:17, 66.56s/it, lr=0.001, test_MAE=0.67, time=65.6, train_MAE=0.614, train_loss=0.739, val_MAE=0.645, val_loss=0.769]Epoch 9:   1%|          | 9/1000 [11:11<18:19:17, 66.56s/it, lr=0.001, test_MAE=0.818, time=66, train_MAE=0.592, train_loss=0.715, val_MAE=0.79, val_loss=0.913]  Epoch 9:   1%|          | 10/1000 [11:11<18:15:26, 66.39s/it, lr=0.001, test_MAE=0.818, time=66, train_MAE=0.592, train_loss=0.715, val_MAE=0.79, val_loss=0.913]Epoch 10:   1%|          | 10/1000 [11:11<18:15:26, 66.39s/it, lr=0.001, test_MAE=0.818, time=66, train_MAE=0.592, train_loss=0.715, val_MAE=0.79, val_loss=0.913]Epoch 10:   1%|          | 10/1000 [12:16<18:15:26, 66.39s/it, lr=0.001, test_MAE=0.636, time=65.6, train_MAE=0.604, train_loss=0.726, val_MAE=0.6, val_loss=0.721]Epoch 10:   1%|          | 11/1000 [12:16<18:10:23, 66.15s/it, lr=0.001, test_MAE=0.636, time=65.6, train_MAE=0.604, train_loss=0.726, val_MAE=0.6, val_loss=0.721]Epoch 11:   1%|          | 11/1000 [12:16<18:10:23, 66.15s/it, lr=0.001, test_MAE=0.636, time=65.6, train_MAE=0.604, train_loss=0.726, val_MAE=0.6, val_loss=0.721]Epoch 11:   1%|          | 11/1000 [13:22<18:10:23, 66.15s/it, lr=0.001, test_MAE=0.625, time=65.2, train_MAE=0.601, train_loss=0.721, val_MAE=0.593, val_loss=0.713]Epoch 11:   1%|          | 12/1000 [13:22<18:05:24, 65.92s/it, lr=0.001, test_MAE=0.625, time=65.2, train_MAE=0.601, train_loss=0.721, val_MAE=0.593, val_loss=0.713]Epoch 12:   1%|          | 12/1000 [13:22<18:05:24, 65.92s/it, lr=0.001, test_MAE=0.625, time=65.2, train_MAE=0.601, train_loss=0.721, val_MAE=0.593, val_loss=0.713]Epoch 12:   1%|          | 12/1000 [14:28<18:05:24, 65.92s/it, lr=0.001, test_MAE=0.642, time=65.9, train_MAE=0.6, train_loss=0.72, val_MAE=0.608, val_loss=0.727]   Epoch 12:   1%|▏         | 13/1000 [14:28<18:04:27, 65.92s/it, lr=0.001, test_MAE=0.642, time=65.9, train_MAE=0.6, train_loss=0.72, val_MAE=0.608, val_loss=0.727]Epoch 13:   1%|▏         | 13/1000 [14:28<18:04:27, 65.92s/it, lr=0.001, test_MAE=0.642, time=65.9, train_MAE=0.6, train_loss=0.72, val_MAE=0.608, val_loss=0.727]Epoch 13:   1%|▏         | 13/1000 [15:33<18:04:27, 65.92s/it, lr=0.001, test_MAE=0.7, time=65.6, train_MAE=0.597, train_loss=0.716, val_MAE=0.657, val_loss=0.775]Epoch 13:   1%|▏         | 14/1000 [15:33<18:01:55, 65.84s/it, lr=0.001, test_MAE=0.7, time=65.6, train_MAE=0.597, train_loss=0.716, val_MAE=0.657, val_loss=0.775]Epoch 14:   1%|▏         | 14/1000 [15:33<18:01:55, 65.84s/it, lr=0.001, test_MAE=0.7, time=65.6, train_MAE=0.597, train_loss=0.716, val_MAE=0.657, val_loss=0.775]Epoch 14:   1%|▏         | 14/1000 [16:39<18:01:55, 65.84s/it, lr=0.001, test_MAE=0.838, time=65.3, train_MAE=0.587, train_loss=0.705, val_MAE=0.806, val_loss=0.924]Epoch 14:   2%|▏         | 15/1000 [16:39<17:58:17, 65.68s/it, lr=0.001, test_MAE=0.838, time=65.3, train_MAE=0.587, train_loss=0.705, val_MAE=0.806, val_loss=0.924]Epoch 15:   2%|▏         | 15/1000 [16:39<17:58:17, 65.68s/it, lr=0.001, test_MAE=0.838, time=65.3, train_MAE=0.587, train_loss=0.705, val_MAE=0.806, val_loss=0.924]Epoch 15:   2%|▏         | 15/1000 [17:45<17:58:17, 65.68s/it, lr=0.001, test_MAE=0.678, time=65.9, train_MAE=0.58, train_loss=0.696, val_MAE=0.634, val_loss=0.751] Epoch 15:   2%|▏         | 16/1000 [17:45<17:58:29, 65.76s/it, lr=0.001, test_MAE=0.678, time=65.9, train_MAE=0.58, train_loss=0.696, val_MAE=0.634, val_loss=0.751]Epoch 16:   2%|▏         | 16/1000 [17:45<17:58:29, 65.76s/it, lr=0.001, test_MAE=0.678, time=65.9, train_MAE=0.58, train_loss=0.696, val_MAE=0.634, val_loss=0.751]Epoch 16:   2%|▏         | 16/1000 [18:50<17:58:29, 65.76s/it, lr=0.001, test_MAE=0.635, time=65.7, train_MAE=0.574, train_loss=0.69, val_MAE=0.597, val_loss=0.713]Epoch 16:   2%|▏         | 17/1000 [18:50<17:56:57, 65.73s/it, lr=0.001, test_MAE=0.635, time=65.7, train_MAE=0.574, train_loss=0.69, val_MAE=0.597, val_loss=0.713]Epoch 17:   2%|▏         | 17/1000 [18:50<17:56:57, 65.73s/it, lr=0.001, test_MAE=0.635, time=65.7, train_MAE=0.574, train_loss=0.69, val_MAE=0.597, val_loss=0.713]Epoch 17:   2%|▏         | 17/1000 [19:56<17:56:57, 65.73s/it, lr=0.001, test_MAE=0.695, time=65.3, train_MAE=0.573, train_loss=0.688, val_MAE=0.639, val_loss=0.754]Epoch 17:   2%|▏         | 18/1000 [19:56<17:53:48, 65.61s/it, lr=0.001, test_MAE=0.695, time=65.3, train_MAE=0.573, train_loss=0.688, val_MAE=0.639, val_loss=0.754]Epoch 18:   2%|▏         | 18/1000 [19:56<17:53:48, 65.61s/it, lr=0.001, test_MAE=0.695, time=65.3, train_MAE=0.573, train_loss=0.688, val_MAE=0.639, val_loss=0.754]Epoch 18:   2%|▏         | 18/1000 [21:02<17:53:48, 65.61s/it, lr=0.001, test_MAE=0.655, time=66, train_MAE=0.575, train_loss=0.689, val_MAE=0.603, val_loss=0.717]  Epoch 18:   2%|▏         | 19/1000 [21:02<17:54:33, 65.72s/it, lr=0.001, test_MAE=0.655, time=66, train_MAE=0.575, train_loss=0.689, val_MAE=0.603, val_loss=0.717]Epoch 19:   2%|▏         | 19/1000 [21:02<17:54:33, 65.72s/it, lr=0.001, test_MAE=0.655, time=66, train_MAE=0.575, train_loss=0.689, val_MAE=0.603, val_loss=0.717]Epoch 19:   2%|▏         | 19/1000 [22:07<17:54:33, 65.72s/it, lr=0.001, test_MAE=0.688, time=65.6, train_MAE=0.574, train_loss=0.688, val_MAE=0.663, val_loss=0.777]Epoch 19:   2%|▏         | 20/1000 [22:07<17:52:56, 65.69s/it, lr=0.001, test_MAE=0.688, time=65.6, train_MAE=0.574, train_loss=0.688, val_MAE=0.663, val_loss=0.777]Epoch 20:   2%|▏         | 20/1000 [22:07<17:52:56, 65.69s/it, lr=0.001, test_MAE=0.688, time=65.6, train_MAE=0.574, train_loss=0.688, val_MAE=0.663, val_loss=0.777]Epoch 20:   2%|▏         | 20/1000 [23:13<17:52:56, 65.69s/it, lr=0.001, test_MAE=0.797, time=65.6, train_MAE=0.582, train_loss=0.696, val_MAE=0.754, val_loss=0.867]Epoch 20:   2%|▏         | 21/1000 [23:13<17:51:28, 65.67s/it, lr=0.001, test_MAE=0.797, time=65.6, train_MAE=0.582, train_loss=0.696, val_MAE=0.754, val_loss=0.867]Epoch 21:   2%|▏         | 21/1000 [23:13<17:51:28, 65.67s/it, lr=0.001, test_MAE=0.797, time=65.6, train_MAE=0.582, train_loss=0.696, val_MAE=0.754, val_loss=0.867]Epoch 21:   2%|▏         | 21/1000 [24:19<17:51:28, 65.67s/it, lr=0.001, test_MAE=0.78, time=66, train_MAE=0.573, train_loss=0.686, val_MAE=0.741, val_loss=0.854]   Epoch 21:   2%|▏         | 22/1000 [24:19<17:51:57, 65.76s/it, lr=0.001, test_MAE=0.78, time=66, train_MAE=0.573, train_loss=0.686, val_MAE=0.741, val_loss=0.854]Epoch 22:   2%|▏         | 22/1000 [24:19<17:51:57, 65.76s/it, lr=0.001, test_MAE=0.78, time=66, train_MAE=0.573, train_loss=0.686, val_MAE=0.741, val_loss=0.854]Epoch 22:   2%|▏         | 22/1000 [25:24<17:51:57, 65.76s/it, lr=0.001, test_MAE=0.617, time=65.3, train_MAE=0.565, train_loss=0.678, val_MAE=0.584, val_loss=0.696]Epoch 22:   2%|▏         | 23/1000 [25:24<17:48:37, 65.63s/it, lr=0.001, test_MAE=0.617, time=65.3, train_MAE=0.565, train_loss=0.678, val_MAE=0.584, val_loss=0.696]Epoch 23:   2%|▏         | 23/1000 [25:24<17:48:37, 65.63s/it, lr=0.001, test_MAE=0.617, time=65.3, train_MAE=0.565, train_loss=0.678, val_MAE=0.584, val_loss=0.696]Epoch 23:   2%|▏         | 23/1000 [26:30<17:48:37, 65.63s/it, lr=0.001, test_MAE=0.617, time=66, train_MAE=0.563, train_loss=0.676, val_MAE=0.582, val_loss=0.694]  Epoch 23:   2%|▏         | 24/1000 [26:30<17:49:11, 65.73s/it, lr=0.001, test_MAE=0.617, time=66, train_MAE=0.563, train_loss=0.676, val_MAE=0.582, val_loss=0.694]Epoch 24:   2%|▏         | 24/1000 [26:30<17:49:11, 65.73s/it, lr=0.001, test_MAE=0.617, time=66, train_MAE=0.563, train_loss=0.676, val_MAE=0.582, val_loss=0.694]Epoch 24:   2%|▏         | 24/1000 [27:36<17:49:11, 65.73s/it, lr=0.001, test_MAE=0.641, time=65.6, train_MAE=0.56, train_loss=0.672, val_MAE=0.594, val_loss=0.705]Epoch 24:   2%|▎         | 25/1000 [27:36<17:47:28, 65.69s/it, lr=0.001, test_MAE=0.641, time=65.6, train_MAE=0.56, train_loss=0.672, val_MAE=0.594, val_loss=0.705]Epoch 25:   2%|▎         | 25/1000 [27:36<17:47:28, 65.69s/it, lr=0.001, test_MAE=0.641, time=65.6, train_MAE=0.56, train_loss=0.672, val_MAE=0.594, val_loss=0.705]Epoch 25:   2%|▎         | 25/1000 [28:41<17:47:28, 65.69s/it, lr=0.001, test_MAE=0.61, time=65.6, train_MAE=0.566, train_loss=0.678, val_MAE=0.57, val_loss=0.681] Epoch 25:   3%|▎         | 26/1000 [28:41<17:45:57, 65.66s/it, lr=0.001, test_MAE=0.61, time=65.6, train_MAE=0.566, train_loss=0.678, val_MAE=0.57, val_loss=0.681]Epoch 26:   3%|▎         | 26/1000 [28:41<17:45:57, 65.66s/it, lr=0.001, test_MAE=0.61, time=65.6, train_MAE=0.566, train_loss=0.678, val_MAE=0.57, val_loss=0.681]Epoch 26:   3%|▎         | 26/1000 [29:47<17:45:57, 65.66s/it, lr=0.001, test_MAE=0.636, time=65.9, train_MAE=0.551, train_loss=0.662, val_MAE=0.584, val_loss=0.695]Epoch 26:   3%|▎         | 27/1000 [29:47<17:45:59, 65.73s/it, lr=0.001, test_MAE=0.636, time=65.9, train_MAE=0.551, train_loss=0.662, val_MAE=0.584, val_loss=0.695]Epoch 27:   3%|▎         | 27/1000 [29:47<17:45:59, 65.73s/it, lr=0.001, test_MAE=0.636, time=65.9, train_MAE=0.551, train_loss=0.662, val_MAE=0.584, val_loss=0.695]Epoch 27:   3%|▎         | 27/1000 [30:53<17:45:59, 65.73s/it, lr=0.001, test_MAE=0.678, time=65.6, train_MAE=0.555, train_loss=0.666, val_MAE=0.637, val_loss=0.748]Epoch 27:   3%|▎         | 28/1000 [30:53<17:44:32, 65.71s/it, lr=0.001, test_MAE=0.678, time=65.6, train_MAE=0.555, train_loss=0.666, val_MAE=0.637, val_loss=0.748]Epoch 28:   3%|▎         | 28/1000 [30:53<17:44:32, 65.71s/it, lr=0.001, test_MAE=0.678, time=65.6, train_MAE=0.555, train_loss=0.666, val_MAE=0.637, val_loss=0.748]Epoch 28:   3%|▎         | 28/1000 [31:58<17:44:32, 65.71s/it, lr=0.001, test_MAE=0.628, time=65.3, train_MAE=0.549, train_loss=0.66, val_MAE=0.588, val_loss=0.698] Epoch 28:   3%|▎         | 29/1000 [31:58<17:42:06, 65.63s/it, lr=0.001, test_MAE=0.628, time=65.3, train_MAE=0.549, train_loss=0.66, val_MAE=0.588, val_loss=0.698]Epoch 29:   3%|▎         | 29/1000 [31:58<17:42:06, 65.63s/it, lr=0.001, test_MAE=0.628, time=65.3, train_MAE=0.549, train_loss=0.66, val_MAE=0.588, val_loss=0.698]Epoch 29:   3%|▎         | 29/1000 [33:04<17:42:06, 65.63s/it, lr=0.001, test_MAE=0.732, time=66, train_MAE=0.549, train_loss=0.66, val_MAE=0.676, val_loss=0.787]  Epoch 29:   3%|▎         | 30/1000 [33:04<17:42:54, 65.75s/it, lr=0.001, test_MAE=0.732, time=66, train_MAE=0.549, train_loss=0.66, val_MAE=0.676, val_loss=0.787]Epoch 30:   3%|▎         | 30/1000 [33:04<17:42:54, 65.75s/it, lr=0.001, test_MAE=0.732, time=66, train_MAE=0.549, train_loss=0.66, val_MAE=0.676, val_loss=0.787]Epoch 30:   3%|▎         | 30/1000 [34:09<17:42:54, 65.75s/it, lr=0.001, test_MAE=0.63, time=64.6, train_MAE=0.554, train_loss=0.664, val_MAE=0.58, val_loss=0.69]Epoch 30:   3%|▎         | 31/1000 [34:09<17:36:25, 65.41s/it, lr=0.001, test_MAE=0.63, time=64.6, train_MAE=0.554, train_loss=0.664, val_MAE=0.58, val_loss=0.69]Epoch 31:   3%|▎         | 31/1000 [34:09<17:36:25, 65.41s/it, lr=0.001, test_MAE=0.63, time=64.6, train_MAE=0.554, train_loss=0.664, val_MAE=0.58, val_loss=0.69]Epoch 31:   3%|▎         | 31/1000 [35:12<17:36:25, 65.41s/it, lr=0.001, test_MAE=0.618, time=63.2, train_MAE=0.551, train_loss=0.661, val_MAE=0.578, val_loss=0.688]Epoch    32: reducing learning rate of group 0 to 5.0000e-04.
Epoch 31:   3%|▎         | 32/1000 [35:12<17:24:43, 64.76s/it, lr=0.001, test_MAE=0.618, time=63.2, train_MAE=0.551, train_loss=0.661, val_MAE=0.578, val_loss=0.688]Epoch 32:   3%|▎         | 32/1000 [35:12<17:24:43, 64.76s/it, lr=0.001, test_MAE=0.618, time=63.2, train_MAE=0.551, train_loss=0.661, val_MAE=0.578, val_loss=0.688]Epoch 32:   3%|▎         | 32/1000 [36:14<17:24:43, 64.76s/it, lr=0.0005, test_MAE=0.626, time=62.2, train_MAE=0.533, train_loss=0.643, val_MAE=0.595, val_loss=0.704]Epoch 32:   3%|▎         | 33/1000 [36:15<17:12:01, 64.03s/it, lr=0.0005, test_MAE=0.626, time=62.2, train_MAE=0.533, train_loss=0.643, val_MAE=0.595, val_loss=0.704]Epoch 33:   3%|▎         | 33/1000 [36:15<17:12:01, 64.03s/it, lr=0.0005, test_MAE=0.626, time=62.2, train_MAE=0.533, train_loss=0.643, val_MAE=0.595, val_loss=0.704]Epoch 33:   3%|▎         | 33/1000 [37:16<17:12:01, 64.03s/it, lr=0.0005, test_MAE=0.602, time=61, train_MAE=0.52, train_loss=0.629, val_MAE=0.566, val_loss=0.675]   Epoch 33:   3%|▎         | 34/1000 [37:16<16:56:32, 63.14s/it, lr=0.0005, test_MAE=0.602, time=61, train_MAE=0.52, train_loss=0.629, val_MAE=0.566, val_loss=0.675]Epoch 34:   3%|▎         | 34/1000 [37:16<16:56:32, 63.14s/it, lr=0.0005, test_MAE=0.602, time=61, train_MAE=0.52, train_loss=0.629, val_MAE=0.566, val_loss=0.675]Epoch 34:   3%|▎         | 34/1000 [38:16<16:56:32, 63.14s/it, lr=0.0005, test_MAE=0.634, time=60.4, train_MAE=0.514, train_loss=0.623, val_MAE=0.606, val_loss=0.715]Epoch 34:   4%|▎         | 35/1000 [38:16<16:42:16, 62.32s/it, lr=0.0005, test_MAE=0.634, time=60.4, train_MAE=0.514, train_loss=0.623, val_MAE=0.606, val_loss=0.715]Epoch 35:   4%|▎         | 35/1000 [38:16<16:42:16, 62.32s/it, lr=0.0005, test_MAE=0.634, time=60.4, train_MAE=0.514, train_loss=0.623, val_MAE=0.606, val_loss=0.715]Epoch 35:   4%|▎         | 35/1000 [39:17<16:42:16, 62.32s/it, lr=0.0005, test_MAE=0.646, time=60.9, train_MAE=0.525, train_loss=0.634, val_MAE=0.593, val_loss=0.702]Epoch 35:   4%|▎         | 36/1000 [39:17<16:34:29, 61.90s/it, lr=0.0005, test_MAE=0.646, time=60.9, train_MAE=0.525, train_loss=0.634, val_MAE=0.593, val_loss=0.702]Epoch 36:   4%|▎         | 36/1000 [39:17<16:34:29, 61.90s/it, lr=0.0005, test_MAE=0.646, time=60.9, train_MAE=0.525, train_loss=0.634, val_MAE=0.593, val_loss=0.702]Epoch 36:   4%|▎         | 36/1000 [40:18<16:34:29, 61.90s/it, lr=0.0005, test_MAE=0.61, time=60.7, train_MAE=0.518, train_loss=0.627, val_MAE=0.57, val_loss=0.679]  Epoch 36:   4%|▎         | 37/1000 [40:18<16:27:42, 61.54s/it, lr=0.0005, test_MAE=0.61, time=60.7, train_MAE=0.518, train_loss=0.627, val_MAE=0.57, val_loss=0.679]Epoch 37:   4%|▎         | 37/1000 [40:18<16:27:42, 61.54s/it, lr=0.0005, test_MAE=0.61, time=60.7, train_MAE=0.518, train_loss=0.627, val_MAE=0.57, val_loss=0.679]Epoch 37:   4%|▎         | 37/1000 [41:18<16:27:42, 61.54s/it, lr=0.0005, test_MAE=0.617, time=60.4, train_MAE=0.524, train_loss=0.633, val_MAE=0.583, val_loss=0.692]Epoch 37:   4%|▍         | 38/1000 [41:18<16:21:21, 61.21s/it, lr=0.0005, test_MAE=0.617, time=60.4, train_MAE=0.524, train_loss=0.633, val_MAE=0.583, val_loss=0.692]Epoch 38:   4%|▍         | 38/1000 [41:18<16:21:21, 61.21s/it, lr=0.0005, test_MAE=0.617, time=60.4, train_MAE=0.524, train_loss=0.633, val_MAE=0.583, val_loss=0.692]Epoch 38:   4%|▍         | 38/1000 [42:19<16:21:21, 61.21s/it, lr=0.0005, test_MAE=0.599, time=60.9, train_MAE=0.526, train_loss=0.635, val_MAE=0.562, val_loss=0.671]Epoch 38:   4%|▍         | 39/1000 [42:19<16:19:12, 61.14s/it, lr=0.0005, test_MAE=0.599, time=60.9, train_MAE=0.526, train_loss=0.635, val_MAE=0.562, val_loss=0.671]Epoch 39:   4%|▍         | 39/1000 [42:19<16:19:12, 61.14s/it, lr=0.0005, test_MAE=0.599, time=60.9, train_MAE=0.526, train_loss=0.635, val_MAE=0.562, val_loss=0.671]Epoch 39:   4%|▍         | 39/1000 [43:20<16:19:12, 61.14s/it, lr=0.0005, test_MAE=0.611, time=60.7, train_MAE=0.511, train_loss=0.619, val_MAE=0.574, val_loss=0.682]Epoch 39:   4%|▍         | 40/1000 [43:20<16:16:00, 61.00s/it, lr=0.0005, test_MAE=0.611, time=60.7, train_MAE=0.511, train_loss=0.619, val_MAE=0.574, val_loss=0.682]Epoch 40:   4%|▍         | 40/1000 [43:20<16:16:00, 61.00s/it, lr=0.0005, test_MAE=0.611, time=60.7, train_MAE=0.511, train_loss=0.619, val_MAE=0.574, val_loss=0.682]Epoch 40:   4%|▍         | 40/1000 [44:20<16:16:00, 61.00s/it, lr=0.0005, test_MAE=0.603, time=60.7, train_MAE=0.518, train_loss=0.627, val_MAE=0.565, val_loss=0.673]Epoch 40:   4%|▍         | 41/1000 [44:20<16:13:28, 60.91s/it, lr=0.0005, test_MAE=0.603, time=60.7, train_MAE=0.518, train_loss=0.627, val_MAE=0.565, val_loss=0.673]Epoch 41:   4%|▍         | 41/1000 [44:20<16:13:28, 60.91s/it, lr=0.0005, test_MAE=0.603, time=60.7, train_MAE=0.518, train_loss=0.627, val_MAE=0.565, val_loss=0.673]Epoch 41:   4%|▍         | 41/1000 [45:21<16:13:28, 60.91s/it, lr=0.0005, test_MAE=0.65, time=60.9, train_MAE=0.51, train_loss=0.619, val_MAE=0.606, val_loss=0.714]  Epoch 41:   4%|▍         | 42/1000 [45:21<16:12:41, 60.92s/it, lr=0.0005, test_MAE=0.65, time=60.9, train_MAE=0.51, train_loss=0.619, val_MAE=0.606, val_loss=0.714]Epoch 42:   4%|▍         | 42/1000 [45:21<16:12:41, 60.92s/it, lr=0.0005, test_MAE=0.65, time=60.9, train_MAE=0.51, train_loss=0.619, val_MAE=0.606, val_loss=0.714]Epoch 42:   4%|▍         | 42/1000 [46:22<16:12:41, 60.92s/it, lr=0.0005, test_MAE=0.61, time=60.4, train_MAE=0.524, train_loss=0.632, val_MAE=0.58, val_loss=0.689]Epoch 42:   4%|▍         | 43/1000 [46:22<16:09:06, 60.76s/it, lr=0.0005, test_MAE=0.61, time=60.4, train_MAE=0.524, train_loss=0.632, val_MAE=0.58, val_loss=0.689]Epoch 43:   4%|▍         | 43/1000 [46:22<16:09:06, 60.76s/it, lr=0.0005, test_MAE=0.61, time=60.4, train_MAE=0.524, train_loss=0.632, val_MAE=0.58, val_loss=0.689]Epoch 43:   4%|▍         | 43/1000 [47:23<16:09:06, 60.76s/it, lr=0.0005, test_MAE=0.627, time=60.9, train_MAE=0.515, train_loss=0.623, val_MAE=0.595, val_loss=0.704]Epoch 43:   4%|▍         | 44/1000 [47:23<16:08:53, 60.81s/it, lr=0.0005, test_MAE=0.627, time=60.9, train_MAE=0.515, train_loss=0.623, val_MAE=0.595, val_loss=0.704]Epoch 44:   4%|▍         | 44/1000 [47:23<16:08:53, 60.81s/it, lr=0.0005, test_MAE=0.627, time=60.9, train_MAE=0.515, train_loss=0.623, val_MAE=0.595, val_loss=0.704]Epoch 44:   4%|▍         | 44/1000 [48:23<16:08:53, 60.81s/it, lr=0.0005, test_MAE=0.625, time=60.6, train_MAE=0.508, train_loss=0.616, val_MAE=0.586, val_loss=0.694]Epoch    45: reducing learning rate of group 0 to 2.5000e-04.
Epoch 44:   4%|▍         | 45/1000 [48:23<16:07:04, 60.76s/it, lr=0.0005, test_MAE=0.625, time=60.6, train_MAE=0.508, train_loss=0.616, val_MAE=0.586, val_loss=0.694]Epoch 45:   4%|▍         | 45/1000 [48:23<16:07:04, 60.76s/it, lr=0.0005, test_MAE=0.625, time=60.6, train_MAE=0.508, train_loss=0.616, val_MAE=0.586, val_loss=0.694]Epoch 45:   4%|▍         | 45/1000 [49:24<16:07:04, 60.76s/it, lr=0.00025, test_MAE=0.594, time=60.6, train_MAE=0.491, train_loss=0.599, val_MAE=0.565, val_loss=0.673]Epoch 45:   5%|▍         | 46/1000 [49:24<16:05:27, 60.72s/it, lr=0.00025, test_MAE=0.594, time=60.6, train_MAE=0.491, train_loss=0.599, val_MAE=0.565, val_loss=0.673]Epoch 46:   5%|▍         | 46/1000 [49:24<16:05:27, 60.72s/it, lr=0.00025, test_MAE=0.594, time=60.6, train_MAE=0.491, train_loss=0.599, val_MAE=0.565, val_loss=0.673]Epoch 46:   5%|▍         | 46/1000 [50:25<16:05:27, 60.72s/it, lr=0.00025, test_MAE=0.622, time=60.9, train_MAE=0.485, train_loss=0.593, val_MAE=0.592, val_loss=0.7]  Epoch 46:   5%|▍         | 47/1000 [50:25<16:05:20, 60.78s/it, lr=0.00025, test_MAE=0.622, time=60.9, train_MAE=0.485, train_loss=0.593, val_MAE=0.592, val_loss=0.7]Epoch 47:   5%|▍         | 47/1000 [50:25<16:05:20, 60.78s/it, lr=0.00025, test_MAE=0.622, time=60.9, train_MAE=0.485, train_loss=0.593, val_MAE=0.592, val_loss=0.7]Epoch 47:   5%|▍         | 47/1000 [51:25<16:05:20, 60.78s/it, lr=0.00025, test_MAE=0.603, time=60.6, train_MAE=0.492, train_loss=0.6, val_MAE=0.568, val_loss=0.676]Epoch 47:   5%|▍         | 48/1000 [51:25<16:03:40, 60.74s/it, lr=0.00025, test_MAE=0.603, time=60.6, train_MAE=0.492, train_loss=0.6, val_MAE=0.568, val_loss=0.676]Epoch 48:   5%|▍         | 48/1000 [51:25<16:03:40, 60.74s/it, lr=0.00025, test_MAE=0.603, time=60.6, train_MAE=0.492, train_loss=0.6, val_MAE=0.568, val_loss=0.676]Epoch 48:   5%|▍         | 48/1000 [52:26<16:03:40, 60.74s/it, lr=0.00025, test_MAE=0.616, time=60.3, train_MAE=0.489, train_loss=0.597, val_MAE=0.58, val_loss=0.688]Epoch 48:   5%|▍         | 49/1000 [52:26<16:00:51, 60.62s/it, lr=0.00025, test_MAE=0.616, time=60.3, train_MAE=0.489, train_loss=0.597, val_MAE=0.58, val_loss=0.688]Epoch 49:   5%|▍         | 49/1000 [52:26<16:00:51, 60.62s/it, lr=0.00025, test_MAE=0.616, time=60.3, train_MAE=0.489, train_loss=0.597, val_MAE=0.58, val_loss=0.688]Epoch 49:   5%|▍         | 49/1000 [53:27<16:00:51, 60.62s/it, lr=0.00025, test_MAE=0.597, time=61.2, train_MAE=0.488, train_loss=0.596, val_MAE=0.566, val_loss=0.674]Epoch 49:   5%|▌         | 50/1000 [53:27<16:02:31, 60.79s/it, lr=0.00025, test_MAE=0.597, time=61.2, train_MAE=0.488, train_loss=0.596, val_MAE=0.566, val_loss=0.674]Epoch 50:   5%|▌         | 50/1000 [53:27<16:02:31, 60.79s/it, lr=0.00025, test_MAE=0.597, time=61.2, train_MAE=0.488, train_loss=0.596, val_MAE=0.566, val_loss=0.674]Epoch 50:   5%|▌         | 50/1000 [54:28<16:02:31, 60.79s/it, lr=0.00025, test_MAE=0.602, time=60.6, train_MAE=0.487, train_loss=0.594, val_MAE=0.567, val_loss=0.674]Epoch    51: reducing learning rate of group 0 to 1.2500e-04.
Epoch 50:   5%|▌         | 51/1000 [54:28<16:00:40, 60.74s/it, lr=0.00025, test_MAE=0.602, time=60.6, train_MAE=0.487, train_loss=0.594, val_MAE=0.567, val_loss=0.674]Epoch 51:   5%|▌         | 51/1000 [54:28<16:00:40, 60.74s/it, lr=0.00025, test_MAE=0.602, time=60.6, train_MAE=0.487, train_loss=0.594, val_MAE=0.567, val_loss=0.674]Epoch 51:   5%|▌         | 51/1000 [55:28<16:00:40, 60.74s/it, lr=0.000125, test_MAE=0.603, time=60.3, train_MAE=0.474, train_loss=0.582, val_MAE=0.58, val_loss=0.687]Epoch 51:   5%|▌         | 52/1000 [55:28<15:57:50, 60.62s/it, lr=0.000125, test_MAE=0.603, time=60.3, train_MAE=0.474, train_loss=0.582, val_MAE=0.58, val_loss=0.687]Epoch 52:   5%|▌         | 52/1000 [55:28<15:57:50, 60.62s/it, lr=0.000125, test_MAE=0.603, time=60.3, train_MAE=0.474, train_loss=0.582, val_MAE=0.58, val_loss=0.687]Epoch 52:   5%|▌         | 52/1000 [56:29<15:57:50, 60.62s/it, lr=0.000125, test_MAE=0.6, time=60.9, train_MAE=0.468, train_loss=0.576, val_MAE=0.566, val_loss=0.673] Epoch 52:   5%|▌         | 53/1000 [56:29<15:58:15, 60.71s/it, lr=0.000125, test_MAE=0.6, time=60.9, train_MAE=0.468, train_loss=0.576, val_MAE=0.566, val_loss=0.673]Epoch 53:   5%|▌         | 53/1000 [56:29<15:58:15, 60.71s/it, lr=0.000125, test_MAE=0.6, time=60.9, train_MAE=0.468, train_loss=0.576, val_MAE=0.566, val_loss=0.673]Epoch 53:   5%|▌         | 53/1000 [57:30<15:58:15, 60.71s/it, lr=0.000125, test_MAE=0.59, time=60.7, train_MAE=0.475, train_loss=0.583, val_MAE=0.558, val_loss=0.666]Epoch 53:   5%|▌         | 54/1000 [57:30<15:57:02, 60.70s/it, lr=0.000125, test_MAE=0.59, time=60.7, train_MAE=0.475, train_loss=0.583, val_MAE=0.558, val_loss=0.666]Epoch 54:   5%|▌         | 54/1000 [57:30<15:57:02, 60.70s/it, lr=0.000125, test_MAE=0.59, time=60.7, train_MAE=0.475, train_loss=0.583, val_MAE=0.558, val_loss=0.666]Epoch 54:   5%|▌         | 54/1000 [58:30<15:57:02, 60.70s/it, lr=0.000125, test_MAE=0.595, time=60.3, train_MAE=0.467, train_loss=0.575, val_MAE=0.565, val_loss=0.673]Epoch 54:   6%|▌         | 55/1000 [58:30<15:54:24, 60.60s/it, lr=0.000125, test_MAE=0.595, time=60.3, train_MAE=0.467, train_loss=0.575, val_MAE=0.565, val_loss=0.673]Epoch 55:   6%|▌         | 55/1000 [58:30<15:54:24, 60.60s/it, lr=0.000125, test_MAE=0.595, time=60.3, train_MAE=0.467, train_loss=0.575, val_MAE=0.565, val_loss=0.673]Epoch 55:   6%|▌         | 55/1000 [59:31<15:54:24, 60.60s/it, lr=0.000125, test_MAE=0.602, time=60.9, train_MAE=0.476, train_loss=0.583, val_MAE=0.566, val_loss=0.673]Epoch 55:   6%|▌         | 56/1000 [59:31<15:54:54, 60.69s/it, lr=0.000125, test_MAE=0.602, time=60.9, train_MAE=0.476, train_loss=0.583, val_MAE=0.566, val_loss=0.673]Epoch 56:   6%|▌         | 56/1000 [59:31<15:54:54, 60.69s/it, lr=0.000125, test_MAE=0.602, time=60.9, train_MAE=0.476, train_loss=0.583, val_MAE=0.566, val_loss=0.673]Epoch 56:   6%|▌         | 56/1000 [1:00:32<15:54:54, 60.69s/it, lr=0.000125, test_MAE=0.588, time=60.6, train_MAE=0.466, train_loss=0.573, val_MAE=0.557, val_loss=0.664]Epoch 56:   6%|▌         | 57/1000 [1:00:32<15:53:41, 60.68s/it, lr=0.000125, test_MAE=0.588, time=60.6, train_MAE=0.466, train_loss=0.573, val_MAE=0.557, val_loss=0.664]Epoch 57:   6%|▌         | 57/1000 [1:00:32<15:53:41, 60.68s/it, lr=0.000125, test_MAE=0.588, time=60.6, train_MAE=0.466, train_loss=0.573, val_MAE=0.557, val_loss=0.664]Epoch 57:   6%|▌         | 57/1000 [1:01:32<15:53:41, 60.68s/it, lr=0.000125, test_MAE=0.596, time=60.4, train_MAE=0.469, train_loss=0.577, val_MAE=0.565, val_loss=0.672]Epoch 57:   6%|▌         | 58/1000 [1:01:32<15:51:21, 60.60s/it, lr=0.000125, test_MAE=0.596, time=60.4, train_MAE=0.469, train_loss=0.577, val_MAE=0.565, val_loss=0.672]Epoch 58:   6%|▌         | 58/1000 [1:01:32<15:51:21, 60.60s/it, lr=0.000125, test_MAE=0.596, time=60.4, train_MAE=0.469, train_loss=0.577, val_MAE=0.565, val_loss=0.672]Epoch 58:   6%|▌         | 58/1000 [1:02:33<15:51:21, 60.60s/it, lr=0.000125, test_MAE=0.6, time=60.9, train_MAE=0.467, train_loss=0.575, val_MAE=0.567, val_loss=0.674]  Epoch 58:   6%|▌         | 59/1000 [1:02:33<15:51:46, 60.69s/it, lr=0.000125, test_MAE=0.6, time=60.9, train_MAE=0.467, train_loss=0.575, val_MAE=0.567, val_loss=0.674]Epoch 59:   6%|▌         | 59/1000 [1:02:33<15:51:46, 60.69s/it, lr=0.000125, test_MAE=0.6, time=60.9, train_MAE=0.467, train_loss=0.575, val_MAE=0.567, val_loss=0.674]Epoch 59:   6%|▌         | 59/1000 [1:03:33<15:51:46, 60.69s/it, lr=0.000125, test_MAE=0.588, time=60.6, train_MAE=0.464, train_loss=0.571, val_MAE=0.554, val_loss=0.662]Epoch 59:   6%|▌         | 60/1000 [1:03:33<15:50:30, 60.67s/it, lr=0.000125, test_MAE=0.588, time=60.6, train_MAE=0.464, train_loss=0.571, val_MAE=0.554, val_loss=0.662]Epoch 60:   6%|▌         | 60/1000 [1:03:33<15:50:30, 60.67s/it, lr=0.000125, test_MAE=0.588, time=60.6, train_MAE=0.464, train_loss=0.571, val_MAE=0.554, val_loss=0.662]Epoch 60:   6%|▌         | 60/1000 [1:04:34<15:50:30, 60.67s/it, lr=0.000125, test_MAE=0.614, time=60.7, train_MAE=0.472, train_loss=0.579, val_MAE=0.593, val_loss=0.7]  Epoch 60:   6%|▌         | 61/1000 [1:04:34<15:49:28, 60.67s/it, lr=0.000125, test_MAE=0.614, time=60.7, train_MAE=0.472, train_loss=0.579, val_MAE=0.593, val_loss=0.7]Epoch 61:   6%|▌         | 61/1000 [1:04:34<15:49:28, 60.67s/it, lr=0.000125, test_MAE=0.614, time=60.7, train_MAE=0.472, train_loss=0.579, val_MAE=0.593, val_loss=0.7]Epoch 61:   6%|▌         | 61/1000 [1:05:35<15:49:28, 60.67s/it, lr=0.000125, test_MAE=0.602, time=60.9, train_MAE=0.461, train_loss=0.568, val_MAE=0.564, val_loss=0.671]Epoch 61:   6%|▌         | 62/1000 [1:05:35<15:49:45, 60.75s/it, lr=0.000125, test_MAE=0.602, time=60.9, train_MAE=0.461, train_loss=0.568, val_MAE=0.564, val_loss=0.671]Epoch 62:   6%|▌         | 62/1000 [1:05:35<15:49:45, 60.75s/it, lr=0.000125, test_MAE=0.602, time=60.9, train_MAE=0.461, train_loss=0.568, val_MAE=0.564, val_loss=0.671]Epoch 62:   6%|▌         | 62/1000 [1:06:35<15:49:45, 60.75s/it, lr=0.000125, test_MAE=0.625, time=60.3, train_MAE=0.463, train_loss=0.57, val_MAE=0.585, val_loss=0.692] Epoch 62:   6%|▋         | 63/1000 [1:06:35<15:46:45, 60.63s/it, lr=0.000125, test_MAE=0.625, time=60.3, train_MAE=0.463, train_loss=0.57, val_MAE=0.585, val_loss=0.692]Epoch 63:   6%|▋         | 63/1000 [1:06:35<15:46:45, 60.63s/it, lr=0.000125, test_MAE=0.625, time=60.3, train_MAE=0.463, train_loss=0.57, val_MAE=0.585, val_loss=0.692]Epoch 63:   6%|▋         | 63/1000 [1:07:36<15:46:45, 60.63s/it, lr=0.000125, test_MAE=0.588, time=60.9, train_MAE=0.462, train_loss=0.569, val_MAE=0.559, val_loss=0.666]Epoch 63:   6%|▋         | 64/1000 [1:07:36<15:47:14, 60.72s/it, lr=0.000125, test_MAE=0.588, time=60.9, train_MAE=0.462, train_loss=0.569, val_MAE=0.559, val_loss=0.666]Epoch 64:   6%|▋         | 64/1000 [1:07:36<15:47:14, 60.72s/it, lr=0.000125, test_MAE=0.588, time=60.9, train_MAE=0.462, train_loss=0.569, val_MAE=0.559, val_loss=0.666]Epoch 64:   6%|▋         | 64/1000 [1:08:37<15:47:14, 60.72s/it, lr=0.000125, test_MAE=0.593, time=60.6, train_MAE=0.46, train_loss=0.567, val_MAE=0.565, val_loss=0.672] Epoch 64:   6%|▋         | 65/1000 [1:08:37<15:45:54, 60.70s/it, lr=0.000125, test_MAE=0.593, time=60.6, train_MAE=0.46, train_loss=0.567, val_MAE=0.565, val_loss=0.672]Epoch 65:   6%|▋         | 65/1000 [1:08:37<15:45:54, 60.70s/it, lr=0.000125, test_MAE=0.593, time=60.6, train_MAE=0.46, train_loss=0.567, val_MAE=0.565, val_loss=0.672]Epoch 65:   6%|▋         | 65/1000 [1:09:38<15:45:54, 60.70s/it, lr=0.000125, test_MAE=0.588, time=60.6, train_MAE=0.458, train_loss=0.565, val_MAE=0.561, val_loss=0.668]Epoch    66: reducing learning rate of group 0 to 6.2500e-05.
Epoch 65:   7%|▋         | 66/1000 [1:09:38<15:44:36, 60.68s/it, lr=0.000125, test_MAE=0.588, time=60.6, train_MAE=0.458, train_loss=0.565, val_MAE=0.561, val_loss=0.668]Epoch 66:   7%|▋         | 66/1000 [1:09:38<15:44:36, 60.68s/it, lr=0.000125, test_MAE=0.588, time=60.6, train_MAE=0.458, train_loss=0.565, val_MAE=0.561, val_loss=0.668]Epoch 66:   7%|▋         | 66/1000 [1:10:39<15:44:36, 60.68s/it, lr=6.25e-5, test_MAE=0.606, time=60.9, train_MAE=0.451, train_loss=0.558, val_MAE=0.567, val_loss=0.674] Epoch 66:   7%|▋         | 67/1000 [1:10:39<15:44:50, 60.76s/it, lr=6.25e-5, test_MAE=0.606, time=60.9, train_MAE=0.451, train_loss=0.558, val_MAE=0.567, val_loss=0.674]Epoch 67:   7%|▋         | 67/1000 [1:10:39<15:44:50, 60.76s/it, lr=6.25e-5, test_MAE=0.606, time=60.9, train_MAE=0.451, train_loss=0.558, val_MAE=0.567, val_loss=0.674]Epoch 67:   7%|▋         | 67/1000 [1:11:39<15:44:50, 60.76s/it, lr=6.25e-5, test_MAE=0.59, time=60.6, train_MAE=0.456, train_loss=0.563, val_MAE=0.559, val_loss=0.666] Epoch 67:   7%|▋         | 68/1000 [1:11:39<15:43:19, 60.73s/it, lr=6.25e-5, test_MAE=0.59, time=60.6, train_MAE=0.456, train_loss=0.563, val_MAE=0.559, val_loss=0.666]Epoch 68:   7%|▋         | 68/1000 [1:11:39<15:43:19, 60.73s/it, lr=6.25e-5, test_MAE=0.59, time=60.6, train_MAE=0.456, train_loss=0.563, val_MAE=0.559, val_loss=0.666]Epoch 68:   7%|▋         | 68/1000 [1:12:40<15:43:19, 60.73s/it, lr=6.25e-5, test_MAE=0.592, time=60.4, train_MAE=0.45, train_loss=0.557, val_MAE=0.562, val_loss=0.668]Epoch 68:   7%|▋         | 69/1000 [1:12:40<15:40:41, 60.62s/it, lr=6.25e-5, test_MAE=0.592, time=60.4, train_MAE=0.45, train_loss=0.557, val_MAE=0.562, val_loss=0.668]Epoch 69:   7%|▋         | 69/1000 [1:12:40<15:40:41, 60.62s/it, lr=6.25e-5, test_MAE=0.592, time=60.4, train_MAE=0.45, train_loss=0.557, val_MAE=0.562, val_loss=0.668]Epoch 69:   7%|▋         | 69/1000 [1:13:41<15:40:41, 60.62s/it, lr=6.25e-5, test_MAE=0.596, time=61.2, train_MAE=0.452, train_loss=0.559, val_MAE=0.563, val_loss=0.67]Epoch 69:   7%|▋         | 70/1000 [1:13:41<15:42:34, 60.81s/it, lr=6.25e-5, test_MAE=0.596, time=61.2, train_MAE=0.452, train_loss=0.559, val_MAE=0.563, val_loss=0.67]Epoch 70:   7%|▋         | 70/1000 [1:13:41<15:42:34, 60.81s/it, lr=6.25e-5, test_MAE=0.596, time=61.2, train_MAE=0.452, train_loss=0.559, val_MAE=0.563, val_loss=0.67]Epoch 70:   7%|▋         | 70/1000 [1:14:41<15:42:34, 60.81s/it, lr=6.25e-5, test_MAE=0.604, time=60.6, train_MAE=0.455, train_loss=0.562, val_MAE=0.569, val_loss=0.676]Epoch 70:   7%|▋         | 71/1000 [1:14:41<15:40:32, 60.75s/it, lr=6.25e-5, test_MAE=0.604, time=60.6, train_MAE=0.455, train_loss=0.562, val_MAE=0.569, val_loss=0.676]Epoch 71:   7%|▋         | 71/1000 [1:14:41<15:40:32, 60.75s/it, lr=6.25e-5, test_MAE=0.604, time=60.6, train_MAE=0.455, train_loss=0.562, val_MAE=0.569, val_loss=0.676]Epoch 71:   7%|▋         | 71/1000 [1:15:41<15:40:32, 60.75s/it, lr=6.25e-5, test_MAE=0.589, time=59.9, train_MAE=0.451, train_loss=0.558, val_MAE=0.56, val_loss=0.667] Epoch    72: reducing learning rate of group 0 to 3.1250e-05.
Epoch 71:   7%|▋         | 72/1000 [1:15:41<15:35:52, 60.51s/it, lr=6.25e-5, test_MAE=0.589, time=59.9, train_MAE=0.451, train_loss=0.558, val_MAE=0.56, val_loss=0.667]Epoch 72:   7%|▋         | 72/1000 [1:15:41<15:35:52, 60.51s/it, lr=6.25e-5, test_MAE=0.589, time=59.9, train_MAE=0.451, train_loss=0.558, val_MAE=0.56, val_loss=0.667]Epoch 72:   7%|▋         | 72/1000 [1:16:42<15:35:52, 60.51s/it, lr=3.13e-5, test_MAE=0.589, time=60.4, train_MAE=0.451, train_loss=0.558, val_MAE=0.562, val_loss=0.668]Epoch 72:   7%|▋         | 73/1000 [1:16:42<15:34:26, 60.48s/it, lr=3.13e-5, test_MAE=0.589, time=60.4, train_MAE=0.451, train_loss=0.558, val_MAE=0.562, val_loss=0.668]Epoch 73:   7%|▋         | 73/1000 [1:16:42<15:34:26, 60.48s/it, lr=3.13e-5, test_MAE=0.589, time=60.4, train_MAE=0.451, train_loss=0.558, val_MAE=0.562, val_loss=0.668]Epoch 73:   7%|▋         | 73/1000 [1:17:42<15:34:26, 60.48s/it, lr=3.13e-5, test_MAE=0.588, time=60.1, train_MAE=0.445, train_loss=0.552, val_MAE=0.558, val_loss=0.664]Epoch 73:   7%|▋         | 74/1000 [1:17:42<15:31:53, 60.38s/it, lr=3.13e-5, test_MAE=0.588, time=60.1, train_MAE=0.445, train_loss=0.552, val_MAE=0.558, val_loss=0.664]Epoch 74:   7%|▋         | 74/1000 [1:17:42<15:31:53, 60.38s/it, lr=3.13e-5, test_MAE=0.588, time=60.1, train_MAE=0.445, train_loss=0.552, val_MAE=0.558, val_loss=0.664]Epoch 74:   7%|▋         | 74/1000 [1:18:42<15:31:53, 60.38s/it, lr=3.13e-5, test_MAE=0.588, time=59.9, train_MAE=0.445, train_loss=0.552, val_MAE=0.559, val_loss=0.666]Epoch 74:   8%|▊         | 75/1000 [1:18:42<15:28:31, 60.23s/it, lr=3.13e-5, test_MAE=0.588, time=59.9, train_MAE=0.445, train_loss=0.552, val_MAE=0.559, val_loss=0.666]Epoch 75:   8%|▊         | 75/1000 [1:18:42<15:28:31, 60.23s/it, lr=3.13e-5, test_MAE=0.588, time=59.9, train_MAE=0.445, train_loss=0.552, val_MAE=0.559, val_loss=0.666]Epoch 75:   8%|▊         | 75/1000 [1:19:42<15:28:31, 60.23s/it, lr=3.13e-5, test_MAE=0.591, time=60.4, train_MAE=0.448, train_loss=0.554, val_MAE=0.559, val_loss=0.666]Epoch 75:   8%|▊         | 76/1000 [1:19:42<15:28:25, 60.29s/it, lr=3.13e-5, test_MAE=0.591, time=60.4, train_MAE=0.448, train_loss=0.554, val_MAE=0.559, val_loss=0.666]Epoch 76:   8%|▊         | 76/1000 [1:19:42<15:28:25, 60.29s/it, lr=3.13e-5, test_MAE=0.591, time=60.4, train_MAE=0.448, train_loss=0.554, val_MAE=0.559, val_loss=0.666]Epoch 76:   8%|▊         | 76/1000 [1:20:42<15:28:25, 60.29s/it, lr=3.13e-5, test_MAE=0.588, time=60.2, train_MAE=0.445, train_loss=0.552, val_MAE=0.558, val_loss=0.665]Epoch 76:   8%|▊         | 77/1000 [1:20:42<15:26:53, 60.25s/it, lr=3.13e-5, test_MAE=0.588, time=60.2, train_MAE=0.445, train_loss=0.552, val_MAE=0.558, val_loss=0.665]Epoch 77:   8%|▊         | 77/1000 [1:20:42<15:26:53, 60.25s/it, lr=3.13e-5, test_MAE=0.588, time=60.2, train_MAE=0.445, train_loss=0.552, val_MAE=0.558, val_loss=0.665]Epoch 77:   8%|▊         | 77/1000 [1:21:42<15:26:53, 60.25s/it, lr=3.13e-5, test_MAE=0.588, time=59.9, train_MAE=0.443, train_loss=0.549, val_MAE=0.559, val_loss=0.666]Epoch    78: reducing learning rate of group 0 to 1.5625e-05.
Epoch 77:   8%|▊         | 78/1000 [1:21:42<15:24:25, 60.16s/it, lr=3.13e-5, test_MAE=0.588, time=59.9, train_MAE=0.443, train_loss=0.549, val_MAE=0.559, val_loss=0.666]Epoch 78:   8%|▊         | 78/1000 [1:21:42<15:24:25, 60.16s/it, lr=3.13e-5, test_MAE=0.588, time=59.9, train_MAE=0.443, train_loss=0.549, val_MAE=0.559, val_loss=0.666]Epoch 78:   8%|▊         | 78/1000 [1:22:43<15:24:25, 60.16s/it, lr=1.56e-5, test_MAE=0.588, time=60.4, train_MAE=0.444, train_loss=0.551, val_MAE=0.559, val_loss=0.666]Epoch 78:   8%|▊         | 79/1000 [1:22:43<15:24:36, 60.24s/it, lr=1.56e-5, test_MAE=0.588, time=60.4, train_MAE=0.444, train_loss=0.551, val_MAE=0.559, val_loss=0.666]Epoch 79:   8%|▊         | 79/1000 [1:22:43<15:24:36, 60.24s/it, lr=1.56e-5, test_MAE=0.588, time=60.4, train_MAE=0.444, train_loss=0.551, val_MAE=0.559, val_loss=0.666]Epoch 79:   8%|▊         | 79/1000 [1:23:43<15:24:36, 60.24s/it, lr=1.56e-5, test_MAE=0.596, time=60.3, train_MAE=0.447, train_loss=0.554, val_MAE=0.564, val_loss=0.671]Epoch 79:   8%|▊         | 80/1000 [1:23:43<15:23:50, 60.25s/it, lr=1.56e-5, test_MAE=0.596, time=60.3, train_MAE=0.447, train_loss=0.554, val_MAE=0.564, val_loss=0.671]Epoch 80:   8%|▊         | 80/1000 [1:23:43<15:23:50, 60.25s/it, lr=1.56e-5, test_MAE=0.596, time=60.3, train_MAE=0.447, train_loss=0.554, val_MAE=0.564, val_loss=0.671]Epoch 80:   8%|▊         | 80/1000 [1:24:43<15:23:50, 60.25s/it, lr=1.56e-5, test_MAE=0.593, time=60.2, train_MAE=0.445, train_loss=0.552, val_MAE=0.56, val_loss=0.667] Epoch 80:   8%|▊         | 81/1000 [1:24:43<15:22:52, 60.25s/it, lr=1.56e-5, test_MAE=0.593, time=60.2, train_MAE=0.445, train_loss=0.552, val_MAE=0.56, val_loss=0.667]Epoch 81:   8%|▊         | 81/1000 [1:24:43<15:22:52, 60.25s/it, lr=1.56e-5, test_MAE=0.593, time=60.2, train_MAE=0.445, train_loss=0.552, val_MAE=0.56, val_loss=0.667]Epoch 81:   8%|▊         | 81/1000 [1:25:44<15:22:52, 60.25s/it, lr=1.56e-5, test_MAE=0.593, time=60.6, train_MAE=0.442, train_loss=0.549, val_MAE=0.561, val_loss=0.668]Epoch 81:   8%|▊         | 82/1000 [1:25:44<15:23:42, 60.37s/it, lr=1.56e-5, test_MAE=0.593, time=60.6, train_MAE=0.442, train_loss=0.549, val_MAE=0.561, val_loss=0.668]Epoch 82:   8%|▊         | 82/1000 [1:25:44<15:23:42, 60.37s/it, lr=1.56e-5, test_MAE=0.593, time=60.6, train_MAE=0.442, train_loss=0.549, val_MAE=0.561, val_loss=0.668]Epoch 82:   8%|▊         | 82/1000 [1:26:44<15:23:42, 60.37s/it, lr=1.56e-5, test_MAE=0.593, time=60, train_MAE=0.45, train_loss=0.557, val_MAE=0.562, val_loss=0.668]   Epoch 82:   8%|▊         | 83/1000 [1:26:44<15:21:06, 60.27s/it, lr=1.56e-5, test_MAE=0.593, time=60, train_MAE=0.45, train_loss=0.557, val_MAE=0.562, val_loss=0.668]Epoch 83:   8%|▊         | 83/1000 [1:26:44<15:21:06, 60.27s/it, lr=1.56e-5, test_MAE=0.593, time=60, train_MAE=0.45, train_loss=0.557, val_MAE=0.562, val_loss=0.668]Epoch 83:   8%|▊         | 83/1000 [1:27:45<15:21:06, 60.27s/it, lr=1.56e-5, test_MAE=0.59, time=60.6, train_MAE=0.444, train_loss=0.551, val_MAE=0.561, val_loss=0.667]Epoch    84: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 83:   8%|▊         | 83/1000 [1:27:45<16:09:30, 63.44s/it, lr=1.56e-5, test_MAE=0.59, time=60.6, train_MAE=0.444, train_loss=0.551, val_MAE=0.561, val_loss=0.667]
Test MAE: 0.5902
Train MAE: 0.4258
Convergence Time (Epochs): 83.0000
TOTAL TIME TAKEN: 5302.7176s
AVG TIME PER EPOCH: 62.6604s
