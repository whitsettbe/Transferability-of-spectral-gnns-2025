I'm echoing to stdout
I'm echoing to stderr
My JobID is 57722153
I have 8 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.0554s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 2, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'cheb02_vec', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_all', 'num_eigs': 16, 'bias_mode': 'spatial', 'eigval_hidden_dim': 5, 'eigval_num_hidden_layer': 3, 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 0.0, 'eigmod': 'rand_basis', 'eigInFiles': {'train': 'supp_data/molecules/aug07/zinc_train_rec.csv', 'test': 'supp_data/molecules/aug07/zinc_test_rec.csv', 'val': 'supp_data/molecules/aug07/zinc_val_rec.csv'}, 'fixMissingPhi1': False, 'extraOrtho': True, 'doublePrecision': True, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [01:50<?, ?it/s, lr=0.001, test_MAE=0.776, time=111, train_MAE=0.906, train_loss=0.906, val_MAE=0.715, val_loss=0.715]Epoch 0:   0%|          | 1/1000 [01:50<30:44:17, 110.77s/it, lr=0.001, test_MAE=0.776, time=111, train_MAE=0.906, train_loss=0.906, val_MAE=0.715, val_loss=0.715]Epoch 1:   0%|          | 1/1000 [01:50<30:44:17, 110.77s/it, lr=0.001, test_MAE=0.776, time=111, train_MAE=0.906, train_loss=0.906, val_MAE=0.715, val_loss=0.715]Epoch 1:   0%|          | 1/1000 [02:51<30:44:17, 110.77s/it, lr=0.001, test_MAE=0.749, time=60.7, train_MAE=0.704, train_loss=0.704, val_MAE=0.672, val_loss=0.672]Epoch 1:   0%|          | 2/1000 [02:51<26:32:37, 95.75s/it, lr=0.001, test_MAE=0.749, time=60.7, train_MAE=0.704, train_loss=0.704, val_MAE=0.672, val_loss=0.672] Epoch 2:   0%|          | 2/1000 [02:51<26:32:37, 95.75s/it, lr=0.001, test_MAE=0.749, time=60.7, train_MAE=0.704, train_loss=0.704, val_MAE=0.672, val_loss=0.672]Epoch 2:   0%|          | 2/1000 [03:52<26:32:37, 95.75s/it, lr=0.001, test_MAE=0.871, time=60.6, train_MAE=0.674, train_loss=0.674, val_MAE=0.802, val_loss=0.802]Epoch 2:   0%|          | 3/1000 [03:52<23:35:48, 85.20s/it, lr=0.001, test_MAE=0.871, time=60.6, train_MAE=0.674, train_loss=0.674, val_MAE=0.802, val_loss=0.802]Epoch 3:   0%|          | 3/1000 [03:52<23:35:48, 85.20s/it, lr=0.001, test_MAE=0.871, time=60.6, train_MAE=0.674, train_loss=0.674, val_MAE=0.802, val_loss=0.802]Epoch 3:   0%|          | 3/1000 [04:53<23:35:48, 85.20s/it, lr=0.001, test_MAE=0.701, time=61, train_MAE=0.661, train_loss=0.661, val_MAE=0.633, val_loss=0.633]  Epoch 3:   0%|          | 4/1000 [04:53<21:33:55, 77.95s/it, lr=0.001, test_MAE=0.701, time=61, train_MAE=0.661, train_loss=0.661, val_MAE=0.633, val_loss=0.633]Epoch 4:   0%|          | 4/1000 [04:53<21:33:55, 77.95s/it, lr=0.001, test_MAE=0.701, time=61, train_MAE=0.661, train_loss=0.661, val_MAE=0.633, val_loss=0.633]Epoch 4:   0%|          | 4/1000 [05:53<21:33:55, 77.95s/it, lr=0.001, test_MAE=0.671, time=60.5, train_MAE=0.652, train_loss=0.652, val_MAE=0.625, val_loss=0.625]Epoch 4:   0%|          | 5/1000 [05:53<20:05:40, 72.70s/it, lr=0.001, test_MAE=0.671, time=60.5, train_MAE=0.652, train_loss=0.652, val_MAE=0.625, val_loss=0.625]Epoch 5:   0%|          | 5/1000 [05:53<20:05:40, 72.70s/it, lr=0.001, test_MAE=0.671, time=60.5, train_MAE=0.652, train_loss=0.652, val_MAE=0.625, val_loss=0.625]Epoch 5:   0%|          | 5/1000 [06:54<20:05:40, 72.70s/it, lr=0.001, test_MAE=0.686, time=61, train_MAE=0.641, train_loss=0.641, val_MAE=0.619, val_loss=0.619]  Epoch 5:   1%|          | 6/1000 [06:54<19:06:30, 69.21s/it, lr=0.001, test_MAE=0.686, time=61, train_MAE=0.641, train_loss=0.641, val_MAE=0.619, val_loss=0.619]Epoch 6:   1%|          | 6/1000 [06:54<19:06:30, 69.21s/it, lr=0.001, test_MAE=0.686, time=61, train_MAE=0.641, train_loss=0.641, val_MAE=0.619, val_loss=0.619]Epoch 6:   1%|          | 6/1000 [07:55<19:06:30, 69.21s/it, lr=0.001, test_MAE=0.66, time=60.7, train_MAE=0.651, train_loss=0.651, val_MAE=0.602, val_loss=0.602]Epoch 6:   1%|          | 7/1000 [07:55<18:23:16, 66.66s/it, lr=0.001, test_MAE=0.66, time=60.7, train_MAE=0.651, train_loss=0.651, val_MAE=0.602, val_loss=0.602]Epoch 7:   1%|          | 7/1000 [07:55<18:23:16, 66.66s/it, lr=0.001, test_MAE=0.66, time=60.7, train_MAE=0.651, train_loss=0.651, val_MAE=0.602, val_loss=0.602]Epoch 7:   1%|          | 7/1000 [08:55<18:23:16, 66.66s/it, lr=0.001, test_MAE=0.706, time=60.6, train_MAE=0.623, train_loss=0.623, val_MAE=0.665, val_loss=0.665]Epoch 7:   1%|          | 8/1000 [08:55<17:52:16, 64.86s/it, lr=0.001, test_MAE=0.706, time=60.6, train_MAE=0.623, train_loss=0.623, val_MAE=0.665, val_loss=0.665]Epoch 8:   1%|          | 8/1000 [08:55<17:52:16, 64.86s/it, lr=0.001, test_MAE=0.706, time=60.6, train_MAE=0.623, train_loss=0.623, val_MAE=0.665, val_loss=0.665]Epoch 8:   1%|          | 8/1000 [09:56<17:52:16, 64.86s/it, lr=0.001, test_MAE=0.698, time=60.9, train_MAE=0.607, train_loss=0.607, val_MAE=0.648, val_loss=0.648]Epoch 8:   1%|          | 9/1000 [09:56<17:31:32, 63.67s/it, lr=0.001, test_MAE=0.698, time=60.9, train_MAE=0.607, train_loss=0.607, val_MAE=0.648, val_loss=0.648]Epoch 9:   1%|          | 9/1000 [09:56<17:31:32, 63.67s/it, lr=0.001, test_MAE=0.698, time=60.9, train_MAE=0.607, train_loss=0.607, val_MAE=0.648, val_loss=0.648]Epoch 9:   1%|          | 9/1000 [10:57<17:31:32, 63.67s/it, lr=0.001, test_MAE=0.71, time=60.5, train_MAE=0.606, train_loss=0.606, val_MAE=0.67, val_loss=0.67]   Epoch 9:   1%|          | 10/1000 [10:57<17:15:07, 62.73s/it, lr=0.001, test_MAE=0.71, time=60.5, train_MAE=0.606, train_loss=0.606, val_MAE=0.67, val_loss=0.67]Epoch 10:   1%|          | 10/1000 [10:57<17:15:07, 62.73s/it, lr=0.001, test_MAE=0.71, time=60.5, train_MAE=0.606, train_loss=0.606, val_MAE=0.67, val_loss=0.67]Epoch 10:   1%|          | 10/1000 [11:57<17:15:07, 62.73s/it, lr=0.001, test_MAE=0.663, time=60.2, train_MAE=0.605, train_loss=0.605, val_MAE=0.619, val_loss=0.619]Epoch 10:   1%|          | 11/1000 [11:57<17:01:35, 61.98s/it, lr=0.001, test_MAE=0.663, time=60.2, train_MAE=0.605, train_loss=0.605, val_MAE=0.619, val_loss=0.619]Epoch 11:   1%|          | 11/1000 [11:57<17:01:35, 61.98s/it, lr=0.001, test_MAE=0.663, time=60.2, train_MAE=0.605, train_loss=0.605, val_MAE=0.619, val_loss=0.619]Epoch 11:   1%|          | 11/1000 [12:58<17:01:35, 61.98s/it, lr=0.001, test_MAE=0.644, time=61.2, train_MAE=0.607, train_loss=0.607, val_MAE=0.592, val_loss=0.592]Epoch 11:   1%|          | 12/1000 [12:58<16:56:39, 61.74s/it, lr=0.001, test_MAE=0.644, time=61.2, train_MAE=0.607, train_loss=0.607, val_MAE=0.592, val_loss=0.592]Epoch 12:   1%|          | 12/1000 [12:58<16:56:39, 61.74s/it, lr=0.001, test_MAE=0.644, time=61.2, train_MAE=0.607, train_loss=0.607, val_MAE=0.592, val_loss=0.592]Epoch 12:   1%|          | 12/1000 [13:59<16:56:39, 61.74s/it, lr=0.001, test_MAE=0.636, time=60.6, train_MAE=0.614, train_loss=0.614, val_MAE=0.586, val_loss=0.586]Epoch 12:   1%|▏         | 13/1000 [13:59<16:50:01, 61.40s/it, lr=0.001, test_MAE=0.636, time=60.6, train_MAE=0.614, train_loss=0.614, val_MAE=0.586, val_loss=0.586]Epoch 13:   1%|▏         | 13/1000 [13:59<16:50:01, 61.40s/it, lr=0.001, test_MAE=0.636, time=60.6, train_MAE=0.614, train_loss=0.614, val_MAE=0.586, val_loss=0.586]Epoch 13:   1%|▏         | 13/1000 [14:59<16:50:01, 61.40s/it, lr=0.001, test_MAE=0.72, time=60.2, train_MAE=0.605, train_loss=0.605, val_MAE=0.683, val_loss=0.683] Epoch 13:   1%|▏         | 14/1000 [14:59<16:43:01, 61.04s/it, lr=0.001, test_MAE=0.72, time=60.2, train_MAE=0.605, train_loss=0.605, val_MAE=0.683, val_loss=0.683]Epoch 14:   1%|▏         | 14/1000 [14:59<16:43:01, 61.04s/it, lr=0.001, test_MAE=0.72, time=60.2, train_MAE=0.605, train_loss=0.605, val_MAE=0.683, val_loss=0.683]Epoch 14:   1%|▏         | 14/1000 [16:00<16:43:01, 61.04s/it, lr=0.001, test_MAE=0.653, time=60.8, train_MAE=0.589, train_loss=0.589, val_MAE=0.591, val_loss=0.591]Epoch 14:   2%|▏         | 15/1000 [16:00<16:40:57, 60.97s/it, lr=0.001, test_MAE=0.653, time=60.8, train_MAE=0.589, train_loss=0.589, val_MAE=0.591, val_loss=0.591]Epoch 15:   2%|▏         | 15/1000 [16:00<16:40:57, 60.97s/it, lr=0.001, test_MAE=0.653, time=60.8, train_MAE=0.589, train_loss=0.589, val_MAE=0.591, val_loss=0.591]Epoch 15:   2%|▏         | 15/1000 [17:00<16:40:57, 60.97s/it, lr=0.001, test_MAE=0.638, time=60.5, train_MAE=0.6, train_loss=0.6, val_MAE=0.582, val_loss=0.582]    Epoch 15:   2%|▏         | 16/1000 [17:00<16:37:42, 60.84s/it, lr=0.001, test_MAE=0.638, time=60.5, train_MAE=0.6, train_loss=0.6, val_MAE=0.582, val_loss=0.582]Epoch 16:   2%|▏         | 16/1000 [17:00<16:37:42, 60.84s/it, lr=0.001, test_MAE=0.638, time=60.5, train_MAE=0.6, train_loss=0.6, val_MAE=0.582, val_loss=0.582]Epoch 16:   2%|▏         | 16/1000 [18:01<16:37:42, 60.84s/it, lr=0.001, test_MAE=0.654, time=60.2, train_MAE=0.596, train_loss=0.596, val_MAE=0.61, val_loss=0.61]Epoch 16:   2%|▏         | 17/1000 [18:01<16:33:25, 60.64s/it, lr=0.001, test_MAE=0.654, time=60.2, train_MAE=0.596, train_loss=0.596, val_MAE=0.61, val_loss=0.61]Epoch 17:   2%|▏         | 17/1000 [18:01<16:33:25, 60.64s/it, lr=0.001, test_MAE=0.654, time=60.2, train_MAE=0.596, train_loss=0.596, val_MAE=0.61, val_loss=0.61]Epoch 17:   2%|▏         | 17/1000 [19:01<16:33:25, 60.64s/it, lr=0.001, test_MAE=0.647, time=60.8, train_MAE=0.587, train_loss=0.587, val_MAE=0.596, val_loss=0.596]Epoch 17:   2%|▏         | 18/1000 [19:01<16:33:17, 60.69s/it, lr=0.001, test_MAE=0.647, time=60.8, train_MAE=0.587, train_loss=0.587, val_MAE=0.596, val_loss=0.596]Epoch 18:   2%|▏         | 18/1000 [19:01<16:33:17, 60.69s/it, lr=0.001, test_MAE=0.647, time=60.8, train_MAE=0.587, train_loss=0.587, val_MAE=0.596, val_loss=0.596]Epoch 18:   2%|▏         | 18/1000 [20:02<16:33:17, 60.69s/it, lr=0.001, test_MAE=0.747, time=60.6, train_MAE=0.589, train_loss=0.589, val_MAE=0.697, val_loss=0.697]Epoch 18:   2%|▏         | 19/1000 [20:02<16:31:55, 60.67s/it, lr=0.001, test_MAE=0.747, time=60.6, train_MAE=0.589, train_loss=0.589, val_MAE=0.697, val_loss=0.697]Epoch 19:   2%|▏         | 19/1000 [20:02<16:31:55, 60.67s/it, lr=0.001, test_MAE=0.747, time=60.6, train_MAE=0.589, train_loss=0.589, val_MAE=0.697, val_loss=0.697]Epoch 19:   2%|▏         | 19/1000 [21:02<16:31:55, 60.67s/it, lr=0.001, test_MAE=0.638, time=60.2, train_MAE=0.574, train_loss=0.574, val_MAE=0.6, val_loss=0.6]    Epoch 19:   2%|▏         | 20/1000 [21:02<16:28:46, 60.54s/it, lr=0.001, test_MAE=0.638, time=60.2, train_MAE=0.574, train_loss=0.574, val_MAE=0.6, val_loss=0.6]Epoch 20:   2%|▏         | 20/1000 [21:02<16:28:46, 60.54s/it, lr=0.001, test_MAE=0.638, time=60.2, train_MAE=0.574, train_loss=0.574, val_MAE=0.6, val_loss=0.6]Epoch 20:   2%|▏         | 20/1000 [22:03<16:28:46, 60.54s/it, lr=0.001, test_MAE=0.644, time=60.8, train_MAE=0.573, train_loss=0.573, val_MAE=0.591, val_loss=0.591]Epoch 20:   2%|▏         | 21/1000 [22:03<16:29:20, 60.63s/it, lr=0.001, test_MAE=0.644, time=60.8, train_MAE=0.573, train_loss=0.573, val_MAE=0.591, val_loss=0.591]Epoch 21:   2%|▏         | 21/1000 [22:03<16:29:20, 60.63s/it, lr=0.001, test_MAE=0.644, time=60.8, train_MAE=0.573, train_loss=0.573, val_MAE=0.591, val_loss=0.591]Epoch 21:   2%|▏         | 21/1000 [23:04<16:29:20, 60.63s/it, lr=0.001, test_MAE=0.683, time=60.6, train_MAE=0.565, train_loss=0.565, val_MAE=0.631, val_loss=0.631]Epoch    22: reducing learning rate of group 0 to 5.0000e-04.
Epoch 21:   2%|▏         | 22/1000 [23:04<16:28:05, 60.62s/it, lr=0.001, test_MAE=0.683, time=60.6, train_MAE=0.565, train_loss=0.565, val_MAE=0.631, val_loss=0.631]Epoch 22:   2%|▏         | 22/1000 [23:04<16:28:05, 60.62s/it, lr=0.001, test_MAE=0.683, time=60.6, train_MAE=0.565, train_loss=0.565, val_MAE=0.631, val_loss=0.631]Epoch 22:   2%|▏         | 22/1000 [24:05<16:28:05, 60.62s/it, lr=0.0005, test_MAE=0.614, time=60.9, train_MAE=0.555, train_loss=0.555, val_MAE=0.571, val_loss=0.571]Epoch 22:   2%|▏         | 23/1000 [24:05<16:28:42, 60.72s/it, lr=0.0005, test_MAE=0.614, time=60.9, train_MAE=0.555, train_loss=0.555, val_MAE=0.571, val_loss=0.571]Epoch 23:   2%|▏         | 23/1000 [24:05<16:28:42, 60.72s/it, lr=0.0005, test_MAE=0.614, time=60.9, train_MAE=0.555, train_loss=0.555, val_MAE=0.571, val_loss=0.571]Epoch 23:   2%|▏         | 23/1000 [25:06<16:28:42, 60.72s/it, lr=0.0005, test_MAE=0.594, time=60.8, train_MAE=0.547, train_loss=0.547, val_MAE=0.561, val_loss=0.561]Epoch 23:   2%|▏         | 24/1000 [25:06<16:28:18, 60.76s/it, lr=0.0005, test_MAE=0.594, time=60.8, train_MAE=0.547, train_loss=0.547, val_MAE=0.561, val_loss=0.561]Epoch 24:   2%|▏         | 24/1000 [25:06<16:28:18, 60.76s/it, lr=0.0005, test_MAE=0.594, time=60.8, train_MAE=0.547, train_loss=0.547, val_MAE=0.561, val_loss=0.561]Epoch 24:   2%|▏         | 24/1000 [26:06<16:28:18, 60.76s/it, lr=0.0005, test_MAE=0.696, time=60.5, train_MAE=0.552, train_loss=0.552, val_MAE=0.632, val_loss=0.632]Epoch 24:   2%|▎         | 25/1000 [26:06<16:26:15, 60.69s/it, lr=0.0005, test_MAE=0.696, time=60.5, train_MAE=0.552, train_loss=0.552, val_MAE=0.632, val_loss=0.632]Epoch 25:   2%|▎         | 25/1000 [26:06<16:26:15, 60.69s/it, lr=0.0005, test_MAE=0.696, time=60.5, train_MAE=0.552, train_loss=0.552, val_MAE=0.632, val_loss=0.632]Epoch 25:   2%|▎         | 25/1000 [27:07<16:26:15, 60.69s/it, lr=0.0005, test_MAE=0.617, time=60.8, train_MAE=0.547, train_loss=0.547, val_MAE=0.567, val_loss=0.567]Epoch 25:   3%|▎         | 26/1000 [27:07<16:25:56, 60.74s/it, lr=0.0005, test_MAE=0.617, time=60.8, train_MAE=0.547, train_loss=0.547, val_MAE=0.567, val_loss=0.567]Epoch 26:   3%|▎         | 26/1000 [27:07<16:25:56, 60.74s/it, lr=0.0005, test_MAE=0.617, time=60.8, train_MAE=0.547, train_loss=0.547, val_MAE=0.567, val_loss=0.567]Epoch 26:   3%|▎         | 26/1000 [28:07<16:25:56, 60.74s/it, lr=0.0005, test_MAE=0.63, time=60.5, train_MAE=0.543, train_loss=0.543, val_MAE=0.584, val_loss=0.584] Epoch 26:   3%|▎         | 27/1000 [28:07<16:24:01, 60.68s/it, lr=0.0005, test_MAE=0.63, time=60.5, train_MAE=0.543, train_loss=0.543, val_MAE=0.584, val_loss=0.584]Epoch 27:   3%|▎         | 27/1000 [28:07<16:24:01, 60.68s/it, lr=0.0005, test_MAE=0.63, time=60.5, train_MAE=0.543, train_loss=0.543, val_MAE=0.584, val_loss=0.584]Epoch 27:   3%|▎         | 27/1000 [29:08<16:24:01, 60.68s/it, lr=0.0005, test_MAE=0.605, time=60.6, train_MAE=0.548, train_loss=0.548, val_MAE=0.568, val_loss=0.568]Epoch 27:   3%|▎         | 28/1000 [29:08<16:22:40, 60.66s/it, lr=0.0005, test_MAE=0.605, time=60.6, train_MAE=0.548, train_loss=0.548, val_MAE=0.568, val_loss=0.568]Epoch 28:   3%|▎         | 28/1000 [29:08<16:22:40, 60.66s/it, lr=0.0005, test_MAE=0.605, time=60.6, train_MAE=0.548, train_loss=0.548, val_MAE=0.568, val_loss=0.568]Epoch 28:   3%|▎         | 28/1000 [30:08<16:22:40, 60.66s/it, lr=0.0005, test_MAE=0.629, time=60.2, train_MAE=0.553, train_loss=0.553, val_MAE=0.579, val_loss=0.579]Epoch 28:   3%|▎         | 29/1000 [30:08<16:19:15, 60.51s/it, lr=0.0005, test_MAE=0.629, time=60.2, train_MAE=0.553, train_loss=0.553, val_MAE=0.579, val_loss=0.579]Epoch 29:   3%|▎         | 29/1000 [30:08<16:19:15, 60.51s/it, lr=0.0005, test_MAE=0.629, time=60.2, train_MAE=0.553, train_loss=0.553, val_MAE=0.579, val_loss=0.579]Epoch 29:   3%|▎         | 29/1000 [31:09<16:19:15, 60.51s/it, lr=0.0005, test_MAE=0.597, time=60.9, train_MAE=0.546, train_loss=0.546, val_MAE=0.553, val_loss=0.553]Epoch 29:   3%|▎         | 30/1000 [31:09<16:20:03, 60.62s/it, lr=0.0005, test_MAE=0.597, time=60.9, train_MAE=0.546, train_loss=0.546, val_MAE=0.553, val_loss=0.553]Epoch 30:   3%|▎         | 30/1000 [31:09<16:20:03, 60.62s/it, lr=0.0005, test_MAE=0.597, time=60.9, train_MAE=0.546, train_loss=0.546, val_MAE=0.553, val_loss=0.553]Epoch 30:   3%|▎         | 30/1000 [32:10<16:20:03, 60.62s/it, lr=0.0005, test_MAE=0.614, time=60.9, train_MAE=0.539, train_loss=0.539, val_MAE=0.563, val_loss=0.563]Epoch 30:   3%|▎         | 31/1000 [32:10<16:20:23, 60.71s/it, lr=0.0005, test_MAE=0.614, time=60.9, train_MAE=0.539, train_loss=0.539, val_MAE=0.563, val_loss=0.563]Epoch 31:   3%|▎         | 31/1000 [32:10<16:20:23, 60.71s/it, lr=0.0005, test_MAE=0.614, time=60.9, train_MAE=0.539, train_loss=0.539, val_MAE=0.563, val_loss=0.563]Epoch 31:   3%|▎         | 31/1000 [33:10<16:20:23, 60.71s/it, lr=0.0005, test_MAE=0.604, time=60.2, train_MAE=0.536, train_loss=0.536, val_MAE=0.565, val_loss=0.565]Epoch 31:   3%|▎         | 32/1000 [33:10<16:17:04, 60.56s/it, lr=0.0005, test_MAE=0.604, time=60.2, train_MAE=0.536, train_loss=0.536, val_MAE=0.565, val_loss=0.565]Epoch 32:   3%|▎         | 32/1000 [33:10<16:17:04, 60.56s/it, lr=0.0005, test_MAE=0.604, time=60.2, train_MAE=0.536, train_loss=0.536, val_MAE=0.565, val_loss=0.565]Epoch 32:   3%|▎         | 32/1000 [34:11<16:17:04, 60.56s/it, lr=0.0005, test_MAE=0.605, time=60.6, train_MAE=0.536, train_loss=0.536, val_MAE=0.565, val_loss=0.565]Epoch 32:   3%|▎         | 33/1000 [34:11<16:16:17, 60.58s/it, lr=0.0005, test_MAE=0.605, time=60.6, train_MAE=0.536, train_loss=0.536, val_MAE=0.565, val_loss=0.565]Epoch 33:   3%|▎         | 33/1000 [34:11<16:16:17, 60.58s/it, lr=0.0005, test_MAE=0.605, time=60.6, train_MAE=0.536, train_loss=0.536, val_MAE=0.565, val_loss=0.565]Epoch 33:   3%|▎         | 33/1000 [35:11<16:16:17, 60.58s/it, lr=0.0005, test_MAE=0.609, time=60.5, train_MAE=0.533, train_loss=0.533, val_MAE=0.558, val_loss=0.558]Epoch 33:   3%|▎         | 34/1000 [35:11<16:15:11, 60.57s/it, lr=0.0005, test_MAE=0.609, time=60.5, train_MAE=0.533, train_loss=0.533, val_MAE=0.558, val_loss=0.558]Epoch 34:   3%|▎         | 34/1000 [35:11<16:15:11, 60.57s/it, lr=0.0005, test_MAE=0.609, time=60.5, train_MAE=0.533, train_loss=0.533, val_MAE=0.558, val_loss=0.558]Epoch 34:   3%|▎         | 34/1000 [36:12<16:15:11, 60.57s/it, lr=0.0005, test_MAE=0.596, time=60.5, train_MAE=0.531, train_loss=0.531, val_MAE=0.556, val_loss=0.556]Epoch 34:   4%|▎         | 35/1000 [36:12<16:13:49, 60.55s/it, lr=0.0005, test_MAE=0.596, time=60.5, train_MAE=0.531, train_loss=0.531, val_MAE=0.556, val_loss=0.556]Epoch 35:   4%|▎         | 35/1000 [36:12<16:13:49, 60.55s/it, lr=0.0005, test_MAE=0.596, time=60.5, train_MAE=0.531, train_loss=0.531, val_MAE=0.556, val_loss=0.556]Epoch 35:   4%|▎         | 35/1000 [37:13<16:13:49, 60.55s/it, lr=0.0005, test_MAE=0.66, time=60.8, train_MAE=0.529, train_loss=0.529, val_MAE=0.611, val_loss=0.611] Epoch    36: reducing learning rate of group 0 to 2.5000e-04.
Epoch 35:   4%|▎         | 36/1000 [37:13<16:14:10, 60.63s/it, lr=0.0005, test_MAE=0.66, time=60.8, train_MAE=0.529, train_loss=0.529, val_MAE=0.611, val_loss=0.611]Epoch 36:   4%|▎         | 36/1000 [37:13<16:14:10, 60.63s/it, lr=0.0005, test_MAE=0.66, time=60.8, train_MAE=0.529, train_loss=0.529, val_MAE=0.611, val_loss=0.611]Epoch 36:   4%|▎         | 36/1000 [38:13<16:14:10, 60.63s/it, lr=0.00025, test_MAE=0.59, time=60.6, train_MAE=0.516, train_loss=0.516, val_MAE=0.552, val_loss=0.552]Epoch 36:   4%|▎         | 37/1000 [38:13<16:13:02, 60.63s/it, lr=0.00025, test_MAE=0.59, time=60.6, train_MAE=0.516, train_loss=0.516, val_MAE=0.552, val_loss=0.552]Epoch 37:   4%|▎         | 37/1000 [38:13<16:13:02, 60.63s/it, lr=0.00025, test_MAE=0.59, time=60.6, train_MAE=0.516, train_loss=0.516, val_MAE=0.552, val_loss=0.552]Epoch 37:   4%|▎         | 37/1000 [39:14<16:13:02, 60.63s/it, lr=0.00025, test_MAE=0.607, time=60.5, train_MAE=0.51, train_loss=0.51, val_MAE=0.564, val_loss=0.564] Epoch 37:   4%|▍         | 38/1000 [39:14<16:11:32, 60.60s/it, lr=0.00025, test_MAE=0.607, time=60.5, train_MAE=0.51, train_loss=0.51, val_MAE=0.564, val_loss=0.564]Epoch 38:   4%|▍         | 38/1000 [39:14<16:11:32, 60.60s/it, lr=0.00025, test_MAE=0.607, time=60.5, train_MAE=0.51, train_loss=0.51, val_MAE=0.564, val_loss=0.564]Epoch 38:   4%|▍         | 38/1000 [40:15<16:11:32, 60.60s/it, lr=0.00025, test_MAE=0.604, time=60.9, train_MAE=0.509, train_loss=0.509, val_MAE=0.559, val_loss=0.559]Epoch 38:   4%|▍         | 39/1000 [40:15<16:11:57, 60.68s/it, lr=0.00025, test_MAE=0.604, time=60.9, train_MAE=0.509, train_loss=0.509, val_MAE=0.559, val_loss=0.559]Epoch 39:   4%|▍         | 39/1000 [40:15<16:11:57, 60.68s/it, lr=0.00025, test_MAE=0.604, time=60.9, train_MAE=0.509, train_loss=0.509, val_MAE=0.559, val_loss=0.559]Epoch 39:   4%|▍         | 39/1000 [41:15<16:11:57, 60.68s/it, lr=0.00025, test_MAE=0.588, time=60.5, train_MAE=0.511, train_loss=0.511, val_MAE=0.546, val_loss=0.546]Epoch 39:   4%|▍         | 40/1000 [41:15<16:10:17, 60.64s/it, lr=0.00025, test_MAE=0.588, time=60.5, train_MAE=0.511, train_loss=0.511, val_MAE=0.546, val_loss=0.546]Epoch 40:   4%|▍         | 40/1000 [41:15<16:10:17, 60.64s/it, lr=0.00025, test_MAE=0.588, time=60.5, train_MAE=0.511, train_loss=0.511, val_MAE=0.546, val_loss=0.546]Epoch 40:   4%|▍         | 40/1000 [42:16<16:10:17, 60.64s/it, lr=0.00025, test_MAE=0.584, time=60.2, train_MAE=0.52, train_loss=0.52, val_MAE=0.545, val_loss=0.545]  Epoch 40:   4%|▍         | 41/1000 [42:16<16:07:24, 60.53s/it, lr=0.00025, test_MAE=0.584, time=60.2, train_MAE=0.52, train_loss=0.52, val_MAE=0.545, val_loss=0.545]Epoch 41:   4%|▍         | 41/1000 [42:16<16:07:24, 60.53s/it, lr=0.00025, test_MAE=0.584, time=60.2, train_MAE=0.52, train_loss=0.52, val_MAE=0.545, val_loss=0.545]Epoch 41:   4%|▍         | 41/1000 [43:16<16:07:24, 60.53s/it, lr=0.00025, test_MAE=0.595, time=60.9, train_MAE=0.503, train_loss=0.503, val_MAE=0.549, val_loss=0.549]Epoch 41:   4%|▍         | 42/1000 [43:16<16:08:12, 60.64s/it, lr=0.00025, test_MAE=0.595, time=60.9, train_MAE=0.503, train_loss=0.503, val_MAE=0.549, val_loss=0.549]Epoch 42:   4%|▍         | 42/1000 [43:16<16:08:12, 60.64s/it, lr=0.00025, test_MAE=0.595, time=60.9, train_MAE=0.503, train_loss=0.503, val_MAE=0.549, val_loss=0.549]Epoch 42:   4%|▍         | 42/1000 [44:17<16:08:12, 60.64s/it, lr=0.00025, test_MAE=0.589, time=60.9, train_MAE=0.508, train_loss=0.508, val_MAE=0.552, val_loss=0.552]Epoch 42:   4%|▍         | 43/1000 [44:17<16:08:35, 60.73s/it, lr=0.00025, test_MAE=0.589, time=60.9, train_MAE=0.508, train_loss=0.508, val_MAE=0.552, val_loss=0.552]Epoch 43:   4%|▍         | 43/1000 [44:17<16:08:35, 60.73s/it, lr=0.00025, test_MAE=0.589, time=60.9, train_MAE=0.508, train_loss=0.508, val_MAE=0.552, val_loss=0.552]Epoch 43:   4%|▍         | 43/1000 [45:18<16:08:35, 60.73s/it, lr=0.00025, test_MAE=0.596, time=60.2, train_MAE=0.507, train_loss=0.507, val_MAE=0.548, val_loss=0.548]Epoch 43:   4%|▍         | 44/1000 [45:18<16:05:09, 60.58s/it, lr=0.00025, test_MAE=0.596, time=60.2, train_MAE=0.507, train_loss=0.507, val_MAE=0.548, val_loss=0.548]Epoch 44:   4%|▍         | 44/1000 [45:18<16:05:09, 60.58s/it, lr=0.00025, test_MAE=0.596, time=60.2, train_MAE=0.507, train_loss=0.507, val_MAE=0.548, val_loss=0.548]Epoch 44:   4%|▍         | 44/1000 [46:18<16:05:09, 60.58s/it, lr=0.00025, test_MAE=0.605, time=60.2, train_MAE=0.5, train_loss=0.5, val_MAE=0.55, val_loss=0.55]      Epoch 44:   4%|▍         | 45/1000 [46:18<16:02:18, 60.46s/it, lr=0.00025, test_MAE=0.605, time=60.2, train_MAE=0.5, train_loss=0.5, val_MAE=0.55, val_loss=0.55]Epoch 45:   4%|▍         | 45/1000 [46:18<16:02:18, 60.46s/it, lr=0.00025, test_MAE=0.605, time=60.2, train_MAE=0.5, train_loss=0.5, val_MAE=0.55, val_loss=0.55]Epoch 45:   4%|▍         | 45/1000 [47:19<16:02:18, 60.46s/it, lr=0.00025, test_MAE=0.594, time=60.8, train_MAE=0.502, train_loss=0.502, val_MAE=0.551, val_loss=0.551]Epoch 45:   5%|▍         | 46/1000 [47:19<16:03:05, 60.57s/it, lr=0.00025, test_MAE=0.594, time=60.8, train_MAE=0.502, train_loss=0.502, val_MAE=0.551, val_loss=0.551]Epoch 46:   5%|▍         | 46/1000 [47:19<16:03:05, 60.57s/it, lr=0.00025, test_MAE=0.594, time=60.8, train_MAE=0.502, train_loss=0.502, val_MAE=0.551, val_loss=0.551]Epoch 46:   5%|▍         | 46/1000 [48:19<16:03:05, 60.57s/it, lr=0.00025, test_MAE=0.622, time=60.6, train_MAE=0.498, train_loss=0.498, val_MAE=0.575, val_loss=0.575]Epoch    47: reducing learning rate of group 0 to 1.2500e-04.
Epoch 46:   5%|▍         | 47/1000 [48:19<16:02:19, 60.59s/it, lr=0.00025, test_MAE=0.622, time=60.6, train_MAE=0.498, train_loss=0.498, val_MAE=0.575, val_loss=0.575]Epoch 47:   5%|▍         | 47/1000 [48:19<16:02:19, 60.59s/it, lr=0.00025, test_MAE=0.622, time=60.6, train_MAE=0.498, train_loss=0.498, val_MAE=0.575, val_loss=0.575]Epoch 47:   5%|▍         | 47/1000 [49:19<16:02:19, 60.59s/it, lr=0.000125, test_MAE=0.583, time=60.2, train_MAE=0.49, train_loss=0.49, val_MAE=0.542, val_loss=0.542] Epoch 47:   5%|▍         | 48/1000 [49:19<15:59:29, 60.47s/it, lr=0.000125, test_MAE=0.583, time=60.2, train_MAE=0.49, train_loss=0.49, val_MAE=0.542, val_loss=0.542]Epoch 48:   5%|▍         | 48/1000 [49:19<15:59:29, 60.47s/it, lr=0.000125, test_MAE=0.583, time=60.2, train_MAE=0.49, train_loss=0.49, val_MAE=0.542, val_loss=0.542]Epoch 48:   5%|▍         | 48/1000 [50:20<15:59:29, 60.47s/it, lr=0.000125, test_MAE=0.589, time=60.9, train_MAE=0.491, train_loss=0.491, val_MAE=0.541, val_loss=0.541]Epoch 48:   5%|▍         | 49/1000 [50:20<16:00:35, 60.61s/it, lr=0.000125, test_MAE=0.589, time=60.9, train_MAE=0.491, train_loss=0.491, val_MAE=0.541, val_loss=0.541]Epoch 49:   5%|▍         | 49/1000 [50:20<16:00:35, 60.61s/it, lr=0.000125, test_MAE=0.589, time=60.9, train_MAE=0.491, train_loss=0.491, val_MAE=0.541, val_loss=0.541]Epoch 49:   5%|▍         | 49/1000 [51:21<16:00:35, 60.61s/it, lr=0.000125, test_MAE=0.583, time=60.5, train_MAE=0.489, train_loss=0.489, val_MAE=0.541, val_loss=0.541]Epoch 49:   5%|▌         | 50/1000 [51:21<15:59:22, 60.59s/it, lr=0.000125, test_MAE=0.583, time=60.5, train_MAE=0.489, train_loss=0.489, val_MAE=0.541, val_loss=0.541]Epoch 50:   5%|▌         | 50/1000 [51:21<15:59:22, 60.59s/it, lr=0.000125, test_MAE=0.583, time=60.5, train_MAE=0.489, train_loss=0.489, val_MAE=0.541, val_loss=0.541]Epoch 50:   5%|▌         | 50/1000 [52:21<15:59:22, 60.59s/it, lr=0.000125, test_MAE=0.609, time=60.6, train_MAE=0.483, train_loss=0.483, val_MAE=0.563, val_loss=0.563]Epoch 50:   5%|▌         | 51/1000 [52:22<15:58:18, 60.59s/it, lr=0.000125, test_MAE=0.609, time=60.6, train_MAE=0.483, train_loss=0.483, val_MAE=0.563, val_loss=0.563]Epoch 51:   5%|▌         | 51/1000 [52:22<15:58:18, 60.59s/it, lr=0.000125, test_MAE=0.609, time=60.6, train_MAE=0.483, train_loss=0.483, val_MAE=0.563, val_loss=0.563]Epoch 51:   5%|▌         | 51/1000 [53:22<15:58:18, 60.59s/it, lr=0.000125, test_MAE=0.588, time=60.6, train_MAE=0.483, train_loss=0.483, val_MAE=0.543, val_loss=0.543]Epoch 51:   5%|▌         | 52/1000 [53:22<15:57:27, 60.60s/it, lr=0.000125, test_MAE=0.588, time=60.6, train_MAE=0.483, train_loss=0.483, val_MAE=0.543, val_loss=0.543]Epoch 52:   5%|▌         | 52/1000 [53:22<15:57:27, 60.60s/it, lr=0.000125, test_MAE=0.588, time=60.6, train_MAE=0.483, train_loss=0.483, val_MAE=0.543, val_loss=0.543]Epoch 52:   5%|▌         | 52/1000 [54:23<15:57:27, 60.60s/it, lr=0.000125, test_MAE=0.585, time=60.5, train_MAE=0.483, train_loss=0.483, val_MAE=0.542, val_loss=0.542]Epoch 52:   5%|▌         | 53/1000 [54:23<15:56:15, 60.59s/it, lr=0.000125, test_MAE=0.585, time=60.5, train_MAE=0.483, train_loss=0.483, val_MAE=0.542, val_loss=0.542]Epoch 53:   5%|▌         | 53/1000 [54:23<15:56:15, 60.59s/it, lr=0.000125, test_MAE=0.585, time=60.5, train_MAE=0.483, train_loss=0.483, val_MAE=0.542, val_loss=0.542]Epoch 53:   5%|▌         | 53/1000 [55:23<15:56:15, 60.59s/it, lr=0.000125, test_MAE=0.584, time=60.5, train_MAE=0.486, train_loss=0.486, val_MAE=0.542, val_loss=0.542]Epoch 53:   5%|▌         | 54/1000 [55:23<15:55:02, 60.57s/it, lr=0.000125, test_MAE=0.584, time=60.5, train_MAE=0.486, train_loss=0.486, val_MAE=0.542, val_loss=0.542]Epoch 54:   5%|▌         | 54/1000 [55:23<15:55:02, 60.57s/it, lr=0.000125, test_MAE=0.584, time=60.5, train_MAE=0.486, train_loss=0.486, val_MAE=0.542, val_loss=0.542]Epoch 54:   5%|▌         | 54/1000 [56:24<15:55:02, 60.57s/it, lr=0.000125, test_MAE=0.587, time=60.9, train_MAE=0.486, train_loss=0.486, val_MAE=0.543, val_loss=0.543]Epoch    55: reducing learning rate of group 0 to 6.2500e-05.
Epoch 54:   6%|▌         | 55/1000 [56:24<15:55:38, 60.68s/it, lr=0.000125, test_MAE=0.587, time=60.9, train_MAE=0.486, train_loss=0.486, val_MAE=0.543, val_loss=0.543]Epoch 55:   6%|▌         | 55/1000 [56:24<15:55:38, 60.68s/it, lr=0.000125, test_MAE=0.587, time=60.9, train_MAE=0.486, train_loss=0.486, val_MAE=0.543, val_loss=0.543]Epoch 55:   6%|▌         | 55/1000 [57:25<15:55:38, 60.68s/it, lr=6.25e-5, test_MAE=0.584, time=60.5, train_MAE=0.473, train_loss=0.473, val_MAE=0.539, val_loss=0.539] Epoch 55:   6%|▌         | 56/1000 [57:25<15:53:54, 60.63s/it, lr=6.25e-5, test_MAE=0.584, time=60.5, train_MAE=0.473, train_loss=0.473, val_MAE=0.539, val_loss=0.539]Epoch 56:   6%|▌         | 56/1000 [57:25<15:53:54, 60.63s/it, lr=6.25e-5, test_MAE=0.584, time=60.5, train_MAE=0.473, train_loss=0.473, val_MAE=0.539, val_loss=0.539]Epoch 56:   6%|▌         | 56/1000 [58:25<15:53:54, 60.63s/it, lr=6.25e-5, test_MAE=0.584, time=60.2, train_MAE=0.473, train_loss=0.473, val_MAE=0.536, val_loss=0.536]Epoch 56:   6%|▌         | 57/1000 [58:25<15:51:10, 60.52s/it, lr=6.25e-5, test_MAE=0.584, time=60.2, train_MAE=0.473, train_loss=0.473, val_MAE=0.536, val_loss=0.536]Epoch 57:   6%|▌         | 57/1000 [58:25<15:51:10, 60.52s/it, lr=6.25e-5, test_MAE=0.584, time=60.2, train_MAE=0.473, train_loss=0.473, val_MAE=0.536, val_loss=0.536]Epoch 57:   6%|▌         | 57/1000 [59:26<15:51:10, 60.52s/it, lr=6.25e-5, test_MAE=0.585, time=61.2, train_MAE=0.476, train_loss=0.476, val_MAE=0.54, val_loss=0.54]  Epoch 57:   6%|▌         | 58/1000 [59:26<15:53:40, 60.74s/it, lr=6.25e-5, test_MAE=0.585, time=61.2, train_MAE=0.476, train_loss=0.476, val_MAE=0.54, val_loss=0.54]Epoch 58:   6%|▌         | 58/1000 [59:26<15:53:40, 60.74s/it, lr=6.25e-5, test_MAE=0.585, time=61.2, train_MAE=0.476, train_loss=0.476, val_MAE=0.54, val_loss=0.54]Epoch 58:   6%|▌         | 58/1000 [1:00:27<15:53:40, 60.74s/it, lr=6.25e-5, test_MAE=0.585, time=60.5, train_MAE=0.477, train_loss=0.477, val_MAE=0.539, val_loss=0.539]Epoch 58:   6%|▌         | 59/1000 [1:00:27<15:51:34, 60.67s/it, lr=6.25e-5, test_MAE=0.585, time=60.5, train_MAE=0.477, train_loss=0.477, val_MAE=0.539, val_loss=0.539]Epoch 59:   6%|▌         | 59/1000 [1:00:27<15:51:34, 60.67s/it, lr=6.25e-5, test_MAE=0.585, time=60.5, train_MAE=0.477, train_loss=0.477, val_MAE=0.539, val_loss=0.539]Epoch 59:   6%|▌         | 59/1000 [1:01:27<15:51:34, 60.67s/it, lr=6.25e-5, test_MAE=0.586, time=60.2, train_MAE=0.476, train_loss=0.476, val_MAE=0.538, val_loss=0.538]Epoch 59:   6%|▌         | 60/1000 [1:01:27<15:48:25, 60.54s/it, lr=6.25e-5, test_MAE=0.586, time=60.2, train_MAE=0.476, train_loss=0.476, val_MAE=0.538, val_loss=0.538]Epoch 60:   6%|▌         | 60/1000 [1:01:27<15:48:25, 60.54s/it, lr=6.25e-5, test_MAE=0.586, time=60.2, train_MAE=0.476, train_loss=0.476, val_MAE=0.538, val_loss=0.538]Epoch 60:   6%|▌         | 60/1000 [1:02:28<15:48:25, 60.54s/it, lr=6.25e-5, test_MAE=0.585, time=60.8, train_MAE=0.471, train_loss=0.471, val_MAE=0.536, val_loss=0.536]Epoch 60:   6%|▌         | 61/1000 [1:02:28<15:48:52, 60.63s/it, lr=6.25e-5, test_MAE=0.585, time=60.8, train_MAE=0.471, train_loss=0.471, val_MAE=0.536, val_loss=0.536]Epoch 61:   6%|▌         | 61/1000 [1:02:28<15:48:52, 60.63s/it, lr=6.25e-5, test_MAE=0.585, time=60.8, train_MAE=0.471, train_loss=0.471, val_MAE=0.536, val_loss=0.536]Epoch 61:   6%|▌         | 61/1000 [1:03:28<15:48:52, 60.63s/it, lr=6.25e-5, test_MAE=0.578, time=60.5, train_MAE=0.47, train_loss=0.47, val_MAE=0.537, val_loss=0.537]  Epoch 61:   6%|▌         | 62/1000 [1:03:28<15:47:25, 60.60s/it, lr=6.25e-5, test_MAE=0.578, time=60.5, train_MAE=0.47, train_loss=0.47, val_MAE=0.537, val_loss=0.537]Epoch 62:   6%|▌         | 62/1000 [1:03:28<15:47:25, 60.60s/it, lr=6.25e-5, test_MAE=0.578, time=60.5, train_MAE=0.47, train_loss=0.47, val_MAE=0.537, val_loss=0.537]Epoch 62:   6%|▌         | 62/1000 [1:04:29<15:47:25, 60.60s/it, lr=6.25e-5, test_MAE=0.583, time=60.2, train_MAE=0.474, train_loss=0.474, val_MAE=0.541, val_loss=0.541]Epoch    63: reducing learning rate of group 0 to 3.1250e-05.
Epoch 62:   6%|▋         | 63/1000 [1:04:29<15:44:31, 60.48s/it, lr=6.25e-5, test_MAE=0.583, time=60.2, train_MAE=0.474, train_loss=0.474, val_MAE=0.541, val_loss=0.541]Epoch 63:   6%|▋         | 63/1000 [1:04:29<15:44:31, 60.48s/it, lr=6.25e-5, test_MAE=0.583, time=60.2, train_MAE=0.474, train_loss=0.474, val_MAE=0.541, val_loss=0.541]Epoch 63:   6%|▋         | 63/1000 [1:05:29<15:44:31, 60.48s/it, lr=3.13e-5, test_MAE=0.582, time=60.9, train_MAE=0.475, train_loss=0.475, val_MAE=0.538, val_loss=0.538]Epoch 63:   6%|▋         | 64/1000 [1:05:29<15:45:34, 60.61s/it, lr=3.13e-5, test_MAE=0.582, time=60.9, train_MAE=0.475, train_loss=0.475, val_MAE=0.538, val_loss=0.538]Epoch 64:   6%|▋         | 64/1000 [1:05:29<15:45:34, 60.61s/it, lr=3.13e-5, test_MAE=0.582, time=60.9, train_MAE=0.475, train_loss=0.475, val_MAE=0.538, val_loss=0.538]Epoch 64:   6%|▋         | 64/1000 [1:06:30<15:45:34, 60.61s/it, lr=3.13e-5, test_MAE=0.581, time=60.5, train_MAE=0.464, train_loss=0.464, val_MAE=0.537, val_loss=0.537]Epoch 64:   6%|▋         | 65/1000 [1:06:30<15:44:17, 60.60s/it, lr=3.13e-5, test_MAE=0.581, time=60.5, train_MAE=0.464, train_loss=0.464, val_MAE=0.537, val_loss=0.537]Epoch 65:   6%|▋         | 65/1000 [1:06:30<15:44:17, 60.60s/it, lr=3.13e-5, test_MAE=0.581, time=60.5, train_MAE=0.464, train_loss=0.464, val_MAE=0.537, val_loss=0.537]Epoch 65:   6%|▋         | 65/1000 [1:07:31<15:44:17, 60.60s/it, lr=3.13e-5, test_MAE=0.581, time=60.5, train_MAE=0.468, train_loss=0.468, val_MAE=0.536, val_loss=0.536]Epoch 65:   7%|▋         | 66/1000 [1:07:31<15:43:20, 60.60s/it, lr=3.13e-5, test_MAE=0.581, time=60.5, train_MAE=0.468, train_loss=0.468, val_MAE=0.536, val_loss=0.536]Epoch 66:   7%|▋         | 66/1000 [1:07:31<15:43:20, 60.60s/it, lr=3.13e-5, test_MAE=0.581, time=60.5, train_MAE=0.468, train_loss=0.468, val_MAE=0.536, val_loss=0.536]Epoch 66:   7%|▋         | 66/1000 [1:08:31<15:43:20, 60.60s/it, lr=3.13e-5, test_MAE=0.582, time=60.6, train_MAE=0.467, train_loss=0.467, val_MAE=0.537, val_loss=0.537]Epoch 66:   7%|▋         | 67/1000 [1:08:31<15:42:36, 60.62s/it, lr=3.13e-5, test_MAE=0.582, time=60.6, train_MAE=0.467, train_loss=0.467, val_MAE=0.537, val_loss=0.537]Epoch 67:   7%|▋         | 67/1000 [1:08:31<15:42:36, 60.62s/it, lr=3.13e-5, test_MAE=0.582, time=60.6, train_MAE=0.467, train_loss=0.467, val_MAE=0.537, val_loss=0.537]Epoch 67:   7%|▋         | 67/1000 [1:09:32<15:42:36, 60.62s/it, lr=3.13e-5, test_MAE=0.585, time=60.5, train_MAE=0.473, train_loss=0.473, val_MAE=0.539, val_loss=0.539]Epoch 67:   7%|▋         | 68/1000 [1:09:32<15:41:24, 60.61s/it, lr=3.13e-5, test_MAE=0.585, time=60.5, train_MAE=0.473, train_loss=0.473, val_MAE=0.539, val_loss=0.539]Epoch 68:   7%|▋         | 68/1000 [1:09:32<15:41:24, 60.61s/it, lr=3.13e-5, test_MAE=0.585, time=60.5, train_MAE=0.473, train_loss=0.473, val_MAE=0.539, val_loss=0.539]Epoch 68:   7%|▋         | 68/1000 [1:10:32<15:41:24, 60.61s/it, lr=3.13e-5, test_MAE=0.585, time=60.5, train_MAE=0.464, train_loss=0.464, val_MAE=0.54, val_loss=0.54]  Epoch    69: reducing learning rate of group 0 to 1.5625e-05.
Epoch 68:   7%|▋         | 69/1000 [1:10:32<15:39:57, 60.58s/it, lr=3.13e-5, test_MAE=0.585, time=60.5, train_MAE=0.464, train_loss=0.464, val_MAE=0.54, val_loss=0.54]Epoch 69:   7%|▋         | 69/1000 [1:10:32<15:39:57, 60.58s/it, lr=3.13e-5, test_MAE=0.585, time=60.5, train_MAE=0.464, train_loss=0.464, val_MAE=0.54, val_loss=0.54]Epoch 69:   7%|▋         | 69/1000 [1:11:33<15:39:57, 60.58s/it, lr=1.56e-5, test_MAE=0.582, time=60.9, train_MAE=0.464, train_loss=0.464, val_MAE=0.536, val_loss=0.536]Epoch 69:   7%|▋         | 70/1000 [1:11:33<15:40:25, 60.67s/it, lr=1.56e-5, test_MAE=0.582, time=60.9, train_MAE=0.464, train_loss=0.464, val_MAE=0.536, val_loss=0.536]Epoch 70:   7%|▋         | 70/1000 [1:11:33<15:40:25, 60.67s/it, lr=1.56e-5, test_MAE=0.582, time=60.9, train_MAE=0.464, train_loss=0.464, val_MAE=0.536, val_loss=0.536]Epoch 70:   7%|▋         | 70/1000 [1:12:34<15:40:25, 60.67s/it, lr=1.56e-5, test_MAE=0.581, time=60.5, train_MAE=0.465, train_loss=0.465, val_MAE=0.534, val_loss=0.534]Epoch 70:   7%|▋         | 71/1000 [1:12:34<15:38:51, 60.64s/it, lr=1.56e-5, test_MAE=0.581, time=60.5, train_MAE=0.465, train_loss=0.465, val_MAE=0.534, val_loss=0.534]Epoch 71:   7%|▋         | 71/1000 [1:12:34<15:38:51, 60.64s/it, lr=1.56e-5, test_MAE=0.581, time=60.5, train_MAE=0.465, train_loss=0.465, val_MAE=0.534, val_loss=0.534]Epoch 71:   7%|▋         | 71/1000 [1:13:34<15:38:51, 60.64s/it, lr=1.56e-5, test_MAE=0.583, time=59.8, train_MAE=0.469, train_loss=0.469, val_MAE=0.536, val_loss=0.536]Epoch 71:   7%|▋         | 72/1000 [1:13:34<15:34:00, 60.39s/it, lr=1.56e-5, test_MAE=0.583, time=59.8, train_MAE=0.469, train_loss=0.469, val_MAE=0.536, val_loss=0.536]Epoch 72:   7%|▋         | 72/1000 [1:13:34<15:34:00, 60.39s/it, lr=1.56e-5, test_MAE=0.583, time=59.8, train_MAE=0.469, train_loss=0.469, val_MAE=0.536, val_loss=0.536]Epoch 72:   7%|▋         | 72/1000 [1:14:34<15:34:00, 60.39s/it, lr=1.56e-5, test_MAE=0.582, time=60.2, train_MAE=0.464, train_loss=0.464, val_MAE=0.536, val_loss=0.536]Epoch 72:   7%|▋         | 73/1000 [1:14:34<15:32:03, 60.33s/it, lr=1.56e-5, test_MAE=0.582, time=60.2, train_MAE=0.464, train_loss=0.464, val_MAE=0.536, val_loss=0.536]Epoch 73:   7%|▋         | 73/1000 [1:14:34<15:32:03, 60.33s/it, lr=1.56e-5, test_MAE=0.582, time=60.2, train_MAE=0.464, train_loss=0.464, val_MAE=0.536, val_loss=0.536]Epoch 73:   7%|▋         | 73/1000 [1:15:33<15:32:03, 60.33s/it, lr=1.56e-5, test_MAE=0.58, time=59.5, train_MAE=0.462, train_loss=0.462, val_MAE=0.536, val_loss=0.536] Epoch 73:   7%|▋         | 74/1000 [1:15:33<15:27:25, 60.09s/it, lr=1.56e-5, test_MAE=0.58, time=59.5, train_MAE=0.462, train_loss=0.462, val_MAE=0.536, val_loss=0.536]Epoch 74:   7%|▋         | 74/1000 [1:15:33<15:27:25, 60.09s/it, lr=1.56e-5, test_MAE=0.58, time=59.5, train_MAE=0.462, train_loss=0.462, val_MAE=0.536, val_loss=0.536]Epoch 74:   7%|▋         | 74/1000 [1:16:33<15:27:25, 60.09s/it, lr=1.56e-5, test_MAE=0.581, time=59.2, train_MAE=0.46, train_loss=0.46, val_MAE=0.534, val_loss=0.534] Epoch 74:   8%|▊         | 75/1000 [1:16:33<15:22:36, 59.84s/it, lr=1.56e-5, test_MAE=0.581, time=59.2, train_MAE=0.46, train_loss=0.46, val_MAE=0.534, val_loss=0.534]Epoch 75:   8%|▊         | 75/1000 [1:16:33<15:22:36, 59.84s/it, lr=1.56e-5, test_MAE=0.581, time=59.2, train_MAE=0.46, train_loss=0.46, val_MAE=0.534, val_loss=0.534]Epoch 75:   8%|▊         | 75/1000 [1:17:32<15:22:36, 59.84s/it, lr=1.56e-5, test_MAE=0.58, time=59.9, train_MAE=0.46, train_loss=0.46, val_MAE=0.535, val_loss=0.535] Epoch 75:   8%|▊         | 76/1000 [1:17:33<15:21:52, 59.86s/it, lr=1.56e-5, test_MAE=0.58, time=59.9, train_MAE=0.46, train_loss=0.46, val_MAE=0.535, val_loss=0.535]Epoch 76:   8%|▊         | 76/1000 [1:17:33<15:21:52, 59.86s/it, lr=1.56e-5, test_MAE=0.58, time=59.9, train_MAE=0.46, train_loss=0.46, val_MAE=0.535, val_loss=0.535]Epoch 76:   8%|▊         | 76/1000 [1:18:32<15:21:52, 59.86s/it, lr=1.56e-5, test_MAE=0.582, time=59.5, train_MAE=0.466, train_loss=0.466, val_MAE=0.537, val_loss=0.537]Epoch    77: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 76:   8%|▊         | 76/1000 [1:18:32<15:54:55, 62.01s/it, lr=1.56e-5, test_MAE=0.582, time=59.5, train_MAE=0.466, train_loss=0.466, val_MAE=0.537, val_loss=0.537]
Test MAE: 0.5816
Train MAE: 0.4495
Convergence Time (Epochs): 76.0000
TOTAL TIME TAKEN: 4749.6151s
AVG TIME PER EPOCH: 61.1834s
