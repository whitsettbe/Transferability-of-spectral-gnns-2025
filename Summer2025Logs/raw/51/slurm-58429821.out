I'm echoing to stdout
I'm echoing to stderr
My JobID is 58429821
I have 4 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.0573s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 16, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 4, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'cheb02_vec', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_sub', 'num_eigs': 16, 'bias_mode': 'spatial', 'l1_reg': 0.0001, 'l2_reg': 0.005, 'gen_reg': 0.0, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/aug07/zinc_train_rec.csv', 'test': 'supp_data/molecules/aug07/zinc_test_rec.csv', 'val': 'supp_data/molecules/aug07/zinc_val_rec.csv'}, 'fixMissingPhi1': False, 'extraOrtho': False, 'doublePrecision': True, 'eigval_hidden_dim': 100, 'eigval_num_hidden_layer': 3, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [04:41<?, ?it/s, lr=0.001, test_MAE=1.37, time=281, train_MAE=0.855, train_loss=2.76, val_MAE=1.34, val_loss=3.07]Epoch 0:   0%|          | 1/1000 [04:41<78:03:49, 281.31s/it, lr=0.001, test_MAE=1.37, time=281, train_MAE=0.855, train_loss=2.76, val_MAE=1.34, val_loss=3.07]Epoch 1:   0%|          | 1/1000 [04:41<78:03:49, 281.31s/it, lr=0.001, test_MAE=1.37, time=281, train_MAE=0.855, train_loss=2.76, val_MAE=1.34, val_loss=3.07]Epoch 1:   0%|          | 1/1000 [09:04<78:03:49, 281.31s/it, lr=0.001, test_MAE=0.839, time=263, train_MAE=0.711, train_loss=2.36, val_MAE=0.758, val_loss=2.37]Epoch 1:   0%|          | 2/1000 [09:04<76:26:43, 275.75s/it, lr=0.001, test_MAE=0.839, time=263, train_MAE=0.711, train_loss=2.36, val_MAE=0.758, val_loss=2.37]Epoch 2:   0%|          | 2/1000 [09:04<76:26:43, 275.75s/it, lr=0.001, test_MAE=0.839, time=263, train_MAE=0.711, train_loss=2.36, val_MAE=0.758, val_loss=2.37]Epoch 2:   0%|          | 2/1000 [13:24<76:26:43, 275.75s/it, lr=0.001, test_MAE=1.03, time=261, train_MAE=0.689, train_loss=2.26, val_MAE=0.993, val_loss=2.51] Epoch 2:   0%|          | 3/1000 [13:25<75:08:04, 271.30s/it, lr=0.001, test_MAE=1.03, time=261, train_MAE=0.689, train_loss=2.26, val_MAE=0.993, val_loss=2.51]Epoch 3:   0%|          | 3/1000 [13:25<75:08:04, 271.30s/it, lr=0.001, test_MAE=1.03, time=261, train_MAE=0.689, train_loss=2.26, val_MAE=0.993, val_loss=2.51]Epoch 3:   0%|          | 3/1000 [17:46<75:08:04, 271.30s/it, lr=0.001, test_MAE=0.855, time=262, train_MAE=0.673, train_loss=2.15, val_MAE=0.79, val_loss=2.23]Epoch 3:   0%|          | 4/1000 [17:46<74:15:03, 268.38s/it, lr=0.001, test_MAE=0.855, time=262, train_MAE=0.673, train_loss=2.15, val_MAE=0.79, val_loss=2.23]Epoch 4:   0%|          | 4/1000 [17:46<74:15:03, 268.38s/it, lr=0.001, test_MAE=0.855, time=262, train_MAE=0.673, train_loss=2.15, val_MAE=0.79, val_loss=2.23]Epoch 4:   0%|          | 4/1000 [22:09<74:15:03, 268.38s/it, lr=0.001, test_MAE=0.813, time=262, train_MAE=0.663, train_loss=2.06, val_MAE=0.763, val_loss=2.12]Epoch 4:   0%|          | 5/1000 [22:09<73:41:20, 266.61s/it, lr=0.001, test_MAE=0.813, time=262, train_MAE=0.663, train_loss=2.06, val_MAE=0.763, val_loss=2.12]Epoch 5:   0%|          | 5/1000 [22:09<73:41:20, 266.61s/it, lr=0.001, test_MAE=0.813, time=262, train_MAE=0.663, train_loss=2.06, val_MAE=0.763, val_loss=2.12]Epoch 5:   0%|          | 5/1000 [26:29<73:41:20, 266.61s/it, lr=0.001, test_MAE=1.28, time=261, train_MAE=0.674, train_loss=2, val_MAE=1.24, val_loss=2.52]     Epoch 5:   1%|          | 6/1000 [26:30<73:08:44, 264.91s/it, lr=0.001, test_MAE=1.28, time=261, train_MAE=0.674, train_loss=2, val_MAE=1.24, val_loss=2.52]Epoch 6:   1%|          | 6/1000 [26:30<73:08:44, 264.91s/it, lr=0.001, test_MAE=1.28, time=261, train_MAE=0.674, train_loss=2, val_MAE=1.24, val_loss=2.52]Epoch 6:   1%|          | 6/1000 [30:51<73:08:44, 264.91s/it, lr=0.001, test_MAE=0.856, time=261, train_MAE=0.653, train_loss=1.89, val_MAE=0.802, val_loss=2.01]Epoch 6:   1%|          | 7/1000 [30:51<72:46:51, 263.86s/it, lr=0.001, test_MAE=0.856, time=261, train_MAE=0.653, train_loss=1.89, val_MAE=0.802, val_loss=2.01]Epoch 7:   1%|          | 7/1000 [30:51<72:46:51, 263.86s/it, lr=0.001, test_MAE=0.856, time=261, train_MAE=0.653, train_loss=1.89, val_MAE=0.802, val_loss=2.01]Epoch 7:   1%|          | 7/1000 [35:13<72:46:51, 263.86s/it, lr=0.001, test_MAE=0.904, time=262, train_MAE=0.649, train_loss=1.82, val_MAE=0.871, val_loss=1.98]Epoch 7:   1%|          | 8/1000 [35:13<72:35:18, 263.43s/it, lr=0.001, test_MAE=0.904, time=262, train_MAE=0.649, train_loss=1.82, val_MAE=0.871, val_loss=1.98]Epoch 8:   1%|          | 8/1000 [35:13<72:35:18, 263.43s/it, lr=0.001, test_MAE=0.904, time=262, train_MAE=0.649, train_loss=1.82, val_MAE=0.871, val_loss=1.98]Epoch 8:   1%|          | 8/1000 [39:34<72:35:18, 263.43s/it, lr=0.001, test_MAE=0.955, time=261, train_MAE=0.661, train_loss=1.76, val_MAE=0.855, val_loss=1.91]Epoch 8:   1%|          | 9/1000 [39:34<72:17:42, 262.63s/it, lr=0.001, test_MAE=0.955, time=261, train_MAE=0.661, train_loss=1.76, val_MAE=0.855, val_loss=1.91]Epoch 9:   1%|          | 9/1000 [39:34<72:17:42, 262.63s/it, lr=0.001, test_MAE=0.955, time=261, train_MAE=0.661, train_loss=1.76, val_MAE=0.855, val_loss=1.91]Epoch 9:   1%|          | 9/1000 [43:56<72:17:42, 262.63s/it, lr=0.001, test_MAE=0.815, time=262, train_MAE=0.655, train_loss=1.68, val_MAE=0.769, val_loss=1.75]Epoch 9:   1%|          | 10/1000 [43:56<72:08:01, 262.30s/it, lr=0.001, test_MAE=0.815, time=262, train_MAE=0.655, train_loss=1.68, val_MAE=0.769, val_loss=1.75]Epoch 10:   1%|          | 10/1000 [43:56<72:08:01, 262.30s/it, lr=0.001, test_MAE=0.815, time=262, train_MAE=0.655, train_loss=1.68, val_MAE=0.769, val_loss=1.75]Epoch 10:   1%|          | 10/1000 [48:18<72:08:01, 262.30s/it, lr=0.001, test_MAE=0.711, time=263, train_MAE=0.647, train_loss=1.59, val_MAE=0.683, val_loss=1.59]Epoch 10:   1%|          | 11/1000 [48:18<72:05:05, 262.39s/it, lr=0.001, test_MAE=0.711, time=263, train_MAE=0.647, train_loss=1.59, val_MAE=0.683, val_loss=1.59]Epoch 11:   1%|          | 11/1000 [48:18<72:05:05, 262.39s/it, lr=0.001, test_MAE=0.711, time=263, train_MAE=0.647, train_loss=1.59, val_MAE=0.683, val_loss=1.59]Epoch 11:   1%|          | 11/1000 [52:39<72:05:05, 262.39s/it, lr=0.001, test_MAE=1.19, time=261, train_MAE=0.64, train_loss=1.52, val_MAE=1.13, val_loss=1.97]   Epoch 11:   1%|          | 12/1000 [52:39<71:54:36, 262.02s/it, lr=0.001, test_MAE=1.19, time=261, train_MAE=0.64, train_loss=1.52, val_MAE=1.13, val_loss=1.97]Epoch 12:   1%|          | 12/1000 [52:39<71:54:36, 262.02s/it, lr=0.001, test_MAE=1.19, time=261, train_MAE=0.64, train_loss=1.52, val_MAE=1.13, val_loss=1.97]Epoch 12:   1%|          | 12/1000 [57:01<71:54:36, 262.02s/it, lr=0.001, test_MAE=1.04, time=262, train_MAE=0.633, train_loss=1.46, val_MAE=1, val_loss=1.79]  Epoch 12:   1%|▏         | 13/1000 [57:01<71:49:38, 261.98s/it, lr=0.001, test_MAE=1.04, time=262, train_MAE=0.633, train_loss=1.46, val_MAE=1, val_loss=1.79]Epoch 13:   1%|▏         | 13/1000 [57:01<71:49:38, 261.98s/it, lr=0.001, test_MAE=1.04, time=262, train_MAE=0.633, train_loss=1.46, val_MAE=1, val_loss=1.79]Epoch 13:   1%|▏         | 13/1000 [1:01:24<71:49:38, 261.98s/it, lr=0.001, test_MAE=0.675, time=263, train_MAE=0.632, train_loss=1.39, val_MAE=0.627, val_loss=1.36]Epoch 13:   1%|▏         | 14/1000 [1:01:24<71:47:58, 262.15s/it, lr=0.001, test_MAE=0.675, time=263, train_MAE=0.632, train_loss=1.39, val_MAE=0.627, val_loss=1.36]Epoch 14:   1%|▏         | 14/1000 [1:01:24<71:47:58, 262.15s/it, lr=0.001, test_MAE=0.675, time=263, train_MAE=0.632, train_loss=1.39, val_MAE=0.627, val_loss=1.36]Epoch 14:   1%|▏         | 14/1000 [1:05:45<71:47:58, 262.15s/it, lr=0.001, test_MAE=0.823, time=261, train_MAE=0.637, train_loss=1.35, val_MAE=0.791, val_loss=1.48]Epoch 14:   2%|▏         | 15/1000 [1:05:45<71:38:30, 261.84s/it, lr=0.001, test_MAE=0.823, time=261, train_MAE=0.637, train_loss=1.35, val_MAE=0.791, val_loss=1.48]Epoch 15:   2%|▏         | 15/1000 [1:05:45<71:38:30, 261.84s/it, lr=0.001, test_MAE=0.823, time=261, train_MAE=0.637, train_loss=1.35, val_MAE=0.791, val_loss=1.48]Epoch 15:   2%|▏         | 15/1000 [1:10:07<71:38:30, 261.84s/it, lr=0.001, test_MAE=0.722, time=262, train_MAE=0.639, train_loss=1.3, val_MAE=0.674, val_loss=1.31] Epoch 15:   2%|▏         | 16/1000 [1:10:07<71:33:51, 261.82s/it, lr=0.001, test_MAE=0.722, time=262, train_MAE=0.639, train_loss=1.3, val_MAE=0.674, val_loss=1.31]Epoch 16:   2%|▏         | 16/1000 [1:10:07<71:33:51, 261.82s/it, lr=0.001, test_MAE=0.722, time=262, train_MAE=0.639, train_loss=1.3, val_MAE=0.674, val_loss=1.31]Epoch 16:   2%|▏         | 16/1000 [1:14:29<71:33:51, 261.82s/it, lr=0.001, test_MAE=0.87, time=263, train_MAE=0.626, train_loss=1.25, val_MAE=0.842, val_loss=1.44]Epoch 16:   2%|▏         | 17/1000 [1:14:29<71:33:33, 262.07s/it, lr=0.001, test_MAE=0.87, time=263, train_MAE=0.626, train_loss=1.25, val_MAE=0.842, val_loss=1.44]Epoch 17:   2%|▏         | 17/1000 [1:14:29<71:33:33, 262.07s/it, lr=0.001, test_MAE=0.87, time=263, train_MAE=0.626, train_loss=1.25, val_MAE=0.842, val_loss=1.44]Epoch 17:   2%|▏         | 17/1000 [1:18:51<71:33:33, 262.07s/it, lr=0.001, test_MAE=0.652, time=261, train_MAE=0.624, train_loss=1.21, val_MAE=0.618, val_loss=1.19]Epoch 17:   2%|▏         | 18/1000 [1:18:51<71:25:40, 261.85s/it, lr=0.001, test_MAE=0.652, time=261, train_MAE=0.624, train_loss=1.21, val_MAE=0.618, val_loss=1.19]Epoch 18:   2%|▏         | 18/1000 [1:18:51<71:25:40, 261.85s/it, lr=0.001, test_MAE=0.652, time=261, train_MAE=0.624, train_loss=1.21, val_MAE=0.618, val_loss=1.19]Epoch 18:   2%|▏         | 18/1000 [1:23:13<71:25:40, 261.85s/it, lr=0.001, test_MAE=0.727, time=262, train_MAE=0.615, train_loss=1.16, val_MAE=0.693, val_loss=1.22]Epoch 18:   2%|▏         | 19/1000 [1:23:13<71:22:09, 261.91s/it, lr=0.001, test_MAE=0.727, time=262, train_MAE=0.615, train_loss=1.16, val_MAE=0.693, val_loss=1.22]Epoch 19:   2%|▏         | 19/1000 [1:23:13<71:22:09, 261.91s/it, lr=0.001, test_MAE=0.727, time=262, train_MAE=0.615, train_loss=1.16, val_MAE=0.693, val_loss=1.22]Epoch 19:   2%|▏         | 19/1000 [1:27:35<71:22:09, 261.91s/it, lr=0.001, test_MAE=0.746, time=263, train_MAE=0.618, train_loss=1.14, val_MAE=0.698, val_loss=1.21]Epoch 19:   2%|▏         | 20/1000 [1:27:35<71:21:21, 262.12s/it, lr=0.001, test_MAE=0.746, time=263, train_MAE=0.618, train_loss=1.14, val_MAE=0.698, val_loss=1.21]Epoch 20:   2%|▏         | 20/1000 [1:27:35<71:21:21, 262.12s/it, lr=0.001, test_MAE=0.746, time=263, train_MAE=0.618, train_loss=1.14, val_MAE=0.698, val_loss=1.21]Epoch 20:   2%|▏         | 20/1000 [1:31:56<71:21:21, 262.12s/it, lr=0.001, test_MAE=1.02, time=261, train_MAE=0.626, train_loss=1.13, val_MAE=0.955, val_loss=1.44] Epoch 20:   2%|▏         | 21/1000 [1:31:56<71:11:51, 261.81s/it, lr=0.001, test_MAE=1.02, time=261, train_MAE=0.626, train_loss=1.13, val_MAE=0.955, val_loss=1.44]Epoch 21:   2%|▏         | 21/1000 [1:31:56<71:11:51, 261.81s/it, lr=0.001, test_MAE=1.02, time=261, train_MAE=0.626, train_loss=1.13, val_MAE=0.955, val_loss=1.44]Epoch 21:   2%|▏         | 21/1000 [1:36:18<71:11:51, 261.81s/it, lr=0.001, test_MAE=0.956, time=262, train_MAE=0.622, train_loss=1.1, val_MAE=0.901, val_loss=1.36]Epoch 21:   2%|▏         | 22/1000 [1:36:18<71:08:07, 261.85s/it, lr=0.001, test_MAE=0.956, time=262, train_MAE=0.622, train_loss=1.1, val_MAE=0.901, val_loss=1.36]Epoch 22:   2%|▏         | 22/1000 [1:36:18<71:08:07, 261.85s/it, lr=0.001, test_MAE=0.956, time=262, train_MAE=0.622, train_loss=1.1, val_MAE=0.901, val_loss=1.36]Epoch 22:   2%|▏         | 22/1000 [1:40:41<71:08:07, 261.85s/it, lr=0.001, test_MAE=0.786, time=263, train_MAE=0.614, train_loss=1.07, val_MAE=0.746, val_loss=1.19]Epoch 22:   2%|▏         | 23/1000 [1:40:41<71:08:34, 262.14s/it, lr=0.001, test_MAE=0.786, time=263, train_MAE=0.614, train_loss=1.07, val_MAE=0.746, val_loss=1.19]Epoch 23:   2%|▏         | 23/1000 [1:40:41<71:08:34, 262.14s/it, lr=0.001, test_MAE=0.786, time=263, train_MAE=0.614, train_loss=1.07, val_MAE=0.746, val_loss=1.19]Epoch 23:   2%|▏         | 23/1000 [1:45:02<71:08:34, 262.14s/it, lr=0.001, test_MAE=0.875, time=261, train_MAE=0.633, train_loss=1.07, val_MAE=0.834, val_loss=1.26]Epoch    24: reducing learning rate of group 0 to 5.0000e-04.
Epoch 23:   2%|▏         | 24/1000 [1:45:02<70:59:41, 261.87s/it, lr=0.001, test_MAE=0.875, time=261, train_MAE=0.633, train_loss=1.07, val_MAE=0.834, val_loss=1.26]Epoch 24:   2%|▏         | 24/1000 [1:45:02<70:59:41, 261.87s/it, lr=0.001, test_MAE=0.875, time=261, train_MAE=0.633, train_loss=1.07, val_MAE=0.834, val_loss=1.26]Epoch 24:   2%|▏         | 24/1000 [1:49:24<70:59:41, 261.87s/it, lr=0.0005, test_MAE=0.658, time=262, train_MAE=0.603, train_loss=1.02, val_MAE=0.624, val_loss=1.03]Epoch 24:   2%|▎         | 25/1000 [1:49:24<70:54:55, 261.84s/it, lr=0.0005, test_MAE=0.658, time=262, train_MAE=0.603, train_loss=1.02, val_MAE=0.624, val_loss=1.03]Epoch 25:   2%|▎         | 25/1000 [1:49:24<70:54:55, 261.84s/it, lr=0.0005, test_MAE=0.658, time=262, train_MAE=0.603, train_loss=1.02, val_MAE=0.624, val_loss=1.03]Epoch 25:   2%|▎         | 25/1000 [1:53:48<70:54:55, 261.84s/it, lr=0.0005, test_MAE=0.628, time=264, train_MAE=0.597, train_loss=1, val_MAE=0.593, val_loss=0.995]  Epoch 25:   3%|▎         | 26/1000 [1:53:48<71:02:08, 262.56s/it, lr=0.0005, test_MAE=0.628, time=264, train_MAE=0.597, train_loss=1, val_MAE=0.593, val_loss=0.995]Epoch 26:   3%|▎         | 26/1000 [1:53:48<71:02:08, 262.56s/it, lr=0.0005, test_MAE=0.628, time=264, train_MAE=0.597, train_loss=1, val_MAE=0.593, val_loss=0.995]Epoch 26:   3%|▎         | 26/1000 [1:58:11<71:02:08, 262.56s/it, lr=0.0005, test_MAE=0.663, time=263, train_MAE=0.592, train_loss=0.991, val_MAE=0.604, val_loss=1]Epoch 26:   3%|▎         | 27/1000 [1:58:11<70:59:59, 262.69s/it, lr=0.0005, test_MAE=0.663, time=263, train_MAE=0.592, train_loss=0.991, val_MAE=0.604, val_loss=1]Epoch 27:   3%|▎         | 27/1000 [1:58:11<70:59:59, 262.69s/it, lr=0.0005, test_MAE=0.663, time=263, train_MAE=0.592, train_loss=0.991, val_MAE=0.604, val_loss=1]Epoch 27:   3%|▎         | 27/1000 [2:02:35<70:59:59, 262.69s/it, lr=0.0005, test_MAE=0.899, time=264, train_MAE=0.6, train_loss=0.993, val_MAE=0.883, val_loss=1.27]Epoch 27:   3%|▎         | 28/1000 [2:02:35<71:00:05, 262.97s/it, lr=0.0005, test_MAE=0.899, time=264, train_MAE=0.6, train_loss=0.993, val_MAE=0.883, val_loss=1.27]Epoch 28:   3%|▎         | 28/1000 [2:02:35<71:00:05, 262.97s/it, lr=0.0005, test_MAE=0.899, time=264, train_MAE=0.6, train_loss=0.993, val_MAE=0.883, val_loss=1.27]Epoch 28:   3%|▎         | 28/1000 [2:06:57<71:00:05, 262.97s/it, lr=0.0005, test_MAE=0.653, time=262, train_MAE=0.598, train_loss=0.983, val_MAE=0.622, val_loss=1] Epoch 28:   3%|▎         | 29/1000 [2:06:57<70:51:08, 262.69s/it, lr=0.0005, test_MAE=0.653, time=262, train_MAE=0.598, train_loss=0.983, val_MAE=0.622, val_loss=1]Epoch 29:   3%|▎         | 29/1000 [2:06:57<70:51:08, 262.69s/it, lr=0.0005, test_MAE=0.653, time=262, train_MAE=0.598, train_loss=0.983, val_MAE=0.622, val_loss=1]Epoch 29:   3%|▎         | 29/1000 [2:11:08<70:51:08, 262.69s/it, lr=0.0005, test_MAE=0.674, time=251, train_MAE=0.6, train_loss=0.982, val_MAE=0.635, val_loss=1.01]Epoch 29:   3%|▎         | 30/1000 [2:11:08<69:49:53, 259.17s/it, lr=0.0005, test_MAE=0.674, time=251, train_MAE=0.6, train_loss=0.982, val_MAE=0.635, val_loss=1.01]Epoch 30:   3%|▎         | 30/1000 [2:11:08<69:49:53, 259.17s/it, lr=0.0005, test_MAE=0.674, time=251, train_MAE=0.6, train_loss=0.982, val_MAE=0.635, val_loss=1.01]Epoch 30:   3%|▎         | 30/1000 [2:15:15<69:49:53, 259.17s/it, lr=0.0005, test_MAE=0.813, time=247, train_MAE=0.597, train_loss=0.972, val_MAE=0.765, val_loss=1.14]Epoch 30:   3%|▎         | 31/1000 [2:15:16<68:48:50, 255.66s/it, lr=0.0005, test_MAE=0.813, time=247, train_MAE=0.597, train_loss=0.972, val_MAE=0.765, val_loss=1.14]Epoch 31:   3%|▎         | 31/1000 [2:15:16<68:48:50, 255.66s/it, lr=0.0005, test_MAE=0.813, time=247, train_MAE=0.597, train_loss=0.972, val_MAE=0.765, val_loss=1.14]Epoch 31:   3%|▎         | 31/1000 [2:19:24<68:48:50, 255.66s/it, lr=0.0005, test_MAE=0.912, time=248, train_MAE=0.594, train_loss=0.963, val_MAE=0.878, val_loss=1.24]Epoch    32: reducing learning rate of group 0 to 2.5000e-04.
Epoch 31:   3%|▎         | 32/1000 [2:19:24<68:07:43, 253.37s/it, lr=0.0005, test_MAE=0.912, time=248, train_MAE=0.594, train_loss=0.963, val_MAE=0.878, val_loss=1.24]Epoch 32:   3%|▎         | 32/1000 [2:19:24<68:07:43, 253.37s/it, lr=0.0005, test_MAE=0.912, time=248, train_MAE=0.594, train_loss=0.963, val_MAE=0.878, val_loss=1.24]Epoch 32:   3%|▎         | 32/1000 [2:23:30<68:07:43, 253.37s/it, lr=0.00025, test_MAE=0.733, time=246, train_MAE=0.588, train_loss=0.949, val_MAE=0.692, val_loss=1.05]Epoch 32:   3%|▎         | 33/1000 [2:23:30<67:28:39, 251.21s/it, lr=0.00025, test_MAE=0.733, time=246, train_MAE=0.588, train_loss=0.949, val_MAE=0.692, val_loss=1.05]Epoch 33:   3%|▎         | 33/1000 [2:23:30<67:28:39, 251.21s/it, lr=0.00025, test_MAE=0.733, time=246, train_MAE=0.588, train_loss=0.949, val_MAE=0.692, val_loss=1.05]Epoch 33:   3%|▎         | 33/1000 [2:27:35<67:28:39, 251.21s/it, lr=0.00025, test_MAE=0.682, time=246, train_MAE=0.577, train_loss=0.935, val_MAE=0.65, val_loss=1.01] Epoch 33:   3%|▎         | 34/1000 [2:27:35<66:57:50, 249.55s/it, lr=0.00025, test_MAE=0.682, time=246, train_MAE=0.577, train_loss=0.935, val_MAE=0.65, val_loss=1.01]Epoch 34:   3%|▎         | 34/1000 [2:27:35<66:57:50, 249.55s/it, lr=0.00025, test_MAE=0.682, time=246, train_MAE=0.577, train_loss=0.935, val_MAE=0.65, val_loss=1.01]Epoch 34:   3%|▎         | 34/1000 [2:31:42<66:57:50, 249.55s/it, lr=0.00025, test_MAE=0.706, time=246, train_MAE=0.572, train_loss=0.927, val_MAE=0.675, val_loss=1.03]Epoch 34:   4%|▎         | 35/1000 [2:31:42<66:38:39, 248.62s/it, lr=0.00025, test_MAE=0.706, time=246, train_MAE=0.572, train_loss=0.927, val_MAE=0.675, val_loss=1.03]Epoch 35:   4%|▎         | 35/1000 [2:31:42<66:38:39, 248.62s/it, lr=0.00025, test_MAE=0.706, time=246, train_MAE=0.572, train_loss=0.927, val_MAE=0.675, val_loss=1.03]Epoch 35:   4%|▎         | 35/1000 [2:35:47<66:38:39, 248.62s/it, lr=0.00025, test_MAE=0.631, time=245, train_MAE=0.579, train_loss=0.931, val_MAE=0.593, val_loss=0.944]Epoch 35:   4%|▎         | 36/1000 [2:35:47<66:17:22, 247.55s/it, lr=0.00025, test_MAE=0.631, time=245, train_MAE=0.579, train_loss=0.931, val_MAE=0.593, val_loss=0.944]Epoch 36:   4%|▎         | 36/1000 [2:35:47<66:17:22, 247.55s/it, lr=0.00025, test_MAE=0.631, time=245, train_MAE=0.579, train_loss=0.931, val_MAE=0.593, val_loss=0.944]Epoch 36:   4%|▎         | 36/1000 [2:39:52<66:17:22, 247.55s/it, lr=0.00025, test_MAE=0.714, time=246, train_MAE=0.582, train_loss=0.933, val_MAE=0.677, val_loss=1.03] Epoch 36:   4%|▎         | 37/1000 [2:39:52<66:03:34, 246.95s/it, lr=0.00025, test_MAE=0.714, time=246, train_MAE=0.582, train_loss=0.933, val_MAE=0.677, val_loss=1.03]Epoch 37:   4%|▎         | 37/1000 [2:39:52<66:03:34, 246.95s/it, lr=0.00025, test_MAE=0.714, time=246, train_MAE=0.582, train_loss=0.933, val_MAE=0.677, val_loss=1.03]Epoch 37:   4%|▎         | 37/1000 [2:43:59<66:03:34, 246.95s/it, lr=0.00025, test_MAE=1.08, time=246, train_MAE=0.568, train_loss=0.917, val_MAE=1.02, val_loss=1.37]  Epoch 37:   4%|▍         | 38/1000 [2:43:59<65:57:00, 246.80s/it, lr=0.00025, test_MAE=1.08, time=246, train_MAE=0.568, train_loss=0.917, val_MAE=1.02, val_loss=1.37]Epoch 38:   4%|▍         | 38/1000 [2:43:59<65:57:00, 246.80s/it, lr=0.00025, test_MAE=1.08, time=246, train_MAE=0.568, train_loss=0.917, val_MAE=1.02, val_loss=1.37]Epoch 38:   4%|▍         | 38/1000 [2:48:04<65:57:00, 246.80s/it, lr=0.00025, test_MAE=0.625, time=245, train_MAE=0.574, train_loss=0.92, val_MAE=0.599, val_loss=0.944]Epoch 38:   4%|▍         | 39/1000 [2:48:04<65:45:25, 246.33s/it, lr=0.00025, test_MAE=0.625, time=245, train_MAE=0.574, train_loss=0.92, val_MAE=0.599, val_loss=0.944]Epoch 39:   4%|▍         | 39/1000 [2:48:04<65:45:25, 246.33s/it, lr=0.00025, test_MAE=0.625, time=245, train_MAE=0.574, train_loss=0.92, val_MAE=0.599, val_loss=0.944]Epoch 39:   4%|▍         | 39/1000 [2:52:10<65:45:25, 246.33s/it, lr=0.00025, test_MAE=0.645, time=246, train_MAE=0.56, train_loss=0.904, val_MAE=0.61, val_loss=0.953] Epoch 39:   4%|▍         | 40/1000 [2:52:10<65:38:23, 246.15s/it, lr=0.00025, test_MAE=0.645, time=246, train_MAE=0.56, train_loss=0.904, val_MAE=0.61, val_loss=0.953]Epoch 40:   4%|▍         | 40/1000 [2:52:10<65:38:23, 246.15s/it, lr=0.00025, test_MAE=0.645, time=246, train_MAE=0.56, train_loss=0.904, val_MAE=0.61, val_loss=0.953]Epoch 40:   4%|▍         | 40/1000 [2:56:16<65:38:23, 246.15s/it, lr=0.00025, test_MAE=0.993, time=246, train_MAE=0.566, train_loss=0.908, val_MAE=0.935, val_loss=1.28]Epoch 40:   4%|▍         | 41/1000 [2:56:16<65:35:20, 246.22s/it, lr=0.00025, test_MAE=0.993, time=246, train_MAE=0.566, train_loss=0.908, val_MAE=0.935, val_loss=1.28]Epoch 41:   4%|▍         | 41/1000 [2:56:16<65:35:20, 246.22s/it, lr=0.00025, test_MAE=0.993, time=246, train_MAE=0.566, train_loss=0.908, val_MAE=0.935, val_loss=1.28]Epoch 41:   4%|▍         | 41/1000 [3:00:21<65:35:20, 246.22s/it, lr=0.00025, test_MAE=0.745, time=245, train_MAE=0.568, train_loss=0.908, val_MAE=0.689, val_loss=1.03]Epoch 41:   4%|▍         | 42/1000 [3:00:21<65:26:00, 245.89s/it, lr=0.00025, test_MAE=0.745, time=245, train_MAE=0.568, train_loss=0.908, val_MAE=0.689, val_loss=1.03]Epoch 42:   4%|▍         | 42/1000 [3:00:21<65:26:00, 245.89s/it, lr=0.00025, test_MAE=0.745, time=245, train_MAE=0.568, train_loss=0.908, val_MAE=0.689, val_loss=1.03]Epoch 42:   4%|▍         | 42/1000 [3:04:27<65:26:00, 245.89s/it, lr=0.00025, test_MAE=1.09, time=246, train_MAE=0.57, train_loss=0.909, val_MAE=1.06, val_loss=1.4]    Epoch 42:   4%|▍         | 43/1000 [3:04:27<65:20:46, 245.82s/it, lr=0.00025, test_MAE=1.09, time=246, train_MAE=0.57, train_loss=0.909, val_MAE=1.06, val_loss=1.4]Epoch 43:   4%|▍         | 43/1000 [3:04:27<65:20:46, 245.82s/it, lr=0.00025, test_MAE=1.09, time=246, train_MAE=0.57, train_loss=0.909, val_MAE=1.06, val_loss=1.4]Epoch 43:   4%|▍         | 43/1000 [3:08:33<65:20:46, 245.82s/it, lr=0.00025, test_MAE=0.634, time=246, train_MAE=0.567, train_loss=0.904, val_MAE=0.592, val_loss=0.927]Epoch 43:   4%|▍         | 44/1000 [3:08:33<65:18:49, 245.95s/it, lr=0.00025, test_MAE=0.634, time=246, train_MAE=0.567, train_loss=0.904, val_MAE=0.592, val_loss=0.927]Epoch 44:   4%|▍         | 44/1000 [3:08:33<65:18:49, 245.95s/it, lr=0.00025, test_MAE=0.634, time=246, train_MAE=0.567, train_loss=0.904, val_MAE=0.592, val_loss=0.927]Epoch 44:   4%|▍         | 44/1000 [3:12:38<65:18:49, 245.95s/it, lr=0.00025, test_MAE=0.674, time=245, train_MAE=0.566, train_loss=0.901, val_MAE=0.629, val_loss=0.962]Epoch 44:   4%|▍         | 45/1000 [3:12:38<65:10:10, 245.67s/it, lr=0.00025, test_MAE=0.674, time=245, train_MAE=0.566, train_loss=0.901, val_MAE=0.629, val_loss=0.962]Epoch 45:   4%|▍         | 45/1000 [3:12:38<65:10:10, 245.67s/it, lr=0.00025, test_MAE=0.674, time=245, train_MAE=0.566, train_loss=0.901, val_MAE=0.629, val_loss=0.962]Epoch 45:   4%|▍         | 45/1000 [3:16:44<65:10:10, 245.67s/it, lr=0.00025, test_MAE=0.722, time=246, train_MAE=0.564, train_loss=0.898, val_MAE=0.677, val_loss=1.01] Epoch 45:   5%|▍         | 46/1000 [3:16:44<65:05:41, 245.64s/it, lr=0.00025, test_MAE=0.722, time=246, train_MAE=0.564, train_loss=0.898, val_MAE=0.677, val_loss=1.01]Epoch 46:   5%|▍         | 46/1000 [3:16:44<65:05:41, 245.64s/it, lr=0.00025, test_MAE=0.722, time=246, train_MAE=0.564, train_loss=0.898, val_MAE=0.677, val_loss=1.01]Epoch 46:   5%|▍         | 46/1000 [3:20:50<65:05:41, 245.64s/it, lr=0.00025, test_MAE=0.752, time=246, train_MAE=0.559, train_loss=0.891, val_MAE=0.709, val_loss=1.04]Epoch 46:   5%|▍         | 47/1000 [3:20:50<65:04:54, 245.85s/it, lr=0.00025, test_MAE=0.752, time=246, train_MAE=0.559, train_loss=0.891, val_MAE=0.709, val_loss=1.04]Epoch 47:   5%|▍         | 47/1000 [3:20:50<65:04:54, 245.85s/it, lr=0.00025, test_MAE=0.752, time=246, train_MAE=0.559, train_loss=0.891, val_MAE=0.709, val_loss=1.04]Epoch 47:   5%|▍         | 47/1000 [3:24:55<65:04:54, 245.85s/it, lr=0.00025, test_MAE=0.708, time=245, train_MAE=0.568, train_loss=0.899, val_MAE=0.696, val_loss=1.03]Epoch 47:   5%|▍         | 48/1000 [3:24:55<64:56:11, 245.56s/it, lr=0.00025, test_MAE=0.708, time=245, train_MAE=0.568, train_loss=0.899, val_MAE=0.696, val_loss=1.03]Epoch 48:   5%|▍         | 48/1000 [3:24:55<64:56:11, 245.56s/it, lr=0.00025, test_MAE=0.708, time=245, train_MAE=0.568, train_loss=0.899, val_MAE=0.696, val_loss=1.03]Epoch 48:   5%|▍         | 48/1000 [3:29:01<64:56:11, 245.56s/it, lr=0.00025, test_MAE=0.796, time=246, train_MAE=0.567, train_loss=0.895, val_MAE=0.756, val_loss=1.08]Epoch 48:   5%|▍         | 49/1000 [3:29:01<64:52:12, 245.57s/it, lr=0.00025, test_MAE=0.796, time=246, train_MAE=0.567, train_loss=0.895, val_MAE=0.756, val_loss=1.08]Epoch 49:   5%|▍         | 49/1000 [3:29:01<64:52:12, 245.57s/it, lr=0.00025, test_MAE=0.796, time=246, train_MAE=0.567, train_loss=0.895, val_MAE=0.756, val_loss=1.08]Epoch 49:   5%|▍         | 49/1000 [3:33:07<64:52:12, 245.57s/it, lr=0.00025, test_MAE=0.644, time=246, train_MAE=0.565, train_loss=0.893, val_MAE=0.607, val_loss=0.934]Epoch    50: reducing learning rate of group 0 to 1.2500e-04.
Epoch 49:   5%|▌         | 50/1000 [3:33:07<64:51:58, 245.81s/it, lr=0.00025, test_MAE=0.644, time=246, train_MAE=0.565, train_loss=0.893, val_MAE=0.607, val_loss=0.934]Epoch 50:   5%|▌         | 50/1000 [3:33:07<64:51:58, 245.81s/it, lr=0.00025, test_MAE=0.644, time=246, train_MAE=0.565, train_loss=0.893, val_MAE=0.607, val_loss=0.934]Epoch 50:   5%|▌         | 50/1000 [3:37:12<64:51:58, 245.81s/it, lr=0.000125, test_MAE=0.629, time=245, train_MAE=0.558, train_loss=0.882, val_MAE=0.59, val_loss=0.913]Epoch 50:   5%|▌         | 51/1000 [3:37:12<64:44:32, 245.60s/it, lr=0.000125, test_MAE=0.629, time=245, train_MAE=0.558, train_loss=0.882, val_MAE=0.59, val_loss=0.913]Epoch 51:   5%|▌         | 51/1000 [3:37:12<64:44:32, 245.60s/it, lr=0.000125, test_MAE=0.629, time=245, train_MAE=0.558, train_loss=0.882, val_MAE=0.59, val_loss=0.913]Epoch 51:   5%|▌         | 51/1000 [3:41:18<64:44:32, 245.60s/it, lr=0.000125, test_MAE=0.617, time=246, train_MAE=0.544, train_loss=0.866, val_MAE=0.588, val_loss=0.91]Epoch 51:   5%|▌         | 52/1000 [3:41:18<64:40:39, 245.61s/it, lr=0.000125, test_MAE=0.617, time=246, train_MAE=0.544, train_loss=0.866, val_MAE=0.588, val_loss=0.91]Epoch 52:   5%|▌         | 52/1000 [3:41:18<64:40:39, 245.61s/it, lr=0.000125, test_MAE=0.617, time=246, train_MAE=0.544, train_loss=0.866, val_MAE=0.588, val_loss=0.91]Epoch 52:   5%|▌         | 52/1000 [3:45:24<64:40:39, 245.61s/it, lr=0.000125, test_MAE=0.69, time=247, train_MAE=0.543, train_loss=0.865, val_MAE=0.648, val_loss=0.969]Epoch 52:   5%|▌         | 53/1000 [3:45:24<64:41:08, 245.90s/it, lr=0.000125, test_MAE=0.69, time=247, train_MAE=0.543, train_loss=0.865, val_MAE=0.648, val_loss=0.969]Epoch 53:   5%|▌         | 53/1000 [3:45:24<64:41:08, 245.90s/it, lr=0.000125, test_MAE=0.69, time=247, train_MAE=0.543, train_loss=0.865, val_MAE=0.648, val_loss=0.969]Epoch 53:   5%|▌         | 53/1000 [3:49:29<64:41:08, 245.90s/it, lr=0.000125, test_MAE=0.616, time=245, train_MAE=0.545, train_loss=0.866, val_MAE=0.586, val_loss=0.907]Epoch 53:   5%|▌         | 54/1000 [3:49:29<64:32:58, 245.64s/it, lr=0.000125, test_MAE=0.616, time=245, train_MAE=0.545, train_loss=0.866, val_MAE=0.586, val_loss=0.907]Epoch 54:   5%|▌         | 54/1000 [3:49:29<64:32:58, 245.64s/it, lr=0.000125, test_MAE=0.616, time=245, train_MAE=0.545, train_loss=0.866, val_MAE=0.586, val_loss=0.907]Epoch 54:   5%|▌         | 54/1000 [3:53:35<64:32:58, 245.64s/it, lr=0.000125, test_MAE=0.877, time=246, train_MAE=0.545, train_loss=0.866, val_MAE=0.838, val_loss=1.16] Epoch 54:   6%|▌         | 55/1000 [3:53:35<64:29:09, 245.66s/it, lr=0.000125, test_MAE=0.877, time=246, train_MAE=0.545, train_loss=0.866, val_MAE=0.838, val_loss=1.16]Epoch 55:   6%|▌         | 55/1000 [3:53:35<64:29:09, 245.66s/it, lr=0.000125, test_MAE=0.877, time=246, train_MAE=0.545, train_loss=0.866, val_MAE=0.838, val_loss=1.16]Epoch 55:   6%|▌         | 55/1000 [3:57:42<64:29:09, 245.66s/it, lr=0.000125, test_MAE=0.633, time=246, train_MAE=0.555, train_loss=0.875, val_MAE=0.597, val_loss=0.916]Epoch 55:   6%|▌         | 56/1000 [3:57:42<64:29:03, 245.91s/it, lr=0.000125, test_MAE=0.633, time=246, train_MAE=0.555, train_loss=0.875, val_MAE=0.597, val_loss=0.916]Epoch 56:   6%|▌         | 56/1000 [3:57:42<64:29:03, 245.91s/it, lr=0.000125, test_MAE=0.633, time=246, train_MAE=0.555, train_loss=0.875, val_MAE=0.597, val_loss=0.916]Epoch 56:   6%|▌         | 56/1000 [4:01:48<64:29:03, 245.91s/it, lr=0.000125, test_MAE=0.746, time=246, train_MAE=0.544, train_loss=0.863, val_MAE=0.709, val_loss=1.03] Epoch 56:   6%|▌         | 57/1000 [4:01:48<64:27:26, 246.07s/it, lr=0.000125, test_MAE=0.746, time=246, train_MAE=0.544, train_loss=0.863, val_MAE=0.709, val_loss=1.03]Epoch 57:   6%|▌         | 57/1000 [4:01:48<64:27:26, 246.07s/it, lr=0.000125, test_MAE=0.746, time=246, train_MAE=0.544, train_loss=0.863, val_MAE=0.709, val_loss=1.03]Epoch 57:   6%|▌         | 57/1000 [4:05:57<64:27:26, 246.07s/it, lr=0.000125, test_MAE=0.698, time=249, train_MAE=0.537, train_loss=0.855, val_MAE=0.65, val_loss=0.968]Epoch 57:   6%|▌         | 58/1000 [4:05:57<64:35:00, 246.82s/it, lr=0.000125, test_MAE=0.698, time=249, train_MAE=0.537, train_loss=0.855, val_MAE=0.65, val_loss=0.968]Epoch 58:   6%|▌         | 58/1000 [4:05:57<64:35:00, 246.82s/it, lr=0.000125, test_MAE=0.698, time=249, train_MAE=0.537, train_loss=0.855, val_MAE=0.65, val_loss=0.968]Epoch 58:   6%|▌         | 58/1000 [4:10:06<64:35:00, 246.82s/it, lr=0.000125, test_MAE=0.646, time=249, train_MAE=0.543, train_loss=0.861, val_MAE=0.612, val_loss=0.929]Epoch 58:   6%|▌         | 59/1000 [4:10:06<64:41:43, 247.51s/it, lr=0.000125, test_MAE=0.646, time=249, train_MAE=0.543, train_loss=0.861, val_MAE=0.612, val_loss=0.929]Epoch 59:   6%|▌         | 59/1000 [4:10:06<64:41:43, 247.51s/it, lr=0.000125, test_MAE=0.646, time=249, train_MAE=0.543, train_loss=0.861, val_MAE=0.612, val_loss=0.929]Epoch 59:   6%|▌         | 59/1000 [4:14:14<64:41:43, 247.51s/it, lr=0.000125, test_MAE=0.682, time=248, train_MAE=0.549, train_loss=0.867, val_MAE=0.643, val_loss=0.96] Epoch    60: reducing learning rate of group 0 to 6.2500e-05.
Epoch 59:   6%|▌         | 60/1000 [4:14:14<64:39:31, 247.63s/it, lr=0.000125, test_MAE=0.682, time=248, train_MAE=0.549, train_loss=0.867, val_MAE=0.643, val_loss=0.96]Epoch 60:   6%|▌         | 60/1000 [4:14:14<64:39:31, 247.63s/it, lr=0.000125, test_MAE=0.682, time=248, train_MAE=0.549, train_loss=0.867, val_MAE=0.643, val_loss=0.96]Epoch 60:   6%|▌         | 60/1000 [4:18:22<64:39:31, 247.63s/it, lr=6.25e-5, test_MAE=0.615, time=248, train_MAE=0.528, train_loss=0.844, val_MAE=0.585, val_loss=0.9]  Epoch 60:   6%|▌         | 61/1000 [4:18:22<64:38:58, 247.86s/it, lr=6.25e-5, test_MAE=0.615, time=248, train_MAE=0.528, train_loss=0.844, val_MAE=0.585, val_loss=0.9]Epoch 61:   6%|▌         | 61/1000 [4:18:22<64:38:58, 247.86s/it, lr=6.25e-5, test_MAE=0.615, time=248, train_MAE=0.528, train_loss=0.844, val_MAE=0.585, val_loss=0.9]Epoch 61:   6%|▌         | 61/1000 [4:22:31<64:38:58, 247.86s/it, lr=6.25e-5, test_MAE=0.655, time=249, train_MAE=0.53, train_loss=0.845, val_MAE=0.62, val_loss=0.934]Epoch 61:   6%|▌         | 62/1000 [4:22:31<64:40:52, 248.24s/it, lr=6.25e-5, test_MAE=0.655, time=249, train_MAE=0.53, train_loss=0.845, val_MAE=0.62, val_loss=0.934]Epoch 62:   6%|▌         | 62/1000 [4:22:31<64:40:52, 248.24s/it, lr=6.25e-5, test_MAE=0.655, time=249, train_MAE=0.53, train_loss=0.845, val_MAE=0.62, val_loss=0.934]Epoch 62:   6%|▌         | 62/1000 [4:26:39<64:40:52, 248.24s/it, lr=6.25e-5, test_MAE=0.616, time=248, train_MAE=0.532, train_loss=0.847, val_MAE=0.584, val_loss=0.898]Epoch 62:   6%|▋         | 63/1000 [4:26:39<64:35:05, 248.14s/it, lr=6.25e-5, test_MAE=0.616, time=248, train_MAE=0.532, train_loss=0.847, val_MAE=0.584, val_loss=0.898]Epoch 63:   6%|▋         | 63/1000 [4:26:39<64:35:05, 248.14s/it, lr=6.25e-5, test_MAE=0.616, time=248, train_MAE=0.532, train_loss=0.847, val_MAE=0.584, val_loss=0.898]Epoch 63:   6%|▋         | 63/1000 [4:30:48<64:35:05, 248.14s/it, lr=6.25e-5, test_MAE=0.691, time=249, train_MAE=0.528, train_loss=0.842, val_MAE=0.658, val_loss=0.972]Epoch 63:   6%|▋         | 64/1000 [4:30:48<64:34:20, 248.36s/it, lr=6.25e-5, test_MAE=0.691, time=249, train_MAE=0.528, train_loss=0.842, val_MAE=0.658, val_loss=0.972]Epoch 64:   6%|▋         | 64/1000 [4:30:48<64:34:20, 248.36s/it, lr=6.25e-5, test_MAE=0.691, time=249, train_MAE=0.528, train_loss=0.842, val_MAE=0.658, val_loss=0.972]Epoch 64:   6%|▋         | 64/1000 [4:34:56<64:34:20, 248.36s/it, lr=6.25e-5, test_MAE=0.71, time=248, train_MAE=0.537, train_loss=0.851, val_MAE=0.676, val_loss=0.99]  Epoch 64:   6%|▋         | 65/1000 [4:34:56<64:29:11, 248.29s/it, lr=6.25e-5, test_MAE=0.71, time=248, train_MAE=0.537, train_loss=0.851, val_MAE=0.676, val_loss=0.99]Epoch 65:   6%|▋         | 65/1000 [4:34:56<64:29:11, 248.29s/it, lr=6.25e-5, test_MAE=0.71, time=248, train_MAE=0.537, train_loss=0.851, val_MAE=0.676, val_loss=0.99]Epoch 65:   6%|▋         | 65/1000 [4:39:03<64:29:11, 248.29s/it, lr=6.25e-5, test_MAE=0.622, time=247, train_MAE=0.523, train_loss=0.837, val_MAE=0.587, val_loss=0.9]Epoch 65:   7%|▋         | 66/1000 [4:39:03<64:17:42, 247.82s/it, lr=6.25e-5, test_MAE=0.622, time=247, train_MAE=0.523, train_loss=0.837, val_MAE=0.587, val_loss=0.9]Epoch 66:   7%|▋         | 66/1000 [4:39:03<64:17:42, 247.82s/it, lr=6.25e-5, test_MAE=0.622, time=247, train_MAE=0.523, train_loss=0.837, val_MAE=0.587, val_loss=0.9]Epoch 66:   7%|▋         | 66/1000 [4:43:10<64:17:42, 247.82s/it, lr=6.25e-5, test_MAE=0.678, time=247, train_MAE=0.524, train_loss=0.837, val_MAE=0.64, val_loss=0.953]Epoch 66:   7%|▋         | 67/1000 [4:43:10<64:11:12, 247.67s/it, lr=6.25e-5, test_MAE=0.678, time=247, train_MAE=0.524, train_loss=0.837, val_MAE=0.64, val_loss=0.953]Epoch 67:   7%|▋         | 67/1000 [4:43:10<64:11:12, 247.67s/it, lr=6.25e-5, test_MAE=0.678, time=247, train_MAE=0.524, train_loss=0.837, val_MAE=0.64, val_loss=0.953]Epoch 67:   7%|▋         | 67/1000 [4:47:18<64:11:12, 247.67s/it, lr=6.25e-5, test_MAE=0.654, time=248, train_MAE=0.524, train_loss=0.837, val_MAE=0.62, val_loss=0.933]Epoch 67:   7%|▋         | 68/1000 [4:47:18<64:10:13, 247.87s/it, lr=6.25e-5, test_MAE=0.654, time=248, train_MAE=0.524, train_loss=0.837, val_MAE=0.62, val_loss=0.933]Epoch 68:   7%|▋         | 68/1000 [4:47:18<64:10:13, 247.87s/it, lr=6.25e-5, test_MAE=0.654, time=248, train_MAE=0.524, train_loss=0.837, val_MAE=0.62, val_loss=0.933]Epoch 68:   7%|▋         | 68/1000 [4:51:25<64:10:13, 247.87s/it, lr=6.25e-5, test_MAE=0.661, time=247, train_MAE=0.522, train_loss=0.834, val_MAE=0.616, val_loss=0.929]Epoch    69: reducing learning rate of group 0 to 3.1250e-05.
Epoch 68:   7%|▋         | 69/1000 [4:51:25<64:00:45, 247.52s/it, lr=6.25e-5, test_MAE=0.661, time=247, train_MAE=0.522, train_loss=0.834, val_MAE=0.616, val_loss=0.929]Epoch 69:   7%|▋         | 69/1000 [4:51:25<64:00:45, 247.52s/it, lr=6.25e-5, test_MAE=0.661, time=247, train_MAE=0.522, train_loss=0.834, val_MAE=0.616, val_loss=0.929]Epoch 69:   7%|▋         | 69/1000 [4:55:32<64:00:45, 247.52s/it, lr=3.13e-5, test_MAE=0.615, time=247, train_MAE=0.513, train_loss=0.825, val_MAE=0.586, val_loss=0.898]Epoch 69:   7%|▋         | 70/1000 [4:55:33<63:55:51, 247.48s/it, lr=3.13e-5, test_MAE=0.615, time=247, train_MAE=0.513, train_loss=0.825, val_MAE=0.586, val_loss=0.898]Epoch 70:   7%|▋         | 70/1000 [4:55:33<63:55:51, 247.48s/it, lr=3.13e-5, test_MAE=0.615, time=247, train_MAE=0.513, train_loss=0.825, val_MAE=0.586, val_loss=0.898]Epoch 70:   7%|▋         | 70/1000 [4:59:41<63:55:51, 247.48s/it, lr=3.13e-5, test_MAE=0.642, time=248, train_MAE=0.519, train_loss=0.831, val_MAE=0.612, val_loss=0.923]Epoch 70:   7%|▋         | 71/1000 [4:59:41<63:54:31, 247.66s/it, lr=3.13e-5, test_MAE=0.642, time=248, train_MAE=0.519, train_loss=0.831, val_MAE=0.612, val_loss=0.923]Epoch 71:   7%|▋         | 71/1000 [4:59:41<63:54:31, 247.66s/it, lr=3.13e-5, test_MAE=0.642, time=248, train_MAE=0.519, train_loss=0.831, val_MAE=0.612, val_loss=0.923]Epoch 71:   7%|▋         | 71/1000 [5:03:47<63:54:31, 247.66s/it, lr=3.13e-5, test_MAE=0.633, time=247, train_MAE=0.522, train_loss=0.833, val_MAE=0.603, val_loss=0.914]Epoch 71:   7%|▋         | 72/1000 [5:03:47<63:45:57, 247.37s/it, lr=3.13e-5, test_MAE=0.633, time=247, train_MAE=0.522, train_loss=0.833, val_MAE=0.603, val_loss=0.914]Epoch 72:   7%|▋         | 72/1000 [5:03:47<63:45:57, 247.37s/it, lr=3.13e-5, test_MAE=0.633, time=247, train_MAE=0.522, train_loss=0.833, val_MAE=0.603, val_loss=0.914]Epoch 72:   7%|▋         | 72/1000 [5:07:55<63:45:57, 247.37s/it, lr=3.13e-5, test_MAE=0.64, time=247, train_MAE=0.507, train_loss=0.818, val_MAE=0.612, val_loss=0.923] Epoch 72:   7%|▋         | 73/1000 [5:07:55<63:41:17, 247.33s/it, lr=3.13e-5, test_MAE=0.64, time=247, train_MAE=0.507, train_loss=0.818, val_MAE=0.612, val_loss=0.923]Epoch 73:   7%|▋         | 73/1000 [5:07:55<63:41:17, 247.33s/it, lr=3.13e-5, test_MAE=0.64, time=247, train_MAE=0.507, train_loss=0.818, val_MAE=0.612, val_loss=0.923]Epoch 73:   7%|▋         | 73/1000 [5:12:03<63:41:17, 247.33s/it, lr=3.13e-5, test_MAE=0.643, time=248, train_MAE=0.515, train_loss=0.826, val_MAE=0.618, val_loss=0.929]Epoch 73:   7%|▋         | 74/1000 [5:12:03<63:41:02, 247.58s/it, lr=3.13e-5, test_MAE=0.643, time=248, train_MAE=0.515, train_loss=0.826, val_MAE=0.618, val_loss=0.929]Epoch 74:   7%|▋         | 74/1000 [5:12:03<63:41:02, 247.58s/it, lr=3.13e-5, test_MAE=0.643, time=248, train_MAE=0.515, train_loss=0.826, val_MAE=0.618, val_loss=0.929]Epoch 74:   7%|▋         | 74/1000 [5:16:13<63:41:02, 247.58s/it, lr=3.13e-5, test_MAE=0.632, time=250, train_MAE=0.52, train_loss=0.831, val_MAE=0.6, val_loss=0.911]   Epoch 74:   8%|▊         | 75/1000 [5:16:13<63:50:05, 248.44s/it, lr=3.13e-5, test_MAE=0.632, time=250, train_MAE=0.52, train_loss=0.831, val_MAE=0.6, val_loss=0.911]Epoch 75:   8%|▊         | 75/1000 [5:16:13<63:50:05, 248.44s/it, lr=3.13e-5, test_MAE=0.632, time=250, train_MAE=0.52, train_loss=0.831, val_MAE=0.6, val_loss=0.911]Epoch 75:   8%|▊         | 75/1000 [5:20:28<63:50:05, 248.44s/it, lr=3.13e-5, test_MAE=0.667, time=254, train_MAE=0.511, train_loss=0.822, val_MAE=0.623, val_loss=0.934]Epoch    76: reducing learning rate of group 0 to 1.5625e-05.
Epoch 75:   8%|▊         | 76/1000 [5:20:28<64:13:39, 250.24s/it, lr=3.13e-5, test_MAE=0.667, time=254, train_MAE=0.511, train_loss=0.822, val_MAE=0.623, val_loss=0.934]Epoch 76:   8%|▊         | 76/1000 [5:20:28<64:13:39, 250.24s/it, lr=3.13e-5, test_MAE=0.667, time=254, train_MAE=0.511, train_loss=0.822, val_MAE=0.623, val_loss=0.934]Epoch 76:   8%|▊         | 76/1000 [5:24:35<64:13:39, 250.24s/it, lr=1.56e-5, test_MAE=0.62, time=247, train_MAE=0.505, train_loss=0.816, val_MAE=0.591, val_loss=0.901] Epoch 76:   8%|▊         | 77/1000 [5:24:35<63:56:37, 249.40s/it, lr=1.56e-5, test_MAE=0.62, time=247, train_MAE=0.505, train_loss=0.816, val_MAE=0.591, val_loss=0.901]Epoch 77:   8%|▊         | 77/1000 [5:24:35<63:56:37, 249.40s/it, lr=1.56e-5, test_MAE=0.62, time=247, train_MAE=0.505, train_loss=0.816, val_MAE=0.591, val_loss=0.901]Epoch 77:   8%|▊         | 77/1000 [5:28:43<63:56:37, 249.40s/it, lr=1.56e-5, test_MAE=0.623, time=248, train_MAE=0.504, train_loss=0.814, val_MAE=0.594, val_loss=0.904]Epoch 77:   8%|▊         | 78/1000 [5:28:43<63:45:40, 248.96s/it, lr=1.56e-5, test_MAE=0.623, time=248, train_MAE=0.504, train_loss=0.814, val_MAE=0.594, val_loss=0.904]Epoch 78:   8%|▊         | 78/1000 [5:28:43<63:45:40, 248.96s/it, lr=1.56e-5, test_MAE=0.623, time=248, train_MAE=0.504, train_loss=0.814, val_MAE=0.594, val_loss=0.904]Epoch 78:   8%|▊         | 78/1000 [5:32:51<63:45:40, 248.96s/it, lr=1.56e-5, test_MAE=0.631, time=248, train_MAE=0.502, train_loss=0.812, val_MAE=0.592, val_loss=0.902]Epoch 78:   8%|▊         | 79/1000 [5:32:51<63:38:21, 248.75s/it, lr=1.56e-5, test_MAE=0.631, time=248, train_MAE=0.502, train_loss=0.812, val_MAE=0.592, val_loss=0.902]Epoch 79:   8%|▊         | 79/1000 [5:32:51<63:38:21, 248.75s/it, lr=1.56e-5, test_MAE=0.631, time=248, train_MAE=0.502, train_loss=0.812, val_MAE=0.592, val_loss=0.902]Epoch 79:   8%|▊         | 79/1000 [5:37:00<63:38:21, 248.75s/it, lr=1.56e-5, test_MAE=0.629, time=249, train_MAE=0.503, train_loss=0.813, val_MAE=0.599, val_loss=0.91] Epoch 79:   8%|▊         | 80/1000 [5:37:00<63:35:56, 248.87s/it, lr=1.56e-5, test_MAE=0.629, time=249, train_MAE=0.503, train_loss=0.813, val_MAE=0.599, val_loss=0.91]Epoch 80:   8%|▊         | 80/1000 [5:37:00<63:35:56, 248.87s/it, lr=1.56e-5, test_MAE=0.629, time=249, train_MAE=0.503, train_loss=0.813, val_MAE=0.599, val_loss=0.91]Epoch 80:   8%|▊         | 80/1000 [5:41:08<63:35:56, 248.87s/it, lr=1.56e-5, test_MAE=0.622, time=248, train_MAE=0.502, train_loss=0.812, val_MAE=0.585, val_loss=0.896]Epoch 80:   8%|▊         | 81/1000 [5:41:08<63:26:32, 248.52s/it, lr=1.56e-5, test_MAE=0.622, time=248, train_MAE=0.502, train_loss=0.812, val_MAE=0.585, val_loss=0.896]Epoch 81:   8%|▊         | 81/1000 [5:41:08<63:26:32, 248.52s/it, lr=1.56e-5, test_MAE=0.622, time=248, train_MAE=0.502, train_loss=0.812, val_MAE=0.585, val_loss=0.896]Epoch 81:   8%|▊         | 81/1000 [5:45:20<63:26:32, 248.52s/it, lr=1.56e-5, test_MAE=0.618, time=252, train_MAE=0.498, train_loss=0.808, val_MAE=0.582, val_loss=0.892]Epoch 81:   8%|▊         | 82/1000 [5:45:20<63:39:24, 249.63s/it, lr=1.56e-5, test_MAE=0.618, time=252, train_MAE=0.498, train_loss=0.808, val_MAE=0.582, val_loss=0.892]Epoch 82:   8%|▊         | 82/1000 [5:45:20<63:39:24, 249.63s/it, lr=1.56e-5, test_MAE=0.618, time=252, train_MAE=0.498, train_loss=0.808, val_MAE=0.582, val_loss=0.892]Epoch 82:   8%|▊         | 82/1000 [5:49:35<63:39:24, 249.63s/it, lr=1.56e-5, test_MAE=0.616, time=255, train_MAE=0.499, train_loss=0.809, val_MAE=0.587, val_loss=0.897]Epoch 82:   8%|▊         | 83/1000 [5:49:35<63:59:01, 251.19s/it, lr=1.56e-5, test_MAE=0.616, time=255, train_MAE=0.499, train_loss=0.809, val_MAE=0.587, val_loss=0.897]Epoch 83:   8%|▊         | 83/1000 [5:49:35<63:59:01, 251.19s/it, lr=1.56e-5, test_MAE=0.616, time=255, train_MAE=0.499, train_loss=0.809, val_MAE=0.587, val_loss=0.897]Epoch 83:   8%|▊         | 83/1000 [5:53:48<63:59:01, 251.19s/it, lr=1.56e-5, test_MAE=0.649, time=253, train_MAE=0.505, train_loss=0.815, val_MAE=0.611, val_loss=0.921]Epoch 83:   8%|▊         | 84/1000 [5:53:48<64:04:42, 251.84s/it, lr=1.56e-5, test_MAE=0.649, time=253, train_MAE=0.505, train_loss=0.815, val_MAE=0.611, val_loss=0.921]Epoch 84:   8%|▊         | 84/1000 [5:53:48<64:04:42, 251.84s/it, lr=1.56e-5, test_MAE=0.649, time=253, train_MAE=0.505, train_loss=0.815, val_MAE=0.611, val_loss=0.921]Epoch 84:   8%|▊         | 84/1000 [5:58:00<64:04:42, 251.84s/it, lr=1.56e-5, test_MAE=0.635, time=252, train_MAE=0.494, train_loss=0.804, val_MAE=0.602, val_loss=0.912]Epoch 84:   8%|▊         | 85/1000 [5:58:00<63:59:40, 251.78s/it, lr=1.56e-5, test_MAE=0.635, time=252, train_MAE=0.494, train_loss=0.804, val_MAE=0.602, val_loss=0.912]Epoch 85:   8%|▊         | 85/1000 [5:58:00<63:59:40, 251.78s/it, lr=1.56e-5, test_MAE=0.635, time=252, train_MAE=0.494, train_loss=0.804, val_MAE=0.602, val_loss=0.912]Epoch 85:   8%|▊         | 85/1000 [6:02:14<63:59:40, 251.78s/it, lr=1.56e-5, test_MAE=0.628, time=254, train_MAE=0.498, train_loss=0.808, val_MAE=0.597, val_loss=0.907]Epoch 85:   9%|▊         | 86/1000 [6:02:14<64:05:43, 252.45s/it, lr=1.56e-5, test_MAE=0.628, time=254, train_MAE=0.498, train_loss=0.808, val_MAE=0.597, val_loss=0.907]Epoch 86:   9%|▊         | 86/1000 [6:02:14<64:05:43, 252.45s/it, lr=1.56e-5, test_MAE=0.628, time=254, train_MAE=0.498, train_loss=0.808, val_MAE=0.597, val_loss=0.907]Epoch 86:   9%|▊         | 86/1000 [6:06:22<64:05:43, 252.45s/it, lr=1.56e-5, test_MAE=0.647, time=248, train_MAE=0.493, train_loss=0.803, val_MAE=0.606, val_loss=0.916]Epoch 86:   9%|▊         | 87/1000 [6:06:22<63:41:54, 251.17s/it, lr=1.56e-5, test_MAE=0.647, time=248, train_MAE=0.493, train_loss=0.803, val_MAE=0.606, val_loss=0.916]Epoch 87:   9%|▊         | 87/1000 [6:06:22<63:41:54, 251.17s/it, lr=1.56e-5, test_MAE=0.647, time=248, train_MAE=0.493, train_loss=0.803, val_MAE=0.606, val_loss=0.916]Epoch 87:   9%|▊         | 87/1000 [6:10:31<63:41:54, 251.17s/it, lr=1.56e-5, test_MAE=0.624, time=248, train_MAE=0.503, train_loss=0.813, val_MAE=0.593, val_loss=0.903]Epoch    88: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 87:   9%|▊         | 87/1000 [6:10:31<64:48:18, 255.53s/it, lr=1.56e-5, test_MAE=0.624, time=248, train_MAE=0.503, train_loss=0.813, val_MAE=0.593, val_loss=0.903]
Test MAE: 0.6244
Train MAE: 0.4922
Convergence Time (Epochs): 87.0000
TOTAL TIME TAKEN: 22386.3424s
AVG TIME PER EPOCH: 252.5897s
