I'm echoing to stdout
I'm echoing to stderr
My JobID is 57978952
I have 4 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.1528s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 2, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'poly_mlp', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_all', 'num_eigs': 16, 'bias_mode': 'spatial', 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 0.0, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/aug07/zinc_train_rec.csv', 'test': 'supp_data/molecules/aug07/zinc_test_rec.csv', 'val': 'supp_data/molecules/aug07/zinc_val_rec.csv'}, 'fixMissingPhi1': False, 'extraOrtho': False, 'doublePrecision': True, 'eigval_hidden_dim': 100, 'eigval_num_hidden_layer': 0, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [01:24<?, ?it/s, lr=0.001, test_MAE=1.02, time=85, train_MAE=0.902, train_loss=0.902, val_MAE=0.973, val_loss=0.973]Epoch 0:   0%|          | 1/1000 [01:24<23:34:49, 84.97s/it, lr=0.001, test_MAE=1.02, time=85, train_MAE=0.902, train_loss=0.902, val_MAE=0.973, val_loss=0.973]Epoch 1:   0%|          | 1/1000 [01:24<23:34:49, 84.97s/it, lr=0.001, test_MAE=1.02, time=85, train_MAE=0.902, train_loss=0.902, val_MAE=0.973, val_loss=0.973]Epoch 1:   0%|          | 1/1000 [02:32<23:34:49, 84.97s/it, lr=0.001, test_MAE=0.711, time=67.5, train_MAE=0.672, train_loss=0.672, val_MAE=0.666, val_loss=0.666]Epoch 1:   0%|          | 2/1000 [02:32<22:06:20, 79.74s/it, lr=0.001, test_MAE=0.711, time=67.5, train_MAE=0.672, train_loss=0.672, val_MAE=0.666, val_loss=0.666]Epoch 2:   0%|          | 2/1000 [02:32<22:06:20, 79.74s/it, lr=0.001, test_MAE=0.711, time=67.5, train_MAE=0.672, train_loss=0.672, val_MAE=0.666, val_loss=0.666]Epoch 2:   0%|          | 2/1000 [03:40<22:06:20, 79.74s/it, lr=0.001, test_MAE=0.671, time=67.5, train_MAE=0.658, train_loss=0.658, val_MAE=0.629, val_loss=0.629]Epoch 2:   0%|          | 3/1000 [03:40<21:04:10, 76.08s/it, lr=0.001, test_MAE=0.671, time=67.5, train_MAE=0.658, train_loss=0.658, val_MAE=0.629, val_loss=0.629]Epoch 3:   0%|          | 3/1000 [03:40<21:04:10, 76.08s/it, lr=0.001, test_MAE=0.671, time=67.5, train_MAE=0.658, train_loss=0.658, val_MAE=0.629, val_loss=0.629]Epoch 3:   0%|          | 3/1000 [04:46<21:04:10, 76.08s/it, lr=0.001, test_MAE=0.875, time=66.8, train_MAE=0.667, train_loss=0.667, val_MAE=0.84, val_loss=0.84]  Epoch 3:   0%|          | 4/1000 [04:46<20:16:53, 73.31s/it, lr=0.001, test_MAE=0.875, time=66.8, train_MAE=0.667, train_loss=0.667, val_MAE=0.84, val_loss=0.84]Epoch 4:   0%|          | 4/1000 [04:46<20:16:53, 73.31s/it, lr=0.001, test_MAE=0.875, time=66.8, train_MAE=0.667, train_loss=0.667, val_MAE=0.84, val_loss=0.84]Epoch 4:   0%|          | 4/1000 [05:53<20:16:53, 73.31s/it, lr=0.001, test_MAE=0.654, time=66.8, train_MAE=0.626, train_loss=0.626, val_MAE=0.621, val_loss=0.621]Epoch 4:   0%|          | 5/1000 [05:53<19:43:23, 71.36s/it, lr=0.001, test_MAE=0.654, time=66.8, train_MAE=0.626, train_loss=0.626, val_MAE=0.621, val_loss=0.621]Epoch 5:   0%|          | 5/1000 [05:53<19:43:23, 71.36s/it, lr=0.001, test_MAE=0.654, time=66.8, train_MAE=0.626, train_loss=0.626, val_MAE=0.621, val_loss=0.621]Epoch 5:   0%|          | 5/1000 [07:00<19:43:23, 71.36s/it, lr=0.001, test_MAE=0.652, time=66.9, train_MAE=0.624, train_loss=0.624, val_MAE=0.62, val_loss=0.62]  Epoch 5:   1%|          | 6/1000 [07:00<19:19:52, 70.01s/it, lr=0.001, test_MAE=0.652, time=66.9, train_MAE=0.624, train_loss=0.624, val_MAE=0.62, val_loss=0.62]Epoch 6:   1%|          | 6/1000 [07:00<19:19:52, 70.01s/it, lr=0.001, test_MAE=0.652, time=66.9, train_MAE=0.624, train_loss=0.624, val_MAE=0.62, val_loss=0.62]Epoch 6:   1%|          | 6/1000 [08:07<19:19:52, 70.01s/it, lr=0.001, test_MAE=0.753, time=67, train_MAE=0.615, train_loss=0.615, val_MAE=0.717, val_loss=0.717]Epoch 6:   1%|          | 7/1000 [08:07<19:03:48, 69.11s/it, lr=0.001, test_MAE=0.753, time=67, train_MAE=0.615, train_loss=0.615, val_MAE=0.717, val_loss=0.717]Epoch 7:   1%|          | 7/1000 [08:07<19:03:48, 69.11s/it, lr=0.001, test_MAE=0.753, time=67, train_MAE=0.615, train_loss=0.615, val_MAE=0.717, val_loss=0.717]Epoch 7:   1%|          | 7/1000 [09:14<19:03:48, 69.11s/it, lr=0.001, test_MAE=0.913, time=66.9, train_MAE=0.613, train_loss=0.613, val_MAE=0.878, val_loss=0.878]Epoch 7:   1%|          | 8/1000 [09:14<18:51:44, 68.45s/it, lr=0.001, test_MAE=0.913, time=66.9, train_MAE=0.613, train_loss=0.613, val_MAE=0.878, val_loss=0.878]Epoch 8:   1%|          | 8/1000 [09:14<18:51:44, 68.45s/it, lr=0.001, test_MAE=0.913, time=66.9, train_MAE=0.613, train_loss=0.613, val_MAE=0.878, val_loss=0.878]Epoch 8:   1%|          | 8/1000 [10:21<18:51:44, 68.45s/it, lr=0.001, test_MAE=0.648, time=66.7, train_MAE=0.615, train_loss=0.615, val_MAE=0.622, val_loss=0.622]Epoch 8:   1%|          | 9/1000 [10:21<18:41:45, 67.92s/it, lr=0.001, test_MAE=0.648, time=66.7, train_MAE=0.615, train_loss=0.615, val_MAE=0.622, val_loss=0.622]Epoch 9:   1%|          | 9/1000 [10:21<18:41:45, 67.92s/it, lr=0.001, test_MAE=0.648, time=66.7, train_MAE=0.615, train_loss=0.615, val_MAE=0.622, val_loss=0.622]Epoch 9:   1%|          | 9/1000 [11:28<18:41:45, 67.92s/it, lr=0.001, test_MAE=0.787, time=66.9, train_MAE=0.591, train_loss=0.591, val_MAE=0.751, val_loss=0.751]Epoch 9:   1%|          | 10/1000 [11:28<18:35:47, 67.62s/it, lr=0.001, test_MAE=0.787, time=66.9, train_MAE=0.591, train_loss=0.591, val_MAE=0.751, val_loss=0.751]Epoch 10:   1%|          | 10/1000 [11:28<18:35:47, 67.62s/it, lr=0.001, test_MAE=0.787, time=66.9, train_MAE=0.591, train_loss=0.591, val_MAE=0.751, val_loss=0.751]Epoch 10:   1%|          | 10/1000 [12:34<18:35:47, 67.62s/it, lr=0.001, test_MAE=0.667, time=66.7, train_MAE=0.602, train_loss=0.602, val_MAE=0.63, val_loss=0.63]  Epoch 10:   1%|          | 11/1000 [12:34<18:30:05, 67.35s/it, lr=0.001, test_MAE=0.667, time=66.7, train_MAE=0.602, train_loss=0.602, val_MAE=0.63, val_loss=0.63]Epoch 11:   1%|          | 11/1000 [12:34<18:30:05, 67.35s/it, lr=0.001, test_MAE=0.667, time=66.7, train_MAE=0.602, train_loss=0.602, val_MAE=0.63, val_loss=0.63]Epoch 11:   1%|          | 11/1000 [13:41<18:30:05, 67.35s/it, lr=0.001, test_MAE=0.631, time=66.5, train_MAE=0.596, train_loss=0.596, val_MAE=0.592, val_loss=0.592]Epoch 11:   1%|          | 12/1000 [13:41<18:24:54, 67.10s/it, lr=0.001, test_MAE=0.631, time=66.5, train_MAE=0.596, train_loss=0.596, val_MAE=0.592, val_loss=0.592]Epoch 12:   1%|          | 12/1000 [13:41<18:24:54, 67.10s/it, lr=0.001, test_MAE=0.631, time=66.5, train_MAE=0.596, train_loss=0.596, val_MAE=0.592, val_loss=0.592]Epoch 12:   1%|          | 12/1000 [14:48<18:24:54, 67.10s/it, lr=0.001, test_MAE=0.755, time=67.2, train_MAE=0.6, train_loss=0.6, val_MAE=0.715, val_loss=0.715]    Epoch 12:   1%|▏         | 13/1000 [14:48<18:24:22, 67.13s/it, lr=0.001, test_MAE=0.755, time=67.2, train_MAE=0.6, train_loss=0.6, val_MAE=0.715, val_loss=0.715]Epoch 13:   1%|▏         | 13/1000 [14:48<18:24:22, 67.13s/it, lr=0.001, test_MAE=0.755, time=67.2, train_MAE=0.6, train_loss=0.6, val_MAE=0.715, val_loss=0.715]Epoch 13:   1%|▏         | 13/1000 [15:55<18:24:22, 67.13s/it, lr=0.001, test_MAE=0.68, time=66.6, train_MAE=0.595, train_loss=0.595, val_MAE=0.643, val_loss=0.643]Epoch 13:   1%|▏         | 14/1000 [15:55<18:20:36, 66.97s/it, lr=0.001, test_MAE=0.68, time=66.6, train_MAE=0.595, train_loss=0.595, val_MAE=0.643, val_loss=0.643]Epoch 14:   1%|▏         | 14/1000 [15:55<18:20:36, 66.97s/it, lr=0.001, test_MAE=0.68, time=66.6, train_MAE=0.595, train_loss=0.595, val_MAE=0.643, val_loss=0.643]Epoch 14:   1%|▏         | 14/1000 [17:01<18:20:36, 66.97s/it, lr=0.001, test_MAE=0.934, time=66.3, train_MAE=0.584, train_loss=0.584, val_MAE=0.903, val_loss=0.903]Epoch 14:   2%|▏         | 15/1000 [17:01<18:16:27, 66.79s/it, lr=0.001, test_MAE=0.934, time=66.3, train_MAE=0.584, train_loss=0.584, val_MAE=0.903, val_loss=0.903]Epoch 15:   2%|▏         | 15/1000 [17:01<18:16:27, 66.79s/it, lr=0.001, test_MAE=0.934, time=66.3, train_MAE=0.584, train_loss=0.584, val_MAE=0.903, val_loss=0.903]Epoch 15:   2%|▏         | 15/1000 [18:08<18:16:27, 66.79s/it, lr=0.001, test_MAE=0.637, time=66.9, train_MAE=0.58, train_loss=0.58, val_MAE=0.588, val_loss=0.588]  Epoch 15:   2%|▏         | 16/1000 [18:08<18:16:01, 66.83s/it, lr=0.001, test_MAE=0.637, time=66.9, train_MAE=0.58, train_loss=0.58, val_MAE=0.588, val_loss=0.588]Epoch 16:   2%|▏         | 16/1000 [18:08<18:16:01, 66.83s/it, lr=0.001, test_MAE=0.637, time=66.9, train_MAE=0.58, train_loss=0.58, val_MAE=0.588, val_loss=0.588]Epoch 16:   2%|▏         | 16/1000 [19:15<18:16:01, 66.83s/it, lr=0.001, test_MAE=0.693, time=66.9, train_MAE=0.569, train_loss=0.569, val_MAE=0.649, val_loss=0.649]Epoch 16:   2%|▏         | 17/1000 [19:15<18:15:28, 66.86s/it, lr=0.001, test_MAE=0.693, time=66.9, train_MAE=0.569, train_loss=0.569, val_MAE=0.649, val_loss=0.649]Epoch 17:   2%|▏         | 17/1000 [19:15<18:15:28, 66.86s/it, lr=0.001, test_MAE=0.693, time=66.9, train_MAE=0.569, train_loss=0.569, val_MAE=0.649, val_loss=0.649]Epoch 17:   2%|▏         | 17/1000 [20:21<18:15:28, 66.86s/it, lr=0.001, test_MAE=0.687, time=66.4, train_MAE=0.569, train_loss=0.569, val_MAE=0.63, val_loss=0.63]  Epoch 17:   2%|▏         | 18/1000 [20:21<18:12:07, 66.73s/it, lr=0.001, test_MAE=0.687, time=66.4, train_MAE=0.569, train_loss=0.569, val_MAE=0.63, val_loss=0.63]Epoch 18:   2%|▏         | 18/1000 [20:21<18:12:07, 66.73s/it, lr=0.001, test_MAE=0.687, time=66.4, train_MAE=0.569, train_loss=0.569, val_MAE=0.63, val_loss=0.63]Epoch 18:   2%|▏         | 18/1000 [21:28<18:12:07, 66.73s/it, lr=0.001, test_MAE=0.656, time=67, train_MAE=0.571, train_loss=0.571, val_MAE=0.599, val_loss=0.599]Epoch 18:   2%|▏         | 19/1000 [21:28<18:12:14, 66.80s/it, lr=0.001, test_MAE=0.656, time=67, train_MAE=0.571, train_loss=0.571, val_MAE=0.599, val_loss=0.599]Epoch 19:   2%|▏         | 19/1000 [21:28<18:12:14, 66.80s/it, lr=0.001, test_MAE=0.656, time=67, train_MAE=0.571, train_loss=0.571, val_MAE=0.599, val_loss=0.599]Epoch 19:   2%|▏         | 19/1000 [22:35<18:12:14, 66.80s/it, lr=0.001, test_MAE=0.676, time=67.1, train_MAE=0.571, train_loss=0.571, val_MAE=0.644, val_loss=0.644]Epoch 19:   2%|▏         | 20/1000 [22:35<18:12:42, 66.90s/it, lr=0.001, test_MAE=0.676, time=67.1, train_MAE=0.571, train_loss=0.571, val_MAE=0.644, val_loss=0.644]Epoch 20:   2%|▏         | 20/1000 [22:35<18:12:42, 66.90s/it, lr=0.001, test_MAE=0.676, time=67.1, train_MAE=0.571, train_loss=0.571, val_MAE=0.644, val_loss=0.644]Epoch 20:   2%|▏         | 20/1000 [23:42<18:12:42, 66.90s/it, lr=0.001, test_MAE=0.672, time=66.6, train_MAE=0.582, train_loss=0.582, val_MAE=0.628, val_loss=0.628]Epoch 20:   2%|▏         | 21/1000 [23:42<18:10:11, 66.81s/it, lr=0.001, test_MAE=0.672, time=66.6, train_MAE=0.582, train_loss=0.582, val_MAE=0.628, val_loss=0.628]Epoch 21:   2%|▏         | 21/1000 [23:42<18:10:11, 66.81s/it, lr=0.001, test_MAE=0.672, time=66.6, train_MAE=0.582, train_loss=0.582, val_MAE=0.628, val_loss=0.628]Epoch 21:   2%|▏         | 21/1000 [24:49<18:10:11, 66.81s/it, lr=0.001, test_MAE=0.77, time=67, train_MAE=0.564, train_loss=0.564, val_MAE=0.731, val_loss=0.731]   Epoch    22: reducing learning rate of group 0 to 5.0000e-04.
Epoch 21:   2%|▏         | 22/1000 [24:49<18:09:55, 66.87s/it, lr=0.001, test_MAE=0.77, time=67, train_MAE=0.564, train_loss=0.564, val_MAE=0.731, val_loss=0.731]Epoch 22:   2%|▏         | 22/1000 [24:49<18:09:55, 66.87s/it, lr=0.001, test_MAE=0.77, time=67, train_MAE=0.564, train_loss=0.564, val_MAE=0.731, val_loss=0.731]Epoch 22:   2%|▏         | 22/1000 [25:55<18:09:55, 66.87s/it, lr=0.0005, test_MAE=0.628, time=66.3, train_MAE=0.543, train_loss=0.543, val_MAE=0.6, val_loss=0.6]Epoch 22:   2%|▏         | 23/1000 [25:55<18:06:09, 66.70s/it, lr=0.0005, test_MAE=0.628, time=66.3, train_MAE=0.543, train_loss=0.543, val_MAE=0.6, val_loss=0.6]Epoch 23:   2%|▏         | 23/1000 [25:55<18:06:09, 66.70s/it, lr=0.0005, test_MAE=0.628, time=66.3, train_MAE=0.543, train_loss=0.543, val_MAE=0.6, val_loss=0.6]Epoch 23:   2%|▏         | 23/1000 [27:02<18:06:09, 66.70s/it, lr=0.0005, test_MAE=0.603, time=67, train_MAE=0.548, train_loss=0.548, val_MAE=0.562, val_loss=0.562]Epoch 23:   2%|▏         | 24/1000 [27:02<18:06:36, 66.80s/it, lr=0.0005, test_MAE=0.603, time=67, train_MAE=0.548, train_loss=0.548, val_MAE=0.562, val_loss=0.562]Epoch 24:   2%|▏         | 24/1000 [27:02<18:06:36, 66.80s/it, lr=0.0005, test_MAE=0.603, time=67, train_MAE=0.548, train_loss=0.548, val_MAE=0.562, val_loss=0.562]Epoch 24:   2%|▏         | 24/1000 [28:09<18:06:36, 66.80s/it, lr=0.0005, test_MAE=0.611, time=66.6, train_MAE=0.54, train_loss=0.54, val_MAE=0.575, val_loss=0.575]Epoch 24:   2%|▎         | 25/1000 [28:09<18:04:45, 66.75s/it, lr=0.0005, test_MAE=0.611, time=66.6, train_MAE=0.54, train_loss=0.54, val_MAE=0.575, val_loss=0.575]Epoch 25:   2%|▎         | 25/1000 [28:09<18:04:45, 66.75s/it, lr=0.0005, test_MAE=0.611, time=66.6, train_MAE=0.54, train_loss=0.54, val_MAE=0.575, val_loss=0.575]Epoch 25:   2%|▎         | 25/1000 [29:16<18:04:45, 66.75s/it, lr=0.0005, test_MAE=0.667, time=66.6, train_MAE=0.544, train_loss=0.544, val_MAE=0.626, val_loss=0.626]Epoch 25:   3%|▎         | 26/1000 [29:16<18:03:07, 66.72s/it, lr=0.0005, test_MAE=0.667, time=66.6, train_MAE=0.544, train_loss=0.544, val_MAE=0.626, val_loss=0.626]Epoch 26:   3%|▎         | 26/1000 [29:16<18:03:07, 66.72s/it, lr=0.0005, test_MAE=0.667, time=66.6, train_MAE=0.544, train_loss=0.544, val_MAE=0.626, val_loss=0.626]Epoch 26:   3%|▎         | 26/1000 [30:23<18:03:07, 66.72s/it, lr=0.0005, test_MAE=0.611, time=66.9, train_MAE=0.535, train_loss=0.535, val_MAE=0.57, val_loss=0.57]  Epoch 26:   3%|▎         | 27/1000 [30:23<18:03:05, 66.79s/it, lr=0.0005, test_MAE=0.611, time=66.9, train_MAE=0.535, train_loss=0.535, val_MAE=0.57, val_loss=0.57]Epoch 27:   3%|▎         | 27/1000 [30:23<18:03:05, 66.79s/it, lr=0.0005, test_MAE=0.611, time=66.9, train_MAE=0.535, train_loss=0.535, val_MAE=0.57, val_loss=0.57]Epoch 27:   3%|▎         | 27/1000 [31:29<18:03:05, 66.79s/it, lr=0.0005, test_MAE=0.614, time=66.7, train_MAE=0.534, train_loss=0.534, val_MAE=0.576, val_loss=0.576]Epoch 27:   3%|▎         | 28/1000 [31:29<18:01:37, 66.77s/it, lr=0.0005, test_MAE=0.614, time=66.7, train_MAE=0.534, train_loss=0.534, val_MAE=0.576, val_loss=0.576]Epoch 28:   3%|▎         | 28/1000 [31:29<18:01:37, 66.77s/it, lr=0.0005, test_MAE=0.614, time=66.7, train_MAE=0.534, train_loss=0.534, val_MAE=0.576, val_loss=0.576]Epoch 28:   3%|▎         | 28/1000 [32:36<18:01:37, 66.77s/it, lr=0.0005, test_MAE=0.602, time=66.3, train_MAE=0.532, train_loss=0.532, val_MAE=0.563, val_loss=0.563]Epoch 28:   3%|▎         | 29/1000 [32:36<17:58:08, 66.62s/it, lr=0.0005, test_MAE=0.602, time=66.3, train_MAE=0.532, train_loss=0.532, val_MAE=0.563, val_loss=0.563]Epoch 29:   3%|▎         | 29/1000 [32:36<17:58:08, 66.62s/it, lr=0.0005, test_MAE=0.602, time=66.3, train_MAE=0.532, train_loss=0.532, val_MAE=0.563, val_loss=0.563]Epoch 29:   3%|▎         | 29/1000 [33:43<17:58:08, 66.62s/it, lr=0.0005, test_MAE=0.742, time=67.3, train_MAE=0.529, train_loss=0.529, val_MAE=0.696, val_loss=0.696]Epoch    30: reducing learning rate of group 0 to 2.5000e-04.
Epoch 29:   3%|▎         | 30/1000 [33:43<18:00:32, 66.84s/it, lr=0.0005, test_MAE=0.742, time=67.3, train_MAE=0.529, train_loss=0.529, val_MAE=0.696, val_loss=0.696]Epoch 30:   3%|▎         | 30/1000 [33:43<18:00:32, 66.84s/it, lr=0.0005, test_MAE=0.742, time=67.3, train_MAE=0.529, train_loss=0.529, val_MAE=0.696, val_loss=0.696]Epoch 30:   3%|▎         | 30/1000 [34:50<18:00:32, 66.84s/it, lr=0.00025, test_MAE=0.633, time=66.7, train_MAE=0.524, train_loss=0.524, val_MAE=0.594, val_loss=0.594]Epoch 30:   3%|▎         | 31/1000 [34:50<17:59:00, 66.81s/it, lr=0.00025, test_MAE=0.633, time=66.7, train_MAE=0.524, train_loss=0.524, val_MAE=0.594, val_loss=0.594]Epoch 31:   3%|▎         | 31/1000 [34:50<17:59:00, 66.81s/it, lr=0.00025, test_MAE=0.633, time=66.7, train_MAE=0.524, train_loss=0.524, val_MAE=0.594, val_loss=0.594]Epoch 31:   3%|▎         | 31/1000 [35:58<17:59:00, 66.81s/it, lr=0.00025, test_MAE=0.6, time=68.3, train_MAE=0.514, train_loss=0.514, val_MAE=0.56, val_loss=0.56]    Epoch 31:   3%|▎         | 32/1000 [35:58<18:05:06, 67.26s/it, lr=0.00025, test_MAE=0.6, time=68.3, train_MAE=0.514, train_loss=0.514, val_MAE=0.56, val_loss=0.56]Epoch 32:   3%|▎         | 32/1000 [35:58<18:05:06, 67.26s/it, lr=0.00025, test_MAE=0.6, time=68.3, train_MAE=0.514, train_loss=0.514, val_MAE=0.56, val_loss=0.56]Epoch 32:   3%|▎         | 32/1000 [37:07<18:05:06, 67.26s/it, lr=0.00025, test_MAE=0.594, time=68.9, train_MAE=0.514, train_loss=0.514, val_MAE=0.561, val_loss=0.561]Epoch 32:   3%|▎         | 33/1000 [37:07<18:12:11, 67.77s/it, lr=0.00025, test_MAE=0.594, time=68.9, train_MAE=0.514, train_loss=0.514, val_MAE=0.561, val_loss=0.561]Epoch 33:   3%|▎         | 33/1000 [37:07<18:12:11, 67.77s/it, lr=0.00025, test_MAE=0.594, time=68.9, train_MAE=0.514, train_loss=0.514, val_MAE=0.561, val_loss=0.561]Epoch 33:   3%|▎         | 33/1000 [38:16<18:12:11, 67.77s/it, lr=0.00025, test_MAE=0.597, time=68.7, train_MAE=0.507, train_loss=0.507, val_MAE=0.563, val_loss=0.563]Epoch 33:   3%|▎         | 34/1000 [38:16<18:15:29, 68.04s/it, lr=0.00025, test_MAE=0.597, time=68.7, train_MAE=0.507, train_loss=0.507, val_MAE=0.563, val_loss=0.563]Epoch 34:   3%|▎         | 34/1000 [38:16<18:15:29, 68.04s/it, lr=0.00025, test_MAE=0.597, time=68.7, train_MAE=0.507, train_loss=0.507, val_MAE=0.563, val_loss=0.563]Epoch 34:   3%|▎         | 34/1000 [39:23<18:15:29, 68.04s/it, lr=0.00025, test_MAE=0.605, time=67.4, train_MAE=0.503, train_loss=0.503, val_MAE=0.575, val_loss=0.575]Epoch 34:   4%|▎         | 35/1000 [39:23<18:11:12, 67.85s/it, lr=0.00025, test_MAE=0.605, time=67.4, train_MAE=0.503, train_loss=0.503, val_MAE=0.575, val_loss=0.575]Epoch 35:   4%|▎         | 35/1000 [39:23<18:11:12, 67.85s/it, lr=0.00025, test_MAE=0.605, time=67.4, train_MAE=0.503, train_loss=0.503, val_MAE=0.575, val_loss=0.575]Epoch 35:   4%|▎         | 35/1000 [40:31<18:11:12, 67.85s/it, lr=0.00025, test_MAE=0.614, time=68.4, train_MAE=0.51, train_loss=0.51, val_MAE=0.573, val_loss=0.573]  Epoch 35:   4%|▎         | 36/1000 [40:31<18:12:48, 68.02s/it, lr=0.00025, test_MAE=0.614, time=68.4, train_MAE=0.51, train_loss=0.51, val_MAE=0.573, val_loss=0.573]Epoch 36:   4%|▎         | 36/1000 [40:31<18:12:48, 68.02s/it, lr=0.00025, test_MAE=0.614, time=68.4, train_MAE=0.51, train_loss=0.51, val_MAE=0.573, val_loss=0.573]Epoch 36:   4%|▎         | 36/1000 [41:38<18:12:48, 68.02s/it, lr=0.00025, test_MAE=0.594, time=66.7, train_MAE=0.508, train_loss=0.508, val_MAE=0.554, val_loss=0.554]Epoch 36:   4%|▎         | 37/1000 [41:38<18:05:35, 67.64s/it, lr=0.00025, test_MAE=0.594, time=66.7, train_MAE=0.508, train_loss=0.508, val_MAE=0.554, val_loss=0.554]Epoch 37:   4%|▎         | 37/1000 [41:38<18:05:35, 67.64s/it, lr=0.00025, test_MAE=0.594, time=66.7, train_MAE=0.508, train_loss=0.508, val_MAE=0.554, val_loss=0.554]Epoch 37:   4%|▎         | 37/1000 [42:45<18:05:35, 67.64s/it, lr=0.00025, test_MAE=0.593, time=66.4, train_MAE=0.509, train_loss=0.509, val_MAE=0.565, val_loss=0.565]Epoch 37:   4%|▍         | 38/1000 [42:45<17:58:39, 67.28s/it, lr=0.00025, test_MAE=0.593, time=66.4, train_MAE=0.509, train_loss=0.509, val_MAE=0.565, val_loss=0.565]Epoch 38:   4%|▍         | 38/1000 [42:45<17:58:39, 67.28s/it, lr=0.00025, test_MAE=0.593, time=66.4, train_MAE=0.509, train_loss=0.509, val_MAE=0.565, val_loss=0.565]Epoch 38:   4%|▍         | 38/1000 [43:52<17:58:39, 67.28s/it, lr=0.00025, test_MAE=0.6, time=66.9, train_MAE=0.514, train_loss=0.514, val_MAE=0.561, val_loss=0.561]  Epoch 38:   4%|▍         | 39/1000 [43:52<17:55:58, 67.18s/it, lr=0.00025, test_MAE=0.6, time=66.9, train_MAE=0.514, train_loss=0.514, val_MAE=0.561, val_loss=0.561]Epoch 39:   4%|▍         | 39/1000 [43:52<17:55:58, 67.18s/it, lr=0.00025, test_MAE=0.6, time=66.9, train_MAE=0.514, train_loss=0.514, val_MAE=0.561, val_loss=0.561]Epoch 39:   4%|▍         | 39/1000 [44:58<17:55:58, 67.18s/it, lr=0.00025, test_MAE=0.593, time=66.8, train_MAE=0.499, train_loss=0.499, val_MAE=0.559, val_loss=0.559]Epoch 39:   4%|▍         | 40/1000 [44:58<17:52:58, 67.06s/it, lr=0.00025, test_MAE=0.593, time=66.8, train_MAE=0.499, train_loss=0.499, val_MAE=0.559, val_loss=0.559]Epoch 40:   4%|▍         | 40/1000 [44:58<17:52:58, 67.06s/it, lr=0.00025, test_MAE=0.593, time=66.8, train_MAE=0.499, train_loss=0.499, val_MAE=0.559, val_loss=0.559]Epoch 40:   4%|▍         | 40/1000 [46:05<17:52:58, 67.06s/it, lr=0.00025, test_MAE=0.605, time=66.7, train_MAE=0.504, train_loss=0.504, val_MAE=0.569, val_loss=0.569]Epoch 40:   4%|▍         | 41/1000 [46:05<17:50:16, 66.96s/it, lr=0.00025, test_MAE=0.605, time=66.7, train_MAE=0.504, train_loss=0.504, val_MAE=0.569, val_loss=0.569]Epoch 41:   4%|▍         | 41/1000 [46:05<17:50:16, 66.96s/it, lr=0.00025, test_MAE=0.605, time=66.7, train_MAE=0.504, train_loss=0.504, val_MAE=0.569, val_loss=0.569]Epoch 41:   4%|▍         | 41/1000 [47:13<17:50:16, 66.96s/it, lr=0.00025, test_MAE=0.599, time=67.5, train_MAE=0.501, train_loss=0.501, val_MAE=0.561, val_loss=0.561]Epoch 41:   4%|▍         | 42/1000 [47:13<17:51:46, 67.13s/it, lr=0.00025, test_MAE=0.599, time=67.5, train_MAE=0.501, train_loss=0.501, val_MAE=0.561, val_loss=0.561]Epoch 42:   4%|▍         | 42/1000 [47:13<17:51:46, 67.13s/it, lr=0.00025, test_MAE=0.599, time=67.5, train_MAE=0.501, train_loss=0.501, val_MAE=0.561, val_loss=0.561]Epoch 42:   4%|▍         | 42/1000 [48:19<17:51:46, 67.13s/it, lr=0.00025, test_MAE=0.597, time=66.4, train_MAE=0.512, train_loss=0.512, val_MAE=0.557, val_loss=0.557]Epoch    43: reducing learning rate of group 0 to 1.2500e-04.
Epoch 42:   4%|▍         | 43/1000 [48:19<17:47:13, 66.91s/it, lr=0.00025, test_MAE=0.597, time=66.4, train_MAE=0.512, train_loss=0.512, val_MAE=0.557, val_loss=0.557]Epoch 43:   4%|▍         | 43/1000 [48:19<17:47:13, 66.91s/it, lr=0.00025, test_MAE=0.597, time=66.4, train_MAE=0.512, train_loss=0.512, val_MAE=0.557, val_loss=0.557]Epoch 43:   4%|▍         | 43/1000 [49:25<17:47:13, 66.91s/it, lr=0.000125, test_MAE=0.591, time=65.6, train_MAE=0.492, train_loss=0.492, val_MAE=0.558, val_loss=0.558]Epoch 43:   4%|▍         | 44/1000 [49:25<17:40:00, 66.53s/it, lr=0.000125, test_MAE=0.591, time=65.6, train_MAE=0.492, train_loss=0.492, val_MAE=0.558, val_loss=0.558]Epoch 44:   4%|▍         | 44/1000 [49:25<17:40:00, 66.53s/it, lr=0.000125, test_MAE=0.591, time=65.6, train_MAE=0.492, train_loss=0.492, val_MAE=0.558, val_loss=0.558]Epoch 44:   4%|▍         | 44/1000 [50:30<17:40:00, 66.53s/it, lr=0.000125, test_MAE=0.611, time=65.3, train_MAE=0.488, train_loss=0.488, val_MAE=0.57, val_loss=0.57]  Epoch 44:   4%|▍         | 45/1000 [50:30<17:32:52, 66.15s/it, lr=0.000125, test_MAE=0.611, time=65.3, train_MAE=0.488, train_loss=0.488, val_MAE=0.57, val_loss=0.57]Epoch 45:   4%|▍         | 45/1000 [50:30<17:32:52, 66.15s/it, lr=0.000125, test_MAE=0.611, time=65.3, train_MAE=0.488, train_loss=0.488, val_MAE=0.57, val_loss=0.57]Epoch 45:   4%|▍         | 45/1000 [51:35<17:32:52, 66.15s/it, lr=0.000125, test_MAE=0.59, time=65.6, train_MAE=0.49, train_loss=0.49, val_MAE=0.562, val_loss=0.562] Epoch 45:   5%|▍         | 46/1000 [51:36<17:29:17, 65.99s/it, lr=0.000125, test_MAE=0.59, time=65.6, train_MAE=0.49, train_loss=0.49, val_MAE=0.562, val_loss=0.562]Epoch 46:   5%|▍         | 46/1000 [51:36<17:29:17, 65.99s/it, lr=0.000125, test_MAE=0.59, time=65.6, train_MAE=0.49, train_loss=0.49, val_MAE=0.562, val_loss=0.562]Epoch 46:   5%|▍         | 46/1000 [52:41<17:29:17, 65.99s/it, lr=0.000125, test_MAE=0.592, time=65.7, train_MAE=0.484, train_loss=0.484, val_MAE=0.559, val_loss=0.559]Epoch 46:   5%|▍         | 47/1000 [52:41<17:26:43, 65.90s/it, lr=0.000125, test_MAE=0.592, time=65.7, train_MAE=0.484, train_loss=0.484, val_MAE=0.559, val_loss=0.559]Epoch 47:   5%|▍         | 47/1000 [52:41<17:26:43, 65.90s/it, lr=0.000125, test_MAE=0.592, time=65.7, train_MAE=0.484, train_loss=0.484, val_MAE=0.559, val_loss=0.559]Epoch 47:   5%|▍         | 47/1000 [53:49<17:26:43, 65.90s/it, lr=0.000125, test_MAE=0.589, time=67.3, train_MAE=0.494, train_loss=0.494, val_MAE=0.559, val_loss=0.559]Epoch 47:   5%|▍         | 48/1000 [53:49<17:32:31, 66.34s/it, lr=0.000125, test_MAE=0.589, time=67.3, train_MAE=0.494, train_loss=0.494, val_MAE=0.559, val_loss=0.559]Epoch 48:   5%|▍         | 48/1000 [53:49<17:32:31, 66.34s/it, lr=0.000125, test_MAE=0.589, time=67.3, train_MAE=0.494, train_loss=0.494, val_MAE=0.559, val_loss=0.559]Epoch 48:   5%|▍         | 48/1000 [54:56<17:32:31, 66.34s/it, lr=0.000125, test_MAE=0.593, time=67.8, train_MAE=0.489, train_loss=0.489, val_MAE=0.556, val_loss=0.556]Epoch    49: reducing learning rate of group 0 to 6.2500e-05.
Epoch 48:   5%|▍         | 49/1000 [54:56<17:38:39, 66.79s/it, lr=0.000125, test_MAE=0.593, time=67.8, train_MAE=0.489, train_loss=0.489, val_MAE=0.556, val_loss=0.556]Epoch 49:   5%|▍         | 49/1000 [54:56<17:38:39, 66.79s/it, lr=0.000125, test_MAE=0.593, time=67.8, train_MAE=0.489, train_loss=0.489, val_MAE=0.556, val_loss=0.556]Epoch 49:   5%|▍         | 49/1000 [56:02<17:38:39, 66.79s/it, lr=6.25e-5, test_MAE=0.59, time=65.6, train_MAE=0.48, train_loss=0.48, val_MAE=0.556, val_loss=0.556]    Epoch 49:   5%|▌         | 50/1000 [56:02<17:31:55, 66.44s/it, lr=6.25e-5, test_MAE=0.59, time=65.6, train_MAE=0.48, train_loss=0.48, val_MAE=0.556, val_loss=0.556]Epoch 50:   5%|▌         | 50/1000 [56:02<17:31:55, 66.44s/it, lr=6.25e-5, test_MAE=0.59, time=65.6, train_MAE=0.48, train_loss=0.48, val_MAE=0.556, val_loss=0.556]Epoch 50:   5%|▌         | 50/1000 [57:06<17:31:55, 66.44s/it, lr=6.25e-5, test_MAE=0.593, time=64.2, train_MAE=0.482, train_loss=0.482, val_MAE=0.558, val_loss=0.558]Epoch 50:   5%|▌         | 51/1000 [57:06<17:20:11, 65.77s/it, lr=6.25e-5, test_MAE=0.593, time=64.2, train_MAE=0.482, train_loss=0.482, val_MAE=0.558, val_loss=0.558]Epoch 51:   5%|▌         | 51/1000 [57:06<17:20:11, 65.77s/it, lr=6.25e-5, test_MAE=0.593, time=64.2, train_MAE=0.482, train_loss=0.482, val_MAE=0.558, val_loss=0.558]Epoch 51:   5%|▌         | 51/1000 [58:10<17:20:11, 65.77s/it, lr=6.25e-5, test_MAE=0.593, time=64.1, train_MAE=0.479, train_loss=0.479, val_MAE=0.56, val_loss=0.56]  Epoch 51:   5%|▌         | 52/1000 [58:10<17:11:05, 65.26s/it, lr=6.25e-5, test_MAE=0.593, time=64.1, train_MAE=0.479, train_loss=0.479, val_MAE=0.56, val_loss=0.56]Epoch 52:   5%|▌         | 52/1000 [58:10<17:11:05, 65.26s/it, lr=6.25e-5, test_MAE=0.593, time=64.1, train_MAE=0.479, train_loss=0.479, val_MAE=0.56, val_loss=0.56]Epoch 52:   5%|▌         | 52/1000 [59:16<17:11:05, 65.26s/it, lr=6.25e-5, test_MAE=0.597, time=65.3, train_MAE=0.474, train_loss=0.474, val_MAE=0.561, val_loss=0.561]Epoch 52:   5%|▌         | 53/1000 [59:16<17:10:04, 65.26s/it, lr=6.25e-5, test_MAE=0.597, time=65.3, train_MAE=0.474, train_loss=0.474, val_MAE=0.561, val_loss=0.561]Epoch 53:   5%|▌         | 53/1000 [59:16<17:10:04, 65.26s/it, lr=6.25e-5, test_MAE=0.597, time=65.3, train_MAE=0.474, train_loss=0.474, val_MAE=0.561, val_loss=0.561]Epoch 53:   5%|▌         | 53/1000 [1:00:22<17:10:04, 65.26s/it, lr=6.25e-5, test_MAE=0.59, time=66.8, train_MAE=0.481, train_loss=0.481, val_MAE=0.555, val_loss=0.555]Epoch 53:   5%|▌         | 54/1000 [1:00:22<17:16:33, 65.74s/it, lr=6.25e-5, test_MAE=0.59, time=66.8, train_MAE=0.481, train_loss=0.481, val_MAE=0.555, val_loss=0.555]Epoch 54:   5%|▌         | 54/1000 [1:00:22<17:16:33, 65.74s/it, lr=6.25e-5, test_MAE=0.59, time=66.8, train_MAE=0.481, train_loss=0.481, val_MAE=0.555, val_loss=0.555]Epoch 54:   5%|▌         | 54/1000 [1:01:30<17:16:33, 65.74s/it, lr=6.25e-5, test_MAE=0.593, time=67.6, train_MAE=0.476, train_loss=0.476, val_MAE=0.554, val_loss=0.554]Epoch    55: reducing learning rate of group 0 to 3.1250e-05.
Epoch 54:   6%|▌         | 55/1000 [1:01:30<17:24:31, 66.32s/it, lr=6.25e-5, test_MAE=0.593, time=67.6, train_MAE=0.476, train_loss=0.476, val_MAE=0.554, val_loss=0.554]Epoch 55:   6%|▌         | 55/1000 [1:01:30<17:24:31, 66.32s/it, lr=6.25e-5, test_MAE=0.593, time=67.6, train_MAE=0.476, train_loss=0.476, val_MAE=0.554, val_loss=0.554]Epoch 55:   6%|▌         | 55/1000 [1:02:37<17:24:31, 66.32s/it, lr=3.13e-5, test_MAE=0.591, time=66.7, train_MAE=0.482, train_loss=0.482, val_MAE=0.556, val_loss=0.556]Epoch 55:   6%|▌         | 56/1000 [1:02:37<17:25:31, 66.45s/it, lr=3.13e-5, test_MAE=0.591, time=66.7, train_MAE=0.482, train_loss=0.482, val_MAE=0.556, val_loss=0.556]Epoch 56:   6%|▌         | 56/1000 [1:02:37<17:25:31, 66.45s/it, lr=3.13e-5, test_MAE=0.591, time=66.7, train_MAE=0.482, train_loss=0.482, val_MAE=0.556, val_loss=0.556]Epoch 56:   6%|▌         | 56/1000 [1:03:43<17:25:31, 66.45s/it, lr=3.13e-5, test_MAE=0.596, time=66.3, train_MAE=0.473, train_loss=0.473, val_MAE=0.56, val_loss=0.56]  Epoch 56:   6%|▌         | 57/1000 [1:03:43<17:23:44, 66.41s/it, lr=3.13e-5, test_MAE=0.596, time=66.3, train_MAE=0.473, train_loss=0.473, val_MAE=0.56, val_loss=0.56]Epoch 57:   6%|▌         | 57/1000 [1:03:43<17:23:44, 66.41s/it, lr=3.13e-5, test_MAE=0.596, time=66.3, train_MAE=0.473, train_loss=0.473, val_MAE=0.56, val_loss=0.56]Epoch 57:   6%|▌         | 57/1000 [1:04:49<17:23:44, 66.41s/it, lr=3.13e-5, test_MAE=0.596, time=66, train_MAE=0.475, train_loss=0.475, val_MAE=0.559, val_loss=0.559]Epoch 57:   6%|▌         | 58/1000 [1:04:49<17:20:35, 66.28s/it, lr=3.13e-5, test_MAE=0.596, time=66, train_MAE=0.475, train_loss=0.475, val_MAE=0.559, val_loss=0.559]Epoch 58:   6%|▌         | 58/1000 [1:04:49<17:20:35, 66.28s/it, lr=3.13e-5, test_MAE=0.596, time=66, train_MAE=0.475, train_loss=0.475, val_MAE=0.559, val_loss=0.559]Epoch 58:   6%|▌         | 58/1000 [1:05:56<17:20:35, 66.28s/it, lr=3.13e-5, test_MAE=0.597, time=67.1, train_MAE=0.476, train_loss=0.476, val_MAE=0.561, val_loss=0.561]Epoch 58:   6%|▌         | 59/1000 [1:05:56<17:23:34, 66.54s/it, lr=3.13e-5, test_MAE=0.597, time=67.1, train_MAE=0.476, train_loss=0.476, val_MAE=0.561, val_loss=0.561]Epoch 59:   6%|▌         | 59/1000 [1:05:56<17:23:34, 66.54s/it, lr=3.13e-5, test_MAE=0.597, time=67.1, train_MAE=0.476, train_loss=0.476, val_MAE=0.561, val_loss=0.561]Epoch 59:   6%|▌         | 59/1000 [1:07:04<17:23:34, 66.54s/it, lr=3.13e-5, test_MAE=0.59, time=67.9, train_MAE=0.471, train_loss=0.471, val_MAE=0.556, val_loss=0.556] Epoch 59:   6%|▌         | 60/1000 [1:07:04<17:28:41, 66.94s/it, lr=3.13e-5, test_MAE=0.59, time=67.9, train_MAE=0.471, train_loss=0.471, val_MAE=0.556, val_loss=0.556]Epoch 60:   6%|▌         | 60/1000 [1:07:04<17:28:41, 66.94s/it, lr=3.13e-5, test_MAE=0.59, time=67.9, train_MAE=0.471, train_loss=0.471, val_MAE=0.556, val_loss=0.556]Epoch 60:   6%|▌         | 60/1000 [1:08:12<17:28:41, 66.94s/it, lr=3.13e-5, test_MAE=0.597, time=67.4, train_MAE=0.48, train_loss=0.48, val_MAE=0.567, val_loss=0.567] Epoch    61: reducing learning rate of group 0 to 1.5625e-05.
Epoch 60:   6%|▌         | 61/1000 [1:08:12<17:29:38, 67.07s/it, lr=3.13e-5, test_MAE=0.597, time=67.4, train_MAE=0.48, train_loss=0.48, val_MAE=0.567, val_loss=0.567]Epoch 61:   6%|▌         | 61/1000 [1:08:12<17:29:38, 67.07s/it, lr=3.13e-5, test_MAE=0.597, time=67.4, train_MAE=0.48, train_loss=0.48, val_MAE=0.567, val_loss=0.567]Epoch 61:   6%|▌         | 61/1000 [1:09:18<17:29:38, 67.07s/it, lr=1.56e-5, test_MAE=0.593, time=66.6, train_MAE=0.471, train_loss=0.471, val_MAE=0.557, val_loss=0.557]Epoch 61:   6%|▌         | 62/1000 [1:09:18<17:26:17, 66.93s/it, lr=1.56e-5, test_MAE=0.593, time=66.6, train_MAE=0.471, train_loss=0.471, val_MAE=0.557, val_loss=0.557]Epoch 62:   6%|▌         | 62/1000 [1:09:18<17:26:17, 66.93s/it, lr=1.56e-5, test_MAE=0.593, time=66.6, train_MAE=0.471, train_loss=0.471, val_MAE=0.557, val_loss=0.557]Epoch 62:   6%|▌         | 62/1000 [1:10:24<17:26:17, 66.93s/it, lr=1.56e-5, test_MAE=0.59, time=65.8, train_MAE=0.472, train_loss=0.472, val_MAE=0.559, val_loss=0.559] Epoch 62:   6%|▋         | 63/1000 [1:10:24<17:20:00, 66.60s/it, lr=1.56e-5, test_MAE=0.59, time=65.8, train_MAE=0.472, train_loss=0.472, val_MAE=0.559, val_loss=0.559]Epoch 63:   6%|▋         | 63/1000 [1:10:24<17:20:00, 66.60s/it, lr=1.56e-5, test_MAE=0.59, time=65.8, train_MAE=0.472, train_loss=0.472, val_MAE=0.559, val_loss=0.559]Epoch 63:   6%|▋         | 63/1000 [1:11:31<17:20:00, 66.60s/it, lr=1.56e-5, test_MAE=0.592, time=66.6, train_MAE=0.472, train_loss=0.472, val_MAE=0.556, val_loss=0.556]Epoch 63:   6%|▋         | 64/1000 [1:11:31<17:19:12, 66.62s/it, lr=1.56e-5, test_MAE=0.592, time=66.6, train_MAE=0.472, train_loss=0.472, val_MAE=0.556, val_loss=0.556]Epoch 64:   6%|▋         | 64/1000 [1:11:31<17:19:12, 66.62s/it, lr=1.56e-5, test_MAE=0.592, time=66.6, train_MAE=0.472, train_loss=0.472, val_MAE=0.556, val_loss=0.556]Epoch 64:   6%|▋         | 64/1000 [1:12:37<17:19:12, 66.62s/it, lr=1.56e-5, test_MAE=0.592, time=66.4, train_MAE=0.47, train_loss=0.47, val_MAE=0.557, val_loss=0.557]  Epoch 64:   6%|▋         | 65/1000 [1:12:37<17:17:03, 66.55s/it, lr=1.56e-5, test_MAE=0.592, time=66.4, train_MAE=0.47, train_loss=0.47, val_MAE=0.557, val_loss=0.557]Epoch 65:   6%|▋         | 65/1000 [1:12:37<17:17:03, 66.55s/it, lr=1.56e-5, test_MAE=0.592, time=66.4, train_MAE=0.47, train_loss=0.47, val_MAE=0.557, val_loss=0.557]Epoch 65:   6%|▋         | 65/1000 [1:13:43<17:17:03, 66.55s/it, lr=1.56e-5, test_MAE=0.59, time=66.3, train_MAE=0.47, train_loss=0.47, val_MAE=0.559, val_loss=0.559] Epoch 65:   7%|▋         | 66/1000 [1:13:43<17:14:38, 66.46s/it, lr=1.56e-5, test_MAE=0.59, time=66.3, train_MAE=0.47, train_loss=0.47, val_MAE=0.559, val_loss=0.559]Epoch 66:   7%|▋         | 66/1000 [1:13:43<17:14:38, 66.46s/it, lr=1.56e-5, test_MAE=0.59, time=66.3, train_MAE=0.47, train_loss=0.47, val_MAE=0.559, val_loss=0.559]Epoch 66:   7%|▋         | 66/1000 [1:14:50<17:14:38, 66.46s/it, lr=1.56e-5, test_MAE=0.591, time=66.4, train_MAE=0.468, train_loss=0.468, val_MAE=0.557, val_loss=0.557]Epoch    67: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 66:   7%|▋         | 66/1000 [1:14:50<17:39:02, 68.03s/it, lr=1.56e-5, test_MAE=0.591, time=66.4, train_MAE=0.468, train_loss=0.468, val_MAE=0.557, val_loss=0.557]
Test MAE: 0.5915
Train MAE: 0.4550
Convergence Time (Epochs): 66.0000
TOTAL TIME TAKEN: 4530.7471s
AVG TIME PER EPOCH: 67.0036s
