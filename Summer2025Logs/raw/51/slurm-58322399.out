I'm echoing to stdout
I'm echoing to stderr
My JobID is 58322399
I have 4 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.1096s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 16, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 4, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'cheb02_vec', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_sub', 'num_eigs': 16, 'bias_mode': 'spatial', 'l1_reg': 0.0, 'l2_reg': 0.0005, 'gen_reg': 0.0, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/aug07/zinc_train_rec.csv', 'test': 'supp_data/molecules/aug07/zinc_test_rec.csv', 'val': 'supp_data/molecules/aug07/zinc_val_rec.csv'}, 'fixMissingPhi1': False, 'extraOrtho': False, 'doublePrecision': True, 'eigval_hidden_dim': 100, 'eigval_num_hidden_layer': 3, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [04:51<?, ?it/s, lr=0.001, test_MAE=2.47, time=292, train_MAE=0.84, train_loss=0.967, val_MAE=2.44, val_loss=2.57]Epoch 0:   0%|          | 1/1000 [04:51<80:59:13, 291.85s/it, lr=0.001, test_MAE=2.47, time=292, train_MAE=0.84, train_loss=0.967, val_MAE=2.44, val_loss=2.57]Epoch 1:   0%|          | 1/1000 [04:51<80:59:13, 291.85s/it, lr=0.001, test_MAE=2.47, time=292, train_MAE=0.84, train_loss=0.967, val_MAE=2.44, val_loss=2.57]Epoch 1:   0%|          | 1/1000 [09:25<80:59:13, 291.85s/it, lr=0.001, test_MAE=0.71, time=274, train_MAE=0.695, train_loss=0.821, val_MAE=0.654, val_loss=0.779]Epoch 1:   0%|          | 2/1000 [09:25<79:24:25, 286.44s/it, lr=0.001, test_MAE=0.71, time=274, train_MAE=0.695, train_loss=0.821, val_MAE=0.654, val_loss=0.779]Epoch 2:   0%|          | 2/1000 [09:25<79:24:25, 286.44s/it, lr=0.001, test_MAE=0.71, time=274, train_MAE=0.695, train_loss=0.821, val_MAE=0.654, val_loss=0.779]Epoch 2:   0%|          | 2/1000 [13:58<79:24:25, 286.44s/it, lr=0.001, test_MAE=0.701, time=273, train_MAE=0.672, train_loss=0.797, val_MAE=0.673, val_loss=0.798]Epoch 2:   0%|          | 3/1000 [13:58<78:12:56, 282.42s/it, lr=0.001, test_MAE=0.701, time=273, train_MAE=0.672, train_loss=0.797, val_MAE=0.673, val_loss=0.798]Epoch 3:   0%|          | 3/1000 [13:58<78:12:56, 282.42s/it, lr=0.001, test_MAE=0.701, time=273, train_MAE=0.672, train_loss=0.797, val_MAE=0.673, val_loss=0.798]Epoch 3:   0%|          | 3/1000 [18:31<78:12:56, 282.42s/it, lr=0.001, test_MAE=0.88, time=273, train_MAE=0.647, train_loss=0.771, val_MAE=0.843, val_loss=0.966] Epoch 3:   0%|          | 4/1000 [18:31<77:19:37, 279.50s/it, lr=0.001, test_MAE=0.88, time=273, train_MAE=0.647, train_loss=0.771, val_MAE=0.843, val_loss=0.966]Epoch 4:   0%|          | 4/1000 [18:31<77:19:37, 279.50s/it, lr=0.001, test_MAE=0.88, time=273, train_MAE=0.647, train_loss=0.771, val_MAE=0.843, val_loss=0.966]Epoch 4:   0%|          | 4/1000 [23:05<77:19:37, 279.50s/it, lr=0.001, test_MAE=0.83, time=274, train_MAE=0.63, train_loss=0.753, val_MAE=0.786, val_loss=0.908] Epoch 4:   0%|          | 5/1000 [23:05<76:45:54, 277.74s/it, lr=0.001, test_MAE=0.83, time=274, train_MAE=0.63, train_loss=0.753, val_MAE=0.786, val_loss=0.908]Epoch 5:   0%|          | 5/1000 [23:05<76:45:54, 277.74s/it, lr=0.001, test_MAE=0.83, time=274, train_MAE=0.63, train_loss=0.753, val_MAE=0.786, val_loss=0.908]Epoch 5:   0%|          | 5/1000 [27:36<76:45:54, 277.74s/it, lr=0.001, test_MAE=1.03, time=272, train_MAE=0.652, train_loss=0.774, val_MAE=0.978, val_loss=1.1] Epoch 5:   1%|          | 6/1000 [27:36<76:11:46, 275.96s/it, lr=0.001, test_MAE=1.03, time=272, train_MAE=0.652, train_loss=0.774, val_MAE=0.978, val_loss=1.1]Epoch 6:   1%|          | 6/1000 [27:36<76:11:46, 275.96s/it, lr=0.001, test_MAE=1.03, time=272, train_MAE=0.652, train_loss=0.774, val_MAE=0.978, val_loss=1.1]Epoch 6:   1%|          | 6/1000 [32:09<76:11:46, 275.96s/it, lr=0.001, test_MAE=0.766, time=272, train_MAE=0.63, train_loss=0.751, val_MAE=0.721, val_loss=0.842]Epoch 6:   1%|          | 7/1000 [32:09<75:49:59, 274.92s/it, lr=0.001, test_MAE=0.766, time=272, train_MAE=0.63, train_loss=0.751, val_MAE=0.721, val_loss=0.842]Epoch 7:   1%|          | 7/1000 [32:09<75:49:59, 274.92s/it, lr=0.001, test_MAE=0.766, time=272, train_MAE=0.63, train_loss=0.751, val_MAE=0.721, val_loss=0.842]Epoch 7:   1%|          | 7/1000 [36:42<75:49:59, 274.92s/it, lr=0.001, test_MAE=0.787, time=274, train_MAE=0.617, train_loss=0.738, val_MAE=0.757, val_loss=0.877]Epoch     8: reducing learning rate of group 0 to 5.0000e-04.
Epoch 7:   1%|          | 8/1000 [36:42<75:38:54, 274.53s/it, lr=0.001, test_MAE=0.787, time=274, train_MAE=0.617, train_loss=0.738, val_MAE=0.757, val_loss=0.877]Epoch 8:   1%|          | 8/1000 [36:42<75:38:54, 274.53s/it, lr=0.001, test_MAE=0.787, time=274, train_MAE=0.617, train_loss=0.738, val_MAE=0.757, val_loss=0.877]Epoch 8:   1%|          | 8/1000 [41:14<75:38:54, 274.53s/it, lr=0.0005, test_MAE=0.668, time=272, train_MAE=0.6, train_loss=0.719, val_MAE=0.644, val_loss=0.763] Epoch 8:   1%|          | 9/1000 [41:14<75:20:24, 273.69s/it, lr=0.0005, test_MAE=0.668, time=272, train_MAE=0.6, train_loss=0.719, val_MAE=0.644, val_loss=0.763]Epoch 9:   1%|          | 9/1000 [41:14<75:20:24, 273.69s/it, lr=0.0005, test_MAE=0.668, time=272, train_MAE=0.6, train_loss=0.719, val_MAE=0.644, val_loss=0.763]Epoch 9:   1%|          | 9/1000 [45:47<75:20:24, 273.69s/it, lr=0.0005, test_MAE=0.631, time=273, train_MAE=0.592, train_loss=0.71, val_MAE=0.607, val_loss=0.725]Epoch 9:   1%|          | 10/1000 [45:47<75:10:30, 273.36s/it, lr=0.0005, test_MAE=0.631, time=273, train_MAE=0.592, train_loss=0.71, val_MAE=0.607, val_loss=0.725]Epoch 10:   1%|          | 10/1000 [45:47<75:10:30, 273.36s/it, lr=0.0005, test_MAE=0.631, time=273, train_MAE=0.592, train_loss=0.71, val_MAE=0.607, val_loss=0.725]Epoch 10:   1%|          | 10/1000 [50:20<75:10:30, 273.36s/it, lr=0.0005, test_MAE=0.656, time=273, train_MAE=0.583, train_loss=0.701, val_MAE=0.62, val_loss=0.738]Epoch 10:   1%|          | 11/1000 [50:20<75:05:57, 273.36s/it, lr=0.0005, test_MAE=0.656, time=273, train_MAE=0.583, train_loss=0.701, val_MAE=0.62, val_loss=0.738]Epoch 11:   1%|          | 11/1000 [50:20<75:05:57, 273.36s/it, lr=0.0005, test_MAE=0.656, time=273, train_MAE=0.583, train_loss=0.701, val_MAE=0.62, val_loss=0.738]Epoch 11:   1%|          | 11/1000 [54:52<75:05:57, 273.36s/it, lr=0.0005, test_MAE=0.729, time=272, train_MAE=0.581, train_loss=0.698, val_MAE=0.698, val_loss=0.815]Epoch 11:   1%|          | 12/1000 [54:52<74:55:22, 273.00s/it, lr=0.0005, test_MAE=0.729, time=272, train_MAE=0.581, train_loss=0.698, val_MAE=0.698, val_loss=0.815]Epoch 12:   1%|          | 12/1000 [54:52<74:55:22, 273.00s/it, lr=0.0005, test_MAE=0.729, time=272, train_MAE=0.581, train_loss=0.698, val_MAE=0.698, val_loss=0.815]Epoch 12:   1%|          | 12/1000 [59:25<74:55:22, 273.00s/it, lr=0.0005, test_MAE=0.671, time=273, train_MAE=0.572, train_loss=0.688, val_MAE=0.621, val_loss=0.738]Epoch 12:   1%|▏         | 13/1000 [59:25<74:48:44, 272.87s/it, lr=0.0005, test_MAE=0.671, time=273, train_MAE=0.572, train_loss=0.688, val_MAE=0.621, val_loss=0.738]Epoch 13:   1%|▏         | 13/1000 [59:25<74:48:44, 272.87s/it, lr=0.0005, test_MAE=0.671, time=273, train_MAE=0.572, train_loss=0.688, val_MAE=0.621, val_loss=0.738]Epoch 13:   1%|▏         | 13/1000 [1:03:58<74:48:44, 272.87s/it, lr=0.0005, test_MAE=0.768, time=273, train_MAE=0.571, train_loss=0.687, val_MAE=0.734, val_loss=0.85]Epoch 13:   1%|▏         | 14/1000 [1:03:58<74:46:25, 273.01s/it, lr=0.0005, test_MAE=0.768, time=273, train_MAE=0.571, train_loss=0.687, val_MAE=0.734, val_loss=0.85]Epoch 14:   1%|▏         | 14/1000 [1:03:58<74:46:25, 273.01s/it, lr=0.0005, test_MAE=0.768, time=273, train_MAE=0.571, train_loss=0.687, val_MAE=0.734, val_loss=0.85]Epoch 14:   1%|▏         | 14/1000 [1:08:30<74:46:25, 273.01s/it, lr=0.0005, test_MAE=0.767, time=272, train_MAE=0.574, train_loss=0.69, val_MAE=0.683, val_loss=0.799]Epoch 14:   2%|▏         | 15/1000 [1:08:30<74:36:45, 272.70s/it, lr=0.0005, test_MAE=0.767, time=272, train_MAE=0.574, train_loss=0.69, val_MAE=0.683, val_loss=0.799]Epoch 15:   2%|▏         | 15/1000 [1:08:30<74:36:45, 272.70s/it, lr=0.0005, test_MAE=0.767, time=272, train_MAE=0.574, train_loss=0.69, val_MAE=0.683, val_loss=0.799]Epoch 15:   2%|▏         | 15/1000 [1:13:03<74:36:45, 272.70s/it, lr=0.0005, test_MAE=0.747, time=273, train_MAE=0.573, train_loss=0.689, val_MAE=0.708, val_loss=0.824]Epoch    16: reducing learning rate of group 0 to 2.5000e-04.
Epoch 15:   2%|▏         | 16/1000 [1:13:03<74:31:51, 272.67s/it, lr=0.0005, test_MAE=0.747, time=273, train_MAE=0.573, train_loss=0.689, val_MAE=0.708, val_loss=0.824]Epoch 16:   2%|▏         | 16/1000 [1:13:03<74:31:51, 272.67s/it, lr=0.0005, test_MAE=0.747, time=273, train_MAE=0.573, train_loss=0.689, val_MAE=0.708, val_loss=0.824]Epoch 16:   2%|▏         | 16/1000 [1:17:37<74:31:51, 272.67s/it, lr=0.00025, test_MAE=0.802, time=274, train_MAE=0.544, train_loss=0.659, val_MAE=0.769, val_loss=0.884]Epoch 16:   2%|▏         | 17/1000 [1:17:37<74:33:06, 273.03s/it, lr=0.00025, test_MAE=0.802, time=274, train_MAE=0.544, train_loss=0.659, val_MAE=0.769, val_loss=0.884]Epoch 17:   2%|▏         | 17/1000 [1:17:37<74:33:06, 273.03s/it, lr=0.00025, test_MAE=0.802, time=274, train_MAE=0.544, train_loss=0.659, val_MAE=0.769, val_loss=0.884]Epoch 17:   2%|▏         | 17/1000 [1:22:09<74:33:06, 273.03s/it, lr=0.00025, test_MAE=0.672, time=272, train_MAE=0.534, train_loss=0.649, val_MAE=0.62, val_loss=0.735] Epoch 17:   2%|▏         | 18/1000 [1:22:09<74:23:24, 272.71s/it, lr=0.00025, test_MAE=0.672, time=272, train_MAE=0.534, train_loss=0.649, val_MAE=0.62, val_loss=0.735]Epoch 18:   2%|▏         | 18/1000 [1:22:09<74:23:24, 272.71s/it, lr=0.00025, test_MAE=0.672, time=272, train_MAE=0.534, train_loss=0.649, val_MAE=0.62, val_loss=0.735]Epoch 18:   2%|▏         | 18/1000 [1:26:41<74:23:24, 272.71s/it, lr=0.00025, test_MAE=0.651, time=273, train_MAE=0.527, train_loss=0.642, val_MAE=0.605, val_loss=0.719]Epoch 18:   2%|▏         | 19/1000 [1:26:41<74:19:07, 272.73s/it, lr=0.00025, test_MAE=0.651, time=273, train_MAE=0.527, train_loss=0.642, val_MAE=0.605, val_loss=0.719]Epoch 19:   2%|▏         | 19/1000 [1:26:41<74:19:07, 272.73s/it, lr=0.00025, test_MAE=0.651, time=273, train_MAE=0.527, train_loss=0.642, val_MAE=0.605, val_loss=0.719]Epoch 19:   2%|▏         | 19/1000 [1:31:15<74:19:07, 272.73s/it, lr=0.00025, test_MAE=0.649, time=274, train_MAE=0.525, train_loss=0.639, val_MAE=0.595, val_loss=0.709]Epoch 19:   2%|▏         | 20/1000 [1:31:15<74:19:04, 273.00s/it, lr=0.00025, test_MAE=0.649, time=274, train_MAE=0.525, train_loss=0.639, val_MAE=0.595, val_loss=0.709]Epoch 20:   2%|▏         | 20/1000 [1:31:15<74:19:04, 273.00s/it, lr=0.00025, test_MAE=0.649, time=274, train_MAE=0.525, train_loss=0.639, val_MAE=0.595, val_loss=0.709]Epoch 20:   2%|▏         | 20/1000 [1:35:47<74:19:04, 273.00s/it, lr=0.00025, test_MAE=0.641, time=272, train_MAE=0.526, train_loss=0.64, val_MAE=0.605, val_loss=0.719] Epoch 20:   2%|▏         | 21/1000 [1:35:47<74:08:46, 272.65s/it, lr=0.00025, test_MAE=0.641, time=272, train_MAE=0.526, train_loss=0.64, val_MAE=0.605, val_loss=0.719]Epoch 21:   2%|▏         | 21/1000 [1:35:47<74:08:46, 272.65s/it, lr=0.00025, test_MAE=0.641, time=272, train_MAE=0.526, train_loss=0.64, val_MAE=0.605, val_loss=0.719]Epoch 21:   2%|▏         | 21/1000 [1:40:19<74:08:46, 272.65s/it, lr=0.00025, test_MAE=0.701, time=273, train_MAE=0.522, train_loss=0.636, val_MAE=0.65, val_loss=0.764]Epoch 21:   2%|▏         | 22/1000 [1:40:19<74:03:49, 272.63s/it, lr=0.00025, test_MAE=0.701, time=273, train_MAE=0.522, train_loss=0.636, val_MAE=0.65, val_loss=0.764]Epoch 22:   2%|▏         | 22/1000 [1:40:19<74:03:49, 272.63s/it, lr=0.00025, test_MAE=0.701, time=273, train_MAE=0.522, train_loss=0.636, val_MAE=0.65, val_loss=0.764]Epoch 22:   2%|▏         | 22/1000 [1:44:53<74:03:49, 272.63s/it, lr=0.00025, test_MAE=0.683, time=273, train_MAE=0.512, train_loss=0.626, val_MAE=0.646, val_loss=0.76]Epoch 22:   2%|▏         | 23/1000 [1:44:53<74:03:27, 272.88s/it, lr=0.00025, test_MAE=0.683, time=273, train_MAE=0.512, train_loss=0.626, val_MAE=0.646, val_loss=0.76]Epoch 23:   2%|▏         | 23/1000 [1:44:53<74:03:27, 272.88s/it, lr=0.00025, test_MAE=0.683, time=273, train_MAE=0.512, train_loss=0.626, val_MAE=0.646, val_loss=0.76]Epoch 23:   2%|▏         | 23/1000 [1:49:25<74:03:27, 272.88s/it, lr=0.00025, test_MAE=0.796, time=272, train_MAE=0.529, train_loss=0.643, val_MAE=0.768, val_loss=0.881]Epoch 23:   2%|▏         | 24/1000 [1:49:25<73:53:39, 272.56s/it, lr=0.00025, test_MAE=0.796, time=272, train_MAE=0.529, train_loss=0.643, val_MAE=0.768, val_loss=0.881]Epoch 24:   2%|▏         | 24/1000 [1:49:25<73:53:39, 272.56s/it, lr=0.00025, test_MAE=0.796, time=272, train_MAE=0.529, train_loss=0.643, val_MAE=0.768, val_loss=0.881]Epoch 24:   2%|▏         | 24/1000 [1:53:58<73:53:39, 272.56s/it, lr=0.00025, test_MAE=0.655, time=273, train_MAE=0.512, train_loss=0.625, val_MAE=0.593, val_loss=0.707]Epoch 24:   2%|▎         | 25/1000 [1:53:58<73:50:41, 272.66s/it, lr=0.00025, test_MAE=0.655, time=273, train_MAE=0.512, train_loss=0.625, val_MAE=0.593, val_loss=0.707]Epoch 25:   2%|▎         | 25/1000 [1:53:58<73:50:41, 272.66s/it, lr=0.00025, test_MAE=0.655, time=273, train_MAE=0.512, train_loss=0.625, val_MAE=0.593, val_loss=0.707]Epoch 25:   2%|▎         | 25/1000 [1:58:31<73:50:41, 272.66s/it, lr=0.00025, test_MAE=0.696, time=274, train_MAE=0.502, train_loss=0.615, val_MAE=0.63, val_loss=0.743] Epoch 25:   3%|▎         | 26/1000 [1:58:31<73:50:41, 272.94s/it, lr=0.00025, test_MAE=0.696, time=274, train_MAE=0.502, train_loss=0.615, val_MAE=0.63, val_loss=0.743]Epoch 26:   3%|▎         | 26/1000 [1:58:31<73:50:41, 272.94s/it, lr=0.00025, test_MAE=0.696, time=274, train_MAE=0.502, train_loss=0.615, val_MAE=0.63, val_loss=0.743]Epoch 26:   3%|▎         | 26/1000 [2:03:06<73:50:41, 272.94s/it, lr=0.00025, test_MAE=0.668, time=275, train_MAE=0.5, train_loss=0.613, val_MAE=0.62, val_loss=0.733]  Epoch 26:   3%|▎         | 27/1000 [2:03:06<73:54:28, 273.45s/it, lr=0.00025, test_MAE=0.668, time=275, train_MAE=0.5, train_loss=0.613, val_MAE=0.62, val_loss=0.733]Epoch 27:   3%|▎         | 27/1000 [2:03:06<73:54:28, 273.45s/it, lr=0.00025, test_MAE=0.668, time=275, train_MAE=0.5, train_loss=0.613, val_MAE=0.62, val_loss=0.733]Epoch 27:   3%|▎         | 27/1000 [2:07:42<73:54:28, 273.45s/it, lr=0.00025, test_MAE=0.639, time=276, train_MAE=0.503, train_loss=0.616, val_MAE=0.602, val_loss=0.715]Epoch 27:   3%|▎         | 28/1000 [2:07:42<74:02:19, 274.22s/it, lr=0.00025, test_MAE=0.639, time=276, train_MAE=0.503, train_loss=0.616, val_MAE=0.602, val_loss=0.715]Epoch 28:   3%|▎         | 28/1000 [2:07:42<74:02:19, 274.22s/it, lr=0.00025, test_MAE=0.639, time=276, train_MAE=0.503, train_loss=0.616, val_MAE=0.602, val_loss=0.715]Epoch 28:   3%|▎         | 28/1000 [2:12:18<74:02:19, 274.22s/it, lr=0.00025, test_MAE=0.63, time=277, train_MAE=0.497, train_loss=0.61, val_MAE=0.598, val_loss=0.711]  Epoch 28:   3%|▎         | 29/1000 [2:12:19<74:09:45, 274.96s/it, lr=0.00025, test_MAE=0.63, time=277, train_MAE=0.497, train_loss=0.61, val_MAE=0.598, val_loss=0.711]Epoch 29:   3%|▎         | 29/1000 [2:12:19<74:09:45, 274.96s/it, lr=0.00025, test_MAE=0.63, time=277, train_MAE=0.497, train_loss=0.61, val_MAE=0.598, val_loss=0.711]Epoch 29:   3%|▎         | 29/1000 [2:16:54<74:09:45, 274.96s/it, lr=0.00025, test_MAE=0.67, time=275, train_MAE=0.494, train_loss=0.607, val_MAE=0.634, val_loss=0.747]Epoch 29:   3%|▎         | 30/1000 [2:16:54<74:05:23, 274.97s/it, lr=0.00025, test_MAE=0.67, time=275, train_MAE=0.494, train_loss=0.607, val_MAE=0.634, val_loss=0.747]Epoch 30:   3%|▎         | 30/1000 [2:16:54<74:05:23, 274.97s/it, lr=0.00025, test_MAE=0.67, time=275, train_MAE=0.494, train_loss=0.607, val_MAE=0.634, val_loss=0.747]Epoch 30:   3%|▎         | 30/1000 [2:21:32<74:05:23, 274.97s/it, lr=0.00025, test_MAE=0.648, time=278, train_MAE=0.492, train_loss=0.605, val_MAE=0.611, val_loss=0.724]Epoch    31: reducing learning rate of group 0 to 1.2500e-04.
Epoch 30:   3%|▎         | 31/1000 [2:21:32<74:17:01, 275.98s/it, lr=0.00025, test_MAE=0.648, time=278, train_MAE=0.492, train_loss=0.605, val_MAE=0.611, val_loss=0.724]Epoch 31:   3%|▎         | 31/1000 [2:21:32<74:17:01, 275.98s/it, lr=0.00025, test_MAE=0.648, time=278, train_MAE=0.492, train_loss=0.605, val_MAE=0.611, val_loss=0.724]Epoch 31:   3%|▎         | 31/1000 [2:26:11<74:17:01, 275.98s/it, lr=0.000125, test_MAE=0.623, time=279, train_MAE=0.464, train_loss=0.577, val_MAE=0.577, val_loss=0.69]Epoch 31:   3%|▎         | 32/1000 [2:26:11<74:29:20, 277.03s/it, lr=0.000125, test_MAE=0.623, time=279, train_MAE=0.464, train_loss=0.577, val_MAE=0.577, val_loss=0.69]Epoch 32:   3%|▎         | 32/1000 [2:26:11<74:29:20, 277.03s/it, lr=0.000125, test_MAE=0.623, time=279, train_MAE=0.464, train_loss=0.577, val_MAE=0.577, val_loss=0.69]Epoch 32:   3%|▎         | 32/1000 [2:30:50<74:29:20, 277.03s/it, lr=0.000125, test_MAE=0.642, time=278, train_MAE=0.463, train_loss=0.575, val_MAE=0.606, val_loss=0.719]Epoch 32:   3%|▎         | 33/1000 [2:30:50<74:30:45, 277.40s/it, lr=0.000125, test_MAE=0.642, time=278, train_MAE=0.463, train_loss=0.575, val_MAE=0.606, val_loss=0.719]Epoch 33:   3%|▎         | 33/1000 [2:30:50<74:30:45, 277.40s/it, lr=0.000125, test_MAE=0.642, time=278, train_MAE=0.463, train_loss=0.575, val_MAE=0.606, val_loss=0.719]Epoch 33:   3%|▎         | 33/1000 [2:35:28<74:30:45, 277.40s/it, lr=0.000125, test_MAE=0.658, time=279, train_MAE=0.449, train_loss=0.562, val_MAE=0.607, val_loss=0.72] Epoch 33:   3%|▎         | 34/1000 [2:35:29<74:33:25, 277.85s/it, lr=0.000125, test_MAE=0.658, time=279, train_MAE=0.449, train_loss=0.562, val_MAE=0.607, val_loss=0.72]Epoch 34:   3%|▎         | 34/1000 [2:35:29<74:33:25, 277.85s/it, lr=0.000125, test_MAE=0.658, time=279, train_MAE=0.449, train_loss=0.562, val_MAE=0.607, val_loss=0.72]Epoch 34:   3%|▎         | 34/1000 [2:40:09<74:33:25, 277.85s/it, lr=0.000125, test_MAE=0.635, time=281, train_MAE=0.449, train_loss=0.562, val_MAE=0.597, val_loss=0.709]Epoch 34:   4%|▎         | 35/1000 [2:40:09<74:42:15, 278.69s/it, lr=0.000125, test_MAE=0.635, time=281, train_MAE=0.449, train_loss=0.562, val_MAE=0.597, val_loss=0.709]Epoch 35:   4%|▎         | 35/1000 [2:40:09<74:42:15, 278.69s/it, lr=0.000125, test_MAE=0.635, time=281, train_MAE=0.449, train_loss=0.562, val_MAE=0.597, val_loss=0.709]Epoch 35:   4%|▎         | 35/1000 [2:44:52<74:42:15, 278.69s/it, lr=0.000125, test_MAE=0.636, time=283, train_MAE=0.448, train_loss=0.56, val_MAE=0.603, val_loss=0.715] Epoch 35:   4%|▎         | 36/1000 [2:44:52<74:58:21, 279.98s/it, lr=0.000125, test_MAE=0.636, time=283, train_MAE=0.448, train_loss=0.56, val_MAE=0.603, val_loss=0.715]Epoch 36:   4%|▎         | 36/1000 [2:44:52<74:58:21, 279.98s/it, lr=0.000125, test_MAE=0.636, time=283, train_MAE=0.448, train_loss=0.56, val_MAE=0.603, val_loss=0.715]Epoch 36:   4%|▎         | 36/1000 [2:49:33<74:58:21, 279.98s/it, lr=0.000125, test_MAE=0.632, time=281, train_MAE=0.451, train_loss=0.563, val_MAE=0.599, val_loss=0.711]Epoch 36:   4%|▎         | 37/1000 [2:49:33<74:57:02, 280.19s/it, lr=0.000125, test_MAE=0.632, time=281, train_MAE=0.451, train_loss=0.563, val_MAE=0.599, val_loss=0.711]Epoch 37:   4%|▎         | 37/1000 [2:49:33<74:57:02, 280.19s/it, lr=0.000125, test_MAE=0.632, time=281, train_MAE=0.451, train_loss=0.563, val_MAE=0.599, val_loss=0.711]Epoch 37:   4%|▎         | 37/1000 [2:54:10<74:57:02, 280.19s/it, lr=0.000125, test_MAE=0.655, time=277, train_MAE=0.434, train_loss=0.546, val_MAE=0.609, val_loss=0.721]Epoch    38: reducing learning rate of group 0 to 6.2500e-05.
Epoch 37:   4%|▍         | 38/1000 [2:54:10<74:36:25, 279.19s/it, lr=0.000125, test_MAE=0.655, time=277, train_MAE=0.434, train_loss=0.546, val_MAE=0.609, val_loss=0.721]Epoch 38:   4%|▍         | 38/1000 [2:54:10<74:36:25, 279.19s/it, lr=0.000125, test_MAE=0.655, time=277, train_MAE=0.434, train_loss=0.546, val_MAE=0.609, val_loss=0.721]Epoch 38:   4%|▍         | 38/1000 [2:58:45<74:36:25, 279.19s/it, lr=6.25e-5, test_MAE=0.64, time=275, train_MAE=0.422, train_loss=0.534, val_MAE=0.591, val_loss=0.703]  Epoch 38:   4%|▍         | 39/1000 [2:58:45<74:11:01, 277.90s/it, lr=6.25e-5, test_MAE=0.64, time=275, train_MAE=0.422, train_loss=0.534, val_MAE=0.591, val_loss=0.703]Epoch 39:   4%|▍         | 39/1000 [2:58:45<74:11:01, 277.90s/it, lr=6.25e-5, test_MAE=0.64, time=275, train_MAE=0.422, train_loss=0.534, val_MAE=0.591, val_loss=0.703]Epoch 39:   4%|▍         | 39/1000 [3:03:20<74:11:01, 277.90s/it, lr=6.25e-5, test_MAE=0.632, time=276, train_MAE=0.405, train_loss=0.517, val_MAE=0.591, val_loss=0.703]Epoch 39:   4%|▍         | 40/1000 [3:03:20<73:55:11, 277.20s/it, lr=6.25e-5, test_MAE=0.632, time=276, train_MAE=0.405, train_loss=0.517, val_MAE=0.591, val_loss=0.703]Epoch 40:   4%|▍         | 40/1000 [3:03:20<73:55:11, 277.20s/it, lr=6.25e-5, test_MAE=0.632, time=276, train_MAE=0.405, train_loss=0.517, val_MAE=0.591, val_loss=0.703]Epoch 40:   4%|▍         | 40/1000 [3:07:57<73:55:11, 277.20s/it, lr=6.25e-5, test_MAE=0.637, time=276, train_MAE=0.411, train_loss=0.523, val_MAE=0.586, val_loss=0.697]Epoch 40:   4%|▍         | 41/1000 [3:07:57<73:47:06, 276.98s/it, lr=6.25e-5, test_MAE=0.637, time=276, train_MAE=0.411, train_loss=0.523, val_MAE=0.586, val_loss=0.697]Epoch 41:   4%|▍         | 41/1000 [3:07:57<73:47:06, 276.98s/it, lr=6.25e-5, test_MAE=0.637, time=276, train_MAE=0.411, train_loss=0.523, val_MAE=0.586, val_loss=0.697]Epoch 41:   4%|▍         | 41/1000 [3:12:32<73:47:06, 276.98s/it, lr=6.25e-5, test_MAE=0.728, time=275, train_MAE=0.407, train_loss=0.519, val_MAE=0.689, val_loss=0.8]  Epoch 41:   4%|▍         | 42/1000 [3:12:32<73:34:06, 276.46s/it, lr=6.25e-5, test_MAE=0.728, time=275, train_MAE=0.407, train_loss=0.519, val_MAE=0.689, val_loss=0.8]Epoch 42:   4%|▍         | 42/1000 [3:12:32<73:34:06, 276.46s/it, lr=6.25e-5, test_MAE=0.728, time=275, train_MAE=0.407, train_loss=0.519, val_MAE=0.689, val_loss=0.8]Epoch 42:   4%|▍         | 42/1000 [3:17:07<73:34:06, 276.46s/it, lr=6.25e-5, test_MAE=0.653, time=275, train_MAE=0.415, train_loss=0.527, val_MAE=0.609, val_loss=0.721]Epoch 42:   4%|▍         | 43/1000 [3:17:07<73:22:53, 276.04s/it, lr=6.25e-5, test_MAE=0.653, time=275, train_MAE=0.415, train_loss=0.527, val_MAE=0.609, val_loss=0.721]Epoch 43:   4%|▍         | 43/1000 [3:17:07<73:22:53, 276.04s/it, lr=6.25e-5, test_MAE=0.653, time=275, train_MAE=0.415, train_loss=0.527, val_MAE=0.609, val_loss=0.721]Epoch 43:   4%|▍         | 43/1000 [3:21:33<73:22:53, 276.04s/it, lr=6.25e-5, test_MAE=0.639, time=266, train_MAE=0.401, train_loss=0.513, val_MAE=0.59, val_loss=0.701] Epoch    44: reducing learning rate of group 0 to 3.1250e-05.
Epoch 43:   4%|▍         | 44/1000 [3:21:33<72:31:54, 273.13s/it, lr=6.25e-5, test_MAE=0.639, time=266, train_MAE=0.401, train_loss=0.513, val_MAE=0.59, val_loss=0.701]Epoch 44:   4%|▍         | 44/1000 [3:21:33<72:31:54, 273.13s/it, lr=6.25e-5, test_MAE=0.639, time=266, train_MAE=0.401, train_loss=0.513, val_MAE=0.59, val_loss=0.701]Epoch 44:   4%|▍         | 44/1000 [3:25:51<72:31:54, 273.13s/it, lr=3.13e-5, test_MAE=0.639, time=258, train_MAE=0.389, train_loss=0.501, val_MAE=0.597, val_loss=0.709]Epoch 44:   4%|▍         | 45/1000 [3:25:51<71:13:10, 268.47s/it, lr=3.13e-5, test_MAE=0.639, time=258, train_MAE=0.389, train_loss=0.501, val_MAE=0.597, val_loss=0.709]Epoch 45:   4%|▍         | 45/1000 [3:25:51<71:13:10, 268.47s/it, lr=3.13e-5, test_MAE=0.639, time=258, train_MAE=0.389, train_loss=0.501, val_MAE=0.597, val_loss=0.709]Epoch 45:   4%|▍         | 45/1000 [3:30:08<71:13:10, 268.47s/it, lr=3.13e-5, test_MAE=0.635, time=257, train_MAE=0.391, train_loss=0.502, val_MAE=0.59, val_loss=0.701] Epoch 45:   5%|▍         | 46/1000 [3:30:08<70:16:06, 265.16s/it, lr=3.13e-5, test_MAE=0.635, time=257, train_MAE=0.391, train_loss=0.502, val_MAE=0.59, val_loss=0.701]Epoch 46:   5%|▍         | 46/1000 [3:30:08<70:16:06, 265.16s/it, lr=3.13e-5, test_MAE=0.635, time=257, train_MAE=0.391, train_loss=0.502, val_MAE=0.59, val_loss=0.701]Epoch 46:   5%|▍         | 46/1000 [3:34:26<70:16:06, 265.16s/it, lr=3.13e-5, test_MAE=0.642, time=258, train_MAE=0.39, train_loss=0.502, val_MAE=0.594, val_loss=0.705]Epoch 46:   5%|▍         | 47/1000 [3:34:26<69:37:58, 263.04s/it, lr=3.13e-5, test_MAE=0.642, time=258, train_MAE=0.39, train_loss=0.502, val_MAE=0.594, val_loss=0.705]Epoch 47:   5%|▍         | 47/1000 [3:34:26<69:37:58, 263.04s/it, lr=3.13e-5, test_MAE=0.642, time=258, train_MAE=0.39, train_loss=0.502, val_MAE=0.594, val_loss=0.705]Epoch 47:   5%|▍         | 47/1000 [3:38:43<69:37:58, 263.04s/it, lr=3.13e-5, test_MAE=0.641, time=257, train_MAE=0.392, train_loss=0.504, val_MAE=0.594, val_loss=0.705]Epoch 47:   5%|▍         | 48/1000 [3:38:43<69:04:12, 261.19s/it, lr=3.13e-5, test_MAE=0.641, time=257, train_MAE=0.392, train_loss=0.504, val_MAE=0.594, val_loss=0.705]Epoch 48:   5%|▍         | 48/1000 [3:38:43<69:04:12, 261.19s/it, lr=3.13e-5, test_MAE=0.641, time=257, train_MAE=0.392, train_loss=0.504, val_MAE=0.594, val_loss=0.705]Epoch 48:   5%|▍         | 48/1000 [3:43:01<69:04:12, 261.19s/it, lr=3.13e-5, test_MAE=0.64, time=257, train_MAE=0.386, train_loss=0.497, val_MAE=0.593, val_loss=0.704] Epoch 48:   5%|▍         | 49/1000 [3:43:01<68:41:57, 260.06s/it, lr=3.13e-5, test_MAE=0.64, time=257, train_MAE=0.386, train_loss=0.497, val_MAE=0.593, val_loss=0.704]Epoch 49:   5%|▍         | 49/1000 [3:43:01<68:41:57, 260.06s/it, lr=3.13e-5, test_MAE=0.64, time=257, train_MAE=0.386, train_loss=0.497, val_MAE=0.593, val_loss=0.704]Epoch 49:   5%|▍         | 49/1000 [3:47:19<68:41:57, 260.06s/it, lr=3.13e-5, test_MAE=0.645, time=258, train_MAE=0.381, train_loss=0.493, val_MAE=0.593, val_loss=0.704]Epoch    50: reducing learning rate of group 0 to 1.5625e-05.
Epoch 49:   5%|▌         | 50/1000 [3:47:19<68:29:17, 259.53s/it, lr=3.13e-5, test_MAE=0.645, time=258, train_MAE=0.381, train_loss=0.493, val_MAE=0.593, val_loss=0.704]Epoch 50:   5%|▌         | 50/1000 [3:47:19<68:29:17, 259.53s/it, lr=3.13e-5, test_MAE=0.645, time=258, train_MAE=0.381, train_loss=0.493, val_MAE=0.593, val_loss=0.704]Epoch 50:   5%|▌         | 50/1000 [3:51:35<68:29:17, 259.53s/it, lr=1.56e-5, test_MAE=0.647, time=256, train_MAE=0.384, train_loss=0.495, val_MAE=0.593, val_loss=0.705]Epoch 50:   5%|▌         | 51/1000 [3:51:35<68:09:38, 258.57s/it, lr=1.56e-5, test_MAE=0.647, time=256, train_MAE=0.384, train_loss=0.495, val_MAE=0.593, val_loss=0.705]Epoch 51:   5%|▌         | 51/1000 [3:51:35<68:09:38, 258.57s/it, lr=1.56e-5, test_MAE=0.647, time=256, train_MAE=0.384, train_loss=0.495, val_MAE=0.593, val_loss=0.705]Epoch 51:   5%|▌         | 51/1000 [3:55:51<68:09:38, 258.57s/it, lr=1.56e-5, test_MAE=0.642, time=256, train_MAE=0.372, train_loss=0.483, val_MAE=0.592, val_loss=0.703]Epoch 51:   5%|▌         | 52/1000 [3:55:51<67:51:50, 257.71s/it, lr=1.56e-5, test_MAE=0.642, time=256, train_MAE=0.372, train_loss=0.483, val_MAE=0.592, val_loss=0.703]Epoch 52:   5%|▌         | 52/1000 [3:55:51<67:51:50, 257.71s/it, lr=1.56e-5, test_MAE=0.642, time=256, train_MAE=0.372, train_loss=0.483, val_MAE=0.592, val_loss=0.703]Epoch 52:   5%|▌         | 52/1000 [4:00:06<67:51:50, 257.71s/it, lr=1.56e-5, test_MAE=0.642, time=255, train_MAE=0.374, train_loss=0.485, val_MAE=0.592, val_loss=0.703]Epoch 52:   5%|▌         | 53/1000 [4:00:06<67:35:36, 256.95s/it, lr=1.56e-5, test_MAE=0.642, time=255, train_MAE=0.374, train_loss=0.485, val_MAE=0.592, val_loss=0.703]Epoch 53:   5%|▌         | 53/1000 [4:00:06<67:35:36, 256.95s/it, lr=1.56e-5, test_MAE=0.642, time=255, train_MAE=0.374, train_loss=0.485, val_MAE=0.592, val_loss=0.703]Epoch 53:   5%|▌         | 53/1000 [4:04:21<67:35:36, 256.95s/it, lr=1.56e-5, test_MAE=0.644, time=255, train_MAE=0.372, train_loss=0.483, val_MAE=0.598, val_loss=0.709]Epoch 53:   5%|▌         | 54/1000 [4:04:21<67:22:51, 256.42s/it, lr=1.56e-5, test_MAE=0.644, time=255, train_MAE=0.372, train_loss=0.483, val_MAE=0.598, val_loss=0.709]Epoch 54:   5%|▌         | 54/1000 [4:04:21<67:22:51, 256.42s/it, lr=1.56e-5, test_MAE=0.644, time=255, train_MAE=0.372, train_loss=0.483, val_MAE=0.598, val_loss=0.709]Epoch 54:   5%|▌         | 54/1000 [4:08:37<67:22:51, 256.42s/it, lr=1.56e-5, test_MAE=0.64, time=256, train_MAE=0.37, train_loss=0.481, val_MAE=0.589, val_loss=0.7]    Epoch 54:   6%|▌         | 55/1000 [4:08:37<67:15:19, 256.21s/it, lr=1.56e-5, test_MAE=0.64, time=256, train_MAE=0.37, train_loss=0.481, val_MAE=0.589, val_loss=0.7]Epoch 55:   6%|▌         | 55/1000 [4:08:37<67:15:19, 256.21s/it, lr=1.56e-5, test_MAE=0.64, time=256, train_MAE=0.37, train_loss=0.481, val_MAE=0.589, val_loss=0.7]Epoch 55:   6%|▌         | 55/1000 [4:12:54<67:15:19, 256.21s/it, lr=1.56e-5, test_MAE=0.644, time=257, train_MAE=0.377, train_loss=0.489, val_MAE=0.595, val_loss=0.706]Epoch    56: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 55:   6%|▌         | 55/1000 [4:12:54<72:25:20, 275.89s/it, lr=1.56e-5, test_MAE=0.644, time=257, train_MAE=0.377, train_loss=0.489, val_MAE=0.595, val_loss=0.706]
Test MAE: 0.6436
Train MAE: 0.3404
Convergence Time (Epochs): 55.0000
TOTAL TIME TAKEN: 15335.7259s
AVG TIME PER EPOCH: 270.9357s
