I'm echoing to stdout
I'm echoing to stderr
My JobID is 58016613
I have 4 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.1633s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 53, 'out_dim': 53, 'residual': True, 'readout': 'mean', 'k': 2, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'poly_mlp', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_all', 'num_eigs': 16, 'bias_mode': 'spatial', 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 0.0, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/aug07/zinc_train_rec.csv', 'test': 'supp_data/molecules/aug07/zinc_test_rec.csv', 'val': 'supp_data/molecules/aug07/zinc_val_rec.csv'}, 'fixMissingPhi1': False, 'extraOrtho': False, 'doublePrecision': True, 'eigval_hidden_dim': 100, 'eigval_num_hidden_layer': 0, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [01:19<?, ?it/s, lr=0.001, test_MAE=0.823, time=80, train_MAE=1.07, train_loss=1.07, val_MAE=0.774, val_loss=0.774]Epoch 0:   0%|          | 1/1000 [01:19<22:11:58, 80.00s/it, lr=0.001, test_MAE=0.823, time=80, train_MAE=1.07, train_loss=1.07, val_MAE=0.774, val_loss=0.774]Epoch 1:   0%|          | 1/1000 [01:19<22:11:58, 80.00s/it, lr=0.001, test_MAE=0.823, time=80, train_MAE=1.07, train_loss=1.07, val_MAE=0.774, val_loss=0.774]Epoch 1:   0%|          | 1/1000 [02:21<22:11:58, 80.00s/it, lr=0.001, test_MAE=0.711, time=61.8, train_MAE=0.714, train_loss=0.714, val_MAE=0.67, val_loss=0.67]Epoch 1:   0%|          | 2/1000 [02:21<20:40:03, 74.55s/it, lr=0.001, test_MAE=0.711, time=61.8, train_MAE=0.714, train_loss=0.714, val_MAE=0.67, val_loss=0.67]Epoch 2:   0%|          | 2/1000 [02:21<20:40:03, 74.55s/it, lr=0.001, test_MAE=0.711, time=61.8, train_MAE=0.714, train_loss=0.714, val_MAE=0.67, val_loss=0.67]Epoch 2:   0%|          | 2/1000 [03:23<20:40:03, 74.55s/it, lr=0.001, test_MAE=0.721, time=61.8, train_MAE=0.683, train_loss=0.683, val_MAE=0.672, val_loss=0.672]Epoch 2:   0%|          | 3/1000 [03:23<19:35:25, 70.74s/it, lr=0.001, test_MAE=0.721, time=61.8, train_MAE=0.683, train_loss=0.683, val_MAE=0.672, val_loss=0.672]Epoch 3:   0%|          | 3/1000 [03:23<19:35:25, 70.74s/it, lr=0.001, test_MAE=0.721, time=61.8, train_MAE=0.683, train_loss=0.683, val_MAE=0.672, val_loss=0.672]Epoch 3:   0%|          | 3/1000 [04:25<19:35:25, 70.74s/it, lr=0.001, test_MAE=0.709, time=61.8, train_MAE=0.65, train_loss=0.65, val_MAE=0.666, val_loss=0.666]  Epoch 3:   0%|          | 4/1000 [04:25<18:49:41, 68.05s/it, lr=0.001, test_MAE=0.709, time=61.8, train_MAE=0.65, train_loss=0.65, val_MAE=0.666, val_loss=0.666]Epoch 4:   0%|          | 4/1000 [04:25<18:49:41, 68.05s/it, lr=0.001, test_MAE=0.709, time=61.8, train_MAE=0.65, train_loss=0.65, val_MAE=0.666, val_loss=0.666]Epoch 4:   0%|          | 4/1000 [05:27<18:49:41, 68.05s/it, lr=0.001, test_MAE=0.698, time=61.7, train_MAE=0.649, train_loss=0.649, val_MAE=0.65, val_loss=0.65]Epoch 4:   0%|          | 5/1000 [05:27<18:17:10, 66.16s/it, lr=0.001, test_MAE=0.698, time=61.7, train_MAE=0.649, train_loss=0.649, val_MAE=0.65, val_loss=0.65]Epoch 5:   0%|          | 5/1000 [05:27<18:17:10, 66.16s/it, lr=0.001, test_MAE=0.698, time=61.7, train_MAE=0.649, train_loss=0.649, val_MAE=0.65, val_loss=0.65]Epoch 5:   0%|          | 5/1000 [06:28<18:17:10, 66.16s/it, lr=0.001, test_MAE=0.666, time=61.8, train_MAE=0.632, train_loss=0.632, val_MAE=0.626, val_loss=0.626]Epoch 5:   1%|          | 6/1000 [06:28<17:54:17, 64.85s/it, lr=0.001, test_MAE=0.666, time=61.8, train_MAE=0.632, train_loss=0.632, val_MAE=0.626, val_loss=0.626]Epoch 6:   1%|          | 6/1000 [06:28<17:54:17, 64.85s/it, lr=0.001, test_MAE=0.666, time=61.8, train_MAE=0.632, train_loss=0.632, val_MAE=0.626, val_loss=0.626]Epoch 6:   1%|          | 6/1000 [07:31<17:54:17, 64.85s/it, lr=0.001, test_MAE=0.879, time=62.1, train_MAE=0.633, train_loss=0.633, val_MAE=0.847, val_loss=0.847]Epoch 6:   1%|          | 7/1000 [07:31<17:39:52, 64.04s/it, lr=0.001, test_MAE=0.879, time=62.1, train_MAE=0.633, train_loss=0.633, val_MAE=0.847, val_loss=0.847]Epoch 7:   1%|          | 7/1000 [07:31<17:39:52, 64.04s/it, lr=0.001, test_MAE=0.879, time=62.1, train_MAE=0.633, train_loss=0.633, val_MAE=0.847, val_loss=0.847]Epoch 7:   1%|          | 7/1000 [08:33<17:39:52, 64.04s/it, lr=0.001, test_MAE=0.689, time=61.9, train_MAE=0.62, train_loss=0.62, val_MAE=0.643, val_loss=0.643]  Epoch 7:   1%|          | 8/1000 [08:33<17:28:30, 63.42s/it, lr=0.001, test_MAE=0.689, time=61.9, train_MAE=0.62, train_loss=0.62, val_MAE=0.643, val_loss=0.643]Epoch 8:   1%|          | 8/1000 [08:33<17:28:30, 63.42s/it, lr=0.001, test_MAE=0.689, time=61.9, train_MAE=0.62, train_loss=0.62, val_MAE=0.643, val_loss=0.643]Epoch 8:   1%|          | 8/1000 [09:35<17:28:30, 63.42s/it, lr=0.001, test_MAE=0.649, time=62.2, train_MAE=0.608, train_loss=0.608, val_MAE=0.601, val_loss=0.601]Epoch 8:   1%|          | 9/1000 [09:35<17:21:39, 63.07s/it, lr=0.001, test_MAE=0.649, time=62.2, train_MAE=0.608, train_loss=0.608, val_MAE=0.601, val_loss=0.601]Epoch 9:   1%|          | 9/1000 [09:35<17:21:39, 63.07s/it, lr=0.001, test_MAE=0.649, time=62.2, train_MAE=0.608, train_loss=0.608, val_MAE=0.601, val_loss=0.601]Epoch 9:   1%|          | 9/1000 [10:38<17:21:39, 63.07s/it, lr=0.001, test_MAE=0.695, time=63.3, train_MAE=0.612, train_loss=0.612, val_MAE=0.643, val_loss=0.643]Epoch 9:   1%|          | 10/1000 [10:38<17:21:45, 63.14s/it, lr=0.001, test_MAE=0.695, time=63.3, train_MAE=0.612, train_loss=0.612, val_MAE=0.643, val_loss=0.643]Epoch 10:   1%|          | 10/1000 [10:38<17:21:45, 63.14s/it, lr=0.001, test_MAE=0.695, time=63.3, train_MAE=0.612, train_loss=0.612, val_MAE=0.643, val_loss=0.643]Epoch 10:   1%|          | 10/1000 [11:41<17:21:45, 63.14s/it, lr=0.001, test_MAE=0.717, time=62.9, train_MAE=0.612, train_loss=0.612, val_MAE=0.679, val_loss=0.679]Epoch 10:   1%|          | 11/1000 [11:41<17:19:56, 63.09s/it, lr=0.001, test_MAE=0.717, time=62.9, train_MAE=0.612, train_loss=0.612, val_MAE=0.679, val_loss=0.679]Epoch 11:   1%|          | 11/1000 [11:41<17:19:56, 63.09s/it, lr=0.001, test_MAE=0.717, time=62.9, train_MAE=0.612, train_loss=0.612, val_MAE=0.679, val_loss=0.679]Epoch 11:   1%|          | 11/1000 [12:44<17:19:56, 63.09s/it, lr=0.001, test_MAE=0.687, time=62.8, train_MAE=0.606, train_loss=0.606, val_MAE=0.642, val_loss=0.642]Epoch 11:   1%|          | 12/1000 [12:44<17:17:43, 63.02s/it, lr=0.001, test_MAE=0.687, time=62.8, train_MAE=0.606, train_loss=0.606, val_MAE=0.642, val_loss=0.642]Epoch 12:   1%|          | 12/1000 [12:44<17:17:43, 63.02s/it, lr=0.001, test_MAE=0.687, time=62.8, train_MAE=0.606, train_loss=0.606, val_MAE=0.642, val_loss=0.642]Epoch 12:   1%|          | 12/1000 [13:47<17:17:43, 63.02s/it, lr=0.001, test_MAE=0.658, time=63.5, train_MAE=0.6, train_loss=0.6, val_MAE=0.607, val_loss=0.607]    Epoch 12:   1%|▏         | 13/1000 [13:48<17:19:01, 63.16s/it, lr=0.001, test_MAE=0.658, time=63.5, train_MAE=0.6, train_loss=0.6, val_MAE=0.607, val_loss=0.607]Epoch 13:   1%|▏         | 13/1000 [13:48<17:19:01, 63.16s/it, lr=0.001, test_MAE=0.658, time=63.5, train_MAE=0.6, train_loss=0.6, val_MAE=0.607, val_loss=0.607]Epoch 13:   1%|▏         | 13/1000 [14:51<17:19:01, 63.16s/it, lr=0.001, test_MAE=0.658, time=63.3, train_MAE=0.597, train_loss=0.597, val_MAE=0.613, val_loss=0.613]Epoch 13:   1%|▏         | 14/1000 [14:51<17:18:38, 63.20s/it, lr=0.001, test_MAE=0.658, time=63.3, train_MAE=0.597, train_loss=0.597, val_MAE=0.613, val_loss=0.613]Epoch 14:   1%|▏         | 14/1000 [14:51<17:18:38, 63.20s/it, lr=0.001, test_MAE=0.658, time=63.3, train_MAE=0.597, train_loss=0.597, val_MAE=0.613, val_loss=0.613]Epoch 14:   1%|▏         | 14/1000 [15:54<17:18:38, 63.20s/it, lr=0.001, test_MAE=1.14, time=63, train_MAE=0.607, train_loss=0.607, val_MAE=1.12, val_loss=1.12]     Epoch    15: reducing learning rate of group 0 to 5.0000e-04.
Epoch 14:   2%|▏         | 15/1000 [15:54<17:16:50, 63.16s/it, lr=0.001, test_MAE=1.14, time=63, train_MAE=0.607, train_loss=0.607, val_MAE=1.12, val_loss=1.12]Epoch 15:   2%|▏         | 15/1000 [15:54<17:16:50, 63.16s/it, lr=0.001, test_MAE=1.14, time=63, train_MAE=0.607, train_loss=0.607, val_MAE=1.12, val_loss=1.12]Epoch 15:   2%|▏         | 15/1000 [16:57<17:16:50, 63.16s/it, lr=0.0005, test_MAE=0.628, time=63.3, train_MAE=0.582, train_loss=0.582, val_MAE=0.584, val_loss=0.584]Epoch 15:   2%|▏         | 16/1000 [16:57<17:16:50, 63.22s/it, lr=0.0005, test_MAE=0.628, time=63.3, train_MAE=0.582, train_loss=0.582, val_MAE=0.584, val_loss=0.584]Epoch 16:   2%|▏         | 16/1000 [16:57<17:16:50, 63.22s/it, lr=0.0005, test_MAE=0.628, time=63.3, train_MAE=0.582, train_loss=0.582, val_MAE=0.584, val_loss=0.584]Epoch 16:   2%|▏         | 16/1000 [18:00<17:16:50, 63.22s/it, lr=0.0005, test_MAE=0.626, time=63, train_MAE=0.577, train_loss=0.577, val_MAE=0.589, val_loss=0.589]  Epoch 16:   2%|▏         | 17/1000 [18:00<17:14:58, 63.17s/it, lr=0.0005, test_MAE=0.626, time=63, train_MAE=0.577, train_loss=0.577, val_MAE=0.589, val_loss=0.589]Epoch 17:   2%|▏         | 17/1000 [18:00<17:14:58, 63.17s/it, lr=0.0005, test_MAE=0.626, time=63, train_MAE=0.577, train_loss=0.577, val_MAE=0.589, val_loss=0.589]Epoch 17:   2%|▏         | 17/1000 [19:03<17:14:58, 63.17s/it, lr=0.0005, test_MAE=0.666, time=62.5, train_MAE=0.576, train_loss=0.576, val_MAE=0.622, val_loss=0.622]Epoch 17:   2%|▏         | 18/1000 [19:03<17:10:47, 62.98s/it, lr=0.0005, test_MAE=0.666, time=62.5, train_MAE=0.576, train_loss=0.576, val_MAE=0.622, val_loss=0.622]Epoch 18:   2%|▏         | 18/1000 [19:03<17:10:47, 62.98s/it, lr=0.0005, test_MAE=0.666, time=62.5, train_MAE=0.576, train_loss=0.576, val_MAE=0.622, val_loss=0.622]Epoch 18:   2%|▏         | 18/1000 [20:06<17:10:47, 62.98s/it, lr=0.0005, test_MAE=0.623, time=63.2, train_MAE=0.578, train_loss=0.578, val_MAE=0.583, val_loss=0.583]Epoch 18:   2%|▏         | 19/1000 [20:06<17:11:00, 63.06s/it, lr=0.0005, test_MAE=0.623, time=63.2, train_MAE=0.578, train_loss=0.578, val_MAE=0.583, val_loss=0.583]Epoch 19:   2%|▏         | 19/1000 [20:06<17:11:00, 63.06s/it, lr=0.0005, test_MAE=0.623, time=63.2, train_MAE=0.578, train_loss=0.578, val_MAE=0.583, val_loss=0.583]Epoch 19:   2%|▏         | 19/1000 [21:09<17:11:00, 63.06s/it, lr=0.0005, test_MAE=0.786, time=62.7, train_MAE=0.578, train_loss=0.578, val_MAE=0.736, val_loss=0.736]Epoch 19:   2%|▏         | 20/1000 [21:09<17:08:27, 62.97s/it, lr=0.0005, test_MAE=0.786, time=62.7, train_MAE=0.578, train_loss=0.578, val_MAE=0.736, val_loss=0.736]Epoch 20:   2%|▏         | 20/1000 [21:09<17:08:27, 62.97s/it, lr=0.0005, test_MAE=0.786, time=62.7, train_MAE=0.578, train_loss=0.578, val_MAE=0.736, val_loss=0.736]Epoch 20:   2%|▏         | 20/1000 [22:11<17:08:27, 62.97s/it, lr=0.0005, test_MAE=0.632, time=62.6, train_MAE=0.563, train_loss=0.563, val_MAE=0.599, val_loss=0.599]Epoch 20:   2%|▏         | 21/1000 [22:11<17:05:51, 62.87s/it, lr=0.0005, test_MAE=0.632, time=62.6, train_MAE=0.563, train_loss=0.563, val_MAE=0.599, val_loss=0.599]Epoch 21:   2%|▏         | 21/1000 [22:11<17:05:51, 62.87s/it, lr=0.0005, test_MAE=0.632, time=62.6, train_MAE=0.563, train_loss=0.563, val_MAE=0.599, val_loss=0.599]Epoch 21:   2%|▏         | 21/1000 [23:15<17:05:51, 62.87s/it, lr=0.0005, test_MAE=0.662, time=63.5, train_MAE=0.568, train_loss=0.568, val_MAE=0.623, val_loss=0.623]Epoch 21:   2%|▏         | 22/1000 [23:15<17:07:43, 63.05s/it, lr=0.0005, test_MAE=0.662, time=63.5, train_MAE=0.568, train_loss=0.568, val_MAE=0.623, val_loss=0.623]Epoch 22:   2%|▏         | 22/1000 [23:15<17:07:43, 63.05s/it, lr=0.0005, test_MAE=0.662, time=63.5, train_MAE=0.568, train_loss=0.568, val_MAE=0.623, val_loss=0.623]Epoch 22:   2%|▏         | 22/1000 [24:17<17:07:43, 63.05s/it, lr=0.0005, test_MAE=0.64, time=62.4, train_MAE=0.571, train_loss=0.571, val_MAE=0.604, val_loss=0.604] Epoch 22:   2%|▏         | 23/1000 [24:17<17:03:47, 62.87s/it, lr=0.0005, test_MAE=0.64, time=62.4, train_MAE=0.571, train_loss=0.571, val_MAE=0.604, val_loss=0.604]Epoch 23:   2%|▏         | 23/1000 [24:17<17:03:47, 62.87s/it, lr=0.0005, test_MAE=0.64, time=62.4, train_MAE=0.571, train_loss=0.571, val_MAE=0.604, val_loss=0.604]Epoch 23:   2%|▏         | 23/1000 [25:21<17:03:47, 62.87s/it, lr=0.0005, test_MAE=0.634, time=63.5, train_MAE=0.569, train_loss=0.569, val_MAE=0.598, val_loss=0.598]Epoch 23:   2%|▏         | 24/1000 [25:21<17:06:00, 63.07s/it, lr=0.0005, test_MAE=0.634, time=63.5, train_MAE=0.569, train_loss=0.569, val_MAE=0.598, val_loss=0.598]Epoch 24:   2%|▏         | 24/1000 [25:21<17:06:00, 63.07s/it, lr=0.0005, test_MAE=0.634, time=63.5, train_MAE=0.569, train_loss=0.569, val_MAE=0.598, val_loss=0.598]Epoch 24:   2%|▏         | 24/1000 [26:24<17:06:00, 63.07s/it, lr=0.0005, test_MAE=0.624, time=62.6, train_MAE=0.564, train_loss=0.564, val_MAE=0.581, val_loss=0.581]Epoch 24:   2%|▎         | 25/1000 [26:24<17:02:46, 62.94s/it, lr=0.0005, test_MAE=0.624, time=62.6, train_MAE=0.564, train_loss=0.564, val_MAE=0.581, val_loss=0.581]Epoch 25:   2%|▎         | 25/1000 [26:24<17:02:46, 62.94s/it, lr=0.0005, test_MAE=0.624, time=62.6, train_MAE=0.564, train_loss=0.564, val_MAE=0.581, val_loss=0.581]Epoch 25:   2%|▎         | 25/1000 [27:25<17:02:46, 62.94s/it, lr=0.0005, test_MAE=0.664, time=61.9, train_MAE=0.559, train_loss=0.559, val_MAE=0.626, val_loss=0.626]Epoch 25:   3%|▎         | 26/1000 [27:26<16:57:01, 62.65s/it, lr=0.0005, test_MAE=0.664, time=61.9, train_MAE=0.559, train_loss=0.559, val_MAE=0.626, val_loss=0.626]Epoch 26:   3%|▎         | 26/1000 [27:26<16:57:01, 62.65s/it, lr=0.0005, test_MAE=0.664, time=61.9, train_MAE=0.559, train_loss=0.559, val_MAE=0.626, val_loss=0.626]Epoch 26:   3%|▎         | 26/1000 [28:28<16:57:01, 62.65s/it, lr=0.0005, test_MAE=0.78, time=62.3, train_MAE=0.566, train_loss=0.566, val_MAE=0.757, val_loss=0.757] Epoch 26:   3%|▎         | 27/1000 [28:28<16:54:17, 62.55s/it, lr=0.0005, test_MAE=0.78, time=62.3, train_MAE=0.566, train_loss=0.566, val_MAE=0.757, val_loss=0.757]Epoch 27:   3%|▎         | 27/1000 [28:28<16:54:17, 62.55s/it, lr=0.0005, test_MAE=0.78, time=62.3, train_MAE=0.566, train_loss=0.566, val_MAE=0.757, val_loss=0.757]Epoch 27:   3%|▎         | 27/1000 [29:30<16:54:17, 62.55s/it, lr=0.0005, test_MAE=0.632, time=61.7, train_MAE=0.566, train_loss=0.566, val_MAE=0.609, val_loss=0.609]Epoch 27:   3%|▎         | 28/1000 [29:30<16:49:13, 62.30s/it, lr=0.0005, test_MAE=0.632, time=61.7, train_MAE=0.566, train_loss=0.566, val_MAE=0.609, val_loss=0.609]Epoch 28:   3%|▎         | 28/1000 [29:30<16:49:13, 62.30s/it, lr=0.0005, test_MAE=0.632, time=61.7, train_MAE=0.566, train_loss=0.566, val_MAE=0.609, val_loss=0.609]Epoch 28:   3%|▎         | 28/1000 [30:33<16:49:13, 62.30s/it, lr=0.0005, test_MAE=0.613, time=63.1, train_MAE=0.562, train_loss=0.562, val_MAE=0.575, val_loss=0.575]Epoch 28:   3%|▎         | 29/1000 [30:33<16:52:27, 62.56s/it, lr=0.0005, test_MAE=0.613, time=63.1, train_MAE=0.562, train_loss=0.562, val_MAE=0.575, val_loss=0.575]Epoch 29:   3%|▎         | 29/1000 [30:33<16:52:27, 62.56s/it, lr=0.0005, test_MAE=0.613, time=63.1, train_MAE=0.562, train_loss=0.562, val_MAE=0.575, val_loss=0.575]Epoch 29:   3%|▎         | 29/1000 [31:39<16:52:27, 62.56s/it, lr=0.0005, test_MAE=0.656, time=65.9, train_MAE=0.556, train_loss=0.556, val_MAE=0.621, val_loss=0.621]Epoch 29:   3%|▎         | 30/1000 [31:39<17:07:59, 63.59s/it, lr=0.0005, test_MAE=0.656, time=65.9, train_MAE=0.556, train_loss=0.556, val_MAE=0.621, val_loss=0.621]Epoch 30:   3%|▎         | 30/1000 [31:39<17:07:59, 63.59s/it, lr=0.0005, test_MAE=0.656, time=65.9, train_MAE=0.556, train_loss=0.556, val_MAE=0.621, val_loss=0.621]Epoch 30:   3%|▎         | 30/1000 [32:43<17:07:59, 63.59s/it, lr=0.0005, test_MAE=0.642, time=63.9, train_MAE=0.561, train_loss=0.561, val_MAE=0.615, val_loss=0.615]Epoch 30:   3%|▎         | 31/1000 [32:43<17:08:41, 63.70s/it, lr=0.0005, test_MAE=0.642, time=63.9, train_MAE=0.561, train_loss=0.561, val_MAE=0.615, val_loss=0.615]Epoch 31:   3%|▎         | 31/1000 [32:43<17:08:41, 63.70s/it, lr=0.0005, test_MAE=0.642, time=63.9, train_MAE=0.561, train_loss=0.561, val_MAE=0.615, val_loss=0.615]Epoch 31:   3%|▎         | 31/1000 [33:47<17:08:41, 63.70s/it, lr=0.0005, test_MAE=0.616, time=64, train_MAE=0.553, train_loss=0.553, val_MAE=0.586, val_loss=0.586]  Epoch 31:   3%|▎         | 32/1000 [33:47<17:09:00, 63.78s/it, lr=0.0005, test_MAE=0.616, time=64, train_MAE=0.553, train_loss=0.553, val_MAE=0.586, val_loss=0.586]Epoch 32:   3%|▎         | 32/1000 [33:47<17:09:00, 63.78s/it, lr=0.0005, test_MAE=0.616, time=64, train_MAE=0.553, train_loss=0.553, val_MAE=0.586, val_loss=0.586]Epoch 32:   3%|▎         | 32/1000 [34:50<17:09:00, 63.78s/it, lr=0.0005, test_MAE=0.643, time=63.2, train_MAE=0.562, train_loss=0.562, val_MAE=0.605, val_loss=0.605]Epoch 32:   3%|▎         | 33/1000 [34:50<17:05:13, 63.61s/it, lr=0.0005, test_MAE=0.643, time=63.2, train_MAE=0.562, train_loss=0.562, val_MAE=0.605, val_loss=0.605]Epoch 33:   3%|▎         | 33/1000 [34:50<17:05:13, 63.61s/it, lr=0.0005, test_MAE=0.643, time=63.2, train_MAE=0.562, train_loss=0.562, val_MAE=0.605, val_loss=0.605]Epoch 33:   3%|▎         | 33/1000 [35:52<17:05:13, 63.61s/it, lr=0.0005, test_MAE=0.666, time=62.4, train_MAE=0.549, train_loss=0.549, val_MAE=0.624, val_loss=0.624]Epoch 33:   3%|▎         | 34/1000 [35:52<16:58:20, 63.25s/it, lr=0.0005, test_MAE=0.666, time=62.4, train_MAE=0.549, train_loss=0.549, val_MAE=0.624, val_loss=0.624]Epoch 34:   3%|▎         | 34/1000 [35:52<16:58:20, 63.25s/it, lr=0.0005, test_MAE=0.666, time=62.4, train_MAE=0.549, train_loss=0.549, val_MAE=0.624, val_loss=0.624]Epoch 34:   3%|▎         | 34/1000 [36:54<16:58:20, 63.25s/it, lr=0.0005, test_MAE=0.648, time=62.2, train_MAE=0.553, train_loss=0.553, val_MAE=0.598, val_loss=0.598]Epoch    35: reducing learning rate of group 0 to 2.5000e-04.
Epoch 34:   4%|▎         | 35/1000 [36:54<16:52:15, 62.94s/it, lr=0.0005, test_MAE=0.648, time=62.2, train_MAE=0.553, train_loss=0.553, val_MAE=0.598, val_loss=0.598]Epoch 35:   4%|▎         | 35/1000 [36:54<16:52:15, 62.94s/it, lr=0.0005, test_MAE=0.648, time=62.2, train_MAE=0.553, train_loss=0.553, val_MAE=0.598, val_loss=0.598]Epoch 35:   4%|▎         | 35/1000 [37:57<16:52:15, 62.94s/it, lr=0.00025, test_MAE=0.638, time=62.8, train_MAE=0.546, train_loss=0.546, val_MAE=0.596, val_loss=0.596]Epoch 35:   4%|▎         | 36/1000 [37:57<16:50:33, 62.90s/it, lr=0.00025, test_MAE=0.638, time=62.8, train_MAE=0.546, train_loss=0.546, val_MAE=0.596, val_loss=0.596]Epoch 36:   4%|▎         | 36/1000 [37:57<16:50:33, 62.90s/it, lr=0.00025, test_MAE=0.638, time=62.8, train_MAE=0.546, train_loss=0.546, val_MAE=0.596, val_loss=0.596]Epoch 36:   4%|▎         | 36/1000 [39:00<16:50:33, 62.90s/it, lr=0.00025, test_MAE=0.623, time=62.5, train_MAE=0.537, train_loss=0.537, val_MAE=0.585, val_loss=0.585]Epoch 36:   4%|▎         | 37/1000 [39:00<16:47:59, 62.80s/it, lr=0.00025, test_MAE=0.623, time=62.5, train_MAE=0.537, train_loss=0.537, val_MAE=0.585, val_loss=0.585]Epoch 37:   4%|▎         | 37/1000 [39:00<16:47:59, 62.80s/it, lr=0.00025, test_MAE=0.623, time=62.5, train_MAE=0.537, train_loss=0.537, val_MAE=0.585, val_loss=0.585]Epoch 37:   4%|▎         | 37/1000 [40:02<16:47:59, 62.80s/it, lr=0.00025, test_MAE=0.614, time=62.2, train_MAE=0.537, train_loss=0.537, val_MAE=0.573, val_loss=0.573]Epoch 37:   4%|▍         | 38/1000 [40:02<16:43:54, 62.61s/it, lr=0.00025, test_MAE=0.614, time=62.2, train_MAE=0.537, train_loss=0.537, val_MAE=0.573, val_loss=0.573]Epoch 38:   4%|▍         | 38/1000 [40:02<16:43:54, 62.61s/it, lr=0.00025, test_MAE=0.614, time=62.2, train_MAE=0.537, train_loss=0.537, val_MAE=0.573, val_loss=0.573]Epoch 38:   4%|▍         | 38/1000 [41:05<16:43:54, 62.61s/it, lr=0.00025, test_MAE=0.638, time=62.9, train_MAE=0.542, train_loss=0.542, val_MAE=0.599, val_loss=0.599]Epoch 38:   4%|▍         | 39/1000 [41:05<16:44:25, 62.71s/it, lr=0.00025, test_MAE=0.638, time=62.9, train_MAE=0.542, train_loss=0.542, val_MAE=0.599, val_loss=0.599]Epoch 39:   4%|▍         | 39/1000 [41:05<16:44:25, 62.71s/it, lr=0.00025, test_MAE=0.638, time=62.9, train_MAE=0.542, train_loss=0.542, val_MAE=0.599, val_loss=0.599]Epoch 39:   4%|▍         | 39/1000 [42:08<16:44:25, 62.71s/it, lr=0.00025, test_MAE=0.657, time=62.7, train_MAE=0.547, train_loss=0.547, val_MAE=0.618, val_loss=0.618]Epoch 39:   4%|▍         | 40/1000 [42:08<16:43:27, 62.72s/it, lr=0.00025, test_MAE=0.657, time=62.7, train_MAE=0.547, train_loss=0.547, val_MAE=0.618, val_loss=0.618]Epoch 40:   4%|▍         | 40/1000 [42:08<16:43:27, 62.72s/it, lr=0.00025, test_MAE=0.657, time=62.7, train_MAE=0.547, train_loss=0.547, val_MAE=0.618, val_loss=0.618]Epoch 40:   4%|▍         | 40/1000 [43:10<16:43:27, 62.72s/it, lr=0.00025, test_MAE=0.614, time=62.8, train_MAE=0.54, train_loss=0.54, val_MAE=0.581, val_loss=0.581]  Epoch 40:   4%|▍         | 41/1000 [43:11<16:42:49, 62.74s/it, lr=0.00025, test_MAE=0.614, time=62.8, train_MAE=0.54, train_loss=0.54, val_MAE=0.581, val_loss=0.581]Epoch 41:   4%|▍         | 41/1000 [43:11<16:42:49, 62.74s/it, lr=0.00025, test_MAE=0.614, time=62.8, train_MAE=0.54, train_loss=0.54, val_MAE=0.581, val_loss=0.581]Epoch 41:   4%|▍         | 41/1000 [44:14<16:42:49, 62.74s/it, lr=0.00025, test_MAE=0.624, time=63.2, train_MAE=0.538, train_loss=0.538, val_MAE=0.588, val_loss=0.588]Epoch 41:   4%|▍         | 42/1000 [44:14<16:44:08, 62.89s/it, lr=0.00025, test_MAE=0.624, time=63.2, train_MAE=0.538, train_loss=0.538, val_MAE=0.588, val_loss=0.588]Epoch 42:   4%|▍         | 42/1000 [44:14<16:44:08, 62.89s/it, lr=0.00025, test_MAE=0.624, time=63.2, train_MAE=0.538, train_loss=0.538, val_MAE=0.588, val_loss=0.588]Epoch 42:   4%|▍         | 42/1000 [45:16<16:44:08, 62.89s/it, lr=0.00025, test_MAE=0.631, time=62.4, train_MAE=0.537, train_loss=0.537, val_MAE=0.592, val_loss=0.592]Epoch 42:   4%|▍         | 43/1000 [45:16<16:40:45, 62.74s/it, lr=0.00025, test_MAE=0.631, time=62.4, train_MAE=0.537, train_loss=0.537, val_MAE=0.592, val_loss=0.592]Epoch 43:   4%|▍         | 43/1000 [45:16<16:40:45, 62.74s/it, lr=0.00025, test_MAE=0.631, time=62.4, train_MAE=0.537, train_loss=0.537, val_MAE=0.592, val_loss=0.592]Epoch 43:   4%|▍         | 43/1000 [46:19<16:40:45, 62.74s/it, lr=0.00025, test_MAE=0.63, time=63.3, train_MAE=0.536, train_loss=0.536, val_MAE=0.604, val_loss=0.604] Epoch    44: reducing learning rate of group 0 to 1.2500e-04.
Epoch 43:   4%|▍         | 44/1000 [46:19<16:42:31, 62.92s/it, lr=0.00025, test_MAE=0.63, time=63.3, train_MAE=0.536, train_loss=0.536, val_MAE=0.604, val_loss=0.604]Epoch 44:   4%|▍         | 44/1000 [46:19<16:42:31, 62.92s/it, lr=0.00025, test_MAE=0.63, time=63.3, train_MAE=0.536, train_loss=0.536, val_MAE=0.604, val_loss=0.604]Epoch 44:   4%|▍         | 44/1000 [47:22<16:42:31, 62.92s/it, lr=0.000125, test_MAE=0.606, time=62.8, train_MAE=0.527, train_loss=0.527, val_MAE=0.572, val_loss=0.572]Epoch 44:   4%|▍         | 45/1000 [47:22<16:40:57, 62.89s/it, lr=0.000125, test_MAE=0.606, time=62.8, train_MAE=0.527, train_loss=0.527, val_MAE=0.572, val_loss=0.572]Epoch 45:   4%|▍         | 45/1000 [47:22<16:40:57, 62.89s/it, lr=0.000125, test_MAE=0.606, time=62.8, train_MAE=0.527, train_loss=0.527, val_MAE=0.572, val_loss=0.572]Epoch 45:   4%|▍         | 45/1000 [48:25<16:40:57, 62.89s/it, lr=0.000125, test_MAE=0.603, time=62.5, train_MAE=0.529, train_loss=0.529, val_MAE=0.571, val_loss=0.571]Epoch 45:   5%|▍         | 46/1000 [48:25<16:38:15, 62.78s/it, lr=0.000125, test_MAE=0.603, time=62.5, train_MAE=0.529, train_loss=0.529, val_MAE=0.571, val_loss=0.571]Epoch 46:   5%|▍         | 46/1000 [48:25<16:38:15, 62.78s/it, lr=0.000125, test_MAE=0.603, time=62.5, train_MAE=0.529, train_loss=0.529, val_MAE=0.571, val_loss=0.571]Epoch 46:   5%|▍         | 46/1000 [49:27<16:38:15, 62.78s/it, lr=0.000125, test_MAE=0.607, time=62.2, train_MAE=0.526, train_loss=0.526, val_MAE=0.57, val_loss=0.57]  Epoch 46:   5%|▍         | 47/1000 [49:27<16:34:32, 62.62s/it, lr=0.000125, test_MAE=0.607, time=62.2, train_MAE=0.526, train_loss=0.526, val_MAE=0.57, val_loss=0.57]Epoch 47:   5%|▍         | 47/1000 [49:27<16:34:32, 62.62s/it, lr=0.000125, test_MAE=0.607, time=62.2, train_MAE=0.526, train_loss=0.526, val_MAE=0.57, val_loss=0.57]Epoch 47:   5%|▍         | 47/1000 [50:28<16:34:32, 62.62s/it, lr=0.000125, test_MAE=0.63, time=61.4, train_MAE=0.532, train_loss=0.532, val_MAE=0.595, val_loss=0.595]Epoch 47:   5%|▍         | 48/1000 [50:28<16:27:54, 62.26s/it, lr=0.000125, test_MAE=0.63, time=61.4, train_MAE=0.532, train_loss=0.532, val_MAE=0.595, val_loss=0.595]Epoch 48:   5%|▍         | 48/1000 [50:28<16:27:54, 62.26s/it, lr=0.000125, test_MAE=0.63, time=61.4, train_MAE=0.532, train_loss=0.532, val_MAE=0.595, val_loss=0.595]Epoch 48:   5%|▍         | 48/1000 [51:29<16:27:54, 62.26s/it, lr=0.000125, test_MAE=0.604, time=60.4, train_MAE=0.525, train_loss=0.525, val_MAE=0.573, val_loss=0.573]Epoch 48:   5%|▍         | 49/1000 [51:29<16:18:07, 61.71s/it, lr=0.000125, test_MAE=0.604, time=60.4, train_MAE=0.525, train_loss=0.525, val_MAE=0.573, val_loss=0.573]Epoch 49:   5%|▍         | 49/1000 [51:29<16:18:07, 61.71s/it, lr=0.000125, test_MAE=0.604, time=60.4, train_MAE=0.525, train_loss=0.525, val_MAE=0.573, val_loss=0.573]Epoch 49:   5%|▍         | 49/1000 [52:29<16:18:07, 61.71s/it, lr=0.000125, test_MAE=0.627, time=60.2, train_MAE=0.534, train_loss=0.534, val_MAE=0.597, val_loss=0.597]Epoch 49:   5%|▌         | 50/1000 [52:29<16:10:12, 61.28s/it, lr=0.000125, test_MAE=0.627, time=60.2, train_MAE=0.534, train_loss=0.534, val_MAE=0.597, val_loss=0.597]Epoch 50:   5%|▌         | 50/1000 [52:29<16:10:12, 61.28s/it, lr=0.000125, test_MAE=0.627, time=60.2, train_MAE=0.534, train_loss=0.534, val_MAE=0.597, val_loss=0.597]Epoch 50:   5%|▌         | 50/1000 [53:28<16:10:12, 61.28s/it, lr=0.000125, test_MAE=0.624, time=58.4, train_MAE=0.53, train_loss=0.53, val_MAE=0.594, val_loss=0.594]  Epoch 50:   5%|▌         | 51/1000 [53:28<15:55:25, 60.41s/it, lr=0.000125, test_MAE=0.624, time=58.4, train_MAE=0.53, train_loss=0.53, val_MAE=0.594, val_loss=0.594]Epoch 51:   5%|▌         | 51/1000 [53:28<15:55:25, 60.41s/it, lr=0.000125, test_MAE=0.624, time=58.4, train_MAE=0.53, train_loss=0.53, val_MAE=0.594, val_loss=0.594]Epoch 51:   5%|▌         | 51/1000 [54:25<15:55:25, 60.41s/it, lr=0.000125, test_MAE=0.622, time=57.3, train_MAE=0.531, train_loss=0.531, val_MAE=0.591, val_loss=0.591]Epoch 51:   5%|▌         | 52/1000 [54:25<15:39:42, 59.48s/it, lr=0.000125, test_MAE=0.622, time=57.3, train_MAE=0.531, train_loss=0.531, val_MAE=0.591, val_loss=0.591]Epoch 52:   5%|▌         | 52/1000 [54:25<15:39:42, 59.48s/it, lr=0.000125, test_MAE=0.622, time=57.3, train_MAE=0.531, train_loss=0.531, val_MAE=0.591, val_loss=0.591]Epoch 52:   5%|▌         | 52/1000 [55:22<15:39:42, 59.48s/it, lr=0.000125, test_MAE=0.608, time=57.6, train_MAE=0.533, train_loss=0.533, val_MAE=0.575, val_loss=0.575]Epoch    53: reducing learning rate of group 0 to 6.2500e-05.
Epoch 52:   5%|▌         | 53/1000 [55:22<15:29:49, 58.91s/it, lr=0.000125, test_MAE=0.608, time=57.6, train_MAE=0.533, train_loss=0.533, val_MAE=0.575, val_loss=0.575]Epoch 53:   5%|▌         | 53/1000 [55:22<15:29:49, 58.91s/it, lr=0.000125, test_MAE=0.608, time=57.6, train_MAE=0.533, train_loss=0.533, val_MAE=0.575, val_loss=0.575]Epoch 53:   5%|▌         | 53/1000 [56:19<15:29:49, 58.91s/it, lr=6.25e-5, test_MAE=0.606, time=56.8, train_MAE=0.517, train_loss=0.517, val_MAE=0.573, val_loss=0.573] Epoch 53:   5%|▌         | 54/1000 [56:19<15:18:57, 58.28s/it, lr=6.25e-5, test_MAE=0.606, time=56.8, train_MAE=0.517, train_loss=0.517, val_MAE=0.573, val_loss=0.573]Epoch 54:   5%|▌         | 54/1000 [56:19<15:18:57, 58.28s/it, lr=6.25e-5, test_MAE=0.606, time=56.8, train_MAE=0.517, train_loss=0.517, val_MAE=0.573, val_loss=0.573]Epoch 54:   5%|▌         | 54/1000 [57:16<15:18:57, 58.28s/it, lr=6.25e-5, test_MAE=0.606, time=56.4, train_MAE=0.515, train_loss=0.515, val_MAE=0.574, val_loss=0.574]Epoch 54:   6%|▌         | 55/1000 [57:16<15:09:13, 57.73s/it, lr=6.25e-5, test_MAE=0.606, time=56.4, train_MAE=0.515, train_loss=0.515, val_MAE=0.574, val_loss=0.574]Epoch 55:   6%|▌         | 55/1000 [57:16<15:09:13, 57.73s/it, lr=6.25e-5, test_MAE=0.606, time=56.4, train_MAE=0.515, train_loss=0.515, val_MAE=0.574, val_loss=0.574]Epoch 55:   6%|▌         | 55/1000 [58:13<15:09:13, 57.73s/it, lr=6.25e-5, test_MAE=0.602, time=57, train_MAE=0.525, train_loss=0.525, val_MAE=0.566, val_loss=0.566]  Epoch 55:   6%|▌         | 56/1000 [58:13<15:04:45, 57.51s/it, lr=6.25e-5, test_MAE=0.602, time=57, train_MAE=0.525, train_loss=0.525, val_MAE=0.566, val_loss=0.566]Epoch 56:   6%|▌         | 56/1000 [58:13<15:04:45, 57.51s/it, lr=6.25e-5, test_MAE=0.602, time=57, train_MAE=0.525, train_loss=0.525, val_MAE=0.566, val_loss=0.566]Epoch 56:   6%|▌         | 56/1000 [59:09<15:04:45, 57.51s/it, lr=6.25e-5, test_MAE=0.607, time=56.7, train_MAE=0.519, train_loss=0.519, val_MAE=0.573, val_loss=0.573]Epoch 56:   6%|▌         | 57/1000 [59:09<15:00:02, 57.27s/it, lr=6.25e-5, test_MAE=0.607, time=56.7, train_MAE=0.519, train_loss=0.519, val_MAE=0.573, val_loss=0.573]Epoch 57:   6%|▌         | 57/1000 [59:09<15:00:02, 57.27s/it, lr=6.25e-5, test_MAE=0.607, time=56.7, train_MAE=0.519, train_loss=0.519, val_MAE=0.573, val_loss=0.573]Epoch 57:   6%|▌         | 57/1000 [1:00:06<15:00:02, 57.27s/it, lr=6.25e-5, test_MAE=0.611, time=56.4, train_MAE=0.518, train_loss=0.518, val_MAE=0.58, val_loss=0.58]Epoch 57:   6%|▌         | 58/1000 [1:00:06<14:55:15, 57.02s/it, lr=6.25e-5, test_MAE=0.611, time=56.4, train_MAE=0.518, train_loss=0.518, val_MAE=0.58, val_loss=0.58]Epoch 58:   6%|▌         | 58/1000 [1:00:06<14:55:15, 57.02s/it, lr=6.25e-5, test_MAE=0.611, time=56.4, train_MAE=0.518, train_loss=0.518, val_MAE=0.58, val_loss=0.58]Epoch 58:   6%|▌         | 58/1000 [1:01:03<14:55:15, 57.02s/it, lr=6.25e-5, test_MAE=0.605, time=57.2, train_MAE=0.529, train_loss=0.529, val_MAE=0.567, val_loss=0.567]Epoch 58:   6%|▌         | 59/1000 [1:01:03<14:55:19, 57.09s/it, lr=6.25e-5, test_MAE=0.605, time=57.2, train_MAE=0.529, train_loss=0.529, val_MAE=0.567, val_loss=0.567]Epoch 59:   6%|▌         | 59/1000 [1:01:03<14:55:19, 57.09s/it, lr=6.25e-5, test_MAE=0.605, time=57.2, train_MAE=0.529, train_loss=0.529, val_MAE=0.567, val_loss=0.567]Epoch 59:   6%|▌         | 59/1000 [1:02:00<14:55:19, 57.09s/it, lr=6.25e-5, test_MAE=0.608, time=57.2, train_MAE=0.529, train_loss=0.529, val_MAE=0.574, val_loss=0.574]Epoch 59:   6%|▌         | 60/1000 [1:02:00<14:55:01, 57.13s/it, lr=6.25e-5, test_MAE=0.608, time=57.2, train_MAE=0.529, train_loss=0.529, val_MAE=0.574, val_loss=0.574]Epoch 60:   6%|▌         | 60/1000 [1:02:00<14:55:01, 57.13s/it, lr=6.25e-5, test_MAE=0.608, time=57.2, train_MAE=0.529, train_loss=0.529, val_MAE=0.574, val_loss=0.574]Epoch 60:   6%|▌         | 60/1000 [1:02:58<14:55:01, 57.13s/it, lr=6.25e-5, test_MAE=0.602, time=57.2, train_MAE=0.519, train_loss=0.519, val_MAE=0.57, val_loss=0.57]  Epoch 60:   6%|▌         | 61/1000 [1:02:58<14:54:42, 57.17s/it, lr=6.25e-5, test_MAE=0.602, time=57.2, train_MAE=0.519, train_loss=0.519, val_MAE=0.57, val_loss=0.57]Epoch 61:   6%|▌         | 61/1000 [1:02:58<14:54:42, 57.17s/it, lr=6.25e-5, test_MAE=0.602, time=57.2, train_MAE=0.519, train_loss=0.519, val_MAE=0.57, val_loss=0.57]Epoch 61:   6%|▌         | 61/1000 [1:03:55<14:54:42, 57.17s/it, lr=6.25e-5, test_MAE=0.603, time=57.5, train_MAE=0.519, train_loss=0.519, val_MAE=0.57, val_loss=0.57]Epoch    62: reducing learning rate of group 0 to 3.1250e-05.
Epoch 61:   6%|▌         | 62/1000 [1:03:55<14:55:27, 57.28s/it, lr=6.25e-5, test_MAE=0.603, time=57.5, train_MAE=0.519, train_loss=0.519, val_MAE=0.57, val_loss=0.57]Epoch 62:   6%|▌         | 62/1000 [1:03:55<14:55:27, 57.28s/it, lr=6.25e-5, test_MAE=0.603, time=57.5, train_MAE=0.519, train_loss=0.519, val_MAE=0.57, val_loss=0.57]Epoch 62:   6%|▌         | 62/1000 [1:04:52<14:55:27, 57.28s/it, lr=3.13e-5, test_MAE=0.602, time=56.9, train_MAE=0.531, train_loss=0.531, val_MAE=0.57, val_loss=0.57]Epoch 62:   6%|▋         | 63/1000 [1:04:52<14:52:49, 57.17s/it, lr=3.13e-5, test_MAE=0.602, time=56.9, train_MAE=0.531, train_loss=0.531, val_MAE=0.57, val_loss=0.57]Epoch 63:   6%|▋         | 63/1000 [1:04:52<14:52:49, 57.17s/it, lr=3.13e-5, test_MAE=0.602, time=56.9, train_MAE=0.531, train_loss=0.531, val_MAE=0.57, val_loss=0.57]Epoch 63:   6%|▋         | 63/1000 [1:05:50<14:52:49, 57.17s/it, lr=3.13e-5, test_MAE=0.608, time=57.5, train_MAE=0.521, train_loss=0.521, val_MAE=0.578, val_loss=0.578]Epoch 63:   6%|▋         | 64/1000 [1:05:50<14:53:31, 57.28s/it, lr=3.13e-5, test_MAE=0.608, time=57.5, train_MAE=0.521, train_loss=0.521, val_MAE=0.578, val_loss=0.578]Epoch 64:   6%|▋         | 64/1000 [1:05:50<14:53:31, 57.28s/it, lr=3.13e-5, test_MAE=0.608, time=57.5, train_MAE=0.521, train_loss=0.521, val_MAE=0.578, val_loss=0.578]Epoch 64:   6%|▋         | 64/1000 [1:06:47<14:53:31, 57.28s/it, lr=3.13e-5, test_MAE=0.609, time=57.2, train_MAE=0.516, train_loss=0.516, val_MAE=0.578, val_loss=0.578]Epoch 64:   6%|▋         | 65/1000 [1:06:47<14:52:22, 57.26s/it, lr=3.13e-5, test_MAE=0.609, time=57.2, train_MAE=0.516, train_loss=0.516, val_MAE=0.578, val_loss=0.578]Epoch 65:   6%|▋         | 65/1000 [1:06:47<14:52:22, 57.26s/it, lr=3.13e-5, test_MAE=0.609, time=57.2, train_MAE=0.516, train_loss=0.516, val_MAE=0.578, val_loss=0.578]Epoch 65:   6%|▋         | 65/1000 [1:07:45<14:52:22, 57.26s/it, lr=3.13e-5, test_MAE=0.604, time=58, train_MAE=0.518, train_loss=0.518, val_MAE=0.567, val_loss=0.567]  Epoch 65:   7%|▋         | 66/1000 [1:07:45<14:54:54, 57.49s/it, lr=3.13e-5, test_MAE=0.604, time=58, train_MAE=0.518, train_loss=0.518, val_MAE=0.567, val_loss=0.567]Epoch 66:   7%|▋         | 66/1000 [1:07:45<14:54:54, 57.49s/it, lr=3.13e-5, test_MAE=0.604, time=58, train_MAE=0.518, train_loss=0.518, val_MAE=0.567, val_loss=0.567]Epoch 66:   7%|▋         | 66/1000 [1:08:43<14:54:54, 57.49s/it, lr=3.13e-5, test_MAE=0.605, time=58.1, train_MAE=0.512, train_loss=0.512, val_MAE=0.566, val_loss=0.566]Epoch 66:   7%|▋         | 67/1000 [1:08:43<14:57:01, 57.69s/it, lr=3.13e-5, test_MAE=0.605, time=58.1, train_MAE=0.512, train_loss=0.512, val_MAE=0.566, val_loss=0.566]Epoch 67:   7%|▋         | 67/1000 [1:08:43<14:57:01, 57.69s/it, lr=3.13e-5, test_MAE=0.605, time=58.1, train_MAE=0.512, train_loss=0.512, val_MAE=0.566, val_loss=0.566]Epoch 67:   7%|▋         | 67/1000 [1:09:40<14:57:01, 57.69s/it, lr=3.13e-5, test_MAE=0.603, time=57.3, train_MAE=0.52, train_loss=0.52, val_MAE=0.57, val_loss=0.57]    Epoch    68: reducing learning rate of group 0 to 1.5625e-05.
Epoch 67:   7%|▋         | 68/1000 [1:09:40<14:54:30, 57.59s/it, lr=3.13e-5, test_MAE=0.603, time=57.3, train_MAE=0.52, train_loss=0.52, val_MAE=0.57, val_loss=0.57]Epoch 68:   7%|▋         | 68/1000 [1:09:40<14:54:30, 57.59s/it, lr=3.13e-5, test_MAE=0.603, time=57.3, train_MAE=0.52, train_loss=0.52, val_MAE=0.57, val_loss=0.57]Epoch 68:   7%|▋         | 68/1000 [1:10:37<14:54:30, 57.59s/it, lr=1.56e-5, test_MAE=0.602, time=57, train_MAE=0.534, train_loss=0.534, val_MAE=0.569, val_loss=0.569]Epoch 68:   7%|▋         | 69/1000 [1:10:37<14:51:03, 57.43s/it, lr=1.56e-5, test_MAE=0.602, time=57, train_MAE=0.534, train_loss=0.534, val_MAE=0.569, val_loss=0.569]Epoch 69:   7%|▋         | 69/1000 [1:10:37<14:51:03, 57.43s/it, lr=1.56e-5, test_MAE=0.602, time=57, train_MAE=0.534, train_loss=0.534, val_MAE=0.569, val_loss=0.569]Epoch 69:   7%|▋         | 69/1000 [1:11:35<14:51:03, 57.43s/it, lr=1.56e-5, test_MAE=0.606, time=57.9, train_MAE=0.514, train_loss=0.514, val_MAE=0.574, val_loss=0.574]Epoch 69:   7%|▋         | 70/1000 [1:11:35<14:52:14, 57.56s/it, lr=1.56e-5, test_MAE=0.606, time=57.9, train_MAE=0.514, train_loss=0.514, val_MAE=0.574, val_loss=0.574]Epoch 70:   7%|▋         | 70/1000 [1:11:35<14:52:14, 57.56s/it, lr=1.56e-5, test_MAE=0.606, time=57.9, train_MAE=0.514, train_loss=0.514, val_MAE=0.574, val_loss=0.574]Epoch 70:   7%|▋         | 70/1000 [1:12:33<14:52:14, 57.56s/it, lr=1.56e-5, test_MAE=0.601, time=57.6, train_MAE=0.521, train_loss=0.521, val_MAE=0.569, val_loss=0.569]Epoch 70:   7%|▋         | 71/1000 [1:12:33<14:51:25, 57.57s/it, lr=1.56e-5, test_MAE=0.601, time=57.6, train_MAE=0.521, train_loss=0.521, val_MAE=0.569, val_loss=0.569]Epoch 71:   7%|▋         | 71/1000 [1:12:33<14:51:25, 57.57s/it, lr=1.56e-5, test_MAE=0.601, time=57.6, train_MAE=0.521, train_loss=0.521, val_MAE=0.569, val_loss=0.569]Epoch 71:   7%|▋         | 71/1000 [1:13:31<14:51:25, 57.57s/it, lr=1.56e-5, test_MAE=0.603, time=58, train_MAE=0.521, train_loss=0.521, val_MAE=0.569, val_loss=0.569]  Epoch 71:   7%|▋         | 72/1000 [1:13:31<14:52:20, 57.69s/it, lr=1.56e-5, test_MAE=0.603, time=58, train_MAE=0.521, train_loss=0.521, val_MAE=0.569, val_loss=0.569]Epoch 72:   7%|▋         | 72/1000 [1:13:31<14:52:20, 57.69s/it, lr=1.56e-5, test_MAE=0.603, time=58, train_MAE=0.521, train_loss=0.521, val_MAE=0.569, val_loss=0.569]Epoch 72:   7%|▋         | 72/1000 [1:14:28<14:52:20, 57.69s/it, lr=1.56e-5, test_MAE=0.602, time=57.2, train_MAE=0.518, train_loss=0.518, val_MAE=0.569, val_loss=0.569]Epoch 72:   7%|▋         | 73/1000 [1:14:28<14:49:05, 57.55s/it, lr=1.56e-5, test_MAE=0.602, time=57.2, train_MAE=0.518, train_loss=0.518, val_MAE=0.569, val_loss=0.569]Epoch 73:   7%|▋         | 73/1000 [1:14:28<14:49:05, 57.55s/it, lr=1.56e-5, test_MAE=0.602, time=57.2, train_MAE=0.518, train_loss=0.518, val_MAE=0.569, val_loss=0.569]Epoch 73:   7%|▋         | 73/1000 [1:15:26<14:49:05, 57.55s/it, lr=1.56e-5, test_MAE=0.603, time=57.9, train_MAE=0.512, train_loss=0.512, val_MAE=0.57, val_loss=0.57]  Epoch    74: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 73:   7%|▋         | 73/1000 [1:15:26<15:57:59, 62.01s/it, lr=1.56e-5, test_MAE=0.603, time=57.9, train_MAE=0.512, train_loss=0.512, val_MAE=0.57, val_loss=0.57]
Test MAE: 0.6031
Train MAE: 0.5022
Convergence Time (Epochs): 73.0000
TOTAL TIME TAKEN: 4563.5173s
AVG TIME PER EPOCH: 61.1472s
