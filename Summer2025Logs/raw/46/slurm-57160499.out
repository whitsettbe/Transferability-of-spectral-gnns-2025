I'm echoing to stdout
I'm echoing to stderr
My JobID is 57160499
I have 8 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.0352s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 4, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'rational_vec', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_all', 'num_eigs': 64, 'bias_mode': 'spatial', 'eigval_hidden_dim': 5, 'eigval_num_hidden_layer': 3, 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 8.0, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/zinc_train_rec_full.csv', 'test': 'supp_data/molecules/zinc_test_rec_full.csv', 'val': 'supp_data/molecules/zinc_val_rec_full.csv'}, 'fixMissingPhi1': False, 'extraOrtho': False, 'doublePrecision': True, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [09:14<?, ?it/s, lr=0.001, test_MAE=1.49, time=555, train_MAE=1.38, train_loss=1.57, val_MAE=1.43, val_loss=1.65]Epoch 0:   0%|          | 1/1000 [09:14<153:55:20, 554.68s/it, lr=0.001, test_MAE=1.49, time=555, train_MAE=1.38, train_loss=1.57, val_MAE=1.43, val_loss=1.65]Epoch 1:   0%|          | 1/1000 [09:14<153:55:20, 554.68s/it, lr=0.001, test_MAE=1.49, time=555, train_MAE=1.38, train_loss=1.57, val_MAE=1.43, val_loss=1.65]Epoch 1:   0%|          | 1/1000 [17:51<153:55:20, 554.68s/it, lr=0.001, test_MAE=1.29, time=516, train_MAE=0.97, train_loss=1.21, val_MAE=1.21, val_loss=1.46]Epoch 1:   0%|          | 2/1000 [17:51<150:35:42, 543.23s/it, lr=0.001, test_MAE=1.29, time=516, train_MAE=0.97, train_loss=1.21, val_MAE=1.21, val_loss=1.46]Epoch 2:   0%|          | 2/1000 [17:51<150:35:42, 543.23s/it, lr=0.001, test_MAE=1.29, time=516, train_MAE=0.97, train_loss=1.21, val_MAE=1.21, val_loss=1.46]Epoch 2:   0%|          | 2/1000 [26:33<150:35:42, 543.23s/it, lr=0.001, test_MAE=1.14, time=522, train_MAE=0.75, train_loss=1, val_MAE=1.07, val_loss=1.33]   Epoch 2:   0%|          | 3/1000 [26:33<148:43:10, 537.00s/it, lr=0.001, test_MAE=1.14, time=522, train_MAE=0.75, train_loss=1, val_MAE=1.07, val_loss=1.33]Epoch 3:   0%|          | 3/1000 [26:33<148:43:10, 537.00s/it, lr=0.001, test_MAE=1.14, time=522, train_MAE=0.75, train_loss=1, val_MAE=1.07, val_loss=1.33]Epoch 3:   0%|          | 3/1000 [35:10<148:43:10, 537.00s/it, lr=0.001, test_MAE=0.927, time=517, train_MAE=0.694, train_loss=0.951, val_MAE=0.853, val_loss=1.11]Epoch 3:   0%|          | 4/1000 [35:10<146:52:56, 530.90s/it, lr=0.001, test_MAE=0.927, time=517, train_MAE=0.694, train_loss=0.951, val_MAE=0.853, val_loss=1.11]Epoch 4:   0%|          | 4/1000 [35:10<146:52:56, 530.90s/it, lr=0.001, test_MAE=0.927, time=517, train_MAE=0.694, train_loss=0.951, val_MAE=0.853, val_loss=1.11]Epoch 4:   0%|          | 4/1000 [43:41<146:52:56, 530.90s/it, lr=0.001, test_MAE=0.87, time=511, train_MAE=0.673, train_loss=0.934, val_MAE=0.792, val_loss=1.06] Epoch 4:   0%|          | 5/1000 [43:41<145:07:06, 525.05s/it, lr=0.001, test_MAE=0.87, time=511, train_MAE=0.673, train_loss=0.934, val_MAE=0.792, val_loss=1.06]Epoch 5:   0%|          | 5/1000 [43:41<145:07:06, 525.05s/it, lr=0.001, test_MAE=0.87, time=511, train_MAE=0.673, train_loss=0.934, val_MAE=0.792, val_loss=1.06]Epoch 5:   0%|          | 5/1000 [52:09<145:07:06, 525.05s/it, lr=0.001, test_MAE=0.871, time=507, train_MAE=0.656, train_loss=0.921, val_MAE=0.803, val_loss=1.07]Epoch 5:   1%|          | 6/1000 [52:09<143:31:01, 519.78s/it, lr=0.001, test_MAE=0.871, time=507, train_MAE=0.656, train_loss=0.921, val_MAE=0.803, val_loss=1.07]Epoch 6:   1%|          | 6/1000 [52:09<143:31:01, 519.78s/it, lr=0.001, test_MAE=0.871, time=507, train_MAE=0.656, train_loss=0.921, val_MAE=0.803, val_loss=1.07]Epoch 6:   1%|          | 6/1000 [1:00:37<143:31:01, 519.78s/it, lr=0.001, test_MAE=0.896, time=508, train_MAE=0.63, train_loss=0.898, val_MAE=0.866, val_loss=1.14]Epoch 6:   1%|          | 7/1000 [1:00:37<142:26:18, 516.39s/it, lr=0.001, test_MAE=0.896, time=508, train_MAE=0.63, train_loss=0.898, val_MAE=0.866, val_loss=1.14]Epoch 7:   1%|          | 7/1000 [1:00:37<142:26:18, 516.39s/it, lr=0.001, test_MAE=0.896, time=508, train_MAE=0.63, train_loss=0.898, val_MAE=0.866, val_loss=1.14]Epoch 7:   1%|          | 7/1000 [1:09:05<142:26:18, 516.39s/it, lr=0.001, test_MAE=0.808, time=508, train_MAE=0.641, train_loss=0.912, val_MAE=0.767, val_loss=1.04]Epoch 7:   1%|          | 8/1000 [1:09:05<141:35:19, 513.83s/it, lr=0.001, test_MAE=0.808, time=508, train_MAE=0.641, train_loss=0.912, val_MAE=0.767, val_loss=1.04]Epoch 8:   1%|          | 8/1000 [1:09:05<141:35:19, 513.83s/it, lr=0.001, test_MAE=0.808, time=508, train_MAE=0.641, train_loss=0.912, val_MAE=0.767, val_loss=1.04]Epoch 8:   1%|          | 8/1000 [1:17:33<141:35:19, 513.83s/it, lr=0.001, test_MAE=1.02, time=508, train_MAE=0.629, train_loss=0.903, val_MAE=0.914, val_loss=1.19] Epoch 8:   1%|          | 9/1000 [1:17:33<140:59:57, 512.21s/it, lr=0.001, test_MAE=1.02, time=508, train_MAE=0.629, train_loss=0.903, val_MAE=0.914, val_loss=1.19]Epoch 9:   1%|          | 9/1000 [1:17:33<140:59:57, 512.21s/it, lr=0.001, test_MAE=1.02, time=508, train_MAE=0.629, train_loss=0.903, val_MAE=0.914, val_loss=1.19]Epoch 9:   1%|          | 9/1000 [1:26:05<140:59:57, 512.21s/it, lr=0.001, test_MAE=0.749, time=512, train_MAE=0.613, train_loss=0.891, val_MAE=0.693, val_loss=0.972]Epoch 9:   1%|          | 10/1000 [1:26:05<140:49:51, 512.11s/it, lr=0.001, test_MAE=0.749, time=512, train_MAE=0.613, train_loss=0.891, val_MAE=0.693, val_loss=0.972]Epoch 10:   1%|          | 10/1000 [1:26:05<140:49:51, 512.11s/it, lr=0.001, test_MAE=0.749, time=512, train_MAE=0.613, train_loss=0.891, val_MAE=0.693, val_loss=0.972]Epoch 10:   1%|          | 10/1000 [1:34:36<140:49:51, 512.11s/it, lr=0.001, test_MAE=0.708, time=510, train_MAE=0.605, train_loss=0.886, val_MAE=0.667, val_loss=0.949]Epoch 10:   1%|          | 11/1000 [1:34:36<140:33:17, 511.63s/it, lr=0.001, test_MAE=0.708, time=510, train_MAE=0.605, train_loss=0.886, val_MAE=0.667, val_loss=0.949]Epoch 11:   1%|          | 11/1000 [1:34:36<140:33:17, 511.63s/it, lr=0.001, test_MAE=0.708, time=510, train_MAE=0.605, train_loss=0.886, val_MAE=0.667, val_loss=0.949]Epoch 11:   1%|          | 11/1000 [1:43:06<140:33:17, 511.63s/it, lr=0.001, test_MAE=0.73, time=510, train_MAE=0.602, train_loss=0.886, val_MAE=0.751, val_loss=1.04]  Epoch 11:   1%|          | 12/1000 [1:43:06<140:15:47, 511.08s/it, lr=0.001, test_MAE=0.73, time=510, train_MAE=0.602, train_loss=0.886, val_MAE=0.751, val_loss=1.04]Epoch 12:   1%|          | 12/1000 [1:43:06<140:15:47, 511.08s/it, lr=0.001, test_MAE=0.73, time=510, train_MAE=0.602, train_loss=0.886, val_MAE=0.751, val_loss=1.04]Epoch 12:   1%|          | 12/1000 [1:51:37<140:15:47, 511.08s/it, lr=0.001, test_MAE=0.72, time=511, train_MAE=0.601, train_loss=0.89, val_MAE=0.661, val_loss=0.951]Epoch 12:   1%|▏         | 13/1000 [1:51:37<140:08:12, 511.14s/it, lr=0.001, test_MAE=0.72, time=511, train_MAE=0.601, train_loss=0.89, val_MAE=0.661, val_loss=0.951]Epoch 13:   1%|▏         | 13/1000 [1:51:37<140:08:12, 511.14s/it, lr=0.001, test_MAE=0.72, time=511, train_MAE=0.601, train_loss=0.89, val_MAE=0.661, val_loss=0.951]Epoch 13:   1%|▏         | 13/1000 [2:00:03<140:08:12, 511.14s/it, lr=0.001, test_MAE=0.652, time=506, train_MAE=0.612, train_loss=0.904, val_MAE=0.6, val_loss=0.893]Epoch 13:   1%|▏         | 14/1000 [2:00:03<139:32:58, 509.51s/it, lr=0.001, test_MAE=0.652, time=506, train_MAE=0.612, train_loss=0.904, val_MAE=0.6, val_loss=0.893]Epoch 14:   1%|▏         | 14/1000 [2:00:03<139:32:58, 509.51s/it, lr=0.001, test_MAE=0.652, time=506, train_MAE=0.612, train_loss=0.904, val_MAE=0.6, val_loss=0.893]Epoch 14:   1%|▏         | 14/1000 [2:08:31<139:32:58, 509.51s/it, lr=0.001, test_MAE=0.878, time=508, train_MAE=0.591, train_loss=0.886, val_MAE=0.835, val_loss=1.13]Epoch 14:   2%|▏         | 15/1000 [2:08:31<139:18:54, 509.17s/it, lr=0.001, test_MAE=0.878, time=508, train_MAE=0.591, train_loss=0.886, val_MAE=0.835, val_loss=1.13]Epoch 15:   2%|▏         | 15/1000 [2:08:31<139:18:54, 509.17s/it, lr=0.001, test_MAE=0.878, time=508, train_MAE=0.591, train_loss=0.886, val_MAE=0.835, val_loss=1.13]Epoch 15:   2%|▏         | 15/1000 [2:17:16<139:18:54, 509.17s/it, lr=0.001, test_MAE=0.748, time=525, train_MAE=0.59, train_loss=0.888, val_MAE=0.712, val_loss=1.01] Epoch 15:   2%|▏         | 16/1000 [2:17:16<140:27:36, 513.88s/it, lr=0.001, test_MAE=0.748, time=525, train_MAE=0.59, train_loss=0.888, val_MAE=0.712, val_loss=1.01]Epoch 16:   2%|▏         | 16/1000 [2:17:16<140:27:36, 513.88s/it, lr=0.001, test_MAE=0.748, time=525, train_MAE=0.59, train_loss=0.888, val_MAE=0.712, val_loss=1.01]Epoch 16:   2%|▏         | 16/1000 [2:26:12<140:27:36, 513.88s/it, lr=0.001, test_MAE=0.701, time=536, train_MAE=0.599, train_loss=0.9, val_MAE=0.639, val_loss=0.942]Epoch 16:   2%|▏         | 17/1000 [2:26:12<142:08:34, 520.56s/it, lr=0.001, test_MAE=0.701, time=536, train_MAE=0.599, train_loss=0.9, val_MAE=0.639, val_loss=0.942]Epoch 17:   2%|▏         | 17/1000 [2:26:12<142:08:34, 520.56s/it, lr=0.001, test_MAE=0.701, time=536, train_MAE=0.599, train_loss=0.9, val_MAE=0.639, val_loss=0.942]Epoch 17:   2%|▏         | 17/1000 [2:35:03<142:08:34, 520.56s/it, lr=0.001, test_MAE=0.683, time=531, train_MAE=0.584, train_loss=0.889, val_MAE=0.639, val_loss=0.946]Epoch 17:   2%|▏         | 18/1000 [2:35:03<142:50:33, 523.66s/it, lr=0.001, test_MAE=0.683, time=531, train_MAE=0.584, train_loss=0.889, val_MAE=0.639, val_loss=0.946]Epoch 18:   2%|▏         | 18/1000 [2:35:03<142:50:33, 523.66s/it, lr=0.001, test_MAE=0.683, time=531, train_MAE=0.584, train_loss=0.889, val_MAE=0.639, val_loss=0.946]Epoch 18:   2%|▏         | 18/1000 [2:43:52<142:50:33, 523.66s/it, lr=0.001, test_MAE=0.64, time=530, train_MAE=0.59, train_loss=0.899, val_MAE=0.589, val_loss=0.9]    Epoch 18:   2%|▏         | 19/1000 [2:43:53<143:10:51, 525.43s/it, lr=0.001, test_MAE=0.64, time=530, train_MAE=0.59, train_loss=0.899, val_MAE=0.589, val_loss=0.9]Epoch 19:   2%|▏         | 19/1000 [2:43:53<143:10:51, 525.43s/it, lr=0.001, test_MAE=0.64, time=530, train_MAE=0.59, train_loss=0.899, val_MAE=0.589, val_loss=0.9]Epoch 19:   2%|▏         | 19/1000 [2:52:42<143:10:51, 525.43s/it, lr=0.001, test_MAE=0.968, time=529, train_MAE=0.585, train_loss=0.898, val_MAE=0.918, val_loss=1.23]Epoch    20: reducing learning rate of group 0 to 5.0000e-04.
Epoch 19:   2%|▏         | 20/1000 [2:52:42<143:19:59, 526.53s/it, lr=0.001, test_MAE=0.968, time=529, train_MAE=0.585, train_loss=0.898, val_MAE=0.918, val_loss=1.23]Epoch 20:   2%|▏         | 20/1000 [2:52:42<143:19:59, 526.53s/it, lr=0.001, test_MAE=0.968, time=529, train_MAE=0.585, train_loss=0.898, val_MAE=0.918, val_loss=1.23]Epoch 20:   2%|▏         | 20/1000 [3:01:30<143:19:59, 526.53s/it, lr=0.0005, test_MAE=0.721, time=528, train_MAE=0.562, train_loss=0.876, val_MAE=0.691, val_loss=1]  Epoch 20:   2%|▏         | 21/1000 [3:01:30<143:20:42, 527.11s/it, lr=0.0005, test_MAE=0.721, time=528, train_MAE=0.562, train_loss=0.876, val_MAE=0.691, val_loss=1]Epoch 21:   2%|▏         | 21/1000 [3:01:30<143:20:42, 527.11s/it, lr=0.0005, test_MAE=0.721, time=528, train_MAE=0.562, train_loss=0.876, val_MAE=0.691, val_loss=1]Epoch 21:   2%|▏         | 21/1000 [3:10:21<143:20:42, 527.11s/it, lr=0.0005, test_MAE=0.637, time=531, train_MAE=0.557, train_loss=0.87, val_MAE=0.587, val_loss=0.899]Epoch 21:   2%|▏         | 22/1000 [3:10:21<143:32:00, 528.34s/it, lr=0.0005, test_MAE=0.637, time=531, train_MAE=0.557, train_loss=0.87, val_MAE=0.587, val_loss=0.899]Epoch 22:   2%|▏         | 22/1000 [3:10:21<143:32:00, 528.34s/it, lr=0.0005, test_MAE=0.637, time=531, train_MAE=0.557, train_loss=0.87, val_MAE=0.587, val_loss=0.899]Epoch 22:   2%|▏         | 22/1000 [3:19:12<143:32:00, 528.34s/it, lr=0.0005, test_MAE=1.49, time=531, train_MAE=0.558, train_loss=0.869, val_MAE=1.46, val_loss=1.77]  Epoch 22:   2%|▏         | 23/1000 [3:19:12<143:34:09, 529.02s/it, lr=0.0005, test_MAE=1.49, time=531, train_MAE=0.558, train_loss=0.869, val_MAE=1.46, val_loss=1.77]Epoch 23:   2%|▏         | 23/1000 [3:19:12<143:34:09, 529.02s/it, lr=0.0005, test_MAE=1.49, time=531, train_MAE=0.558, train_loss=0.869, val_MAE=1.46, val_loss=1.77]Epoch 23:   2%|▏         | 23/1000 [3:28:01<143:34:09, 529.02s/it, lr=0.0005, test_MAE=0.713, time=529, train_MAE=0.565, train_loss=0.877, val_MAE=0.654, val_loss=0.966]Epoch 23:   2%|▏         | 24/1000 [3:28:01<143:27:16, 529.14s/it, lr=0.0005, test_MAE=0.713, time=529, train_MAE=0.565, train_loss=0.877, val_MAE=0.654, val_loss=0.966]Epoch 24:   2%|▏         | 24/1000 [3:28:01<143:27:16, 529.14s/it, lr=0.0005, test_MAE=0.713, time=529, train_MAE=0.565, train_loss=0.877, val_MAE=0.654, val_loss=0.966]Epoch 24:   2%|▏         | 24/1000 [3:36:51<143:27:16, 529.14s/it, lr=0.0005, test_MAE=1.46, time=529, train_MAE=0.555, train_loss=0.867, val_MAE=1.41, val_loss=1.72]   Epoch 24:   2%|▎         | 25/1000 [3:36:51<143:19:48, 529.22s/it, lr=0.0005, test_MAE=1.46, time=529, train_MAE=0.555, train_loss=0.867, val_MAE=1.41, val_loss=1.72]Epoch 25:   2%|▎         | 25/1000 [3:36:51<143:19:48, 529.22s/it, lr=0.0005, test_MAE=1.46, time=529, train_MAE=0.555, train_loss=0.867, val_MAE=1.41, val_loss=1.72]Epoch 25:   2%|▎         | 25/1000 [3:45:42<143:19:48, 529.22s/it, lr=0.0005, test_MAE=1.21, time=531, train_MAE=0.557, train_loss=0.868, val_MAE=1.27, val_loss=1.59]Epoch    26: reducing learning rate of group 0 to 2.5000e-04.
Epoch 25:   3%|▎         | 26/1000 [3:45:42<143:21:57, 529.90s/it, lr=0.0005, test_MAE=1.21, time=531, train_MAE=0.557, train_loss=0.868, val_MAE=1.27, val_loss=1.59]Epoch 26:   3%|▎         | 26/1000 [3:45:42<143:21:57, 529.90s/it, lr=0.0005, test_MAE=1.21, time=531, train_MAE=0.557, train_loss=0.868, val_MAE=1.27, val_loss=1.59]Epoch 26:   3%|▎         | 26/1000 [3:54:51<143:21:57, 529.90s/it, lr=0.00025, test_MAE=0.615, time=549, train_MAE=0.548, train_loss=0.859, val_MAE=0.567, val_loss=0.877]Epoch 26:   3%|▎         | 27/1000 [3:54:51<144:47:06, 535.69s/it, lr=0.00025, test_MAE=0.615, time=549, train_MAE=0.548, train_loss=0.859, val_MAE=0.567, val_loss=0.877]Epoch 27:   3%|▎         | 27/1000 [3:54:51<144:47:06, 535.69s/it, lr=0.00025, test_MAE=0.615, time=549, train_MAE=0.548, train_loss=0.859, val_MAE=0.567, val_loss=0.877]Epoch 27:   3%|▎         | 27/1000 [4:04:06<144:47:06, 535.69s/it, lr=0.00025, test_MAE=0.599, time=555, train_MAE=0.541, train_loss=0.851, val_MAE=0.553, val_loss=0.863]Epoch 27:   3%|▎         | 28/1000 [4:04:06<146:10:06, 541.36s/it, lr=0.00025, test_MAE=0.599, time=555, train_MAE=0.541, train_loss=0.851, val_MAE=0.553, val_loss=0.863]Epoch 28:   3%|▎         | 28/1000 [4:04:06<146:10:06, 541.36s/it, lr=0.00025, test_MAE=0.599, time=555, train_MAE=0.541, train_loss=0.851, val_MAE=0.553, val_loss=0.863]Epoch 28:   3%|▎         | 28/1000 [4:13:25<146:10:06, 541.36s/it, lr=0.00025, test_MAE=0.675, time=559, train_MAE=0.54, train_loss=0.85, val_MAE=0.633, val_loss=0.942]  Epoch 28:   3%|▎         | 29/1000 [4:13:25<147:28:42, 546.78s/it, lr=0.00025, test_MAE=0.675, time=559, train_MAE=0.54, train_loss=0.85, val_MAE=0.633, val_loss=0.942]Epoch 29:   3%|▎         | 29/1000 [4:13:25<147:28:42, 546.78s/it, lr=0.00025, test_MAE=0.675, time=559, train_MAE=0.54, train_loss=0.85, val_MAE=0.633, val_loss=0.942]Epoch 29:   3%|▎         | 29/1000 [4:22:29<147:28:42, 546.78s/it, lr=0.00025, test_MAE=0.853, time=544, train_MAE=0.54, train_loss=0.849, val_MAE=0.83, val_loss=1.14] Epoch 29:   3%|▎         | 30/1000 [4:22:29<147:05:36, 545.91s/it, lr=0.00025, test_MAE=0.853, time=544, train_MAE=0.54, train_loss=0.849, val_MAE=0.83, val_loss=1.14]Epoch 30:   3%|▎         | 30/1000 [4:22:29<147:05:36, 545.91s/it, lr=0.00025, test_MAE=0.853, time=544, train_MAE=0.54, train_loss=0.849, val_MAE=0.83, val_loss=1.14]Epoch 30:   3%|▎         | 30/1000 [4:31:36<147:05:36, 545.91s/it, lr=0.00025, test_MAE=0.671, time=547, train_MAE=0.53, train_loss=0.839, val_MAE=0.64, val_loss=0.948]Epoch 30:   3%|▎         | 31/1000 [4:31:36<147:02:20, 546.28s/it, lr=0.00025, test_MAE=0.671, time=547, train_MAE=0.53, train_loss=0.839, val_MAE=0.64, val_loss=0.948]Epoch 31:   3%|▎         | 31/1000 [4:31:36<147:02:20, 546.28s/it, lr=0.00025, test_MAE=0.671, time=547, train_MAE=0.53, train_loss=0.839, val_MAE=0.64, val_loss=0.948]Epoch 31:   3%|▎         | 31/1000 [4:40:43<147:02:20, 546.28s/it, lr=0.00025, test_MAE=0.612, time=547, train_MAE=0.533, train_loss=0.841, val_MAE=0.578, val_loss=0.886]Epoch 31:   3%|▎         | 32/1000 [4:40:43<146:56:34, 546.48s/it, lr=0.00025, test_MAE=0.612, time=547, train_MAE=0.533, train_loss=0.841, val_MAE=0.578, val_loss=0.886]Epoch 32:   3%|▎         | 32/1000 [4:40:43<146:56:34, 546.48s/it, lr=0.00025, test_MAE=0.612, time=547, train_MAE=0.533, train_loss=0.841, val_MAE=0.578, val_loss=0.886]Epoch 32:   3%|▎         | 32/1000 [4:49:51<146:56:34, 546.48s/it, lr=0.00025, test_MAE=0.711, time=547, train_MAE=0.534, train_loss=0.841, val_MAE=0.641, val_loss=0.948]Epoch 32:   3%|▎         | 33/1000 [4:49:51<146:51:30, 546.73s/it, lr=0.00025, test_MAE=0.711, time=547, train_MAE=0.534, train_loss=0.841, val_MAE=0.641, val_loss=0.948]Epoch 33:   3%|▎         | 33/1000 [4:49:51<146:51:30, 546.73s/it, lr=0.00025, test_MAE=0.711, time=547, train_MAE=0.534, train_loss=0.841, val_MAE=0.641, val_loss=0.948]Epoch 33:   3%|▎         | 33/1000 [4:58:59<146:51:30, 546.73s/it, lr=0.00025, test_MAE=0.649, time=548, train_MAE=0.539, train_loss=0.847, val_MAE=0.61, val_loss=0.917] Epoch    34: reducing learning rate of group 0 to 1.2500e-04.
Epoch 33:   3%|▎         | 34/1000 [4:58:59<146:49:30, 547.17s/it, lr=0.00025, test_MAE=0.649, time=548, train_MAE=0.539, train_loss=0.847, val_MAE=0.61, val_loss=0.917]Epoch 34:   3%|▎         | 34/1000 [4:58:59<146:49:30, 547.17s/it, lr=0.00025, test_MAE=0.649, time=548, train_MAE=0.539, train_loss=0.847, val_MAE=0.61, val_loss=0.917]Epoch 34:   3%|▎         | 34/1000 [5:08:04<146:49:30, 547.17s/it, lr=0.000125, test_MAE=0.582, time=546, train_MAE=0.53, train_loss=0.836, val_MAE=0.544, val_loss=0.85]Epoch 34:   4%|▎         | 35/1000 [5:08:04<146:32:42, 546.70s/it, lr=0.000125, test_MAE=0.582, time=546, train_MAE=0.53, train_loss=0.836, val_MAE=0.544, val_loss=0.85]Epoch 35:   4%|▎         | 35/1000 [5:08:04<146:32:42, 546.70s/it, lr=0.000125, test_MAE=0.582, time=546, train_MAE=0.53, train_loss=0.836, val_MAE=0.544, val_loss=0.85]Epoch 35:   4%|▎         | 35/1000 [5:17:05<146:32:42, 546.70s/it, lr=0.000125, test_MAE=0.595, time=540, train_MAE=0.519, train_loss=0.825, val_MAE=0.547, val_loss=0.853]Epoch 35:   4%|▎         | 36/1000 [5:17:05<145:53:12, 544.81s/it, lr=0.000125, test_MAE=0.595, time=540, train_MAE=0.519, train_loss=0.825, val_MAE=0.547, val_loss=0.853]Epoch 36:   4%|▎         | 36/1000 [5:17:05<145:53:12, 544.81s/it, lr=0.000125, test_MAE=0.595, time=540, train_MAE=0.519, train_loss=0.825, val_MAE=0.547, val_loss=0.853]Epoch 36:   4%|▎         | 36/1000 [5:26:12<145:53:12, 544.81s/it, lr=0.000125, test_MAE=0.627, time=547, train_MAE=0.517, train_loss=0.822, val_MAE=0.579, val_loss=0.884]Epoch 36:   4%|▎         | 37/1000 [5:26:12<145:56:13, 545.56s/it, lr=0.000125, test_MAE=0.627, time=547, train_MAE=0.517, train_loss=0.822, val_MAE=0.579, val_loss=0.884]Epoch 37:   4%|▎         | 37/1000 [5:26:12<145:56:13, 545.56s/it, lr=0.000125, test_MAE=0.627, time=547, train_MAE=0.517, train_loss=0.822, val_MAE=0.579, val_loss=0.884]Epoch 37:   4%|▎         | 37/1000 [5:35:22<145:56:13, 545.56s/it, lr=0.000125, test_MAE=0.632, time=549, train_MAE=0.516, train_loss=0.821, val_MAE=0.572, val_loss=0.877]Epoch 37:   4%|▍         | 38/1000 [5:35:22<146:06:14, 546.75s/it, lr=0.000125, test_MAE=0.632, time=549, train_MAE=0.516, train_loss=0.821, val_MAE=0.572, val_loss=0.877]Epoch 38:   4%|▍         | 38/1000 [5:35:22<146:06:14, 546.75s/it, lr=0.000125, test_MAE=0.632, time=549, train_MAE=0.516, train_loss=0.821, val_MAE=0.572, val_loss=0.877]Epoch 38:   4%|▍         | 38/1000 [5:44:31<146:06:14, 546.75s/it, lr=0.000125, test_MAE=0.668, time=549, train_MAE=0.517, train_loss=0.821, val_MAE=0.649, val_loss=0.953]Epoch 38:   4%|▍         | 39/1000 [5:44:31<146:08:37, 547.47s/it, lr=0.000125, test_MAE=0.668, time=549, train_MAE=0.517, train_loss=0.821, val_MAE=0.649, val_loss=0.953]Epoch 39:   4%|▍         | 39/1000 [5:44:31<146:08:37, 547.47s/it, lr=0.000125, test_MAE=0.668, time=549, train_MAE=0.517, train_loss=0.821, val_MAE=0.649, val_loss=0.953]Epoch 39:   4%|▍         | 39/1000 [5:53:39<146:08:37, 547.47s/it, lr=0.000125, test_MAE=0.59, time=548, train_MAE=0.521, train_loss=0.825, val_MAE=0.547, val_loss=0.851] Epoch 39:   4%|▍         | 40/1000 [5:53:39<146:02:04, 547.63s/it, lr=0.000125, test_MAE=0.59, time=548, train_MAE=0.521, train_loss=0.825, val_MAE=0.547, val_loss=0.851]Epoch 40:   4%|▍         | 40/1000 [5:53:39<146:02:04, 547.63s/it, lr=0.000125, test_MAE=0.59, time=548, train_MAE=0.521, train_loss=0.825, val_MAE=0.547, val_loss=0.851]Epoch 40:   4%|▍         | 40/1000 [6:02:46<146:02:04, 547.63s/it, lr=0.000125, test_MAE=0.627, time=547, train_MAE=0.518, train_loss=0.821, val_MAE=0.586, val_loss=0.889]Epoch    41: reducing learning rate of group 0 to 6.2500e-05.
Epoch 40:   4%|▍         | 41/1000 [6:02:46<145:51:04, 547.51s/it, lr=0.000125, test_MAE=0.627, time=547, train_MAE=0.518, train_loss=0.821, val_MAE=0.586, val_loss=0.889]Epoch 41:   4%|▍         | 41/1000 [6:02:46<145:51:04, 547.51s/it, lr=0.000125, test_MAE=0.627, time=547, train_MAE=0.518, train_loss=0.821, val_MAE=0.586, val_loss=0.889]Epoch 41:   4%|▍         | 41/1000 [6:11:55<145:51:04, 547.51s/it, lr=6.25e-5, test_MAE=0.591, time=549, train_MAE=0.507, train_loss=0.81, val_MAE=0.541, val_loss=0.844]  Epoch 41:   4%|▍         | 42/1000 [6:11:55<145:46:54, 547.82s/it, lr=6.25e-5, test_MAE=0.591, time=549, train_MAE=0.507, train_loss=0.81, val_MAE=0.541, val_loss=0.844]Epoch 42:   4%|▍         | 42/1000 [6:11:55<145:46:54, 547.82s/it, lr=6.25e-5, test_MAE=0.591, time=549, train_MAE=0.507, train_loss=0.81, val_MAE=0.541, val_loss=0.844]Epoch 42:   4%|▍         | 42/1000 [6:21:05<145:46:54, 547.82s/it, lr=6.25e-5, test_MAE=0.589, time=550, train_MAE=0.514, train_loss=0.816, val_MAE=0.551, val_loss=0.853]Epoch 42:   4%|▍         | 43/1000 [6:21:05<145:48:29, 548.50s/it, lr=6.25e-5, test_MAE=0.589, time=550, train_MAE=0.514, train_loss=0.816, val_MAE=0.551, val_loss=0.853]Epoch 43:   4%|▍         | 43/1000 [6:21:05<145:48:29, 548.50s/it, lr=6.25e-5, test_MAE=0.589, time=550, train_MAE=0.514, train_loss=0.816, val_MAE=0.551, val_loss=0.853]Epoch 43:   4%|▍         | 43/1000 [6:30:21<145:48:29, 548.50s/it, lr=6.25e-5, test_MAE=0.631, time=556, train_MAE=0.499, train_loss=0.801, val_MAE=0.58, val_loss=0.882] Epoch 43:   4%|▍         | 44/1000 [6:30:21<146:17:05, 550.86s/it, lr=6.25e-5, test_MAE=0.631, time=556, train_MAE=0.499, train_loss=0.801, val_MAE=0.58, val_loss=0.882]Epoch 44:   4%|▍         | 44/1000 [6:30:21<146:17:05, 550.86s/it, lr=6.25e-5, test_MAE=0.631, time=556, train_MAE=0.499, train_loss=0.801, val_MAE=0.58, val_loss=0.882]Epoch 44:   4%|▍         | 44/1000 [6:39:21<146:17:05, 550.86s/it, lr=6.25e-5, test_MAE=0.691, time=540, train_MAE=0.503, train_loss=0.804, val_MAE=0.647, val_loss=0.948]Epoch 44:   4%|▍         | 45/1000 [6:39:21<145:14:18, 547.50s/it, lr=6.25e-5, test_MAE=0.691, time=540, train_MAE=0.503, train_loss=0.804, val_MAE=0.647, val_loss=0.948]Epoch 45:   4%|▍         | 45/1000 [6:39:21<145:14:18, 547.50s/it, lr=6.25e-5, test_MAE=0.691, time=540, train_MAE=0.503, train_loss=0.804, val_MAE=0.647, val_loss=0.948]Epoch 45:   4%|▍         | 45/1000 [6:48:19<145:14:18, 547.50s/it, lr=6.25e-5, test_MAE=0.58, time=539, train_MAE=0.504, train_loss=0.805, val_MAE=0.536, val_loss=0.837] Epoch 45:   5%|▍         | 46/1000 [6:48:19<144:22:54, 544.84s/it, lr=6.25e-5, test_MAE=0.58, time=539, train_MAE=0.504, train_loss=0.805, val_MAE=0.536, val_loss=0.837]Epoch 46:   5%|▍         | 46/1000 [6:48:19<144:22:54, 544.84s/it, lr=6.25e-5, test_MAE=0.58, time=539, train_MAE=0.504, train_loss=0.805, val_MAE=0.536, val_loss=0.837]Epoch 46:   5%|▍         | 46/1000 [6:57:18<144:22:54, 544.84s/it, lr=6.25e-5, test_MAE=0.577, time=539, train_MAE=0.503, train_loss=0.804, val_MAE=0.529, val_loss=0.83]Epoch 46:   5%|▍         | 47/1000 [6:57:18<143:44:20, 542.98s/it, lr=6.25e-5, test_MAE=0.577, time=539, train_MAE=0.503, train_loss=0.804, val_MAE=0.529, val_loss=0.83]Epoch 47:   5%|▍         | 47/1000 [6:57:18<143:44:20, 542.98s/it, lr=6.25e-5, test_MAE=0.577, time=539, train_MAE=0.503, train_loss=0.804, val_MAE=0.529, val_loss=0.83]Epoch 47:   5%|▍         | 47/1000 [7:06:16<143:44:20, 542.98s/it, lr=6.25e-5, test_MAE=0.604, time=538, train_MAE=0.505, train_loss=0.806, val_MAE=0.561, val_loss=0.861]Epoch 47:   5%|▍         | 48/1000 [7:06:16<143:12:06, 541.52s/it, lr=6.25e-5, test_MAE=0.604, time=538, train_MAE=0.505, train_loss=0.806, val_MAE=0.561, val_loss=0.861]Epoch 48:   5%|▍         | 48/1000 [7:06:16<143:12:06, 541.52s/it, lr=6.25e-5, test_MAE=0.604, time=538, train_MAE=0.505, train_loss=0.806, val_MAE=0.561, val_loss=0.861]Epoch 48:   5%|▍         | 48/1000 [7:15:15<143:12:06, 541.52s/it, lr=6.25e-5, test_MAE=0.837, time=539, train_MAE=0.505, train_loss=0.805, val_MAE=0.811, val_loss=1.11] Epoch 48:   5%|▍         | 49/1000 [7:15:15<142:49:36, 540.67s/it, lr=6.25e-5, test_MAE=0.837, time=539, train_MAE=0.505, train_loss=0.805, val_MAE=0.811, val_loss=1.11]Epoch 49:   5%|▍         | 49/1000 [7:15:15<142:49:36, 540.67s/it, lr=6.25e-5, test_MAE=0.837, time=539, train_MAE=0.505, train_loss=0.805, val_MAE=0.811, val_loss=1.11]Epoch 49:   5%|▍         | 49/1000 [7:24:24<142:49:36, 540.67s/it, lr=6.25e-5, test_MAE=0.585, time=549, train_MAE=0.505, train_loss=0.804, val_MAE=0.548, val_loss=0.847]Epoch 49:   5%|▌         | 50/1000 [7:24:24<143:18:59, 543.09s/it, lr=6.25e-5, test_MAE=0.585, time=549, train_MAE=0.505, train_loss=0.804, val_MAE=0.548, val_loss=0.847]Epoch 50:   5%|▌         | 50/1000 [7:24:24<143:18:59, 543.09s/it, lr=6.25e-5, test_MAE=0.585, time=549, train_MAE=0.505, train_loss=0.804, val_MAE=0.548, val_loss=0.847]Epoch 50:   5%|▌         | 50/1000 [7:33:34<143:18:59, 543.09s/it, lr=6.25e-5, test_MAE=0.615, time=550, train_MAE=0.502, train_loss=0.801, val_MAE=0.568, val_loss=0.867]Epoch 50:   5%|▌         | 51/1000 [7:33:34<143:45:02, 545.31s/it, lr=6.25e-5, test_MAE=0.615, time=550, train_MAE=0.502, train_loss=0.801, val_MAE=0.568, val_loss=0.867]Epoch 51:   5%|▌         | 51/1000 [7:33:34<143:45:02, 545.31s/it, lr=6.25e-5, test_MAE=0.615, time=550, train_MAE=0.502, train_loss=0.801, val_MAE=0.568, val_loss=0.867]Epoch 51:   5%|▌         | 51/1000 [7:42:46<143:45:02, 545.31s/it, lr=6.25e-5, test_MAE=0.595, time=552, train_MAE=0.498, train_loss=0.797, val_MAE=0.547, val_loss=0.846]Epoch 51:   5%|▌         | 52/1000 [7:42:46<144:08:49, 547.39s/it, lr=6.25e-5, test_MAE=0.595, time=552, train_MAE=0.498, train_loss=0.797, val_MAE=0.547, val_loss=0.846]Epoch 52:   5%|▌         | 52/1000 [7:42:46<144:08:49, 547.39s/it, lr=6.25e-5, test_MAE=0.595, time=552, train_MAE=0.498, train_loss=0.797, val_MAE=0.547, val_loss=0.846]Epoch 52:   5%|▌         | 52/1000 [7:51:59<144:08:49, 547.39s/it, lr=6.25e-5, test_MAE=0.595, time=552, train_MAE=0.508, train_loss=0.807, val_MAE=0.545, val_loss=0.843]Epoch    53: reducing learning rate of group 0 to 3.1250e-05.
Epoch 52:   5%|▌         | 53/1000 [7:51:59<144:22:48, 548.86s/it, lr=6.25e-5, test_MAE=0.595, time=552, train_MAE=0.508, train_loss=0.807, val_MAE=0.545, val_loss=0.843]Epoch 53:   5%|▌         | 53/1000 [7:51:59<144:22:48, 548.86s/it, lr=6.25e-5, test_MAE=0.595, time=552, train_MAE=0.508, train_loss=0.807, val_MAE=0.545, val_loss=0.843]Epoch 53:   5%|▌         | 53/1000 [8:01:10<144:22:48, 548.86s/it, lr=3.13e-5, test_MAE=0.574, time=552, train_MAE=0.493, train_loss=0.791, val_MAE=0.529, val_loss=0.827]Epoch 53:   5%|▌         | 54/1000 [8:01:10<144:27:16, 549.72s/it, lr=3.13e-5, test_MAE=0.574, time=552, train_MAE=0.493, train_loss=0.791, val_MAE=0.529, val_loss=0.827]Epoch 54:   5%|▌         | 54/1000 [8:01:10<144:27:16, 549.72s/it, lr=3.13e-5, test_MAE=0.574, time=552, train_MAE=0.493, train_loss=0.791, val_MAE=0.529, val_loss=0.827]Epoch 54:   5%|▌         | 54/1000 [8:10:23<144:27:16, 549.72s/it, lr=3.13e-5, test_MAE=0.591, time=553, train_MAE=0.482, train_loss=0.78, val_MAE=0.555, val_loss=0.853] Epoch 54:   6%|▌         | 55/1000 [8:10:23<144:33:48, 550.72s/it, lr=3.13e-5, test_MAE=0.591, time=553, train_MAE=0.482, train_loss=0.78, val_MAE=0.555, val_loss=0.853]Epoch 55:   6%|▌         | 55/1000 [8:10:23<144:33:48, 550.72s/it, lr=3.13e-5, test_MAE=0.591, time=553, train_MAE=0.482, train_loss=0.78, val_MAE=0.555, val_loss=0.853]Epoch 55:   6%|▌         | 55/1000 [8:19:30<144:33:48, 550.72s/it, lr=3.13e-5, test_MAE=0.584, time=547, train_MAE=0.485, train_loss=0.783, val_MAE=0.54, val_loss=0.837]Epoch 55:   6%|▌         | 56/1000 [8:19:30<144:05:01, 549.47s/it, lr=3.13e-5, test_MAE=0.584, time=547, train_MAE=0.485, train_loss=0.783, val_MAE=0.54, val_loss=0.837]Epoch 56:   6%|▌         | 56/1000 [8:19:30<144:05:01, 549.47s/it, lr=3.13e-5, test_MAE=0.584, time=547, train_MAE=0.485, train_loss=0.783, val_MAE=0.54, val_loss=0.837]Epoch 56:   6%|▌         | 56/1000 [8:28:39<144:05:01, 549.47s/it, lr=3.13e-5, test_MAE=0.574, time=549, train_MAE=0.482, train_loss=0.779, val_MAE=0.529, val_loss=0.826]Epoch 56:   6%|▌         | 57/1000 [8:28:39<143:52:09, 549.24s/it, lr=3.13e-5, test_MAE=0.574, time=549, train_MAE=0.482, train_loss=0.779, val_MAE=0.529, val_loss=0.826]Epoch 57:   6%|▌         | 57/1000 [8:28:39<143:52:09, 549.24s/it, lr=3.13e-5, test_MAE=0.574, time=549, train_MAE=0.482, train_loss=0.779, val_MAE=0.529, val_loss=0.826]Epoch 57:   6%|▌         | 57/1000 [8:37:50<143:52:09, 549.24s/it, lr=3.13e-5, test_MAE=0.594, time=551, train_MAE=0.486, train_loss=0.783, val_MAE=0.543, val_loss=0.839]Epoch 57:   6%|▌         | 58/1000 [8:37:50<143:53:18, 549.89s/it, lr=3.13e-5, test_MAE=0.594, time=551, train_MAE=0.486, train_loss=0.783, val_MAE=0.543, val_loss=0.839]Epoch 58:   6%|▌         | 58/1000 [8:37:50<143:53:18, 549.89s/it, lr=3.13e-5, test_MAE=0.594, time=551, train_MAE=0.486, train_loss=0.783, val_MAE=0.543, val_loss=0.839]Epoch 58:   6%|▌         | 58/1000 [8:47:03<143:53:18, 549.89s/it, lr=3.13e-5, test_MAE=0.587, time=553, train_MAE=0.49, train_loss=0.787, val_MAE=0.53, val_loss=0.827]  Epoch 58:   6%|▌         | 59/1000 [8:47:03<144:00:04, 550.91s/it, lr=3.13e-5, test_MAE=0.587, time=553, train_MAE=0.49, train_loss=0.787, val_MAE=0.53, val_loss=0.827]Epoch 59:   6%|▌         | 59/1000 [8:47:03<144:00:04, 550.91s/it, lr=3.13e-5, test_MAE=0.587, time=553, train_MAE=0.49, train_loss=0.787, val_MAE=0.53, val_loss=0.827]Epoch 59:   6%|▌         | 59/1000 [8:56:13<144:00:04, 550.91s/it, lr=3.13e-5, test_MAE=0.577, time=550, train_MAE=0.488, train_loss=0.785, val_MAE=0.53, val_loss=0.827]Epoch 59:   6%|▌         | 60/1000 [8:56:13<143:45:09, 550.54s/it, lr=3.13e-5, test_MAE=0.577, time=550, train_MAE=0.488, train_loss=0.785, val_MAE=0.53, val_loss=0.827]Epoch 60:   6%|▌         | 60/1000 [8:56:13<143:45:09, 550.54s/it, lr=3.13e-5, test_MAE=0.577, time=550, train_MAE=0.488, train_loss=0.785, val_MAE=0.53, val_loss=0.827]Epoch 60:   6%|▌         | 60/1000 [9:05:23<143:45:09, 550.54s/it, lr=3.13e-5, test_MAE=0.59, time=550, train_MAE=0.48, train_loss=0.776, val_MAE=0.555, val_loss=0.851] Epoch 60:   6%|▌         | 61/1000 [9:05:23<143:34:05, 550.42s/it, lr=3.13e-5, test_MAE=0.59, time=550, train_MAE=0.48, train_loss=0.776, val_MAE=0.555, val_loss=0.851]Epoch 61:   6%|▌         | 61/1000 [9:05:23<143:34:05, 550.42s/it, lr=3.13e-5, test_MAE=0.59, time=550, train_MAE=0.48, train_loss=0.776, val_MAE=0.555, val_loss=0.851]Epoch 61:   6%|▌         | 61/1000 [9:14:34<143:34:05, 550.42s/it, lr=3.13e-5, test_MAE=0.614, time=551, train_MAE=0.486, train_loss=0.782, val_MAE=0.575, val_loss=0.87]Epoch 61:   6%|▌         | 62/1000 [9:14:34<143:26:58, 550.55s/it, lr=3.13e-5, test_MAE=0.614, time=551, train_MAE=0.486, train_loss=0.782, val_MAE=0.575, val_loss=0.87]Epoch 62:   6%|▌         | 62/1000 [9:14:34<143:26:58, 550.55s/it, lr=3.13e-5, test_MAE=0.614, time=551, train_MAE=0.486, train_loss=0.782, val_MAE=0.575, val_loss=0.87]Epoch 62:   6%|▌         | 62/1000 [9:23:44<143:26:58, 550.55s/it, lr=3.13e-5, test_MAE=0.618, time=550, train_MAE=0.491, train_loss=0.787, val_MAE=0.581, val_loss=0.876]Epoch    63: reducing learning rate of group 0 to 1.5625e-05.
Epoch 62:   6%|▋         | 63/1000 [9:23:44<143:13:05, 550.25s/it, lr=3.13e-5, test_MAE=0.618, time=550, train_MAE=0.491, train_loss=0.787, val_MAE=0.581, val_loss=0.876]Epoch 63:   6%|▋         | 63/1000 [9:23:44<143:13:05, 550.25s/it, lr=3.13e-5, test_MAE=0.618, time=550, train_MAE=0.491, train_loss=0.787, val_MAE=0.581, val_loss=0.876]Epoch 63:   6%|▋         | 63/1000 [9:32:52<143:13:05, 550.25s/it, lr=1.56e-5, test_MAE=0.574, time=549, train_MAE=0.479, train_loss=0.774, val_MAE=0.524, val_loss=0.819]Epoch 63:   6%|▋         | 64/1000 [9:32:53<142:57:47, 549.86s/it, lr=1.56e-5, test_MAE=0.574, time=549, train_MAE=0.479, train_loss=0.774, val_MAE=0.524, val_loss=0.819]Epoch 64:   6%|▋         | 64/1000 [9:32:53<142:57:47, 549.86s/it, lr=1.56e-5, test_MAE=0.574, time=549, train_MAE=0.479, train_loss=0.774, val_MAE=0.524, val_loss=0.819]Epoch 64:   6%|▋         | 64/1000 [9:42:03<142:57:47, 549.86s/it, lr=1.56e-5, test_MAE=0.572, time=550, train_MAE=0.476, train_loss=0.771, val_MAE=0.524, val_loss=0.819]Epoch 64:   6%|▋         | 65/1000 [9:42:03<142:50:28, 549.98s/it, lr=1.56e-5, test_MAE=0.572, time=550, train_MAE=0.476, train_loss=0.771, val_MAE=0.524, val_loss=0.819]Epoch 65:   6%|▋         | 65/1000 [9:42:03<142:50:28, 549.98s/it, lr=1.56e-5, test_MAE=0.572, time=550, train_MAE=0.476, train_loss=0.771, val_MAE=0.524, val_loss=0.819]Epoch 65:   6%|▋         | 65/1000 [9:51:13<142:50:28, 549.98s/it, lr=1.56e-5, test_MAE=0.571, time=550, train_MAE=0.474, train_loss=0.769, val_MAE=0.532, val_loss=0.827]Epoch 65:   7%|▋         | 66/1000 [9:51:13<142:42:25, 550.05s/it, lr=1.56e-5, test_MAE=0.571, time=550, train_MAE=0.474, train_loss=0.769, val_MAE=0.532, val_loss=0.827]Epoch 66:   7%|▋         | 66/1000 [9:51:13<142:42:25, 550.05s/it, lr=1.56e-5, test_MAE=0.571, time=550, train_MAE=0.474, train_loss=0.769, val_MAE=0.532, val_loss=0.827]Epoch 66:   7%|▋         | 66/1000 [10:00:23<142:42:25, 550.05s/it, lr=1.56e-5, test_MAE=0.579, time=550, train_MAE=0.481, train_loss=0.775, val_MAE=0.525, val_loss=0.82]Epoch 66:   7%|▋         | 67/1000 [10:00:23<142:31:54, 549.96s/it, lr=1.56e-5, test_MAE=0.579, time=550, train_MAE=0.481, train_loss=0.775, val_MAE=0.525, val_loss=0.82]Epoch 67:   7%|▋         | 67/1000 [10:00:23<142:31:54, 549.96s/it, lr=1.56e-5, test_MAE=0.579, time=550, train_MAE=0.481, train_loss=0.775, val_MAE=0.525, val_loss=0.82]Epoch 67:   7%|▋         | 67/1000 [10:09:33<142:31:54, 549.96s/it, lr=1.56e-5, test_MAE=0.574, time=550, train_MAE=0.477, train_loss=0.771, val_MAE=0.527, val_loss=0.821]Epoch 67:   7%|▋         | 68/1000 [10:09:33<142:22:13, 549.93s/it, lr=1.56e-5, test_MAE=0.574, time=550, train_MAE=0.477, train_loss=0.771, val_MAE=0.527, val_loss=0.821]Epoch 68:   7%|▋         | 68/1000 [10:09:33<142:22:13, 549.93s/it, lr=1.56e-5, test_MAE=0.574, time=550, train_MAE=0.477, train_loss=0.771, val_MAE=0.527, val_loss=0.821]Epoch 68:   7%|▋         | 68/1000 [10:18:40<142:22:13, 549.93s/it, lr=1.56e-5, test_MAE=0.577, time=548, train_MAE=0.473, train_loss=0.768, val_MAE=0.524, val_loss=0.818]Epoch 68:   7%|▋         | 69/1000 [10:18:40<142:03:05, 549.29s/it, lr=1.56e-5, test_MAE=0.577, time=548, train_MAE=0.473, train_loss=0.768, val_MAE=0.524, val_loss=0.818]Epoch 69:   7%|▋         | 69/1000 [10:18:40<142:03:05, 549.29s/it, lr=1.56e-5, test_MAE=0.577, time=548, train_MAE=0.473, train_loss=0.768, val_MAE=0.524, val_loss=0.818]Epoch 69:   7%|▋         | 69/1000 [10:27:48<142:03:05, 549.29s/it, lr=1.56e-5, test_MAE=0.573, time=547, train_MAE=0.466, train_loss=0.761, val_MAE=0.532, val_loss=0.826]Epoch 69:   7%|▋         | 70/1000 [10:27:48<141:44:07, 548.65s/it, lr=1.56e-5, test_MAE=0.573, time=547, train_MAE=0.466, train_loss=0.761, val_MAE=0.532, val_loss=0.826]Epoch 70:   7%|▋         | 70/1000 [10:27:48<141:44:07, 548.65s/it, lr=1.56e-5, test_MAE=0.573, time=547, train_MAE=0.466, train_loss=0.761, val_MAE=0.532, val_loss=0.826]Epoch 70:   7%|▋         | 70/1000 [10:37:02<141:44:07, 548.65s/it, lr=1.56e-5, test_MAE=0.574, time=555, train_MAE=0.47, train_loss=0.764, val_MAE=0.529, val_loss=0.823] Epoch 70:   7%|▋         | 71/1000 [10:37:02<142:02:23, 550.42s/it, lr=1.56e-5, test_MAE=0.574, time=555, train_MAE=0.47, train_loss=0.764, val_MAE=0.529, val_loss=0.823]Epoch 71:   7%|▋         | 71/1000 [10:37:02<142:02:23, 550.42s/it, lr=1.56e-5, test_MAE=0.574, time=555, train_MAE=0.47, train_loss=0.764, val_MAE=0.529, val_loss=0.823]Epoch 71:   7%|▋         | 71/1000 [10:46:20<142:02:23, 550.42s/it, lr=1.56e-5, test_MAE=0.573, time=558, train_MAE=0.484, train_loss=0.778, val_MAE=0.528, val_loss=0.822]Epoch 71:   7%|▋         | 72/1000 [10:46:20<142:26:42, 552.59s/it, lr=1.56e-5, test_MAE=0.573, time=558, train_MAE=0.484, train_loss=0.778, val_MAE=0.528, val_loss=0.822]Epoch 72:   7%|▋         | 72/1000 [10:46:20<142:26:42, 552.59s/it, lr=1.56e-5, test_MAE=0.573, time=558, train_MAE=0.484, train_loss=0.778, val_MAE=0.528, val_loss=0.822]Epoch 72:   7%|▋         | 72/1000 [10:55:36<142:26:42, 552.59s/it, lr=1.56e-5, test_MAE=0.573, time=557, train_MAE=0.466, train_loss=0.76, val_MAE=0.522, val_loss=0.816] Epoch 72:   7%|▋         | 73/1000 [10:55:36<142:36:02, 553.79s/it, lr=1.56e-5, test_MAE=0.573, time=557, train_MAE=0.466, train_loss=0.76, val_MAE=0.522, val_loss=0.816]Epoch 73:   7%|▋         | 73/1000 [10:55:36<142:36:02, 553.79s/it, lr=1.56e-5, test_MAE=0.573, time=557, train_MAE=0.466, train_loss=0.76, val_MAE=0.522, val_loss=0.816]Epoch 73:   7%|▋         | 73/1000 [11:04:59<142:36:02, 553.79s/it, lr=1.56e-5, test_MAE=0.572, time=563, train_MAE=0.47, train_loss=0.764, val_MAE=0.529, val_loss=0.822]Epoch 73:   7%|▋         | 74/1000 [11:04:59<143:09:23, 556.55s/it, lr=1.56e-5, test_MAE=0.572, time=563, train_MAE=0.47, train_loss=0.764, val_MAE=0.529, val_loss=0.822]Epoch 74:   7%|▋         | 74/1000 [11:04:59<143:09:23, 556.55s/it, lr=1.56e-5, test_MAE=0.572, time=563, train_MAE=0.47, train_loss=0.764, val_MAE=0.529, val_loss=0.822]Epoch 74:   7%|▋         | 74/1000 [11:14:14<143:09:23, 556.55s/it, lr=1.56e-5, test_MAE=0.567, time=555, train_MAE=0.468, train_loss=0.762, val_MAE=0.521, val_loss=0.814]Epoch 74:   8%|▊         | 75/1000 [11:14:14<142:52:48, 556.07s/it, lr=1.56e-5, test_MAE=0.567, time=555, train_MAE=0.468, train_loss=0.762, val_MAE=0.521, val_loss=0.814]Epoch 75:   8%|▊         | 75/1000 [11:14:14<142:52:48, 556.07s/it, lr=1.56e-5, test_MAE=0.567, time=555, train_MAE=0.468, train_loss=0.762, val_MAE=0.521, val_loss=0.814]Epoch 75:   8%|▊         | 75/1000 [11:23:24<142:52:48, 556.07s/it, lr=1.56e-5, test_MAE=0.605, time=550, train_MAE=0.465, train_loss=0.758, val_MAE=0.567, val_loss=0.86] Epoch 75:   8%|▊         | 76/1000 [11:23:24<142:13:23, 554.12s/it, lr=1.56e-5, test_MAE=0.605, time=550, train_MAE=0.465, train_loss=0.758, val_MAE=0.567, val_loss=0.86]Epoch 76:   8%|▊         | 76/1000 [11:23:24<142:13:23, 554.12s/it, lr=1.56e-5, test_MAE=0.605, time=550, train_MAE=0.465, train_loss=0.758, val_MAE=0.567, val_loss=0.86]Epoch 76:   8%|▊         | 76/1000 [11:32:34<142:13:23, 554.12s/it, lr=1.56e-5, test_MAE=0.568, time=550, train_MAE=0.466, train_loss=0.758, val_MAE=0.523, val_loss=0.816]Epoch 76:   8%|▊         | 77/1000 [11:32:34<141:46:00, 552.94s/it, lr=1.56e-5, test_MAE=0.568, time=550, train_MAE=0.466, train_loss=0.758, val_MAE=0.523, val_loss=0.816]Epoch 77:   8%|▊         | 77/1000 [11:32:34<141:46:00, 552.94s/it, lr=1.56e-5, test_MAE=0.568, time=550, train_MAE=0.466, train_loss=0.758, val_MAE=0.523, val_loss=0.816]Epoch 77:   8%|▊         | 77/1000 [11:41:43<141:46:00, 552.94s/it, lr=1.56e-5, test_MAE=0.58, time=549, train_MAE=0.461, train_loss=0.753, val_MAE=0.539, val_loss=0.831] Epoch 77:   8%|▊         | 78/1000 [11:41:43<141:19:01, 551.78s/it, lr=1.56e-5, test_MAE=0.58, time=549, train_MAE=0.461, train_loss=0.753, val_MAE=0.539, val_loss=0.831]Epoch 78:   8%|▊         | 78/1000 [11:41:43<141:19:01, 551.78s/it, lr=1.56e-5, test_MAE=0.58, time=549, train_MAE=0.461, train_loss=0.753, val_MAE=0.539, val_loss=0.831]Epoch 78:   8%|▊         | 78/1000 [11:50:59<141:19:01, 551.78s/it, lr=1.56e-5, test_MAE=0.574, time=556, train_MAE=0.464, train_loss=0.756, val_MAE=0.535, val_loss=0.827]Epoch 78:   8%|▊         | 79/1000 [11:50:59<141:28:24, 552.99s/it, lr=1.56e-5, test_MAE=0.574, time=556, train_MAE=0.464, train_loss=0.756, val_MAE=0.535, val_loss=0.827]Epoch 79:   8%|▊         | 79/1000 [11:50:59<141:28:24, 552.99s/it, lr=1.56e-5, test_MAE=0.574, time=556, train_MAE=0.464, train_loss=0.756, val_MAE=0.535, val_loss=0.827]Epoch 79:   8%|▊         | 79/1000 [12:00:23<141:28:24, 552.99s/it, lr=1.56e-5, test_MAE=0.575, time=564, train_MAE=0.471, train_loss=0.763, val_MAE=0.535, val_loss=0.828]Epoch 79:   8%|▊         | 80/1000 [12:00:23<142:08:34, 556.21s/it, lr=1.56e-5, test_MAE=0.575, time=564, train_MAE=0.471, train_loss=0.763, val_MAE=0.535, val_loss=0.828]Epoch 80:   8%|▊         | 80/1000 [12:00:23<142:08:34, 556.21s/it, lr=1.56e-5, test_MAE=0.575, time=564, train_MAE=0.471, train_loss=0.763, val_MAE=0.535, val_loss=0.828]Epoch 80:   8%|▊         | 80/1000 [12:09:45<142:08:34, 556.21s/it, lr=1.56e-5, test_MAE=0.581, time=562, train_MAE=0.467, train_loss=0.759, val_MAE=0.539, val_loss=0.831]Epoch    81: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 80:   8%|▊         | 80/1000 [12:09:45<139:52:10, 547.32s/it, lr=1.56e-5, test_MAE=0.581, time=562, train_MAE=0.467, train_loss=0.759, val_MAE=0.539, val_loss=0.831]
Test MAE: 0.5805
Train MAE: 0.4628
Convergence Time (Epochs): 80.0000
TOTAL TIME TAKEN: 44002.9718s
AVG TIME PER EPOCH: 540.5301s
