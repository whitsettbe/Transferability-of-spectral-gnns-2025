I'm echoing to stdout
I'm echoing to stderr
My JobID is 56855516
I have 4 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset SBM_CLUSTER...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 7.3506s
Dataset: SBM_CLUSTER,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 70, 'out_dim': 70, 'residual': False, 'k': 5, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'cheb02_vec', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_all', 'num_eigs': 190, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'in_dim': 7, 'n_classes': 6, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
Number of Classes:  6
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]/vast/palmer/pi/krishnaswamy_smita/bsw38/GraphML/Transferability-of-spectral-gnns-2025/Benchmark-gnn/nets/SBMs_node_classification/ChebNet.py:74: UserWarning: This overload of nonzero is deprecated:
	nonzero()
Consider using one of the following signatures instead:
	nonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629427478/work/torch/csrc/utils/python_arg_parser.cpp:766.)
  label_count = label_count[label_count.nonzero()].squeeze()
Epoch 0:   0%|          | 0/1000 [04:07<?, ?it/s, lr=0.001, test_acc=36.5, time=248, train_acc=37.6, train_loss=1.52, val_acc=36, val_loss=1.67]Epoch 0:   0%|          | 1/1000 [04:07<68:45:31, 247.78s/it, lr=0.001, test_acc=36.5, time=248, train_acc=37.6, train_loss=1.52, val_acc=36, val_loss=1.67]Epoch 1:   0%|          | 1/1000 [04:07<68:45:31, 247.78s/it, lr=0.001, test_acc=36.5, time=248, train_acc=37.6, train_loss=1.52, val_acc=36, val_loss=1.67]Epoch 1:   0%|          | 1/1000 [07:09<68:45:31, 247.78s/it, lr=0.001, test_acc=57.2, time=181, train_acc=61.1, train_loss=1.07, val_acc=57, val_loss=1.21]Epoch 1:   0%|          | 2/1000 [07:09<63:10:19, 227.88s/it, lr=0.001, test_acc=57.2, time=181, train_acc=61.1, train_loss=1.07, val_acc=57, val_loss=1.21]Epoch 2:   0%|          | 2/1000 [07:09<63:10:19, 227.88s/it, lr=0.001, test_acc=57.2, time=181, train_acc=61.1, train_loss=1.07, val_acc=57, val_loss=1.21]Epoch 2:   0%|          | 2/1000 [10:11<63:10:19, 227.88s/it, lr=0.001, test_acc=58.5, time=182, train_acc=63.9, train_loss=0.992, val_acc=58.4, val_loss=1.19]Epoch 2:   0%|          | 3/1000 [10:11<59:18:10, 214.13s/it, lr=0.001, test_acc=58.5, time=182, train_acc=63.9, train_loss=0.992, val_acc=58.4, val_loss=1.19]Epoch 3:   0%|          | 3/1000 [10:11<59:18:10, 214.13s/it, lr=0.001, test_acc=58.5, time=182, train_acc=63.9, train_loss=0.992, val_acc=58.4, val_loss=1.19]Epoch 3:   0%|          | 3/1000 [13:12<59:18:10, 214.13s/it, lr=0.001, test_acc=60, time=182, train_acc=65.4, train_loss=0.948, val_acc=59.7, val_loss=1.14]  Epoch 3:   0%|          | 4/1000 [13:12<56:32:51, 204.39s/it, lr=0.001, test_acc=60, time=182, train_acc=65.4, train_loss=0.948, val_acc=59.7, val_loss=1.14]Epoch 4:   0%|          | 4/1000 [13:12<56:32:51, 204.39s/it, lr=0.001, test_acc=60, time=182, train_acc=65.4, train_loss=0.948, val_acc=59.7, val_loss=1.14]Epoch 4:   0%|          | 4/1000 [16:14<56:32:51, 204.39s/it, lr=0.001, test_acc=60.3, time=182, train_acc=65.8, train_loss=0.938, val_acc=60.1, val_loss=1.11]Epoch 4:   0%|          | 5/1000 [16:14<54:36:17, 197.57s/it, lr=0.001, test_acc=60.3, time=182, train_acc=65.8, train_loss=0.938, val_acc=60.1, val_loss=1.11]Epoch 5:   0%|          | 5/1000 [16:14<54:36:17, 197.57s/it, lr=0.001, test_acc=60.3, time=182, train_acc=65.8, train_loss=0.938, val_acc=60.1, val_loss=1.11]Epoch 5:   0%|          | 5/1000 [19:16<54:36:17, 197.57s/it, lr=0.001, test_acc=62.8, time=182, train_acc=66.9, train_loss=0.907, val_acc=63, val_loss=1.03]  Epoch 5:   1%|          | 6/1000 [19:16<53:15:07, 192.86s/it, lr=0.001, test_acc=62.8, time=182, train_acc=66.9, train_loss=0.907, val_acc=63, val_loss=1.03]Epoch 6:   1%|          | 6/1000 [19:16<53:15:07, 192.86s/it, lr=0.001, test_acc=62.8, time=182, train_acc=66.9, train_loss=0.907, val_acc=63, val_loss=1.03]Epoch 6:   1%|          | 6/1000 [22:18<53:15:07, 192.86s/it, lr=0.001, test_acc=64.5, time=182, train_acc=67.6, train_loss=0.889, val_acc=64.6, val_loss=0.981]Epoch 6:   1%|          | 7/1000 [22:18<52:18:11, 189.62s/it, lr=0.001, test_acc=64.5, time=182, train_acc=67.6, train_loss=0.889, val_acc=64.6, val_loss=0.981]Epoch 7:   1%|          | 7/1000 [22:18<52:18:11, 189.62s/it, lr=0.001, test_acc=64.5, time=182, train_acc=67.6, train_loss=0.889, val_acc=64.6, val_loss=0.981]Epoch 7:   1%|          | 7/1000 [25:20<52:18:11, 189.62s/it, lr=0.001, test_acc=64.6, time=182, train_acc=67.5, train_loss=0.888, val_acc=64.6, val_loss=1.02] Epoch 7:   1%|          | 8/1000 [25:20<51:37:46, 187.37s/it, lr=0.001, test_acc=64.6, time=182, train_acc=67.5, train_loss=0.888, val_acc=64.6, val_loss=1.02]Epoch 8:   1%|          | 8/1000 [25:20<51:37:46, 187.37s/it, lr=0.001, test_acc=64.6, time=182, train_acc=67.5, train_loss=0.888, val_acc=64.6, val_loss=1.02]Epoch 8:   1%|          | 8/1000 [28:22<51:37:46, 187.37s/it, lr=0.001, test_acc=60, time=182, train_acc=68.3, train_loss=0.869, val_acc=59.6, val_loss=1.08]  Epoch 8:   1%|          | 9/1000 [28:22<51:05:45, 185.62s/it, lr=0.001, test_acc=60, time=182, train_acc=68.3, train_loss=0.869, val_acc=59.6, val_loss=1.08]Epoch 9:   1%|          | 9/1000 [28:22<51:05:45, 185.62s/it, lr=0.001, test_acc=60, time=182, train_acc=68.3, train_loss=0.869, val_acc=59.6, val_loss=1.08]Epoch 9:   1%|          | 9/1000 [31:23<51:05:45, 185.62s/it, lr=0.001, test_acc=66.4, time=181, train_acc=68.6, train_loss=0.861, val_acc=66.2, val_loss=1.02]Epoch 9:   1%|          | 10/1000 [31:23<50:39:59, 184.24s/it, lr=0.001, test_acc=66.4, time=181, train_acc=68.6, train_loss=0.861, val_acc=66.2, val_loss=1.02]Epoch 10:   1%|          | 10/1000 [31:23<50:39:59, 184.24s/it, lr=0.001, test_acc=66.4, time=181, train_acc=68.6, train_loss=0.861, val_acc=66.2, val_loss=1.02]Epoch 10:   1%|          | 10/1000 [34:24<50:39:59, 184.24s/it, lr=0.001, test_acc=66.2, time=181, train_acc=68.7, train_loss=0.856, val_acc=66.1, val_loss=0.968]Epoch 10:   1%|          | 11/1000 [34:24<50:20:55, 183.27s/it, lr=0.001, test_acc=66.2, time=181, train_acc=68.7, train_loss=0.856, val_acc=66.1, val_loss=0.968]Epoch 11:   1%|          | 11/1000 [34:24<50:20:55, 183.27s/it, lr=0.001, test_acc=66.2, time=181, train_acc=68.7, train_loss=0.856, val_acc=66.1, val_loss=0.968]Epoch 11:   1%|          | 11/1000 [37:25<50:20:55, 183.27s/it, lr=0.001, test_acc=64.3, time=181, train_acc=68.9, train_loss=0.85, val_acc=63.9, val_loss=0.994] Epoch 11:   1%|          | 12/1000 [37:25<50:06:31, 182.58s/it, lr=0.001, test_acc=64.3, time=181, train_acc=68.9, train_loss=0.85, val_acc=63.9, val_loss=0.994]Epoch 12:   1%|          | 12/1000 [37:25<50:06:31, 182.58s/it, lr=0.001, test_acc=64.3, time=181, train_acc=68.9, train_loss=0.85, val_acc=63.9, val_loss=0.994]Epoch 12:   1%|          | 12/1000 [40:25<50:06:31, 182.58s/it, lr=0.001, test_acc=61.8, time=181, train_acc=69.2, train_loss=0.843, val_acc=61.4, val_loss=1.07]Epoch 12:   1%|▏         | 13/1000 [40:25<49:54:37, 182.04s/it, lr=0.001, test_acc=61.8, time=181, train_acc=69.2, train_loss=0.843, val_acc=61.4, val_loss=1.07]Epoch 13:   1%|▏         | 13/1000 [40:25<49:54:37, 182.04s/it, lr=0.001, test_acc=61.8, time=181, train_acc=69.2, train_loss=0.843, val_acc=61.4, val_loss=1.07]Epoch 13:   1%|▏         | 13/1000 [43:26<49:54:37, 182.04s/it, lr=0.001, test_acc=58.6, time=181, train_acc=69.4, train_loss=0.837, val_acc=58, val_loss=1.22]  Epoch 13:   1%|▏         | 14/1000 [43:26<49:45:24, 181.67s/it, lr=0.001, test_acc=58.6, time=181, train_acc=69.4, train_loss=0.837, val_acc=58, val_loss=1.22]Epoch 14:   1%|▏         | 14/1000 [43:26<49:45:24, 181.67s/it, lr=0.001, test_acc=58.6, time=181, train_acc=69.4, train_loss=0.837, val_acc=58, val_loss=1.22]Epoch 14:   1%|▏         | 14/1000 [46:27<49:45:24, 181.67s/it, lr=0.001, test_acc=62.3, time=181, train_acc=69.5, train_loss=0.835, val_acc=62.4, val_loss=1.04]Epoch 14:   2%|▏         | 15/1000 [46:27<49:39:00, 181.46s/it, lr=0.001, test_acc=62.3, time=181, train_acc=69.5, train_loss=0.835, val_acc=62.4, val_loss=1.04]Epoch 15:   2%|▏         | 15/1000 [46:27<49:39:00, 181.46s/it, lr=0.001, test_acc=62.3, time=181, train_acc=69.5, train_loss=0.835, val_acc=62.4, val_loss=1.04]Epoch 15:   2%|▏         | 15/1000 [49:28<49:39:00, 181.46s/it, lr=0.001, test_acc=66.4, time=181, train_acc=69.5, train_loss=0.833, val_acc=66.5, val_loss=0.945]Epoch 15:   2%|▏         | 16/1000 [49:28<49:32:35, 181.26s/it, lr=0.001, test_acc=66.4, time=181, train_acc=69.5, train_loss=0.833, val_acc=66.5, val_loss=0.945]Epoch 16:   2%|▏         | 16/1000 [49:28<49:32:35, 181.26s/it, lr=0.001, test_acc=66.4, time=181, train_acc=69.5, train_loss=0.833, val_acc=66.5, val_loss=0.945]Epoch 16:   2%|▏         | 16/1000 [52:29<49:32:35, 181.26s/it, lr=0.001, test_acc=61.3, time=181, train_acc=69.3, train_loss=0.844, val_acc=60.9, val_loss=1.13] Epoch 16:   2%|▏         | 17/1000 [52:29<49:28:17, 181.18s/it, lr=0.001, test_acc=61.3, time=181, train_acc=69.3, train_loss=0.844, val_acc=60.9, val_loss=1.13]Epoch 17:   2%|▏         | 17/1000 [52:29<49:28:17, 181.18s/it, lr=0.001, test_acc=61.3, time=181, train_acc=69.3, train_loss=0.844, val_acc=60.9, val_loss=1.13]Epoch 17:   2%|▏         | 17/1000 [55:30<49:28:17, 181.18s/it, lr=0.001, test_acc=67.9, time=181, train_acc=69.2, train_loss=0.843, val_acc=67.7, val_loss=0.898]Epoch 17:   2%|▏         | 18/1000 [55:30<49:24:26, 181.13s/it, lr=0.001, test_acc=67.9, time=181, train_acc=69.2, train_loss=0.843, val_acc=67.7, val_loss=0.898]Epoch 18:   2%|▏         | 18/1000 [55:30<49:24:26, 181.13s/it, lr=0.001, test_acc=67.9, time=181, train_acc=69.2, train_loss=0.843, val_acc=67.7, val_loss=0.898]Epoch 18:   2%|▏         | 18/1000 [58:31<49:24:26, 181.13s/it, lr=0.001, test_acc=67.4, time=181, train_acc=69.9, train_loss=0.823, val_acc=66.9, val_loss=0.909]Epoch 18:   2%|▏         | 19/1000 [58:31<49:21:05, 181.11s/it, lr=0.001, test_acc=67.4, time=181, train_acc=69.9, train_loss=0.823, val_acc=66.9, val_loss=0.909]Epoch 19:   2%|▏         | 19/1000 [58:31<49:21:05, 181.11s/it, lr=0.001, test_acc=67.4, time=181, train_acc=69.9, train_loss=0.823, val_acc=66.9, val_loss=0.909]Epoch 19:   2%|▏         | 19/1000 [1:01:32<49:21:05, 181.11s/it, lr=0.001, test_acc=67.7, time=181, train_acc=69.4, train_loss=0.84, val_acc=67.6, val_loss=0.904]Epoch 19:   2%|▏         | 20/1000 [1:01:32<49:19:28, 181.19s/it, lr=0.001, test_acc=67.7, time=181, train_acc=69.4, train_loss=0.84, val_acc=67.6, val_loss=0.904]Epoch 20:   2%|▏         | 20/1000 [1:01:32<49:19:28, 181.19s/it, lr=0.001, test_acc=67.7, time=181, train_acc=69.4, train_loss=0.84, val_acc=67.6, val_loss=0.904]Epoch 20:   2%|▏         | 20/1000 [1:04:34<49:19:28, 181.19s/it, lr=0.001, test_acc=66, time=182, train_acc=69.9, train_loss=0.823, val_acc=66, val_loss=0.974]   Epoch 20:   2%|▏         | 21/1000 [1:04:34<49:19:04, 181.35s/it, lr=0.001, test_acc=66, time=182, train_acc=69.9, train_loss=0.823, val_acc=66, val_loss=0.974]Epoch 21:   2%|▏         | 21/1000 [1:04:34<49:19:04, 181.35s/it, lr=0.001, test_acc=66, time=182, train_acc=69.9, train_loss=0.823, val_acc=66, val_loss=0.974]Epoch 21:   2%|▏         | 21/1000 [1:07:36<49:19:04, 181.35s/it, lr=0.001, test_acc=67.3, time=182, train_acc=70, train_loss=0.821, val_acc=66.9, val_loss=0.897]Epoch 21:   2%|▏         | 22/1000 [1:07:36<49:17:43, 181.46s/it, lr=0.001, test_acc=67.3, time=182, train_acc=70, train_loss=0.821, val_acc=66.9, val_loss=0.897]Epoch 22:   2%|▏         | 22/1000 [1:07:36<49:17:43, 181.46s/it, lr=0.001, test_acc=67.3, time=182, train_acc=70, train_loss=0.821, val_acc=66.9, val_loss=0.897]Epoch 22:   2%|▏         | 22/1000 [1:10:37<49:17:43, 181.46s/it, lr=0.001, test_acc=68.5, time=181, train_acc=70.4, train_loss=0.81, val_acc=67.9, val_loss=0.879]Epoch 22:   2%|▏         | 23/1000 [1:10:37<49:15:02, 181.48s/it, lr=0.001, test_acc=68.5, time=181, train_acc=70.4, train_loss=0.81, val_acc=67.9, val_loss=0.879]Epoch 23:   2%|▏         | 23/1000 [1:10:37<49:15:02, 181.48s/it, lr=0.001, test_acc=68.5, time=181, train_acc=70.4, train_loss=0.81, val_acc=67.9, val_loss=0.879]Epoch 23:   2%|▏         | 23/1000 [1:13:39<49:15:02, 181.48s/it, lr=0.001, test_acc=68.3, time=182, train_acc=70.7, train_loss=0.802, val_acc=67.8, val_loss=0.914]Epoch 23:   2%|▏         | 24/1000 [1:13:39<49:12:42, 181.52s/it, lr=0.001, test_acc=68.3, time=182, train_acc=70.7, train_loss=0.802, val_acc=67.8, val_loss=0.914]Epoch 24:   2%|▏         | 24/1000 [1:13:39<49:12:42, 181.52s/it, lr=0.001, test_acc=68.3, time=182, train_acc=70.7, train_loss=0.802, val_acc=67.8, val_loss=0.914]Epoch 24:   2%|▏         | 24/1000 [1:16:41<49:12:42, 181.52s/it, lr=0.001, test_acc=66.6, time=182, train_acc=70.9, train_loss=0.796, val_acc=66.4, val_loss=0.907]Epoch 24:   2%|▎         | 25/1000 [1:16:41<49:10:27, 181.57s/it, lr=0.001, test_acc=66.6, time=182, train_acc=70.9, train_loss=0.796, val_acc=66.4, val_loss=0.907]Epoch 25:   2%|▎         | 25/1000 [1:16:41<49:10:27, 181.57s/it, lr=0.001, test_acc=66.6, time=182, train_acc=70.9, train_loss=0.796, val_acc=66.4, val_loss=0.907]Epoch 25:   2%|▎         | 25/1000 [1:19:42<49:10:27, 181.57s/it, lr=0.001, test_acc=68.6, time=182, train_acc=71, train_loss=0.793, val_acc=68.1, val_loss=0.891]  Epoch 25:   3%|▎         | 26/1000 [1:19:42<49:07:09, 181.55s/it, lr=0.001, test_acc=68.6, time=182, train_acc=71, train_loss=0.793, val_acc=68.1, val_loss=0.891]Epoch 26:   3%|▎         | 26/1000 [1:19:42<49:07:09, 181.55s/it, lr=0.001, test_acc=68.6, time=182, train_acc=71, train_loss=0.793, val_acc=68.1, val_loss=0.891]Epoch 26:   3%|▎         | 26/1000 [1:22:44<49:07:09, 181.55s/it, lr=0.001, test_acc=67.9, time=182, train_acc=70.9, train_loss=0.795, val_acc=67.5, val_loss=0.891]Epoch 26:   3%|▎         | 27/1000 [1:22:44<49:04:51, 181.59s/it, lr=0.001, test_acc=67.9, time=182, train_acc=70.9, train_loss=0.795, val_acc=67.5, val_loss=0.891]Epoch 27:   3%|▎         | 27/1000 [1:22:44<49:04:51, 181.59s/it, lr=0.001, test_acc=67.9, time=182, train_acc=70.9, train_loss=0.795, val_acc=67.5, val_loss=0.891]Epoch 27:   3%|▎         | 27/1000 [1:25:46<49:04:51, 181.59s/it, lr=0.001, test_acc=66.4, time=182, train_acc=71.1, train_loss=0.79, val_acc=66.2, val_loss=0.924] Epoch 27:   3%|▎         | 28/1000 [1:25:46<49:04:12, 181.74s/it, lr=0.001, test_acc=66.4, time=182, train_acc=71.1, train_loss=0.79, val_acc=66.2, val_loss=0.924]Epoch 28:   3%|▎         | 28/1000 [1:25:46<49:04:12, 181.74s/it, lr=0.001, test_acc=66.4, time=182, train_acc=71.1, train_loss=0.79, val_acc=66.2, val_loss=0.924]Epoch 28:   3%|▎         | 28/1000 [1:28:50<49:04:12, 181.74s/it, lr=0.001, test_acc=67.8, time=184, train_acc=71.2, train_loss=0.786, val_acc=67.3, val_loss=0.982]Epoch    29: reducing learning rate of group 0 to 5.0000e-04.
Epoch 28:   3%|▎         | 29/1000 [1:28:50<49:10:11, 182.30s/it, lr=0.001, test_acc=67.8, time=184, train_acc=71.2, train_loss=0.786, val_acc=67.3, val_loss=0.982]Epoch 29:   3%|▎         | 29/1000 [1:28:50<49:10:11, 182.30s/it, lr=0.001, test_acc=67.8, time=184, train_acc=71.2, train_loss=0.786, val_acc=67.3, val_loss=0.982]Epoch 29:   3%|▎         | 29/1000 [1:31:51<49:10:11, 182.30s/it, lr=0.0005, test_acc=69.5, time=182, train_acc=71.9, train_loss=0.769, val_acc=69.1, val_loss=0.879]Epoch 29:   3%|▎         | 30/1000 [1:31:51<49:04:47, 182.15s/it, lr=0.0005, test_acc=69.5, time=182, train_acc=71.9, train_loss=0.769, val_acc=69.1, val_loss=0.879]Epoch 30:   3%|▎         | 30/1000 [1:31:51<49:04:47, 182.15s/it, lr=0.0005, test_acc=69.5, time=182, train_acc=71.9, train_loss=0.769, val_acc=69.1, val_loss=0.879]Epoch 30:   3%|▎         | 30/1000 [1:34:53<49:04:47, 182.15s/it, lr=0.0005, test_acc=69.4, time=182, train_acc=72.1, train_loss=0.764, val_acc=69.2, val_loss=0.845]Epoch 30:   3%|▎         | 31/1000 [1:34:53<49:01:22, 182.13s/it, lr=0.0005, test_acc=69.4, time=182, train_acc=72.1, train_loss=0.764, val_acc=69.2, val_loss=0.845]Epoch 31:   3%|▎         | 31/1000 [1:34:53<49:01:22, 182.13s/it, lr=0.0005, test_acc=69.4, time=182, train_acc=72.1, train_loss=0.764, val_acc=69.2, val_loss=0.845]Epoch 31:   3%|▎         | 31/1000 [1:37:55<49:01:22, 182.13s/it, lr=0.0005, test_acc=69.8, time=182, train_acc=72.1, train_loss=0.764, val_acc=69.4, val_loss=0.837]Epoch 31:   3%|▎         | 32/1000 [1:37:55<48:56:38, 182.02s/it, lr=0.0005, test_acc=69.8, time=182, train_acc=72.1, train_loss=0.764, val_acc=69.4, val_loss=0.837]Epoch 32:   3%|▎         | 32/1000 [1:37:55<48:56:38, 182.02s/it, lr=0.0005, test_acc=69.8, time=182, train_acc=72.1, train_loss=0.764, val_acc=69.4, val_loss=0.837]Epoch 32:   3%|▎         | 32/1000 [1:40:57<48:56:38, 182.02s/it, lr=0.0005, test_acc=69.1, time=182, train_acc=72.2, train_loss=0.762, val_acc=68.8, val_loss=0.871]Epoch 32:   3%|▎         | 33/1000 [1:40:57<48:52:10, 181.93s/it, lr=0.0005, test_acc=69.1, time=182, train_acc=72.2, train_loss=0.762, val_acc=68.8, val_loss=0.871]Epoch 33:   3%|▎         | 33/1000 [1:40:57<48:52:10, 181.93s/it, lr=0.0005, test_acc=69.1, time=182, train_acc=72.2, train_loss=0.762, val_acc=68.8, val_loss=0.871]Epoch 33:   3%|▎         | 33/1000 [1:43:59<48:52:10, 181.93s/it, lr=0.0005, test_acc=68.9, time=182, train_acc=72.3, train_loss=0.76, val_acc=68.4, val_loss=0.862] Epoch 33:   3%|▎         | 34/1000 [1:43:59<48:48:23, 181.89s/it, lr=0.0005, test_acc=68.9, time=182, train_acc=72.3, train_loss=0.76, val_acc=68.4, val_loss=0.862]Epoch 34:   3%|▎         | 34/1000 [1:43:59<48:48:23, 181.89s/it, lr=0.0005, test_acc=68.9, time=182, train_acc=72.3, train_loss=0.76, val_acc=68.4, val_loss=0.862]Epoch 34:   3%|▎         | 34/1000 [1:47:01<48:48:23, 181.89s/it, lr=0.0005, test_acc=69.3, time=182, train_acc=72.2, train_loss=0.76, val_acc=68.7, val_loss=0.851]Epoch 34:   4%|▎         | 35/1000 [1:47:01<48:45:15, 181.88s/it, lr=0.0005, test_acc=69.3, time=182, train_acc=72.2, train_loss=0.76, val_acc=68.7, val_loss=0.851]Epoch 35:   4%|▎         | 35/1000 [1:47:01<48:45:15, 181.88s/it, lr=0.0005, test_acc=69.3, time=182, train_acc=72.2, train_loss=0.76, val_acc=68.7, val_loss=0.851]Epoch 35:   4%|▎         | 35/1000 [1:50:03<48:45:15, 181.88s/it, lr=0.0005, test_acc=69.2, time=182, train_acc=72.3, train_loss=0.758, val_acc=68.7, val_loss=0.865]Epoch 35:   4%|▎         | 36/1000 [1:50:03<48:44:29, 182.02s/it, lr=0.0005, test_acc=69.2, time=182, train_acc=72.3, train_loss=0.758, val_acc=68.7, val_loss=0.865]Epoch 36:   4%|▎         | 36/1000 [1:50:03<48:44:29, 182.02s/it, lr=0.0005, test_acc=69.2, time=182, train_acc=72.3, train_loss=0.758, val_acc=68.7, val_loss=0.865]Epoch 36:   4%|▎         | 36/1000 [1:53:05<48:44:29, 182.02s/it, lr=0.0005, test_acc=68.2, time=182, train_acc=72.4, train_loss=0.757, val_acc=68, val_loss=0.891]  Epoch 36:   4%|▎         | 37/1000 [1:53:05<48:40:26, 181.96s/it, lr=0.0005, test_acc=68.2, time=182, train_acc=72.4, train_loss=0.757, val_acc=68, val_loss=0.891]Epoch 37:   4%|▎         | 37/1000 [1:53:05<48:40:26, 181.96s/it, lr=0.0005, test_acc=68.2, time=182, train_acc=72.4, train_loss=0.757, val_acc=68, val_loss=0.891]Epoch 37:   4%|▎         | 37/1000 [1:56:06<48:40:26, 181.96s/it, lr=0.0005, test_acc=69, time=182, train_acc=72.3, train_loss=0.757, val_acc=68.9, val_loss=0.915]Epoch    38: reducing learning rate of group 0 to 2.5000e-04.
Epoch 37:   4%|▍         | 38/1000 [1:56:06<48:35:34, 181.84s/it, lr=0.0005, test_acc=69, time=182, train_acc=72.3, train_loss=0.757, val_acc=68.9, val_loss=0.915]Epoch 38:   4%|▍         | 38/1000 [1:56:06<48:35:34, 181.84s/it, lr=0.0005, test_acc=69, time=182, train_acc=72.3, train_loss=0.757, val_acc=68.9, val_loss=0.915]Epoch 38:   4%|▍         | 38/1000 [1:59:08<48:35:34, 181.84s/it, lr=0.00025, test_acc=70, time=182, train_acc=72.8, train_loss=0.745, val_acc=69.8, val_loss=0.83]Epoch 38:   4%|▍         | 39/1000 [1:59:08<48:31:46, 181.80s/it, lr=0.00025, test_acc=70, time=182, train_acc=72.8, train_loss=0.745, val_acc=69.8, val_loss=0.83]Epoch 39:   4%|▍         | 39/1000 [1:59:08<48:31:46, 181.80s/it, lr=0.00025, test_acc=70, time=182, train_acc=72.8, train_loss=0.745, val_acc=69.8, val_loss=0.83]Epoch 39:   4%|▍         | 39/1000 [2:02:10<48:31:46, 181.80s/it, lr=0.00025, test_acc=69, time=182, train_acc=72.9, train_loss=0.741, val_acc=68.7, val_loss=0.856]Epoch 39:   4%|▍         | 40/1000 [2:02:10<48:28:07, 181.76s/it, lr=0.00025, test_acc=69, time=182, train_acc=72.9, train_loss=0.741, val_acc=68.7, val_loss=0.856]Epoch 40:   4%|▍         | 40/1000 [2:02:10<48:28:07, 181.76s/it, lr=0.00025, test_acc=69, time=182, train_acc=72.9, train_loss=0.741, val_acc=68.7, val_loss=0.856]Epoch 40:   4%|▍         | 40/1000 [2:05:11<48:28:07, 181.76s/it, lr=0.00025, test_acc=70, time=182, train_acc=73, train_loss=0.741, val_acc=69.7, val_loss=0.828]  Epoch 40:   4%|▍         | 41/1000 [2:05:11<48:25:06, 181.76s/it, lr=0.00025, test_acc=70, time=182, train_acc=73, train_loss=0.741, val_acc=69.7, val_loss=0.828]Epoch 41:   4%|▍         | 41/1000 [2:05:11<48:25:06, 181.76s/it, lr=0.00025, test_acc=70, time=182, train_acc=73, train_loss=0.741, val_acc=69.7, val_loss=0.828]Epoch 41:   4%|▍         | 41/1000 [2:08:14<48:25:06, 181.76s/it, lr=0.00025, test_acc=70, time=182, train_acc=73, train_loss=0.738, val_acc=69.7, val_loss=0.829]Epoch 41:   4%|▍         | 42/1000 [2:08:14<48:23:45, 181.86s/it, lr=0.00025, test_acc=70, time=182, train_acc=73, train_loss=0.738, val_acc=69.7, val_loss=0.829]Epoch 42:   4%|▍         | 42/1000 [2:08:14<48:23:45, 181.86s/it, lr=0.00025, test_acc=70, time=182, train_acc=73, train_loss=0.738, val_acc=69.7, val_loss=0.829]Epoch 42:   4%|▍         | 42/1000 [2:11:15<48:23:45, 181.86s/it, lr=0.00025, test_acc=70, time=182, train_acc=73, train_loss=0.739, val_acc=69.6, val_loss=0.832]Epoch 42:   4%|▍         | 43/1000 [2:11:15<48:19:46, 181.80s/it, lr=0.00025, test_acc=70, time=182, train_acc=73, train_loss=0.739, val_acc=69.6, val_loss=0.832]Epoch 43:   4%|▍         | 43/1000 [2:11:15<48:19:46, 181.80s/it, lr=0.00025, test_acc=70, time=182, train_acc=73, train_loss=0.739, val_acc=69.6, val_loss=0.832]Epoch 43:   4%|▍         | 43/1000 [2:14:17<48:19:46, 181.80s/it, lr=0.00025, test_acc=69.7, time=182, train_acc=73, train_loss=0.74, val_acc=69.3, val_loss=0.858]Epoch 43:   4%|▍         | 44/1000 [2:14:17<48:15:56, 181.75s/it, lr=0.00025, test_acc=69.7, time=182, train_acc=73, train_loss=0.74, val_acc=69.3, val_loss=0.858]Epoch 44:   4%|▍         | 44/1000 [2:14:17<48:15:56, 181.75s/it, lr=0.00025, test_acc=69.7, time=182, train_acc=73, train_loss=0.74, val_acc=69.3, val_loss=0.858]Epoch 44:   4%|▍         | 44/1000 [2:17:19<48:15:56, 181.75s/it, lr=0.00025, test_acc=70, time=182, train_acc=72.8, train_loss=0.746, val_acc=69.8, val_loss=0.863]Epoch 44:   4%|▍         | 45/1000 [2:17:19<48:13:09, 181.77s/it, lr=0.00025, test_acc=70, time=182, train_acc=72.8, train_loss=0.746, val_acc=69.8, val_loss=0.863]Epoch 45:   4%|▍         | 45/1000 [2:17:19<48:13:09, 181.77s/it, lr=0.00025, test_acc=70, time=182, train_acc=72.8, train_loss=0.746, val_acc=69.8, val_loss=0.863]Epoch 45:   4%|▍         | 45/1000 [2:20:20<48:13:09, 181.77s/it, lr=0.00025, test_acc=69.6, time=181, train_acc=73.1, train_loss=0.737, val_acc=69.5, val_loss=0.835]Epoch 45:   5%|▍         | 46/1000 [2:20:20<48:06:02, 181.51s/it, lr=0.00025, test_acc=69.6, time=181, train_acc=73.1, train_loss=0.737, val_acc=69.5, val_loss=0.835]Epoch 46:   5%|▍         | 46/1000 [2:20:20<48:06:02, 181.51s/it, lr=0.00025, test_acc=69.6, time=181, train_acc=73.1, train_loss=0.737, val_acc=69.5, val_loss=0.835]Epoch 46:   5%|▍         | 46/1000 [2:23:19<48:06:02, 181.51s/it, lr=0.00025, test_acc=69.5, time=179, train_acc=73.2, train_loss=0.735, val_acc=69, val_loss=0.849]  Epoch    47: reducing learning rate of group 0 to 1.2500e-04.
Epoch 46:   5%|▍         | 47/1000 [2:23:19<47:50:50, 180.75s/it, lr=0.00025, test_acc=69.5, time=179, train_acc=73.2, train_loss=0.735, val_acc=69, val_loss=0.849]Epoch 47:   5%|▍         | 47/1000 [2:23:19<47:50:50, 180.75s/it, lr=0.00025, test_acc=69.5, time=179, train_acc=73.2, train_loss=0.735, val_acc=69, val_loss=0.849]Epoch 47:   5%|▍         | 47/1000 [2:26:16<47:50:50, 180.75s/it, lr=0.000125, test_acc=70.3, time=177, train_acc=73.4, train_loss=0.731, val_acc=70, val_loss=0.823]Epoch 47:   5%|▍         | 48/1000 [2:26:16<47:31:48, 179.74s/it, lr=0.000125, test_acc=70.3, time=177, train_acc=73.4, train_loss=0.731, val_acc=70, val_loss=0.823]Epoch 48:   5%|▍         | 48/1000 [2:26:16<47:31:48, 179.74s/it, lr=0.000125, test_acc=70.3, time=177, train_acc=73.4, train_loss=0.731, val_acc=70, val_loss=0.823]Epoch 48:   5%|▍         | 48/1000 [2:29:12<47:31:48, 179.74s/it, lr=0.000125, test_acc=70.1, time=176, train_acc=73.4, train_loss=0.73, val_acc=69.8, val_loss=0.826]Epoch 48:   5%|▍         | 49/1000 [2:29:12<47:09:34, 178.52s/it, lr=0.000125, test_acc=70.1, time=176, train_acc=73.4, train_loss=0.73, val_acc=69.8, val_loss=0.826]Epoch 49:   5%|▍         | 49/1000 [2:29:12<47:09:34, 178.52s/it, lr=0.000125, test_acc=70.1, time=176, train_acc=73.4, train_loss=0.73, val_acc=69.8, val_loss=0.826]Epoch 49:   5%|▍         | 49/1000 [2:32:05<47:09:34, 178.52s/it, lr=0.000125, test_acc=70, time=174, train_acc=73.5, train_loss=0.726, val_acc=69.8, val_loss=0.827] Epoch 49:   5%|▌         | 50/1000 [2:32:05<46:44:18, 177.11s/it, lr=0.000125, test_acc=70, time=174, train_acc=73.5, train_loss=0.726, val_acc=69.8, val_loss=0.827]Epoch 50:   5%|▌         | 50/1000 [2:32:05<46:44:18, 177.11s/it, lr=0.000125, test_acc=70, time=174, train_acc=73.5, train_loss=0.726, val_acc=69.8, val_loss=0.827]Epoch 50:   5%|▌         | 50/1000 [2:34:58<46:44:18, 177.11s/it, lr=0.000125, test_acc=70.4, time=172, train_acc=73.4, train_loss=0.728, val_acc=70, val_loss=0.836]Epoch 50:   5%|▌         | 51/1000 [2:34:58<46:17:21, 175.60s/it, lr=0.000125, test_acc=70.4, time=172, train_acc=73.4, train_loss=0.728, val_acc=70, val_loss=0.836]Epoch 51:   5%|▌         | 51/1000 [2:34:58<46:17:21, 175.60s/it, lr=0.000125, test_acc=70.4, time=172, train_acc=73.4, train_loss=0.728, val_acc=70, val_loss=0.836]Epoch 51:   5%|▌         | 51/1000 [2:37:48<46:17:21, 175.60s/it, lr=0.000125, test_acc=70, time=171, train_acc=73.5, train_loss=0.727, val_acc=69.7, val_loss=0.827]Epoch 51:   5%|▌         | 52/1000 [2:37:48<45:50:46, 174.10s/it, lr=0.000125, test_acc=70, time=171, train_acc=73.5, train_loss=0.727, val_acc=69.7, val_loss=0.827]Epoch 52:   5%|▌         | 52/1000 [2:37:48<45:50:46, 174.10s/it, lr=0.000125, test_acc=70, time=171, train_acc=73.5, train_loss=0.727, val_acc=69.7, val_loss=0.827]Epoch 52:   5%|▌         | 52/1000 [2:40:37<45:50:46, 174.10s/it, lr=0.000125, test_acc=70.1, time=169, train_acc=73.4, train_loss=0.728, val_acc=69.8, val_loss=0.842]Epoch 52:   5%|▌         | 53/1000 [2:40:37<45:22:27, 172.49s/it, lr=0.000125, test_acc=70.1, time=169, train_acc=73.4, train_loss=0.728, val_acc=69.8, val_loss=0.842]Epoch 53:   5%|▌         | 53/1000 [2:40:37<45:22:27, 172.49s/it, lr=0.000125, test_acc=70.1, time=169, train_acc=73.4, train_loss=0.728, val_acc=69.8, val_loss=0.842]Epoch 53:   5%|▌         | 53/1000 [2:43:24<45:22:27, 172.49s/it, lr=0.000125, test_acc=70.1, time=167, train_acc=73.5, train_loss=0.726, val_acc=69.9, val_loss=0.824]Epoch    54: reducing learning rate of group 0 to 6.2500e-05.
Epoch 53:   5%|▌         | 54/1000 [2:43:24<44:52:54, 170.80s/it, lr=0.000125, test_acc=70.1, time=167, train_acc=73.5, train_loss=0.726, val_acc=69.9, val_loss=0.824]Epoch 54:   5%|▌         | 54/1000 [2:43:24<44:52:54, 170.80s/it, lr=0.000125, test_acc=70.1, time=167, train_acc=73.5, train_loss=0.726, val_acc=69.9, val_loss=0.824]Epoch 54:   5%|▌         | 54/1000 [2:46:08<44:52:54, 170.80s/it, lr=6.25e-5, test_acc=70.4, time=165, train_acc=73.7, train_loss=0.721, val_acc=70.1, val_loss=0.818] Epoch 54:   6%|▌         | 55/1000 [2:46:08<44:21:20, 168.97s/it, lr=6.25e-5, test_acc=70.4, time=165, train_acc=73.7, train_loss=0.721, val_acc=70.1, val_loss=0.818]Epoch 55:   6%|▌         | 55/1000 [2:46:08<44:21:20, 168.97s/it, lr=6.25e-5, test_acc=70.4, time=165, train_acc=73.7, train_loss=0.721, val_acc=70.1, val_loss=0.818]Epoch 55:   6%|▌         | 55/1000 [2:48:50<44:21:20, 168.97s/it, lr=6.25e-5, test_acc=70.4, time=162, train_acc=73.7, train_loss=0.721, val_acc=70.2, val_loss=0.818]Epoch 55:   6%|▌         | 56/1000 [2:48:50<43:44:07, 166.79s/it, lr=6.25e-5, test_acc=70.4, time=162, train_acc=73.7, train_loss=0.721, val_acc=70.2, val_loss=0.818]Epoch 56:   6%|▌         | 56/1000 [2:48:50<43:44:07, 166.79s/it, lr=6.25e-5, test_acc=70.4, time=162, train_acc=73.7, train_loss=0.721, val_acc=70.2, val_loss=0.818]Epoch 56:   6%|▌         | 56/1000 [2:51:31<43:44:07, 166.79s/it, lr=6.25e-5, test_acc=70.4, time=161, train_acc=73.7, train_loss=0.721, val_acc=70.1, val_loss=0.821]Epoch 56:   6%|▌         | 57/1000 [2:51:31<43:14:50, 165.10s/it, lr=6.25e-5, test_acc=70.4, time=161, train_acc=73.7, train_loss=0.721, val_acc=70.1, val_loss=0.821]Epoch 57:   6%|▌         | 57/1000 [2:51:31<43:14:50, 165.10s/it, lr=6.25e-5, test_acc=70.4, time=161, train_acc=73.7, train_loss=0.721, val_acc=70.1, val_loss=0.821]Epoch 57:   6%|▌         | 57/1000 [2:54:12<43:14:50, 165.10s/it, lr=6.25e-5, test_acc=70.5, time=161, train_acc=73.7, train_loss=0.72, val_acc=70.3, val_loss=0.823] Epoch 57:   6%|▌         | 58/1000 [2:54:12<42:53:40, 163.93s/it, lr=6.25e-5, test_acc=70.5, time=161, train_acc=73.7, train_loss=0.72, val_acc=70.3, val_loss=0.823]Epoch 58:   6%|▌         | 58/1000 [2:54:12<42:53:40, 163.93s/it, lr=6.25e-5, test_acc=70.5, time=161, train_acc=73.7, train_loss=0.72, val_acc=70.3, val_loss=0.823]Epoch 58:   6%|▌         | 58/1000 [2:56:53<42:53:40, 163.93s/it, lr=6.25e-5, test_acc=70.5, time=161, train_acc=73.7, train_loss=0.719, val_acc=70.2, val_loss=0.831]Epoch 58:   6%|▌         | 59/1000 [2:56:53<42:35:10, 162.92s/it, lr=6.25e-5, test_acc=70.5, time=161, train_acc=73.7, train_loss=0.719, val_acc=70.2, val_loss=0.831]Epoch 59:   6%|▌         | 59/1000 [2:56:53<42:35:10, 162.92s/it, lr=6.25e-5, test_acc=70.5, time=161, train_acc=73.7, train_loss=0.719, val_acc=70.2, val_loss=0.831]Epoch 59:   6%|▌         | 59/1000 [2:59:33<42:35:10, 162.92s/it, lr=6.25e-5, test_acc=70.5, time=160, train_acc=73.8, train_loss=0.719, val_acc=70.1, val_loss=0.821]Epoch 59:   6%|▌         | 60/1000 [2:59:33<42:20:33, 162.16s/it, lr=6.25e-5, test_acc=70.5, time=160, train_acc=73.8, train_loss=0.719, val_acc=70.1, val_loss=0.821]Epoch 60:   6%|▌         | 60/1000 [2:59:33<42:20:33, 162.16s/it, lr=6.25e-5, test_acc=70.5, time=160, train_acc=73.8, train_loss=0.719, val_acc=70.1, val_loss=0.821]Epoch 60:   6%|▌         | 60/1000 [3:02:14<42:20:33, 162.16s/it, lr=6.25e-5, test_acc=70.2, time=160, train_acc=73.8, train_loss=0.718, val_acc=69.9, val_loss=0.827]Epoch    61: reducing learning rate of group 0 to 3.1250e-05.
Epoch 60:   6%|▌         | 61/1000 [3:02:14<42:09:21, 161.62s/it, lr=6.25e-5, test_acc=70.2, time=160, train_acc=73.8, train_loss=0.718, val_acc=69.9, val_loss=0.827]Epoch 61:   6%|▌         | 61/1000 [3:02:14<42:09:21, 161.62s/it, lr=6.25e-5, test_acc=70.2, time=160, train_acc=73.8, train_loss=0.718, val_acc=69.9, val_loss=0.827]Epoch 61:   6%|▌         | 61/1000 [3:04:54<42:09:21, 161.62s/it, lr=3.13e-5, test_acc=70.3, time=160, train_acc=73.8, train_loss=0.717, val_acc=70.1, val_loss=0.819]Epoch 61:   6%|▌         | 62/1000 [3:04:54<42:00:57, 161.26s/it, lr=3.13e-5, test_acc=70.3, time=160, train_acc=73.8, train_loss=0.717, val_acc=70.1, val_loss=0.819]Epoch 62:   6%|▌         | 62/1000 [3:04:54<42:00:57, 161.26s/it, lr=3.13e-5, test_acc=70.3, time=160, train_acc=73.8, train_loss=0.717, val_acc=70.1, val_loss=0.819]Epoch 62:   6%|▌         | 62/1000 [3:07:35<42:00:57, 161.26s/it, lr=3.13e-5, test_acc=70.5, time=160, train_acc=73.8, train_loss=0.718, val_acc=70.2, val_loss=0.816]Epoch 62:   6%|▋         | 63/1000 [3:07:35<41:54:29, 161.01s/it, lr=3.13e-5, test_acc=70.5, time=160, train_acc=73.8, train_loss=0.718, val_acc=70.2, val_loss=0.816]Epoch 63:   6%|▋         | 63/1000 [3:07:35<41:54:29, 161.01s/it, lr=3.13e-5, test_acc=70.5, time=160, train_acc=73.8, train_loss=0.718, val_acc=70.2, val_loss=0.816]Epoch 63:   6%|▋         | 63/1000 [3:10:15<41:54:29, 161.01s/it, lr=3.13e-5, test_acc=70.6, time=160, train_acc=73.8, train_loss=0.717, val_acc=70.3, val_loss=0.823]Epoch 63:   6%|▋         | 64/1000 [3:10:15<41:48:40, 160.81s/it, lr=3.13e-5, test_acc=70.6, time=160, train_acc=73.8, train_loss=0.717, val_acc=70.3, val_loss=0.823]Epoch 64:   6%|▋         | 64/1000 [3:10:15<41:48:40, 160.81s/it, lr=3.13e-5, test_acc=70.6, time=160, train_acc=73.8, train_loss=0.717, val_acc=70.3, val_loss=0.823]Epoch 64:   6%|▋         | 64/1000 [3:12:55<41:48:40, 160.81s/it, lr=3.13e-5, test_acc=70.4, time=160, train_acc=73.8, train_loss=0.717, val_acc=70.1, val_loss=0.82] Epoch 64:   6%|▋         | 65/1000 [3:12:55<41:43:33, 160.66s/it, lr=3.13e-5, test_acc=70.4, time=160, train_acc=73.8, train_loss=0.717, val_acc=70.1, val_loss=0.82]Epoch 65:   6%|▋         | 65/1000 [3:12:55<41:43:33, 160.66s/it, lr=3.13e-5, test_acc=70.4, time=160, train_acc=73.8, train_loss=0.717, val_acc=70.1, val_loss=0.82]Epoch 65:   6%|▋         | 65/1000 [3:15:36<41:43:33, 160.66s/it, lr=3.13e-5, test_acc=70.5, time=160, train_acc=73.8, train_loss=0.716, val_acc=70.1, val_loss=0.819]Epoch 65:   7%|▋         | 66/1000 [3:15:36<41:39:59, 160.60s/it, lr=3.13e-5, test_acc=70.5, time=160, train_acc=73.8, train_loss=0.716, val_acc=70.1, val_loss=0.819]Epoch 66:   7%|▋         | 66/1000 [3:15:36<41:39:59, 160.60s/it, lr=3.13e-5, test_acc=70.5, time=160, train_acc=73.8, train_loss=0.716, val_acc=70.1, val_loss=0.819]Epoch 66:   7%|▋         | 66/1000 [3:18:16<41:39:59, 160.60s/it, lr=3.13e-5, test_acc=70.4, time=160, train_acc=73.9, train_loss=0.716, val_acc=70.1, val_loss=0.818]Epoch 66:   7%|▋         | 67/1000 [3:18:16<41:36:51, 160.57s/it, lr=3.13e-5, test_acc=70.4, time=160, train_acc=73.9, train_loss=0.716, val_acc=70.1, val_loss=0.818]Epoch 67:   7%|▋         | 67/1000 [3:18:16<41:36:51, 160.57s/it, lr=3.13e-5, test_acc=70.4, time=160, train_acc=73.9, train_loss=0.716, val_acc=70.1, val_loss=0.818]Epoch 67:   7%|▋         | 67/1000 [3:20:57<41:36:51, 160.57s/it, lr=3.13e-5, test_acc=70.4, time=161, train_acc=73.9, train_loss=0.717, val_acc=70.1, val_loss=0.82] Epoch 67:   7%|▋         | 68/1000 [3:20:57<41:34:15, 160.57s/it, lr=3.13e-5, test_acc=70.4, time=161, train_acc=73.9, train_loss=0.717, val_acc=70.1, val_loss=0.82]Epoch 68:   7%|▋         | 68/1000 [3:20:57<41:34:15, 160.57s/it, lr=3.13e-5, test_acc=70.4, time=161, train_acc=73.9, train_loss=0.717, val_acc=70.1, val_loss=0.82]Epoch 68:   7%|▋         | 68/1000 [3:23:37<41:34:15, 160.57s/it, lr=3.13e-5, test_acc=70.4, time=160, train_acc=73.8, train_loss=0.718, val_acc=70.1, val_loss=0.818]Epoch    69: reducing learning rate of group 0 to 1.5625e-05.
Epoch 68:   7%|▋         | 69/1000 [3:23:37<41:31:05, 160.54s/it, lr=3.13e-5, test_acc=70.4, time=160, train_acc=73.8, train_loss=0.718, val_acc=70.1, val_loss=0.818]Epoch 69:   7%|▋         | 69/1000 [3:23:37<41:31:05, 160.54s/it, lr=3.13e-5, test_acc=70.4, time=160, train_acc=73.8, train_loss=0.718, val_acc=70.1, val_loss=0.818]Epoch 69:   7%|▋         | 69/1000 [3:26:18<41:31:05, 160.54s/it, lr=1.56e-5, test_acc=70.4, time=160, train_acc=73.9, train_loss=0.715, val_acc=70.2, val_loss=0.818]Epoch 69:   7%|▋         | 70/1000 [3:26:18<41:28:08, 160.53s/it, lr=1.56e-5, test_acc=70.4, time=160, train_acc=73.9, train_loss=0.715, val_acc=70.2, val_loss=0.818]Epoch 70:   7%|▋         | 70/1000 [3:26:18<41:28:08, 160.53s/it, lr=1.56e-5, test_acc=70.4, time=160, train_acc=73.9, train_loss=0.715, val_acc=70.2, val_loss=0.818]Epoch 70:   7%|▋         | 70/1000 [3:28:59<41:28:08, 160.53s/it, lr=1.56e-5, test_acc=70.6, time=161, train_acc=73.9, train_loss=0.716, val_acc=70.3, val_loss=0.822]Epoch 70:   7%|▋         | 71/1000 [3:28:59<41:26:58, 160.62s/it, lr=1.56e-5, test_acc=70.6, time=161, train_acc=73.9, train_loss=0.716, val_acc=70.3, val_loss=0.822]Epoch 71:   7%|▋         | 71/1000 [3:28:59<41:26:58, 160.62s/it, lr=1.56e-5, test_acc=70.6, time=161, train_acc=73.9, train_loss=0.716, val_acc=70.3, val_loss=0.822]Epoch 71:   7%|▋         | 71/1000 [3:31:38<41:26:58, 160.62s/it, lr=1.56e-5, test_acc=70.5, time=160, train_acc=73.9, train_loss=0.715, val_acc=70.2, val_loss=0.818]Epoch 71:   7%|▋         | 72/1000 [3:31:39<41:20:50, 160.40s/it, lr=1.56e-5, test_acc=70.5, time=160, train_acc=73.9, train_loss=0.715, val_acc=70.2, val_loss=0.818]Epoch 72:   7%|▋         | 72/1000 [3:31:39<41:20:50, 160.40s/it, lr=1.56e-5, test_acc=70.5, time=160, train_acc=73.9, train_loss=0.715, val_acc=70.2, val_loss=0.818]Epoch 72:   7%|▋         | 72/1000 [3:34:18<41:20:50, 160.40s/it, lr=1.56e-5, test_acc=70.5, time=159, train_acc=73.9, train_loss=0.716, val_acc=70.2, val_loss=0.821]Epoch 72:   7%|▋         | 73/1000 [3:34:18<41:11:55, 160.00s/it, lr=1.56e-5, test_acc=70.5, time=159, train_acc=73.9, train_loss=0.716, val_acc=70.2, val_loss=0.821]Epoch 73:   7%|▋         | 73/1000 [3:34:18<41:11:55, 160.00s/it, lr=1.56e-5, test_acc=70.5, time=159, train_acc=73.9, train_loss=0.716, val_acc=70.2, val_loss=0.821]Epoch 73:   7%|▋         | 73/1000 [3:36:57<41:11:55, 160.00s/it, lr=1.56e-5, test_acc=70.5, time=159, train_acc=73.9, train_loss=0.715, val_acc=70.2, val_loss=0.819]Epoch 73:   7%|▋         | 74/1000 [3:36:57<41:05:13, 159.73s/it, lr=1.56e-5, test_acc=70.5, time=159, train_acc=73.9, train_loss=0.715, val_acc=70.2, val_loss=0.819]Epoch 74:   7%|▋         | 74/1000 [3:36:57<41:05:13, 159.73s/it, lr=1.56e-5, test_acc=70.5, time=159, train_acc=73.9, train_loss=0.715, val_acc=70.2, val_loss=0.819]Epoch 74:   7%|▋         | 74/1000 [3:39:36<41:05:13, 159.73s/it, lr=1.56e-5, test_acc=70.5, time=159, train_acc=73.9, train_loss=0.715, val_acc=70.2, val_loss=0.82] Epoch    75: reducing learning rate of group 0 to 7.8125e-06.

!! LR SMALLER OR EQUAL TO MIN LR THRESHOLD.
Epoch 74:   7%|▋         | 74/1000 [3:39:36<45:48:03, 178.06s/it, lr=1.56e-5, test_acc=70.5, time=159, train_acc=73.9, train_loss=0.715, val_acc=70.2, val_loss=0.82]
Test Accuracy: 70.5212
Train Accuracy: 74.1621
Convergence Time (Epochs): 74.0000
TOTAL TIME TAKEN: 13293.1941s
AVG TIME PER EPOCH: 175.6691s
