I'm echoing to stdout
I'm echoing to stderr
My JobID is 55843679
I have 4 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.0378s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 3, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'parallel', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'num_eigs': 15, 'biases': True, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [01:08<?, ?it/s, lr=0.001, test_MAE=1.2, time=68, train_MAE=1.26, train_loss=1.26, val_MAE=1.12, val_loss=1.12]Epoch 0:   0%|          | 1/1000 [01:08<18:53:34, 68.08s/it, lr=0.001, test_MAE=1.2, time=68, train_MAE=1.26, train_loss=1.26, val_MAE=1.12, val_loss=1.12]Epoch 1:   0%|          | 1/1000 [01:08<18:53:34, 68.08s/it, lr=0.001, test_MAE=1.2, time=68, train_MAE=1.26, train_loss=1.26, val_MAE=1.12, val_loss=1.12]Epoch 1:   0%|          | 1/1000 [02:09<18:53:34, 68.08s/it, lr=0.001, test_MAE=1.09, time=61.1, train_MAE=1.09, train_loss=1.09, val_MAE=1, val_loss=1]   Epoch 1:   0%|          | 2/1000 [02:09<18:17:36, 65.99s/it, lr=0.001, test_MAE=1.09, time=61.1, train_MAE=1.09, train_loss=1.09, val_MAE=1, val_loss=1]Epoch 2:   0%|          | 2/1000 [02:09<18:17:36, 65.99s/it, lr=0.001, test_MAE=1.09, time=61.1, train_MAE=1.09, train_loss=1.09, val_MAE=1, val_loss=1]Epoch 2:   0%|          | 2/1000 [03:10<18:17:36, 65.99s/it, lr=0.001, test_MAE=1.04, time=61.5, train_MAE=1.01, train_loss=1.01, val_MAE=0.949, val_loss=0.949]Epoch 2:   0%|          | 3/1000 [03:10<17:54:41, 64.68s/it, lr=0.001, test_MAE=1.04, time=61.5, train_MAE=1.01, train_loss=1.01, val_MAE=0.949, val_loss=0.949]Epoch 3:   0%|          | 3/1000 [03:10<17:54:41, 64.68s/it, lr=0.001, test_MAE=1.04, time=61.5, train_MAE=1.01, train_loss=1.01, val_MAE=0.949, val_loss=0.949]Epoch 3:   0%|          | 3/1000 [04:12<17:54:41, 64.68s/it, lr=0.001, test_MAE=1.1, time=61.6, train_MAE=0.974, train_loss=0.974, val_MAE=1.02, val_loss=1.02] Epoch 3:   0%|          | 4/1000 [04:12<17:38:19, 63.75s/it, lr=0.001, test_MAE=1.1, time=61.6, train_MAE=0.974, train_loss=0.974, val_MAE=1.02, val_loss=1.02]Epoch 4:   0%|          | 4/1000 [04:12<17:38:19, 63.75s/it, lr=0.001, test_MAE=1.1, time=61.6, train_MAE=0.974, train_loss=0.974, val_MAE=1.02, val_loss=1.02]Epoch 4:   0%|          | 4/1000 [05:13<17:38:19, 63.75s/it, lr=0.001, test_MAE=0.962, time=61.1, train_MAE=0.951, train_loss=0.951, val_MAE=0.866, val_loss=0.866]Epoch 4:   0%|          | 5/1000 [05:13<17:24:20, 62.98s/it, lr=0.001, test_MAE=0.962, time=61.1, train_MAE=0.951, train_loss=0.951, val_MAE=0.866, val_loss=0.866]Epoch 5:   0%|          | 5/1000 [05:13<17:24:20, 62.98s/it, lr=0.001, test_MAE=0.962, time=61.1, train_MAE=0.951, train_loss=0.951, val_MAE=0.866, val_loss=0.866]Epoch 5:   0%|          | 5/1000 [06:15<17:24:20, 62.98s/it, lr=0.001, test_MAE=0.939, time=61.5, train_MAE=0.927, train_loss=0.927, val_MAE=0.846, val_loss=0.846]Epoch 5:   1%|          | 6/1000 [06:15<17:16:13, 62.55s/it, lr=0.001, test_MAE=0.939, time=61.5, train_MAE=0.927, train_loss=0.927, val_MAE=0.846, val_loss=0.846]Epoch 6:   1%|          | 6/1000 [06:15<17:16:13, 62.55s/it, lr=0.001, test_MAE=0.939, time=61.5, train_MAE=0.927, train_loss=0.927, val_MAE=0.846, val_loss=0.846]Epoch 6:   1%|          | 6/1000 [07:16<17:16:13, 62.55s/it, lr=0.001, test_MAE=0.931, time=61.7, train_MAE=0.918, train_loss=0.918, val_MAE=0.839, val_loss=0.839]Epoch 6:   1%|          | 7/1000 [07:16<17:10:57, 62.29s/it, lr=0.001, test_MAE=0.931, time=61.7, train_MAE=0.918, train_loss=0.918, val_MAE=0.839, val_loss=0.839]Epoch 7:   1%|          | 7/1000 [07:16<17:10:57, 62.29s/it, lr=0.001, test_MAE=0.931, time=61.7, train_MAE=0.918, train_loss=0.918, val_MAE=0.839, val_loss=0.839]Epoch 7:   1%|          | 7/1000 [08:18<17:10:57, 62.29s/it, lr=0.001, test_MAE=0.921, time=61.3, train_MAE=0.897, train_loss=0.897, val_MAE=0.828, val_loss=0.828]Epoch 7:   1%|          | 8/1000 [08:18<17:05:13, 62.01s/it, lr=0.001, test_MAE=0.921, time=61.3, train_MAE=0.897, train_loss=0.897, val_MAE=0.828, val_loss=0.828]Epoch 8:   1%|          | 8/1000 [08:18<17:05:13, 62.01s/it, lr=0.001, test_MAE=0.921, time=61.3, train_MAE=0.897, train_loss=0.897, val_MAE=0.828, val_loss=0.828]Epoch 8:   1%|          | 8/1000 [09:19<17:05:13, 62.01s/it, lr=0.001, test_MAE=0.909, time=61.3, train_MAE=0.862, train_loss=0.862, val_MAE=0.812, val_loss=0.812]Epoch 8:   1%|          | 9/1000 [09:19<17:00:46, 61.80s/it, lr=0.001, test_MAE=0.909, time=61.3, train_MAE=0.862, train_loss=0.862, val_MAE=0.812, val_loss=0.812]Epoch 9:   1%|          | 9/1000 [09:19<17:00:46, 61.80s/it, lr=0.001, test_MAE=0.909, time=61.3, train_MAE=0.862, train_loss=0.862, val_MAE=0.812, val_loss=0.812]Epoch 9:   1%|          | 9/1000 [10:21<17:00:46, 61.80s/it, lr=0.001, test_MAE=0.9, time=61.7, train_MAE=0.867, train_loss=0.867, val_MAE=0.809, val_loss=0.809]  Epoch 9:   1%|          | 10/1000 [10:21<16:59:27, 61.78s/it, lr=0.001, test_MAE=0.9, time=61.7, train_MAE=0.867, train_loss=0.867, val_MAE=0.809, val_loss=0.809]Epoch 10:   1%|          | 10/1000 [10:21<16:59:27, 61.78s/it, lr=0.001, test_MAE=0.9, time=61.7, train_MAE=0.867, train_loss=0.867, val_MAE=0.809, val_loss=0.809]Epoch 10:   1%|          | 10/1000 [11:22<16:59:27, 61.78s/it, lr=0.001, test_MAE=0.896, time=61.6, train_MAE=0.858, train_loss=0.858, val_MAE=0.789, val_loss=0.789]Epoch 10:   1%|          | 11/1000 [11:22<16:57:48, 61.75s/it, lr=0.001, test_MAE=0.896, time=61.6, train_MAE=0.858, train_loss=0.858, val_MAE=0.789, val_loss=0.789]Epoch 11:   1%|          | 11/1000 [11:22<16:57:48, 61.75s/it, lr=0.001, test_MAE=0.896, time=61.6, train_MAE=0.858, train_loss=0.858, val_MAE=0.789, val_loss=0.789]Epoch 11:   1%|          | 11/1000 [12:23<16:57:48, 61.75s/it, lr=0.001, test_MAE=0.886, time=61, train_MAE=0.853, train_loss=0.853, val_MAE=0.784, val_loss=0.784]  Epoch 11:   1%|          | 12/1000 [12:23<16:53:12, 61.53s/it, lr=0.001, test_MAE=0.886, time=61, train_MAE=0.853, train_loss=0.853, val_MAE=0.784, val_loss=0.784]Epoch 12:   1%|          | 12/1000 [12:23<16:53:12, 61.53s/it, lr=0.001, test_MAE=0.886, time=61, train_MAE=0.853, train_loss=0.853, val_MAE=0.784, val_loss=0.784]Epoch 12:   1%|          | 12/1000 [13:25<16:53:12, 61.53s/it, lr=0.001, test_MAE=0.879, time=61.3, train_MAE=0.821, train_loss=0.821, val_MAE=0.776, val_loss=0.776]Epoch 12:   1%|▏         | 13/1000 [13:25<16:51:06, 61.47s/it, lr=0.001, test_MAE=0.879, time=61.3, train_MAE=0.821, train_loss=0.821, val_MAE=0.776, val_loss=0.776]Epoch 13:   1%|▏         | 13/1000 [13:25<16:51:06, 61.47s/it, lr=0.001, test_MAE=0.879, time=61.3, train_MAE=0.821, train_loss=0.821, val_MAE=0.776, val_loss=0.776]Epoch 13:   1%|▏         | 13/1000 [14:27<16:51:06, 61.47s/it, lr=0.001, test_MAE=0.883, time=62, train_MAE=0.846, train_loss=0.846, val_MAE=0.783, val_loss=0.783]  Epoch 13:   1%|▏         | 14/1000 [14:27<16:52:39, 61.62s/it, lr=0.001, test_MAE=0.883, time=62, train_MAE=0.846, train_loss=0.846, val_MAE=0.783, val_loss=0.783]Epoch 14:   1%|▏         | 14/1000 [14:27<16:52:39, 61.62s/it, lr=0.001, test_MAE=0.883, time=62, train_MAE=0.846, train_loss=0.846, val_MAE=0.783, val_loss=0.783]Epoch 14:   1%|▏         | 14/1000 [15:26<16:52:39, 61.62s/it, lr=0.001, test_MAE=0.896, time=59.3, train_MAE=0.821, train_loss=0.821, val_MAE=0.798, val_loss=0.798]Epoch 14:   2%|▏         | 15/1000 [15:26<16:40:24, 60.94s/it, lr=0.001, test_MAE=0.896, time=59.3, train_MAE=0.821, train_loss=0.821, val_MAE=0.798, val_loss=0.798]Epoch 15:   2%|▏         | 15/1000 [15:26<16:40:24, 60.94s/it, lr=0.001, test_MAE=0.896, time=59.3, train_MAE=0.821, train_loss=0.821, val_MAE=0.798, val_loss=0.798]Epoch 15:   2%|▏         | 15/1000 [16:26<16:40:24, 60.94s/it, lr=0.001, test_MAE=0.891, time=59.5, train_MAE=0.824, train_loss=0.824, val_MAE=0.798, val_loss=0.798]Epoch 15:   2%|▏         | 16/1000 [16:26<16:32:13, 60.50s/it, lr=0.001, test_MAE=0.891, time=59.5, train_MAE=0.824, train_loss=0.824, val_MAE=0.798, val_loss=0.798]Epoch 16:   2%|▏         | 16/1000 [16:26<16:32:13, 60.50s/it, lr=0.001, test_MAE=0.891, time=59.5, train_MAE=0.824, train_loss=0.824, val_MAE=0.798, val_loss=0.798]Epoch 16:   2%|▏         | 16/1000 [17:24<16:32:13, 60.50s/it, lr=0.001, test_MAE=0.868, time=58.8, train_MAE=0.801, train_loss=0.801, val_MAE=0.768, val_loss=0.768]Epoch 16:   2%|▏         | 17/1000 [17:24<16:22:53, 59.99s/it, lr=0.001, test_MAE=0.868, time=58.8, train_MAE=0.801, train_loss=0.801, val_MAE=0.768, val_loss=0.768]Epoch 17:   2%|▏         | 17/1000 [17:24<16:22:53, 59.99s/it, lr=0.001, test_MAE=0.868, time=58.8, train_MAE=0.801, train_loss=0.801, val_MAE=0.768, val_loss=0.768]Epoch 17:   2%|▏         | 17/1000 [18:27<16:22:53, 59.99s/it, lr=0.001, test_MAE=0.877, time=63.2, train_MAE=0.789, train_loss=0.789, val_MAE=0.794, val_loss=0.794]Epoch 17:   2%|▏         | 18/1000 [18:28<16:37:40, 60.96s/it, lr=0.001, test_MAE=0.877, time=63.2, train_MAE=0.789, train_loss=0.789, val_MAE=0.794, val_loss=0.794]Epoch 18:   2%|▏         | 18/1000 [18:28<16:37:40, 60.96s/it, lr=0.001, test_MAE=0.877, time=63.2, train_MAE=0.789, train_loss=0.789, val_MAE=0.794, val_loss=0.794]Epoch 18:   2%|▏         | 18/1000 [19:31<16:37:40, 60.96s/it, lr=0.001, test_MAE=0.854, time=63.3, train_MAE=0.791, train_loss=0.791, val_MAE=0.76, val_loss=0.76]  Epoch 18:   2%|▏         | 19/1000 [19:31<16:48:28, 61.68s/it, lr=0.001, test_MAE=0.854, time=63.3, train_MAE=0.791, train_loss=0.791, val_MAE=0.76, val_loss=0.76]Epoch 19:   2%|▏         | 19/1000 [19:31<16:48:28, 61.68s/it, lr=0.001, test_MAE=0.854, time=63.3, train_MAE=0.791, train_loss=0.791, val_MAE=0.76, val_loss=0.76]Epoch 19:   2%|▏         | 19/1000 [20:34<16:48:28, 61.68s/it, lr=0.001, test_MAE=0.85, time=63.1, train_MAE=0.79, train_loss=0.79, val_MAE=0.748, val_loss=0.748] Epoch 19:   2%|▏         | 20/1000 [20:34<16:54:31, 62.11s/it, lr=0.001, test_MAE=0.85, time=63.1, train_MAE=0.79, train_loss=0.79, val_MAE=0.748, val_loss=0.748]Epoch 20:   2%|▏         | 20/1000 [20:34<16:54:31, 62.11s/it, lr=0.001, test_MAE=0.85, time=63.1, train_MAE=0.79, train_loss=0.79, val_MAE=0.748, val_loss=0.748]Epoch 20:   2%|▏         | 20/1000 [21:37<16:54:31, 62.11s/it, lr=0.001, test_MAE=0.851, time=63.2, train_MAE=0.768, train_loss=0.768, val_MAE=0.75, val_loss=0.75]Epoch 20:   2%|▏         | 21/1000 [21:37<16:59:17, 62.47s/it, lr=0.001, test_MAE=0.851, time=63.2, train_MAE=0.768, train_loss=0.768, val_MAE=0.75, val_loss=0.75]Epoch 21:   2%|▏         | 21/1000 [21:37<16:59:17, 62.47s/it, lr=0.001, test_MAE=0.851, time=63.2, train_MAE=0.768, train_loss=0.768, val_MAE=0.75, val_loss=0.75]Epoch 21:   2%|▏         | 21/1000 [22:41<16:59:17, 62.47s/it, lr=0.001, test_MAE=0.869, time=63.5, train_MAE=0.78, train_loss=0.78, val_MAE=0.791, val_loss=0.791]Epoch 21:   2%|▏         | 22/1000 [22:41<17:03:36, 62.80s/it, lr=0.001, test_MAE=0.869, time=63.5, train_MAE=0.78, train_loss=0.78, val_MAE=0.791, val_loss=0.791]Epoch 22:   2%|▏         | 22/1000 [22:41<17:03:36, 62.80s/it, lr=0.001, test_MAE=0.869, time=63.5, train_MAE=0.78, train_loss=0.78, val_MAE=0.791, val_loss=0.791]Epoch 22:   2%|▏         | 22/1000 [23:44<17:03:36, 62.80s/it, lr=0.001, test_MAE=0.846, time=63.1, train_MAE=0.777, train_loss=0.777, val_MAE=0.75, val_loss=0.75]Epoch 22:   2%|▏         | 23/1000 [23:44<17:04:28, 62.92s/it, lr=0.001, test_MAE=0.846, time=63.1, train_MAE=0.777, train_loss=0.777, val_MAE=0.75, val_loss=0.75]Epoch 23:   2%|▏         | 23/1000 [23:44<17:04:28, 62.92s/it, lr=0.001, test_MAE=0.846, time=63.1, train_MAE=0.777, train_loss=0.777, val_MAE=0.75, val_loss=0.75]Epoch 23:   2%|▏         | 23/1000 [24:47<17:04:28, 62.92s/it, lr=0.001, test_MAE=0.844, time=63, train_MAE=0.758, train_loss=0.758, val_MAE=0.758, val_loss=0.758]Epoch 23:   2%|▏         | 24/1000 [24:47<17:03:58, 62.95s/it, lr=0.001, test_MAE=0.844, time=63, train_MAE=0.758, train_loss=0.758, val_MAE=0.758, val_loss=0.758]Epoch 24:   2%|▏         | 24/1000 [24:47<17:03:58, 62.95s/it, lr=0.001, test_MAE=0.844, time=63, train_MAE=0.758, train_loss=0.758, val_MAE=0.758, val_loss=0.758]Epoch 24:   2%|▏         | 24/1000 [25:51<17:03:58, 62.95s/it, lr=0.001, test_MAE=0.834, time=63.7, train_MAE=0.755, train_loss=0.755, val_MAE=0.727, val_loss=0.727]Epoch 24:   2%|▎         | 25/1000 [25:51<17:06:49, 63.19s/it, lr=0.001, test_MAE=0.834, time=63.7, train_MAE=0.755, train_loss=0.755, val_MAE=0.727, val_loss=0.727]Epoch 25:   2%|▎         | 25/1000 [25:51<17:06:49, 63.19s/it, lr=0.001, test_MAE=0.834, time=63.7, train_MAE=0.755, train_loss=0.755, val_MAE=0.727, val_loss=0.727]Epoch 25:   2%|▎         | 25/1000 [26:55<17:06:49, 63.19s/it, lr=0.001, test_MAE=0.838, time=64, train_MAE=0.746, train_loss=0.746, val_MAE=0.747, val_loss=0.747]  Epoch 25:   3%|▎         | 26/1000 [26:55<17:10:03, 63.45s/it, lr=0.001, test_MAE=0.838, time=64, train_MAE=0.746, train_loss=0.746, val_MAE=0.747, val_loss=0.747]Epoch 26:   3%|▎         | 26/1000 [26:55<17:10:03, 63.45s/it, lr=0.001, test_MAE=0.838, time=64, train_MAE=0.746, train_loss=0.746, val_MAE=0.747, val_loss=0.747]Epoch 26:   3%|▎         | 26/1000 [27:59<17:10:03, 63.45s/it, lr=0.001, test_MAE=0.833, time=63.8, train_MAE=0.753, train_loss=0.753, val_MAE=0.742, val_loss=0.742]Epoch 26:   3%|▎         | 27/1000 [27:59<17:10:41, 63.56s/it, lr=0.001, test_MAE=0.833, time=63.8, train_MAE=0.753, train_loss=0.753, val_MAE=0.742, val_loss=0.742]Epoch 27:   3%|▎         | 27/1000 [27:59<17:10:41, 63.56s/it, lr=0.001, test_MAE=0.833, time=63.8, train_MAE=0.753, train_loss=0.753, val_MAE=0.742, val_loss=0.742]Epoch 27:   3%|▎         | 27/1000 [29:06<17:10:41, 63.56s/it, lr=0.001, test_MAE=0.825, time=67.5, train_MAE=0.74, train_loss=0.74, val_MAE=0.73, val_loss=0.73]    Epoch 27:   3%|▎         | 28/1000 [29:06<17:28:58, 64.75s/it, lr=0.001, test_MAE=0.825, time=67.5, train_MAE=0.74, train_loss=0.74, val_MAE=0.73, val_loss=0.73]Epoch 28:   3%|▎         | 28/1000 [29:06<17:28:58, 64.75s/it, lr=0.001, test_MAE=0.825, time=67.5, train_MAE=0.74, train_loss=0.74, val_MAE=0.73, val_loss=0.73]Epoch 28:   3%|▎         | 28/1000 [30:15<17:28:58, 64.75s/it, lr=0.001, test_MAE=0.85, time=68.5, train_MAE=0.75, train_loss=0.75, val_MAE=0.774, val_loss=0.774]Epoch 28:   3%|▎         | 29/1000 [30:15<17:46:06, 65.88s/it, lr=0.001, test_MAE=0.85, time=68.5, train_MAE=0.75, train_loss=0.75, val_MAE=0.774, val_loss=0.774]Epoch 29:   3%|▎         | 29/1000 [30:15<17:46:06, 65.88s/it, lr=0.001, test_MAE=0.85, time=68.5, train_MAE=0.75, train_loss=0.75, val_MAE=0.774, val_loss=0.774]Epoch 29:   3%|▎         | 29/1000 [31:22<17:46:06, 65.88s/it, lr=0.001, test_MAE=0.828, time=67.3, train_MAE=0.743, train_loss=0.743, val_MAE=0.745, val_loss=0.745]Epoch 29:   3%|▎         | 30/1000 [31:22<17:52:06, 66.32s/it, lr=0.001, test_MAE=0.828, time=67.3, train_MAE=0.743, train_loss=0.743, val_MAE=0.745, val_loss=0.745]Epoch 30:   3%|▎         | 30/1000 [31:22<17:52:06, 66.32s/it, lr=0.001, test_MAE=0.828, time=67.3, train_MAE=0.743, train_loss=0.743, val_MAE=0.745, val_loss=0.745]Epoch 30:   3%|▎         | 30/1000 [32:30<17:52:06, 66.32s/it, lr=0.001, test_MAE=0.815, time=67.4, train_MAE=0.732, train_loss=0.732, val_MAE=0.734, val_loss=0.734]Epoch    31: reducing learning rate of group 0 to 5.0000e-04.
Epoch 30:   3%|▎         | 31/1000 [32:30<17:56:38, 66.66s/it, lr=0.001, test_MAE=0.815, time=67.4, train_MAE=0.732, train_loss=0.732, val_MAE=0.734, val_loss=0.734]Epoch 31:   3%|▎         | 31/1000 [32:30<17:56:38, 66.66s/it, lr=0.001, test_MAE=0.815, time=67.4, train_MAE=0.732, train_loss=0.732, val_MAE=0.734, val_loss=0.734]Epoch 31:   3%|▎         | 31/1000 [33:37<17:56:38, 66.66s/it, lr=0.0005, test_MAE=0.808, time=67, train_MAE=0.72, train_loss=0.72, val_MAE=0.721, val_loss=0.721]   Epoch 31:   3%|▎         | 32/1000 [33:37<17:57:29, 66.79s/it, lr=0.0005, test_MAE=0.808, time=67, train_MAE=0.72, train_loss=0.72, val_MAE=0.721, val_loss=0.721]Epoch 32:   3%|▎         | 32/1000 [33:37<17:57:29, 66.79s/it, lr=0.0005, test_MAE=0.808, time=67, train_MAE=0.72, train_loss=0.72, val_MAE=0.721, val_loss=0.721]Epoch 32:   3%|▎         | 32/1000 [34:45<17:57:29, 66.79s/it, lr=0.0005, test_MAE=0.809, time=68, train_MAE=0.714, train_loss=0.714, val_MAE=0.729, val_loss=0.729]Epoch 32:   3%|▎         | 33/1000 [34:45<18:02:23, 67.16s/it, lr=0.0005, test_MAE=0.809, time=68, train_MAE=0.714, train_loss=0.714, val_MAE=0.729, val_loss=0.729]Epoch 33:   3%|▎         | 33/1000 [34:45<18:02:23, 67.16s/it, lr=0.0005, test_MAE=0.809, time=68, train_MAE=0.714, train_loss=0.714, val_MAE=0.729, val_loss=0.729]Epoch 33:   3%|▎         | 33/1000 [35:52<18:02:23, 67.16s/it, lr=0.0005, test_MAE=0.803, time=67.5, train_MAE=0.714, train_loss=0.714, val_MAE=0.712, val_loss=0.712]Epoch 33:   3%|▎         | 34/1000 [35:52<18:03:16, 67.28s/it, lr=0.0005, test_MAE=0.803, time=67.5, train_MAE=0.714, train_loss=0.714, val_MAE=0.712, val_loss=0.712]Epoch 34:   3%|▎         | 34/1000 [35:52<18:03:16, 67.28s/it, lr=0.0005, test_MAE=0.803, time=67.5, train_MAE=0.714, train_loss=0.714, val_MAE=0.712, val_loss=0.712]Epoch 34:   3%|▎         | 34/1000 [37:00<18:03:16, 67.28s/it, lr=0.0005, test_MAE=0.805, time=68, train_MAE=0.711, train_loss=0.711, val_MAE=0.714, val_loss=0.714]  Epoch 34:   4%|▎         | 35/1000 [37:00<18:05:56, 67.52s/it, lr=0.0005, test_MAE=0.805, time=68, train_MAE=0.711, train_loss=0.711, val_MAE=0.714, val_loss=0.714]Epoch 35:   4%|▎         | 35/1000 [37:00<18:05:56, 67.52s/it, lr=0.0005, test_MAE=0.805, time=68, train_MAE=0.711, train_loss=0.711, val_MAE=0.714, val_loss=0.714]Epoch 35:   4%|▎         | 35/1000 [38:08<18:05:56, 67.52s/it, lr=0.0005, test_MAE=0.802, time=67.9, train_MAE=0.71, train_loss=0.71, val_MAE=0.72, val_loss=0.72]  Epoch 35:   4%|▎         | 36/1000 [38:08<18:06:44, 67.64s/it, lr=0.0005, test_MAE=0.802, time=67.9, train_MAE=0.71, train_loss=0.71, val_MAE=0.72, val_loss=0.72]Epoch 36:   4%|▎         | 36/1000 [38:08<18:06:44, 67.64s/it, lr=0.0005, test_MAE=0.802, time=67.9, train_MAE=0.71, train_loss=0.71, val_MAE=0.72, val_loss=0.72]Epoch 36:   4%|▎         | 36/1000 [39:16<18:06:44, 67.64s/it, lr=0.0005, test_MAE=0.818, time=68, train_MAE=0.712, train_loss=0.712, val_MAE=0.719, val_loss=0.719]Epoch 36:   4%|▎         | 37/1000 [39:16<18:07:42, 67.77s/it, lr=0.0005, test_MAE=0.818, time=68, train_MAE=0.712, train_loss=0.712, val_MAE=0.719, val_loss=0.719]Epoch 37:   4%|▎         | 37/1000 [39:16<18:07:42, 67.77s/it, lr=0.0005, test_MAE=0.818, time=68, train_MAE=0.712, train_loss=0.712, val_MAE=0.719, val_loss=0.719]Epoch 37:   4%|▎         | 37/1000 [40:24<18:07:42, 67.77s/it, lr=0.0005, test_MAE=0.801, time=67.6, train_MAE=0.711, train_loss=0.711, val_MAE=0.715, val_loss=0.715]Epoch 37:   4%|▍         | 38/1000 [40:24<18:05:55, 67.73s/it, lr=0.0005, test_MAE=0.801, time=67.6, train_MAE=0.711, train_loss=0.711, val_MAE=0.715, val_loss=0.715]Epoch 38:   4%|▍         | 38/1000 [40:24<18:05:55, 67.73s/it, lr=0.0005, test_MAE=0.801, time=67.6, train_MAE=0.711, train_loss=0.711, val_MAE=0.715, val_loss=0.715]Epoch 38:   4%|▍         | 38/1000 [41:31<18:05:55, 67.73s/it, lr=0.0005, test_MAE=0.798, time=67.1, train_MAE=0.712, train_loss=0.712, val_MAE=0.712, val_loss=0.712]Epoch 38:   4%|▍         | 39/1000 [41:31<18:01:59, 67.55s/it, lr=0.0005, test_MAE=0.798, time=67.1, train_MAE=0.712, train_loss=0.712, val_MAE=0.712, val_loss=0.712]Epoch 39:   4%|▍         | 39/1000 [41:31<18:01:59, 67.55s/it, lr=0.0005, test_MAE=0.798, time=67.1, train_MAE=0.712, train_loss=0.712, val_MAE=0.712, val_loss=0.712]Epoch 39:   4%|▍         | 39/1000 [42:39<18:01:59, 67.55s/it, lr=0.0005, test_MAE=0.806, time=67.8, train_MAE=0.706, train_loss=0.706, val_MAE=0.717, val_loss=0.717]Epoch    40: reducing learning rate of group 0 to 2.5000e-04.
Epoch 39:   4%|▍         | 40/1000 [42:39<18:02:22, 67.65s/it, lr=0.0005, test_MAE=0.806, time=67.8, train_MAE=0.706, train_loss=0.706, val_MAE=0.717, val_loss=0.717]Epoch 40:   4%|▍         | 40/1000 [42:39<18:02:22, 67.65s/it, lr=0.0005, test_MAE=0.806, time=67.8, train_MAE=0.706, train_loss=0.706, val_MAE=0.717, val_loss=0.717]Epoch 40:   4%|▍         | 40/1000 [43:47<18:02:22, 67.65s/it, lr=0.00025, test_MAE=0.794, time=67.8, train_MAE=0.696, train_loss=0.696, val_MAE=0.709, val_loss=0.709]Epoch 40:   4%|▍         | 41/1000 [43:47<18:02:11, 67.71s/it, lr=0.00025, test_MAE=0.794, time=67.8, train_MAE=0.696, train_loss=0.696, val_MAE=0.709, val_loss=0.709]Epoch 41:   4%|▍         | 41/1000 [43:47<18:02:11, 67.71s/it, lr=0.00025, test_MAE=0.794, time=67.8, train_MAE=0.696, train_loss=0.696, val_MAE=0.709, val_loss=0.709]Epoch 41:   4%|▍         | 41/1000 [44:54<18:02:11, 67.71s/it, lr=0.00025, test_MAE=0.801, time=66.9, train_MAE=0.693, train_loss=0.693, val_MAE=0.708, val_loss=0.708]Epoch 41:   4%|▍         | 42/1000 [44:54<17:57:28, 67.48s/it, lr=0.00025, test_MAE=0.801, time=66.9, train_MAE=0.693, train_loss=0.693, val_MAE=0.708, val_loss=0.708]Epoch 42:   4%|▍         | 42/1000 [44:54<17:57:28, 67.48s/it, lr=0.00025, test_MAE=0.801, time=66.9, train_MAE=0.693, train_loss=0.693, val_MAE=0.708, val_loss=0.708]Epoch 42:   4%|▍         | 42/1000 [46:01<17:57:28, 67.48s/it, lr=0.00025, test_MAE=0.801, time=67.3, train_MAE=0.692, train_loss=0.692, val_MAE=0.708, val_loss=0.708]Epoch 42:   4%|▍         | 43/1000 [46:01<17:55:44, 67.44s/it, lr=0.00025, test_MAE=0.801, time=67.3, train_MAE=0.692, train_loss=0.692, val_MAE=0.708, val_loss=0.708]Epoch 43:   4%|▍         | 43/1000 [46:01<17:55:44, 67.44s/it, lr=0.00025, test_MAE=0.801, time=67.3, train_MAE=0.692, train_loss=0.692, val_MAE=0.708, val_loss=0.708]Epoch 43:   4%|▍         | 43/1000 [47:09<17:55:44, 67.44s/it, lr=0.00025, test_MAE=0.795, time=68.2, train_MAE=0.692, train_loss=0.692, val_MAE=0.708, val_loss=0.708]Epoch 43:   4%|▍         | 44/1000 [47:09<17:58:11, 67.67s/it, lr=0.00025, test_MAE=0.795, time=68.2, train_MAE=0.692, train_loss=0.692, val_MAE=0.708, val_loss=0.708]Epoch 44:   4%|▍         | 44/1000 [47:09<17:58:11, 67.67s/it, lr=0.00025, test_MAE=0.795, time=68.2, train_MAE=0.692, train_loss=0.692, val_MAE=0.708, val_loss=0.708]Epoch 44:   4%|▍         | 44/1000 [48:16<17:58:11, 67.67s/it, lr=0.00025, test_MAE=0.798, time=66.3, train_MAE=0.692, train_loss=0.692, val_MAE=0.707, val_loss=0.707]Epoch 44:   4%|▍         | 45/1000 [48:16<17:50:42, 67.27s/it, lr=0.00025, test_MAE=0.798, time=66.3, train_MAE=0.692, train_loss=0.692, val_MAE=0.707, val_loss=0.707]Epoch 45:   4%|▍         | 45/1000 [48:16<17:50:42, 67.27s/it, lr=0.00025, test_MAE=0.798, time=66.3, train_MAE=0.692, train_loss=0.692, val_MAE=0.707, val_loss=0.707]Epoch 45:   4%|▍         | 45/1000 [49:21<17:50:42, 67.27s/it, lr=0.00025, test_MAE=0.793, time=65.1, train_MAE=0.696, train_loss=0.696, val_MAE=0.708, val_loss=0.708]Epoch 45:   5%|▍         | 46/1000 [49:21<17:39:33, 66.64s/it, lr=0.00025, test_MAE=0.793, time=65.1, train_MAE=0.696, train_loss=0.696, val_MAE=0.708, val_loss=0.708]Epoch 46:   5%|▍         | 46/1000 [49:21<17:39:33, 66.64s/it, lr=0.00025, test_MAE=0.793, time=65.1, train_MAE=0.696, train_loss=0.696, val_MAE=0.708, val_loss=0.708]Epoch 46:   5%|▍         | 46/1000 [50:27<17:39:33, 66.64s/it, lr=0.00025, test_MAE=0.798, time=66.4, train_MAE=0.685, train_loss=0.685, val_MAE=0.711, val_loss=0.711]Epoch 46:   5%|▍         | 47/1000 [50:27<17:37:21, 66.57s/it, lr=0.00025, test_MAE=0.798, time=66.4, train_MAE=0.685, train_loss=0.685, val_MAE=0.711, val_loss=0.711]Epoch 47:   5%|▍         | 47/1000 [50:27<17:37:21, 66.57s/it, lr=0.00025, test_MAE=0.798, time=66.4, train_MAE=0.685, train_loss=0.685, val_MAE=0.711, val_loss=0.711]Epoch 47:   5%|▍         | 47/1000 [51:35<17:37:21, 66.57s/it, lr=0.00025, test_MAE=0.794, time=67.9, train_MAE=0.689, train_loss=0.689, val_MAE=0.708, val_loss=0.708]Epoch 47:   5%|▍         | 48/1000 [51:35<17:42:38, 66.97s/it, lr=0.00025, test_MAE=0.794, time=67.9, train_MAE=0.689, train_loss=0.689, val_MAE=0.708, val_loss=0.708]Epoch 48:   5%|▍         | 48/1000 [51:35<17:42:38, 66.97s/it, lr=0.00025, test_MAE=0.794, time=67.9, train_MAE=0.689, train_loss=0.689, val_MAE=0.708, val_loss=0.708]Epoch 48:   5%|▍         | 48/1000 [52:43<17:42:38, 66.97s/it, lr=0.00025, test_MAE=0.794, time=67.4, train_MAE=0.687, train_loss=0.687, val_MAE=0.716, val_loss=0.716]Epoch 48:   5%|▍         | 49/1000 [52:43<17:43:53, 67.12s/it, lr=0.00025, test_MAE=0.794, time=67.4, train_MAE=0.687, train_loss=0.687, val_MAE=0.716, val_loss=0.716]Epoch 49:   5%|▍         | 49/1000 [52:43<17:43:53, 67.12s/it, lr=0.00025, test_MAE=0.794, time=67.4, train_MAE=0.687, train_loss=0.687, val_MAE=0.716, val_loss=0.716]Epoch 49:   5%|▍         | 49/1000 [53:50<17:43:53, 67.12s/it, lr=0.00025, test_MAE=0.795, time=67.6, train_MAE=0.693, train_loss=0.693, val_MAE=0.709, val_loss=0.709]Epoch 49:   5%|▌         | 50/1000 [53:50<17:45:03, 67.27s/it, lr=0.00025, test_MAE=0.795, time=67.6, train_MAE=0.693, train_loss=0.693, val_MAE=0.709, val_loss=0.709]Epoch 50:   5%|▌         | 50/1000 [53:50<17:45:03, 67.27s/it, lr=0.00025, test_MAE=0.795, time=67.6, train_MAE=0.693, train_loss=0.693, val_MAE=0.709, val_loss=0.709]Epoch 50:   5%|▌         | 50/1000 [54:57<17:45:03, 67.27s/it, lr=0.00025, test_MAE=0.795, time=67.2, train_MAE=0.689, train_loss=0.689, val_MAE=0.708, val_loss=0.708]Epoch    51: reducing learning rate of group 0 to 1.2500e-04.
Epoch 50:   5%|▌         | 51/1000 [54:58<17:43:56, 67.27s/it, lr=0.00025, test_MAE=0.795, time=67.2, train_MAE=0.689, train_loss=0.689, val_MAE=0.708, val_loss=0.708]Epoch 51:   5%|▌         | 51/1000 [54:58<17:43:56, 67.27s/it, lr=0.00025, test_MAE=0.795, time=67.2, train_MAE=0.689, train_loss=0.689, val_MAE=0.708, val_loss=0.708]Epoch 51:   5%|▌         | 51/1000 [56:05<17:43:56, 67.27s/it, lr=0.000125, test_MAE=0.795, time=67.8, train_MAE=0.682, train_loss=0.682, val_MAE=0.711, val_loss=0.711]Epoch 51:   5%|▌         | 52/1000 [56:05<17:45:31, 67.44s/it, lr=0.000125, test_MAE=0.795, time=67.8, train_MAE=0.682, train_loss=0.682, val_MAE=0.711, val_loss=0.711]Epoch 52:   5%|▌         | 52/1000 [56:05<17:45:31, 67.44s/it, lr=0.000125, test_MAE=0.795, time=67.8, train_MAE=0.682, train_loss=0.682, val_MAE=0.711, val_loss=0.711]Epoch 52:   5%|▌         | 52/1000 [57:13<17:45:31, 67.44s/it, lr=0.000125, test_MAE=0.792, time=67.6, train_MAE=0.679, train_loss=0.679, val_MAE=0.705, val_loss=0.705]Epoch 52:   5%|▌         | 53/1000 [57:13<17:45:20, 67.50s/it, lr=0.000125, test_MAE=0.792, time=67.6, train_MAE=0.679, train_loss=0.679, val_MAE=0.705, val_loss=0.705]Epoch 53:   5%|▌         | 53/1000 [57:13<17:45:20, 67.50s/it, lr=0.000125, test_MAE=0.792, time=67.6, train_MAE=0.679, train_loss=0.679, val_MAE=0.705, val_loss=0.705]Epoch 53:   5%|▌         | 53/1000 [58:20<17:45:20, 67.50s/it, lr=0.000125, test_MAE=0.791, time=66.7, train_MAE=0.676, train_loss=0.676, val_MAE=0.709, val_loss=0.709]Epoch 53:   5%|▌         | 54/1000 [58:20<17:40:39, 67.27s/it, lr=0.000125, test_MAE=0.791, time=66.7, train_MAE=0.676, train_loss=0.676, val_MAE=0.709, val_loss=0.709]Epoch 54:   5%|▌         | 54/1000 [58:20<17:40:39, 67.27s/it, lr=0.000125, test_MAE=0.791, time=66.7, train_MAE=0.676, train_loss=0.676, val_MAE=0.709, val_loss=0.709]Epoch 54:   5%|▌         | 54/1000 [59:28<17:40:39, 67.27s/it, lr=0.000125, test_MAE=0.788, time=67.8, train_MAE=0.677, train_loss=0.677, val_MAE=0.709, val_loss=0.709]Epoch 54:   6%|▌         | 55/1000 [59:28<17:42:18, 67.45s/it, lr=0.000125, test_MAE=0.788, time=67.8, train_MAE=0.677, train_loss=0.677, val_MAE=0.709, val_loss=0.709]Epoch 55:   6%|▌         | 55/1000 [59:28<17:42:18, 67.45s/it, lr=0.000125, test_MAE=0.788, time=67.8, train_MAE=0.677, train_loss=0.677, val_MAE=0.709, val_loss=0.709]Epoch 55:   6%|▌         | 55/1000 [1:00:35<17:42:18, 67.45s/it, lr=0.000125, test_MAE=0.789, time=67.9, train_MAE=0.678, train_loss=0.678, val_MAE=0.703, val_loss=0.703]Epoch 55:   6%|▌         | 56/1000 [1:00:36<17:43:27, 67.59s/it, lr=0.000125, test_MAE=0.789, time=67.9, train_MAE=0.678, train_loss=0.678, val_MAE=0.703, val_loss=0.703]Epoch 56:   6%|▌         | 56/1000 [1:00:36<17:43:27, 67.59s/it, lr=0.000125, test_MAE=0.789, time=67.9, train_MAE=0.678, train_loss=0.678, val_MAE=0.703, val_loss=0.703]Epoch 56:   6%|▌         | 56/1000 [1:01:43<17:43:27, 67.59s/it, lr=0.000125, test_MAE=0.788, time=67.1, train_MAE=0.682, train_loss=0.682, val_MAE=0.707, val_loss=0.707]Epoch 56:   6%|▌         | 57/1000 [1:01:43<17:40:07, 67.45s/it, lr=0.000125, test_MAE=0.788, time=67.1, train_MAE=0.682, train_loss=0.682, val_MAE=0.707, val_loss=0.707]Epoch 57:   6%|▌         | 57/1000 [1:01:43<17:40:07, 67.45s/it, lr=0.000125, test_MAE=0.788, time=67.1, train_MAE=0.682, train_loss=0.682, val_MAE=0.707, val_loss=0.707]Epoch 57:   6%|▌         | 57/1000 [1:02:50<17:40:07, 67.45s/it, lr=0.000125, test_MAE=0.789, time=67.6, train_MAE=0.683, train_loss=0.683, val_MAE=0.705, val_loss=0.705]Epoch 57:   6%|▌         | 58/1000 [1:02:50<17:39:56, 67.51s/it, lr=0.000125, test_MAE=0.789, time=67.6, train_MAE=0.683, train_loss=0.683, val_MAE=0.705, val_loss=0.705]Epoch 58:   6%|▌         | 58/1000 [1:02:50<17:39:56, 67.51s/it, lr=0.000125, test_MAE=0.789, time=67.6, train_MAE=0.683, train_loss=0.683, val_MAE=0.705, val_loss=0.705]Epoch 58:   6%|▌         | 58/1000 [1:03:58<17:39:56, 67.51s/it, lr=0.000125, test_MAE=0.785, time=67.3, train_MAE=0.677, train_loss=0.677, val_MAE=0.704, val_loss=0.704]Epoch 58:   6%|▌         | 59/1000 [1:03:58<17:37:59, 67.46s/it, lr=0.000125, test_MAE=0.785, time=67.3, train_MAE=0.677, train_loss=0.677, val_MAE=0.704, val_loss=0.704]Epoch 59:   6%|▌         | 59/1000 [1:03:58<17:37:59, 67.46s/it, lr=0.000125, test_MAE=0.785, time=67.3, train_MAE=0.677, train_loss=0.677, val_MAE=0.704, val_loss=0.704]Epoch 59:   6%|▌         | 59/1000 [1:05:01<17:37:59, 67.46s/it, lr=0.000125, test_MAE=0.785, time=63.3, train_MAE=0.683, train_loss=0.683, val_MAE=0.707, val_loss=0.707]Epoch 59:   6%|▌         | 60/1000 [1:05:01<17:17:43, 66.24s/it, lr=0.000125, test_MAE=0.785, time=63.3, train_MAE=0.683, train_loss=0.683, val_MAE=0.707, val_loss=0.707]Epoch 60:   6%|▌         | 60/1000 [1:05:01<17:17:43, 66.24s/it, lr=0.000125, test_MAE=0.785, time=63.3, train_MAE=0.683, train_loss=0.683, val_MAE=0.707, val_loss=0.707]Epoch 60:   6%|▌         | 60/1000 [1:06:06<17:17:43, 66.24s/it, lr=0.000125, test_MAE=0.79, time=65.2, train_MAE=0.68, train_loss=0.68, val_MAE=0.71, val_loss=0.71]     Epoch 60:   6%|▌         | 61/1000 [1:06:06<17:12:07, 65.95s/it, lr=0.000125, test_MAE=0.79, time=65.2, train_MAE=0.68, train_loss=0.68, val_MAE=0.71, val_loss=0.71]Epoch 61:   6%|▌         | 61/1000 [1:06:06<17:12:07, 65.95s/it, lr=0.000125, test_MAE=0.79, time=65.2, train_MAE=0.68, train_loss=0.68, val_MAE=0.71, val_loss=0.71]Epoch 61:   6%|▌         | 61/1000 [1:07:14<17:12:07, 65.95s/it, lr=0.000125, test_MAE=0.788, time=67.3, train_MAE=0.681, train_loss=0.681, val_MAE=0.709, val_loss=0.709]Epoch    62: reducing learning rate of group 0 to 6.2500e-05.
Epoch 61:   6%|▌         | 62/1000 [1:07:14<17:17:22, 66.36s/it, lr=0.000125, test_MAE=0.788, time=67.3, train_MAE=0.681, train_loss=0.681, val_MAE=0.709, val_loss=0.709]Epoch 62:   6%|▌         | 62/1000 [1:07:14<17:17:22, 66.36s/it, lr=0.000125, test_MAE=0.788, time=67.3, train_MAE=0.681, train_loss=0.681, val_MAE=0.709, val_loss=0.709]Epoch 62:   6%|▌         | 62/1000 [1:08:22<17:17:22, 66.36s/it, lr=6.25e-5, test_MAE=0.789, time=68.1, train_MAE=0.685, train_loss=0.685, val_MAE=0.704, val_loss=0.704] Epoch 62:   6%|▋         | 63/1000 [1:08:22<17:24:43, 66.90s/it, lr=6.25e-5, test_MAE=0.789, time=68.1, train_MAE=0.685, train_loss=0.685, val_MAE=0.704, val_loss=0.704]Epoch 63:   6%|▋         | 63/1000 [1:08:22<17:24:43, 66.90s/it, lr=6.25e-5, test_MAE=0.789, time=68.1, train_MAE=0.685, train_loss=0.685, val_MAE=0.704, val_loss=0.704]Epoch 63:   6%|▋         | 63/1000 [1:09:29<17:24:43, 66.90s/it, lr=6.25e-5, test_MAE=0.788, time=67.4, train_MAE=0.674, train_loss=0.674, val_MAE=0.706, val_loss=0.706]Epoch 63:   6%|▋         | 64/1000 [1:09:29<17:26:10, 67.06s/it, lr=6.25e-5, test_MAE=0.788, time=67.4, train_MAE=0.674, train_loss=0.674, val_MAE=0.706, val_loss=0.706]Epoch 64:   6%|▋         | 64/1000 [1:09:29<17:26:10, 67.06s/it, lr=6.25e-5, test_MAE=0.788, time=67.4, train_MAE=0.674, train_loss=0.674, val_MAE=0.706, val_loss=0.706]Epoch 64:   6%|▋         | 64/1000 [1:10:37<17:26:10, 67.06s/it, lr=6.25e-5, test_MAE=0.784, time=67.7, train_MAE=0.677, train_loss=0.677, val_MAE=0.706, val_loss=0.706]Epoch 64:   6%|▋         | 65/1000 [1:10:37<17:28:00, 67.25s/it, lr=6.25e-5, test_MAE=0.784, time=67.7, train_MAE=0.677, train_loss=0.677, val_MAE=0.706, val_loss=0.706]Epoch 65:   6%|▋         | 65/1000 [1:10:37<17:28:00, 67.25s/it, lr=6.25e-5, test_MAE=0.784, time=67.7, train_MAE=0.677, train_loss=0.677, val_MAE=0.706, val_loss=0.706]Epoch 65:   6%|▋         | 65/1000 [1:11:44<17:28:00, 67.25s/it, lr=6.25e-5, test_MAE=0.787, time=67.4, train_MAE=0.675, train_loss=0.675, val_MAE=0.705, val_loss=0.705]Epoch 65:   7%|▋         | 66/1000 [1:11:44<17:27:32, 67.29s/it, lr=6.25e-5, test_MAE=0.787, time=67.4, train_MAE=0.675, train_loss=0.675, val_MAE=0.705, val_loss=0.705]Epoch 66:   7%|▋         | 66/1000 [1:11:44<17:27:32, 67.29s/it, lr=6.25e-5, test_MAE=0.787, time=67.4, train_MAE=0.675, train_loss=0.675, val_MAE=0.705, val_loss=0.705]Epoch 66:   7%|▋         | 66/1000 [1:12:52<17:27:32, 67.29s/it, lr=6.25e-5, test_MAE=0.786, time=67.4, train_MAE=0.678, train_loss=0.678, val_MAE=0.708, val_loss=0.708]Epoch 66:   7%|▋         | 67/1000 [1:12:52<17:27:15, 67.35s/it, lr=6.25e-5, test_MAE=0.786, time=67.4, train_MAE=0.678, train_loss=0.678, val_MAE=0.708, val_loss=0.708]Epoch 67:   7%|▋         | 67/1000 [1:12:52<17:27:15, 67.35s/it, lr=6.25e-5, test_MAE=0.786, time=67.4, train_MAE=0.678, train_loss=0.678, val_MAE=0.708, val_loss=0.708]Epoch 67:   7%|▋         | 67/1000 [1:13:59<17:27:15, 67.35s/it, lr=6.25e-5, test_MAE=0.788, time=67, train_MAE=0.702, train_loss=0.702, val_MAE=0.705, val_loss=0.705]  Epoch    68: reducing learning rate of group 0 to 3.1250e-05.
Epoch 67:   7%|▋         | 68/1000 [1:13:59<17:24:25, 67.24s/it, lr=6.25e-5, test_MAE=0.788, time=67, train_MAE=0.702, train_loss=0.702, val_MAE=0.705, val_loss=0.705]Epoch 68:   7%|▋         | 68/1000 [1:13:59<17:24:25, 67.24s/it, lr=6.25e-5, test_MAE=0.788, time=67, train_MAE=0.702, train_loss=0.702, val_MAE=0.705, val_loss=0.705]Epoch 68:   7%|▋         | 68/1000 [1:15:06<17:24:25, 67.24s/it, lr=3.13e-5, test_MAE=0.784, time=67.3, train_MAE=0.676, train_loss=0.676, val_MAE=0.702, val_loss=0.702]Epoch 68:   7%|▋         | 69/1000 [1:15:06<17:23:42, 67.26s/it, lr=3.13e-5, test_MAE=0.784, time=67.3, train_MAE=0.676, train_loss=0.676, val_MAE=0.702, val_loss=0.702]Epoch 69:   7%|▋         | 69/1000 [1:15:06<17:23:42, 67.26s/it, lr=3.13e-5, test_MAE=0.784, time=67.3, train_MAE=0.676, train_loss=0.676, val_MAE=0.702, val_loss=0.702]Epoch 69:   7%|▋         | 69/1000 [1:16:14<17:23:42, 67.26s/it, lr=3.13e-5, test_MAE=0.789, time=67.9, train_MAE=0.67, train_loss=0.67, val_MAE=0.706, val_loss=0.706]  Epoch 69:   7%|▋         | 70/1000 [1:16:14<17:25:36, 67.46s/it, lr=3.13e-5, test_MAE=0.789, time=67.9, train_MAE=0.67, train_loss=0.67, val_MAE=0.706, val_loss=0.706]Epoch 70:   7%|▋         | 70/1000 [1:16:14<17:25:36, 67.46s/it, lr=3.13e-5, test_MAE=0.789, time=67.9, train_MAE=0.67, train_loss=0.67, val_MAE=0.706, val_loss=0.706]Epoch 70:   7%|▋         | 70/1000 [1:17:21<17:25:36, 67.46s/it, lr=3.13e-5, test_MAE=0.788, time=67.3, train_MAE=0.676, train_loss=0.676, val_MAE=0.707, val_loss=0.707]Epoch 70:   7%|▋         | 71/1000 [1:17:21<17:24:05, 67.43s/it, lr=3.13e-5, test_MAE=0.788, time=67.3, train_MAE=0.676, train_loss=0.676, val_MAE=0.707, val_loss=0.707]Epoch 71:   7%|▋         | 71/1000 [1:17:21<17:24:05, 67.43s/it, lr=3.13e-5, test_MAE=0.788, time=67.3, train_MAE=0.676, train_loss=0.676, val_MAE=0.707, val_loss=0.707]Epoch 71:   7%|▋         | 71/1000 [1:18:28<17:24:05, 67.43s/it, lr=3.13e-5, test_MAE=0.786, time=67.1, train_MAE=0.675, train_loss=0.675, val_MAE=0.704, val_loss=0.704]Epoch 71:   7%|▋         | 72/1000 [1:18:28<17:21:23, 67.33s/it, lr=3.13e-5, test_MAE=0.786, time=67.1, train_MAE=0.675, train_loss=0.675, val_MAE=0.704, val_loss=0.704]Epoch 72:   7%|▋         | 72/1000 [1:18:28<17:21:23, 67.33s/it, lr=3.13e-5, test_MAE=0.786, time=67.1, train_MAE=0.675, train_loss=0.675, val_MAE=0.704, val_loss=0.704]Epoch 72:   7%|▋         | 72/1000 [1:19:36<17:21:23, 67.33s/it, lr=3.13e-5, test_MAE=0.787, time=67.3, train_MAE=0.676, train_loss=0.676, val_MAE=0.707, val_loss=0.707]Epoch 72:   7%|▋         | 73/1000 [1:19:36<17:20:12, 67.33s/it, lr=3.13e-5, test_MAE=0.787, time=67.3, train_MAE=0.676, train_loss=0.676, val_MAE=0.707, val_loss=0.707]Epoch 73:   7%|▋         | 73/1000 [1:19:36<17:20:12, 67.33s/it, lr=3.13e-5, test_MAE=0.787, time=67.3, train_MAE=0.676, train_loss=0.676, val_MAE=0.707, val_loss=0.707]Epoch 73:   7%|▋         | 73/1000 [1:20:42<17:20:12, 67.33s/it, lr=3.13e-5, test_MAE=0.787, time=66.7, train_MAE=0.68, train_loss=0.68, val_MAE=0.703, val_loss=0.703]  Epoch 73:   7%|▋         | 74/1000 [1:20:42<17:16:16, 67.15s/it, lr=3.13e-5, test_MAE=0.787, time=66.7, train_MAE=0.68, train_loss=0.68, val_MAE=0.703, val_loss=0.703]Epoch 74:   7%|▋         | 74/1000 [1:20:42<17:16:16, 67.15s/it, lr=3.13e-5, test_MAE=0.787, time=66.7, train_MAE=0.68, train_loss=0.68, val_MAE=0.703, val_loss=0.703]Epoch 74:   7%|▋         | 74/1000 [1:21:47<17:16:16, 67.15s/it, lr=3.13e-5, test_MAE=0.791, time=64.8, train_MAE=0.68, train_loss=0.68, val_MAE=0.707, val_loss=0.707]Epoch    75: reducing learning rate of group 0 to 1.5625e-05.
Epoch 74:   8%|▊         | 75/1000 [1:21:47<17:04:26, 66.45s/it, lr=3.13e-5, test_MAE=0.791, time=64.8, train_MAE=0.68, train_loss=0.68, val_MAE=0.707, val_loss=0.707]Epoch 75:   8%|▊         | 75/1000 [1:21:47<17:04:26, 66.45s/it, lr=3.13e-5, test_MAE=0.791, time=64.8, train_MAE=0.68, train_loss=0.68, val_MAE=0.707, val_loss=0.707]Epoch 75:   8%|▊         | 75/1000 [1:22:54<17:04:26, 66.45s/it, lr=1.56e-5, test_MAE=0.79, time=66.3, train_MAE=0.679, train_loss=0.679, val_MAE=0.707, val_loss=0.707]Epoch 75:   8%|▊         | 76/1000 [1:22:54<17:02:41, 66.41s/it, lr=1.56e-5, test_MAE=0.79, time=66.3, train_MAE=0.679, train_loss=0.679, val_MAE=0.707, val_loss=0.707]Epoch 76:   8%|▊         | 76/1000 [1:22:54<17:02:41, 66.41s/it, lr=1.56e-5, test_MAE=0.79, time=66.3, train_MAE=0.679, train_loss=0.679, val_MAE=0.707, val_loss=0.707]Epoch 76:   8%|▊         | 76/1000 [1:24:01<17:02:41, 66.41s/it, lr=1.56e-5, test_MAE=0.788, time=67.6, train_MAE=0.668, train_loss=0.668, val_MAE=0.704, val_loss=0.704]Epoch 76:   8%|▊         | 77/1000 [1:24:01<17:06:58, 66.76s/it, lr=1.56e-5, test_MAE=0.788, time=67.6, train_MAE=0.668, train_loss=0.668, val_MAE=0.704, val_loss=0.704]Epoch 77:   8%|▊         | 77/1000 [1:24:01<17:06:58, 66.76s/it, lr=1.56e-5, test_MAE=0.788, time=67.6, train_MAE=0.668, train_loss=0.668, val_MAE=0.704, val_loss=0.704]Epoch 77:   8%|▊         | 77/1000 [1:25:09<17:06:58, 66.76s/it, lr=1.56e-5, test_MAE=0.784, time=67.7, train_MAE=0.674, train_loss=0.674, val_MAE=0.706, val_loss=0.706]Epoch 77:   8%|▊         | 78/1000 [1:25:09<17:10:35, 67.07s/it, lr=1.56e-5, test_MAE=0.784, time=67.7, train_MAE=0.674, train_loss=0.674, val_MAE=0.706, val_loss=0.706]Epoch 78:   8%|▊         | 78/1000 [1:25:09<17:10:35, 67.07s/it, lr=1.56e-5, test_MAE=0.784, time=67.7, train_MAE=0.674, train_loss=0.674, val_MAE=0.706, val_loss=0.706]Epoch 78:   8%|▊         | 78/1000 [1:26:17<17:10:35, 67.07s/it, lr=1.56e-5, test_MAE=0.788, time=67.6, train_MAE=0.677, train_loss=0.677, val_MAE=0.704, val_loss=0.704]Epoch 78:   8%|▊         | 79/1000 [1:26:17<17:11:46, 67.22s/it, lr=1.56e-5, test_MAE=0.788, time=67.6, train_MAE=0.677, train_loss=0.677, val_MAE=0.704, val_loss=0.704]Epoch 79:   8%|▊         | 79/1000 [1:26:17<17:11:46, 67.22s/it, lr=1.56e-5, test_MAE=0.788, time=67.6, train_MAE=0.677, train_loss=0.677, val_MAE=0.704, val_loss=0.704]Epoch 79:   8%|▊         | 79/1000 [1:27:24<17:11:46, 67.22s/it, lr=1.56e-5, test_MAE=0.785, time=67.5, train_MAE=0.67, train_loss=0.67, val_MAE=0.704, val_loss=0.704]  Epoch 79:   8%|▊         | 80/1000 [1:27:24<17:11:52, 67.30s/it, lr=1.56e-5, test_MAE=0.785, time=67.5, train_MAE=0.67, train_loss=0.67, val_MAE=0.704, val_loss=0.704]Epoch 80:   8%|▊         | 80/1000 [1:27:24<17:11:52, 67.30s/it, lr=1.56e-5, test_MAE=0.785, time=67.5, train_MAE=0.67, train_loss=0.67, val_MAE=0.704, val_loss=0.704]Epoch 80:   8%|▊         | 80/1000 [1:28:32<17:11:52, 67.30s/it, lr=1.56e-5, test_MAE=0.784, time=67.5, train_MAE=0.675, train_loss=0.675, val_MAE=0.701, val_loss=0.701]Epoch 80:   8%|▊         | 81/1000 [1:28:32<17:11:33, 67.35s/it, lr=1.56e-5, test_MAE=0.784, time=67.5, train_MAE=0.675, train_loss=0.675, val_MAE=0.701, val_loss=0.701]Epoch 81:   8%|▊         | 81/1000 [1:28:32<17:11:33, 67.35s/it, lr=1.56e-5, test_MAE=0.784, time=67.5, train_MAE=0.675, train_loss=0.675, val_MAE=0.701, val_loss=0.701]Epoch 81:   8%|▊         | 81/1000 [1:29:39<17:11:33, 67.35s/it, lr=1.56e-5, test_MAE=0.787, time=68, train_MAE=0.676, train_loss=0.676, val_MAE=0.707, val_loss=0.707]  Epoch 81:   8%|▊         | 82/1000 [1:29:40<17:13:23, 67.54s/it, lr=1.56e-5, test_MAE=0.787, time=68, train_MAE=0.676, train_loss=0.676, val_MAE=0.707, val_loss=0.707]Epoch 82:   8%|▊         | 82/1000 [1:29:40<17:13:23, 67.54s/it, lr=1.56e-5, test_MAE=0.787, time=68, train_MAE=0.676, train_loss=0.676, val_MAE=0.707, val_loss=0.707]Epoch 82:   8%|▊         | 82/1000 [1:30:46<17:13:23, 67.54s/it, lr=1.56e-5, test_MAE=0.784, time=66.9, train_MAE=0.672, train_loss=0.672, val_MAE=0.702, val_loss=0.702]Epoch 82:   8%|▊         | 83/1000 [1:30:46<17:09:27, 67.36s/it, lr=1.56e-5, test_MAE=0.784, time=66.9, train_MAE=0.672, train_loss=0.672, val_MAE=0.702, val_loss=0.702]Epoch 83:   8%|▊         | 83/1000 [1:30:46<17:09:27, 67.36s/it, lr=1.56e-5, test_MAE=0.784, time=66.9, train_MAE=0.672, train_loss=0.672, val_MAE=0.702, val_loss=0.702]Epoch 83:   8%|▊         | 83/1000 [1:31:54<17:09:27, 67.36s/it, lr=1.56e-5, test_MAE=0.785, time=67.6, train_MAE=0.677, train_loss=0.677, val_MAE=0.704, val_loss=0.704]Epoch 83:   8%|▊         | 84/1000 [1:31:54<17:09:45, 67.45s/it, lr=1.56e-5, test_MAE=0.785, time=67.6, train_MAE=0.677, train_loss=0.677, val_MAE=0.704, val_loss=0.704]Epoch 84:   8%|▊         | 84/1000 [1:31:54<17:09:45, 67.45s/it, lr=1.56e-5, test_MAE=0.785, time=67.6, train_MAE=0.677, train_loss=0.677, val_MAE=0.704, val_loss=0.704]Epoch 84:   8%|▊         | 84/1000 [1:33:02<17:09:45, 67.45s/it, lr=1.56e-5, test_MAE=0.787, time=67.6, train_MAE=0.676, train_loss=0.676, val_MAE=0.706, val_loss=0.706]Epoch 84:   8%|▊         | 85/1000 [1:33:02<17:09:14, 67.49s/it, lr=1.56e-5, test_MAE=0.787, time=67.6, train_MAE=0.676, train_loss=0.676, val_MAE=0.706, val_loss=0.706]Epoch 85:   8%|▊         | 85/1000 [1:33:02<17:09:14, 67.49s/it, lr=1.56e-5, test_MAE=0.787, time=67.6, train_MAE=0.676, train_loss=0.676, val_MAE=0.706, val_loss=0.706]Epoch 85:   8%|▊         | 85/1000 [1:34:09<17:09:14, 67.49s/it, lr=1.56e-5, test_MAE=0.784, time=67.7, train_MAE=0.67, train_loss=0.67, val_MAE=0.704, val_loss=0.704]  Epoch 85:   9%|▊         | 86/1000 [1:34:09<17:09:13, 67.56s/it, lr=1.56e-5, test_MAE=0.784, time=67.7, train_MAE=0.67, train_loss=0.67, val_MAE=0.704, val_loss=0.704]Epoch 86:   9%|▊         | 86/1000 [1:34:09<17:09:13, 67.56s/it, lr=1.56e-5, test_MAE=0.784, time=67.7, train_MAE=0.67, train_loss=0.67, val_MAE=0.704, val_loss=0.704]Epoch 86:   9%|▊         | 86/1000 [1:35:16<17:09:13, 67.56s/it, lr=1.56e-5, test_MAE=0.786, time=67, train_MAE=0.676, train_loss=0.676, val_MAE=0.702, val_loss=0.702]Epoch    87: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 86:   9%|▊         | 86/1000 [1:35:16<16:52:39, 66.48s/it, lr=1.56e-5, test_MAE=0.786, time=67, train_MAE=0.676, train_loss=0.676, val_MAE=0.702, val_loss=0.702]
Test MAE: 0.7855
Train MAE: 0.6591
Convergence Time (Epochs): 86.0000
TOTAL TIME TAKEN: 5749.7573s
AVG TIME PER EPOCH: 65.6759s
