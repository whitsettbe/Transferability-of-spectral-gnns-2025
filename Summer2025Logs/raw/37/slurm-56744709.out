I'm echoing to stdout
I'm echoing to stderr
My JobID is 56744709
I have 8 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.0535s
Dataset: ZINC,
Model: ChebAugmentedFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 2, 'k_aug': 4, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'parallel_simp', 'normalized_laplacian': True, 'post_normalized': False, 'eigval_norm': '', 'num_eigs': 64, 'bias_mode': 'spatial', 'eigval_hidden_dim': 5, 'eigval_num_hidden_layer': 3, 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 0.0, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/zinc_train_rec_full.csv', 'test': 'supp_data/molecules/zinc_test_rec_full.csv', 'val': 'supp_data/molecules/zinc_val_rec_full.csv'}, 'fixMissingPhi1': False, 'extraOrtho': True, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [02:57<?, ?it/s, lr=0.001, test_MAE=0.859, time=178, train_MAE=0.773, train_loss=0.773, val_MAE=0.828, val_loss=0.828]Epoch 0:   0%|          | 1/1000 [02:57<49:17:42, 177.64s/it, lr=0.001, test_MAE=0.859, time=178, train_MAE=0.773, train_loss=0.773, val_MAE=0.828, val_loss=0.828]Epoch 1:   0%|          | 1/1000 [02:57<49:17:42, 177.64s/it, lr=0.001, test_MAE=0.859, time=178, train_MAE=0.773, train_loss=0.773, val_MAE=0.828, val_loss=0.828]Epoch 1:   0%|          | 1/1000 [03:30<49:17:42, 177.64s/it, lr=0.001, test_MAE=0.596, time=32.6, train_MAE=0.595, train_loss=0.595, val_MAE=0.574, val_loss=0.574]Epoch 1:   0%|          | 2/1000 [03:30<37:11:07, 134.14s/it, lr=0.001, test_MAE=0.596, time=32.6, train_MAE=0.595, train_loss=0.595, val_MAE=0.574, val_loss=0.574]Epoch 2:   0%|          | 2/1000 [03:30<37:11:07, 134.14s/it, lr=0.001, test_MAE=0.596, time=32.6, train_MAE=0.595, train_loss=0.595, val_MAE=0.574, val_loss=0.574]Epoch 2:   0%|          | 2/1000 [04:03<37:11:07, 134.14s/it, lr=0.001, test_MAE=0.661, time=33.2, train_MAE=0.591, train_loss=0.591, val_MAE=0.617, val_loss=0.617]Epoch 2:   0%|          | 3/1000 [04:03<28:45:41, 103.85s/it, lr=0.001, test_MAE=0.661, time=33.2, train_MAE=0.591, train_loss=0.591, val_MAE=0.617, val_loss=0.617]Epoch 3:   0%|          | 3/1000 [04:03<28:45:41, 103.85s/it, lr=0.001, test_MAE=0.661, time=33.2, train_MAE=0.591, train_loss=0.591, val_MAE=0.617, val_loss=0.617]Epoch 3:   0%|          | 3/1000 [04:36<28:45:41, 103.85s/it, lr=0.001, test_MAE=0.627, time=33.3, train_MAE=0.563, train_loss=0.563, val_MAE=0.61, val_loss=0.61]  Epoch 3:   0%|          | 4/1000 [04:36<22:52:38, 82.69s/it, lr=0.001, test_MAE=0.627, time=33.3, train_MAE=0.563, train_loss=0.563, val_MAE=0.61, val_loss=0.61] Epoch 4:   0%|          | 4/1000 [04:36<22:52:38, 82.69s/it, lr=0.001, test_MAE=0.627, time=33.3, train_MAE=0.563, train_loss=0.563, val_MAE=0.61, val_loss=0.61]Epoch 4:   0%|          | 4/1000 [05:09<22:52:38, 82.69s/it, lr=0.001, test_MAE=1.35, time=32.8, train_MAE=0.55, train_loss=0.55, val_MAE=1.3, val_loss=1.3]     Epoch 4:   0%|          | 5/1000 [05:09<18:43:24, 67.74s/it, lr=0.001, test_MAE=1.35, time=32.8, train_MAE=0.55, train_loss=0.55, val_MAE=1.3, val_loss=1.3]Epoch 5:   0%|          | 5/1000 [05:09<18:43:24, 67.74s/it, lr=0.001, test_MAE=1.35, time=32.8, train_MAE=0.55, train_loss=0.55, val_MAE=1.3, val_loss=1.3]Epoch 5:   0%|          | 5/1000 [05:42<18:43:24, 67.74s/it, lr=0.001, test_MAE=1.59, time=33, train_MAE=0.551, train_loss=0.551, val_MAE=1.58, val_loss=1.58]Epoch 5:   1%|          | 6/1000 [05:42<15:49:39, 57.32s/it, lr=0.001, test_MAE=1.59, time=33, train_MAE=0.551, train_loss=0.551, val_MAE=1.58, val_loss=1.58]Epoch 6:   1%|          | 6/1000 [05:42<15:49:39, 57.32s/it, lr=0.001, test_MAE=1.59, time=33, train_MAE=0.551, train_loss=0.551, val_MAE=1.58, val_loss=1.58]Epoch 6:   1%|          | 6/1000 [06:15<15:49:39, 57.32s/it, lr=0.001, test_MAE=0.996, time=33.2, train_MAE=0.536, train_loss=0.536, val_MAE=0.943, val_loss=0.943]Epoch 6:   1%|          | 7/1000 [06:15<13:49:10, 50.10s/it, lr=0.001, test_MAE=0.996, time=33.2, train_MAE=0.536, train_loss=0.536, val_MAE=0.943, val_loss=0.943]Epoch 7:   1%|          | 7/1000 [06:15<13:49:10, 50.10s/it, lr=0.001, test_MAE=0.996, time=33.2, train_MAE=0.536, train_loss=0.536, val_MAE=0.943, val_loss=0.943]Epoch 7:   1%|          | 7/1000 [06:48<13:49:10, 50.10s/it, lr=0.001, test_MAE=0.609, time=32.9, train_MAE=0.511, train_loss=0.511, val_MAE=0.582, val_loss=0.582]Epoch     8: reducing learning rate of group 0 to 5.0000e-04.
Epoch 7:   1%|          | 8/1000 [06:48<12:23:13, 44.95s/it, lr=0.001, test_MAE=0.609, time=32.9, train_MAE=0.511, train_loss=0.511, val_MAE=0.582, val_loss=0.582]Epoch 8:   1%|          | 8/1000 [06:48<12:23:13, 44.95s/it, lr=0.001, test_MAE=0.609, time=32.9, train_MAE=0.511, train_loss=0.511, val_MAE=0.582, val_loss=0.582]Epoch 8:   1%|          | 8/1000 [07:21<12:23:13, 44.95s/it, lr=0.0005, test_MAE=0.534, time=32.9, train_MAE=0.476, train_loss=0.476, val_MAE=0.504, val_loss=0.504]Epoch 8:   1%|          | 9/1000 [07:21<11:22:49, 41.34s/it, lr=0.0005, test_MAE=0.534, time=32.9, train_MAE=0.476, train_loss=0.476, val_MAE=0.504, val_loss=0.504]Epoch 9:   1%|          | 9/1000 [07:21<11:22:49, 41.34s/it, lr=0.0005, test_MAE=0.534, time=32.9, train_MAE=0.476, train_loss=0.476, val_MAE=0.504, val_loss=0.504]Epoch 9:   1%|          | 9/1000 [07:54<11:22:49, 41.34s/it, lr=0.0005, test_MAE=0.688, time=32.9, train_MAE=0.478, train_loss=0.478, val_MAE=0.662, val_loss=0.662]Epoch 9:   1%|          | 10/1000 [07:54<10:40:39, 38.83s/it, lr=0.0005, test_MAE=0.688, time=32.9, train_MAE=0.478, train_loss=0.478, val_MAE=0.662, val_loss=0.662]Epoch 10:   1%|          | 10/1000 [07:54<10:40:39, 38.83s/it, lr=0.0005, test_MAE=0.688, time=32.9, train_MAE=0.478, train_loss=0.478, val_MAE=0.662, val_loss=0.662]Epoch 10:   1%|          | 10/1000 [08:27<10:40:39, 38.83s/it, lr=0.0005, test_MAE=0.805, time=33.2, train_MAE=0.472, train_loss=0.472, val_MAE=0.773, val_loss=0.773]Epoch 10:   1%|          | 11/1000 [08:27<10:12:12, 37.14s/it, lr=0.0005, test_MAE=0.805, time=33.2, train_MAE=0.472, train_loss=0.472, val_MAE=0.773, val_loss=0.773]Epoch 11:   1%|          | 11/1000 [08:27<10:12:12, 37.14s/it, lr=0.0005, test_MAE=0.805, time=33.2, train_MAE=0.472, train_loss=0.472, val_MAE=0.773, val_loss=0.773]Epoch 11:   1%|          | 11/1000 [09:00<10:12:12, 37.14s/it, lr=0.0005, test_MAE=0.597, time=32.7, train_MAE=0.456, train_loss=0.456, val_MAE=0.565, val_loss=0.565]Epoch 11:   1%|          | 12/1000 [09:00<9:49:41, 35.81s/it, lr=0.0005, test_MAE=0.597, time=32.7, train_MAE=0.456, train_loss=0.456, val_MAE=0.565, val_loss=0.565] Epoch 12:   1%|          | 12/1000 [09:00<9:49:41, 35.81s/it, lr=0.0005, test_MAE=0.597, time=32.7, train_MAE=0.456, train_loss=0.456, val_MAE=0.565, val_loss=0.565]Epoch 12:   1%|          | 12/1000 [09:33<9:49:41, 35.81s/it, lr=0.0005, test_MAE=0.485, time=32.6, train_MAE=0.47, train_loss=0.47, val_MAE=0.469, val_loss=0.469]  Epoch 12:   1%|▏         | 13/1000 [09:33<9:33:15, 34.85s/it, lr=0.0005, test_MAE=0.485, time=32.6, train_MAE=0.47, train_loss=0.47, val_MAE=0.469, val_loss=0.469]Epoch 13:   1%|▏         | 13/1000 [09:33<9:33:15, 34.85s/it, lr=0.0005, test_MAE=0.485, time=32.6, train_MAE=0.47, train_loss=0.47, val_MAE=0.469, val_loss=0.469]Epoch 13:   1%|▏         | 13/1000 [10:06<9:33:15, 34.85s/it, lr=0.0005, test_MAE=0.497, time=32.9, train_MAE=0.464, train_loss=0.464, val_MAE=0.47, val_loss=0.47]Epoch 13:   1%|▏         | 14/1000 [10:06<9:22:57, 34.26s/it, lr=0.0005, test_MAE=0.497, time=32.9, train_MAE=0.464, train_loss=0.464, val_MAE=0.47, val_loss=0.47]Epoch 14:   1%|▏         | 14/1000 [10:06<9:22:57, 34.26s/it, lr=0.0005, test_MAE=0.497, time=32.9, train_MAE=0.464, train_loss=0.464, val_MAE=0.47, val_loss=0.47]Epoch 14:   1%|▏         | 14/1000 [10:38<9:22:57, 34.26s/it, lr=0.0005, test_MAE=1.61, time=32.6, train_MAE=0.438, train_loss=0.438, val_MAE=1.6, val_loss=1.6]   Epoch 14:   2%|▏         | 15/1000 [10:38<9:14:09, 33.76s/it, lr=0.0005, test_MAE=1.61, time=32.6, train_MAE=0.438, train_loss=0.438, val_MAE=1.6, val_loss=1.6]Epoch 15:   2%|▏         | 15/1000 [10:38<9:14:09, 33.76s/it, lr=0.0005, test_MAE=1.61, time=32.6, train_MAE=0.438, train_loss=0.438, val_MAE=1.6, val_loss=1.6]Epoch 15:   2%|▏         | 15/1000 [11:11<9:14:09, 33.76s/it, lr=0.0005, test_MAE=0.716, time=32.8, train_MAE=0.445, train_loss=0.445, val_MAE=0.681, val_loss=0.681]Epoch 15:   2%|▏         | 16/1000 [11:11<9:08:42, 33.46s/it, lr=0.0005, test_MAE=0.716, time=32.8, train_MAE=0.445, train_loss=0.445, val_MAE=0.681, val_loss=0.681]Epoch 16:   2%|▏         | 16/1000 [11:11<9:08:42, 33.46s/it, lr=0.0005, test_MAE=0.716, time=32.8, train_MAE=0.445, train_loss=0.445, val_MAE=0.681, val_loss=0.681]Epoch 16:   2%|▏         | 16/1000 [11:44<9:08:42, 33.46s/it, lr=0.0005, test_MAE=0.876, time=32.6, train_MAE=0.443, train_loss=0.443, val_MAE=0.851, val_loss=0.851]Epoch 16:   2%|▏         | 17/1000 [11:44<9:03:54, 33.20s/it, lr=0.0005, test_MAE=0.876, time=32.6, train_MAE=0.443, train_loss=0.443, val_MAE=0.851, val_loss=0.851]Epoch 17:   2%|▏         | 17/1000 [11:44<9:03:54, 33.20s/it, lr=0.0005, test_MAE=0.876, time=32.6, train_MAE=0.443, train_loss=0.443, val_MAE=0.851, val_loss=0.851]Epoch 17:   2%|▏         | 17/1000 [12:16<9:03:54, 33.20s/it, lr=0.0005, test_MAE=0.568, time=32.9, train_MAE=0.434, train_loss=0.434, val_MAE=0.546, val_loss=0.546]Epoch 17:   2%|▏         | 18/1000 [12:16<9:02:00, 33.12s/it, lr=0.0005, test_MAE=0.568, time=32.9, train_MAE=0.434, train_loss=0.434, val_MAE=0.546, val_loss=0.546]Epoch 18:   2%|▏         | 18/1000 [12:16<9:02:00, 33.12s/it, lr=0.0005, test_MAE=0.568, time=32.9, train_MAE=0.434, train_loss=0.434, val_MAE=0.546, val_loss=0.546]Epoch 18:   2%|▏         | 18/1000 [12:49<9:02:00, 33.12s/it, lr=0.0005, test_MAE=0.49, time=32.8, train_MAE=0.443, train_loss=0.443, val_MAE=0.47, val_loss=0.47]   Epoch    19: reducing learning rate of group 0 to 2.5000e-04.
Epoch 18:   2%|▏         | 19/1000 [12:49<9:00:11, 33.04s/it, lr=0.0005, test_MAE=0.49, time=32.8, train_MAE=0.443, train_loss=0.443, val_MAE=0.47, val_loss=0.47]Epoch 19:   2%|▏         | 19/1000 [12:49<9:00:11, 33.04s/it, lr=0.0005, test_MAE=0.49, time=32.8, train_MAE=0.443, train_loss=0.443, val_MAE=0.47, val_loss=0.47]Epoch 19:   2%|▏         | 19/1000 [13:22<9:00:11, 33.04s/it, lr=0.00025, test_MAE=0.448, time=32.3, train_MAE=0.414, train_loss=0.414, val_MAE=0.435, val_loss=0.435]Epoch 19:   2%|▏         | 20/1000 [13:22<8:56:04, 32.82s/it, lr=0.00025, test_MAE=0.448, time=32.3, train_MAE=0.414, train_loss=0.414, val_MAE=0.435, val_loss=0.435]Epoch 20:   2%|▏         | 20/1000 [13:22<8:56:04, 32.82s/it, lr=0.00025, test_MAE=0.448, time=32.3, train_MAE=0.414, train_loss=0.414, val_MAE=0.435, val_loss=0.435]Epoch 20:   2%|▏         | 20/1000 [13:54<8:56:04, 32.82s/it, lr=0.00025, test_MAE=0.652, time=32.8, train_MAE=0.41, train_loss=0.41, val_MAE=0.626, val_loss=0.626]  Epoch 20:   2%|▏         | 21/1000 [13:54<8:55:34, 32.82s/it, lr=0.00025, test_MAE=0.652, time=32.8, train_MAE=0.41, train_loss=0.41, val_MAE=0.626, val_loss=0.626]Epoch 21:   2%|▏         | 21/1000 [13:54<8:55:34, 32.82s/it, lr=0.00025, test_MAE=0.652, time=32.8, train_MAE=0.41, train_loss=0.41, val_MAE=0.626, val_loss=0.626]Epoch 21:   2%|▏         | 21/1000 [14:27<8:55:34, 32.82s/it, lr=0.00025, test_MAE=0.454, time=33, train_MAE=0.41, train_loss=0.41, val_MAE=0.434, val_loss=0.434]  Epoch 21:   2%|▏         | 22/1000 [14:27<8:55:53, 32.88s/it, lr=0.00025, test_MAE=0.454, time=33, train_MAE=0.41, train_loss=0.41, val_MAE=0.434, val_loss=0.434]Epoch 22:   2%|▏         | 22/1000 [14:27<8:55:53, 32.88s/it, lr=0.00025, test_MAE=0.454, time=33, train_MAE=0.41, train_loss=0.41, val_MAE=0.434, val_loss=0.434]Epoch 22:   2%|▏         | 22/1000 [15:00<8:55:53, 32.88s/it, lr=0.00025, test_MAE=0.447, time=32.2, train_MAE=0.405, train_loss=0.405, val_MAE=0.437, val_loss=0.437]Epoch 22:   2%|▏         | 23/1000 [15:00<8:52:06, 32.68s/it, lr=0.00025, test_MAE=0.447, time=32.2, train_MAE=0.405, train_loss=0.405, val_MAE=0.437, val_loss=0.437]Epoch 23:   2%|▏         | 23/1000 [15:00<8:52:06, 32.68s/it, lr=0.00025, test_MAE=0.447, time=32.2, train_MAE=0.405, train_loss=0.405, val_MAE=0.437, val_loss=0.437]Epoch 23:   2%|▏         | 23/1000 [15:32<8:52:06, 32.68s/it, lr=0.00025, test_MAE=0.447, time=32.6, train_MAE=0.405, train_loss=0.405, val_MAE=0.433, val_loss=0.433]Epoch 23:   2%|▏         | 24/1000 [15:32<8:51:19, 32.66s/it, lr=0.00025, test_MAE=0.447, time=32.6, train_MAE=0.405, train_loss=0.405, val_MAE=0.433, val_loss=0.433]Epoch 24:   2%|▏         | 24/1000 [15:32<8:51:19, 32.66s/it, lr=0.00025, test_MAE=0.447, time=32.6, train_MAE=0.405, train_loss=0.405, val_MAE=0.433, val_loss=0.433]Epoch 24:   2%|▏         | 24/1000 [16:05<8:51:19, 32.66s/it, lr=0.00025, test_MAE=0.448, time=32.8, train_MAE=0.413, train_loss=0.413, val_MAE=0.445, val_loss=0.445]Epoch 24:   2%|▎         | 25/1000 [16:05<8:51:44, 32.72s/it, lr=0.00025, test_MAE=0.448, time=32.8, train_MAE=0.413, train_loss=0.413, val_MAE=0.445, val_loss=0.445]Epoch 25:   2%|▎         | 25/1000 [16:05<8:51:44, 32.72s/it, lr=0.00025, test_MAE=0.448, time=32.8, train_MAE=0.413, train_loss=0.413, val_MAE=0.445, val_loss=0.445]Epoch 25:   2%|▎         | 25/1000 [16:38<8:51:44, 32.72s/it, lr=0.00025, test_MAE=0.536, time=32.9, train_MAE=0.415, train_loss=0.415, val_MAE=0.517, val_loss=0.517]Epoch 25:   3%|▎         | 26/1000 [16:38<8:52:20, 32.79s/it, lr=0.00025, test_MAE=0.536, time=32.9, train_MAE=0.415, train_loss=0.415, val_MAE=0.517, val_loss=0.517]Epoch 26:   3%|▎         | 26/1000 [16:38<8:52:20, 32.79s/it, lr=0.00025, test_MAE=0.536, time=32.9, train_MAE=0.415, train_loss=0.415, val_MAE=0.517, val_loss=0.517]Epoch 26:   3%|▎         | 26/1000 [17:10<8:52:20, 32.79s/it, lr=0.00025, test_MAE=0.513, time=32.3, train_MAE=0.394, train_loss=0.394, val_MAE=0.497, val_loss=0.497]Epoch 26:   3%|▎         | 27/1000 [17:10<8:49:25, 32.65s/it, lr=0.00025, test_MAE=0.513, time=32.3, train_MAE=0.394, train_loss=0.394, val_MAE=0.497, val_loss=0.497]Epoch 27:   3%|▎         | 27/1000 [17:10<8:49:25, 32.65s/it, lr=0.00025, test_MAE=0.513, time=32.3, train_MAE=0.394, train_loss=0.394, val_MAE=0.497, val_loss=0.497]Epoch 27:   3%|▎         | 27/1000 [17:44<8:49:25, 32.65s/it, lr=0.00025, test_MAE=0.75, time=33.2, train_MAE=0.402, train_loss=0.402, val_MAE=0.737, val_loss=0.737] Epoch 27:   3%|▎         | 28/1000 [17:44<8:51:41, 32.82s/it, lr=0.00025, test_MAE=0.75, time=33.2, train_MAE=0.402, train_loss=0.402, val_MAE=0.737, val_loss=0.737]Epoch 28:   3%|▎         | 28/1000 [17:44<8:51:41, 32.82s/it, lr=0.00025, test_MAE=0.75, time=33.2, train_MAE=0.402, train_loss=0.402, val_MAE=0.737, val_loss=0.737]Epoch 28:   3%|▎         | 28/1000 [18:17<8:51:41, 32.82s/it, lr=0.00025, test_MAE=0.745, time=33.8, train_MAE=0.399, train_loss=0.399, val_MAE=0.721, val_loss=0.721]Epoch 28:   3%|▎         | 29/1000 [18:17<8:55:57, 33.12s/it, lr=0.00025, test_MAE=0.745, time=33.8, train_MAE=0.399, train_loss=0.399, val_MAE=0.721, val_loss=0.721]Epoch 29:   3%|▎         | 29/1000 [18:17<8:55:57, 33.12s/it, lr=0.00025, test_MAE=0.745, time=33.8, train_MAE=0.399, train_loss=0.399, val_MAE=0.721, val_loss=0.721]Epoch 29:   3%|▎         | 29/1000 [18:51<8:55:57, 33.12s/it, lr=0.00025, test_MAE=0.438, time=33, train_MAE=0.398, train_loss=0.398, val_MAE=0.427, val_loss=0.427]  Epoch 29:   3%|▎         | 30/1000 [18:51<8:55:09, 33.10s/it, lr=0.00025, test_MAE=0.438, time=33, train_MAE=0.398, train_loss=0.398, val_MAE=0.427, val_loss=0.427]Epoch 30:   3%|▎         | 30/1000 [18:51<8:55:09, 33.10s/it, lr=0.00025, test_MAE=0.438, time=33, train_MAE=0.398, train_loss=0.398, val_MAE=0.427, val_loss=0.427]Epoch 30:   3%|▎         | 30/1000 [19:24<8:55:09, 33.10s/it, lr=0.00025, test_MAE=0.433, time=33.4, train_MAE=0.4, train_loss=0.4, val_MAE=0.426, val_loss=0.426]  Epoch 30:   3%|▎         | 31/1000 [19:24<8:56:12, 33.20s/it, lr=0.00025, test_MAE=0.433, time=33.4, train_MAE=0.4, train_loss=0.4, val_MAE=0.426, val_loss=0.426]Epoch 31:   3%|▎         | 31/1000 [19:24<8:56:12, 33.20s/it, lr=0.00025, test_MAE=0.433, time=33.4, train_MAE=0.4, train_loss=0.4, val_MAE=0.426, val_loss=0.426]Epoch 31:   3%|▎         | 31/1000 [19:58<8:56:12, 33.20s/it, lr=0.00025, test_MAE=0.491, time=34, train_MAE=0.387, train_loss=0.387, val_MAE=0.476, val_loss=0.476]Epoch 31:   3%|▎         | 32/1000 [19:58<8:59:45, 33.46s/it, lr=0.00025, test_MAE=0.491, time=34, train_MAE=0.387, train_loss=0.387, val_MAE=0.476, val_loss=0.476]Epoch 32:   3%|▎         | 32/1000 [19:58<8:59:45, 33.46s/it, lr=0.00025, test_MAE=0.491, time=34, train_MAE=0.387, train_loss=0.387, val_MAE=0.476, val_loss=0.476]Epoch 32:   3%|▎         | 32/1000 [20:32<8:59:45, 33.46s/it, lr=0.00025, test_MAE=0.527, time=33.6, train_MAE=0.396, train_loss=0.396, val_MAE=0.512, val_loss=0.512]Epoch 32:   3%|▎         | 33/1000 [20:32<8:59:59, 33.51s/it, lr=0.00025, test_MAE=0.527, time=33.6, train_MAE=0.396, train_loss=0.396, val_MAE=0.512, val_loss=0.512]Epoch 33:   3%|▎         | 33/1000 [20:32<8:59:59, 33.51s/it, lr=0.00025, test_MAE=0.527, time=33.6, train_MAE=0.396, train_loss=0.396, val_MAE=0.512, val_loss=0.512]Epoch 33:   3%|▎         | 33/1000 [21:05<8:59:59, 33.51s/it, lr=0.00025, test_MAE=0.467, time=33.7, train_MAE=0.378, train_loss=0.378, val_MAE=0.45, val_loss=0.45]  Epoch 33:   3%|▎         | 34/1000 [21:05<9:00:13, 33.55s/it, lr=0.00025, test_MAE=0.467, time=33.7, train_MAE=0.378, train_loss=0.378, val_MAE=0.45, val_loss=0.45]Epoch 34:   3%|▎         | 34/1000 [21:05<9:00:13, 33.55s/it, lr=0.00025, test_MAE=0.467, time=33.7, train_MAE=0.378, train_loss=0.378, val_MAE=0.45, val_loss=0.45]Epoch 34:   3%|▎         | 34/1000 [21:39<9:00:13, 33.55s/it, lr=0.00025, test_MAE=0.488, time=33.4, train_MAE=0.392, train_loss=0.392, val_MAE=0.465, val_loss=0.465]Epoch 34:   4%|▎         | 35/1000 [21:39<8:59:08, 33.52s/it, lr=0.00025, test_MAE=0.488, time=33.4, train_MAE=0.392, train_loss=0.392, val_MAE=0.465, val_loss=0.465]Epoch 35:   4%|▎         | 35/1000 [21:39<8:59:08, 33.52s/it, lr=0.00025, test_MAE=0.488, time=33.4, train_MAE=0.392, train_loss=0.392, val_MAE=0.465, val_loss=0.465]Epoch 35:   4%|▎         | 35/1000 [22:13<8:59:08, 33.52s/it, lr=0.00025, test_MAE=0.501, time=33.8, train_MAE=0.376, train_loss=0.376, val_MAE=0.486, val_loss=0.486]Epoch 35:   4%|▎         | 36/1000 [22:13<9:00:08, 33.62s/it, lr=0.00025, test_MAE=0.501, time=33.8, train_MAE=0.376, train_loss=0.376, val_MAE=0.486, val_loss=0.486]Epoch 36:   4%|▎         | 36/1000 [22:13<9:00:08, 33.62s/it, lr=0.00025, test_MAE=0.501, time=33.8, train_MAE=0.376, train_loss=0.376, val_MAE=0.486, val_loss=0.486]Epoch 36:   4%|▎         | 36/1000 [22:46<9:00:08, 33.62s/it, lr=0.00025, test_MAE=0.631, time=33, train_MAE=0.378, train_loss=0.378, val_MAE=0.609, val_loss=0.609]  Epoch    37: reducing learning rate of group 0 to 1.2500e-04.
Epoch 36:   4%|▎         | 37/1000 [22:46<8:56:33, 33.43s/it, lr=0.00025, test_MAE=0.631, time=33, train_MAE=0.378, train_loss=0.378, val_MAE=0.609, val_loss=0.609]Epoch 37:   4%|▎         | 37/1000 [22:46<8:56:33, 33.43s/it, lr=0.00025, test_MAE=0.631, time=33, train_MAE=0.378, train_loss=0.378, val_MAE=0.609, val_loss=0.609]Epoch 37:   4%|▎         | 37/1000 [23:19<8:56:33, 33.43s/it, lr=0.000125, test_MAE=0.427, time=33.7, train_MAE=0.365, train_loss=0.365, val_MAE=0.413, val_loss=0.413]Epoch 37:   4%|▍         | 38/1000 [23:19<8:57:17, 33.51s/it, lr=0.000125, test_MAE=0.427, time=33.7, train_MAE=0.365, train_loss=0.365, val_MAE=0.413, val_loss=0.413]Epoch 38:   4%|▍         | 38/1000 [23:19<8:57:17, 33.51s/it, lr=0.000125, test_MAE=0.427, time=33.7, train_MAE=0.365, train_loss=0.365, val_MAE=0.413, val_loss=0.413]Epoch 38:   4%|▍         | 38/1000 [23:54<8:57:17, 33.51s/it, lr=0.000125, test_MAE=0.449, time=34.3, train_MAE=0.363, train_loss=0.363, val_MAE=0.433, val_loss=0.433]Epoch 38:   4%|▍         | 39/1000 [23:54<9:00:23, 33.74s/it, lr=0.000125, test_MAE=0.449, time=34.3, train_MAE=0.363, train_loss=0.363, val_MAE=0.433, val_loss=0.433]Epoch 39:   4%|▍         | 39/1000 [23:54<9:00:23, 33.74s/it, lr=0.000125, test_MAE=0.449, time=34.3, train_MAE=0.363, train_loss=0.363, val_MAE=0.433, val_loss=0.433]Epoch 39:   4%|▍         | 39/1000 [24:27<9:00:23, 33.74s/it, lr=0.000125, test_MAE=0.488, time=33.1, train_MAE=0.365, train_loss=0.365, val_MAE=0.464, val_loss=0.464]Epoch 39:   4%|▍         | 40/1000 [24:27<8:56:50, 33.55s/it, lr=0.000125, test_MAE=0.488, time=33.1, train_MAE=0.365, train_loss=0.365, val_MAE=0.464, val_loss=0.464]Epoch 40:   4%|▍         | 40/1000 [24:27<8:56:50, 33.55s/it, lr=0.000125, test_MAE=0.488, time=33.1, train_MAE=0.365, train_loss=0.365, val_MAE=0.464, val_loss=0.464]Epoch 40:   4%|▍         | 40/1000 [25:00<8:56:50, 33.55s/it, lr=0.000125, test_MAE=0.441, time=33.6, train_MAE=0.367, train_loss=0.367, val_MAE=0.426, val_loss=0.426]Epoch 40:   4%|▍         | 41/1000 [25:00<8:56:41, 33.58s/it, lr=0.000125, test_MAE=0.441, time=33.6, train_MAE=0.367, train_loss=0.367, val_MAE=0.426, val_loss=0.426]Epoch 41:   4%|▍         | 41/1000 [25:00<8:56:41, 33.58s/it, lr=0.000125, test_MAE=0.441, time=33.6, train_MAE=0.367, train_loss=0.367, val_MAE=0.426, val_loss=0.426]Epoch 41:   4%|▍         | 41/1000 [25:34<8:56:41, 33.58s/it, lr=0.000125, test_MAE=0.476, time=33.6, train_MAE=0.358, train_loss=0.358, val_MAE=0.462, val_loss=0.462]Epoch 41:   4%|▍         | 42/1000 [25:34<8:56:17, 33.59s/it, lr=0.000125, test_MAE=0.476, time=33.6, train_MAE=0.358, train_loss=0.358, val_MAE=0.462, val_loss=0.462]Epoch 42:   4%|▍         | 42/1000 [25:34<8:56:17, 33.59s/it, lr=0.000125, test_MAE=0.476, time=33.6, train_MAE=0.358, train_loss=0.358, val_MAE=0.462, val_loss=0.462]Epoch 42:   4%|▍         | 42/1000 [26:07<8:56:17, 33.59s/it, lr=0.000125, test_MAE=0.523, time=33.3, train_MAE=0.362, train_loss=0.362, val_MAE=0.502, val_loss=0.502]Epoch 42:   4%|▍         | 43/1000 [26:07<8:54:28, 33.51s/it, lr=0.000125, test_MAE=0.523, time=33.3, train_MAE=0.362, train_loss=0.362, val_MAE=0.502, val_loss=0.502]Epoch 43:   4%|▍         | 43/1000 [26:07<8:54:28, 33.51s/it, lr=0.000125, test_MAE=0.523, time=33.3, train_MAE=0.362, train_loss=0.362, val_MAE=0.502, val_loss=0.502]Epoch 43:   4%|▍         | 43/1000 [26:41<8:54:28, 33.51s/it, lr=0.000125, test_MAE=0.438, time=33.6, train_MAE=0.366, train_loss=0.366, val_MAE=0.42, val_loss=0.42]  Epoch    44: reducing learning rate of group 0 to 6.2500e-05.
Epoch 43:   4%|▍         | 44/1000 [26:41<8:54:16, 33.53s/it, lr=0.000125, test_MAE=0.438, time=33.6, train_MAE=0.366, train_loss=0.366, val_MAE=0.42, val_loss=0.42]Epoch 44:   4%|▍         | 44/1000 [26:41<8:54:16, 33.53s/it, lr=0.000125, test_MAE=0.438, time=33.6, train_MAE=0.366, train_loss=0.366, val_MAE=0.42, val_loss=0.42]Epoch 44:   4%|▍         | 44/1000 [27:14<8:54:16, 33.53s/it, lr=6.25e-5, test_MAE=0.444, time=33.4, train_MAE=0.356, train_loss=0.356, val_MAE=0.427, val_loss=0.427]Epoch 44:   4%|▍         | 45/1000 [27:14<8:53:01, 33.49s/it, lr=6.25e-5, test_MAE=0.444, time=33.4, train_MAE=0.356, train_loss=0.356, val_MAE=0.427, val_loss=0.427]Epoch 45:   4%|▍         | 45/1000 [27:14<8:53:01, 33.49s/it, lr=6.25e-5, test_MAE=0.444, time=33.4, train_MAE=0.356, train_loss=0.356, val_MAE=0.427, val_loss=0.427]Epoch 45:   4%|▍         | 45/1000 [27:48<8:53:01, 33.49s/it, lr=6.25e-5, test_MAE=0.425, time=33.6, train_MAE=0.348, train_loss=0.348, val_MAE=0.413, val_loss=0.413]Epoch 45:   5%|▍         | 46/1000 [27:48<8:52:59, 33.52s/it, lr=6.25e-5, test_MAE=0.425, time=33.6, train_MAE=0.348, train_loss=0.348, val_MAE=0.413, val_loss=0.413]Epoch 46:   5%|▍         | 46/1000 [27:48<8:52:59, 33.52s/it, lr=6.25e-5, test_MAE=0.425, time=33.6, train_MAE=0.348, train_loss=0.348, val_MAE=0.413, val_loss=0.413]Epoch 46:   5%|▍         | 46/1000 [28:22<8:52:59, 33.52s/it, lr=6.25e-5, test_MAE=0.454, time=33.9, train_MAE=0.353, train_loss=0.353, val_MAE=0.438, val_loss=0.438]Epoch 46:   5%|▍         | 47/1000 [28:22<8:54:06, 33.63s/it, lr=6.25e-5, test_MAE=0.454, time=33.9, train_MAE=0.353, train_loss=0.353, val_MAE=0.438, val_loss=0.438]Epoch 47:   5%|▍         | 47/1000 [28:22<8:54:06, 33.63s/it, lr=6.25e-5, test_MAE=0.454, time=33.9, train_MAE=0.353, train_loss=0.353, val_MAE=0.438, val_loss=0.438]Epoch 47:   5%|▍         | 47/1000 [28:55<8:54:06, 33.63s/it, lr=6.25e-5, test_MAE=0.455, time=33.2, train_MAE=0.351, train_loss=0.351, val_MAE=0.438, val_loss=0.438]Epoch 47:   5%|▍         | 48/1000 [28:55<8:51:29, 33.50s/it, lr=6.25e-5, test_MAE=0.455, time=33.2, train_MAE=0.351, train_loss=0.351, val_MAE=0.438, val_loss=0.438]Epoch 48:   5%|▍         | 48/1000 [28:55<8:51:29, 33.50s/it, lr=6.25e-5, test_MAE=0.455, time=33.2, train_MAE=0.351, train_loss=0.351, val_MAE=0.438, val_loss=0.438]Epoch 48:   5%|▍         | 48/1000 [29:28<8:51:29, 33.50s/it, lr=6.25e-5, test_MAE=0.422, time=33.5, train_MAE=0.345, train_loss=0.345, val_MAE=0.404, val_loss=0.404]Epoch 48:   5%|▍         | 49/1000 [29:28<8:51:04, 33.51s/it, lr=6.25e-5, test_MAE=0.422, time=33.5, train_MAE=0.345, train_loss=0.345, val_MAE=0.404, val_loss=0.404]Epoch 49:   5%|▍         | 49/1000 [29:28<8:51:04, 33.51s/it, lr=6.25e-5, test_MAE=0.422, time=33.5, train_MAE=0.345, train_loss=0.345, val_MAE=0.404, val_loss=0.404]Epoch 49:   5%|▍         | 49/1000 [30:02<8:51:04, 33.51s/it, lr=6.25e-5, test_MAE=0.424, time=33.8, train_MAE=0.351, train_loss=0.351, val_MAE=0.407, val_loss=0.407]Epoch 49:   5%|▌         | 50/1000 [30:02<8:51:56, 33.60s/it, lr=6.25e-5, test_MAE=0.424, time=33.8, train_MAE=0.351, train_loss=0.351, val_MAE=0.407, val_loss=0.407]Epoch 50:   5%|▌         | 50/1000 [30:02<8:51:56, 33.60s/it, lr=6.25e-5, test_MAE=0.424, time=33.8, train_MAE=0.351, train_loss=0.351, val_MAE=0.407, val_loss=0.407]Epoch 50:   5%|▌         | 50/1000 [30:36<8:51:56, 33.60s/it, lr=6.25e-5, test_MAE=0.428, time=33.3, train_MAE=0.349, train_loss=0.349, val_MAE=0.412, val_loss=0.412]Epoch 50:   5%|▌         | 51/1000 [30:36<8:49:59, 33.51s/it, lr=6.25e-5, test_MAE=0.428, time=33.3, train_MAE=0.349, train_loss=0.349, val_MAE=0.412, val_loss=0.412]Epoch 51:   5%|▌         | 51/1000 [30:36<8:49:59, 33.51s/it, lr=6.25e-5, test_MAE=0.428, time=33.3, train_MAE=0.349, train_loss=0.349, val_MAE=0.412, val_loss=0.412]Epoch 51:   5%|▌         | 51/1000 [31:08<8:49:59, 33.51s/it, lr=6.25e-5, test_MAE=0.47, time=32.9, train_MAE=0.356, train_loss=0.356, val_MAE=0.452, val_loss=0.452] Epoch 51:   5%|▌         | 52/1000 [31:08<8:46:48, 33.34s/it, lr=6.25e-5, test_MAE=0.47, time=32.9, train_MAE=0.356, train_loss=0.356, val_MAE=0.452, val_loss=0.452]Epoch 52:   5%|▌         | 52/1000 [31:08<8:46:48, 33.34s/it, lr=6.25e-5, test_MAE=0.47, time=32.9, train_MAE=0.356, train_loss=0.356, val_MAE=0.452, val_loss=0.452]Epoch 52:   5%|▌         | 52/1000 [31:43<8:46:48, 33.34s/it, lr=6.25e-5, test_MAE=0.446, time=34.1, train_MAE=0.347, train_loss=0.347, val_MAE=0.431, val_loss=0.431]Epoch 52:   5%|▌         | 53/1000 [31:43<8:50:03, 33.58s/it, lr=6.25e-5, test_MAE=0.446, time=34.1, train_MAE=0.347, train_loss=0.347, val_MAE=0.431, val_loss=0.431]Epoch 53:   5%|▌         | 53/1000 [31:43<8:50:03, 33.58s/it, lr=6.25e-5, test_MAE=0.446, time=34.1, train_MAE=0.347, train_loss=0.347, val_MAE=0.431, val_loss=0.431]Epoch 53:   5%|▌         | 53/1000 [32:16<8:50:03, 33.58s/it, lr=6.25e-5, test_MAE=0.455, time=33.6, train_MAE=0.348, train_loss=0.348, val_MAE=0.439, val_loss=0.439]Epoch 53:   5%|▌         | 54/1000 [32:16<8:49:43, 33.60s/it, lr=6.25e-5, test_MAE=0.455, time=33.6, train_MAE=0.348, train_loss=0.348, val_MAE=0.439, val_loss=0.439]Epoch 54:   5%|▌         | 54/1000 [32:16<8:49:43, 33.60s/it, lr=6.25e-5, test_MAE=0.455, time=33.6, train_MAE=0.348, train_loss=0.348, val_MAE=0.439, val_loss=0.439]Epoch 54:   5%|▌         | 54/1000 [32:51<8:49:43, 33.60s/it, lr=6.25e-5, test_MAE=0.418, time=34.4, train_MAE=0.346, train_loss=0.346, val_MAE=0.405, val_loss=0.405]Epoch    55: reducing learning rate of group 0 to 3.1250e-05.
Epoch 54:   6%|▌         | 55/1000 [32:51<8:53:05, 33.85s/it, lr=6.25e-5, test_MAE=0.418, time=34.4, train_MAE=0.346, train_loss=0.346, val_MAE=0.405, val_loss=0.405]Epoch 55:   6%|▌         | 55/1000 [32:51<8:53:05, 33.85s/it, lr=6.25e-5, test_MAE=0.418, time=34.4, train_MAE=0.346, train_loss=0.346, val_MAE=0.405, val_loss=0.405]Epoch 55:   6%|▌         | 55/1000 [33:26<8:53:05, 33.85s/it, lr=3.13e-5, test_MAE=0.422, time=35.3, train_MAE=0.346, train_loss=0.346, val_MAE=0.407, val_loss=0.407]Epoch 55:   6%|▌         | 56/1000 [33:26<8:59:20, 34.28s/it, lr=3.13e-5, test_MAE=0.422, time=35.3, train_MAE=0.346, train_loss=0.346, val_MAE=0.407, val_loss=0.407]Epoch 56:   6%|▌         | 56/1000 [33:26<8:59:20, 34.28s/it, lr=3.13e-5, test_MAE=0.422, time=35.3, train_MAE=0.346, train_loss=0.346, val_MAE=0.407, val_loss=0.407]Epoch 56:   6%|▌         | 56/1000 [34:01<8:59:20, 34.28s/it, lr=3.13e-5, test_MAE=0.434, time=35.5, train_MAE=0.346, train_loss=0.346, val_MAE=0.421, val_loss=0.421]Epoch 56:   6%|▌         | 57/1000 [34:02<9:04:34, 34.65s/it, lr=3.13e-5, test_MAE=0.434, time=35.5, train_MAE=0.346, train_loss=0.346, val_MAE=0.421, val_loss=0.421]Epoch 57:   6%|▌         | 57/1000 [34:02<9:04:34, 34.65s/it, lr=3.13e-5, test_MAE=0.434, time=35.5, train_MAE=0.346, train_loss=0.346, val_MAE=0.421, val_loss=0.421]Epoch 57:   6%|▌         | 57/1000 [34:37<9:04:34, 34.65s/it, lr=3.13e-5, test_MAE=0.437, time=35, train_MAE=0.346, train_loss=0.346, val_MAE=0.425, val_loss=0.425]  Epoch 57:   6%|▌         | 58/1000 [34:37<9:05:51, 34.77s/it, lr=3.13e-5, test_MAE=0.437, time=35, train_MAE=0.346, train_loss=0.346, val_MAE=0.425, val_loss=0.425]Epoch 58:   6%|▌         | 58/1000 [34:37<9:05:51, 34.77s/it, lr=3.13e-5, test_MAE=0.437, time=35, train_MAE=0.346, train_loss=0.346, val_MAE=0.425, val_loss=0.425]Epoch 58:   6%|▌         | 58/1000 [35:11<9:05:51, 34.77s/it, lr=3.13e-5, test_MAE=0.42, time=34.2, train_MAE=0.34, train_loss=0.34, val_MAE=0.403, val_loss=0.403] Epoch 58:   6%|▌         | 59/1000 [35:11<9:02:33, 34.59s/it, lr=3.13e-5, test_MAE=0.42, time=34.2, train_MAE=0.34, train_loss=0.34, val_MAE=0.403, val_loss=0.403]Epoch 59:   6%|▌         | 59/1000 [35:11<9:02:33, 34.59s/it, lr=3.13e-5, test_MAE=0.42, time=34.2, train_MAE=0.34, train_loss=0.34, val_MAE=0.403, val_loss=0.403]Epoch 59:   6%|▌         | 59/1000 [35:46<9:02:33, 34.59s/it, lr=3.13e-5, test_MAE=0.458, time=35.4, train_MAE=0.343, train_loss=0.343, val_MAE=0.439, val_loss=0.439]Epoch 59:   6%|▌         | 60/1000 [35:46<9:05:45, 34.84s/it, lr=3.13e-5, test_MAE=0.458, time=35.4, train_MAE=0.343, train_loss=0.343, val_MAE=0.439, val_loss=0.439]Epoch 60:   6%|▌         | 60/1000 [35:46<9:05:45, 34.84s/it, lr=3.13e-5, test_MAE=0.458, time=35.4, train_MAE=0.343, train_loss=0.343, val_MAE=0.439, val_loss=0.439]Epoch 60:   6%|▌         | 60/1000 [36:20<9:05:45, 34.84s/it, lr=3.13e-5, test_MAE=0.455, time=33.8, train_MAE=0.348, train_loss=0.348, val_MAE=0.441, val_loss=0.441]Epoch 60:   6%|▌         | 61/1000 [36:20<9:00:26, 34.53s/it, lr=3.13e-5, test_MAE=0.455, time=33.8, train_MAE=0.348, train_loss=0.348, val_MAE=0.441, val_loss=0.441]Epoch 61:   6%|▌         | 61/1000 [36:20<9:00:26, 34.53s/it, lr=3.13e-5, test_MAE=0.455, time=33.8, train_MAE=0.348, train_loss=0.348, val_MAE=0.441, val_loss=0.441]Epoch 61:   6%|▌         | 61/1000 [36:52<9:00:26, 34.53s/it, lr=3.13e-5, test_MAE=0.44, time=32.5, train_MAE=0.337, train_loss=0.337, val_MAE=0.426, val_loss=0.426] Epoch 61:   6%|▌         | 62/1000 [36:53<8:50:40, 33.95s/it, lr=3.13e-5, test_MAE=0.44, time=32.5, train_MAE=0.337, train_loss=0.337, val_MAE=0.426, val_loss=0.426]Epoch 62:   6%|▌         | 62/1000 [36:53<8:50:40, 33.95s/it, lr=3.13e-5, test_MAE=0.44, time=32.5, train_MAE=0.337, train_loss=0.337, val_MAE=0.426, val_loss=0.426]Epoch 62:   6%|▌         | 62/1000 [37:26<8:50:40, 33.95s/it, lr=3.13e-5, test_MAE=0.446, time=33.6, train_MAE=0.334, train_loss=0.334, val_MAE=0.428, val_loss=0.428]Epoch 62:   6%|▋         | 63/1000 [37:26<8:48:46, 33.86s/it, lr=3.13e-5, test_MAE=0.446, time=33.6, train_MAE=0.334, train_loss=0.334, val_MAE=0.428, val_loss=0.428]Epoch 63:   6%|▋         | 63/1000 [37:26<8:48:46, 33.86s/it, lr=3.13e-5, test_MAE=0.446, time=33.6, train_MAE=0.334, train_loss=0.334, val_MAE=0.428, val_loss=0.428]Epoch 63:   6%|▋         | 63/1000 [38:00<8:48:46, 33.86s/it, lr=3.13e-5, test_MAE=0.454, time=33.5, train_MAE=0.337, train_loss=0.337, val_MAE=0.436, val_loss=0.436]Epoch 63:   6%|▋         | 64/1000 [38:00<8:46:32, 33.75s/it, lr=3.13e-5, test_MAE=0.454, time=33.5, train_MAE=0.337, train_loss=0.337, val_MAE=0.436, val_loss=0.436]Epoch 64:   6%|▋         | 64/1000 [38:00<8:46:32, 33.75s/it, lr=3.13e-5, test_MAE=0.454, time=33.5, train_MAE=0.337, train_loss=0.337, val_MAE=0.436, val_loss=0.436]Epoch 64:   6%|▋         | 64/1000 [38:33<8:46:32, 33.75s/it, lr=3.13e-5, test_MAE=0.422, time=33.4, train_MAE=0.334, train_loss=0.334, val_MAE=0.407, val_loss=0.407]Epoch    65: reducing learning rate of group 0 to 1.5625e-05.
Epoch 64:   6%|▋         | 65/1000 [38:33<8:44:18, 33.65s/it, lr=3.13e-5, test_MAE=0.422, time=33.4, train_MAE=0.334, train_loss=0.334, val_MAE=0.407, val_loss=0.407]Epoch 65:   6%|▋         | 65/1000 [38:33<8:44:18, 33.65s/it, lr=3.13e-5, test_MAE=0.422, time=33.4, train_MAE=0.334, train_loss=0.334, val_MAE=0.407, val_loss=0.407]Epoch 65:   6%|▋         | 65/1000 [39:06<8:44:18, 33.65s/it, lr=1.56e-5, test_MAE=0.43, time=33.4, train_MAE=0.339, train_loss=0.339, val_MAE=0.412, val_loss=0.412] Epoch 65:   7%|▋         | 66/1000 [39:06<8:42:28, 33.56s/it, lr=1.56e-5, test_MAE=0.43, time=33.4, train_MAE=0.339, train_loss=0.339, val_MAE=0.412, val_loss=0.412]Epoch 66:   7%|▋         | 66/1000 [39:06<8:42:28, 33.56s/it, lr=1.56e-5, test_MAE=0.43, time=33.4, train_MAE=0.339, train_loss=0.339, val_MAE=0.412, val_loss=0.412]Epoch 66:   7%|▋         | 66/1000 [39:40<8:42:28, 33.56s/it, lr=1.56e-5, test_MAE=0.417, time=34, train_MAE=0.341, train_loss=0.341, val_MAE=0.403, val_loss=0.403] Epoch 66:   7%|▋         | 67/1000 [39:40<8:43:53, 33.69s/it, lr=1.56e-5, test_MAE=0.417, time=34, train_MAE=0.341, train_loss=0.341, val_MAE=0.403, val_loss=0.403]Epoch 67:   7%|▋         | 67/1000 [39:40<8:43:53, 33.69s/it, lr=1.56e-5, test_MAE=0.417, time=34, train_MAE=0.341, train_loss=0.341, val_MAE=0.403, val_loss=0.403]Epoch 67:   7%|▋         | 67/1000 [40:14<8:43:53, 33.69s/it, lr=1.56e-5, test_MAE=0.423, time=33.7, train_MAE=0.339, train_loss=0.339, val_MAE=0.411, val_loss=0.411]Epoch 67:   7%|▋         | 68/1000 [40:14<8:43:25, 33.70s/it, lr=1.56e-5, test_MAE=0.423, time=33.7, train_MAE=0.339, train_loss=0.339, val_MAE=0.411, val_loss=0.411]Epoch 68:   7%|▋         | 68/1000 [40:14<8:43:25, 33.70s/it, lr=1.56e-5, test_MAE=0.423, time=33.7, train_MAE=0.339, train_loss=0.339, val_MAE=0.411, val_loss=0.411]Epoch 68:   7%|▋         | 68/1000 [40:47<8:43:25, 33.70s/it, lr=1.56e-5, test_MAE=0.42, time=33.3, train_MAE=0.344, train_loss=0.344, val_MAE=0.405, val_loss=0.405] Epoch 68:   7%|▋         | 69/1000 [40:47<8:41:05, 33.58s/it, lr=1.56e-5, test_MAE=0.42, time=33.3, train_MAE=0.344, train_loss=0.344, val_MAE=0.405, val_loss=0.405]Epoch 69:   7%|▋         | 69/1000 [40:47<8:41:05, 33.58s/it, lr=1.56e-5, test_MAE=0.42, time=33.3, train_MAE=0.344, train_loss=0.344, val_MAE=0.405, val_loss=0.405]Epoch 69:   7%|▋         | 69/1000 [41:21<8:41:05, 33.58s/it, lr=1.56e-5, test_MAE=0.419, time=33.4, train_MAE=0.34, train_loss=0.34, val_MAE=0.404, val_loss=0.404] Epoch 69:   7%|▋         | 70/1000 [41:21<8:39:33, 33.52s/it, lr=1.56e-5, test_MAE=0.419, time=33.4, train_MAE=0.34, train_loss=0.34, val_MAE=0.404, val_loss=0.404]Epoch 70:   7%|▋         | 70/1000 [41:21<8:39:33, 33.52s/it, lr=1.56e-5, test_MAE=0.419, time=33.4, train_MAE=0.34, train_loss=0.34, val_MAE=0.404, val_loss=0.404]Epoch 70:   7%|▋         | 70/1000 [41:54<8:39:33, 33.52s/it, lr=1.56e-5, test_MAE=0.417, time=33.4, train_MAE=0.339, train_loss=0.339, val_MAE=0.404, val_loss=0.404]Epoch    71: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 70:   7%|▋         | 70/1000 [41:54<9:16:49, 35.92s/it, lr=1.56e-5, test_MAE=0.417, time=33.4, train_MAE=0.339, train_loss=0.339, val_MAE=0.404, val_loss=0.404]
Test MAE: 0.4172
Train MAE: 0.3131
Convergence Time (Epochs): 70.0000
TOTAL TIME TAKEN: 2536.7205s
AVG TIME PER EPOCH: 35.4027s
