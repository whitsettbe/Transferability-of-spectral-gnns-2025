I'm echoing to stdout
I'm echoing to stderr
My JobID is 56750753
I have 8 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.0568s
Dataset: ZINC,
Model: ChebAugmentedFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 2, 'k_aug': 4, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'parallel_dense_simp', 'normalized_laplacian': True, 'post_normalized': False, 'eigval_norm': '', 'num_eigs': 64, 'bias_mode': 'spatial', 'eigval_hidden_dim': 5, 'eigval_num_hidden_layer': 3, 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 0.0, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/zinc_train_rec_full.csv', 'test': 'supp_data/molecules/zinc_test_rec_full.csv', 'val': 'supp_data/molecules/zinc_val_rec_full.csv'}, 'fixMissingPhi1': False, 'extraOrtho': True, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [03:00<?, ?it/s, lr=0.001, test_MAE=0.654, time=181, train_MAE=0.784, train_loss=0.784, val_MAE=0.627, val_loss=0.627]Epoch 0:   0%|          | 1/1000 [03:00<50:07:18, 180.62s/it, lr=0.001, test_MAE=0.654, time=181, train_MAE=0.784, train_loss=0.784, val_MAE=0.627, val_loss=0.627]Epoch 1:   0%|          | 1/1000 [03:00<50:07:18, 180.62s/it, lr=0.001, test_MAE=0.654, time=181, train_MAE=0.784, train_loss=0.784, val_MAE=0.627, val_loss=0.627]Epoch 1:   0%|          | 1/1000 [03:33<50:07:18, 180.62s/it, lr=0.001, test_MAE=0.605, time=32.9, train_MAE=0.594, train_loss=0.594, val_MAE=0.565, val_loss=0.565]Epoch 1:   0%|          | 2/1000 [03:33<37:47:13, 136.31s/it, lr=0.001, test_MAE=0.605, time=32.9, train_MAE=0.594, train_loss=0.594, val_MAE=0.565, val_loss=0.565]Epoch 2:   0%|          | 2/1000 [03:33<37:47:13, 136.31s/it, lr=0.001, test_MAE=0.605, time=32.9, train_MAE=0.594, train_loss=0.594, val_MAE=0.565, val_loss=0.565]Epoch 2:   0%|          | 2/1000 [04:06<37:47:13, 136.31s/it, lr=0.001, test_MAE=0.835, time=33.4, train_MAE=0.585, train_loss=0.585, val_MAE=0.78, val_loss=0.78]  Epoch 2:   0%|          | 3/1000 [04:06<29:11:51, 105.43s/it, lr=0.001, test_MAE=0.835, time=33.4, train_MAE=0.585, train_loss=0.585, val_MAE=0.78, val_loss=0.78]Epoch 3:   0%|          | 3/1000 [04:06<29:11:51, 105.43s/it, lr=0.001, test_MAE=0.835, time=33.4, train_MAE=0.585, train_loss=0.585, val_MAE=0.78, val_loss=0.78]Epoch 3:   0%|          | 3/1000 [04:40<29:11:51, 105.43s/it, lr=0.001, test_MAE=0.741, time=33.8, train_MAE=0.578, train_loss=0.578, val_MAE=0.681, val_loss=0.681]Epoch 3:   0%|          | 4/1000 [04:40<23:13:13, 83.93s/it, lr=0.001, test_MAE=0.741, time=33.8, train_MAE=0.578, train_loss=0.578, val_MAE=0.681, val_loss=0.681] Epoch 4:   0%|          | 4/1000 [04:40<23:13:13, 83.93s/it, lr=0.001, test_MAE=0.741, time=33.8, train_MAE=0.578, train_loss=0.578, val_MAE=0.681, val_loss=0.681]Epoch 4:   0%|          | 4/1000 [05:13<23:13:13, 83.93s/it, lr=0.001, test_MAE=0.609, time=32.7, train_MAE=0.551, train_loss=0.551, val_MAE=0.567, val_loss=0.567]Epoch 4:   0%|          | 5/1000 [05:13<18:57:03, 68.57s/it, lr=0.001, test_MAE=0.609, time=32.7, train_MAE=0.551, train_loss=0.551, val_MAE=0.567, val_loss=0.567]Epoch 5:   0%|          | 5/1000 [05:13<18:57:03, 68.57s/it, lr=0.001, test_MAE=0.609, time=32.7, train_MAE=0.551, train_loss=0.551, val_MAE=0.567, val_loss=0.567]Epoch 5:   0%|          | 5/1000 [05:45<18:57:03, 68.57s/it, lr=0.001, test_MAE=0.67, time=32.4, train_MAE=0.522, train_loss=0.522, val_MAE=0.658, val_loss=0.658] Epoch 5:   1%|          | 6/1000 [05:45<15:56:31, 57.74s/it, lr=0.001, test_MAE=0.67, time=32.4, train_MAE=0.522, train_loss=0.522, val_MAE=0.658, val_loss=0.658]Epoch 6:   1%|          | 6/1000 [05:45<15:56:31, 57.74s/it, lr=0.001, test_MAE=0.67, time=32.4, train_MAE=0.522, train_loss=0.522, val_MAE=0.658, val_loss=0.658]Epoch 6:   1%|          | 6/1000 [06:19<15:56:31, 57.74s/it, lr=0.001, test_MAE=0.526, time=33.3, train_MAE=0.504, train_loss=0.504, val_MAE=0.5, val_loss=0.5]   Epoch 6:   1%|          | 7/1000 [06:19<13:54:17, 50.41s/it, lr=0.001, test_MAE=0.526, time=33.3, train_MAE=0.504, train_loss=0.504, val_MAE=0.5, val_loss=0.5]Epoch 7:   1%|          | 7/1000 [06:19<13:54:17, 50.41s/it, lr=0.001, test_MAE=0.526, time=33.3, train_MAE=0.504, train_loss=0.504, val_MAE=0.5, val_loss=0.5]Epoch 7:   1%|          | 7/1000 [06:51<13:54:17, 50.41s/it, lr=0.001, test_MAE=0.549, time=32.7, train_MAE=0.518, train_loss=0.518, val_MAE=0.517, val_loss=0.517]Epoch 7:   1%|          | 8/1000 [06:51<12:25:54, 45.12s/it, lr=0.001, test_MAE=0.549, time=32.7, train_MAE=0.518, train_loss=0.518, val_MAE=0.517, val_loss=0.517]Epoch 8:   1%|          | 8/1000 [06:51<12:25:54, 45.12s/it, lr=0.001, test_MAE=0.549, time=32.7, train_MAE=0.518, train_loss=0.518, val_MAE=0.517, val_loss=0.517]Epoch 8:   1%|          | 8/1000 [07:25<12:25:54, 45.12s/it, lr=0.001, test_MAE=0.54, time=33.4, train_MAE=0.485, train_loss=0.485, val_MAE=0.496, val_loss=0.496] Epoch 8:   1%|          | 9/1000 [07:25<11:27:05, 41.60s/it, lr=0.001, test_MAE=0.54, time=33.4, train_MAE=0.485, train_loss=0.485, val_MAE=0.496, val_loss=0.496]Epoch 9:   1%|          | 9/1000 [07:25<11:27:05, 41.60s/it, lr=0.001, test_MAE=0.54, time=33.4, train_MAE=0.485, train_loss=0.485, val_MAE=0.496, val_loss=0.496]Epoch 9:   1%|          | 9/1000 [07:58<11:27:05, 41.60s/it, lr=0.001, test_MAE=0.6, time=33.4, train_MAE=0.473, train_loss=0.473, val_MAE=0.56, val_loss=0.56]   Epoch 9:   1%|          | 10/1000 [07:58<10:46:07, 39.16s/it, lr=0.001, test_MAE=0.6, time=33.4, train_MAE=0.473, train_loss=0.473, val_MAE=0.56, val_loss=0.56]Epoch 10:   1%|          | 10/1000 [07:58<10:46:07, 39.16s/it, lr=0.001, test_MAE=0.6, time=33.4, train_MAE=0.473, train_loss=0.473, val_MAE=0.56, val_loss=0.56]Epoch 10:   1%|          | 10/1000 [08:31<10:46:07, 39.16s/it, lr=0.001, test_MAE=0.562, time=33.1, train_MAE=0.473, train_loss=0.473, val_MAE=0.543, val_loss=0.543]Epoch 10:   1%|          | 11/1000 [08:31<10:15:43, 37.35s/it, lr=0.001, test_MAE=0.562, time=33.1, train_MAE=0.473, train_loss=0.473, val_MAE=0.543, val_loss=0.543]Epoch 11:   1%|          | 11/1000 [08:31<10:15:43, 37.35s/it, lr=0.001, test_MAE=0.562, time=33.1, train_MAE=0.473, train_loss=0.473, val_MAE=0.543, val_loss=0.543]Epoch 11:   1%|          | 11/1000 [09:05<10:15:43, 37.35s/it, lr=0.001, test_MAE=0.513, time=33.3, train_MAE=0.463, train_loss=0.463, val_MAE=0.495, val_loss=0.495]Epoch 11:   1%|          | 12/1000 [09:05<9:54:56, 36.13s/it, lr=0.001, test_MAE=0.513, time=33.3, train_MAE=0.463, train_loss=0.463, val_MAE=0.495, val_loss=0.495] Epoch 12:   1%|          | 12/1000 [09:05<9:54:56, 36.13s/it, lr=0.001, test_MAE=0.513, time=33.3, train_MAE=0.463, train_loss=0.463, val_MAE=0.495, val_loss=0.495]Epoch 12:   1%|          | 12/1000 [09:38<9:54:56, 36.13s/it, lr=0.001, test_MAE=0.593, time=32.9, train_MAE=0.45, train_loss=0.45, val_MAE=0.574, val_loss=0.574]  Epoch 12:   1%|▏         | 13/1000 [09:38<9:38:29, 35.17s/it, lr=0.001, test_MAE=0.593, time=32.9, train_MAE=0.45, train_loss=0.45, val_MAE=0.574, val_loss=0.574]Epoch 13:   1%|▏         | 13/1000 [09:38<9:38:29, 35.17s/it, lr=0.001, test_MAE=0.593, time=32.9, train_MAE=0.45, train_loss=0.45, val_MAE=0.574, val_loss=0.574]Epoch 13:   1%|▏         | 13/1000 [10:11<9:38:29, 35.17s/it, lr=0.001, test_MAE=1.02, time=33.3, train_MAE=0.461, train_loss=0.461, val_MAE=0.988, val_loss=0.988]Epoch 13:   1%|▏         | 14/1000 [10:11<9:28:50, 34.62s/it, lr=0.001, test_MAE=1.02, time=33.3, train_MAE=0.461, train_loss=0.461, val_MAE=0.988, val_loss=0.988]Epoch 14:   1%|▏         | 14/1000 [10:11<9:28:50, 34.62s/it, lr=0.001, test_MAE=1.02, time=33.3, train_MAE=0.461, train_loss=0.461, val_MAE=0.988, val_loss=0.988]Epoch 14:   1%|▏         | 14/1000 [10:44<9:28:50, 34.62s/it, lr=0.001, test_MAE=0.557, time=33.2, train_MAE=0.446, train_loss=0.446, val_MAE=0.542, val_loss=0.542]Epoch 14:   2%|▏         | 15/1000 [10:44<9:21:22, 34.20s/it, lr=0.001, test_MAE=0.557, time=33.2, train_MAE=0.446, train_loss=0.446, val_MAE=0.542, val_loss=0.542]Epoch 15:   2%|▏         | 15/1000 [10:44<9:21:22, 34.20s/it, lr=0.001, test_MAE=0.557, time=33.2, train_MAE=0.446, train_loss=0.446, val_MAE=0.542, val_loss=0.542]Epoch 15:   2%|▏         | 15/1000 [11:17<9:21:22, 34.20s/it, lr=0.001, test_MAE=0.5, time=33.1, train_MAE=0.438, train_loss=0.438, val_MAE=0.473, val_loss=0.473]  Epoch 15:   2%|▏         | 16/1000 [11:17<9:15:31, 33.87s/it, lr=0.001, test_MAE=0.5, time=33.1, train_MAE=0.438, train_loss=0.438, val_MAE=0.473, val_loss=0.473]Epoch 16:   2%|▏         | 16/1000 [11:17<9:15:31, 33.87s/it, lr=0.001, test_MAE=0.5, time=33.1, train_MAE=0.438, train_loss=0.438, val_MAE=0.473, val_loss=0.473]Epoch 16:   2%|▏         | 16/1000 [11:50<9:15:31, 33.87s/it, lr=0.001, test_MAE=0.751, time=32.9, train_MAE=0.438, train_loss=0.438, val_MAE=0.719, val_loss=0.719]Epoch 16:   2%|▏         | 17/1000 [11:50<9:10:18, 33.59s/it, lr=0.001, test_MAE=0.751, time=32.9, train_MAE=0.438, train_loss=0.438, val_MAE=0.719, val_loss=0.719]Epoch 17:   2%|▏         | 17/1000 [11:50<9:10:18, 33.59s/it, lr=0.001, test_MAE=0.751, time=32.9, train_MAE=0.438, train_loss=0.438, val_MAE=0.719, val_loss=0.719]Epoch 17:   2%|▏         | 17/1000 [12:24<9:10:18, 33.59s/it, lr=0.001, test_MAE=1.03, time=33.5, train_MAE=0.438, train_loss=0.438, val_MAE=1, val_loss=1]         Epoch 17:   2%|▏         | 18/1000 [12:24<9:09:09, 33.55s/it, lr=0.001, test_MAE=1.03, time=33.5, train_MAE=0.438, train_loss=0.438, val_MAE=1, val_loss=1]Epoch 18:   2%|▏         | 18/1000 [12:24<9:09:09, 33.55s/it, lr=0.001, test_MAE=1.03, time=33.5, train_MAE=0.438, train_loss=0.438, val_MAE=1, val_loss=1]Epoch 18:   2%|▏         | 18/1000 [12:57<9:09:09, 33.55s/it, lr=0.001, test_MAE=0.792, time=33.5, train_MAE=0.436, train_loss=0.436, val_MAE=0.754, val_loss=0.754]Epoch 18:   2%|▏         | 19/1000 [12:57<9:08:28, 33.55s/it, lr=0.001, test_MAE=0.792, time=33.5, train_MAE=0.436, train_loss=0.436, val_MAE=0.754, val_loss=0.754]Epoch 19:   2%|▏         | 19/1000 [12:57<9:08:28, 33.55s/it, lr=0.001, test_MAE=0.792, time=33.5, train_MAE=0.436, train_loss=0.436, val_MAE=0.754, val_loss=0.754]Epoch 19:   2%|▏         | 19/1000 [13:30<9:08:28, 33.55s/it, lr=0.001, test_MAE=0.636, time=32.7, train_MAE=0.431, train_loss=0.431, val_MAE=0.625, val_loss=0.625]Epoch 19:   2%|▏         | 20/1000 [13:30<9:03:59, 33.31s/it, lr=0.001, test_MAE=0.636, time=32.7, train_MAE=0.431, train_loss=0.431, val_MAE=0.625, val_loss=0.625]Epoch 20:   2%|▏         | 20/1000 [13:30<9:03:59, 33.31s/it, lr=0.001, test_MAE=0.636, time=32.7, train_MAE=0.431, train_loss=0.431, val_MAE=0.625, val_loss=0.625]Epoch 20:   2%|▏         | 20/1000 [14:03<9:03:59, 33.31s/it, lr=0.001, test_MAE=0.499, time=33.3, train_MAE=0.411, train_loss=0.411, val_MAE=0.471, val_loss=0.471]Epoch 20:   2%|▏         | 21/1000 [14:03<9:03:16, 33.30s/it, lr=0.001, test_MAE=0.499, time=33.3, train_MAE=0.411, train_loss=0.411, val_MAE=0.471, val_loss=0.471]Epoch 21:   2%|▏         | 21/1000 [14:03<9:03:16, 33.30s/it, lr=0.001, test_MAE=0.499, time=33.3, train_MAE=0.411, train_loss=0.411, val_MAE=0.471, val_loss=0.471]Epoch 21:   2%|▏         | 21/1000 [14:37<9:03:16, 33.30s/it, lr=0.001, test_MAE=0.488, time=33.5, train_MAE=0.404, train_loss=0.404, val_MAE=0.463, val_loss=0.463]Epoch 21:   2%|▏         | 22/1000 [14:37<9:03:46, 33.36s/it, lr=0.001, test_MAE=0.488, time=33.5, train_MAE=0.404, train_loss=0.404, val_MAE=0.463, val_loss=0.463]Epoch 22:   2%|▏         | 22/1000 [14:37<9:03:46, 33.36s/it, lr=0.001, test_MAE=0.488, time=33.5, train_MAE=0.404, train_loss=0.404, val_MAE=0.463, val_loss=0.463]Epoch 22:   2%|▏         | 22/1000 [15:10<9:03:46, 33.36s/it, lr=0.001, test_MAE=0.606, time=33, train_MAE=0.403, train_loss=0.403, val_MAE=0.588, val_loss=0.588]  Epoch 22:   2%|▏         | 23/1000 [15:10<9:01:22, 33.25s/it, lr=0.001, test_MAE=0.606, time=33, train_MAE=0.403, train_loss=0.403, val_MAE=0.588, val_loss=0.588]Epoch 23:   2%|▏         | 23/1000 [15:10<9:01:22, 33.25s/it, lr=0.001, test_MAE=0.606, time=33, train_MAE=0.403, train_loss=0.403, val_MAE=0.588, val_loss=0.588]Epoch 23:   2%|▏         | 23/1000 [15:43<9:01:22, 33.25s/it, lr=0.001, test_MAE=0.487, time=32.8, train_MAE=0.394, train_loss=0.394, val_MAE=0.47, val_loss=0.47]Epoch 23:   2%|▏         | 24/1000 [15:43<8:58:39, 33.11s/it, lr=0.001, test_MAE=0.487, time=32.8, train_MAE=0.394, train_loss=0.394, val_MAE=0.47, val_loss=0.47]Epoch 24:   2%|▏         | 24/1000 [15:43<8:58:39, 33.11s/it, lr=0.001, test_MAE=0.487, time=32.8, train_MAE=0.394, train_loss=0.394, val_MAE=0.47, val_loss=0.47]Epoch 24:   2%|▏         | 24/1000 [16:16<8:58:39, 33.11s/it, lr=0.001, test_MAE=0.481, time=33.9, train_MAE=0.392, train_loss=0.392, val_MAE=0.454, val_loss=0.454]Epoch 24:   2%|▎         | 25/1000 [16:17<9:02:14, 33.37s/it, lr=0.001, test_MAE=0.481, time=33.9, train_MAE=0.392, train_loss=0.392, val_MAE=0.454, val_loss=0.454]Epoch 25:   2%|▎         | 25/1000 [16:17<9:02:14, 33.37s/it, lr=0.001, test_MAE=0.481, time=33.9, train_MAE=0.392, train_loss=0.392, val_MAE=0.454, val_loss=0.454]Epoch 25:   2%|▎         | 25/1000 [16:51<9:02:14, 33.37s/it, lr=0.001, test_MAE=0.588, time=34.9, train_MAE=0.377, train_loss=0.377, val_MAE=0.589, val_loss=0.589]Epoch 25:   3%|▎         | 26/1000 [16:51<9:09:18, 33.84s/it, lr=0.001, test_MAE=0.588, time=34.9, train_MAE=0.377, train_loss=0.377, val_MAE=0.589, val_loss=0.589]Epoch 26:   3%|▎         | 26/1000 [16:51<9:09:18, 33.84s/it, lr=0.001, test_MAE=0.588, time=34.9, train_MAE=0.377, train_loss=0.377, val_MAE=0.589, val_loss=0.589]Epoch 26:   3%|▎         | 26/1000 [17:26<9:09:18, 33.84s/it, lr=0.001, test_MAE=0.479, time=34.3, train_MAE=0.394, train_loss=0.394, val_MAE=0.453, val_loss=0.453]Epoch 26:   3%|▎         | 27/1000 [17:26<9:10:55, 33.97s/it, lr=0.001, test_MAE=0.479, time=34.3, train_MAE=0.394, train_loss=0.394, val_MAE=0.453, val_loss=0.453]Epoch 27:   3%|▎         | 27/1000 [17:26<9:10:55, 33.97s/it, lr=0.001, test_MAE=0.479, time=34.3, train_MAE=0.394, train_loss=0.394, val_MAE=0.453, val_loss=0.453]Epoch 27:   3%|▎         | 27/1000 [18:01<9:10:55, 33.97s/it, lr=0.001, test_MAE=0.818, time=35, train_MAE=0.38, train_loss=0.38, val_MAE=0.787, val_loss=0.787]    Epoch 27:   3%|▎         | 28/1000 [18:01<9:15:35, 34.30s/it, lr=0.001, test_MAE=0.818, time=35, train_MAE=0.38, train_loss=0.38, val_MAE=0.787, val_loss=0.787]Epoch 28:   3%|▎         | 28/1000 [18:01<9:15:35, 34.30s/it, lr=0.001, test_MAE=0.818, time=35, train_MAE=0.38, train_loss=0.38, val_MAE=0.787, val_loss=0.787]Epoch 28:   3%|▎         | 28/1000 [18:36<9:15:35, 34.30s/it, lr=0.001, test_MAE=0.492, time=35.3, train_MAE=0.375, train_loss=0.375, val_MAE=0.465, val_loss=0.465]Epoch 28:   3%|▎         | 29/1000 [18:36<9:20:09, 34.61s/it, lr=0.001, test_MAE=0.492, time=35.3, train_MAE=0.375, train_loss=0.375, val_MAE=0.465, val_loss=0.465]Epoch 29:   3%|▎         | 29/1000 [18:36<9:20:09, 34.61s/it, lr=0.001, test_MAE=0.492, time=35.3, train_MAE=0.375, train_loss=0.375, val_MAE=0.465, val_loss=0.465]Epoch 29:   3%|▎         | 29/1000 [19:09<9:20:09, 34.61s/it, lr=0.001, test_MAE=0.499, time=33.2, train_MAE=0.367, train_loss=0.367, val_MAE=0.485, val_loss=0.485]Epoch 29:   3%|▎         | 30/1000 [19:09<9:12:49, 34.20s/it, lr=0.001, test_MAE=0.499, time=33.2, train_MAE=0.367, train_loss=0.367, val_MAE=0.485, val_loss=0.485]Epoch 30:   3%|▎         | 30/1000 [19:09<9:12:49, 34.20s/it, lr=0.001, test_MAE=0.499, time=33.2, train_MAE=0.367, train_loss=0.367, val_MAE=0.485, val_loss=0.485]Epoch 30:   3%|▎         | 30/1000 [19:44<9:12:49, 34.20s/it, lr=0.001, test_MAE=0.506, time=34.2, train_MAE=0.369, train_loss=0.369, val_MAE=0.483, val_loss=0.483]Epoch 30:   3%|▎         | 31/1000 [19:44<9:12:13, 34.19s/it, lr=0.001, test_MAE=0.506, time=34.2, train_MAE=0.369, train_loss=0.369, val_MAE=0.483, val_loss=0.483]Epoch 31:   3%|▎         | 31/1000 [19:44<9:12:13, 34.19s/it, lr=0.001, test_MAE=0.506, time=34.2, train_MAE=0.369, train_loss=0.369, val_MAE=0.483, val_loss=0.483]Epoch 31:   3%|▎         | 31/1000 [20:17<9:12:13, 34.19s/it, lr=0.001, test_MAE=0.635, time=33.6, train_MAE=0.364, train_loss=0.364, val_MAE=0.621, val_loss=0.621]Epoch 31:   3%|▎         | 32/1000 [20:17<9:08:52, 34.02s/it, lr=0.001, test_MAE=0.635, time=33.6, train_MAE=0.364, train_loss=0.364, val_MAE=0.621, val_loss=0.621]Epoch 32:   3%|▎         | 32/1000 [20:17<9:08:52, 34.02s/it, lr=0.001, test_MAE=0.635, time=33.6, train_MAE=0.364, train_loss=0.364, val_MAE=0.621, val_loss=0.621]Epoch 32:   3%|▎         | 32/1000 [20:49<9:08:52, 34.02s/it, lr=0.001, test_MAE=0.74, time=32.3, train_MAE=0.372, train_loss=0.372, val_MAE=0.727, val_loss=0.727] Epoch    33: reducing learning rate of group 0 to 5.0000e-04.
Epoch 32:   3%|▎         | 33/1000 [20:49<9:00:10, 33.52s/it, lr=0.001, test_MAE=0.74, time=32.3, train_MAE=0.372, train_loss=0.372, val_MAE=0.727, val_loss=0.727]Epoch 33:   3%|▎         | 33/1000 [20:49<9:00:10, 33.52s/it, lr=0.001, test_MAE=0.74, time=32.3, train_MAE=0.372, train_loss=0.372, val_MAE=0.727, val_loss=0.727]Epoch 33:   3%|▎         | 33/1000 [21:22<9:00:10, 33.52s/it, lr=0.0005, test_MAE=0.479, time=32.3, train_MAE=0.328, train_loss=0.328, val_MAE=0.471, val_loss=0.471]Epoch 33:   3%|▎         | 34/1000 [21:22<8:53:45, 33.15s/it, lr=0.0005, test_MAE=0.479, time=32.3, train_MAE=0.328, train_loss=0.328, val_MAE=0.471, val_loss=0.471]Epoch 34:   3%|▎         | 34/1000 [21:22<8:53:45, 33.15s/it, lr=0.0005, test_MAE=0.479, time=32.3, train_MAE=0.328, train_loss=0.328, val_MAE=0.471, val_loss=0.471]Epoch 34:   3%|▎         | 34/1000 [21:54<8:53:45, 33.15s/it, lr=0.0005, test_MAE=0.676, time=32.6, train_MAE=0.329, train_loss=0.329, val_MAE=0.668, val_loss=0.668]Epoch 34:   4%|▎         | 35/1000 [21:54<8:50:32, 32.99s/it, lr=0.0005, test_MAE=0.676, time=32.6, train_MAE=0.329, train_loss=0.329, val_MAE=0.668, val_loss=0.668]Epoch 35:   4%|▎         | 35/1000 [21:54<8:50:32, 32.99s/it, lr=0.0005, test_MAE=0.676, time=32.6, train_MAE=0.329, train_loss=0.329, val_MAE=0.668, val_loss=0.668]Epoch 35:   4%|▎         | 35/1000 [22:27<8:50:32, 32.99s/it, lr=0.0005, test_MAE=0.555, time=32.2, train_MAE=0.328, train_loss=0.328, val_MAE=0.536, val_loss=0.536]Epoch 35:   4%|▎         | 36/1000 [22:27<8:46:31, 32.77s/it, lr=0.0005, test_MAE=0.555, time=32.2, train_MAE=0.328, train_loss=0.328, val_MAE=0.536, val_loss=0.536]Epoch 36:   4%|▎         | 36/1000 [22:27<8:46:31, 32.77s/it, lr=0.0005, test_MAE=0.555, time=32.2, train_MAE=0.328, train_loss=0.328, val_MAE=0.536, val_loss=0.536]Epoch 36:   4%|▎         | 36/1000 [22:59<8:46:31, 32.77s/it, lr=0.0005, test_MAE=0.484, time=32.1, train_MAE=0.329, train_loss=0.329, val_MAE=0.469, val_loss=0.469]Epoch 36:   4%|▎         | 37/1000 [22:59<8:42:58, 32.58s/it, lr=0.0005, test_MAE=0.484, time=32.1, train_MAE=0.329, train_loss=0.329, val_MAE=0.469, val_loss=0.469]Epoch 37:   4%|▎         | 37/1000 [22:59<8:42:58, 32.58s/it, lr=0.0005, test_MAE=0.484, time=32.1, train_MAE=0.329, train_loss=0.329, val_MAE=0.469, val_loss=0.469]Epoch 37:   4%|▎         | 37/1000 [23:31<8:42:58, 32.58s/it, lr=0.0005, test_MAE=0.563, time=31.9, train_MAE=0.317, train_loss=0.317, val_MAE=0.559, val_loss=0.559]Epoch 37:   4%|▍         | 38/1000 [23:31<8:39:24, 32.40s/it, lr=0.0005, test_MAE=0.563, time=31.9, train_MAE=0.317, train_loss=0.317, val_MAE=0.559, val_loss=0.559]Epoch 38:   4%|▍         | 38/1000 [23:31<8:39:24, 32.40s/it, lr=0.0005, test_MAE=0.563, time=31.9, train_MAE=0.317, train_loss=0.317, val_MAE=0.559, val_loss=0.559]Epoch 38:   4%|▍         | 38/1000 [24:03<8:39:24, 32.40s/it, lr=0.0005, test_MAE=0.469, time=32, train_MAE=0.329, train_loss=0.329, val_MAE=0.451, val_loss=0.451]  Epoch 38:   4%|▍         | 39/1000 [24:03<8:37:15, 32.29s/it, lr=0.0005, test_MAE=0.469, time=32, train_MAE=0.329, train_loss=0.329, val_MAE=0.451, val_loss=0.451]Epoch 39:   4%|▍         | 39/1000 [24:03<8:37:15, 32.29s/it, lr=0.0005, test_MAE=0.469, time=32, train_MAE=0.329, train_loss=0.329, val_MAE=0.451, val_loss=0.451]Epoch 39:   4%|▍         | 39/1000 [24:34<8:37:15, 32.29s/it, lr=0.0005, test_MAE=0.458, time=31.6, train_MAE=0.31, train_loss=0.31, val_MAE=0.451, val_loss=0.451]Epoch 39:   4%|▍         | 40/1000 [24:34<8:33:28, 32.09s/it, lr=0.0005, test_MAE=0.458, time=31.6, train_MAE=0.31, train_loss=0.31, val_MAE=0.451, val_loss=0.451]Epoch 40:   4%|▍         | 40/1000 [24:34<8:33:28, 32.09s/it, lr=0.0005, test_MAE=0.458, time=31.6, train_MAE=0.31, train_loss=0.31, val_MAE=0.451, val_loss=0.451]Epoch 40:   4%|▍         | 40/1000 [25:06<8:33:28, 32.09s/it, lr=0.0005, test_MAE=0.589, time=31.2, train_MAE=0.301, train_loss=0.301, val_MAE=0.586, val_loss=0.586]Epoch 40:   4%|▍         | 41/1000 [25:06<8:28:55, 31.84s/it, lr=0.0005, test_MAE=0.589, time=31.2, train_MAE=0.301, train_loss=0.301, val_MAE=0.586, val_loss=0.586]Epoch 41:   4%|▍         | 41/1000 [25:06<8:28:55, 31.84s/it, lr=0.0005, test_MAE=0.589, time=31.2, train_MAE=0.301, train_loss=0.301, val_MAE=0.586, val_loss=0.586]Epoch 41:   4%|▍         | 41/1000 [25:37<8:28:55, 31.84s/it, lr=0.0005, test_MAE=0.473, time=31.2, train_MAE=0.316, train_loss=0.316, val_MAE=0.451, val_loss=0.451]Epoch 41:   4%|▍         | 42/1000 [25:37<8:25:16, 31.65s/it, lr=0.0005, test_MAE=0.473, time=31.2, train_MAE=0.316, train_loss=0.316, val_MAE=0.451, val_loss=0.451]Epoch 42:   4%|▍         | 42/1000 [25:37<8:25:16, 31.65s/it, lr=0.0005, test_MAE=0.473, time=31.2, train_MAE=0.316, train_loss=0.316, val_MAE=0.451, val_loss=0.451]Epoch 42:   4%|▍         | 42/1000 [26:07<8:25:16, 31.65s/it, lr=0.0005, test_MAE=0.462, time=30.5, train_MAE=0.305, train_loss=0.305, val_MAE=0.443, val_loss=0.443]Epoch 42:   4%|▍         | 43/1000 [26:07<8:19:21, 31.31s/it, lr=0.0005, test_MAE=0.462, time=30.5, train_MAE=0.305, train_loss=0.305, val_MAE=0.443, val_loss=0.443]Epoch 43:   4%|▍         | 43/1000 [26:07<8:19:21, 31.31s/it, lr=0.0005, test_MAE=0.462, time=30.5, train_MAE=0.305, train_loss=0.305, val_MAE=0.443, val_loss=0.443]Epoch 43:   4%|▍         | 43/1000 [26:38<8:19:21, 31.31s/it, lr=0.0005, test_MAE=0.656, time=30.3, train_MAE=0.299, train_loss=0.299, val_MAE=0.648, val_loss=0.648]Epoch 43:   4%|▍         | 44/1000 [26:38<8:13:55, 31.00s/it, lr=0.0005, test_MAE=0.656, time=30.3, train_MAE=0.299, train_loss=0.299, val_MAE=0.648, val_loss=0.648]Epoch 44:   4%|▍         | 44/1000 [26:38<8:13:55, 31.00s/it, lr=0.0005, test_MAE=0.656, time=30.3, train_MAE=0.299, train_loss=0.299, val_MAE=0.648, val_loss=0.648]Epoch 44:   4%|▍         | 44/1000 [27:08<8:13:55, 31.00s/it, lr=0.0005, test_MAE=0.481, time=30.2, train_MAE=0.296, train_loss=0.296, val_MAE=0.474, val_loss=0.474]Epoch 44:   4%|▍         | 45/1000 [27:08<8:09:33, 30.76s/it, lr=0.0005, test_MAE=0.481, time=30.2, train_MAE=0.296, train_loss=0.296, val_MAE=0.474, val_loss=0.474]Epoch 45:   4%|▍         | 45/1000 [27:08<8:09:33, 30.76s/it, lr=0.0005, test_MAE=0.481, time=30.2, train_MAE=0.296, train_loss=0.296, val_MAE=0.474, val_loss=0.474]Epoch 45:   4%|▍         | 45/1000 [27:38<8:09:33, 30.76s/it, lr=0.0005, test_MAE=0.473, time=30.4, train_MAE=0.291, train_loss=0.291, val_MAE=0.451, val_loss=0.451]Epoch 45:   5%|▍         | 46/1000 [27:38<8:07:34, 30.67s/it, lr=0.0005, test_MAE=0.473, time=30.4, train_MAE=0.291, train_loss=0.291, val_MAE=0.451, val_loss=0.451]Epoch 46:   5%|▍         | 46/1000 [27:38<8:07:34, 30.67s/it, lr=0.0005, test_MAE=0.473, time=30.4, train_MAE=0.291, train_loss=0.291, val_MAE=0.451, val_loss=0.451]Epoch 46:   5%|▍         | 46/1000 [28:09<8:07:34, 30.67s/it, lr=0.0005, test_MAE=0.473, time=30.4, train_MAE=0.295, train_loss=0.295, val_MAE=0.464, val_loss=0.464]Epoch 46:   5%|▍         | 47/1000 [28:09<8:05:53, 30.59s/it, lr=0.0005, test_MAE=0.473, time=30.4, train_MAE=0.295, train_loss=0.295, val_MAE=0.464, val_loss=0.464]Epoch 47:   5%|▍         | 47/1000 [28:09<8:05:53, 30.59s/it, lr=0.0005, test_MAE=0.473, time=30.4, train_MAE=0.295, train_loss=0.295, val_MAE=0.464, val_loss=0.464]Epoch 47:   5%|▍         | 47/1000 [28:39<8:05:53, 30.59s/it, lr=0.0005, test_MAE=0.49, time=29.8, train_MAE=0.296, train_loss=0.296, val_MAE=0.469, val_loss=0.469] Epoch 47:   5%|▍         | 48/1000 [28:39<8:01:34, 30.35s/it, lr=0.0005, test_MAE=0.49, time=29.8, train_MAE=0.296, train_loss=0.296, val_MAE=0.469, val_loss=0.469]Epoch 48:   5%|▍         | 48/1000 [28:39<8:01:34, 30.35s/it, lr=0.0005, test_MAE=0.49, time=29.8, train_MAE=0.296, train_loss=0.296, val_MAE=0.469, val_loss=0.469]Epoch 48:   5%|▍         | 48/1000 [29:09<8:01:34, 30.35s/it, lr=0.0005, test_MAE=0.685, time=30.4, train_MAE=0.284, train_loss=0.284, val_MAE=0.686, val_loss=0.686]Epoch    49: reducing learning rate of group 0 to 2.5000e-04.
Epoch 48:   5%|▍         | 49/1000 [29:09<8:01:22, 30.37s/it, lr=0.0005, test_MAE=0.685, time=30.4, train_MAE=0.284, train_loss=0.284, val_MAE=0.686, val_loss=0.686]Epoch 49:   5%|▍         | 49/1000 [29:09<8:01:22, 30.37s/it, lr=0.0005, test_MAE=0.685, time=30.4, train_MAE=0.284, train_loss=0.284, val_MAE=0.686, val_loss=0.686]Epoch 49:   5%|▍         | 49/1000 [29:39<8:01:22, 30.37s/it, lr=0.00025, test_MAE=0.505, time=30.3, train_MAE=0.273, train_loss=0.273, val_MAE=0.508, val_loss=0.508]Epoch 49:   5%|▌         | 50/1000 [29:39<8:00:47, 30.37s/it, lr=0.00025, test_MAE=0.505, time=30.3, train_MAE=0.273, train_loss=0.273, val_MAE=0.508, val_loss=0.508]Epoch 50:   5%|▌         | 50/1000 [29:39<8:00:47, 30.37s/it, lr=0.00025, test_MAE=0.505, time=30.3, train_MAE=0.273, train_loss=0.273, val_MAE=0.508, val_loss=0.508]Epoch 50:   5%|▌         | 50/1000 [30:09<8:00:47, 30.37s/it, lr=0.00025, test_MAE=0.465, time=29.9, train_MAE=0.263, train_loss=0.263, val_MAE=0.459, val_loss=0.459]Epoch 50:   5%|▌         | 51/1000 [30:09<7:58:06, 30.23s/it, lr=0.00025, test_MAE=0.465, time=29.9, train_MAE=0.263, train_loss=0.263, val_MAE=0.459, val_loss=0.459]Epoch 51:   5%|▌         | 51/1000 [30:09<7:58:06, 30.23s/it, lr=0.00025, test_MAE=0.465, time=29.9, train_MAE=0.263, train_loss=0.263, val_MAE=0.459, val_loss=0.459]Epoch 51:   5%|▌         | 51/1000 [30:39<7:58:06, 30.23s/it, lr=0.00025, test_MAE=0.467, time=30.1, train_MAE=0.267, train_loss=0.267, val_MAE=0.468, val_loss=0.468]Epoch 51:   5%|▌         | 52/1000 [30:39<7:57:01, 30.19s/it, lr=0.00025, test_MAE=0.467, time=30.1, train_MAE=0.267, train_loss=0.267, val_MAE=0.468, val_loss=0.468]Epoch 52:   5%|▌         | 52/1000 [30:39<7:57:01, 30.19s/it, lr=0.00025, test_MAE=0.467, time=30.1, train_MAE=0.267, train_loss=0.267, val_MAE=0.468, val_loss=0.468]Epoch 52:   5%|▌         | 52/1000 [31:10<7:57:01, 30.19s/it, lr=0.00025, test_MAE=0.468, time=30.4, train_MAE=0.261, train_loss=0.261, val_MAE=0.469, val_loss=0.469]Epoch 52:   5%|▌         | 53/1000 [31:10<7:57:48, 30.27s/it, lr=0.00025, test_MAE=0.468, time=30.4, train_MAE=0.261, train_loss=0.261, val_MAE=0.469, val_loss=0.469]Epoch 53:   5%|▌         | 53/1000 [31:10<7:57:48, 30.27s/it, lr=0.00025, test_MAE=0.468, time=30.4, train_MAE=0.261, train_loss=0.261, val_MAE=0.469, val_loss=0.469]Epoch 53:   5%|▌         | 53/1000 [31:40<7:57:48, 30.27s/it, lr=0.00025, test_MAE=0.496, time=30.3, train_MAE=0.254, train_loss=0.254, val_MAE=0.485, val_loss=0.485]Epoch 53:   5%|▌         | 54/1000 [31:40<7:57:37, 30.29s/it, lr=0.00025, test_MAE=0.496, time=30.3, train_MAE=0.254, train_loss=0.254, val_MAE=0.485, val_loss=0.485]Epoch 54:   5%|▌         | 54/1000 [31:40<7:57:37, 30.29s/it, lr=0.00025, test_MAE=0.496, time=30.3, train_MAE=0.254, train_loss=0.254, val_MAE=0.485, val_loss=0.485]Epoch 54:   5%|▌         | 54/1000 [32:10<7:57:37, 30.29s/it, lr=0.00025, test_MAE=0.542, time=29.9, train_MAE=0.252, train_loss=0.252, val_MAE=0.552, val_loss=0.552]Epoch    55: reducing learning rate of group 0 to 1.2500e-04.
Epoch 54:   6%|▌         | 55/1000 [32:10<7:55:06, 30.17s/it, lr=0.00025, test_MAE=0.542, time=29.9, train_MAE=0.252, train_loss=0.252, val_MAE=0.552, val_loss=0.552]Epoch 55:   6%|▌         | 55/1000 [32:10<7:55:06, 30.17s/it, lr=0.00025, test_MAE=0.542, time=29.9, train_MAE=0.252, train_loss=0.252, val_MAE=0.552, val_loss=0.552]Epoch 55:   6%|▌         | 55/1000 [32:40<7:55:06, 30.17s/it, lr=0.000125, test_MAE=0.465, time=30.3, train_MAE=0.253, train_loss=0.253, val_MAE=0.458, val_loss=0.458]Epoch 55:   6%|▌         | 56/1000 [32:40<7:55:25, 30.22s/it, lr=0.000125, test_MAE=0.465, time=30.3, train_MAE=0.253, train_loss=0.253, val_MAE=0.458, val_loss=0.458]Epoch 56:   6%|▌         | 56/1000 [32:40<7:55:25, 30.22s/it, lr=0.000125, test_MAE=0.465, time=30.3, train_MAE=0.253, train_loss=0.253, val_MAE=0.458, val_loss=0.458]Epoch 56:   6%|▌         | 56/1000 [33:11<7:55:25, 30.22s/it, lr=0.000125, test_MAE=0.473, time=30.4, train_MAE=0.242, train_loss=0.242, val_MAE=0.462, val_loss=0.462]Epoch 56:   6%|▌         | 57/1000 [33:11<7:55:38, 30.26s/it, lr=0.000125, test_MAE=0.473, time=30.4, train_MAE=0.242, train_loss=0.242, val_MAE=0.462, val_loss=0.462]Epoch 57:   6%|▌         | 57/1000 [33:11<7:55:38, 30.26s/it, lr=0.000125, test_MAE=0.473, time=30.4, train_MAE=0.242, train_loss=0.242, val_MAE=0.462, val_loss=0.462]Epoch 57:   6%|▌         | 57/1000 [33:41<7:55:38, 30.26s/it, lr=0.000125, test_MAE=0.462, time=29.8, train_MAE=0.245, train_loss=0.245, val_MAE=0.45, val_loss=0.45]  Epoch 57:   6%|▌         | 58/1000 [33:41<7:53:00, 30.13s/it, lr=0.000125, test_MAE=0.462, time=29.8, train_MAE=0.245, train_loss=0.245, val_MAE=0.45, val_loss=0.45]Epoch 58:   6%|▌         | 58/1000 [33:41<7:53:00, 30.13s/it, lr=0.000125, test_MAE=0.462, time=29.8, train_MAE=0.245, train_loss=0.245, val_MAE=0.45, val_loss=0.45]Epoch 58:   6%|▌         | 58/1000 [34:11<7:53:00, 30.13s/it, lr=0.000125, test_MAE=0.459, time=30.1, train_MAE=0.238, train_loss=0.238, val_MAE=0.451, val_loss=0.451]Epoch 58:   6%|▌         | 59/1000 [34:11<7:52:29, 30.13s/it, lr=0.000125, test_MAE=0.459, time=30.1, train_MAE=0.238, train_loss=0.238, val_MAE=0.451, val_loss=0.451]Epoch 59:   6%|▌         | 59/1000 [34:11<7:52:29, 30.13s/it, lr=0.000125, test_MAE=0.459, time=30.1, train_MAE=0.238, train_loss=0.238, val_MAE=0.451, val_loss=0.451]Epoch 59:   6%|▌         | 59/1000 [34:41<7:52:29, 30.13s/it, lr=0.000125, test_MAE=0.461, time=30.6, train_MAE=0.246, train_loss=0.246, val_MAE=0.452, val_loss=0.452]Epoch 59:   6%|▌         | 60/1000 [34:41<7:54:09, 30.27s/it, lr=0.000125, test_MAE=0.461, time=30.6, train_MAE=0.246, train_loss=0.246, val_MAE=0.452, val_loss=0.452]Epoch 60:   6%|▌         | 60/1000 [34:41<7:54:09, 30.27s/it, lr=0.000125, test_MAE=0.461, time=30.6, train_MAE=0.246, train_loss=0.246, val_MAE=0.452, val_loss=0.452]Epoch 60:   6%|▌         | 60/1000 [35:11<7:54:09, 30.27s/it, lr=0.000125, test_MAE=0.472, time=30.2, train_MAE=0.233, train_loss=0.233, val_MAE=0.462, val_loss=0.462]Epoch    61: reducing learning rate of group 0 to 6.2500e-05.
Epoch 60:   6%|▌         | 61/1000 [35:11<7:53:19, 30.24s/it, lr=0.000125, test_MAE=0.472, time=30.2, train_MAE=0.233, train_loss=0.233, val_MAE=0.462, val_loss=0.462]Epoch 61:   6%|▌         | 61/1000 [35:11<7:53:19, 30.24s/it, lr=0.000125, test_MAE=0.472, time=30.2, train_MAE=0.233, train_loss=0.233, val_MAE=0.462, val_loss=0.462]Epoch 61:   6%|▌         | 61/1000 [35:42<7:53:19, 30.24s/it, lr=6.25e-5, test_MAE=0.463, time=30.1, train_MAE=0.236, train_loss=0.236, val_MAE=0.464, val_loss=0.464] Epoch 61:   6%|▌         | 62/1000 [35:42<7:52:08, 30.20s/it, lr=6.25e-5, test_MAE=0.463, time=30.1, train_MAE=0.236, train_loss=0.236, val_MAE=0.464, val_loss=0.464]Epoch 62:   6%|▌         | 62/1000 [35:42<7:52:08, 30.20s/it, lr=6.25e-5, test_MAE=0.463, time=30.1, train_MAE=0.236, train_loss=0.236, val_MAE=0.464, val_loss=0.464]Epoch 62:   6%|▌         | 62/1000 [36:12<7:52:08, 30.20s/it, lr=6.25e-5, test_MAE=0.459, time=30.4, train_MAE=0.239, train_loss=0.239, val_MAE=0.455, val_loss=0.455]Epoch 62:   6%|▋         | 63/1000 [36:12<7:52:50, 30.28s/it, lr=6.25e-5, test_MAE=0.459, time=30.4, train_MAE=0.239, train_loss=0.239, val_MAE=0.455, val_loss=0.455]Epoch 63:   6%|▋         | 63/1000 [36:12<7:52:50, 30.28s/it, lr=6.25e-5, test_MAE=0.459, time=30.4, train_MAE=0.239, train_loss=0.239, val_MAE=0.455, val_loss=0.455]Epoch 63:   6%|▋         | 63/1000 [36:42<7:52:50, 30.28s/it, lr=6.25e-5, test_MAE=0.48, time=30.1, train_MAE=0.234, train_loss=0.234, val_MAE=0.481, val_loss=0.481] Epoch 63:   6%|▋         | 64/1000 [36:42<7:51:25, 30.22s/it, lr=6.25e-5, test_MAE=0.48, time=30.1, train_MAE=0.234, train_loss=0.234, val_MAE=0.481, val_loss=0.481]Epoch 64:   6%|▋         | 64/1000 [36:42<7:51:25, 30.22s/it, lr=6.25e-5, test_MAE=0.48, time=30.1, train_MAE=0.234, train_loss=0.234, val_MAE=0.481, val_loss=0.481]Epoch 64:   6%|▋         | 64/1000 [37:12<7:51:25, 30.22s/it, lr=6.25e-5, test_MAE=0.466, time=30.1, train_MAE=0.232, train_loss=0.232, val_MAE=0.465, val_loss=0.465]Epoch 64:   6%|▋         | 65/1000 [37:12<7:50:28, 30.19s/it, lr=6.25e-5, test_MAE=0.466, time=30.1, train_MAE=0.232, train_loss=0.232, val_MAE=0.465, val_loss=0.465]Epoch 65:   6%|▋         | 65/1000 [37:12<7:50:28, 30.19s/it, lr=6.25e-5, test_MAE=0.466, time=30.1, train_MAE=0.232, train_loss=0.232, val_MAE=0.465, val_loss=0.465]Epoch 65:   6%|▋         | 65/1000 [37:42<7:50:28, 30.19s/it, lr=6.25e-5, test_MAE=0.466, time=30.1, train_MAE=0.232, train_loss=0.232, val_MAE=0.457, val_loss=0.457]Epoch 65:   7%|▋         | 66/1000 [37:42<7:49:25, 30.16s/it, lr=6.25e-5, test_MAE=0.466, time=30.1, train_MAE=0.232, train_loss=0.232, val_MAE=0.457, val_loss=0.457]Epoch 66:   7%|▋         | 66/1000 [37:42<7:49:25, 30.16s/it, lr=6.25e-5, test_MAE=0.466, time=30.1, train_MAE=0.232, train_loss=0.232, val_MAE=0.457, val_loss=0.457]Epoch 66:   7%|▋         | 66/1000 [38:13<7:49:25, 30.16s/it, lr=6.25e-5, test_MAE=0.462, time=30.4, train_MAE=0.227, train_loss=0.227, val_MAE=0.458, val_loss=0.458]Epoch    67: reducing learning rate of group 0 to 3.1250e-05.
Epoch 66:   7%|▋         | 67/1000 [38:13<7:50:03, 30.23s/it, lr=6.25e-5, test_MAE=0.462, time=30.4, train_MAE=0.227, train_loss=0.227, val_MAE=0.458, val_loss=0.458]Epoch 67:   7%|▋         | 67/1000 [38:13<7:50:03, 30.23s/it, lr=6.25e-5, test_MAE=0.462, time=30.4, train_MAE=0.227, train_loss=0.227, val_MAE=0.458, val_loss=0.458]Epoch 67:   7%|▋         | 67/1000 [38:43<7:50:03, 30.23s/it, lr=3.13e-5, test_MAE=0.467, time=30.1, train_MAE=0.221, train_loss=0.221, val_MAE=0.465, val_loss=0.465]Epoch 67:   7%|▋         | 68/1000 [38:43<7:48:48, 30.18s/it, lr=3.13e-5, test_MAE=0.467, time=30.1, train_MAE=0.221, train_loss=0.221, val_MAE=0.465, val_loss=0.465]Epoch 68:   7%|▋         | 68/1000 [38:43<7:48:48, 30.18s/it, lr=3.13e-5, test_MAE=0.467, time=30.1, train_MAE=0.221, train_loss=0.221, val_MAE=0.465, val_loss=0.465]Epoch 68:   7%|▋         | 68/1000 [39:13<7:48:48, 30.18s/it, lr=3.13e-5, test_MAE=0.464, time=30.1, train_MAE=0.222, train_loss=0.222, val_MAE=0.461, val_loss=0.461]Epoch 68:   7%|▋         | 69/1000 [39:13<7:47:48, 30.15s/it, lr=3.13e-5, test_MAE=0.464, time=30.1, train_MAE=0.222, train_loss=0.222, val_MAE=0.461, val_loss=0.461]Epoch 69:   7%|▋         | 69/1000 [39:13<7:47:48, 30.15s/it, lr=3.13e-5, test_MAE=0.464, time=30.1, train_MAE=0.222, train_loss=0.222, val_MAE=0.461, val_loss=0.461]Epoch 69:   7%|▋         | 69/1000 [39:43<7:47:48, 30.15s/it, lr=3.13e-5, test_MAE=0.465, time=30.4, train_MAE=0.224, train_loss=0.224, val_MAE=0.463, val_loss=0.463]Epoch 69:   7%|▋         | 70/1000 [39:43<7:48:25, 30.22s/it, lr=3.13e-5, test_MAE=0.465, time=30.4, train_MAE=0.224, train_loss=0.224, val_MAE=0.463, val_loss=0.463]Epoch 70:   7%|▋         | 70/1000 [39:43<7:48:25, 30.22s/it, lr=3.13e-5, test_MAE=0.465, time=30.4, train_MAE=0.224, train_loss=0.224, val_MAE=0.463, val_loss=0.463]Epoch 70:   7%|▋         | 70/1000 [40:13<7:48:25, 30.22s/it, lr=3.13e-5, test_MAE=0.472, time=30.1, train_MAE=0.221, train_loss=0.221, val_MAE=0.471, val_loss=0.471]Epoch 70:   7%|▋         | 71/1000 [40:13<7:47:25, 30.19s/it, lr=3.13e-5, test_MAE=0.472, time=30.1, train_MAE=0.221, train_loss=0.221, val_MAE=0.471, val_loss=0.471]Epoch 71:   7%|▋         | 71/1000 [40:13<7:47:25, 30.19s/it, lr=3.13e-5, test_MAE=0.472, time=30.1, train_MAE=0.221, train_loss=0.221, val_MAE=0.471, val_loss=0.471]Epoch 71:   7%|▋         | 71/1000 [40:43<7:47:25, 30.19s/it, lr=3.13e-5, test_MAE=0.462, time=30.1, train_MAE=0.228, train_loss=0.228, val_MAE=0.459, val_loss=0.459]Epoch 71:   7%|▋         | 72/1000 [40:43<7:46:37, 30.17s/it, lr=3.13e-5, test_MAE=0.462, time=30.1, train_MAE=0.228, train_loss=0.228, val_MAE=0.459, val_loss=0.459]Epoch 72:   7%|▋         | 72/1000 [40:43<7:46:37, 30.17s/it, lr=3.13e-5, test_MAE=0.462, time=30.1, train_MAE=0.228, train_loss=0.228, val_MAE=0.459, val_loss=0.459]Epoch 72:   7%|▋         | 72/1000 [41:14<7:46:37, 30.17s/it, lr=3.13e-5, test_MAE=0.461, time=30.1, train_MAE=0.223, train_loss=0.223, val_MAE=0.456, val_loss=0.456]Epoch    73: reducing learning rate of group 0 to 1.5625e-05.
Epoch 72:   7%|▋         | 73/1000 [41:14<7:45:44, 30.14s/it, lr=3.13e-5, test_MAE=0.461, time=30.1, train_MAE=0.223, train_loss=0.223, val_MAE=0.456, val_loss=0.456]Epoch 73:   7%|▋         | 73/1000 [41:14<7:45:44, 30.14s/it, lr=3.13e-5, test_MAE=0.461, time=30.1, train_MAE=0.223, train_loss=0.223, val_MAE=0.456, val_loss=0.456]Epoch 73:   7%|▋         | 73/1000 [41:44<7:45:44, 30.14s/it, lr=1.56e-5, test_MAE=0.465, time=30.4, train_MAE=0.223, train_loss=0.223, val_MAE=0.463, val_loss=0.463]Epoch 73:   7%|▋         | 74/1000 [41:44<7:46:27, 30.22s/it, lr=1.56e-5, test_MAE=0.465, time=30.4, train_MAE=0.223, train_loss=0.223, val_MAE=0.463, val_loss=0.463]Epoch 74:   7%|▋         | 74/1000 [41:44<7:46:27, 30.22s/it, lr=1.56e-5, test_MAE=0.465, time=30.4, train_MAE=0.223, train_loss=0.223, val_MAE=0.463, val_loss=0.463]Epoch 74:   7%|▋         | 74/1000 [42:14<7:46:27, 30.22s/it, lr=1.56e-5, test_MAE=0.468, time=30.3, train_MAE=0.218, train_loss=0.218, val_MAE=0.47, val_loss=0.47]  Epoch 74:   8%|▊         | 75/1000 [42:14<7:46:39, 30.27s/it, lr=1.56e-5, test_MAE=0.468, time=30.3, train_MAE=0.218, train_loss=0.218, val_MAE=0.47, val_loss=0.47]Epoch 75:   8%|▊         | 75/1000 [42:14<7:46:39, 30.27s/it, lr=1.56e-5, test_MAE=0.468, time=30.3, train_MAE=0.218, train_loss=0.218, val_MAE=0.47, val_loss=0.47]Epoch 75:   8%|▊         | 75/1000 [42:44<7:46:39, 30.27s/it, lr=1.56e-5, test_MAE=0.466, time=29.8, train_MAE=0.218, train_loss=0.218, val_MAE=0.467, val_loss=0.467]Epoch 75:   8%|▊         | 76/1000 [42:44<7:44:11, 30.14s/it, lr=1.56e-5, test_MAE=0.466, time=29.8, train_MAE=0.218, train_loss=0.218, val_MAE=0.467, val_loss=0.467]Epoch 76:   8%|▊         | 76/1000 [42:44<7:44:11, 30.14s/it, lr=1.56e-5, test_MAE=0.466, time=29.8, train_MAE=0.218, train_loss=0.218, val_MAE=0.467, val_loss=0.467]Epoch 76:   8%|▊         | 76/1000 [43:15<7:44:11, 30.14s/it, lr=1.56e-5, test_MAE=0.464, time=30.4, train_MAE=0.22, train_loss=0.22, val_MAE=0.461, val_loss=0.461]  Epoch 76:   8%|▊         | 77/1000 [43:15<7:44:48, 30.22s/it, lr=1.56e-5, test_MAE=0.464, time=30.4, train_MAE=0.22, train_loss=0.22, val_MAE=0.461, val_loss=0.461]Epoch 77:   8%|▊         | 77/1000 [43:15<7:44:48, 30.22s/it, lr=1.56e-5, test_MAE=0.464, time=30.4, train_MAE=0.22, train_loss=0.22, val_MAE=0.461, val_loss=0.461]Epoch 77:   8%|▊         | 77/1000 [43:45<7:44:48, 30.22s/it, lr=1.56e-5, test_MAE=0.461, time=30.4, train_MAE=0.218, train_loss=0.218, val_MAE=0.457, val_loss=0.457]Epoch 77:   8%|▊         | 78/1000 [43:45<7:45:02, 30.26s/it, lr=1.56e-5, test_MAE=0.461, time=30.4, train_MAE=0.218, train_loss=0.218, val_MAE=0.457, val_loss=0.457]Epoch 78:   8%|▊         | 78/1000 [43:45<7:45:02, 30.26s/it, lr=1.56e-5, test_MAE=0.461, time=30.4, train_MAE=0.218, train_loss=0.218, val_MAE=0.457, val_loss=0.457]Epoch 78:   8%|▊         | 78/1000 [44:15<7:45:02, 30.26s/it, lr=1.56e-5, test_MAE=0.464, time=29.8, train_MAE=0.218, train_loss=0.218, val_MAE=0.463, val_loss=0.463]Epoch    79: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 78:   8%|▊         | 78/1000 [44:15<8:43:06, 34.04s/it, lr=1.56e-5, test_MAE=0.464, time=29.8, train_MAE=0.218, train_loss=0.218, val_MAE=0.463, val_loss=0.463]
Test MAE: 0.4644
Train MAE: 0.1924
Convergence Time (Epochs): 78.0000
TOTAL TIME TAKEN: 2675.2963s
AVG TIME PER EPOCH: 33.5941s
