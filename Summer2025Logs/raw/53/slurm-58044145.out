I'm echoing to stdout
I'm echoing to stderr
My JobID is 58044145
I have 4 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.0360s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 2, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': False, 'self_loop': False, 'subtype': 'poly_mlp', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_all', 'num_eigs': 16, 'bias_mode': 'spatial', 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 0.0, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/aug07/zinc_train_rec.csv', 'test': 'supp_data/molecules/aug07/zinc_test_rec.csv', 'val': 'supp_data/molecules/aug07/zinc_val_rec.csv'}, 'fixMissingPhi1': False, 'extraOrtho': False, 'doublePrecision': True, 'eigval_hidden_dim': 100, 'eigval_num_hidden_layer': 0, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [01:20<?, ?it/s, lr=0.001, test_MAE=1.01, time=80.9, train_MAE=1.31, train_loss=1.31, val_MAE=0.945, val_loss=0.945]Epoch 0:   0%|          | 1/1000 [01:20<22:28:23, 80.98s/it, lr=0.001, test_MAE=1.01, time=80.9, train_MAE=1.31, train_loss=1.31, val_MAE=0.945, val_loss=0.945]Epoch 1:   0%|          | 1/1000 [01:20<22:28:23, 80.98s/it, lr=0.001, test_MAE=1.01, time=80.9, train_MAE=1.31, train_loss=1.31, val_MAE=0.945, val_loss=0.945]Epoch 1:   0%|          | 1/1000 [02:24<22:28:23, 80.98s/it, lr=0.001, test_MAE=0.783, time=63.3, train_MAE=0.792, train_loss=0.792, val_MAE=0.754, val_loss=0.754]Epoch 1:   0%|          | 2/1000 [02:24<20:58:38, 75.67s/it, lr=0.001, test_MAE=0.783, time=63.3, train_MAE=0.792, train_loss=0.792, val_MAE=0.754, val_loss=0.754]Epoch 2:   0%|          | 2/1000 [02:24<20:58:38, 75.67s/it, lr=0.001, test_MAE=0.783, time=63.3, train_MAE=0.792, train_loss=0.792, val_MAE=0.754, val_loss=0.754]Epoch 2:   0%|          | 2/1000 [03:27<20:58:38, 75.67s/it, lr=0.001, test_MAE=0.726, time=63.2, train_MAE=0.708, train_loss=0.708, val_MAE=0.703, val_loss=0.703]Epoch 2:   0%|          | 3/1000 [03:27<19:55:13, 71.93s/it, lr=0.001, test_MAE=0.726, time=63.2, train_MAE=0.708, train_loss=0.708, val_MAE=0.703, val_loss=0.703]Epoch 3:   0%|          | 3/1000 [03:27<19:55:13, 71.93s/it, lr=0.001, test_MAE=0.726, time=63.2, train_MAE=0.708, train_loss=0.708, val_MAE=0.703, val_loss=0.703]Epoch 3:   0%|          | 3/1000 [04:30<19:55:13, 71.93s/it, lr=0.001, test_MAE=0.755, time=62.9, train_MAE=0.662, train_loss=0.662, val_MAE=0.725, val_loss=0.725]Epoch 3:   0%|          | 4/1000 [04:30<19:09:15, 69.23s/it, lr=0.001, test_MAE=0.755, time=62.9, train_MAE=0.662, train_loss=0.662, val_MAE=0.725, val_loss=0.725]Epoch 4:   0%|          | 4/1000 [04:30<19:09:15, 69.23s/it, lr=0.001, test_MAE=0.755, time=62.9, train_MAE=0.662, train_loss=0.662, val_MAE=0.725, val_loss=0.725]Epoch 4:   0%|          | 4/1000 [05:33<19:09:15, 69.23s/it, lr=0.001, test_MAE=0.651, time=62.9, train_MAE=0.632, train_loss=0.632, val_MAE=0.614, val_loss=0.614]Epoch 4:   0%|          | 5/1000 [05:33<18:36:40, 67.34s/it, lr=0.001, test_MAE=0.651, time=62.9, train_MAE=0.632, train_loss=0.632, val_MAE=0.614, val_loss=0.614]Epoch 5:   0%|          | 5/1000 [05:33<18:36:40, 67.34s/it, lr=0.001, test_MAE=0.651, time=62.9, train_MAE=0.632, train_loss=0.632, val_MAE=0.614, val_loss=0.614]Epoch 5:   0%|          | 5/1000 [06:36<18:36:40, 67.34s/it, lr=0.001, test_MAE=0.65, time=63, train_MAE=0.624, train_loss=0.624, val_MAE=0.618, val_loss=0.618]   Epoch 5:   1%|          | 6/1000 [06:36<18:14:12, 66.05s/it, lr=0.001, test_MAE=0.65, time=63, train_MAE=0.624, train_loss=0.624, val_MAE=0.618, val_loss=0.618]Epoch 6:   1%|          | 6/1000 [06:36<18:14:12, 66.05s/it, lr=0.001, test_MAE=0.65, time=63, train_MAE=0.624, train_loss=0.624, val_MAE=0.618, val_loss=0.618]Epoch 6:   1%|          | 6/1000 [07:39<18:14:12, 66.05s/it, lr=0.001, test_MAE=0.64, time=63.3, train_MAE=0.621, train_loss=0.621, val_MAE=0.599, val_loss=0.599]Epoch 6:   1%|          | 7/1000 [07:39<17:59:36, 65.23s/it, lr=0.001, test_MAE=0.64, time=63.3, train_MAE=0.621, train_loss=0.621, val_MAE=0.599, val_loss=0.599]Epoch 7:   1%|          | 7/1000 [07:39<17:59:36, 65.23s/it, lr=0.001, test_MAE=0.64, time=63.3, train_MAE=0.621, train_loss=0.621, val_MAE=0.599, val_loss=0.599]Epoch 7:   1%|          | 7/1000 [08:42<17:59:36, 65.23s/it, lr=0.001, test_MAE=0.691, time=63.1, train_MAE=0.601, train_loss=0.601, val_MAE=0.652, val_loss=0.652]Epoch 7:   1%|          | 8/1000 [08:42<17:47:52, 64.59s/it, lr=0.001, test_MAE=0.691, time=63.1, train_MAE=0.601, train_loss=0.601, val_MAE=0.652, val_loss=0.652]Epoch 8:   1%|          | 8/1000 [08:42<17:47:52, 64.59s/it, lr=0.001, test_MAE=0.691, time=63.1, train_MAE=0.601, train_loss=0.601, val_MAE=0.652, val_loss=0.652]Epoch 8:   1%|          | 8/1000 [09:45<17:47:52, 64.59s/it, lr=0.001, test_MAE=0.64, time=63.2, train_MAE=0.601, train_loss=0.601, val_MAE=0.598, val_loss=0.598] Epoch 8:   1%|          | 9/1000 [09:45<17:39:53, 64.17s/it, lr=0.001, test_MAE=0.64, time=63.2, train_MAE=0.601, train_loss=0.601, val_MAE=0.598, val_loss=0.598]Epoch 9:   1%|          | 9/1000 [09:45<17:39:53, 64.17s/it, lr=0.001, test_MAE=0.64, time=63.2, train_MAE=0.601, train_loss=0.601, val_MAE=0.598, val_loss=0.598]Epoch 9:   1%|          | 9/1000 [10:49<17:39:53, 64.17s/it, lr=0.001, test_MAE=0.685, time=63.3, train_MAE=0.591, train_loss=0.591, val_MAE=0.649, val_loss=0.649]Epoch 9:   1%|          | 10/1000 [10:49<17:34:22, 63.90s/it, lr=0.001, test_MAE=0.685, time=63.3, train_MAE=0.591, train_loss=0.591, val_MAE=0.649, val_loss=0.649]Epoch 10:   1%|          | 10/1000 [10:49<17:34:22, 63.90s/it, lr=0.001, test_MAE=0.685, time=63.3, train_MAE=0.591, train_loss=0.591, val_MAE=0.649, val_loss=0.649]Epoch 10:   1%|          | 10/1000 [11:52<17:34:22, 63.90s/it, lr=0.001, test_MAE=0.636, time=62.9, train_MAE=0.594, train_loss=0.594, val_MAE=0.593, val_loss=0.593]Epoch 10:   1%|          | 11/1000 [11:52<17:28:39, 63.62s/it, lr=0.001, test_MAE=0.636, time=62.9, train_MAE=0.594, train_loss=0.594, val_MAE=0.593, val_loss=0.593]Epoch 11:   1%|          | 11/1000 [11:52<17:28:39, 63.62s/it, lr=0.001, test_MAE=0.636, time=62.9, train_MAE=0.594, train_loss=0.594, val_MAE=0.593, val_loss=0.593]Epoch 11:   1%|          | 11/1000 [12:54<17:28:39, 63.62s/it, lr=0.001, test_MAE=0.62, time=62.6, train_MAE=0.574, train_loss=0.574, val_MAE=0.581, val_loss=0.581] Epoch 11:   1%|          | 12/1000 [12:54<17:22:45, 63.33s/it, lr=0.001, test_MAE=0.62, time=62.6, train_MAE=0.574, train_loss=0.574, val_MAE=0.581, val_loss=0.581]Epoch 12:   1%|          | 12/1000 [12:54<17:22:45, 63.33s/it, lr=0.001, test_MAE=0.62, time=62.6, train_MAE=0.574, train_loss=0.574, val_MAE=0.581, val_loss=0.581]Epoch 12:   1%|          | 12/1000 [13:58<17:22:45, 63.33s/it, lr=0.001, test_MAE=0.627, time=63.2, train_MAE=0.58, train_loss=0.58, val_MAE=0.586, val_loss=0.586] Epoch 12:   1%|▏         | 13/1000 [13:58<17:21:12, 63.30s/it, lr=0.001, test_MAE=0.627, time=63.2, train_MAE=0.58, train_loss=0.58, val_MAE=0.586, val_loss=0.586]Epoch 13:   1%|▏         | 13/1000 [13:58<17:21:12, 63.30s/it, lr=0.001, test_MAE=0.627, time=63.2, train_MAE=0.58, train_loss=0.58, val_MAE=0.586, val_loss=0.586]Epoch 13:   1%|▏         | 13/1000 [15:01<17:21:12, 63.30s/it, lr=0.001, test_MAE=0.626, time=63, train_MAE=0.585, train_loss=0.585, val_MAE=0.586, val_loss=0.586]Epoch 13:   1%|▏         | 14/1000 [15:01<17:18:32, 63.20s/it, lr=0.001, test_MAE=0.626, time=63, train_MAE=0.585, train_loss=0.585, val_MAE=0.586, val_loss=0.586]Epoch 14:   1%|▏         | 14/1000 [15:01<17:18:32, 63.20s/it, lr=0.001, test_MAE=0.626, time=63, train_MAE=0.585, train_loss=0.585, val_MAE=0.586, val_loss=0.586]Epoch 14:   1%|▏         | 14/1000 [16:03<17:18:32, 63.20s/it, lr=0.001, test_MAE=0.622, time=62.6, train_MAE=0.573, train_loss=0.573, val_MAE=0.586, val_loss=0.586]Epoch 14:   2%|▏         | 15/1000 [16:03<17:14:36, 63.02s/it, lr=0.001, test_MAE=0.622, time=62.6, train_MAE=0.573, train_loss=0.573, val_MAE=0.586, val_loss=0.586]Epoch 15:   2%|▏         | 15/1000 [16:03<17:14:36, 63.02s/it, lr=0.001, test_MAE=0.622, time=62.6, train_MAE=0.573, train_loss=0.573, val_MAE=0.586, val_loss=0.586]Epoch 15:   2%|▏         | 15/1000 [17:06<17:14:36, 63.02s/it, lr=0.001, test_MAE=0.631, time=63.3, train_MAE=0.567, train_loss=0.567, val_MAE=0.589, val_loss=0.589]Epoch 15:   2%|▏         | 16/1000 [17:06<17:15:08, 63.12s/it, lr=0.001, test_MAE=0.631, time=63.3, train_MAE=0.567, train_loss=0.567, val_MAE=0.589, val_loss=0.589]Epoch 16:   2%|▏         | 16/1000 [17:06<17:15:08, 63.12s/it, lr=0.001, test_MAE=0.631, time=63.3, train_MAE=0.567, train_loss=0.567, val_MAE=0.589, val_loss=0.589]Epoch 16:   2%|▏         | 16/1000 [18:09<17:15:08, 63.12s/it, lr=0.001, test_MAE=0.628, time=62.9, train_MAE=0.56, train_loss=0.56, val_MAE=0.599, val_loss=0.599]  Epoch 16:   2%|▏         | 17/1000 [18:10<17:13:47, 63.10s/it, lr=0.001, test_MAE=0.628, time=62.9, train_MAE=0.56, train_loss=0.56, val_MAE=0.599, val_loss=0.599]Epoch 17:   2%|▏         | 17/1000 [18:10<17:13:47, 63.10s/it, lr=0.001, test_MAE=0.628, time=62.9, train_MAE=0.56, train_loss=0.56, val_MAE=0.599, val_loss=0.599]Epoch 17:   2%|▏         | 17/1000 [19:12<17:13:47, 63.10s/it, lr=0.001, test_MAE=0.648, time=62.6, train_MAE=0.563, train_loss=0.563, val_MAE=0.604, val_loss=0.604]Epoch    18: reducing learning rate of group 0 to 5.0000e-04.
Epoch 17:   2%|▏         | 18/1000 [19:12<17:10:31, 62.96s/it, lr=0.001, test_MAE=0.648, time=62.6, train_MAE=0.563, train_loss=0.563, val_MAE=0.604, val_loss=0.604]Epoch 18:   2%|▏         | 18/1000 [19:12<17:10:31, 62.96s/it, lr=0.001, test_MAE=0.648, time=62.6, train_MAE=0.563, train_loss=0.563, val_MAE=0.604, val_loss=0.604]Epoch 18:   2%|▏         | 18/1000 [20:15<17:10:31, 62.96s/it, lr=0.0005, test_MAE=0.616, time=63.2, train_MAE=0.556, train_loss=0.556, val_MAE=0.578, val_loss=0.578]Epoch 18:   2%|▏         | 19/1000 [20:15<17:10:54, 63.05s/it, lr=0.0005, test_MAE=0.616, time=63.2, train_MAE=0.556, train_loss=0.556, val_MAE=0.578, val_loss=0.578]Epoch 19:   2%|▏         | 19/1000 [20:15<17:10:54, 63.05s/it, lr=0.0005, test_MAE=0.616, time=63.2, train_MAE=0.556, train_loss=0.556, val_MAE=0.578, val_loss=0.578]Epoch 19:   2%|▏         | 19/1000 [21:18<17:10:54, 63.05s/it, lr=0.0005, test_MAE=0.603, time=62.9, train_MAE=0.549, train_loss=0.549, val_MAE=0.568, val_loss=0.568]Epoch 19:   2%|▏         | 20/1000 [21:18<17:09:10, 63.01s/it, lr=0.0005, test_MAE=0.603, time=62.9, train_MAE=0.549, train_loss=0.549, val_MAE=0.568, val_loss=0.568]Epoch 20:   2%|▏         | 20/1000 [21:18<17:09:10, 63.01s/it, lr=0.0005, test_MAE=0.603, time=62.9, train_MAE=0.549, train_loss=0.549, val_MAE=0.568, val_loss=0.568]Epoch 20:   2%|▏         | 20/1000 [22:21<17:09:10, 63.01s/it, lr=0.0005, test_MAE=0.601, time=62.9, train_MAE=0.547, train_loss=0.547, val_MAE=0.558, val_loss=0.558]Epoch 20:   2%|▏         | 21/1000 [22:21<17:07:52, 63.00s/it, lr=0.0005, test_MAE=0.601, time=62.9, train_MAE=0.547, train_loss=0.547, val_MAE=0.558, val_loss=0.558]Epoch 21:   2%|▏         | 21/1000 [22:21<17:07:52, 63.00s/it, lr=0.0005, test_MAE=0.601, time=62.9, train_MAE=0.547, train_loss=0.547, val_MAE=0.558, val_loss=0.558]Epoch 21:   2%|▏         | 21/1000 [23:25<17:07:52, 63.00s/it, lr=0.0005, test_MAE=0.598, time=63.4, train_MAE=0.545, train_loss=0.545, val_MAE=0.561, val_loss=0.561]Epoch 21:   2%|▏         | 22/1000 [23:25<17:08:53, 63.12s/it, lr=0.0005, test_MAE=0.598, time=63.4, train_MAE=0.545, train_loss=0.545, val_MAE=0.561, val_loss=0.561]Epoch 22:   2%|▏         | 22/1000 [23:25<17:08:53, 63.12s/it, lr=0.0005, test_MAE=0.598, time=63.4, train_MAE=0.545, train_loss=0.545, val_MAE=0.561, val_loss=0.561]Epoch 22:   2%|▏         | 22/1000 [24:28<17:08:53, 63.12s/it, lr=0.0005, test_MAE=0.595, time=63.4, train_MAE=0.543, train_loss=0.543, val_MAE=0.562, val_loss=0.562]Epoch 22:   2%|▏         | 23/1000 [24:28<17:09:38, 63.23s/it, lr=0.0005, test_MAE=0.595, time=63.4, train_MAE=0.543, train_loss=0.543, val_MAE=0.562, val_loss=0.562]Epoch 23:   2%|▏         | 23/1000 [24:28<17:09:38, 63.23s/it, lr=0.0005, test_MAE=0.595, time=63.4, train_MAE=0.543, train_loss=0.543, val_MAE=0.562, val_loss=0.562]Epoch 23:   2%|▏         | 23/1000 [25:33<17:09:38, 63.23s/it, lr=0.0005, test_MAE=0.597, time=64.4, train_MAE=0.546, train_loss=0.546, val_MAE=0.566, val_loss=0.566]Epoch 23:   2%|▏         | 24/1000 [25:33<17:14:26, 63.59s/it, lr=0.0005, test_MAE=0.597, time=64.4, train_MAE=0.546, train_loss=0.546, val_MAE=0.566, val_loss=0.566]Epoch 24:   2%|▏         | 24/1000 [25:33<17:14:26, 63.59s/it, lr=0.0005, test_MAE=0.597, time=64.4, train_MAE=0.546, train_loss=0.546, val_MAE=0.566, val_loss=0.566]Epoch 24:   2%|▏         | 24/1000 [26:36<17:14:26, 63.59s/it, lr=0.0005, test_MAE=0.595, time=63.7, train_MAE=0.552, train_loss=0.552, val_MAE=0.565, val_loss=0.565]Epoch 24:   2%|▎         | 25/1000 [26:36<17:14:06, 63.64s/it, lr=0.0005, test_MAE=0.595, time=63.7, train_MAE=0.552, train_loss=0.552, val_MAE=0.565, val_loss=0.565]Epoch 25:   2%|▎         | 25/1000 [26:36<17:14:06, 63.64s/it, lr=0.0005, test_MAE=0.595, time=63.7, train_MAE=0.552, train_loss=0.552, val_MAE=0.565, val_loss=0.565]Epoch 25:   2%|▎         | 25/1000 [27:38<17:14:06, 63.64s/it, lr=0.0005, test_MAE=0.594, time=61.8, train_MAE=0.545, train_loss=0.545, val_MAE=0.564, val_loss=0.564]Epoch 25:   3%|▎         | 26/1000 [27:38<17:04:05, 63.09s/it, lr=0.0005, test_MAE=0.594, time=61.8, train_MAE=0.545, train_loss=0.545, val_MAE=0.564, val_loss=0.564]Epoch 26:   3%|▎         | 26/1000 [27:38<17:04:05, 63.09s/it, lr=0.0005, test_MAE=0.594, time=61.8, train_MAE=0.545, train_loss=0.545, val_MAE=0.564, val_loss=0.564]Epoch 26:   3%|▎         | 26/1000 [28:39<17:04:05, 63.09s/it, lr=0.0005, test_MAE=0.594, time=61, train_MAE=0.548, train_loss=0.548, val_MAE=0.561, val_loss=0.561]  Epoch    27: reducing learning rate of group 0 to 2.5000e-04.
Epoch 26:   3%|▎         | 27/1000 [28:39<16:53:12, 62.48s/it, lr=0.0005, test_MAE=0.594, time=61, train_MAE=0.548, train_loss=0.548, val_MAE=0.561, val_loss=0.561]Epoch 27:   3%|▎         | 27/1000 [28:39<16:53:12, 62.48s/it, lr=0.0005, test_MAE=0.594, time=61, train_MAE=0.548, train_loss=0.548, val_MAE=0.561, val_loss=0.561]Epoch 27:   3%|▎         | 27/1000 [29:39<16:53:12, 62.48s/it, lr=0.00025, test_MAE=0.601, time=59.5, train_MAE=0.531, train_loss=0.531, val_MAE=0.561, val_loss=0.561]Epoch 27:   3%|▎         | 28/1000 [29:39<16:37:29, 61.57s/it, lr=0.00025, test_MAE=0.601, time=59.5, train_MAE=0.531, train_loss=0.531, val_MAE=0.561, val_loss=0.561]Epoch 28:   3%|▎         | 28/1000 [29:39<16:37:29, 61.57s/it, lr=0.00025, test_MAE=0.601, time=59.5, train_MAE=0.531, train_loss=0.531, val_MAE=0.561, val_loss=0.561]Epoch 28:   3%|▎         | 28/1000 [30:37<16:37:29, 61.57s/it, lr=0.00025, test_MAE=0.595, time=58.4, train_MAE=0.529, train_loss=0.529, val_MAE=0.558, val_loss=0.558]Epoch 28:   3%|▎         | 29/1000 [30:37<16:21:18, 60.64s/it, lr=0.00025, test_MAE=0.595, time=58.4, train_MAE=0.529, train_loss=0.529, val_MAE=0.558, val_loss=0.558]Epoch 29:   3%|▎         | 29/1000 [30:37<16:21:18, 60.64s/it, lr=0.00025, test_MAE=0.595, time=58.4, train_MAE=0.529, train_loss=0.529, val_MAE=0.558, val_loss=0.558]Epoch 29:   3%|▎         | 29/1000 [31:36<16:21:18, 60.64s/it, lr=0.00025, test_MAE=0.588, time=58.9, train_MAE=0.532, train_loss=0.532, val_MAE=0.559, val_loss=0.559]Epoch 29:   3%|▎         | 30/1000 [31:36<16:11:43, 60.11s/it, lr=0.00025, test_MAE=0.588, time=58.9, train_MAE=0.532, train_loss=0.532, val_MAE=0.559, val_loss=0.559]Epoch 30:   3%|▎         | 30/1000 [31:36<16:11:43, 60.11s/it, lr=0.00025, test_MAE=0.588, time=58.9, train_MAE=0.532, train_loss=0.532, val_MAE=0.559, val_loss=0.559]Epoch 30:   3%|▎         | 30/1000 [32:34<16:11:43, 60.11s/it, lr=0.00025, test_MAE=0.592, time=58.4, train_MAE=0.533, train_loss=0.533, val_MAE=0.557, val_loss=0.557]Epoch 30:   3%|▎         | 31/1000 [32:34<16:02:27, 59.59s/it, lr=0.00025, test_MAE=0.592, time=58.4, train_MAE=0.533, train_loss=0.533, val_MAE=0.557, val_loss=0.557]Epoch 31:   3%|▎         | 31/1000 [32:34<16:02:27, 59.59s/it, lr=0.00025, test_MAE=0.592, time=58.4, train_MAE=0.533, train_loss=0.533, val_MAE=0.557, val_loss=0.557]Epoch 31:   3%|▎         | 31/1000 [33:33<16:02:27, 59.59s/it, lr=0.00025, test_MAE=0.587, time=58.1, train_MAE=0.53, train_loss=0.53, val_MAE=0.556, val_loss=0.556]  Epoch 31:   3%|▎         | 32/1000 [33:33<15:54:03, 59.14s/it, lr=0.00025, test_MAE=0.587, time=58.1, train_MAE=0.53, train_loss=0.53, val_MAE=0.556, val_loss=0.556]Epoch 32:   3%|▎         | 32/1000 [33:33<15:54:03, 59.14s/it, lr=0.00025, test_MAE=0.587, time=58.1, train_MAE=0.53, train_loss=0.53, val_MAE=0.556, val_loss=0.556]Epoch 32:   3%|▎         | 32/1000 [34:31<15:54:03, 59.14s/it, lr=0.00025, test_MAE=0.589, time=58.6, train_MAE=0.527, train_loss=0.527, val_MAE=0.558, val_loss=0.558]Epoch 32:   3%|▎         | 33/1000 [34:31<15:50:39, 58.99s/it, lr=0.00025, test_MAE=0.589, time=58.6, train_MAE=0.527, train_loss=0.527, val_MAE=0.558, val_loss=0.558]Epoch 33:   3%|▎         | 33/1000 [34:31<15:50:39, 58.99s/it, lr=0.00025, test_MAE=0.589, time=58.6, train_MAE=0.527, train_loss=0.527, val_MAE=0.558, val_loss=0.558]Epoch 33:   3%|▎         | 33/1000 [35:30<15:50:39, 58.99s/it, lr=0.00025, test_MAE=0.593, time=58.4, train_MAE=0.529, train_loss=0.529, val_MAE=0.566, val_loss=0.566]Epoch 33:   3%|▎         | 34/1000 [35:30<15:46:43, 58.80s/it, lr=0.00025, test_MAE=0.593, time=58.4, train_MAE=0.529, train_loss=0.529, val_MAE=0.566, val_loss=0.566]Epoch 34:   3%|▎         | 34/1000 [35:30<15:46:43, 58.80s/it, lr=0.00025, test_MAE=0.593, time=58.4, train_MAE=0.529, train_loss=0.529, val_MAE=0.566, val_loss=0.566]Epoch 34:   3%|▎         | 34/1000 [36:28<15:46:43, 58.80s/it, lr=0.00025, test_MAE=0.587, time=58.1, train_MAE=0.526, train_loss=0.526, val_MAE=0.56, val_loss=0.56]  Epoch 34:   4%|▎         | 35/1000 [36:28<15:42:23, 58.59s/it, lr=0.00025, test_MAE=0.587, time=58.1, train_MAE=0.526, train_loss=0.526, val_MAE=0.56, val_loss=0.56]Epoch 35:   4%|▎         | 35/1000 [36:28<15:42:23, 58.59s/it, lr=0.00025, test_MAE=0.587, time=58.1, train_MAE=0.526, train_loss=0.526, val_MAE=0.56, val_loss=0.56]Epoch 35:   4%|▎         | 35/1000 [37:26<15:42:23, 58.59s/it, lr=0.00025, test_MAE=0.589, time=58.6, train_MAE=0.53, train_loss=0.53, val_MAE=0.557, val_loss=0.557]Epoch 35:   4%|▎         | 36/1000 [37:26<15:41:33, 58.60s/it, lr=0.00025, test_MAE=0.589, time=58.6, train_MAE=0.53, train_loss=0.53, val_MAE=0.557, val_loss=0.557]Epoch 36:   4%|▎         | 36/1000 [37:26<15:41:33, 58.60s/it, lr=0.00025, test_MAE=0.589, time=58.6, train_MAE=0.53, train_loss=0.53, val_MAE=0.557, val_loss=0.557]Epoch 36:   4%|▎         | 36/1000 [38:25<15:41:33, 58.60s/it, lr=0.00025, test_MAE=0.588, time=58.4, train_MAE=0.529, train_loss=0.529, val_MAE=0.558, val_loss=0.558]Epoch 36:   4%|▎         | 37/1000 [38:25<15:39:36, 58.54s/it, lr=0.00025, test_MAE=0.588, time=58.4, train_MAE=0.529, train_loss=0.529, val_MAE=0.558, val_loss=0.558]Epoch 37:   4%|▎         | 37/1000 [38:25<15:39:36, 58.54s/it, lr=0.00025, test_MAE=0.588, time=58.4, train_MAE=0.529, train_loss=0.529, val_MAE=0.558, val_loss=0.558]Epoch 37:   4%|▎         | 37/1000 [39:23<15:39:36, 58.54s/it, lr=0.00025, test_MAE=0.593, time=58.1, train_MAE=0.525, train_loss=0.525, val_MAE=0.564, val_loss=0.564]Epoch    38: reducing learning rate of group 0 to 1.2500e-04.
Epoch 37:   4%|▍         | 38/1000 [39:23<15:36:21, 58.40s/it, lr=0.00025, test_MAE=0.593, time=58.1, train_MAE=0.525, train_loss=0.525, val_MAE=0.564, val_loss=0.564]Epoch 38:   4%|▍         | 38/1000 [39:23<15:36:21, 58.40s/it, lr=0.00025, test_MAE=0.593, time=58.1, train_MAE=0.525, train_loss=0.525, val_MAE=0.564, val_loss=0.564]Epoch 38:   4%|▍         | 38/1000 [40:21<15:36:21, 58.40s/it, lr=0.000125, test_MAE=0.586, time=58.6, train_MAE=0.519, train_loss=0.519, val_MAE=0.554, val_loss=0.554]Epoch 38:   4%|▍         | 39/1000 [40:21<15:36:30, 58.47s/it, lr=0.000125, test_MAE=0.586, time=58.6, train_MAE=0.519, train_loss=0.519, val_MAE=0.554, val_loss=0.554]Epoch 39:   4%|▍         | 39/1000 [40:21<15:36:30, 58.47s/it, lr=0.000125, test_MAE=0.586, time=58.6, train_MAE=0.519, train_loss=0.519, val_MAE=0.554, val_loss=0.554]Epoch 39:   4%|▍         | 39/1000 [41:20<15:36:30, 58.47s/it, lr=0.000125, test_MAE=0.585, time=58.4, train_MAE=0.518, train_loss=0.518, val_MAE=0.554, val_loss=0.554]Epoch 39:   4%|▍         | 40/1000 [41:20<15:35:01, 58.44s/it, lr=0.000125, test_MAE=0.585, time=58.4, train_MAE=0.518, train_loss=0.518, val_MAE=0.554, val_loss=0.554]Epoch 40:   4%|▍         | 40/1000 [41:20<15:35:01, 58.44s/it, lr=0.000125, test_MAE=0.585, time=58.4, train_MAE=0.518, train_loss=0.518, val_MAE=0.554, val_loss=0.554]Epoch 40:   4%|▍         | 40/1000 [42:18<15:35:01, 58.44s/it, lr=0.000125, test_MAE=0.584, time=58.3, train_MAE=0.521, train_loss=0.521, val_MAE=0.557, val_loss=0.557]Epoch 40:   4%|▍         | 41/1000 [42:18<15:33:35, 58.41s/it, lr=0.000125, test_MAE=0.584, time=58.3, train_MAE=0.521, train_loss=0.521, val_MAE=0.557, val_loss=0.557]Epoch 41:   4%|▍         | 41/1000 [42:18<15:33:35, 58.41s/it, lr=0.000125, test_MAE=0.584, time=58.3, train_MAE=0.521, train_loss=0.521, val_MAE=0.557, val_loss=0.557]Epoch 41:   4%|▍         | 41/1000 [43:16<15:33:35, 58.41s/it, lr=0.000125, test_MAE=0.59, time=58.4, train_MAE=0.52, train_loss=0.52, val_MAE=0.559, val_loss=0.559]   Epoch 41:   4%|▍         | 42/1000 [43:16<15:32:28, 58.40s/it, lr=0.000125, test_MAE=0.59, time=58.4, train_MAE=0.52, train_loss=0.52, val_MAE=0.559, val_loss=0.559]Epoch 42:   4%|▍         | 42/1000 [43:16<15:32:28, 58.40s/it, lr=0.000125, test_MAE=0.59, time=58.4, train_MAE=0.52, train_loss=0.52, val_MAE=0.559, val_loss=0.559]Epoch 42:   4%|▍         | 42/1000 [44:15<15:32:28, 58.40s/it, lr=0.000125, test_MAE=0.585, time=58.6, train_MAE=0.521, train_loss=0.521, val_MAE=0.556, val_loss=0.556]Epoch 42:   4%|▍         | 43/1000 [44:15<15:32:31, 58.47s/it, lr=0.000125, test_MAE=0.585, time=58.6, train_MAE=0.521, train_loss=0.521, val_MAE=0.556, val_loss=0.556]Epoch 43:   4%|▍         | 43/1000 [44:15<15:32:31, 58.47s/it, lr=0.000125, test_MAE=0.585, time=58.6, train_MAE=0.521, train_loss=0.521, val_MAE=0.556, val_loss=0.556]Epoch 43:   4%|▍         | 43/1000 [45:13<15:32:31, 58.47s/it, lr=0.000125, test_MAE=0.585, time=58.4, train_MAE=0.519, train_loss=0.519, val_MAE=0.559, val_loss=0.559]Epoch 43:   4%|▍         | 44/1000 [45:13<15:31:09, 58.44s/it, lr=0.000125, test_MAE=0.585, time=58.4, train_MAE=0.519, train_loss=0.519, val_MAE=0.559, val_loss=0.559]Epoch 44:   4%|▍         | 44/1000 [45:13<15:31:09, 58.44s/it, lr=0.000125, test_MAE=0.585, time=58.4, train_MAE=0.519, train_loss=0.519, val_MAE=0.559, val_loss=0.559]Epoch 44:   4%|▍         | 44/1000 [46:12<15:31:09, 58.44s/it, lr=0.000125, test_MAE=0.592, time=58.1, train_MAE=0.521, train_loss=0.521, val_MAE=0.558, val_loss=0.558]Epoch    45: reducing learning rate of group 0 to 6.2500e-05.
Epoch 44:   4%|▍         | 45/1000 [46:12<15:28:29, 58.33s/it, lr=0.000125, test_MAE=0.592, time=58.1, train_MAE=0.521, train_loss=0.521, val_MAE=0.558, val_loss=0.558]Epoch 45:   4%|▍         | 45/1000 [46:12<15:28:29, 58.33s/it, lr=0.000125, test_MAE=0.592, time=58.1, train_MAE=0.521, train_loss=0.521, val_MAE=0.558, val_loss=0.558]Epoch 45:   4%|▍         | 45/1000 [47:10<15:28:29, 58.33s/it, lr=6.25e-5, test_MAE=0.584, time=58.6, train_MAE=0.518, train_loss=0.518, val_MAE=0.554, val_loss=0.554] Epoch 45:   5%|▍         | 46/1000 [47:10<15:29:01, 58.43s/it, lr=6.25e-5, test_MAE=0.584, time=58.6, train_MAE=0.518, train_loss=0.518, val_MAE=0.554, val_loss=0.554]Epoch 46:   5%|▍         | 46/1000 [47:10<15:29:01, 58.43s/it, lr=6.25e-5, test_MAE=0.584, time=58.6, train_MAE=0.518, train_loss=0.518, val_MAE=0.554, val_loss=0.554]Epoch 46:   5%|▍         | 46/1000 [48:09<15:29:01, 58.43s/it, lr=6.25e-5, test_MAE=0.586, time=58.3, train_MAE=0.516, train_loss=0.516, val_MAE=0.554, val_loss=0.554]Epoch 46:   5%|▍         | 47/1000 [48:09<15:27:40, 58.41s/it, lr=6.25e-5, test_MAE=0.586, time=58.3, train_MAE=0.516, train_loss=0.516, val_MAE=0.554, val_loss=0.554]Epoch 47:   5%|▍         | 47/1000 [48:09<15:27:40, 58.41s/it, lr=6.25e-5, test_MAE=0.586, time=58.3, train_MAE=0.516, train_loss=0.516, val_MAE=0.554, val_loss=0.554]Epoch 47:   5%|▍         | 47/1000 [49:07<15:27:40, 58.41s/it, lr=6.25e-5, test_MAE=0.583, time=58.1, train_MAE=0.517, train_loss=0.517, val_MAE=0.554, val_loss=0.554]Epoch 47:   5%|▍         | 48/1000 [49:07<15:25:11, 58.31s/it, lr=6.25e-5, test_MAE=0.583, time=58.1, train_MAE=0.517, train_loss=0.517, val_MAE=0.554, val_loss=0.554]Epoch 48:   5%|▍         | 48/1000 [49:07<15:25:11, 58.31s/it, lr=6.25e-5, test_MAE=0.583, time=58.1, train_MAE=0.517, train_loss=0.517, val_MAE=0.554, val_loss=0.554]Epoch 48:   5%|▍         | 48/1000 [50:05<15:25:11, 58.31s/it, lr=6.25e-5, test_MAE=0.583, time=58.6, train_MAE=0.517, train_loss=0.517, val_MAE=0.56, val_loss=0.56]  Epoch 48:   5%|▍         | 49/1000 [50:05<15:25:43, 58.41s/it, lr=6.25e-5, test_MAE=0.583, time=58.6, train_MAE=0.517, train_loss=0.517, val_MAE=0.56, val_loss=0.56]Epoch 49:   5%|▍         | 49/1000 [50:05<15:25:43, 58.41s/it, lr=6.25e-5, test_MAE=0.583, time=58.6, train_MAE=0.517, train_loss=0.517, val_MAE=0.56, val_loss=0.56]Epoch 49:   5%|▍         | 49/1000 [51:04<15:25:43, 58.41s/it, lr=6.25e-5, test_MAE=0.583, time=58.4, train_MAE=0.513, train_loss=0.513, val_MAE=0.555, val_loss=0.555]Epoch 49:   5%|▌         | 50/1000 [51:04<15:24:37, 58.40s/it, lr=6.25e-5, test_MAE=0.583, time=58.4, train_MAE=0.513, train_loss=0.513, val_MAE=0.555, val_loss=0.555]Epoch 50:   5%|▌         | 50/1000 [51:04<15:24:37, 58.40s/it, lr=6.25e-5, test_MAE=0.583, time=58.4, train_MAE=0.513, train_loss=0.513, val_MAE=0.555, val_loss=0.555]Epoch 50:   5%|▌         | 50/1000 [52:02<15:24:37, 58.40s/it, lr=6.25e-5, test_MAE=0.584, time=58.1, train_MAE=0.514, train_loss=0.514, val_MAE=0.555, val_loss=0.555]Epoch 50:   5%|▌         | 51/1000 [52:02<15:22:06, 58.30s/it, lr=6.25e-5, test_MAE=0.584, time=58.1, train_MAE=0.514, train_loss=0.514, val_MAE=0.555, val_loss=0.555]Epoch 51:   5%|▌         | 51/1000 [52:02<15:22:06, 58.30s/it, lr=6.25e-5, test_MAE=0.584, time=58.1, train_MAE=0.514, train_loss=0.514, val_MAE=0.555, val_loss=0.555]Epoch 51:   5%|▌         | 51/1000 [53:00<15:22:06, 58.30s/it, lr=6.25e-5, test_MAE=0.585, time=58.6, train_MAE=0.515, train_loss=0.515, val_MAE=0.555, val_loss=0.555]Epoch    52: reducing learning rate of group 0 to 3.1250e-05.
Epoch 51:   5%|▌         | 52/1000 [53:00<15:22:36, 58.39s/it, lr=6.25e-5, test_MAE=0.585, time=58.6, train_MAE=0.515, train_loss=0.515, val_MAE=0.555, val_loss=0.555]Epoch 52:   5%|▌         | 52/1000 [53:00<15:22:36, 58.39s/it, lr=6.25e-5, test_MAE=0.585, time=58.6, train_MAE=0.515, train_loss=0.515, val_MAE=0.555, val_loss=0.555]Epoch 52:   5%|▌         | 52/1000 [53:59<15:22:36, 58.39s/it, lr=3.13e-5, test_MAE=0.583, time=58.3, train_MAE=0.509, train_loss=0.509, val_MAE=0.554, val_loss=0.554]Epoch 52:   5%|▌         | 53/1000 [53:59<15:21:27, 58.38s/it, lr=3.13e-5, test_MAE=0.583, time=58.3, train_MAE=0.509, train_loss=0.509, val_MAE=0.554, val_loss=0.554]Epoch 53:   5%|▌         | 53/1000 [53:59<15:21:27, 58.38s/it, lr=3.13e-5, test_MAE=0.583, time=58.3, train_MAE=0.509, train_loss=0.509, val_MAE=0.554, val_loss=0.554]Epoch 53:   5%|▌         | 53/1000 [54:57<15:21:27, 58.38s/it, lr=3.13e-5, test_MAE=0.585, time=58.4, train_MAE=0.514, train_loss=0.514, val_MAE=0.555, val_loss=0.555]Epoch 53:   5%|▌         | 54/1000 [54:57<15:20:27, 58.38s/it, lr=3.13e-5, test_MAE=0.585, time=58.4, train_MAE=0.514, train_loss=0.514, val_MAE=0.555, val_loss=0.555]Epoch 54:   5%|▌         | 54/1000 [54:57<15:20:27, 58.38s/it, lr=3.13e-5, test_MAE=0.585, time=58.4, train_MAE=0.514, train_loss=0.514, val_MAE=0.555, val_loss=0.555]Epoch 54:   5%|▌         | 54/1000 [55:55<15:20:27, 58.38s/it, lr=3.13e-5, test_MAE=0.584, time=58.3, train_MAE=0.511, train_loss=0.511, val_MAE=0.554, val_loss=0.554]Epoch 54:   6%|▌         | 55/1000 [55:55<15:19:23, 58.37s/it, lr=3.13e-5, test_MAE=0.584, time=58.3, train_MAE=0.511, train_loss=0.511, val_MAE=0.554, val_loss=0.554]Epoch 55:   6%|▌         | 55/1000 [55:55<15:19:23, 58.37s/it, lr=3.13e-5, test_MAE=0.584, time=58.3, train_MAE=0.511, train_loss=0.511, val_MAE=0.554, val_loss=0.554]Epoch 55:   6%|▌         | 55/1000 [56:54<15:19:23, 58.37s/it, lr=3.13e-5, test_MAE=0.583, time=58.6, train_MAE=0.516, train_loss=0.516, val_MAE=0.554, val_loss=0.554]Epoch 55:   6%|▌         | 56/1000 [56:54<15:19:42, 58.46s/it, lr=3.13e-5, test_MAE=0.583, time=58.6, train_MAE=0.516, train_loss=0.516, val_MAE=0.554, val_loss=0.554]Epoch 56:   6%|▌         | 56/1000 [56:54<15:19:42, 58.46s/it, lr=3.13e-5, test_MAE=0.583, time=58.6, train_MAE=0.516, train_loss=0.516, val_MAE=0.554, val_loss=0.554]Epoch 56:   6%|▌         | 56/1000 [57:52<15:19:42, 58.46s/it, lr=3.13e-5, test_MAE=0.584, time=58.3, train_MAE=0.511, train_loss=0.511, val_MAE=0.553, val_loss=0.553]Epoch 56:   6%|▌         | 57/1000 [57:52<15:18:10, 58.42s/it, lr=3.13e-5, test_MAE=0.584, time=58.3, train_MAE=0.511, train_loss=0.511, val_MAE=0.553, val_loss=0.553]Epoch 57:   6%|▌         | 57/1000 [57:52<15:18:10, 58.42s/it, lr=3.13e-5, test_MAE=0.584, time=58.3, train_MAE=0.511, train_loss=0.511, val_MAE=0.553, val_loss=0.553]Epoch 57:   6%|▌         | 57/1000 [58:50<15:18:10, 58.42s/it, lr=3.13e-5, test_MAE=0.583, time=58.1, train_MAE=0.51, train_loss=0.51, val_MAE=0.555, val_loss=0.555]  Epoch 57:   6%|▌         | 58/1000 [58:51<15:15:43, 58.33s/it, lr=3.13e-5, test_MAE=0.583, time=58.1, train_MAE=0.51, train_loss=0.51, val_MAE=0.555, val_loss=0.555]Epoch 58:   6%|▌         | 58/1000 [58:51<15:15:43, 58.33s/it, lr=3.13e-5, test_MAE=0.583, time=58.1, train_MAE=0.51, train_loss=0.51, val_MAE=0.555, val_loss=0.555]Epoch 58:   6%|▌         | 58/1000 [59:49<15:15:43, 58.33s/it, lr=3.13e-5, test_MAE=0.583, time=58.6, train_MAE=0.512, train_loss=0.512, val_MAE=0.554, val_loss=0.554]Epoch 58:   6%|▌         | 59/1000 [59:49<15:16:04, 58.41s/it, lr=3.13e-5, test_MAE=0.583, time=58.6, train_MAE=0.512, train_loss=0.512, val_MAE=0.554, val_loss=0.554]Epoch 59:   6%|▌         | 59/1000 [59:49<15:16:04, 58.41s/it, lr=3.13e-5, test_MAE=0.583, time=58.6, train_MAE=0.512, train_loss=0.512, val_MAE=0.554, val_loss=0.554]Epoch 59:   6%|▌         | 59/1000 [1:00:47<15:16:04, 58.41s/it, lr=3.13e-5, test_MAE=0.583, time=58.3, train_MAE=0.511, train_loss=0.511, val_MAE=0.554, val_loss=0.554]Epoch 59:   6%|▌         | 60/1000 [1:00:47<15:14:31, 58.37s/it, lr=3.13e-5, test_MAE=0.583, time=58.3, train_MAE=0.511, train_loss=0.511, val_MAE=0.554, val_loss=0.554]Epoch 60:   6%|▌         | 60/1000 [1:00:47<15:14:31, 58.37s/it, lr=3.13e-5, test_MAE=0.583, time=58.3, train_MAE=0.511, train_loss=0.511, val_MAE=0.554, val_loss=0.554]Epoch 60:   6%|▌         | 60/1000 [1:01:45<15:14:31, 58.37s/it, lr=3.13e-5, test_MAE=0.583, time=57.9, train_MAE=0.514, train_loss=0.514, val_MAE=0.553, val_loss=0.553]Epoch 60:   6%|▌         | 61/1000 [1:01:45<15:11:27, 58.24s/it, lr=3.13e-5, test_MAE=0.583, time=57.9, train_MAE=0.514, train_loss=0.514, val_MAE=0.553, val_loss=0.553]Epoch 61:   6%|▌         | 61/1000 [1:01:45<15:11:27, 58.24s/it, lr=3.13e-5, test_MAE=0.583, time=57.9, train_MAE=0.514, train_loss=0.514, val_MAE=0.553, val_loss=0.553]Epoch 61:   6%|▌         | 61/1000 [1:02:44<15:11:27, 58.24s/it, lr=3.13e-5, test_MAE=0.582, time=58.5, train_MAE=0.513, train_loss=0.513, val_MAE=0.554, val_loss=0.554]Epoch 61:   6%|▌         | 62/1000 [1:02:44<15:11:52, 58.33s/it, lr=3.13e-5, test_MAE=0.582, time=58.5, train_MAE=0.513, train_loss=0.513, val_MAE=0.554, val_loss=0.554]Epoch 62:   6%|▌         | 62/1000 [1:02:44<15:11:52, 58.33s/it, lr=3.13e-5, test_MAE=0.582, time=58.5, train_MAE=0.513, train_loss=0.513, val_MAE=0.554, val_loss=0.554]Epoch 62:   6%|▌         | 62/1000 [1:03:42<15:11:52, 58.33s/it, lr=3.13e-5, test_MAE=0.582, time=58.2, train_MAE=0.512, train_loss=0.512, val_MAE=0.555, val_loss=0.555]Epoch    63: reducing learning rate of group 0 to 1.5625e-05.
Epoch 62:   6%|▋         | 63/1000 [1:03:42<15:10:15, 58.29s/it, lr=3.13e-5, test_MAE=0.582, time=58.2, train_MAE=0.512, train_loss=0.512, val_MAE=0.555, val_loss=0.555]Epoch 63:   6%|▋         | 63/1000 [1:03:42<15:10:15, 58.29s/it, lr=3.13e-5, test_MAE=0.582, time=58.2, train_MAE=0.512, train_loss=0.512, val_MAE=0.555, val_loss=0.555]Epoch 63:   6%|▋         | 63/1000 [1:04:40<15:10:15, 58.29s/it, lr=1.56e-5, test_MAE=0.582, time=58, train_MAE=0.515, train_loss=0.515, val_MAE=0.554, val_loss=0.554]  Epoch 63:   6%|▋         | 64/1000 [1:04:40<15:08:02, 58.21s/it, lr=1.56e-5, test_MAE=0.582, time=58, train_MAE=0.515, train_loss=0.515, val_MAE=0.554, val_loss=0.554]Epoch 64:   6%|▋         | 64/1000 [1:04:40<15:08:02, 58.21s/it, lr=1.56e-5, test_MAE=0.582, time=58, train_MAE=0.515, train_loss=0.515, val_MAE=0.554, val_loss=0.554]Epoch 64:   6%|▋         | 64/1000 [1:05:39<15:08:02, 58.21s/it, lr=1.56e-5, test_MAE=0.582, time=58.5, train_MAE=0.512, train_loss=0.512, val_MAE=0.554, val_loss=0.554]Epoch 64:   6%|▋         | 65/1000 [1:05:39<15:08:15, 58.28s/it, lr=1.56e-5, test_MAE=0.582, time=58.5, train_MAE=0.512, train_loss=0.512, val_MAE=0.554, val_loss=0.554]Epoch 65:   6%|▋         | 65/1000 [1:05:39<15:08:15, 58.28s/it, lr=1.56e-5, test_MAE=0.582, time=58.5, train_MAE=0.512, train_loss=0.512, val_MAE=0.554, val_loss=0.554]Epoch 65:   6%|▋         | 65/1000 [1:06:37<15:08:15, 58.28s/it, lr=1.56e-5, test_MAE=0.582, time=58.3, train_MAE=0.511, train_loss=0.511, val_MAE=0.554, val_loss=0.554]Epoch 65:   7%|▋         | 66/1000 [1:06:37<15:07:12, 58.28s/it, lr=1.56e-5, test_MAE=0.582, time=58.3, train_MAE=0.511, train_loss=0.511, val_MAE=0.554, val_loss=0.554]Epoch 66:   7%|▋         | 66/1000 [1:06:37<15:07:12, 58.28s/it, lr=1.56e-5, test_MAE=0.582, time=58.3, train_MAE=0.511, train_loss=0.511, val_MAE=0.554, val_loss=0.554]Epoch 66:   7%|▋         | 66/1000 [1:07:35<15:07:12, 58.28s/it, lr=1.56e-5, test_MAE=0.582, time=58.2, train_MAE=0.509, train_loss=0.509, val_MAE=0.554, val_loss=0.554]Epoch 66:   7%|▋         | 67/1000 [1:07:35<15:06:01, 58.27s/it, lr=1.56e-5, test_MAE=0.582, time=58.2, train_MAE=0.509, train_loss=0.509, val_MAE=0.554, val_loss=0.554]Epoch 67:   7%|▋         | 67/1000 [1:07:35<15:06:01, 58.27s/it, lr=1.56e-5, test_MAE=0.582, time=58.2, train_MAE=0.509, train_loss=0.509, val_MAE=0.554, val_loss=0.554]Epoch 67:   7%|▋         | 67/1000 [1:08:33<15:06:01, 58.27s/it, lr=1.56e-5, test_MAE=0.583, time=58.4, train_MAE=0.511, train_loss=0.511, val_MAE=0.554, val_loss=0.554]Epoch 67:   7%|▋         | 68/1000 [1:08:33<15:05:34, 58.30s/it, lr=1.56e-5, test_MAE=0.583, time=58.4, train_MAE=0.511, train_loss=0.511, val_MAE=0.554, val_loss=0.554]Epoch 68:   7%|▋         | 68/1000 [1:08:33<15:05:34, 58.30s/it, lr=1.56e-5, test_MAE=0.583, time=58.4, train_MAE=0.511, train_loss=0.511, val_MAE=0.554, val_loss=0.554]Epoch 68:   7%|▋         | 68/1000 [1:09:33<15:05:34, 58.30s/it, lr=1.56e-5, test_MAE=0.582, time=59.6, train_MAE=0.509, train_loss=0.509, val_MAE=0.554, val_loss=0.554]Epoch    69: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 68:   7%|▋         | 68/1000 [1:09:33<15:53:21, 61.38s/it, lr=1.56e-5, test_MAE=0.582, time=59.6, train_MAE=0.509, train_loss=0.509, val_MAE=0.554, val_loss=0.554]
Test MAE: 0.5823
Train MAE: 0.5103
Convergence Time (Epochs): 68.0000
TOTAL TIME TAKEN: 4210.7475s
AVG TIME PER EPOCH: 60.4693s
