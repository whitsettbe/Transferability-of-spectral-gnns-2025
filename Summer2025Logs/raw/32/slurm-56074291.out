I'm echoing to stdout
I'm echoing to stderr
My JobID is 56074291
I have 8 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.7087s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 4, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'rational_vec', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_all', 'num_eigs': 40, 'bias_mode': 'spatial', 'eigval_hidden_dim': 5, 'eigval_num_hidden_layer': 3, 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 0.05, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [04:30<?, ?it/s, lr=0.001, test_MAE=1.45, time=270, train_MAE=1.39, train_loss=1.39, val_MAE=1.41, val_loss=1.42]Epoch 0:   0%|          | 1/1000 [04:30<74:56:31, 270.06s/it, lr=0.001, test_MAE=1.45, time=270, train_MAE=1.39, train_loss=1.39, val_MAE=1.41, val_loss=1.42]Epoch 1:   0%|          | 1/1000 [04:30<74:56:31, 270.06s/it, lr=0.001, test_MAE=1.45, time=270, train_MAE=1.39, train_loss=1.39, val_MAE=1.41, val_loss=1.42]Epoch 1:   0%|          | 1/1000 [08:55<74:56:31, 270.06s/it, lr=0.001, test_MAE=1.58, time=266, train_MAE=1.1, train_loss=1.1, val_MAE=1.56, val_loss=1.56]  Epoch 1:   0%|          | 2/1000 [08:55<74:30:19, 268.76s/it, lr=0.001, test_MAE=1.58, time=266, train_MAE=1.1, train_loss=1.1, val_MAE=1.56, val_loss=1.56]Epoch 2:   0%|          | 2/1000 [08:55<74:30:19, 268.76s/it, lr=0.001, test_MAE=1.58, time=266, train_MAE=1.1, train_loss=1.1, val_MAE=1.56, val_loss=1.56]Epoch 2:   0%|          | 2/1000 [13:12<74:30:19, 268.76s/it, lr=0.001, test_MAE=1.35, time=257, train_MAE=0.833, train_loss=0.836, val_MAE=1.32, val_loss=1.33]Epoch 2:   0%|          | 3/1000 [13:12<73:25:18, 265.11s/it, lr=0.001, test_MAE=1.35, time=257, train_MAE=0.833, train_loss=0.836, val_MAE=1.32, val_loss=1.33]Epoch 3:   0%|          | 3/1000 [13:12<73:25:18, 265.11s/it, lr=0.001, test_MAE=1.35, time=257, train_MAE=0.833, train_loss=0.836, val_MAE=1.32, val_loss=1.33]Epoch 3:   0%|          | 3/1000 [17:27<73:25:18, 265.11s/it, lr=0.001, test_MAE=1.08, time=255, train_MAE=0.714, train_loss=0.716, val_MAE=1.02, val_loss=1.02]Epoch 3:   0%|          | 4/1000 [17:27<72:32:26, 262.20s/it, lr=0.001, test_MAE=1.08, time=255, train_MAE=0.714, train_loss=0.716, val_MAE=1.02, val_loss=1.02]Epoch 4:   0%|          | 4/1000 [17:27<72:32:26, 262.20s/it, lr=0.001, test_MAE=1.08, time=255, train_MAE=0.714, train_loss=0.716, val_MAE=1.02, val_loss=1.02]Epoch 4:   0%|          | 4/1000 [21:44<72:32:26, 262.20s/it, lr=0.001, test_MAE=0.933, time=256, train_MAE=0.655, train_loss=0.657, val_MAE=0.924, val_loss=0.926]Epoch 4:   0%|          | 5/1000 [21:44<71:59:49, 260.49s/it, lr=0.001, test_MAE=0.933, time=256, train_MAE=0.655, train_loss=0.657, val_MAE=0.924, val_loss=0.926]Epoch 5:   0%|          | 5/1000 [21:44<71:59:49, 260.49s/it, lr=0.001, test_MAE=0.933, time=256, train_MAE=0.655, train_loss=0.657, val_MAE=0.924, val_loss=0.926]Epoch 5:   0%|          | 5/1000 [26:00<71:59:49, 260.49s/it, lr=0.001, test_MAE=0.803, time=256, train_MAE=0.633, train_loss=0.635, val_MAE=0.753, val_loss=0.755]Epoch 5:   1%|          | 6/1000 [26:00<71:31:56, 259.07s/it, lr=0.001, test_MAE=0.803, time=256, train_MAE=0.633, train_loss=0.635, val_MAE=0.753, val_loss=0.755]Epoch 6:   1%|          | 6/1000 [26:00<71:31:56, 259.07s/it, lr=0.001, test_MAE=0.803, time=256, train_MAE=0.633, train_loss=0.635, val_MAE=0.753, val_loss=0.755]Epoch 6:   1%|          | 6/1000 [30:16<71:31:56, 259.07s/it, lr=0.001, test_MAE=0.729, time=256, train_MAE=0.617, train_loss=0.619, val_MAE=0.681, val_loss=0.683]Epoch 6:   1%|          | 7/1000 [30:16<71:12:25, 258.15s/it, lr=0.001, test_MAE=0.729, time=256, train_MAE=0.617, train_loss=0.619, val_MAE=0.681, val_loss=0.683]Epoch 7:   1%|          | 7/1000 [30:16<71:12:25, 258.15s/it, lr=0.001, test_MAE=0.729, time=256, train_MAE=0.617, train_loss=0.619, val_MAE=0.681, val_loss=0.683]Epoch 7:   1%|          | 7/1000 [34:33<71:12:25, 258.15s/it, lr=0.001, test_MAE=0.715, time=257, train_MAE=0.594, train_loss=0.596, val_MAE=0.677, val_loss=0.68] Epoch 7:   1%|          | 8/1000 [34:33<71:03:20, 257.86s/it, lr=0.001, test_MAE=0.715, time=257, train_MAE=0.594, train_loss=0.596, val_MAE=0.677, val_loss=0.68]Epoch 8:   1%|          | 8/1000 [34:33<71:03:20, 257.86s/it, lr=0.001, test_MAE=0.715, time=257, train_MAE=0.594, train_loss=0.596, val_MAE=0.677, val_loss=0.68]Epoch 8:   1%|          | 8/1000 [38:49<71:03:20, 257.86s/it, lr=0.001, test_MAE=0.719, time=257, train_MAE=0.584, train_loss=0.586, val_MAE=0.652, val_loss=0.655]Epoch 8:   1%|          | 9/1000 [38:49<70:53:09, 257.51s/it, lr=0.001, test_MAE=0.719, time=257, train_MAE=0.584, train_loss=0.586, val_MAE=0.652, val_loss=0.655]Epoch 9:   1%|          | 9/1000 [38:49<70:53:09, 257.51s/it, lr=0.001, test_MAE=0.719, time=257, train_MAE=0.584, train_loss=0.586, val_MAE=0.652, val_loss=0.655]Epoch 9:   1%|          | 9/1000 [43:06<70:53:09, 257.51s/it, lr=0.001, test_MAE=0.679, time=257, train_MAE=0.598, train_loss=0.6, val_MAE=0.646, val_loss=0.648]  Epoch 9:   1%|          | 10/1000 [43:06<70:45:06, 257.28s/it, lr=0.001, test_MAE=0.679, time=257, train_MAE=0.598, train_loss=0.6, val_MAE=0.646, val_loss=0.648]Epoch 10:   1%|          | 10/1000 [43:06<70:45:06, 257.28s/it, lr=0.001, test_MAE=0.679, time=257, train_MAE=0.598, train_loss=0.6, val_MAE=0.646, val_loss=0.648]Epoch 10:   1%|          | 10/1000 [47:23<70:45:06, 257.28s/it, lr=0.001, test_MAE=0.809, time=257, train_MAE=0.575, train_loss=0.577, val_MAE=0.776, val_loss=0.778]Epoch 10:   1%|          | 11/1000 [47:23<70:39:12, 257.18s/it, lr=0.001, test_MAE=0.809, time=257, train_MAE=0.575, train_loss=0.577, val_MAE=0.776, val_loss=0.778]Epoch 11:   1%|          | 11/1000 [47:23<70:39:12, 257.18s/it, lr=0.001, test_MAE=0.809, time=257, train_MAE=0.575, train_loss=0.577, val_MAE=0.776, val_loss=0.778]Epoch 11:   1%|          | 11/1000 [51:40<70:39:12, 257.18s/it, lr=0.001, test_MAE=0.702, time=257, train_MAE=0.559, train_loss=0.561, val_MAE=0.7, val_loss=0.702]  Epoch 11:   1%|          | 12/1000 [51:40<70:33:23, 257.09s/it, lr=0.001, test_MAE=0.702, time=257, train_MAE=0.559, train_loss=0.561, val_MAE=0.7, val_loss=0.702]Epoch 12:   1%|          | 12/1000 [51:40<70:33:23, 257.09s/it, lr=0.001, test_MAE=0.702, time=257, train_MAE=0.559, train_loss=0.561, val_MAE=0.7, val_loss=0.702]Epoch 12:   1%|          | 12/1000 [55:57<70:33:23, 257.09s/it, lr=0.001, test_MAE=0.932, time=257, train_MAE=0.547, train_loss=0.549, val_MAE=0.895, val_loss=0.897]Epoch 12:   1%|▏         | 13/1000 [55:57<70:29:24, 257.11s/it, lr=0.001, test_MAE=0.932, time=257, train_MAE=0.547, train_loss=0.549, val_MAE=0.895, val_loss=0.897]Epoch 13:   1%|▏         | 13/1000 [55:57<70:29:24, 257.11s/it, lr=0.001, test_MAE=0.932, time=257, train_MAE=0.547, train_loss=0.549, val_MAE=0.895, val_loss=0.897]Epoch 13:   1%|▏         | 13/1000 [1:00:13<70:29:24, 257.11s/it, lr=0.001, test_MAE=0.588, time=256, train_MAE=0.54, train_loss=0.543, val_MAE=0.552, val_loss=0.555]Epoch 13:   1%|▏         | 14/1000 [1:00:13<70:19:41, 256.78s/it, lr=0.001, test_MAE=0.588, time=256, train_MAE=0.54, train_loss=0.543, val_MAE=0.552, val_loss=0.555]Epoch 14:   1%|▏         | 14/1000 [1:00:13<70:19:41, 256.78s/it, lr=0.001, test_MAE=0.588, time=256, train_MAE=0.54, train_loss=0.543, val_MAE=0.552, val_loss=0.555]Epoch 14:   1%|▏         | 14/1000 [1:04:30<70:19:41, 256.78s/it, lr=0.001, test_MAE=0.583, time=257, train_MAE=0.539, train_loss=0.541, val_MAE=0.552, val_loss=0.554]Epoch 14:   2%|▏         | 15/1000 [1:04:30<70:15:23, 256.77s/it, lr=0.001, test_MAE=0.583, time=257, train_MAE=0.539, train_loss=0.541, val_MAE=0.552, val_loss=0.554]Epoch 15:   2%|▏         | 15/1000 [1:04:30<70:15:23, 256.77s/it, lr=0.001, test_MAE=0.583, time=257, train_MAE=0.539, train_loss=0.541, val_MAE=0.552, val_loss=0.554]Epoch 15:   2%|▏         | 15/1000 [1:08:47<70:15:23, 256.77s/it, lr=0.001, test_MAE=0.611, time=257, train_MAE=0.513, train_loss=0.516, val_MAE=0.567, val_loss=0.569]Epoch 15:   2%|▏         | 16/1000 [1:08:47<70:11:03, 256.77s/it, lr=0.001, test_MAE=0.611, time=257, train_MAE=0.513, train_loss=0.516, val_MAE=0.567, val_loss=0.569]Epoch 16:   2%|▏         | 16/1000 [1:08:47<70:11:03, 256.77s/it, lr=0.001, test_MAE=0.611, time=257, train_MAE=0.513, train_loss=0.516, val_MAE=0.567, val_loss=0.569]Epoch 16:   2%|▏         | 16/1000 [1:13:04<70:11:03, 256.77s/it, lr=0.001, test_MAE=0.561, time=257, train_MAE=0.518, train_loss=0.521, val_MAE=0.55, val_loss=0.553] Epoch 16:   2%|▏         | 17/1000 [1:13:04<70:08:51, 256.90s/it, lr=0.001, test_MAE=0.561, time=257, train_MAE=0.518, train_loss=0.521, val_MAE=0.55, val_loss=0.553]Epoch 17:   2%|▏         | 17/1000 [1:13:04<70:08:51, 256.90s/it, lr=0.001, test_MAE=0.561, time=257, train_MAE=0.518, train_loss=0.521, val_MAE=0.55, val_loss=0.553]Epoch 17:   2%|▏         | 17/1000 [1:17:22<70:08:51, 256.90s/it, lr=0.001, test_MAE=0.837, time=258, train_MAE=0.508, train_loss=0.51, val_MAE=0.878, val_loss=0.881]Epoch 17:   2%|▏         | 18/1000 [1:17:22<70:12:00, 257.35s/it, lr=0.001, test_MAE=0.837, time=258, train_MAE=0.508, train_loss=0.51, val_MAE=0.878, val_loss=0.881]Epoch 18:   2%|▏         | 18/1000 [1:17:22<70:12:00, 257.35s/it, lr=0.001, test_MAE=0.837, time=258, train_MAE=0.508, train_loss=0.51, val_MAE=0.878, val_loss=0.881]Epoch 18:   2%|▏         | 18/1000 [1:21:40<70:12:00, 257.35s/it, lr=0.001, test_MAE=0.773, time=258, train_MAE=0.505, train_loss=0.507, val_MAE=0.713, val_loss=0.716]Epoch 18:   2%|▏         | 19/1000 [1:21:40<70:10:42, 257.54s/it, lr=0.001, test_MAE=0.773, time=258, train_MAE=0.505, train_loss=0.507, val_MAE=0.713, val_loss=0.716]Epoch 19:   2%|▏         | 19/1000 [1:21:40<70:10:42, 257.54s/it, lr=0.001, test_MAE=0.773, time=258, train_MAE=0.505, train_loss=0.507, val_MAE=0.713, val_loss=0.716]Epoch 19:   2%|▏         | 19/1000 [1:25:58<70:10:42, 257.54s/it, lr=0.001, test_MAE=0.671, time=258, train_MAE=0.507, train_loss=0.51, val_MAE=0.628, val_loss=0.631] Epoch 19:   2%|▏         | 20/1000 [1:25:58<70:07:04, 257.58s/it, lr=0.001, test_MAE=0.671, time=258, train_MAE=0.507, train_loss=0.51, val_MAE=0.628, val_loss=0.631]Epoch 20:   2%|▏         | 20/1000 [1:25:58<70:07:04, 257.58s/it, lr=0.001, test_MAE=0.671, time=258, train_MAE=0.507, train_loss=0.51, val_MAE=0.628, val_loss=0.631]Epoch 20:   2%|▏         | 20/1000 [1:30:16<70:07:04, 257.58s/it, lr=0.001, test_MAE=0.551, time=258, train_MAE=0.518, train_loss=0.52, val_MAE=0.522, val_loss=0.524]Epoch 20:   2%|▏         | 21/1000 [1:30:16<70:06:00, 257.77s/it, lr=0.001, test_MAE=0.551, time=258, train_MAE=0.518, train_loss=0.52, val_MAE=0.522, val_loss=0.524]Epoch 21:   2%|▏         | 21/1000 [1:30:16<70:06:00, 257.77s/it, lr=0.001, test_MAE=0.551, time=258, train_MAE=0.518, train_loss=0.52, val_MAE=0.522, val_loss=0.524]Epoch 21:   2%|▏         | 21/1000 [1:34:33<70:06:00, 257.77s/it, lr=0.001, test_MAE=0.713, time=257, train_MAE=0.51, train_loss=0.512, val_MAE=0.655, val_loss=0.657]Epoch 21:   2%|▏         | 22/1000 [1:34:33<69:57:46, 257.53s/it, lr=0.001, test_MAE=0.713, time=257, train_MAE=0.51, train_loss=0.512, val_MAE=0.655, val_loss=0.657]Epoch 22:   2%|▏         | 22/1000 [1:34:33<69:57:46, 257.53s/it, lr=0.001, test_MAE=0.713, time=257, train_MAE=0.51, train_loss=0.512, val_MAE=0.655, val_loss=0.657]Epoch 22:   2%|▏         | 22/1000 [1:38:51<69:57:46, 257.53s/it, lr=0.001, test_MAE=0.547, time=258, train_MAE=0.488, train_loss=0.491, val_MAE=0.514, val_loss=0.516]Epoch 22:   2%|▏         | 23/1000 [1:38:51<69:55:58, 257.69s/it, lr=0.001, test_MAE=0.547, time=258, train_MAE=0.488, train_loss=0.491, val_MAE=0.514, val_loss=0.516]Epoch 23:   2%|▏         | 23/1000 [1:38:51<69:55:58, 257.69s/it, lr=0.001, test_MAE=0.547, time=258, train_MAE=0.488, train_loss=0.491, val_MAE=0.514, val_loss=0.516]Epoch 23:   2%|▏         | 23/1000 [1:43:08<69:55:58, 257.69s/it, lr=0.001, test_MAE=0.56, time=257, train_MAE=0.489, train_loss=0.492, val_MAE=0.538, val_loss=0.541] Epoch 23:   2%|▏         | 24/1000 [1:43:08<69:49:07, 257.53s/it, lr=0.001, test_MAE=0.56, time=257, train_MAE=0.489, train_loss=0.492, val_MAE=0.538, val_loss=0.541]Epoch 24:   2%|▏         | 24/1000 [1:43:08<69:49:07, 257.53s/it, lr=0.001, test_MAE=0.56, time=257, train_MAE=0.489, train_loss=0.492, val_MAE=0.538, val_loss=0.541]Epoch 24:   2%|▏         | 24/1000 [1:47:25<69:49:07, 257.53s/it, lr=0.001, test_MAE=0.527, time=257, train_MAE=0.486, train_loss=0.489, val_MAE=0.513, val_loss=0.516]Epoch 24:   2%|▎         | 25/1000 [1:47:25<69:40:47, 257.28s/it, lr=0.001, test_MAE=0.527, time=257, train_MAE=0.486, train_loss=0.489, val_MAE=0.513, val_loss=0.516]Epoch 25:   2%|▎         | 25/1000 [1:47:25<69:40:47, 257.28s/it, lr=0.001, test_MAE=0.527, time=257, train_MAE=0.486, train_loss=0.489, val_MAE=0.513, val_loss=0.516]Epoch 25:   2%|▎         | 25/1000 [1:51:42<69:40:47, 257.28s/it, lr=0.001, test_MAE=0.513, time=257, train_MAE=0.481, train_loss=0.483, val_MAE=0.5, val_loss=0.502]  Epoch 25:   3%|▎         | 26/1000 [1:51:42<69:36:31, 257.28s/it, lr=0.001, test_MAE=0.513, time=257, train_MAE=0.481, train_loss=0.483, val_MAE=0.5, val_loss=0.502]Epoch 26:   3%|▎         | 26/1000 [1:51:42<69:36:31, 257.28s/it, lr=0.001, test_MAE=0.513, time=257, train_MAE=0.481, train_loss=0.483, val_MAE=0.5, val_loss=0.502]Epoch 26:   3%|▎         | 26/1000 [1:55:59<69:36:31, 257.28s/it, lr=0.001, test_MAE=0.537, time=257, train_MAE=0.483, train_loss=0.485, val_MAE=0.515, val_loss=0.518]Epoch 26:   3%|▎         | 27/1000 [1:55:59<69:30:23, 257.17s/it, lr=0.001, test_MAE=0.537, time=257, train_MAE=0.483, train_loss=0.485, val_MAE=0.515, val_loss=0.518]Epoch 27:   3%|▎         | 27/1000 [1:55:59<69:30:23, 257.17s/it, lr=0.001, test_MAE=0.537, time=257, train_MAE=0.483, train_loss=0.485, val_MAE=0.515, val_loss=0.518]Epoch 27:   3%|▎         | 27/1000 [2:00:16<69:30:23, 257.17s/it, lr=0.001, test_MAE=0.544, time=257, train_MAE=0.474, train_loss=0.476, val_MAE=0.527, val_loss=0.529]Epoch 27:   3%|▎         | 28/1000 [2:00:17<69:26:42, 257.20s/it, lr=0.001, test_MAE=0.544, time=257, train_MAE=0.474, train_loss=0.476, val_MAE=0.527, val_loss=0.529]Epoch 28:   3%|▎         | 28/1000 [2:00:17<69:26:42, 257.20s/it, lr=0.001, test_MAE=0.544, time=257, train_MAE=0.474, train_loss=0.476, val_MAE=0.527, val_loss=0.529]Epoch 28:   3%|▎         | 28/1000 [2:04:38<69:26:42, 257.20s/it, lr=0.001, test_MAE=0.55, time=261, train_MAE=0.465, train_loss=0.468, val_MAE=0.532, val_loss=0.534] Epoch 28:   3%|▎         | 29/1000 [2:04:38<69:41:54, 258.41s/it, lr=0.001, test_MAE=0.55, time=261, train_MAE=0.465, train_loss=0.468, val_MAE=0.532, val_loss=0.534]Epoch 29:   3%|▎         | 29/1000 [2:04:38<69:41:54, 258.41s/it, lr=0.001, test_MAE=0.55, time=261, train_MAE=0.465, train_loss=0.468, val_MAE=0.532, val_loss=0.534]Epoch 29:   3%|▎         | 29/1000 [2:08:59<69:41:54, 258.41s/it, lr=0.001, test_MAE=0.543, time=261, train_MAE=0.489, train_loss=0.491, val_MAE=0.527, val_loss=0.53]Epoch 29:   3%|▎         | 30/1000 [2:08:59<69:50:03, 259.18s/it, lr=0.001, test_MAE=0.543, time=261, train_MAE=0.489, train_loss=0.491, val_MAE=0.527, val_loss=0.53]Epoch 30:   3%|▎         | 30/1000 [2:08:59<69:50:03, 259.18s/it, lr=0.001, test_MAE=0.543, time=261, train_MAE=0.489, train_loss=0.491, val_MAE=0.527, val_loss=0.53]Epoch 30:   3%|▎         | 30/1000 [2:13:17<69:50:03, 259.18s/it, lr=0.001, test_MAE=0.584, time=258, train_MAE=0.467, train_loss=0.47, val_MAE=0.557, val_loss=0.56] Epoch 30:   3%|▎         | 31/1000 [2:13:17<69:40:05, 258.83s/it, lr=0.001, test_MAE=0.584, time=258, train_MAE=0.467, train_loss=0.47, val_MAE=0.557, val_loss=0.56]Epoch 31:   3%|▎         | 31/1000 [2:13:17<69:40:05, 258.83s/it, lr=0.001, test_MAE=0.584, time=258, train_MAE=0.467, train_loss=0.47, val_MAE=0.557, val_loss=0.56]Epoch 31:   3%|▎         | 31/1000 [2:17:28<69:40:05, 258.83s/it, lr=0.001, test_MAE=1.41, time=252, train_MAE=0.467, train_loss=0.469, val_MAE=0.891, val_loss=0.894]Epoch    32: reducing learning rate of group 0 to 5.0000e-04.
Epoch 31:   3%|▎         | 32/1000 [2:17:28<69:01:09, 256.68s/it, lr=0.001, test_MAE=1.41, time=252, train_MAE=0.467, train_loss=0.469, val_MAE=0.891, val_loss=0.894]Epoch 32:   3%|▎         | 32/1000 [2:17:28<69:01:09, 256.68s/it, lr=0.001, test_MAE=1.41, time=252, train_MAE=0.467, train_loss=0.469, val_MAE=0.891, val_loss=0.894]Epoch 32:   3%|▎         | 32/1000 [2:21:39<69:01:09, 256.68s/it, lr=0.0005, test_MAE=0.505, time=250, train_MAE=0.458, train_loss=0.461, val_MAE=0.496, val_loss=0.498]Epoch 32:   3%|▎         | 33/1000 [2:21:39<68:26:09, 254.78s/it, lr=0.0005, test_MAE=0.505, time=250, train_MAE=0.458, train_loss=0.461, val_MAE=0.496, val_loss=0.498]Epoch 33:   3%|▎         | 33/1000 [2:21:39<68:26:09, 254.78s/it, lr=0.0005, test_MAE=0.505, time=250, train_MAE=0.458, train_loss=0.461, val_MAE=0.496, val_loss=0.498]Epoch 33:   3%|▎         | 33/1000 [2:25:49<68:26:09, 254.78s/it, lr=0.0005, test_MAE=0.658, time=250, train_MAE=0.437, train_loss=0.439, val_MAE=0.621, val_loss=0.624]Epoch 33:   3%|▎         | 34/1000 [2:25:49<67:58:39, 253.33s/it, lr=0.0005, test_MAE=0.658, time=250, train_MAE=0.437, train_loss=0.439, val_MAE=0.621, val_loss=0.624]Epoch 34:   3%|▎         | 34/1000 [2:25:49<67:58:39, 253.33s/it, lr=0.0005, test_MAE=0.658, time=250, train_MAE=0.437, train_loss=0.439, val_MAE=0.621, val_loss=0.624]Epoch 34:   3%|▎         | 34/1000 [2:29:58<67:58:39, 253.33s/it, lr=0.0005, test_MAE=0.485, time=249, train_MAE=0.438, train_loss=0.441, val_MAE=0.456, val_loss=0.458]Epoch 34:   4%|▎         | 35/1000 [2:29:58<67:33:55, 252.06s/it, lr=0.0005, test_MAE=0.485, time=249, train_MAE=0.438, train_loss=0.441, val_MAE=0.456, val_loss=0.458]Epoch 35:   4%|▎         | 35/1000 [2:29:58<67:33:55, 252.06s/it, lr=0.0005, test_MAE=0.485, time=249, train_MAE=0.438, train_loss=0.441, val_MAE=0.456, val_loss=0.458]Epoch 35:   4%|▎         | 35/1000 [2:34:07<67:33:55, 252.06s/it, lr=0.0005, test_MAE=0.487, time=250, train_MAE=0.436, train_loss=0.439, val_MAE=0.477, val_loss=0.48] Epoch 35:   4%|▎         | 36/1000 [2:34:07<67:17:49, 251.32s/it, lr=0.0005, test_MAE=0.487, time=250, train_MAE=0.436, train_loss=0.439, val_MAE=0.477, val_loss=0.48]Epoch 36:   4%|▎         | 36/1000 [2:34:07<67:17:49, 251.32s/it, lr=0.0005, test_MAE=0.487, time=250, train_MAE=0.436, train_loss=0.439, val_MAE=0.477, val_loss=0.48]Epoch 36:   4%|▎         | 36/1000 [2:38:17<67:17:49, 251.32s/it, lr=0.0005, test_MAE=0.476, time=250, train_MAE=0.431, train_loss=0.434, val_MAE=0.463, val_loss=0.466]Epoch 36:   4%|▎         | 37/1000 [2:38:17<67:05:25, 250.81s/it, lr=0.0005, test_MAE=0.476, time=250, train_MAE=0.431, train_loss=0.434, val_MAE=0.463, val_loss=0.466]Epoch 37:   4%|▎         | 37/1000 [2:38:17<67:05:25, 250.81s/it, lr=0.0005, test_MAE=0.476, time=250, train_MAE=0.431, train_loss=0.434, val_MAE=0.463, val_loss=0.466]Epoch 37:   4%|▎         | 37/1000 [2:42:27<67:05:25, 250.81s/it, lr=0.0005, test_MAE=0.482, time=250, train_MAE=0.432, train_loss=0.435, val_MAE=0.466, val_loss=0.469]Epoch 37:   4%|▍         | 38/1000 [2:42:27<66:56:01, 250.48s/it, lr=0.0005, test_MAE=0.482, time=250, train_MAE=0.432, train_loss=0.435, val_MAE=0.466, val_loss=0.469]Epoch 38:   4%|▍         | 38/1000 [2:42:27<66:56:01, 250.48s/it, lr=0.0005, test_MAE=0.482, time=250, train_MAE=0.432, train_loss=0.435, val_MAE=0.466, val_loss=0.469]Epoch 38:   4%|▍         | 38/1000 [2:46:36<66:56:01, 250.48s/it, lr=0.0005, test_MAE=0.472, time=250, train_MAE=0.427, train_loss=0.429, val_MAE=0.463, val_loss=0.465]Epoch 38:   4%|▍         | 39/1000 [2:46:36<66:47:51, 250.23s/it, lr=0.0005, test_MAE=0.472, time=250, train_MAE=0.427, train_loss=0.429, val_MAE=0.463, val_loss=0.465]Epoch 39:   4%|▍         | 39/1000 [2:46:36<66:47:51, 250.23s/it, lr=0.0005, test_MAE=0.472, time=250, train_MAE=0.427, train_loss=0.429, val_MAE=0.463, val_loss=0.465]Epoch 39:   4%|▍         | 39/1000 [2:50:46<66:47:51, 250.23s/it, lr=0.0005, test_MAE=0.521, time=249, train_MAE=0.427, train_loss=0.43, val_MAE=0.501, val_loss=0.504] Epoch 39:   4%|▍         | 40/1000 [2:50:46<66:39:29, 249.97s/it, lr=0.0005, test_MAE=0.521, time=249, train_MAE=0.427, train_loss=0.43, val_MAE=0.501, val_loss=0.504]Epoch 40:   4%|▍         | 40/1000 [2:50:46<66:39:29, 249.97s/it, lr=0.0005, test_MAE=0.521, time=249, train_MAE=0.427, train_loss=0.43, val_MAE=0.501, val_loss=0.504]Epoch 40:   4%|▍         | 40/1000 [2:54:56<66:39:29, 249.97s/it, lr=0.0005, test_MAE=0.753, time=250, train_MAE=0.423, train_loss=0.426, val_MAE=0.71, val_loss=0.713]Epoch    41: reducing learning rate of group 0 to 2.5000e-04.
Epoch 40:   4%|▍         | 41/1000 [2:54:56<66:34:47, 249.93s/it, lr=0.0005, test_MAE=0.753, time=250, train_MAE=0.423, train_loss=0.426, val_MAE=0.71, val_loss=0.713]Epoch 41:   4%|▍         | 41/1000 [2:54:56<66:34:47, 249.93s/it, lr=0.0005, test_MAE=0.753, time=250, train_MAE=0.423, train_loss=0.426, val_MAE=0.71, val_loss=0.713]Epoch 41:   4%|▍         | 41/1000 [2:59:05<66:34:47, 249.93s/it, lr=0.00025, test_MAE=0.447, time=249, train_MAE=0.413, train_loss=0.416, val_MAE=0.431, val_loss=0.434]Epoch 41:   4%|▍         | 42/1000 [2:59:05<66:26:55, 249.70s/it, lr=0.00025, test_MAE=0.447, time=249, train_MAE=0.413, train_loss=0.416, val_MAE=0.431, val_loss=0.434]Epoch 42:   4%|▍         | 42/1000 [2:59:05<66:26:55, 249.70s/it, lr=0.00025, test_MAE=0.447, time=249, train_MAE=0.413, train_loss=0.416, val_MAE=0.431, val_loss=0.434]Epoch 42:   4%|▍         | 42/1000 [3:03:14<66:26:55, 249.70s/it, lr=0.00025, test_MAE=0.463, time=250, train_MAE=0.409, train_loss=0.412, val_MAE=0.441, val_loss=0.444]Epoch 42:   4%|▍         | 43/1000 [3:03:14<66:22:52, 249.71s/it, lr=0.00025, test_MAE=0.463, time=250, train_MAE=0.409, train_loss=0.412, val_MAE=0.441, val_loss=0.444]Epoch 43:   4%|▍         | 43/1000 [3:03:14<66:22:52, 249.71s/it, lr=0.00025, test_MAE=0.463, time=250, train_MAE=0.409, train_loss=0.412, val_MAE=0.441, val_loss=0.444]Epoch 43:   4%|▍         | 43/1000 [3:07:24<66:22:52, 249.71s/it, lr=0.00025, test_MAE=0.457, time=250, train_MAE=0.408, train_loss=0.41, val_MAE=0.444, val_loss=0.447] Epoch 43:   4%|▍         | 44/1000 [3:07:24<66:18:02, 249.67s/it, lr=0.00025, test_MAE=0.457, time=250, train_MAE=0.408, train_loss=0.41, val_MAE=0.444, val_loss=0.447]Epoch 44:   4%|▍         | 44/1000 [3:07:24<66:18:02, 249.67s/it, lr=0.00025, test_MAE=0.457, time=250, train_MAE=0.408, train_loss=0.41, val_MAE=0.444, val_loss=0.447]Epoch 44:   4%|▍         | 44/1000 [3:11:34<66:18:02, 249.67s/it, lr=0.00025, test_MAE=0.454, time=250, train_MAE=0.407, train_loss=0.41, val_MAE=0.455, val_loss=0.458]Epoch 44:   4%|▍         | 45/1000 [3:11:34<66:16:19, 249.82s/it, lr=0.00025, test_MAE=0.454, time=250, train_MAE=0.407, train_loss=0.41, val_MAE=0.455, val_loss=0.458]Epoch 45:   4%|▍         | 45/1000 [3:11:34<66:16:19, 249.82s/it, lr=0.00025, test_MAE=0.454, time=250, train_MAE=0.407, train_loss=0.41, val_MAE=0.455, val_loss=0.458]Epoch 45:   4%|▍         | 45/1000 [3:15:44<66:16:19, 249.82s/it, lr=0.00025, test_MAE=0.457, time=250, train_MAE=0.406, train_loss=0.409, val_MAE=0.452, val_loss=0.454]Epoch 45:   5%|▍         | 46/1000 [3:15:44<66:12:04, 249.82s/it, lr=0.00025, test_MAE=0.457, time=250, train_MAE=0.406, train_loss=0.409, val_MAE=0.452, val_loss=0.454]Epoch 46:   5%|▍         | 46/1000 [3:15:44<66:12:04, 249.82s/it, lr=0.00025, test_MAE=0.457, time=250, train_MAE=0.406, train_loss=0.409, val_MAE=0.452, val_loss=0.454]Epoch 46:   5%|▍         | 46/1000 [3:19:54<66:12:04, 249.82s/it, lr=0.00025, test_MAE=0.454, time=250, train_MAE=0.404, train_loss=0.407, val_MAE=0.44, val_loss=0.443] Epoch 46:   5%|▍         | 47/1000 [3:19:54<66:09:14, 249.90s/it, lr=0.00025, test_MAE=0.454, time=250, train_MAE=0.404, train_loss=0.407, val_MAE=0.44, val_loss=0.443]Epoch 47:   5%|▍         | 47/1000 [3:19:54<66:09:14, 249.90s/it, lr=0.00025, test_MAE=0.454, time=250, train_MAE=0.404, train_loss=0.407, val_MAE=0.44, val_loss=0.443]Epoch 47:   5%|▍         | 47/1000 [3:24:04<66:09:14, 249.90s/it, lr=0.00025, test_MAE=0.483, time=250, train_MAE=0.398, train_loss=0.4, val_MAE=0.473, val_loss=0.476] Epoch    48: reducing learning rate of group 0 to 1.2500e-04.
Epoch 47:   5%|▍         | 48/1000 [3:24:04<66:04:21, 249.85s/it, lr=0.00025, test_MAE=0.483, time=250, train_MAE=0.398, train_loss=0.4, val_MAE=0.473, val_loss=0.476]Epoch 48:   5%|▍         | 48/1000 [3:24:04<66:04:21, 249.85s/it, lr=0.00025, test_MAE=0.483, time=250, train_MAE=0.398, train_loss=0.4, val_MAE=0.473, val_loss=0.476]Epoch 48:   5%|▍         | 48/1000 [3:28:13<66:04:21, 249.85s/it, lr=0.000125, test_MAE=0.448, time=249, train_MAE=0.389, train_loss=0.392, val_MAE=0.435, val_loss=0.437]Epoch 48:   5%|▍         | 49/1000 [3:28:13<65:58:08, 249.73s/it, lr=0.000125, test_MAE=0.448, time=249, train_MAE=0.389, train_loss=0.392, val_MAE=0.435, val_loss=0.437]Epoch 49:   5%|▍         | 49/1000 [3:28:13<65:58:08, 249.73s/it, lr=0.000125, test_MAE=0.448, time=249, train_MAE=0.389, train_loss=0.392, val_MAE=0.435, val_loss=0.437]Epoch 49:   5%|▍         | 49/1000 [3:32:24<65:58:08, 249.73s/it, lr=0.000125, test_MAE=0.443, time=250, train_MAE=0.382, train_loss=0.385, val_MAE=0.424, val_loss=0.427]Epoch 49:   5%|▌         | 50/1000 [3:32:24<65:57:02, 249.92s/it, lr=0.000125, test_MAE=0.443, time=250, train_MAE=0.382, train_loss=0.385, val_MAE=0.424, val_loss=0.427]Epoch 50:   5%|▌         | 50/1000 [3:32:24<65:57:02, 249.92s/it, lr=0.000125, test_MAE=0.443, time=250, train_MAE=0.382, train_loss=0.385, val_MAE=0.424, val_loss=0.427]Epoch 50:   5%|▌         | 50/1000 [3:36:34<65:57:02, 249.92s/it, lr=0.000125, test_MAE=0.467, time=250, train_MAE=0.388, train_loss=0.39, val_MAE=0.462, val_loss=0.465] Epoch 50:   5%|▌         | 51/1000 [3:36:34<65:53:08, 249.93s/it, lr=0.000125, test_MAE=0.467, time=250, train_MAE=0.388, train_loss=0.39, val_MAE=0.462, val_loss=0.465]Epoch 51:   5%|▌         | 51/1000 [3:36:34<65:53:08, 249.93s/it, lr=0.000125, test_MAE=0.467, time=250, train_MAE=0.388, train_loss=0.39, val_MAE=0.462, val_loss=0.465]Epoch 51:   5%|▌         | 51/1000 [3:40:43<65:53:08, 249.93s/it, lr=0.000125, test_MAE=0.444, time=250, train_MAE=0.387, train_loss=0.39, val_MAE=0.436, val_loss=0.439]Epoch 51:   5%|▌         | 52/1000 [3:40:43<65:48:07, 249.88s/it, lr=0.000125, test_MAE=0.444, time=250, train_MAE=0.387, train_loss=0.39, val_MAE=0.436, val_loss=0.439]Epoch 52:   5%|▌         | 52/1000 [3:40:43<65:48:07, 249.88s/it, lr=0.000125, test_MAE=0.444, time=250, train_MAE=0.387, train_loss=0.39, val_MAE=0.436, val_loss=0.439]Epoch 52:   5%|▌         | 52/1000 [3:44:54<65:48:07, 249.88s/it, lr=0.000125, test_MAE=0.446, time=250, train_MAE=0.384, train_loss=0.386, val_MAE=0.439, val_loss=0.441]Epoch 52:   5%|▌         | 53/1000 [3:44:54<65:45:36, 249.99s/it, lr=0.000125, test_MAE=0.446, time=250, train_MAE=0.384, train_loss=0.386, val_MAE=0.439, val_loss=0.441]Epoch 53:   5%|▌         | 53/1000 [3:44:54<65:45:36, 249.99s/it, lr=0.000125, test_MAE=0.446, time=250, train_MAE=0.384, train_loss=0.386, val_MAE=0.439, val_loss=0.441]Epoch 53:   5%|▌         | 53/1000 [3:49:04<65:45:36, 249.99s/it, lr=0.000125, test_MAE=0.46, time=250, train_MAE=0.385, train_loss=0.388, val_MAE=0.451, val_loss=0.454] Epoch 53:   5%|▌         | 54/1000 [3:49:04<65:42:26, 250.05s/it, lr=0.000125, test_MAE=0.46, time=250, train_MAE=0.385, train_loss=0.388, val_MAE=0.451, val_loss=0.454]Epoch 54:   5%|▌         | 54/1000 [3:49:04<65:42:26, 250.05s/it, lr=0.000125, test_MAE=0.46, time=250, train_MAE=0.385, train_loss=0.388, val_MAE=0.451, val_loss=0.454]Epoch 54:   5%|▌         | 54/1000 [3:53:14<65:42:26, 250.05s/it, lr=0.000125, test_MAE=0.459, time=250, train_MAE=0.384, train_loss=0.387, val_MAE=0.437, val_loss=0.44]Epoch 54:   6%|▌         | 55/1000 [3:53:14<65:38:18, 250.05s/it, lr=0.000125, test_MAE=0.459, time=250, train_MAE=0.384, train_loss=0.387, val_MAE=0.437, val_loss=0.44]Epoch 55:   6%|▌         | 55/1000 [3:53:14<65:38:18, 250.05s/it, lr=0.000125, test_MAE=0.459, time=250, train_MAE=0.384, train_loss=0.387, val_MAE=0.437, val_loss=0.44]Epoch 55:   6%|▌         | 55/1000 [3:57:23<65:38:18, 250.05s/it, lr=0.000125, test_MAE=0.473, time=249, train_MAE=0.388, train_loss=0.391, val_MAE=0.461, val_loss=0.464]Epoch    56: reducing learning rate of group 0 to 6.2500e-05.
Epoch 55:   6%|▌         | 56/1000 [3:57:23<65:30:58, 249.85s/it, lr=0.000125, test_MAE=0.473, time=249, train_MAE=0.388, train_loss=0.391, val_MAE=0.461, val_loss=0.464]Epoch 56:   6%|▌         | 56/1000 [3:57:23<65:30:58, 249.85s/it, lr=0.000125, test_MAE=0.473, time=249, train_MAE=0.388, train_loss=0.391, val_MAE=0.461, val_loss=0.464]Epoch 56:   6%|▌         | 56/1000 [4:01:34<65:30:58, 249.85s/it, lr=6.25e-5, test_MAE=0.443, time=250, train_MAE=0.375, train_loss=0.377, val_MAE=0.431, val_loss=0.434] Epoch 56:   6%|▌         | 57/1000 [4:01:34<65:29:12, 250.00s/it, lr=6.25e-5, test_MAE=0.443, time=250, train_MAE=0.375, train_loss=0.377, val_MAE=0.431, val_loss=0.434]Epoch 57:   6%|▌         | 57/1000 [4:01:34<65:29:12, 250.00s/it, lr=6.25e-5, test_MAE=0.443, time=250, train_MAE=0.375, train_loss=0.377, val_MAE=0.431, val_loss=0.434]Epoch 57:   6%|▌         | 57/1000 [4:05:43<65:29:12, 250.00s/it, lr=6.25e-5, test_MAE=0.439, time=250, train_MAE=0.375, train_loss=0.377, val_MAE=0.424, val_loss=0.426]Epoch 57:   6%|▌         | 58/1000 [4:05:43<65:22:50, 249.86s/it, lr=6.25e-5, test_MAE=0.439, time=250, train_MAE=0.375, train_loss=0.377, val_MAE=0.424, val_loss=0.426]Epoch 58:   6%|▌         | 58/1000 [4:05:43<65:22:50, 249.86s/it, lr=6.25e-5, test_MAE=0.439, time=250, train_MAE=0.375, train_loss=0.377, val_MAE=0.424, val_loss=0.426]Epoch 58:   6%|▌         | 58/1000 [4:09:53<65:22:50, 249.86s/it, lr=6.25e-5, test_MAE=0.435, time=249, train_MAE=0.377, train_loss=0.379, val_MAE=0.421, val_loss=0.423]Epoch 58:   6%|▌         | 59/1000 [4:09:53<65:16:34, 249.73s/it, lr=6.25e-5, test_MAE=0.435, time=249, train_MAE=0.377, train_loss=0.379, val_MAE=0.421, val_loss=0.423]Epoch 59:   6%|▌         | 59/1000 [4:09:53<65:16:34, 249.73s/it, lr=6.25e-5, test_MAE=0.435, time=249, train_MAE=0.377, train_loss=0.379, val_MAE=0.421, val_loss=0.423]Epoch 59:   6%|▌         | 59/1000 [4:14:03<65:16:34, 249.73s/it, lr=6.25e-5, test_MAE=0.441, time=250, train_MAE=0.373, train_loss=0.376, val_MAE=0.431, val_loss=0.434]Epoch 59:   6%|▌         | 60/1000 [4:14:03<65:15:58, 249.96s/it, lr=6.25e-5, test_MAE=0.441, time=250, train_MAE=0.373, train_loss=0.376, val_MAE=0.431, val_loss=0.434]Epoch 60:   6%|▌         | 60/1000 [4:14:03<65:15:58, 249.96s/it, lr=6.25e-5, test_MAE=0.441, time=250, train_MAE=0.373, train_loss=0.376, val_MAE=0.431, val_loss=0.434]Epoch 60:   6%|▌         | 60/1000 [4:18:13<65:15:58, 249.96s/it, lr=6.25e-5, test_MAE=0.425, time=250, train_MAE=0.376, train_loss=0.379, val_MAE=0.416, val_loss=0.418]Epoch 60:   6%|▌         | 61/1000 [4:18:13<65:11:16, 249.92s/it, lr=6.25e-5, test_MAE=0.425, time=250, train_MAE=0.376, train_loss=0.379, val_MAE=0.416, val_loss=0.418]Epoch 61:   6%|▌         | 61/1000 [4:18:13<65:11:16, 249.92s/it, lr=6.25e-5, test_MAE=0.425, time=250, train_MAE=0.376, train_loss=0.379, val_MAE=0.416, val_loss=0.418]Epoch 61:   6%|▌         | 61/1000 [4:22:23<65:11:16, 249.92s/it, lr=6.25e-5, test_MAE=0.425, time=250, train_MAE=0.373, train_loss=0.375, val_MAE=0.417, val_loss=0.42] Epoch 61:   6%|▌         | 62/1000 [4:22:23<65:06:06, 249.86s/it, lr=6.25e-5, test_MAE=0.425, time=250, train_MAE=0.373, train_loss=0.375, val_MAE=0.417, val_loss=0.42]Epoch 62:   6%|▌         | 62/1000 [4:22:23<65:06:06, 249.86s/it, lr=6.25e-5, test_MAE=0.425, time=250, train_MAE=0.373, train_loss=0.375, val_MAE=0.417, val_loss=0.42]Epoch 62:   6%|▌         | 62/1000 [4:26:32<65:06:06, 249.86s/it, lr=6.25e-5, test_MAE=0.43, time=250, train_MAE=0.377, train_loss=0.38, val_MAE=0.42, val_loss=0.422]  Epoch 62:   6%|▋         | 63/1000 [4:26:32<65:00:31, 249.77s/it, lr=6.25e-5, test_MAE=0.43, time=250, train_MAE=0.377, train_loss=0.38, val_MAE=0.42, val_loss=0.422]Epoch 63:   6%|▋         | 63/1000 [4:26:32<65:00:31, 249.77s/it, lr=6.25e-5, test_MAE=0.43, time=250, train_MAE=0.377, train_loss=0.38, val_MAE=0.42, val_loss=0.422]Epoch 63:   6%|▋         | 63/1000 [4:30:42<65:00:31, 249.77s/it, lr=6.25e-5, test_MAE=0.445, time=250, train_MAE=0.373, train_loss=0.375, val_MAE=0.435, val_loss=0.438]Epoch 63:   6%|▋         | 64/1000 [4:30:42<64:57:48, 249.86s/it, lr=6.25e-5, test_MAE=0.445, time=250, train_MAE=0.373, train_loss=0.375, val_MAE=0.435, val_loss=0.438]Epoch 64:   6%|▋         | 64/1000 [4:30:42<64:57:48, 249.86s/it, lr=6.25e-5, test_MAE=0.445, time=250, train_MAE=0.373, train_loss=0.375, val_MAE=0.435, val_loss=0.438]Epoch 64:   6%|▋         | 64/1000 [4:34:52<64:57:48, 249.86s/it, lr=6.25e-5, test_MAE=0.512, time=250, train_MAE=0.371, train_loss=0.374, val_MAE=0.481, val_loss=0.484]Epoch 64:   6%|▋         | 65/1000 [4:34:52<64:54:12, 249.90s/it, lr=6.25e-5, test_MAE=0.512, time=250, train_MAE=0.371, train_loss=0.374, val_MAE=0.481, val_loss=0.484]Epoch 65:   6%|▋         | 65/1000 [4:34:52<64:54:12, 249.90s/it, lr=6.25e-5, test_MAE=0.512, time=250, train_MAE=0.371, train_loss=0.374, val_MAE=0.481, val_loss=0.484]Epoch 65:   6%|▋         | 65/1000 [4:39:02<64:54:12, 249.90s/it, lr=6.25e-5, test_MAE=0.43, time=250, train_MAE=0.365, train_loss=0.368, val_MAE=0.418, val_loss=0.421] Epoch 65:   7%|▋         | 66/1000 [4:39:02<64:51:30, 249.99s/it, lr=6.25e-5, test_MAE=0.43, time=250, train_MAE=0.365, train_loss=0.368, val_MAE=0.418, val_loss=0.421]Epoch 66:   7%|▋         | 66/1000 [4:39:02<64:51:30, 249.99s/it, lr=6.25e-5, test_MAE=0.43, time=250, train_MAE=0.365, train_loss=0.368, val_MAE=0.418, val_loss=0.421]Epoch 66:   7%|▋         | 66/1000 [4:43:12<64:51:30, 249.99s/it, lr=6.25e-5, test_MAE=0.427, time=250, train_MAE=0.367, train_loss=0.37, val_MAE=0.417, val_loss=0.42] Epoch    67: reducing learning rate of group 0 to 3.1250e-05.
Epoch 66:   7%|▋         | 67/1000 [4:43:12<64:45:38, 249.88s/it, lr=6.25e-5, test_MAE=0.427, time=250, train_MAE=0.367, train_loss=0.37, val_MAE=0.417, val_loss=0.42]Epoch 67:   7%|▋         | 67/1000 [4:43:12<64:45:38, 249.88s/it, lr=6.25e-5, test_MAE=0.427, time=250, train_MAE=0.367, train_loss=0.37, val_MAE=0.417, val_loss=0.42]Epoch 67:   7%|▋         | 67/1000 [4:47:23<64:45:38, 249.88s/it, lr=3.13e-5, test_MAE=0.426, time=251, train_MAE=0.379, train_loss=0.382, val_MAE=0.416, val_loss=0.418]Epoch 67:   7%|▋         | 68/1000 [4:47:23<64:45:36, 250.15s/it, lr=3.13e-5, test_MAE=0.426, time=251, train_MAE=0.379, train_loss=0.382, val_MAE=0.416, val_loss=0.418]Epoch 68:   7%|▋         | 68/1000 [4:47:23<64:45:36, 250.15s/it, lr=3.13e-5, test_MAE=0.426, time=251, train_MAE=0.379, train_loss=0.382, val_MAE=0.416, val_loss=0.418]Epoch 68:   7%|▋         | 68/1000 [4:51:32<64:45:36, 250.15s/it, lr=3.13e-5, test_MAE=0.421, time=249, train_MAE=0.363, train_loss=0.365, val_MAE=0.41, val_loss=0.413] Epoch 68:   7%|▋         | 69/1000 [4:51:32<64:36:55, 249.86s/it, lr=3.13e-5, test_MAE=0.421, time=249, train_MAE=0.363, train_loss=0.365, val_MAE=0.41, val_loss=0.413]Epoch 69:   7%|▋         | 69/1000 [4:51:32<64:36:55, 249.86s/it, lr=3.13e-5, test_MAE=0.421, time=249, train_MAE=0.363, train_loss=0.365, val_MAE=0.41, val_loss=0.413]Epoch 69:   7%|▋         | 69/1000 [4:55:40<64:36:55, 249.86s/it, lr=3.13e-5, test_MAE=0.433, time=248, train_MAE=0.367, train_loss=0.37, val_MAE=0.425, val_loss=0.427]Epoch 69:   7%|▋         | 70/1000 [4:55:40<64:23:13, 249.24s/it, lr=3.13e-5, test_MAE=0.433, time=248, train_MAE=0.367, train_loss=0.37, val_MAE=0.425, val_loss=0.427]Epoch 70:   7%|▋         | 70/1000 [4:55:40<64:23:13, 249.24s/it, lr=3.13e-5, test_MAE=0.433, time=248, train_MAE=0.367, train_loss=0.37, val_MAE=0.425, val_loss=0.427]Epoch 70:   7%|▋         | 70/1000 [4:59:47<64:23:13, 249.24s/it, lr=3.13e-5, test_MAE=0.426, time=248, train_MAE=0.365, train_loss=0.367, val_MAE=0.408, val_loss=0.411]Epoch 70:   7%|▋         | 71/1000 [4:59:47<64:12:02, 248.79s/it, lr=3.13e-5, test_MAE=0.426, time=248, train_MAE=0.365, train_loss=0.367, val_MAE=0.408, val_loss=0.411]Epoch 71:   7%|▋         | 71/1000 [4:59:47<64:12:02, 248.79s/it, lr=3.13e-5, test_MAE=0.426, time=248, train_MAE=0.365, train_loss=0.367, val_MAE=0.408, val_loss=0.411]Epoch 71:   7%|▋         | 71/1000 [5:03:55<64:12:02, 248.79s/it, lr=3.13e-5, test_MAE=0.424, time=248, train_MAE=0.362, train_loss=0.364, val_MAE=0.413, val_loss=0.415]Epoch 71:   7%|▋         | 72/1000 [5:03:55<64:03:35, 248.51s/it, lr=3.13e-5, test_MAE=0.424, time=248, train_MAE=0.362, train_loss=0.364, val_MAE=0.413, val_loss=0.415]Epoch 72:   7%|▋         | 72/1000 [5:03:55<64:03:35, 248.51s/it, lr=3.13e-5, test_MAE=0.424, time=248, train_MAE=0.362, train_loss=0.364, val_MAE=0.413, val_loss=0.415]Epoch 72:   7%|▋         | 72/1000 [5:08:03<64:03:35, 248.51s/it, lr=3.13e-5, test_MAE=0.425, time=248, train_MAE=0.366, train_loss=0.369, val_MAE=0.419, val_loss=0.422]Epoch 72:   7%|▋         | 73/1000 [5:08:03<63:55:49, 248.27s/it, lr=3.13e-5, test_MAE=0.425, time=248, train_MAE=0.366, train_loss=0.369, val_MAE=0.419, val_loss=0.422]Epoch 73:   7%|▋         | 73/1000 [5:08:03<63:55:49, 248.27s/it, lr=3.13e-5, test_MAE=0.425, time=248, train_MAE=0.366, train_loss=0.369, val_MAE=0.419, val_loss=0.422]Epoch 73:   7%|▋         | 73/1000 [5:12:11<63:55:49, 248.27s/it, lr=3.13e-5, test_MAE=0.422, time=248, train_MAE=0.36, train_loss=0.363, val_MAE=0.408, val_loss=0.411] Epoch 73:   7%|▋         | 74/1000 [5:12:11<63:50:19, 248.18s/it, lr=3.13e-5, test_MAE=0.422, time=248, train_MAE=0.36, train_loss=0.363, val_MAE=0.408, val_loss=0.411]Epoch 74:   7%|▋         | 74/1000 [5:12:11<63:50:19, 248.18s/it, lr=3.13e-5, test_MAE=0.422, time=248, train_MAE=0.36, train_loss=0.363, val_MAE=0.408, val_loss=0.411]Epoch 74:   7%|▋         | 74/1000 [5:16:19<63:50:19, 248.18s/it, lr=3.13e-5, test_MAE=0.415, time=248, train_MAE=0.363, train_loss=0.366, val_MAE=0.408, val_loss=0.41]Epoch 74:   8%|▊         | 75/1000 [5:16:19<63:46:07, 248.18s/it, lr=3.13e-5, test_MAE=0.415, time=248, train_MAE=0.363, train_loss=0.366, val_MAE=0.408, val_loss=0.41]Epoch 75:   8%|▊         | 75/1000 [5:16:19<63:46:07, 248.18s/it, lr=3.13e-5, test_MAE=0.415, time=248, train_MAE=0.363, train_loss=0.366, val_MAE=0.408, val_loss=0.41]Epoch 75:   8%|▊         | 75/1000 [5:20:28<63:46:07, 248.18s/it, lr=3.13e-5, test_MAE=0.432, time=248, train_MAE=0.356, train_loss=0.359, val_MAE=0.423, val_loss=0.426]Epoch 75:   8%|▊         | 76/1000 [5:20:28<63:43:26, 248.28s/it, lr=3.13e-5, test_MAE=0.432, time=248, train_MAE=0.356, train_loss=0.359, val_MAE=0.423, val_loss=0.426]Epoch 76:   8%|▊         | 76/1000 [5:20:28<63:43:26, 248.28s/it, lr=3.13e-5, test_MAE=0.432, time=248, train_MAE=0.356, train_loss=0.359, val_MAE=0.423, val_loss=0.426]Epoch 76:   8%|▊         | 76/1000 [5:24:36<63:43:26, 248.28s/it, lr=3.13e-5, test_MAE=0.429, time=248, train_MAE=0.36, train_loss=0.363, val_MAE=0.419, val_loss=0.421] Epoch 76:   8%|▊         | 77/1000 [5:24:36<63:37:46, 248.18s/it, lr=3.13e-5, test_MAE=0.429, time=248, train_MAE=0.36, train_loss=0.363, val_MAE=0.419, val_loss=0.421]Epoch 77:   8%|▊         | 77/1000 [5:24:36<63:37:46, 248.18s/it, lr=3.13e-5, test_MAE=0.429, time=248, train_MAE=0.36, train_loss=0.363, val_MAE=0.419, val_loss=0.421]Epoch 77:   8%|▊         | 77/1000 [5:28:44<63:37:46, 248.18s/it, lr=3.13e-5, test_MAE=0.424, time=249, train_MAE=0.352, train_loss=0.354, val_MAE=0.414, val_loss=0.417]Epoch 77:   8%|▊         | 78/1000 [5:28:44<63:36:25, 248.36s/it, lr=3.13e-5, test_MAE=0.424, time=249, train_MAE=0.352, train_loss=0.354, val_MAE=0.414, val_loss=0.417]Epoch 78:   8%|▊         | 78/1000 [5:28:44<63:36:25, 248.36s/it, lr=3.13e-5, test_MAE=0.424, time=249, train_MAE=0.352, train_loss=0.354, val_MAE=0.414, val_loss=0.417]Epoch 78:   8%|▊         | 78/1000 [5:32:53<63:36:25, 248.36s/it, lr=3.13e-5, test_MAE=0.418, time=248, train_MAE=0.362, train_loss=0.364, val_MAE=0.412, val_loss=0.415]Epoch 78:   8%|▊         | 79/1000 [5:32:53<63:32:44, 248.39s/it, lr=3.13e-5, test_MAE=0.418, time=248, train_MAE=0.362, train_loss=0.364, val_MAE=0.412, val_loss=0.415]Epoch 79:   8%|▊         | 79/1000 [5:32:53<63:32:44, 248.39s/it, lr=3.13e-5, test_MAE=0.418, time=248, train_MAE=0.362, train_loss=0.364, val_MAE=0.412, val_loss=0.415]Epoch 79:   8%|▊         | 79/1000 [5:37:01<63:32:44, 248.39s/it, lr=3.13e-5, test_MAE=0.423, time=248, train_MAE=0.36, train_loss=0.363, val_MAE=0.41, val_loss=0.413]  Epoch 79:   8%|▊         | 80/1000 [5:37:01<63:25:31, 248.19s/it, lr=3.13e-5, test_MAE=0.423, time=248, train_MAE=0.36, train_loss=0.363, val_MAE=0.41, val_loss=0.413]Epoch 80:   8%|▊         | 80/1000 [5:37:01<63:25:31, 248.19s/it, lr=3.13e-5, test_MAE=0.423, time=248, train_MAE=0.36, train_loss=0.363, val_MAE=0.41, val_loss=0.413]Epoch 80:   8%|▊         | 80/1000 [5:41:09<63:25:31, 248.19s/it, lr=3.13e-5, test_MAE=0.414, time=248, train_MAE=0.359, train_loss=0.362, val_MAE=0.407, val_loss=0.41]Epoch 80:   8%|▊         | 81/1000 [5:41:09<63:21:29, 248.19s/it, lr=3.13e-5, test_MAE=0.414, time=248, train_MAE=0.359, train_loss=0.362, val_MAE=0.407, val_loss=0.41]Epoch 81:   8%|▊         | 81/1000 [5:41:09<63:21:29, 248.19s/it, lr=3.13e-5, test_MAE=0.414, time=248, train_MAE=0.359, train_loss=0.362, val_MAE=0.407, val_loss=0.41]Epoch 81:   8%|▊         | 81/1000 [5:45:16<63:21:29, 248.19s/it, lr=3.13e-5, test_MAE=0.416, time=247, train_MAE=0.357, train_loss=0.36, val_MAE=0.41, val_loss=0.413] Epoch 81:   8%|▊         | 82/1000 [5:45:16<63:14:19, 247.99s/it, lr=3.13e-5, test_MAE=0.416, time=247, train_MAE=0.357, train_loss=0.36, val_MAE=0.41, val_loss=0.413]Epoch 82:   8%|▊         | 82/1000 [5:45:16<63:14:19, 247.99s/it, lr=3.13e-5, test_MAE=0.416, time=247, train_MAE=0.357, train_loss=0.36, val_MAE=0.41, val_loss=0.413]Epoch 82:   8%|▊         | 82/1000 [5:49:24<63:14:19, 247.99s/it, lr=3.13e-5, test_MAE=0.421, time=248, train_MAE=0.364, train_loss=0.366, val_MAE=0.413, val_loss=0.416]Epoch 82:   8%|▊         | 83/1000 [5:49:24<63:08:35, 247.89s/it, lr=3.13e-5, test_MAE=0.421, time=248, train_MAE=0.364, train_loss=0.366, val_MAE=0.413, val_loss=0.416]Epoch 83:   8%|▊         | 83/1000 [5:49:24<63:08:35, 247.89s/it, lr=3.13e-5, test_MAE=0.421, time=248, train_MAE=0.364, train_loss=0.366, val_MAE=0.413, val_loss=0.416]Epoch 83:   8%|▊         | 83/1000 [5:53:32<63:08:35, 247.89s/it, lr=3.13e-5, test_MAE=0.43, time=248, train_MAE=0.357, train_loss=0.359, val_MAE=0.42, val_loss=0.423]  Epoch 83:   8%|▊         | 84/1000 [5:53:32<63:05:26, 247.95s/it, lr=3.13e-5, test_MAE=0.43, time=248, train_MAE=0.357, train_loss=0.359, val_MAE=0.42, val_loss=0.423]Epoch 84:   8%|▊         | 84/1000 [5:53:32<63:05:26, 247.95s/it, lr=3.13e-5, test_MAE=0.43, time=248, train_MAE=0.357, train_loss=0.359, val_MAE=0.42, val_loss=0.423]Epoch 84:   8%|▊         | 84/1000 [5:57:40<63:05:26, 247.95s/it, lr=3.13e-5, test_MAE=0.42, time=248, train_MAE=0.356, train_loss=0.359, val_MAE=0.41, val_loss=0.412]Epoch 84:   8%|▊         | 85/1000 [5:57:40<63:00:10, 247.88s/it, lr=3.13e-5, test_MAE=0.42, time=248, train_MAE=0.356, train_loss=0.359, val_MAE=0.41, val_loss=0.412]Epoch 85:   8%|▊         | 85/1000 [5:57:40<63:00:10, 247.88s/it, lr=3.13e-5, test_MAE=0.42, time=248, train_MAE=0.356, train_loss=0.359, val_MAE=0.41, val_loss=0.412]Epoch 85:   8%|▊         | 85/1000 [6:01:48<63:00:10, 247.88s/it, lr=3.13e-5, test_MAE=0.423, time=248, train_MAE=0.354, train_loss=0.357, val_MAE=0.411, val_loss=0.414]Epoch 85:   9%|▊         | 86/1000 [6:01:48<62:58:27, 248.04s/it, lr=3.13e-5, test_MAE=0.423, time=248, train_MAE=0.354, train_loss=0.357, val_MAE=0.411, val_loss=0.414]Epoch 86:   9%|▊         | 86/1000 [6:01:48<62:58:27, 248.04s/it, lr=3.13e-5, test_MAE=0.423, time=248, train_MAE=0.354, train_loss=0.357, val_MAE=0.411, val_loss=0.414]Epoch 86:   9%|▊         | 86/1000 [6:05:57<62:58:27, 248.04s/it, lr=3.13e-5, test_MAE=0.42, time=249, train_MAE=0.351, train_loss=0.354, val_MAE=0.41, val_loss=0.412]  Epoch    87: reducing learning rate of group 0 to 1.5625e-05.
Epoch 86:   9%|▊         | 87/1000 [6:05:57<62:56:42, 248.20s/it, lr=3.13e-5, test_MAE=0.42, time=249, train_MAE=0.351, train_loss=0.354, val_MAE=0.41, val_loss=0.412]Epoch 87:   9%|▊         | 87/1000 [6:05:57<62:56:42, 248.20s/it, lr=3.13e-5, test_MAE=0.42, time=249, train_MAE=0.351, train_loss=0.354, val_MAE=0.41, val_loss=0.412]Epoch 87:   9%|▊         | 87/1000 [6:10:05<62:56:42, 248.20s/it, lr=1.56e-5, test_MAE=0.422, time=248, train_MAE=0.353, train_loss=0.356, val_MAE=0.403, val_loss=0.406]Epoch 87:   9%|▉         | 88/1000 [6:10:05<62:51:50, 248.15s/it, lr=1.56e-5, test_MAE=0.422, time=248, train_MAE=0.353, train_loss=0.356, val_MAE=0.403, val_loss=0.406]Epoch 88:   9%|▉         | 88/1000 [6:10:05<62:51:50, 248.15s/it, lr=1.56e-5, test_MAE=0.422, time=248, train_MAE=0.353, train_loss=0.356, val_MAE=0.403, val_loss=0.406]Epoch 88:   9%|▉         | 88/1000 [6:14:13<62:51:50, 248.15s/it, lr=1.56e-5, test_MAE=0.419, time=248, train_MAE=0.351, train_loss=0.353, val_MAE=0.409, val_loss=0.412]Epoch 88:   9%|▉         | 89/1000 [6:14:13<62:45:56, 248.03s/it, lr=1.56e-5, test_MAE=0.419, time=248, train_MAE=0.351, train_loss=0.353, val_MAE=0.409, val_loss=0.412]Epoch 89:   9%|▉         | 89/1000 [6:14:13<62:45:56, 248.03s/it, lr=1.56e-5, test_MAE=0.419, time=248, train_MAE=0.351, train_loss=0.353, val_MAE=0.409, val_loss=0.412]Epoch 89:   9%|▉         | 89/1000 [6:18:21<62:45:56, 248.03s/it, lr=1.56e-5, test_MAE=0.42, time=248, train_MAE=0.35, train_loss=0.353, val_MAE=0.408, val_loss=0.411]  Epoch 89:   9%|▉         | 90/1000 [6:18:21<62:43:09, 248.12s/it, lr=1.56e-5, test_MAE=0.42, time=248, train_MAE=0.35, train_loss=0.353, val_MAE=0.408, val_loss=0.411]Epoch 90:   9%|▉         | 90/1000 [6:18:21<62:43:09, 248.12s/it, lr=1.56e-5, test_MAE=0.42, time=248, train_MAE=0.35, train_loss=0.353, val_MAE=0.408, val_loss=0.411]Epoch 90:   9%|▉         | 90/1000 [6:22:28<62:43:09, 248.12s/it, lr=1.56e-5, test_MAE=0.419, time=247, train_MAE=0.35, train_loss=0.352, val_MAE=0.408, val_loss=0.411]Epoch 90:   9%|▉         | 91/1000 [6:22:28<62:36:09, 247.93s/it, lr=1.56e-5, test_MAE=0.419, time=247, train_MAE=0.35, train_loss=0.352, val_MAE=0.408, val_loss=0.411]Epoch 91:   9%|▉         | 91/1000 [6:22:28<62:36:09, 247.93s/it, lr=1.56e-5, test_MAE=0.419, time=247, train_MAE=0.35, train_loss=0.352, val_MAE=0.408, val_loss=0.411]Epoch 91:   9%|▉         | 91/1000 [6:26:36<62:36:09, 247.93s/it, lr=1.56e-5, test_MAE=0.416, time=248, train_MAE=0.345, train_loss=0.348, val_MAE=0.405, val_loss=0.407]Epoch 91:   9%|▉         | 92/1000 [6:26:36<62:30:10, 247.81s/it, lr=1.56e-5, test_MAE=0.416, time=248, train_MAE=0.345, train_loss=0.348, val_MAE=0.405, val_loss=0.407]Epoch 92:   9%|▉         | 92/1000 [6:26:36<62:30:10, 247.81s/it, lr=1.56e-5, test_MAE=0.416, time=248, train_MAE=0.345, train_loss=0.348, val_MAE=0.405, val_loss=0.407]Epoch 92:   9%|▉         | 92/1000 [6:30:44<62:30:10, 247.81s/it, lr=1.56e-5, test_MAE=0.414, time=248, train_MAE=0.345, train_loss=0.348, val_MAE=0.4, val_loss=0.402]  Epoch 92:   9%|▉         | 93/1000 [6:30:44<62:28:35, 247.98s/it, lr=1.56e-5, test_MAE=0.414, time=248, train_MAE=0.345, train_loss=0.348, val_MAE=0.4, val_loss=0.402]Epoch 93:   9%|▉         | 93/1000 [6:30:44<62:28:35, 247.98s/it, lr=1.56e-5, test_MAE=0.414, time=248, train_MAE=0.345, train_loss=0.348, val_MAE=0.4, val_loss=0.402]Epoch 93:   9%|▉         | 93/1000 [6:34:52<62:28:35, 247.98s/it, lr=1.56e-5, test_MAE=0.413, time=248, train_MAE=0.346, train_loss=0.349, val_MAE=0.404, val_loss=0.407]Epoch 93:   9%|▉         | 94/1000 [6:34:52<62:23:16, 247.90s/it, lr=1.56e-5, test_MAE=0.413, time=248, train_MAE=0.346, train_loss=0.349, val_MAE=0.404, val_loss=0.407]Epoch 94:   9%|▉         | 94/1000 [6:34:52<62:23:16, 247.90s/it, lr=1.56e-5, test_MAE=0.413, time=248, train_MAE=0.346, train_loss=0.349, val_MAE=0.404, val_loss=0.407]Epoch 94:   9%|▉         | 94/1000 [6:39:01<62:23:16, 247.90s/it, lr=1.56e-5, test_MAE=0.416, time=249, train_MAE=0.345, train_loss=0.348, val_MAE=0.403, val_loss=0.406]Epoch 94:  10%|▉         | 95/1000 [6:39:01<62:23:23, 248.18s/it, lr=1.56e-5, test_MAE=0.416, time=249, train_MAE=0.345, train_loss=0.348, val_MAE=0.403, val_loss=0.406]Epoch 95:  10%|▉         | 95/1000 [6:39:01<62:23:23, 248.18s/it, lr=1.56e-5, test_MAE=0.416, time=249, train_MAE=0.345, train_loss=0.348, val_MAE=0.403, val_loss=0.406]Epoch 95:  10%|▉         | 95/1000 [6:43:09<62:23:23, 248.18s/it, lr=1.56e-5, test_MAE=0.422, time=249, train_MAE=0.343, train_loss=0.346, val_MAE=0.406, val_loss=0.408]Epoch 95:  10%|▉         | 96/1000 [6:43:09<62:20:49, 248.29s/it, lr=1.56e-5, test_MAE=0.422, time=249, train_MAE=0.343, train_loss=0.346, val_MAE=0.406, val_loss=0.408]Epoch 96:  10%|▉         | 96/1000 [6:43:09<62:20:49, 248.29s/it, lr=1.56e-5, test_MAE=0.422, time=249, train_MAE=0.343, train_loss=0.346, val_MAE=0.406, val_loss=0.408]Epoch 96:  10%|▉         | 96/1000 [6:47:17<62:20:49, 248.29s/it, lr=1.56e-5, test_MAE=0.42, time=248, train_MAE=0.344, train_loss=0.346, val_MAE=0.413, val_loss=0.416] Epoch 96:  10%|▉         | 97/1000 [6:47:17<62:15:31, 248.21s/it, lr=1.56e-5, test_MAE=0.42, time=248, train_MAE=0.344, train_loss=0.346, val_MAE=0.413, val_loss=0.416]Epoch 97:  10%|▉         | 97/1000 [6:47:17<62:15:31, 248.21s/it, lr=1.56e-5, test_MAE=0.42, time=248, train_MAE=0.344, train_loss=0.346, val_MAE=0.413, val_loss=0.416]Epoch 97:  10%|▉         | 97/1000 [6:51:26<62:15:31, 248.21s/it, lr=1.56e-5, test_MAE=0.42, time=249, train_MAE=0.344, train_loss=0.347, val_MAE=0.41, val_loss=0.412] Epoch 97:  10%|▉         | 98/1000 [6:51:26<62:13:04, 248.32s/it, lr=1.56e-5, test_MAE=0.42, time=249, train_MAE=0.344, train_loss=0.347, val_MAE=0.41, val_loss=0.412]Epoch 98:  10%|▉         | 98/1000 [6:51:26<62:13:04, 248.32s/it, lr=1.56e-5, test_MAE=0.42, time=249, train_MAE=0.344, train_loss=0.347, val_MAE=0.41, val_loss=0.412]Epoch 98:  10%|▉         | 98/1000 [6:55:34<62:13:04, 248.32s/it, lr=1.56e-5, test_MAE=0.414, time=248, train_MAE=0.343, train_loss=0.346, val_MAE=0.403, val_loss=0.406]Epoch    99: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 98:  10%|▉         | 98/1000 [6:55:34<63:44:59, 254.43s/it, lr=1.56e-5, test_MAE=0.414, time=248, train_MAE=0.343, train_loss=0.346, val_MAE=0.403, val_loss=0.406]
Test MAE: 0.4140
Train MAE: 0.3315
Convergence Time (Epochs): 98.0000
TOTAL TIME TAKEN: 25040.1109s
AVG TIME PER EPOCH: 251.8405s
