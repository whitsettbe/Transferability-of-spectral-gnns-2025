I'm echoing to stdout
I'm echoing to stderr
My JobID is 56599720
I have 8 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.0755s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 4, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'rational_vec', 'normalized_laplacian': True, 'post_normalized': False, 'eigval_norm': '', 'num_eigs': 15, 'bias_mode': 'spatial', 'eigval_hidden_dim': 5, 'eigval_num_hidden_layer': 3, 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 1, 'eigmod': 'rand_basis', 'eigInFiles': {'train': 'supp_data/molecules/zinc_train_rec_full.csv', 'test': 'supp_data/molecules/zinc_test_rec_full.csv', 'val': 'supp_data/molecules/zinc_val_rec_full.csv'}, 'fixMissingPhi1': False, 'extraOrtho': True, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [03:18<?, ?it/s, lr=0.001, test_MAE=1.54, time=199, train_MAE=1.19, train_loss=1.21, val_MAE=1.49, val_loss=1.52]Epoch 0:   0%|          | 1/1000 [03:18<55:06:26, 198.59s/it, lr=0.001, test_MAE=1.54, time=199, train_MAE=1.19, train_loss=1.21, val_MAE=1.49, val_loss=1.52]Epoch 1:   0%|          | 1/1000 [03:18<55:06:26, 198.59s/it, lr=0.001, test_MAE=1.54, time=199, train_MAE=1.19, train_loss=1.21, val_MAE=1.49, val_loss=1.52]Epoch 1:   0%|          | 1/1000 [05:37<55:06:26, 198.59s/it, lr=0.001, test_MAE=0.905, time=139, train_MAE=0.771, train_loss=0.799, val_MAE=0.848, val_loss=0.877]Epoch 1:   0%|          | 2/1000 [05:37<50:07:08, 180.79s/it, lr=0.001, test_MAE=0.905, time=139, train_MAE=0.771, train_loss=0.799, val_MAE=0.848, val_loss=0.877]Epoch 2:   0%|          | 2/1000 [05:37<50:07:08, 180.79s/it, lr=0.001, test_MAE=0.905, time=139, train_MAE=0.771, train_loss=0.799, val_MAE=0.848, val_loss=0.877]Epoch 2:   0%|          | 2/1000 [07:55<50:07:08, 180.79s/it, lr=0.001, test_MAE=0.73, time=137, train_MAE=0.68, train_loss=0.709, val_MAE=0.687, val_loss=0.717]  Epoch 2:   0%|          | 3/1000 [07:55<46:26:43, 167.71s/it, lr=0.001, test_MAE=0.73, time=137, train_MAE=0.68, train_loss=0.709, val_MAE=0.687, val_loss=0.717]Epoch 3:   0%|          | 3/1000 [07:55<46:26:43, 167.71s/it, lr=0.001, test_MAE=0.73, time=137, train_MAE=0.68, train_loss=0.709, val_MAE=0.687, val_loss=0.717]Epoch 3:   0%|          | 3/1000 [10:11<46:26:43, 167.71s/it, lr=0.001, test_MAE=0.696, time=136, train_MAE=0.653, train_loss=0.683, val_MAE=0.659, val_loss=0.689]Epoch 3:   0%|          | 4/1000 [10:11<43:46:59, 158.25s/it, lr=0.001, test_MAE=0.696, time=136, train_MAE=0.653, train_loss=0.683, val_MAE=0.659, val_loss=0.689]Epoch 4:   0%|          | 4/1000 [10:11<43:46:59, 158.25s/it, lr=0.001, test_MAE=0.696, time=136, train_MAE=0.653, train_loss=0.683, val_MAE=0.659, val_loss=0.689]Epoch 4:   0%|          | 4/1000 [12:27<43:46:59, 158.25s/it, lr=0.001, test_MAE=0.732, time=137, train_MAE=0.643, train_loss=0.673, val_MAE=0.678, val_loss=0.708]Epoch 4:   0%|          | 5/1000 [12:27<41:56:18, 151.74s/it, lr=0.001, test_MAE=0.732, time=137, train_MAE=0.643, train_loss=0.673, val_MAE=0.678, val_loss=0.708]Epoch 5:   0%|          | 5/1000 [12:27<41:56:18, 151.74s/it, lr=0.001, test_MAE=0.732, time=137, train_MAE=0.643, train_loss=0.673, val_MAE=0.678, val_loss=0.708]Epoch 5:   0%|          | 5/1000 [14:44<41:56:18, 151.74s/it, lr=0.001, test_MAE=0.672, time=136, train_MAE=0.633, train_loss=0.664, val_MAE=0.619, val_loss=0.65] Epoch 5:   1%|          | 6/1000 [14:44<40:37:09, 147.11s/it, lr=0.001, test_MAE=0.672, time=136, train_MAE=0.633, train_loss=0.664, val_MAE=0.619, val_loss=0.65]Epoch 6:   1%|          | 6/1000 [14:44<40:37:09, 147.11s/it, lr=0.001, test_MAE=0.672, time=136, train_MAE=0.633, train_loss=0.664, val_MAE=0.619, val_loss=0.65]Epoch 6:   1%|          | 6/1000 [17:00<40:37:09, 147.11s/it, lr=0.001, test_MAE=0.707, time=136, train_MAE=0.641, train_loss=0.671, val_MAE=0.647, val_loss=0.678]Epoch 6:   1%|          | 7/1000 [17:00<39:39:45, 143.79s/it, lr=0.001, test_MAE=0.707, time=136, train_MAE=0.641, train_loss=0.671, val_MAE=0.647, val_loss=0.678]Epoch 7:   1%|          | 7/1000 [17:00<39:39:45, 143.79s/it, lr=0.001, test_MAE=0.707, time=136, train_MAE=0.641, train_loss=0.671, val_MAE=0.647, val_loss=0.678]Epoch 7:   1%|          | 7/1000 [19:16<39:39:45, 143.79s/it, lr=0.001, test_MAE=0.694, time=136, train_MAE=0.641, train_loss=0.672, val_MAE=0.631, val_loss=0.663]Epoch 7:   1%|          | 8/1000 [19:16<38:59:20, 141.49s/it, lr=0.001, test_MAE=0.694, time=136, train_MAE=0.641, train_loss=0.672, val_MAE=0.631, val_loss=0.663]Epoch 8:   1%|          | 8/1000 [19:16<38:59:20, 141.49s/it, lr=0.001, test_MAE=0.694, time=136, train_MAE=0.641, train_loss=0.672, val_MAE=0.631, val_loss=0.663]Epoch 8:   1%|          | 8/1000 [21:34<38:59:20, 141.49s/it, lr=0.001, test_MAE=0.711, time=138, train_MAE=0.631, train_loss=0.662, val_MAE=0.687, val_loss=0.719]Epoch 8:   1%|          | 9/1000 [21:34<38:38:42, 140.39s/it, lr=0.001, test_MAE=0.711, time=138, train_MAE=0.631, train_loss=0.662, val_MAE=0.687, val_loss=0.719]Epoch 9:   1%|          | 9/1000 [21:34<38:38:42, 140.39s/it, lr=0.001, test_MAE=0.711, time=138, train_MAE=0.631, train_loss=0.662, val_MAE=0.687, val_loss=0.719]Epoch 9:   1%|          | 9/1000 [23:50<38:38:42, 140.39s/it, lr=0.001, test_MAE=0.662, time=137, train_MAE=0.622, train_loss=0.654, val_MAE=0.613, val_loss=0.645]Epoch 9:   1%|          | 10/1000 [23:50<38:19:16, 139.35s/it, lr=0.001, test_MAE=0.662, time=137, train_MAE=0.622, train_loss=0.654, val_MAE=0.613, val_loss=0.645]Epoch 10:   1%|          | 10/1000 [23:50<38:19:16, 139.35s/it, lr=0.001, test_MAE=0.662, time=137, train_MAE=0.622, train_loss=0.654, val_MAE=0.613, val_loss=0.645]Epoch 10:   1%|          | 10/1000 [26:05<38:19:16, 139.35s/it, lr=0.001, test_MAE=0.667, time=134, train_MAE=0.628, train_loss=0.66, val_MAE=0.628, val_loss=0.66]  Epoch 10:   1%|          | 11/1000 [26:05<37:52:25, 137.86s/it, lr=0.001, test_MAE=0.667, time=134, train_MAE=0.628, train_loss=0.66, val_MAE=0.628, val_loss=0.66]Epoch 11:   1%|          | 11/1000 [26:05<37:52:25, 137.86s/it, lr=0.001, test_MAE=0.667, time=134, train_MAE=0.628, train_loss=0.66, val_MAE=0.628, val_loss=0.66]Epoch 11:   1%|          | 11/1000 [28:18<37:52:25, 137.86s/it, lr=0.001, test_MAE=0.664, time=133, train_MAE=0.617, train_loss=0.649, val_MAE=0.631, val_loss=0.663]Epoch 11:   1%|          | 12/1000 [28:18<37:25:28, 136.36s/it, lr=0.001, test_MAE=0.664, time=133, train_MAE=0.617, train_loss=0.649, val_MAE=0.631, val_loss=0.663]Epoch 12:   1%|          | 12/1000 [28:18<37:25:28, 136.36s/it, lr=0.001, test_MAE=0.664, time=133, train_MAE=0.617, train_loss=0.649, val_MAE=0.631, val_loss=0.663]Epoch 12:   1%|          | 12/1000 [30:30<37:25:28, 136.36s/it, lr=0.001, test_MAE=0.703, time=132, train_MAE=0.638, train_loss=0.67, val_MAE=0.675, val_loss=0.708] Epoch 12:   1%|▏         | 13/1000 [30:30<37:01:55, 135.07s/it, lr=0.001, test_MAE=0.703, time=132, train_MAE=0.638, train_loss=0.67, val_MAE=0.675, val_loss=0.708]Epoch 13:   1%|▏         | 13/1000 [30:30<37:01:55, 135.07s/it, lr=0.001, test_MAE=0.703, time=132, train_MAE=0.638, train_loss=0.67, val_MAE=0.675, val_loss=0.708]Epoch 13:   1%|▏         | 13/1000 [32:42<37:01:55, 135.07s/it, lr=0.001, test_MAE=0.669, time=133, train_MAE=0.607, train_loss=0.64, val_MAE=0.627, val_loss=0.66] Epoch 13:   1%|▏         | 14/1000 [32:42<36:47:31, 134.33s/it, lr=0.001, test_MAE=0.669, time=133, train_MAE=0.607, train_loss=0.64, val_MAE=0.627, val_loss=0.66]Epoch 14:   1%|▏         | 14/1000 [32:42<36:47:31, 134.33s/it, lr=0.001, test_MAE=0.669, time=133, train_MAE=0.607, train_loss=0.64, val_MAE=0.627, val_loss=0.66]Epoch 14:   1%|▏         | 14/1000 [35:01<36:47:31, 134.33s/it, lr=0.001, test_MAE=0.702, time=139, train_MAE=0.608, train_loss=0.641, val_MAE=0.645, val_loss=0.678]Epoch 14:   2%|▏         | 15/1000 [35:01<37:07:42, 135.70s/it, lr=0.001, test_MAE=0.702, time=139, train_MAE=0.608, train_loss=0.641, val_MAE=0.645, val_loss=0.678]Epoch 15:   2%|▏         | 15/1000 [35:01<37:07:42, 135.70s/it, lr=0.001, test_MAE=0.702, time=139, train_MAE=0.608, train_loss=0.641, val_MAE=0.645, val_loss=0.678]Epoch 15:   2%|▏         | 15/1000 [37:17<37:07:42, 135.70s/it, lr=0.001, test_MAE=0.715, time=136, train_MAE=0.61, train_loss=0.644, val_MAE=0.65, val_loss=0.684]  Epoch    16: reducing learning rate of group 0 to 5.0000e-04.
Epoch 15:   2%|▏         | 16/1000 [37:17<37:05:53, 135.72s/it, lr=0.001, test_MAE=0.715, time=136, train_MAE=0.61, train_loss=0.644, val_MAE=0.65, val_loss=0.684]Epoch 16:   2%|▏         | 16/1000 [37:17<37:05:53, 135.72s/it, lr=0.001, test_MAE=0.715, time=136, train_MAE=0.61, train_loss=0.644, val_MAE=0.65, val_loss=0.684]Epoch 16:   2%|▏         | 16/1000 [39:32<37:05:53, 135.72s/it, lr=0.0005, test_MAE=0.673, time=135, train_MAE=0.598, train_loss=0.631, val_MAE=0.626, val_loss=0.659]Epoch 16:   2%|▏         | 17/1000 [39:32<37:01:42, 135.61s/it, lr=0.0005, test_MAE=0.673, time=135, train_MAE=0.598, train_loss=0.631, val_MAE=0.626, val_loss=0.659]Epoch 17:   2%|▏         | 17/1000 [39:32<37:01:42, 135.61s/it, lr=0.0005, test_MAE=0.673, time=135, train_MAE=0.598, train_loss=0.631, val_MAE=0.626, val_loss=0.659]Epoch 17:   2%|▏         | 17/1000 [41:47<37:01:42, 135.61s/it, lr=0.0005, test_MAE=0.671, time=135, train_MAE=0.588, train_loss=0.621, val_MAE=0.629, val_loss=0.663]Epoch 17:   2%|▏         | 18/1000 [41:47<36:56:07, 135.41s/it, lr=0.0005, test_MAE=0.671, time=135, train_MAE=0.588, train_loss=0.621, val_MAE=0.629, val_loss=0.663]Epoch 18:   2%|▏         | 18/1000 [41:47<36:56:07, 135.41s/it, lr=0.0005, test_MAE=0.671, time=135, train_MAE=0.588, train_loss=0.621, val_MAE=0.629, val_loss=0.663]Epoch 18:   2%|▏         | 18/1000 [44:02<36:56:07, 135.41s/it, lr=0.0005, test_MAE=0.639, time=134, train_MAE=0.599, train_loss=0.632, val_MAE=0.601, val_loss=0.635]Epoch 18:   2%|▏         | 19/1000 [44:02<36:49:27, 135.14s/it, lr=0.0005, test_MAE=0.639, time=134, train_MAE=0.599, train_loss=0.632, val_MAE=0.601, val_loss=0.635]Epoch 19:   2%|▏         | 19/1000 [44:02<36:49:27, 135.14s/it, lr=0.0005, test_MAE=0.639, time=134, train_MAE=0.599, train_loss=0.632, val_MAE=0.601, val_loss=0.635]Epoch 19:   2%|▏         | 19/1000 [46:16<36:49:27, 135.14s/it, lr=0.0005, test_MAE=0.679, time=135, train_MAE=0.591, train_loss=0.624, val_MAE=0.615, val_loss=0.648]Epoch 19:   2%|▏         | 20/1000 [46:16<36:44:42, 134.98s/it, lr=0.0005, test_MAE=0.679, time=135, train_MAE=0.591, train_loss=0.624, val_MAE=0.615, val_loss=0.648]Epoch 20:   2%|▏         | 20/1000 [46:16<36:44:42, 134.98s/it, lr=0.0005, test_MAE=0.679, time=135, train_MAE=0.591, train_loss=0.624, val_MAE=0.615, val_loss=0.648]Epoch 20:   2%|▏         | 20/1000 [48:31<36:44:42, 134.98s/it, lr=0.0005, test_MAE=0.655, time=135, train_MAE=0.589, train_loss=0.622, val_MAE=0.599, val_loss=0.632]Epoch 20:   2%|▏         | 21/1000 [48:31<36:42:19, 134.97s/it, lr=0.0005, test_MAE=0.655, time=135, train_MAE=0.589, train_loss=0.622, val_MAE=0.599, val_loss=0.632]Epoch 21:   2%|▏         | 21/1000 [48:31<36:42:19, 134.97s/it, lr=0.0005, test_MAE=0.655, time=135, train_MAE=0.589, train_loss=0.622, val_MAE=0.599, val_loss=0.632]Epoch 21:   2%|▏         | 21/1000 [50:46<36:42:19, 134.97s/it, lr=0.0005, test_MAE=0.655, time=134, train_MAE=0.597, train_loss=0.63, val_MAE=0.614, val_loss=0.647] Epoch 21:   2%|▏         | 22/1000 [50:46<36:37:08, 134.79s/it, lr=0.0005, test_MAE=0.655, time=134, train_MAE=0.597, train_loss=0.63, val_MAE=0.614, val_loss=0.647]Epoch 22:   2%|▏         | 22/1000 [50:46<36:37:08, 134.79s/it, lr=0.0005, test_MAE=0.655, time=134, train_MAE=0.597, train_loss=0.63, val_MAE=0.614, val_loss=0.647]Epoch 22:   2%|▏         | 22/1000 [53:01<36:37:08, 134.79s/it, lr=0.0005, test_MAE=0.634, time=135, train_MAE=0.591, train_loss=0.625, val_MAE=0.583, val_loss=0.617]Epoch 22:   2%|▏         | 23/1000 [53:01<36:35:01, 134.80s/it, lr=0.0005, test_MAE=0.634, time=135, train_MAE=0.591, train_loss=0.625, val_MAE=0.583, val_loss=0.617]Epoch 23:   2%|▏         | 23/1000 [53:01<36:35:01, 134.80s/it, lr=0.0005, test_MAE=0.634, time=135, train_MAE=0.591, train_loss=0.625, val_MAE=0.583, val_loss=0.617]Epoch 23:   2%|▏         | 23/1000 [55:15<36:35:01, 134.80s/it, lr=0.0005, test_MAE=0.643, time=135, train_MAE=0.589, train_loss=0.622, val_MAE=0.587, val_loss=0.621]Epoch 23:   2%|▏         | 24/1000 [55:15<36:31:42, 134.74s/it, lr=0.0005, test_MAE=0.643, time=135, train_MAE=0.589, train_loss=0.622, val_MAE=0.587, val_loss=0.621]Epoch 24:   2%|▏         | 24/1000 [55:15<36:31:42, 134.74s/it, lr=0.0005, test_MAE=0.643, time=135, train_MAE=0.589, train_loss=0.622, val_MAE=0.587, val_loss=0.621]Epoch 24:   2%|▏         | 24/1000 [57:30<36:31:42, 134.74s/it, lr=0.0005, test_MAE=0.641, time=134, train_MAE=0.583, train_loss=0.617, val_MAE=0.59, val_loss=0.623] Epoch 24:   2%|▎         | 25/1000 [57:30<36:27:49, 134.64s/it, lr=0.0005, test_MAE=0.641, time=134, train_MAE=0.583, train_loss=0.617, val_MAE=0.59, val_loss=0.623]Epoch 25:   2%|▎         | 25/1000 [57:30<36:27:49, 134.64s/it, lr=0.0005, test_MAE=0.641, time=134, train_MAE=0.583, train_loss=0.617, val_MAE=0.59, val_loss=0.623]Epoch 25:   2%|▎         | 25/1000 [59:44<36:27:49, 134.64s/it, lr=0.0005, test_MAE=0.656, time=134, train_MAE=0.584, train_loss=0.618, val_MAE=0.614, val_loss=0.647]Epoch 25:   3%|▎         | 26/1000 [59:44<36:23:28, 134.51s/it, lr=0.0005, test_MAE=0.656, time=134, train_MAE=0.584, train_loss=0.618, val_MAE=0.614, val_loss=0.647]Epoch 26:   3%|▎         | 26/1000 [59:44<36:23:28, 134.51s/it, lr=0.0005, test_MAE=0.656, time=134, train_MAE=0.584, train_loss=0.618, val_MAE=0.614, val_loss=0.647]Epoch 26:   3%|▎         | 26/1000 [1:02:00<36:23:28, 134.51s/it, lr=0.0005, test_MAE=0.631, time=136, train_MAE=0.581, train_loss=0.615, val_MAE=0.592, val_loss=0.626]Epoch 26:   3%|▎         | 27/1000 [1:02:00<36:27:03, 134.86s/it, lr=0.0005, test_MAE=0.631, time=136, train_MAE=0.581, train_loss=0.615, val_MAE=0.592, val_loss=0.626]Epoch 27:   3%|▎         | 27/1000 [1:02:00<36:27:03, 134.86s/it, lr=0.0005, test_MAE=0.631, time=136, train_MAE=0.581, train_loss=0.615, val_MAE=0.592, val_loss=0.626]Epoch 27:   3%|▎         | 27/1000 [1:04:14<36:27:03, 134.86s/it, lr=0.0005, test_MAE=0.656, time=135, train_MAE=0.582, train_loss=0.616, val_MAE=0.624, val_loss=0.658]Epoch 27:   3%|▎         | 28/1000 [1:04:14<36:24:02, 134.82s/it, lr=0.0005, test_MAE=0.656, time=135, train_MAE=0.582, train_loss=0.616, val_MAE=0.624, val_loss=0.658]Epoch 28:   3%|▎         | 28/1000 [1:04:14<36:24:02, 134.82s/it, lr=0.0005, test_MAE=0.656, time=135, train_MAE=0.582, train_loss=0.616, val_MAE=0.624, val_loss=0.658]Epoch 28:   3%|▎         | 28/1000 [1:06:29<36:24:02, 134.82s/it, lr=0.0005, test_MAE=0.679, time=135, train_MAE=0.574, train_loss=0.608, val_MAE=0.623, val_loss=0.657]Epoch    29: reducing learning rate of group 0 to 2.5000e-04.
Epoch 28:   3%|▎         | 29/1000 [1:06:29<36:21:01, 134.77s/it, lr=0.0005, test_MAE=0.679, time=135, train_MAE=0.574, train_loss=0.608, val_MAE=0.623, val_loss=0.657]Epoch 29:   3%|▎         | 29/1000 [1:06:29<36:21:01, 134.77s/it, lr=0.0005, test_MAE=0.679, time=135, train_MAE=0.574, train_loss=0.608, val_MAE=0.623, val_loss=0.657]Epoch 29:   3%|▎         | 29/1000 [1:08:44<36:21:01, 134.77s/it, lr=0.00025, test_MAE=0.648, time=135, train_MAE=0.573, train_loss=0.607, val_MAE=0.608, val_loss=0.642]Epoch 29:   3%|▎         | 30/1000 [1:08:44<36:18:46, 134.77s/it, lr=0.00025, test_MAE=0.648, time=135, train_MAE=0.573, train_loss=0.607, val_MAE=0.608, val_loss=0.642]Epoch 30:   3%|▎         | 30/1000 [1:08:44<36:18:46, 134.77s/it, lr=0.00025, test_MAE=0.648, time=135, train_MAE=0.573, train_loss=0.607, val_MAE=0.608, val_loss=0.642]Epoch 30:   3%|▎         | 30/1000 [1:10:59<36:18:46, 134.77s/it, lr=0.00025, test_MAE=0.63, time=135, train_MAE=0.571, train_loss=0.605, val_MAE=0.585, val_loss=0.619] Epoch 30:   3%|▎         | 31/1000 [1:10:59<36:17:47, 134.85s/it, lr=0.00025, test_MAE=0.63, time=135, train_MAE=0.571, train_loss=0.605, val_MAE=0.585, val_loss=0.619]Epoch 31:   3%|▎         | 31/1000 [1:10:59<36:17:47, 134.85s/it, lr=0.00025, test_MAE=0.63, time=135, train_MAE=0.571, train_loss=0.605, val_MAE=0.585, val_loss=0.619]Epoch 31:   3%|▎         | 31/1000 [1:13:09<36:17:47, 134.85s/it, lr=0.00025, test_MAE=0.645, time=130, train_MAE=0.571, train_loss=0.605, val_MAE=0.596, val_loss=0.63]Epoch 31:   3%|▎         | 32/1000 [1:13:09<35:52:53, 133.44s/it, lr=0.00025, test_MAE=0.645, time=130, train_MAE=0.571, train_loss=0.605, val_MAE=0.596, val_loss=0.63]Epoch 32:   3%|▎         | 32/1000 [1:13:09<35:52:53, 133.44s/it, lr=0.00025, test_MAE=0.645, time=130, train_MAE=0.571, train_loss=0.605, val_MAE=0.596, val_loss=0.63]Epoch 32:   3%|▎         | 32/1000 [1:15:18<35:52:53, 133.44s/it, lr=0.00025, test_MAE=0.641, time=129, train_MAE=0.57, train_loss=0.604, val_MAE=0.609, val_loss=0.642]Epoch 32:   3%|▎         | 33/1000 [1:15:18<35:30:41, 132.20s/it, lr=0.00025, test_MAE=0.641, time=129, train_MAE=0.57, train_loss=0.604, val_MAE=0.609, val_loss=0.642]Epoch 33:   3%|▎         | 33/1000 [1:15:18<35:30:41, 132.20s/it, lr=0.00025, test_MAE=0.641, time=129, train_MAE=0.57, train_loss=0.604, val_MAE=0.609, val_loss=0.642]Epoch 33:   3%|▎         | 33/1000 [1:17:28<35:30:41, 132.20s/it, lr=0.00025, test_MAE=0.631, time=129, train_MAE=0.569, train_loss=0.602, val_MAE=0.589, val_loss=0.622]Epoch 33:   3%|▎         | 34/1000 [1:17:28<35:14:53, 131.36s/it, lr=0.00025, test_MAE=0.631, time=129, train_MAE=0.569, train_loss=0.602, val_MAE=0.589, val_loss=0.622]Epoch 34:   3%|▎         | 34/1000 [1:17:28<35:14:53, 131.36s/it, lr=0.00025, test_MAE=0.631, time=129, train_MAE=0.569, train_loss=0.602, val_MAE=0.589, val_loss=0.622]Epoch 34:   3%|▎         | 34/1000 [1:19:37<35:14:53, 131.36s/it, lr=0.00025, test_MAE=0.636, time=129, train_MAE=0.563, train_loss=0.597, val_MAE=0.579, val_loss=0.613]Epoch 34:   4%|▎         | 35/1000 [1:19:37<35:02:03, 130.70s/it, lr=0.00025, test_MAE=0.636, time=129, train_MAE=0.563, train_loss=0.597, val_MAE=0.579, val_loss=0.613]Epoch 35:   4%|▎         | 35/1000 [1:19:37<35:02:03, 130.70s/it, lr=0.00025, test_MAE=0.636, time=129, train_MAE=0.563, train_loss=0.597, val_MAE=0.579, val_loss=0.613]Epoch 35:   4%|▎         | 35/1000 [1:21:46<35:02:03, 130.70s/it, lr=0.00025, test_MAE=0.642, time=129, train_MAE=0.576, train_loss=0.609, val_MAE=0.598, val_loss=0.631]Epoch 35:   4%|▎         | 36/1000 [1:21:46<34:53:31, 130.30s/it, lr=0.00025, test_MAE=0.642, time=129, train_MAE=0.576, train_loss=0.609, val_MAE=0.598, val_loss=0.631]Epoch 36:   4%|▎         | 36/1000 [1:21:46<34:53:31, 130.30s/it, lr=0.00025, test_MAE=0.642, time=129, train_MAE=0.576, train_loss=0.609, val_MAE=0.598, val_loss=0.631]Epoch 36:   4%|▎         | 36/1000 [1:23:56<34:53:31, 130.30s/it, lr=0.00025, test_MAE=0.647, time=130, train_MAE=0.562, train_loss=0.595, val_MAE=0.603, val_loss=0.637]Epoch 36:   4%|▎         | 37/1000 [1:23:56<34:48:43, 130.14s/it, lr=0.00025, test_MAE=0.647, time=130, train_MAE=0.562, train_loss=0.595, val_MAE=0.603, val_loss=0.637]Epoch 37:   4%|▎         | 37/1000 [1:23:56<34:48:43, 130.14s/it, lr=0.00025, test_MAE=0.647, time=130, train_MAE=0.562, train_loss=0.595, val_MAE=0.603, val_loss=0.637]Epoch 37:   4%|▎         | 37/1000 [1:26:05<34:48:43, 130.14s/it, lr=0.00025, test_MAE=0.664, time=129, train_MAE=0.561, train_loss=0.594, val_MAE=0.623, val_loss=0.656]Epoch 37:   4%|▍         | 38/1000 [1:26:05<34:41:51, 129.85s/it, lr=0.00025, test_MAE=0.664, time=129, train_MAE=0.561, train_loss=0.594, val_MAE=0.623, val_loss=0.656]Epoch 38:   4%|▍         | 38/1000 [1:26:05<34:41:51, 129.85s/it, lr=0.00025, test_MAE=0.664, time=129, train_MAE=0.561, train_loss=0.594, val_MAE=0.623, val_loss=0.656]Epoch 38:   4%|▍         | 38/1000 [1:28:15<34:41:51, 129.85s/it, lr=0.00025, test_MAE=0.617, time=130, train_MAE=0.563, train_loss=0.597, val_MAE=0.574, val_loss=0.608]Epoch 38:   4%|▍         | 39/1000 [1:28:15<34:38:11, 129.75s/it, lr=0.00025, test_MAE=0.617, time=130, train_MAE=0.563, train_loss=0.597, val_MAE=0.574, val_loss=0.608]Epoch 39:   4%|▍         | 39/1000 [1:28:15<34:38:11, 129.75s/it, lr=0.00025, test_MAE=0.617, time=130, train_MAE=0.563, train_loss=0.597, val_MAE=0.574, val_loss=0.608]Epoch 39:   4%|▍         | 39/1000 [1:30:24<34:38:11, 129.75s/it, lr=0.00025, test_MAE=0.632, time=129, train_MAE=0.565, train_loss=0.598, val_MAE=0.596, val_loss=0.629]Epoch 39:   4%|▍         | 40/1000 [1:30:24<34:33:15, 129.58s/it, lr=0.00025, test_MAE=0.632, time=129, train_MAE=0.565, train_loss=0.598, val_MAE=0.596, val_loss=0.629]Epoch 40:   4%|▍         | 40/1000 [1:30:24<34:33:15, 129.58s/it, lr=0.00025, test_MAE=0.632, time=129, train_MAE=0.565, train_loss=0.598, val_MAE=0.596, val_loss=0.629]Epoch 40:   4%|▍         | 40/1000 [1:32:34<34:33:15, 129.58s/it, lr=0.00025, test_MAE=0.628, time=130, train_MAE=0.565, train_loss=0.599, val_MAE=0.595, val_loss=0.628]Epoch 40:   4%|▍         | 41/1000 [1:32:34<34:32:50, 129.69s/it, lr=0.00025, test_MAE=0.628, time=130, train_MAE=0.565, train_loss=0.599, val_MAE=0.595, val_loss=0.628]Epoch 41:   4%|▍         | 41/1000 [1:32:34<34:32:50, 129.69s/it, lr=0.00025, test_MAE=0.628, time=130, train_MAE=0.565, train_loss=0.599, val_MAE=0.595, val_loss=0.628]Epoch 41:   4%|▍         | 41/1000 [1:34:43<34:32:50, 129.69s/it, lr=0.00025, test_MAE=0.663, time=130, train_MAE=0.556, train_loss=0.589, val_MAE=0.62, val_loss=0.653] Epoch 41:   4%|▍         | 42/1000 [1:34:43<34:30:15, 129.66s/it, lr=0.00025, test_MAE=0.663, time=130, train_MAE=0.556, train_loss=0.589, val_MAE=0.62, val_loss=0.653]Epoch 42:   4%|▍         | 42/1000 [1:34:43<34:30:15, 129.66s/it, lr=0.00025, test_MAE=0.663, time=130, train_MAE=0.556, train_loss=0.589, val_MAE=0.62, val_loss=0.653]Epoch 42:   4%|▍         | 42/1000 [1:36:52<34:30:15, 129.66s/it, lr=0.00025, test_MAE=0.623, time=129, train_MAE=0.556, train_loss=0.59, val_MAE=0.587, val_loss=0.62] Epoch 42:   4%|▍         | 43/1000 [1:36:52<34:23:00, 129.34s/it, lr=0.00025, test_MAE=0.623, time=129, train_MAE=0.556, train_loss=0.59, val_MAE=0.587, val_loss=0.62]Epoch 43:   4%|▍         | 43/1000 [1:36:52<34:23:00, 129.34s/it, lr=0.00025, test_MAE=0.623, time=129, train_MAE=0.556, train_loss=0.59, val_MAE=0.587, val_loss=0.62]Epoch 43:   4%|▍         | 43/1000 [1:39:02<34:23:00, 129.34s/it, lr=0.00025, test_MAE=0.667, time=130, train_MAE=0.567, train_loss=0.601, val_MAE=0.631, val_loss=0.664]Epoch 43:   4%|▍         | 44/1000 [1:39:02<34:22:39, 129.46s/it, lr=0.00025, test_MAE=0.667, time=130, train_MAE=0.567, train_loss=0.601, val_MAE=0.631, val_loss=0.664]Epoch 44:   4%|▍         | 44/1000 [1:39:02<34:22:39, 129.46s/it, lr=0.00025, test_MAE=0.667, time=130, train_MAE=0.567, train_loss=0.601, val_MAE=0.631, val_loss=0.664]Epoch 44:   4%|▍         | 44/1000 [1:41:11<34:22:39, 129.46s/it, lr=0.00025, test_MAE=0.694, time=129, train_MAE=0.57, train_loss=0.603, val_MAE=0.621, val_loss=0.654] Epoch    45: reducing learning rate of group 0 to 1.2500e-04.
Epoch 44:   4%|▍         | 45/1000 [1:41:11<34:19:49, 129.41s/it, lr=0.00025, test_MAE=0.694, time=129, train_MAE=0.57, train_loss=0.603, val_MAE=0.621, val_loss=0.654]Epoch 45:   4%|▍         | 45/1000 [1:41:11<34:19:49, 129.41s/it, lr=0.00025, test_MAE=0.694, time=129, train_MAE=0.57, train_loss=0.603, val_MAE=0.621, val_loss=0.654]Epoch 45:   4%|▍         | 45/1000 [1:43:20<34:19:49, 129.41s/it, lr=0.000125, test_MAE=0.617, time=129, train_MAE=0.553, train_loss=0.587, val_MAE=0.583, val_loss=0.616]Epoch 45:   5%|▍         | 46/1000 [1:43:20<34:16:04, 129.31s/it, lr=0.000125, test_MAE=0.617, time=129, train_MAE=0.553, train_loss=0.587, val_MAE=0.583, val_loss=0.616]Epoch 46:   5%|▍         | 46/1000 [1:43:20<34:16:04, 129.31s/it, lr=0.000125, test_MAE=0.617, time=129, train_MAE=0.553, train_loss=0.587, val_MAE=0.583, val_loss=0.616]Epoch 46:   5%|▍         | 46/1000 [1:45:29<34:16:04, 129.31s/it, lr=0.000125, test_MAE=0.634, time=129, train_MAE=0.554, train_loss=0.588, val_MAE=0.586, val_loss=0.62] Epoch 46:   5%|▍         | 47/1000 [1:45:29<34:12:57, 129.25s/it, lr=0.000125, test_MAE=0.634, time=129, train_MAE=0.554, train_loss=0.588, val_MAE=0.586, val_loss=0.62]Epoch 47:   5%|▍         | 47/1000 [1:45:29<34:12:57, 129.25s/it, lr=0.000125, test_MAE=0.634, time=129, train_MAE=0.554, train_loss=0.588, val_MAE=0.586, val_loss=0.62]Epoch 47:   5%|▍         | 47/1000 [1:47:38<34:12:57, 129.25s/it, lr=0.000125, test_MAE=0.634, time=129, train_MAE=0.551, train_loss=0.584, val_MAE=0.578, val_loss=0.611]Epoch 47:   5%|▍         | 48/1000 [1:47:38<34:10:31, 129.24s/it, lr=0.000125, test_MAE=0.634, time=129, train_MAE=0.551, train_loss=0.584, val_MAE=0.578, val_loss=0.611]Epoch 48:   5%|▍         | 48/1000 [1:47:38<34:10:31, 129.24s/it, lr=0.000125, test_MAE=0.634, time=129, train_MAE=0.551, train_loss=0.584, val_MAE=0.578, val_loss=0.611]Epoch 48:   5%|▍         | 48/1000 [1:49:47<34:10:31, 129.24s/it, lr=0.000125, test_MAE=0.622, time=129, train_MAE=0.543, train_loss=0.576, val_MAE=0.583, val_loss=0.616]Epoch 48:   5%|▍         | 49/1000 [1:49:47<34:06:49, 129.14s/it, lr=0.000125, test_MAE=0.622, time=129, train_MAE=0.543, train_loss=0.576, val_MAE=0.583, val_loss=0.616]Epoch 49:   5%|▍         | 49/1000 [1:49:47<34:06:49, 129.14s/it, lr=0.000125, test_MAE=0.622, time=129, train_MAE=0.543, train_loss=0.576, val_MAE=0.583, val_loss=0.616]Epoch 49:   5%|▍         | 49/1000 [1:51:56<34:06:49, 129.14s/it, lr=0.000125, test_MAE=0.621, time=129, train_MAE=0.546, train_loss=0.579, val_MAE=0.585, val_loss=0.618]Epoch 49:   5%|▌         | 50/1000 [1:51:56<34:03:28, 129.06s/it, lr=0.000125, test_MAE=0.621, time=129, train_MAE=0.546, train_loss=0.579, val_MAE=0.585, val_loss=0.618]Epoch 50:   5%|▌         | 50/1000 [1:51:56<34:03:28, 129.06s/it, lr=0.000125, test_MAE=0.621, time=129, train_MAE=0.546, train_loss=0.579, val_MAE=0.585, val_loss=0.618]Epoch 50:   5%|▌         | 50/1000 [1:54:05<34:03:28, 129.06s/it, lr=0.000125, test_MAE=0.61, time=129, train_MAE=0.547, train_loss=0.58, val_MAE=0.575, val_loss=0.608]  Epoch    51: reducing learning rate of group 0 to 6.2500e-05.
Epoch 50:   5%|▌         | 51/1000 [1:54:05<34:02:22, 129.13s/it, lr=0.000125, test_MAE=0.61, time=129, train_MAE=0.547, train_loss=0.58, val_MAE=0.575, val_loss=0.608]Epoch 51:   5%|▌         | 51/1000 [1:54:05<34:02:22, 129.13s/it, lr=0.000125, test_MAE=0.61, time=129, train_MAE=0.547, train_loss=0.58, val_MAE=0.575, val_loss=0.608]Epoch 51:   5%|▌         | 51/1000 [1:56:15<34:02:22, 129.13s/it, lr=6.25e-5, test_MAE=0.61, time=129, train_MAE=0.543, train_loss=0.577, val_MAE=0.574, val_loss=0.607]Epoch 51:   5%|▌         | 52/1000 [1:56:15<34:00:40, 129.16s/it, lr=6.25e-5, test_MAE=0.61, time=129, train_MAE=0.543, train_loss=0.577, val_MAE=0.574, val_loss=0.607]Epoch 52:   5%|▌         | 52/1000 [1:56:15<34:00:40, 129.16s/it, lr=6.25e-5, test_MAE=0.61, time=129, train_MAE=0.543, train_loss=0.577, val_MAE=0.574, val_loss=0.607]Epoch 52:   5%|▌         | 52/1000 [1:58:24<34:00:40, 129.16s/it, lr=6.25e-5, test_MAE=0.607, time=129, train_MAE=0.537, train_loss=0.57, val_MAE=0.572, val_loss=0.605]Epoch 52:   5%|▌         | 53/1000 [1:58:24<33:58:26, 129.15s/it, lr=6.25e-5, test_MAE=0.607, time=129, train_MAE=0.537, train_loss=0.57, val_MAE=0.572, val_loss=0.605]Epoch 53:   5%|▌         | 53/1000 [1:58:24<33:58:26, 129.15s/it, lr=6.25e-5, test_MAE=0.607, time=129, train_MAE=0.537, train_loss=0.57, val_MAE=0.572, val_loss=0.605]Epoch 53:   5%|▌         | 53/1000 [2:00:33<33:58:26, 129.15s/it, lr=6.25e-5, test_MAE=0.616, time=129, train_MAE=0.538, train_loss=0.571, val_MAE=0.575, val_loss=0.608]Epoch 53:   5%|▌         | 54/1000 [2:00:33<33:55:30, 129.10s/it, lr=6.25e-5, test_MAE=0.616, time=129, train_MAE=0.538, train_loss=0.571, val_MAE=0.575, val_loss=0.608]Epoch 54:   5%|▌         | 54/1000 [2:00:33<33:55:30, 129.10s/it, lr=6.25e-5, test_MAE=0.616, time=129, train_MAE=0.538, train_loss=0.571, val_MAE=0.575, val_loss=0.608]Epoch 54:   5%|▌         | 54/1000 [2:02:46<33:55:30, 129.10s/it, lr=6.25e-5, test_MAE=0.618, time=134, train_MAE=0.537, train_loss=0.57, val_MAE=0.572, val_loss=0.605] Epoch 54:   6%|▌         | 55/1000 [2:02:46<34:14:20, 130.43s/it, lr=6.25e-5, test_MAE=0.618, time=134, train_MAE=0.537, train_loss=0.57, val_MAE=0.572, val_loss=0.605]Epoch 55:   6%|▌         | 55/1000 [2:02:46<34:14:20, 130.43s/it, lr=6.25e-5, test_MAE=0.618, time=134, train_MAE=0.537, train_loss=0.57, val_MAE=0.572, val_loss=0.605]Epoch 55:   6%|▌         | 55/1000 [2:05:00<34:14:20, 130.43s/it, lr=6.25e-5, test_MAE=0.618, time=133, train_MAE=0.536, train_loss=0.568, val_MAE=0.574, val_loss=0.607]Epoch 55:   6%|▌         | 56/1000 [2:05:00<34:26:20, 131.34s/it, lr=6.25e-5, test_MAE=0.618, time=133, train_MAE=0.536, train_loss=0.568, val_MAE=0.574, val_loss=0.607]Epoch 56:   6%|▌         | 56/1000 [2:05:00<34:26:20, 131.34s/it, lr=6.25e-5, test_MAE=0.618, time=133, train_MAE=0.536, train_loss=0.568, val_MAE=0.574, val_loss=0.607]Epoch 56:   6%|▌         | 56/1000 [2:07:17<34:26:20, 131.34s/it, lr=6.25e-5, test_MAE=0.609, time=137, train_MAE=0.533, train_loss=0.566, val_MAE=0.575, val_loss=0.608]Epoch 56:   6%|▌         | 57/1000 [2:07:17<34:50:42, 133.03s/it, lr=6.25e-5, test_MAE=0.609, time=137, train_MAE=0.533, train_loss=0.566, val_MAE=0.575, val_loss=0.608]Epoch 57:   6%|▌         | 57/1000 [2:07:17<34:50:42, 133.03s/it, lr=6.25e-5, test_MAE=0.609, time=137, train_MAE=0.533, train_loss=0.566, val_MAE=0.575, val_loss=0.608]Epoch 57:   6%|▌         | 57/1000 [2:09:33<34:50:42, 133.03s/it, lr=6.25e-5, test_MAE=0.609, time=136, train_MAE=0.531, train_loss=0.564, val_MAE=0.567, val_loss=0.6]  Epoch 57:   6%|▌         | 58/1000 [2:09:33<35:02:27, 133.91s/it, lr=6.25e-5, test_MAE=0.609, time=136, train_MAE=0.531, train_loss=0.564, val_MAE=0.567, val_loss=0.6]Epoch 58:   6%|▌         | 58/1000 [2:09:33<35:02:27, 133.91s/it, lr=6.25e-5, test_MAE=0.609, time=136, train_MAE=0.531, train_loss=0.564, val_MAE=0.567, val_loss=0.6]Epoch 58:   6%|▌         | 58/1000 [2:11:45<35:02:27, 133.91s/it, lr=6.25e-5, test_MAE=0.641, time=132, train_MAE=0.533, train_loss=0.566, val_MAE=0.587, val_loss=0.62]Epoch 58:   6%|▌         | 59/1000 [2:11:45<34:53:23, 133.48s/it, lr=6.25e-5, test_MAE=0.641, time=132, train_MAE=0.533, train_loss=0.566, val_MAE=0.587, val_loss=0.62]Epoch 59:   6%|▌         | 59/1000 [2:11:45<34:53:23, 133.48s/it, lr=6.25e-5, test_MAE=0.641, time=132, train_MAE=0.533, train_loss=0.566, val_MAE=0.587, val_loss=0.62]Epoch 59:   6%|▌         | 59/1000 [2:13:57<34:53:23, 133.48s/it, lr=6.25e-5, test_MAE=0.613, time=132, train_MAE=0.535, train_loss=0.568, val_MAE=0.576, val_loss=0.609]Epoch 59:   6%|▌         | 60/1000 [2:13:57<34:46:03, 133.15s/it, lr=6.25e-5, test_MAE=0.613, time=132, train_MAE=0.535, train_loss=0.568, val_MAE=0.576, val_loss=0.609]Epoch 60:   6%|▌         | 60/1000 [2:13:57<34:46:03, 133.15s/it, lr=6.25e-5, test_MAE=0.613, time=132, train_MAE=0.535, train_loss=0.568, val_MAE=0.576, val_loss=0.609]Epoch 60:   6%|▌         | 60/1000 [2:16:09<34:46:03, 133.15s/it, lr=6.25e-5, test_MAE=0.607, time=132, train_MAE=0.538, train_loss=0.571, val_MAE=0.577, val_loss=0.61] Epoch 60:   6%|▌         | 61/1000 [2:16:09<34:36:36, 132.69s/it, lr=6.25e-5, test_MAE=0.607, time=132, train_MAE=0.538, train_loss=0.571, val_MAE=0.577, val_loss=0.61]Epoch 61:   6%|▌         | 61/1000 [2:16:09<34:36:36, 132.69s/it, lr=6.25e-5, test_MAE=0.607, time=132, train_MAE=0.538, train_loss=0.571, val_MAE=0.577, val_loss=0.61]Epoch 61:   6%|▌         | 61/1000 [2:18:21<34:36:36, 132.69s/it, lr=6.25e-5, test_MAE=0.614, time=132, train_MAE=0.533, train_loss=0.565, val_MAE=0.583, val_loss=0.616]Epoch 61:   6%|▌         | 62/1000 [2:18:21<34:30:37, 132.45s/it, lr=6.25e-5, test_MAE=0.614, time=132, train_MAE=0.533, train_loss=0.565, val_MAE=0.583, val_loss=0.616]Epoch 62:   6%|▌         | 62/1000 [2:18:21<34:30:37, 132.45s/it, lr=6.25e-5, test_MAE=0.614, time=132, train_MAE=0.533, train_loss=0.565, val_MAE=0.583, val_loss=0.616]Epoch 62:   6%|▌         | 62/1000 [2:20:32<34:30:37, 132.45s/it, lr=6.25e-5, test_MAE=0.614, time=131, train_MAE=0.535, train_loss=0.568, val_MAE=0.609, val_loss=0.642]Epoch 62:   6%|▋         | 63/1000 [2:20:32<34:23:35, 132.14s/it, lr=6.25e-5, test_MAE=0.614, time=131, train_MAE=0.535, train_loss=0.568, val_MAE=0.609, val_loss=0.642]Epoch 63:   6%|▋         | 63/1000 [2:20:32<34:23:35, 132.14s/it, lr=6.25e-5, test_MAE=0.614, time=131, train_MAE=0.535, train_loss=0.568, val_MAE=0.609, val_loss=0.642]Epoch 63:   6%|▋         | 63/1000 [2:22:44<34:23:35, 132.14s/it, lr=6.25e-5, test_MAE=0.624, time=132, train_MAE=0.54, train_loss=0.573, val_MAE=0.589, val_loss=0.621] Epoch    64: reducing learning rate of group 0 to 3.1250e-05.
Epoch 63:   6%|▋         | 64/1000 [2:22:44<34:19:02, 131.99s/it, lr=6.25e-5, test_MAE=0.624, time=132, train_MAE=0.54, train_loss=0.573, val_MAE=0.589, val_loss=0.621]Epoch 64:   6%|▋         | 64/1000 [2:22:44<34:19:02, 131.99s/it, lr=6.25e-5, test_MAE=0.624, time=132, train_MAE=0.54, train_loss=0.573, val_MAE=0.589, val_loss=0.621]Epoch 64:   6%|▋         | 64/1000 [2:24:57<34:19:02, 131.99s/it, lr=3.13e-5, test_MAE=0.613, time=133, train_MAE=0.53, train_loss=0.562, val_MAE=0.575, val_loss=0.608]Epoch 64:   6%|▋         | 65/1000 [2:24:57<34:19:42, 132.17s/it, lr=3.13e-5, test_MAE=0.613, time=133, train_MAE=0.53, train_loss=0.562, val_MAE=0.575, val_loss=0.608]Epoch 65:   6%|▋         | 65/1000 [2:24:57<34:19:42, 132.17s/it, lr=3.13e-5, test_MAE=0.613, time=133, train_MAE=0.53, train_loss=0.562, val_MAE=0.575, val_loss=0.608]Epoch 65:   6%|▋         | 65/1000 [2:27:09<34:19:42, 132.17s/it, lr=3.13e-5, test_MAE=0.611, time=132, train_MAE=0.529, train_loss=0.561, val_MAE=0.575, val_loss=0.607]Epoch 65:   7%|▋         | 66/1000 [2:27:09<34:17:39, 132.18s/it, lr=3.13e-5, test_MAE=0.611, time=132, train_MAE=0.529, train_loss=0.561, val_MAE=0.575, val_loss=0.607]Epoch 66:   7%|▋         | 66/1000 [2:27:09<34:17:39, 132.18s/it, lr=3.13e-5, test_MAE=0.611, time=132, train_MAE=0.529, train_loss=0.561, val_MAE=0.575, val_loss=0.607]Epoch 66:   7%|▋         | 66/1000 [2:29:18<34:17:39, 132.18s/it, lr=3.13e-5, test_MAE=0.609, time=129, train_MAE=0.524, train_loss=0.557, val_MAE=0.576, val_loss=0.608]Epoch 66:   7%|▋         | 67/1000 [2:29:18<34:01:08, 131.26s/it, lr=3.13e-5, test_MAE=0.609, time=129, train_MAE=0.524, train_loss=0.557, val_MAE=0.576, val_loss=0.608]Epoch 67:   7%|▋         | 67/1000 [2:29:18<34:01:08, 131.26s/it, lr=3.13e-5, test_MAE=0.609, time=129, train_MAE=0.524, train_loss=0.557, val_MAE=0.576, val_loss=0.608]Epoch 67:   7%|▋         | 67/1000 [2:31:24<34:01:08, 131.26s/it, lr=3.13e-5, test_MAE=0.607, time=126, train_MAE=0.528, train_loss=0.561, val_MAE=0.576, val_loss=0.609]Epoch 67:   7%|▋         | 68/1000 [2:31:24<33:34:29, 129.69s/it, lr=3.13e-5, test_MAE=0.607, time=126, train_MAE=0.528, train_loss=0.561, val_MAE=0.576, val_loss=0.609]Epoch 68:   7%|▋         | 68/1000 [2:31:24<33:34:29, 129.69s/it, lr=3.13e-5, test_MAE=0.607, time=126, train_MAE=0.528, train_loss=0.561, val_MAE=0.576, val_loss=0.609]Epoch 68:   7%|▋         | 68/1000 [2:33:30<33:34:29, 129.69s/it, lr=3.13e-5, test_MAE=0.607, time=126, train_MAE=0.525, train_loss=0.558, val_MAE=0.571, val_loss=0.604]Epoch 68:   7%|▋         | 69/1000 [2:33:30<33:16:33, 128.67s/it, lr=3.13e-5, test_MAE=0.607, time=126, train_MAE=0.525, train_loss=0.558, val_MAE=0.571, val_loss=0.604]Epoch 69:   7%|▋         | 69/1000 [2:33:30<33:16:33, 128.67s/it, lr=3.13e-5, test_MAE=0.607, time=126, train_MAE=0.525, train_loss=0.558, val_MAE=0.571, val_loss=0.604]Epoch 69:   7%|▋         | 69/1000 [2:35:36<33:16:33, 128.67s/it, lr=3.13e-5, test_MAE=0.611, time=126, train_MAE=0.526, train_loss=0.558, val_MAE=0.575, val_loss=0.608]Epoch    70: reducing learning rate of group 0 to 1.5625e-05.
Epoch 69:   7%|▋         | 70/1000 [2:35:36<33:02:03, 127.87s/it, lr=3.13e-5, test_MAE=0.611, time=126, train_MAE=0.526, train_loss=0.558, val_MAE=0.575, val_loss=0.608]Epoch 70:   7%|▋         | 70/1000 [2:35:36<33:02:03, 127.87s/it, lr=3.13e-5, test_MAE=0.611, time=126, train_MAE=0.526, train_loss=0.558, val_MAE=0.575, val_loss=0.608]Epoch 70:   7%|▋         | 70/1000 [2:37:42<33:02:03, 127.87s/it, lr=1.56e-5, test_MAE=0.608, time=126, train_MAE=0.526, train_loss=0.558, val_MAE=0.572, val_loss=0.605]Epoch 70:   7%|▋         | 71/1000 [2:37:42<32:49:28, 127.20s/it, lr=1.56e-5, test_MAE=0.608, time=126, train_MAE=0.526, train_loss=0.558, val_MAE=0.572, val_loss=0.605]Epoch 71:   7%|▋         | 71/1000 [2:37:42<32:49:28, 127.20s/it, lr=1.56e-5, test_MAE=0.608, time=126, train_MAE=0.526, train_loss=0.558, val_MAE=0.572, val_loss=0.605]Epoch 71:   7%|▋         | 71/1000 [2:39:48<32:49:28, 127.20s/it, lr=1.56e-5, test_MAE=0.612, time=126, train_MAE=0.521, train_loss=0.553, val_MAE=0.578, val_loss=0.61] Epoch 71:   7%|▋         | 72/1000 [2:39:48<32:42:19, 126.87s/it, lr=1.56e-5, test_MAE=0.612, time=126, train_MAE=0.521, train_loss=0.553, val_MAE=0.578, val_loss=0.61]Epoch 72:   7%|▋         | 72/1000 [2:39:48<32:42:19, 126.87s/it, lr=1.56e-5, test_MAE=0.612, time=126, train_MAE=0.521, train_loss=0.553, val_MAE=0.578, val_loss=0.61]Epoch 72:   7%|▋         | 72/1000 [2:41:54<32:42:19, 126.87s/it, lr=1.56e-5, test_MAE=0.612, time=126, train_MAE=0.522, train_loss=0.554, val_MAE=0.569, val_loss=0.602]Epoch 72:   7%|▋         | 73/1000 [2:41:54<32:35:13, 126.55s/it, lr=1.56e-5, test_MAE=0.612, time=126, train_MAE=0.522, train_loss=0.554, val_MAE=0.569, val_loss=0.602]Epoch 73:   7%|▋         | 73/1000 [2:41:54<32:35:13, 126.55s/it, lr=1.56e-5, test_MAE=0.612, time=126, train_MAE=0.522, train_loss=0.554, val_MAE=0.569, val_loss=0.602]Epoch 73:   7%|▋         | 73/1000 [2:44:00<32:35:13, 126.55s/it, lr=1.56e-5, test_MAE=0.641, time=126, train_MAE=0.521, train_loss=0.554, val_MAE=0.575, val_loss=0.608]Epoch 73:   7%|▋         | 74/1000 [2:44:00<32:29:24, 126.31s/it, lr=1.56e-5, test_MAE=0.641, time=126, train_MAE=0.521, train_loss=0.554, val_MAE=0.575, val_loss=0.608]Epoch 74:   7%|▋         | 74/1000 [2:44:00<32:29:24, 126.31s/it, lr=1.56e-5, test_MAE=0.641, time=126, train_MAE=0.521, train_loss=0.554, val_MAE=0.575, val_loss=0.608]Epoch 74:   7%|▋         | 74/1000 [2:46:05<32:29:24, 126.31s/it, lr=1.56e-5, test_MAE=0.607, time=126, train_MAE=0.519, train_loss=0.552, val_MAE=0.572, val_loss=0.605]Epoch 74:   8%|▊         | 75/1000 [2:46:05<32:23:53, 126.09s/it, lr=1.56e-5, test_MAE=0.607, time=126, train_MAE=0.519, train_loss=0.552, val_MAE=0.572, val_loss=0.605]Epoch 75:   8%|▊         | 75/1000 [2:46:05<32:23:53, 126.09s/it, lr=1.56e-5, test_MAE=0.607, time=126, train_MAE=0.519, train_loss=0.552, val_MAE=0.572, val_loss=0.605]Epoch 75:   8%|▊         | 75/1000 [2:48:12<32:23:53, 126.09s/it, lr=1.56e-5, test_MAE=0.603, time=127, train_MAE=0.527, train_loss=0.56, val_MAE=0.576, val_loss=0.608] Epoch    76: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 75:   8%|▊         | 75/1000 [2:48:12<34:34:35, 134.57s/it, lr=1.56e-5, test_MAE=0.603, time=127, train_MAE=0.527, train_loss=0.56, val_MAE=0.576, val_loss=0.608]
Test MAE: 0.6031
Train MAE: 0.5180
Convergence Time (Epochs): 75.0000
TOTAL TIME TAKEN: 10145.6143s
AVG TIME PER EPOCH: 132.7806s
