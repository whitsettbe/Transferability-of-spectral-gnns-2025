I'm echoing to stdout
I'm echoing to stderr
My JobID is 57072305
I have 8 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.1847s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 4, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'rational_vec', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_all', 'num_eigs': 64, 'bias_mode': 'spatial', 'eigval_hidden_dim': 5, 'eigval_num_hidden_layer': 3, 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 0.05, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/zinc_train_rec_full.csv', 'test': 'supp_data/molecules/zinc_test_rec_full.csv', 'val': 'supp_data/molecules/zinc_val_rec_full.csv'}, 'fixMissingPhi1': True, 'extraOrtho': False, 'doublePrecision': True, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [09:50<?, ?it/s, lr=0.001, test_MAE=1.45, time=590, train_MAE=1.26, train_loss=1.27, val_MAE=1.35, val_loss=1.35]Epoch 0:   0%|          | 1/1000 [09:50<163:47:14, 590.23s/it, lr=0.001, test_MAE=1.45, time=590, train_MAE=1.26, train_loss=1.27, val_MAE=1.35, val_loss=1.35]Epoch 1:   0%|          | 1/1000 [09:50<163:47:14, 590.23s/it, lr=0.001, test_MAE=1.45, time=590, train_MAE=1.26, train_loss=1.27, val_MAE=1.35, val_loss=1.35]Epoch 1:   0%|          | 1/1000 [19:19<163:47:14, 590.23s/it, lr=0.001, test_MAE=1.18, time=569, train_MAE=0.879, train_loss=0.881, val_MAE=1.1, val_loss=1.1]Epoch 1:   0%|          | 2/1000 [19:19<161:50:42, 583.81s/it, lr=0.001, test_MAE=1.18, time=569, train_MAE=0.879, train_loss=0.881, val_MAE=1.1, val_loss=1.1]Epoch 2:   0%|          | 2/1000 [19:19<161:50:42, 583.81s/it, lr=0.001, test_MAE=1.18, time=569, train_MAE=0.879, train_loss=0.881, val_MAE=1.1, val_loss=1.1]Epoch 2:   0%|          | 2/1000 [28:48<161:50:42, 583.81s/it, lr=0.001, test_MAE=2.36, time=569, train_MAE=0.732, train_loss=0.734, val_MAE=2.15, val_loss=2.15]Epoch 2:   0%|          | 3/1000 [28:48<160:29:05, 579.48s/it, lr=0.001, test_MAE=2.36, time=569, train_MAE=0.732, train_loss=0.734, val_MAE=2.15, val_loss=2.15]Epoch 3:   0%|          | 3/1000 [28:48<160:29:05, 579.48s/it, lr=0.001, test_MAE=2.36, time=569, train_MAE=0.732, train_loss=0.734, val_MAE=2.15, val_loss=2.15]Epoch 3:   0%|          | 3/1000 [38:18<160:29:05, 579.48s/it, lr=0.001, test_MAE=1.07, time=570, train_MAE=0.685, train_loss=0.687, val_MAE=1.04, val_loss=1.04]Epoch 3:   0%|          | 4/1000 [38:18<159:32:33, 576.66s/it, lr=0.001, test_MAE=1.07, time=570, train_MAE=0.685, train_loss=0.687, val_MAE=1.04, val_loss=1.04]Epoch 4:   0%|          | 4/1000 [38:18<159:32:33, 576.66s/it, lr=0.001, test_MAE=1.07, time=570, train_MAE=0.685, train_loss=0.687, val_MAE=1.04, val_loss=1.04]Epoch 4:   0%|          | 4/1000 [47:50<159:32:33, 576.66s/it, lr=0.001, test_MAE=0.803, time=572, train_MAE=0.668, train_loss=0.67, val_MAE=0.735, val_loss=0.737]Epoch 4:   0%|          | 5/1000 [47:50<158:59:12, 575.23s/it, lr=0.001, test_MAE=0.803, time=572, train_MAE=0.668, train_loss=0.67, val_MAE=0.735, val_loss=0.737]Epoch 5:   0%|          | 5/1000 [47:50<158:59:12, 575.23s/it, lr=0.001, test_MAE=0.803, time=572, train_MAE=0.668, train_loss=0.67, val_MAE=0.735, val_loss=0.737]Epoch 5:   0%|          | 5/1000 [57:21<158:59:12, 575.23s/it, lr=0.001, test_MAE=0.967, time=571, train_MAE=0.661, train_loss=0.663, val_MAE=0.832, val_loss=0.834]Epoch 5:   1%|          | 6/1000 [57:21<158:28:37, 573.96s/it, lr=0.001, test_MAE=0.967, time=571, train_MAE=0.661, train_loss=0.663, val_MAE=0.832, val_loss=0.834]Epoch 6:   1%|          | 6/1000 [57:21<158:28:37, 573.96s/it, lr=0.001, test_MAE=0.967, time=571, train_MAE=0.661, train_loss=0.663, val_MAE=0.832, val_loss=0.834]Epoch 6:   1%|          | 6/1000 [1:06:50<158:28:37, 573.96s/it, lr=0.001, test_MAE=0.749, time=570, train_MAE=0.641, train_loss=0.644, val_MAE=0.684, val_loss=0.686]Epoch 6:   1%|          | 7/1000 [1:06:50<157:57:10, 572.64s/it, lr=0.001, test_MAE=0.749, time=570, train_MAE=0.641, train_loss=0.644, val_MAE=0.684, val_loss=0.686]Epoch 7:   1%|          | 7/1000 [1:06:50<157:57:10, 572.64s/it, lr=0.001, test_MAE=0.749, time=570, train_MAE=0.641, train_loss=0.644, val_MAE=0.684, val_loss=0.686]Epoch 7:   1%|          | 7/1000 [1:16:21<157:57:10, 572.64s/it, lr=0.001, test_MAE=0.726, time=570, train_MAE=0.636, train_loss=0.639, val_MAE=0.672, val_loss=0.675]Epoch 7:   1%|          | 8/1000 [1:16:21<157:35:47, 571.92s/it, lr=0.001, test_MAE=0.726, time=570, train_MAE=0.636, train_loss=0.639, val_MAE=0.672, val_loss=0.675]Epoch 8:   1%|          | 8/1000 [1:16:21<157:35:47, 571.92s/it, lr=0.001, test_MAE=0.726, time=570, train_MAE=0.636, train_loss=0.639, val_MAE=0.672, val_loss=0.675]Epoch 8:   1%|          | 8/1000 [1:25:52<157:35:47, 571.92s/it, lr=0.001, test_MAE=1.06, time=572, train_MAE=0.631, train_loss=0.634, val_MAE=1.02, val_loss=1.02]   Epoch 8:   1%|          | 9/1000 [1:25:52<157:25:06, 571.85s/it, lr=0.001, test_MAE=1.06, time=572, train_MAE=0.631, train_loss=0.634, val_MAE=1.02, val_loss=1.02]Epoch 9:   1%|          | 9/1000 [1:25:52<157:25:06, 571.85s/it, lr=0.001, test_MAE=1.06, time=572, train_MAE=0.631, train_loss=0.634, val_MAE=1.02, val_loss=1.02]Epoch 9:   1%|          | 9/1000 [1:34:45<157:25:06, 571.85s/it, lr=0.001, test_MAE=2.56, time=533, train_MAE=0.619, train_loss=0.621, val_MAE=2.53, val_loss=2.54]Epoch 9:   1%|          | 10/1000 [1:34:45<154:01:47, 560.11s/it, lr=0.001, test_MAE=2.56, time=533, train_MAE=0.619, train_loss=0.621, val_MAE=2.53, val_loss=2.54]Epoch 10:   1%|          | 10/1000 [1:34:45<154:01:47, 560.11s/it, lr=0.001, test_MAE=2.56, time=533, train_MAE=0.619, train_loss=0.621, val_MAE=2.53, val_loss=2.54]Epoch 10:   1%|          | 10/1000 [1:43:14<154:01:47, 560.11s/it, lr=0.001, test_MAE=0.733, time=509, train_MAE=0.607, train_loss=0.609, val_MAE=0.663, val_loss=0.665]Epoch 10:   1%|          | 11/1000 [1:43:14<149:40:49, 544.84s/it, lr=0.001, test_MAE=0.733, time=509, train_MAE=0.607, train_loss=0.609, val_MAE=0.663, val_loss=0.665]Epoch 11:   1%|          | 11/1000 [1:43:14<149:40:49, 544.84s/it, lr=0.001, test_MAE=0.733, time=509, train_MAE=0.607, train_loss=0.609, val_MAE=0.663, val_loss=0.665]Epoch 11:   1%|          | 11/1000 [1:51:43<149:40:49, 544.84s/it, lr=0.001, test_MAE=0.792, time=508, train_MAE=0.603, train_loss=0.605, val_MAE=0.752, val_loss=0.755]Epoch 11:   1%|          | 12/1000 [1:51:43<146:31:49, 533.92s/it, lr=0.001, test_MAE=0.792, time=508, train_MAE=0.603, train_loss=0.605, val_MAE=0.752, val_loss=0.755]Epoch 12:   1%|          | 12/1000 [1:51:43<146:31:49, 533.92s/it, lr=0.001, test_MAE=0.792, time=508, train_MAE=0.603, train_loss=0.605, val_MAE=0.752, val_loss=0.755]Epoch 12:   1%|          | 12/1000 [2:00:19<146:31:49, 533.92s/it, lr=0.001, test_MAE=0.743, time=516, train_MAE=0.605, train_loss=0.608, val_MAE=0.681, val_loss=0.683]Epoch 12:   1%|▏         | 13/1000 [2:00:19<144:54:14, 528.53s/it, lr=0.001, test_MAE=0.743, time=516, train_MAE=0.605, train_loss=0.608, val_MAE=0.681, val_loss=0.683]Epoch 13:   1%|▏         | 13/1000 [2:00:19<144:54:14, 528.53s/it, lr=0.001, test_MAE=0.743, time=516, train_MAE=0.605, train_loss=0.608, val_MAE=0.681, val_loss=0.683]Epoch 13:   1%|▏         | 13/1000 [2:09:10<144:54:14, 528.53s/it, lr=0.001, test_MAE=0.75, time=531, train_MAE=0.602, train_loss=0.604, val_MAE=0.711, val_loss=0.714] Epoch 13:   1%|▏         | 14/1000 [2:09:10<144:58:56, 529.35s/it, lr=0.001, test_MAE=0.75, time=531, train_MAE=0.602, train_loss=0.604, val_MAE=0.711, val_loss=0.714]Epoch 14:   1%|▏         | 14/1000 [2:09:10<144:58:56, 529.35s/it, lr=0.001, test_MAE=0.75, time=531, train_MAE=0.602, train_loss=0.604, val_MAE=0.711, val_loss=0.714]Epoch 14:   1%|▏         | 14/1000 [2:17:58<144:58:56, 529.35s/it, lr=0.001, test_MAE=0.668, time=528, train_MAE=0.59, train_loss=0.592, val_MAE=0.625, val_loss=0.627]Epoch 14:   2%|▏         | 15/1000 [2:17:58<144:44:09, 528.98s/it, lr=0.001, test_MAE=0.668, time=528, train_MAE=0.59, train_loss=0.592, val_MAE=0.625, val_loss=0.627]Epoch 15:   2%|▏         | 15/1000 [2:17:58<144:44:09, 528.98s/it, lr=0.001, test_MAE=0.668, time=528, train_MAE=0.59, train_loss=0.592, val_MAE=0.625, val_loss=0.627]Epoch 15:   2%|▏         | 15/1000 [2:26:46<144:44:09, 528.98s/it, lr=0.001, test_MAE=1.01, time=528, train_MAE=0.588, train_loss=0.59, val_MAE=0.963, val_loss=0.965] Epoch 15:   2%|▏         | 16/1000 [2:26:46<144:29:11, 528.61s/it, lr=0.001, test_MAE=1.01, time=528, train_MAE=0.588, train_loss=0.59, val_MAE=0.963, val_loss=0.965]Epoch 16:   2%|▏         | 16/1000 [2:26:46<144:29:11, 528.61s/it, lr=0.001, test_MAE=1.01, time=528, train_MAE=0.588, train_loss=0.59, val_MAE=0.963, val_loss=0.965]Epoch 16:   2%|▏         | 16/1000 [2:35:47<144:29:11, 528.61s/it, lr=0.001, test_MAE=0.71, time=541, train_MAE=0.596, train_loss=0.599, val_MAE=0.655, val_loss=0.657]Epoch 16:   2%|▏         | 17/1000 [2:35:47<145:21:14, 532.32s/it, lr=0.001, test_MAE=0.71, time=541, train_MAE=0.596, train_loss=0.599, val_MAE=0.655, val_loss=0.657]Epoch 17:   2%|▏         | 17/1000 [2:35:47<145:21:14, 532.32s/it, lr=0.001, test_MAE=0.71, time=541, train_MAE=0.596, train_loss=0.599, val_MAE=0.655, val_loss=0.657]Epoch 17:   2%|▏         | 17/1000 [2:44:50<145:21:14, 532.32s/it, lr=0.001, test_MAE=0.676, time=543, train_MAE=0.587, train_loss=0.589, val_MAE=0.624, val_loss=0.627]Epoch 17:   2%|▏         | 18/1000 [2:44:50<146:05:22, 535.56s/it, lr=0.001, test_MAE=0.676, time=543, train_MAE=0.587, train_loss=0.589, val_MAE=0.624, val_loss=0.627]Epoch 18:   2%|▏         | 18/1000 [2:44:50<146:05:22, 535.56s/it, lr=0.001, test_MAE=0.676, time=543, train_MAE=0.587, train_loss=0.589, val_MAE=0.624, val_loss=0.627]Epoch 18:   2%|▏         | 18/1000 [2:53:33<146:05:22, 535.56s/it, lr=0.001, test_MAE=0.669, time=523, train_MAE=0.588, train_loss=0.59, val_MAE=0.598, val_loss=0.6]   Epoch 18:   2%|▏         | 19/1000 [2:53:33<144:54:06, 531.75s/it, lr=0.001, test_MAE=0.669, time=523, train_MAE=0.588, train_loss=0.59, val_MAE=0.598, val_loss=0.6]Epoch 19:   2%|▏         | 19/1000 [2:53:33<144:54:06, 531.75s/it, lr=0.001, test_MAE=0.669, time=523, train_MAE=0.588, train_loss=0.59, val_MAE=0.598, val_loss=0.6]Epoch 19:   2%|▏         | 19/1000 [3:02:32<144:54:06, 531.75s/it, lr=0.001, test_MAE=0.661, time=539, train_MAE=0.579, train_loss=0.581, val_MAE=0.626, val_loss=0.629]Epoch 19:   2%|▏         | 20/1000 [3:02:32<145:20:54, 533.93s/it, lr=0.001, test_MAE=0.661, time=539, train_MAE=0.579, train_loss=0.581, val_MAE=0.626, val_loss=0.629]Epoch 20:   2%|▏         | 20/1000 [3:02:32<145:20:54, 533.93s/it, lr=0.001, test_MAE=0.661, time=539, train_MAE=0.579, train_loss=0.581, val_MAE=0.626, val_loss=0.629]Epoch 20:   2%|▏         | 20/1000 [3:11:40<145:20:54, 533.93s/it, lr=0.001, test_MAE=0.705, time=548, train_MAE=0.57, train_loss=0.572, val_MAE=0.648, val_loss=0.65]  Epoch 20:   2%|▏         | 21/1000 [3:11:40<146:20:37, 538.14s/it, lr=0.001, test_MAE=0.705, time=548, train_MAE=0.57, train_loss=0.572, val_MAE=0.648, val_loss=0.65]Epoch 21:   2%|▏         | 21/1000 [3:11:40<146:20:37, 538.14s/it, lr=0.001, test_MAE=0.705, time=548, train_MAE=0.57, train_loss=0.572, val_MAE=0.648, val_loss=0.65]Epoch 21:   2%|▏         | 21/1000 [3:20:44<146:20:37, 538.14s/it, lr=0.001, test_MAE=0.629, time=544, train_MAE=0.577, train_loss=0.579, val_MAE=0.588, val_loss=0.59]Epoch 21:   2%|▏         | 22/1000 [3:20:44<146:39:25, 539.84s/it, lr=0.001, test_MAE=0.629, time=544, train_MAE=0.577, train_loss=0.579, val_MAE=0.588, val_loss=0.59]Epoch 22:   2%|▏         | 22/1000 [3:20:44<146:39:25, 539.84s/it, lr=0.001, test_MAE=0.629, time=544, train_MAE=0.577, train_loss=0.579, val_MAE=0.588, val_loss=0.59]Epoch 22:   2%|▏         | 22/1000 [3:29:39<146:39:25, 539.84s/it, lr=0.001, test_MAE=0.909, time=536, train_MAE=0.57, train_loss=0.573, val_MAE=0.843, val_loss=0.845]Epoch 22:   2%|▏         | 23/1000 [3:29:39<146:10:32, 538.62s/it, lr=0.001, test_MAE=0.909, time=536, train_MAE=0.57, train_loss=0.573, val_MAE=0.843, val_loss=0.845]Epoch 23:   2%|▏         | 23/1000 [3:29:39<146:10:32, 538.62s/it, lr=0.001, test_MAE=0.909, time=536, train_MAE=0.57, train_loss=0.573, val_MAE=0.843, val_loss=0.845]Epoch 23:   2%|▏         | 23/1000 [3:38:04<146:10:32, 538.62s/it, lr=0.001, test_MAE=0.68, time=505, train_MAE=0.58, train_loss=0.582, val_MAE=0.631, val_loss=0.633] Epoch 23:   2%|▏         | 24/1000 [3:38:04<143:16:40, 528.48s/it, lr=0.001, test_MAE=0.68, time=505, train_MAE=0.58, train_loss=0.582, val_MAE=0.631, val_loss=0.633]Epoch 24:   2%|▏         | 24/1000 [3:38:04<143:16:40, 528.48s/it, lr=0.001, test_MAE=0.68, time=505, train_MAE=0.58, train_loss=0.582, val_MAE=0.631, val_loss=0.633]Epoch 24:   2%|▏         | 24/1000 [3:46:27<143:16:40, 528.48s/it, lr=0.001, test_MAE=0.808, time=503, train_MAE=0.567, train_loss=0.57, val_MAE=0.758, val_loss=0.761]Epoch 24:   2%|▎         | 25/1000 [3:46:27<141:02:50, 520.79s/it, lr=0.001, test_MAE=0.808, time=503, train_MAE=0.567, train_loss=0.57, val_MAE=0.758, val_loss=0.761]Epoch 25:   2%|▎         | 25/1000 [3:46:27<141:02:50, 520.79s/it, lr=0.001, test_MAE=0.808, time=503, train_MAE=0.567, train_loss=0.57, val_MAE=0.758, val_loss=0.761]Epoch 25:   2%|▎         | 25/1000 [3:54:51<141:02:50, 520.79s/it, lr=0.001, test_MAE=0.674, time=504, train_MAE=0.567, train_loss=0.57, val_MAE=0.64, val_loss=0.642] Epoch 25:   3%|▎         | 26/1000 [3:54:51<139:32:06, 515.74s/it, lr=0.001, test_MAE=0.674, time=504, train_MAE=0.567, train_loss=0.57, val_MAE=0.64, val_loss=0.642]Epoch 26:   3%|▎         | 26/1000 [3:54:51<139:32:06, 515.74s/it, lr=0.001, test_MAE=0.674, time=504, train_MAE=0.567, train_loss=0.57, val_MAE=0.64, val_loss=0.642]Epoch 26:   3%|▎         | 26/1000 [4:03:29<139:32:06, 515.74s/it, lr=0.001, test_MAE=0.664, time=518, train_MAE=0.564, train_loss=0.567, val_MAE=0.616, val_loss=0.619]Epoch 26:   3%|▎         | 27/1000 [4:03:29<139:34:49, 516.43s/it, lr=0.001, test_MAE=0.664, time=518, train_MAE=0.564, train_loss=0.567, val_MAE=0.616, val_loss=0.619]Epoch 27:   3%|▎         | 27/1000 [4:03:29<139:34:49, 516.43s/it, lr=0.001, test_MAE=0.664, time=518, train_MAE=0.564, train_loss=0.567, val_MAE=0.616, val_loss=0.619]Epoch 27:   3%|▎         | 27/1000 [4:12:15<139:34:49, 516.43s/it, lr=0.001, test_MAE=0.61, time=526, train_MAE=0.563, train_loss=0.566, val_MAE=0.578, val_loss=0.581] Epoch 27:   3%|▎         | 28/1000 [4:12:15<140:11:08, 519.21s/it, lr=0.001, test_MAE=0.61, time=526, train_MAE=0.563, train_loss=0.566, val_MAE=0.578, val_loss=0.581]Epoch 28:   3%|▎         | 28/1000 [4:12:15<140:11:08, 519.21s/it, lr=0.001, test_MAE=0.61, time=526, train_MAE=0.563, train_loss=0.566, val_MAE=0.578, val_loss=0.581]Epoch 28:   3%|▎         | 28/1000 [4:21:11<140:11:08, 519.21s/it, lr=0.001, test_MAE=0.658, time=536, train_MAE=0.563, train_loss=0.566, val_MAE=0.602, val_loss=0.605]Epoch 28:   3%|▎         | 29/1000 [4:21:11<141:24:57, 524.30s/it, lr=0.001, test_MAE=0.658, time=536, train_MAE=0.563, train_loss=0.566, val_MAE=0.602, val_loss=0.605]Epoch 29:   3%|▎         | 29/1000 [4:21:11<141:24:57, 524.30s/it, lr=0.001, test_MAE=0.658, time=536, train_MAE=0.563, train_loss=0.566, val_MAE=0.602, val_loss=0.605]Epoch 29:   3%|▎         | 29/1000 [4:30:10<141:24:57, 524.30s/it, lr=0.001, test_MAE=0.779, time=539, train_MAE=0.56, train_loss=0.563, val_MAE=0.74, val_loss=0.742]  Epoch 29:   3%|▎         | 30/1000 [4:30:10<142:28:25, 528.77s/it, lr=0.001, test_MAE=0.779, time=539, train_MAE=0.56, train_loss=0.563, val_MAE=0.74, val_loss=0.742]Epoch 30:   3%|▎         | 30/1000 [4:30:10<142:28:25, 528.77s/it, lr=0.001, test_MAE=0.779, time=539, train_MAE=0.56, train_loss=0.563, val_MAE=0.74, val_loss=0.742]Epoch 30:   3%|▎         | 30/1000 [4:39:18<142:28:25, 528.77s/it, lr=0.001, test_MAE=0.67, time=548, train_MAE=0.557, train_loss=0.56, val_MAE=0.622, val_loss=0.624]Epoch 30:   3%|▎         | 31/1000 [4:39:18<143:51:18, 534.45s/it, lr=0.001, test_MAE=0.67, time=548, train_MAE=0.557, train_loss=0.56, val_MAE=0.622, val_loss=0.624]Epoch 31:   3%|▎         | 31/1000 [4:39:18<143:51:18, 534.45s/it, lr=0.001, test_MAE=0.67, time=548, train_MAE=0.557, train_loss=0.56, val_MAE=0.622, val_loss=0.624]Epoch 31:   3%|▎         | 31/1000 [4:48:14<143:51:18, 534.45s/it, lr=0.001, test_MAE=0.624, time=537, train_MAE=0.553, train_loss=0.555, val_MAE=0.597, val_loss=0.599]Epoch 31:   3%|▎         | 32/1000 [4:48:15<143:53:21, 535.13s/it, lr=0.001, test_MAE=0.624, time=537, train_MAE=0.553, train_loss=0.555, val_MAE=0.597, val_loss=0.599]Epoch 32:   3%|▎         | 32/1000 [4:48:15<143:53:21, 535.13s/it, lr=0.001, test_MAE=0.624, time=537, train_MAE=0.553, train_loss=0.555, val_MAE=0.597, val_loss=0.599]Epoch 32:   3%|▎         | 32/1000 [4:56:53<143:53:21, 535.13s/it, lr=0.001, test_MAE=0.849, time=518, train_MAE=0.551, train_loss=0.554, val_MAE=0.797, val_loss=0.8]  Epoch 32:   3%|▎         | 33/1000 [4:56:53<142:22:05, 530.02s/it, lr=0.001, test_MAE=0.849, time=518, train_MAE=0.551, train_loss=0.554, val_MAE=0.797, val_loss=0.8]Epoch 33:   3%|▎         | 33/1000 [4:56:53<142:22:05, 530.02s/it, lr=0.001, test_MAE=0.849, time=518, train_MAE=0.551, train_loss=0.554, val_MAE=0.797, val_loss=0.8]Epoch 33:   3%|▎         | 33/1000 [5:05:17<142:22:05, 530.02s/it, lr=0.001, test_MAE=0.731, time=504, train_MAE=0.554, train_loss=0.557, val_MAE=0.688, val_loss=0.691]Epoch    34: reducing learning rate of group 0 to 5.0000e-04.
Epoch 33:   3%|▎         | 34/1000 [5:05:17<140:07:53, 522.23s/it, lr=0.001, test_MAE=0.731, time=504, train_MAE=0.554, train_loss=0.557, val_MAE=0.688, val_loss=0.691]Epoch 34:   3%|▎         | 34/1000 [5:05:17<140:07:53, 522.23s/it, lr=0.001, test_MAE=0.731, time=504, train_MAE=0.554, train_loss=0.557, val_MAE=0.688, val_loss=0.691]Epoch 34:   3%|▎         | 34/1000 [5:13:42<140:07:53, 522.23s/it, lr=0.0005, test_MAE=0.732, time=505, train_MAE=0.545, train_loss=0.548, val_MAE=0.64, val_loss=0.642]Epoch 34:   4%|▎         | 35/1000 [5:13:42<138:38:06, 517.19s/it, lr=0.0005, test_MAE=0.732, time=505, train_MAE=0.545, train_loss=0.548, val_MAE=0.64, val_loss=0.642]Epoch 35:   4%|▎         | 35/1000 [5:13:42<138:38:06, 517.19s/it, lr=0.0005, test_MAE=0.732, time=505, train_MAE=0.545, train_loss=0.548, val_MAE=0.64, val_loss=0.642]Epoch 35:   4%|▎         | 35/1000 [5:22:14<138:38:06, 517.19s/it, lr=0.0005, test_MAE=0.614, time=512, train_MAE=0.529, train_loss=0.532, val_MAE=0.56, val_loss=0.563]Epoch 35:   4%|▎         | 36/1000 [5:22:14<138:02:28, 515.51s/it, lr=0.0005, test_MAE=0.614, time=512, train_MAE=0.529, train_loss=0.532, val_MAE=0.56, val_loss=0.563]Epoch 36:   4%|▎         | 36/1000 [5:22:14<138:02:28, 515.51s/it, lr=0.0005, test_MAE=0.614, time=512, train_MAE=0.529, train_loss=0.532, val_MAE=0.56, val_loss=0.563]Epoch 36:   4%|▎         | 36/1000 [5:31:25<138:02:28, 515.51s/it, lr=0.0005, test_MAE=0.624, time=551, train_MAE=0.523, train_loss=0.526, val_MAE=0.565, val_loss=0.568]Epoch 36:   4%|▎         | 37/1000 [5:31:25<140:46:53, 526.29s/it, lr=0.0005, test_MAE=0.624, time=551, train_MAE=0.523, train_loss=0.526, val_MAE=0.565, val_loss=0.568]Epoch 37:   4%|▎         | 37/1000 [5:31:25<140:46:53, 526.29s/it, lr=0.0005, test_MAE=0.624, time=551, train_MAE=0.523, train_loss=0.526, val_MAE=0.565, val_loss=0.568]Epoch 37:   4%|▎         | 37/1000 [5:40:23<140:46:53, 526.29s/it, lr=0.0005, test_MAE=2.87, time=538, train_MAE=0.523, train_loss=0.526, val_MAE=2.87, val_loss=2.87]   Epoch 37:   4%|▍         | 38/1000 [5:40:23<141:35:36, 529.87s/it, lr=0.0005, test_MAE=2.87, time=538, train_MAE=0.523, train_loss=0.526, val_MAE=2.87, val_loss=2.87]Epoch 38:   4%|▍         | 38/1000 [5:40:23<141:35:36, 529.87s/it, lr=0.0005, test_MAE=2.87, time=538, train_MAE=0.523, train_loss=0.526, val_MAE=2.87, val_loss=2.87]Epoch 38:   4%|▍         | 38/1000 [5:49:22<141:35:36, 529.87s/it, lr=0.0005, test_MAE=0.611, time=538, train_MAE=0.526, train_loss=0.529, val_MAE=0.546, val_loss=0.549]Epoch 38:   4%|▍         | 39/1000 [5:49:22<142:07:56, 532.44s/it, lr=0.0005, test_MAE=0.611, time=538, train_MAE=0.526, train_loss=0.529, val_MAE=0.546, val_loss=0.549]Epoch 39:   4%|▍         | 39/1000 [5:49:22<142:07:56, 532.44s/it, lr=0.0005, test_MAE=0.611, time=538, train_MAE=0.526, train_loss=0.529, val_MAE=0.546, val_loss=0.549]Epoch 39:   4%|▍         | 39/1000 [5:58:04<142:07:56, 532.44s/it, lr=0.0005, test_MAE=0.899, time=522, train_MAE=0.527, train_loss=0.53, val_MAE=0.811, val_loss=0.814] Epoch 39:   4%|▍         | 40/1000 [5:58:04<141:08:06, 529.26s/it, lr=0.0005, test_MAE=0.899, time=522, train_MAE=0.527, train_loss=0.53, val_MAE=0.811, val_loss=0.814]Epoch 40:   4%|▍         | 40/1000 [5:58:04<141:08:06, 529.26s/it, lr=0.0005, test_MAE=0.899, time=522, train_MAE=0.527, train_loss=0.53, val_MAE=0.811, val_loss=0.814]Epoch 40:   4%|▍         | 40/1000 [6:06:36<141:08:06, 529.26s/it, lr=0.0005, test_MAE=0.682, time=513, train_MAE=0.521, train_loss=0.524, val_MAE=0.626, val_loss=0.629]Epoch 40:   4%|▍         | 41/1000 [6:06:36<139:39:34, 524.27s/it, lr=0.0005, test_MAE=0.682, time=513, train_MAE=0.521, train_loss=0.524, val_MAE=0.626, val_loss=0.629]Epoch 41:   4%|▍         | 41/1000 [6:06:36<139:39:34, 524.27s/it, lr=0.0005, test_MAE=0.682, time=513, train_MAE=0.521, train_loss=0.524, val_MAE=0.626, val_loss=0.629]Epoch 41:   4%|▍         | 41/1000 [6:15:00<139:39:34, 524.27s/it, lr=0.0005, test_MAE=0.614, time=504, train_MAE=0.521, train_loss=0.524, val_MAE=0.553, val_loss=0.556]Epoch 41:   4%|▍         | 42/1000 [6:15:01<137:54:56, 518.26s/it, lr=0.0005, test_MAE=0.614, time=504, train_MAE=0.521, train_loss=0.524, val_MAE=0.553, val_loss=0.556]Epoch 42:   4%|▍         | 42/1000 [6:15:01<137:54:56, 518.26s/it, lr=0.0005, test_MAE=0.614, time=504, train_MAE=0.521, train_loss=0.524, val_MAE=0.553, val_loss=0.556]Epoch 42:   4%|▍         | 42/1000 [6:23:23<137:54:56, 518.26s/it, lr=0.0005, test_MAE=0.666, time=502, train_MAE=0.531, train_loss=0.534, val_MAE=0.633, val_loss=0.636]Epoch 42:   4%|▍         | 43/1000 [6:23:23<136:29:44, 513.46s/it, lr=0.0005, test_MAE=0.666, time=502, train_MAE=0.531, train_loss=0.534, val_MAE=0.633, val_loss=0.636]Epoch 43:   4%|▍         | 43/1000 [6:23:23<136:29:44, 513.46s/it, lr=0.0005, test_MAE=0.666, time=502, train_MAE=0.531, train_loss=0.534, val_MAE=0.633, val_loss=0.636]Epoch 43:   4%|▍         | 43/1000 [6:31:51<136:29:44, 513.46s/it, lr=0.0005, test_MAE=0.608, time=508, train_MAE=0.517, train_loss=0.52, val_MAE=0.566, val_loss=0.569] Epoch 43:   4%|▍         | 44/1000 [6:31:51<135:56:09, 511.89s/it, lr=0.0005, test_MAE=0.608, time=508, train_MAE=0.517, train_loss=0.52, val_MAE=0.566, val_loss=0.569]Epoch 44:   4%|▍         | 44/1000 [6:31:51<135:56:09, 511.89s/it, lr=0.0005, test_MAE=0.608, time=508, train_MAE=0.517, train_loss=0.52, val_MAE=0.566, val_loss=0.569]Epoch 44:   4%|▍         | 44/1000 [6:40:19<135:56:09, 511.89s/it, lr=0.0005, test_MAE=0.602, time=508, train_MAE=0.517, train_loss=0.519, val_MAE=0.565, val_loss=0.568]Epoch    45: reducing learning rate of group 0 to 2.5000e-04.
Epoch 44:   4%|▍         | 45/1000 [6:40:19<135:28:11, 510.67s/it, lr=0.0005, test_MAE=0.602, time=508, train_MAE=0.517, train_loss=0.519, val_MAE=0.565, val_loss=0.568]Epoch 45:   4%|▍         | 45/1000 [6:40:19<135:28:11, 510.67s/it, lr=0.0005, test_MAE=0.602, time=508, train_MAE=0.517, train_loss=0.519, val_MAE=0.565, val_loss=0.568]Epoch 45:   4%|▍         | 45/1000 [6:48:48<135:28:11, 510.67s/it, lr=0.00025, test_MAE=0.824, time=509, train_MAE=0.503, train_loss=0.506, val_MAE=0.784, val_loss=0.787]Epoch 45:   5%|▍         | 46/1000 [6:48:48<135:14:17, 510.33s/it, lr=0.00025, test_MAE=0.824, time=509, train_MAE=0.503, train_loss=0.506, val_MAE=0.784, val_loss=0.787]Epoch 46:   5%|▍         | 46/1000 [6:48:48<135:14:17, 510.33s/it, lr=0.00025, test_MAE=0.824, time=509, train_MAE=0.503, train_loss=0.506, val_MAE=0.784, val_loss=0.787]Epoch 46:   5%|▍         | 46/1000 [6:57:07<135:14:17, 510.33s/it, lr=0.00025, test_MAE=0.584, time=499, train_MAE=0.504, train_loss=0.507, val_MAE=0.532, val_loss=0.535]Epoch 46:   5%|▍         | 47/1000 [6:57:07<134:09:50, 506.81s/it, lr=0.00025, test_MAE=0.584, time=499, train_MAE=0.504, train_loss=0.507, val_MAE=0.532, val_loss=0.535]Epoch 47:   5%|▍         | 47/1000 [6:57:07<134:09:50, 506.81s/it, lr=0.00025, test_MAE=0.584, time=499, train_MAE=0.504, train_loss=0.507, val_MAE=0.532, val_loss=0.535]Epoch 47:   5%|▍         | 47/1000 [7:05:27<134:09:50, 506.81s/it, lr=0.00025, test_MAE=0.58, time=500, train_MAE=0.502, train_loss=0.505, val_MAE=0.529, val_loss=0.532] Epoch 47:   5%|▍         | 48/1000 [7:05:27<133:29:45, 504.82s/it, lr=0.00025, test_MAE=0.58, time=500, train_MAE=0.502, train_loss=0.505, val_MAE=0.529, val_loss=0.532]Epoch 48:   5%|▍         | 48/1000 [7:05:27<133:29:45, 504.82s/it, lr=0.00025, test_MAE=0.58, time=500, train_MAE=0.502, train_loss=0.505, val_MAE=0.529, val_loss=0.532]Epoch 48:   5%|▍         | 48/1000 [7:13:47<133:29:45, 504.82s/it, lr=0.00025, test_MAE=0.587, time=500, train_MAE=0.5, train_loss=0.503, val_MAE=0.543, val_loss=0.546] Epoch 48:   5%|▍         | 49/1000 [7:13:47<132:56:43, 503.26s/it, lr=0.00025, test_MAE=0.587, time=500, train_MAE=0.5, train_loss=0.503, val_MAE=0.543, val_loss=0.546]Epoch 49:   5%|▍         | 49/1000 [7:13:47<132:56:43, 503.26s/it, lr=0.00025, test_MAE=0.587, time=500, train_MAE=0.5, train_loss=0.503, val_MAE=0.543, val_loss=0.546]Epoch 49:   5%|▍         | 49/1000 [7:22:06<132:56:43, 503.26s/it, lr=0.00025, test_MAE=0.582, time=499, train_MAE=0.501, train_loss=0.504, val_MAE=0.54, val_loss=0.543]Epoch 49:   5%|▌         | 50/1000 [7:22:06<132:27:33, 501.95s/it, lr=0.00025, test_MAE=0.582, time=499, train_MAE=0.501, train_loss=0.504, val_MAE=0.54, val_loss=0.543]Epoch 50:   5%|▌         | 50/1000 [7:22:06<132:27:33, 501.95s/it, lr=0.00025, test_MAE=0.582, time=499, train_MAE=0.501, train_loss=0.504, val_MAE=0.54, val_loss=0.543]Epoch 50:   5%|▌         | 50/1000 [7:30:24<132:27:33, 501.95s/it, lr=0.00025, test_MAE=0.6, time=498, train_MAE=0.498, train_loss=0.501, val_MAE=0.553, val_loss=0.556] Epoch 50:   5%|▌         | 51/1000 [7:30:24<132:01:54, 500.86s/it, lr=0.00025, test_MAE=0.6, time=498, train_MAE=0.498, train_loss=0.501, val_MAE=0.553, val_loss=0.556]Epoch 51:   5%|▌         | 51/1000 [7:30:24<132:01:54, 500.86s/it, lr=0.00025, test_MAE=0.6, time=498, train_MAE=0.498, train_loss=0.501, val_MAE=0.553, val_loss=0.556]Epoch 51:   5%|▌         | 51/1000 [7:38:42<132:01:54, 500.86s/it, lr=0.00025, test_MAE=0.586, time=498, train_MAE=0.494, train_loss=0.497, val_MAE=0.534, val_loss=0.537]Epoch 51:   5%|▌         | 52/1000 [7:38:42<131:42:16, 500.14s/it, lr=0.00025, test_MAE=0.586, time=498, train_MAE=0.494, train_loss=0.497, val_MAE=0.534, val_loss=0.537]Epoch 52:   5%|▌         | 52/1000 [7:38:42<131:42:16, 500.14s/it, lr=0.00025, test_MAE=0.586, time=498, train_MAE=0.494, train_loss=0.497, val_MAE=0.534, val_loss=0.537]Epoch 52:   5%|▌         | 52/1000 [7:47:12<131:42:16, 500.14s/it, lr=0.00025, test_MAE=0.598, time=509, train_MAE=0.502, train_loss=0.505, val_MAE=0.554, val_loss=0.557]Epoch 52:   5%|▌         | 53/1000 [7:47:12<132:18:07, 502.94s/it, lr=0.00025, test_MAE=0.598, time=509, train_MAE=0.502, train_loss=0.505, val_MAE=0.554, val_loss=0.557]Epoch 53:   5%|▌         | 53/1000 [7:47:12<132:18:07, 502.94s/it, lr=0.00025, test_MAE=0.598, time=509, train_MAE=0.502, train_loss=0.505, val_MAE=0.554, val_loss=0.557]Epoch 53:   5%|▌         | 53/1000 [7:55:40<132:18:07, 502.94s/it, lr=0.00025, test_MAE=0.616, time=508, train_MAE=0.503, train_loss=0.506, val_MAE=0.585, val_loss=0.588]Epoch    54: reducing learning rate of group 0 to 1.2500e-04.
Epoch 53:   5%|▌         | 54/1000 [7:55:40<132:35:39, 504.59s/it, lr=0.00025, test_MAE=0.616, time=508, train_MAE=0.503, train_loss=0.506, val_MAE=0.585, val_loss=0.588]Epoch 54:   5%|▌         | 54/1000 [7:55:40<132:35:39, 504.59s/it, lr=0.00025, test_MAE=0.616, time=508, train_MAE=0.503, train_loss=0.506, val_MAE=0.585, val_loss=0.588]Epoch 54:   5%|▌         | 54/1000 [8:04:10<132:35:39, 504.59s/it, lr=0.000125, test_MAE=0.567, time=510, train_MAE=0.48, train_loss=0.483, val_MAE=0.527, val_loss=0.529]Epoch 54:   6%|▌         | 55/1000 [8:04:10<132:53:19, 506.24s/it, lr=0.000125, test_MAE=0.567, time=510, train_MAE=0.48, train_loss=0.483, val_MAE=0.527, val_loss=0.529]Epoch 55:   6%|▌         | 55/1000 [8:04:10<132:53:19, 506.24s/it, lr=0.000125, test_MAE=0.567, time=510, train_MAE=0.48, train_loss=0.483, val_MAE=0.527, val_loss=0.529]Epoch 55:   6%|▌         | 55/1000 [8:12:33<132:53:19, 506.24s/it, lr=0.000125, test_MAE=0.582, time=503, train_MAE=0.479, train_loss=0.482, val_MAE=0.532, val_loss=0.535]Epoch 55:   6%|▌         | 56/1000 [8:12:33<132:28:30, 505.20s/it, lr=0.000125, test_MAE=0.582, time=503, train_MAE=0.479, train_loss=0.482, val_MAE=0.532, val_loss=0.535]Epoch 56:   6%|▌         | 56/1000 [8:12:33<132:28:30, 505.20s/it, lr=0.000125, test_MAE=0.582, time=503, train_MAE=0.479, train_loss=0.482, val_MAE=0.532, val_loss=0.535]Epoch 56:   6%|▌         | 56/1000 [8:20:57<132:28:30, 505.20s/it, lr=0.000125, test_MAE=0.568, time=503, train_MAE=0.477, train_loss=0.48, val_MAE=0.528, val_loss=0.531] Epoch 56:   6%|▌         | 57/1000 [8:20:57<132:11:19, 504.64s/it, lr=0.000125, test_MAE=0.568, time=503, train_MAE=0.477, train_loss=0.48, val_MAE=0.528, val_loss=0.531]Epoch 57:   6%|▌         | 57/1000 [8:20:57<132:11:19, 504.64s/it, lr=0.000125, test_MAE=0.568, time=503, train_MAE=0.477, train_loss=0.48, val_MAE=0.528, val_loss=0.531]Epoch 57:   6%|▌         | 57/1000 [8:29:21<132:11:19, 504.64s/it, lr=0.000125, test_MAE=0.628, time=504, train_MAE=0.471, train_loss=0.474, val_MAE=0.583, val_loss=0.586]Epoch 57:   6%|▌         | 58/1000 [8:29:21<132:00:12, 504.47s/it, lr=0.000125, test_MAE=0.628, time=504, train_MAE=0.471, train_loss=0.474, val_MAE=0.583, val_loss=0.586]Epoch 58:   6%|▌         | 58/1000 [8:29:21<132:00:12, 504.47s/it, lr=0.000125, test_MAE=0.628, time=504, train_MAE=0.471, train_loss=0.474, val_MAE=0.583, val_loss=0.586]Epoch 58:   6%|▌         | 58/1000 [8:37:44<132:00:12, 504.47s/it, lr=0.000125, test_MAE=0.581, time=503, train_MAE=0.476, train_loss=0.479, val_MAE=0.534, val_loss=0.537]Epoch 58:   6%|▌         | 59/1000 [8:37:44<131:45:33, 504.07s/it, lr=0.000125, test_MAE=0.581, time=503, train_MAE=0.476, train_loss=0.479, val_MAE=0.534, val_loss=0.537]Epoch 59:   6%|▌         | 59/1000 [8:37:44<131:45:33, 504.07s/it, lr=0.000125, test_MAE=0.581, time=503, train_MAE=0.476, train_loss=0.479, val_MAE=0.534, val_loss=0.537]Epoch 59:   6%|▌         | 59/1000 [8:46:06<131:45:33, 504.07s/it, lr=0.000125, test_MAE=0.567, time=502, train_MAE=0.473, train_loss=0.476, val_MAE=0.521, val_loss=0.524]Epoch 59:   6%|▌         | 60/1000 [8:46:06<131:29:17, 503.57s/it, lr=0.000125, test_MAE=0.567, time=502, train_MAE=0.473, train_loss=0.476, val_MAE=0.521, val_loss=0.524]Epoch 60:   6%|▌         | 60/1000 [8:46:06<131:29:17, 503.57s/it, lr=0.000125, test_MAE=0.567, time=502, train_MAE=0.473, train_loss=0.476, val_MAE=0.521, val_loss=0.524]Epoch 60:   6%|▌         | 60/1000 [8:54:30<131:29:17, 503.57s/it, lr=0.000125, test_MAE=0.575, time=504, train_MAE=0.476, train_loss=0.478, val_MAE=0.533, val_loss=0.536]Epoch 60:   6%|▌         | 61/1000 [8:54:30<131:22:11, 503.65s/it, lr=0.000125, test_MAE=0.575, time=504, train_MAE=0.476, train_loss=0.478, val_MAE=0.533, val_loss=0.536]Epoch 61:   6%|▌         | 61/1000 [8:54:30<131:22:11, 503.65s/it, lr=0.000125, test_MAE=0.575, time=504, train_MAE=0.476, train_loss=0.478, val_MAE=0.533, val_loss=0.536]Epoch 61:   6%|▌         | 61/1000 [9:02:54<131:22:11, 503.65s/it, lr=0.000125, test_MAE=0.602, time=504, train_MAE=0.475, train_loss=0.478, val_MAE=0.553, val_loss=0.555]Epoch 61:   6%|▌         | 62/1000 [9:02:54<131:13:59, 503.67s/it, lr=0.000125, test_MAE=0.602, time=504, train_MAE=0.475, train_loss=0.478, val_MAE=0.553, val_loss=0.555]Epoch 62:   6%|▌         | 62/1000 [9:02:54<131:13:59, 503.67s/it, lr=0.000125, test_MAE=0.602, time=504, train_MAE=0.475, train_loss=0.478, val_MAE=0.553, val_loss=0.555]Epoch 62:   6%|▌         | 62/1000 [9:11:16<131:13:59, 503.67s/it, lr=0.000125, test_MAE=0.567, time=503, train_MAE=0.479, train_loss=0.482, val_MAE=0.529, val_loss=0.531]Epoch 62:   6%|▋         | 63/1000 [9:11:17<131:01:34, 503.41s/it, lr=0.000125, test_MAE=0.567, time=503, train_MAE=0.479, train_loss=0.482, val_MAE=0.529, val_loss=0.531]Epoch 63:   6%|▋         | 63/1000 [9:11:17<131:01:34, 503.41s/it, lr=0.000125, test_MAE=0.567, time=503, train_MAE=0.479, train_loss=0.482, val_MAE=0.529, val_loss=0.531]Epoch 63:   6%|▋         | 63/1000 [9:19:39<131:01:34, 503.41s/it, lr=0.000125, test_MAE=0.616, time=503, train_MAE=0.472, train_loss=0.475, val_MAE=0.58, val_loss=0.583] Epoch 63:   6%|▋         | 64/1000 [9:19:39<130:50:21, 503.23s/it, lr=0.000125, test_MAE=0.616, time=503, train_MAE=0.472, train_loss=0.475, val_MAE=0.58, val_loss=0.583]Epoch 64:   6%|▋         | 64/1000 [9:19:39<130:50:21, 503.23s/it, lr=0.000125, test_MAE=0.616, time=503, train_MAE=0.472, train_loss=0.475, val_MAE=0.58, val_loss=0.583]Epoch 64:   6%|▋         | 64/1000 [9:28:03<130:50:21, 503.23s/it, lr=0.000125, test_MAE=0.573, time=504, train_MAE=0.47, train_loss=0.473, val_MAE=0.538, val_loss=0.541]Epoch 64:   6%|▋         | 65/1000 [9:28:03<130:43:27, 503.32s/it, lr=0.000125, test_MAE=0.573, time=504, train_MAE=0.47, train_loss=0.473, val_MAE=0.538, val_loss=0.541]Epoch 65:   6%|▋         | 65/1000 [9:28:03<130:43:27, 503.32s/it, lr=0.000125, test_MAE=0.573, time=504, train_MAE=0.47, train_loss=0.473, val_MAE=0.538, val_loss=0.541]Epoch 65:   6%|▋         | 65/1000 [9:36:26<130:43:27, 503.32s/it, lr=0.000125, test_MAE=0.591, time=503, train_MAE=0.468, train_loss=0.471, val_MAE=0.542, val_loss=0.545]Epoch    66: reducing learning rate of group 0 to 6.2500e-05.
Epoch 65:   7%|▋         | 66/1000 [9:36:26<130:32:41, 503.17s/it, lr=0.000125, test_MAE=0.591, time=503, train_MAE=0.468, train_loss=0.471, val_MAE=0.542, val_loss=0.545]Epoch 66:   7%|▋         | 66/1000 [9:36:26<130:32:41, 503.17s/it, lr=0.000125, test_MAE=0.591, time=503, train_MAE=0.468, train_loss=0.471, val_MAE=0.542, val_loss=0.545]Epoch 66:   7%|▋         | 66/1000 [9:44:46<130:32:41, 503.17s/it, lr=6.25e-5, test_MAE=0.631, time=500, train_MAE=0.467, train_loss=0.47, val_MAE=0.595, val_loss=0.597]  Epoch 66:   7%|▋         | 67/1000 [9:44:46<130:10:06, 502.26s/it, lr=6.25e-5, test_MAE=0.631, time=500, train_MAE=0.467, train_loss=0.47, val_MAE=0.595, val_loss=0.597]Epoch 67:   7%|▋         | 67/1000 [9:44:46<130:10:06, 502.26s/it, lr=6.25e-5, test_MAE=0.631, time=500, train_MAE=0.467, train_loss=0.47, val_MAE=0.595, val_loss=0.597]Epoch 67:   7%|▋         | 67/1000 [9:53:07<130:10:06, 502.26s/it, lr=6.25e-5, test_MAE=0.585, time=502, train_MAE=0.46, train_loss=0.463, val_MAE=0.55, val_loss=0.552] Epoch 67:   7%|▋         | 68/1000 [9:53:07<129:58:17, 502.04s/it, lr=6.25e-5, test_MAE=0.585, time=502, train_MAE=0.46, train_loss=0.463, val_MAE=0.55, val_loss=0.552]Epoch 68:   7%|▋         | 68/1000 [9:53:07<129:58:17, 502.04s/it, lr=6.25e-5, test_MAE=0.585, time=502, train_MAE=0.46, train_loss=0.463, val_MAE=0.55, val_loss=0.552]Epoch 68:   7%|▋         | 68/1000 [10:01:30<129:58:17, 502.04s/it, lr=6.25e-5, test_MAE=0.605, time=503, train_MAE=0.456, train_loss=0.458, val_MAE=0.548, val_loss=0.551]Epoch 68:   7%|▋         | 69/1000 [10:01:30<129:52:31, 502.20s/it, lr=6.25e-5, test_MAE=0.605, time=503, train_MAE=0.456, train_loss=0.458, val_MAE=0.548, val_loss=0.551]Epoch 69:   7%|▋         | 69/1000 [10:01:30<129:52:31, 502.20s/it, lr=6.25e-5, test_MAE=0.605, time=503, train_MAE=0.456, train_loss=0.458, val_MAE=0.548, val_loss=0.551]Epoch 69:   7%|▋         | 69/1000 [10:09:52<129:52:31, 502.20s/it, lr=6.25e-5, test_MAE=0.557, time=502, train_MAE=0.452, train_loss=0.455, val_MAE=0.511, val_loss=0.514]Epoch 69:   7%|▋         | 70/1000 [10:09:52<129:42:57, 502.13s/it, lr=6.25e-5, test_MAE=0.557, time=502, train_MAE=0.452, train_loss=0.455, val_MAE=0.511, val_loss=0.514]Epoch 70:   7%|▋         | 70/1000 [10:09:52<129:42:57, 502.13s/it, lr=6.25e-5, test_MAE=0.557, time=502, train_MAE=0.452, train_loss=0.455, val_MAE=0.511, val_loss=0.514]Epoch 70:   7%|▋         | 70/1000 [10:18:14<129:42:57, 502.13s/it, lr=6.25e-5, test_MAE=0.56, time=502, train_MAE=0.45, train_loss=0.453, val_MAE=0.513, val_loss=0.516]  Epoch 70:   7%|▋         | 71/1000 [10:18:14<129:34:27, 502.12s/it, lr=6.25e-5, test_MAE=0.56, time=502, train_MAE=0.45, train_loss=0.453, val_MAE=0.513, val_loss=0.516]Epoch 71:   7%|▋         | 71/1000 [10:18:14<129:34:27, 502.12s/it, lr=6.25e-5, test_MAE=0.56, time=502, train_MAE=0.45, train_loss=0.453, val_MAE=0.513, val_loss=0.516]Epoch 71:   7%|▋         | 71/1000 [10:26:35<129:34:27, 502.12s/it, lr=6.25e-5, test_MAE=0.583, time=501, train_MAE=0.467, train_loss=0.47, val_MAE=0.549, val_loss=0.552]Epoch 71:   7%|▋         | 72/1000 [10:26:35<129:23:12, 501.93s/it, lr=6.25e-5, test_MAE=0.583, time=501, train_MAE=0.467, train_loss=0.47, val_MAE=0.549, val_loss=0.552]Epoch 72:   7%|▋         | 72/1000 [10:26:35<129:23:12, 501.93s/it, lr=6.25e-5, test_MAE=0.583, time=501, train_MAE=0.467, train_loss=0.47, val_MAE=0.549, val_loss=0.552]Epoch 72:   7%|▋         | 72/1000 [10:34:57<129:23:12, 501.93s/it, lr=6.25e-5, test_MAE=0.614, time=502, train_MAE=0.451, train_loss=0.454, val_MAE=0.556, val_loss=0.559]Epoch 72:   7%|▋         | 73/1000 [10:34:57<129:13:51, 501.87s/it, lr=6.25e-5, test_MAE=0.614, time=502, train_MAE=0.451, train_loss=0.454, val_MAE=0.556, val_loss=0.559]Epoch 73:   7%|▋         | 73/1000 [10:34:57<129:13:51, 501.87s/it, lr=6.25e-5, test_MAE=0.614, time=502, train_MAE=0.451, train_loss=0.454, val_MAE=0.556, val_loss=0.559]Epoch 73:   7%|▋         | 73/1000 [10:43:18<129:13:51, 501.87s/it, lr=6.25e-5, test_MAE=0.571, time=501, train_MAE=0.46, train_loss=0.463, val_MAE=0.52, val_loss=0.523]  Epoch 73:   7%|▋         | 74/1000 [10:43:18<129:02:43, 501.69s/it, lr=6.25e-5, test_MAE=0.571, time=501, train_MAE=0.46, train_loss=0.463, val_MAE=0.52, val_loss=0.523]Epoch 74:   7%|▋         | 74/1000 [10:43:18<129:02:43, 501.69s/it, lr=6.25e-5, test_MAE=0.571, time=501, train_MAE=0.46, train_loss=0.463, val_MAE=0.52, val_loss=0.523]Epoch 74:   7%|▋         | 74/1000 [10:51:40<129:02:43, 501.69s/it, lr=6.25e-5, test_MAE=0.561, time=501, train_MAE=0.452, train_loss=0.455, val_MAE=0.519, val_loss=0.522]Epoch 74:   8%|▊         | 75/1000 [10:51:40<128:53:00, 501.60s/it, lr=6.25e-5, test_MAE=0.561, time=501, train_MAE=0.452, train_loss=0.455, val_MAE=0.519, val_loss=0.522]Epoch 75:   8%|▊         | 75/1000 [10:51:40<128:53:00, 501.60s/it, lr=6.25e-5, test_MAE=0.561, time=501, train_MAE=0.452, train_loss=0.455, val_MAE=0.519, val_loss=0.522]Epoch 75:   8%|▊         | 75/1000 [11:00:02<128:53:00, 501.60s/it, lr=6.25e-5, test_MAE=0.574, time=502, train_MAE=0.45, train_loss=0.453, val_MAE=0.525, val_loss=0.527] Epoch    76: reducing learning rate of group 0 to 3.1250e-05.
Epoch 75:   8%|▊         | 76/1000 [11:00:02<128:45:08, 501.63s/it, lr=6.25e-5, test_MAE=0.574, time=502, train_MAE=0.45, train_loss=0.453, val_MAE=0.525, val_loss=0.527]Epoch 76:   8%|▊         | 76/1000 [11:00:02<128:45:08, 501.63s/it, lr=6.25e-5, test_MAE=0.574, time=502, train_MAE=0.45, train_loss=0.453, val_MAE=0.525, val_loss=0.527]Epoch 76:   8%|▊         | 76/1000 [11:08:23<128:45:08, 501.63s/it, lr=3.13e-5, test_MAE=0.573, time=501, train_MAE=0.443, train_loss=0.446, val_MAE=0.519, val_loss=0.522]Epoch 76:   8%|▊         | 77/1000 [11:08:23<128:34:50, 501.51s/it, lr=3.13e-5, test_MAE=0.573, time=501, train_MAE=0.443, train_loss=0.446, val_MAE=0.519, val_loss=0.522]Epoch 77:   8%|▊         | 77/1000 [11:08:23<128:34:50, 501.51s/it, lr=3.13e-5, test_MAE=0.573, time=501, train_MAE=0.443, train_loss=0.446, val_MAE=0.519, val_loss=0.522]Epoch 77:   8%|▊         | 77/1000 [11:16:43<128:34:50, 501.51s/it, lr=3.13e-5, test_MAE=0.566, time=501, train_MAE=0.437, train_loss=0.44, val_MAE=0.513, val_loss=0.516] Epoch 77:   8%|▊         | 78/1000 [11:16:43<128:22:36, 501.25s/it, lr=3.13e-5, test_MAE=0.566, time=501, train_MAE=0.437, train_loss=0.44, val_MAE=0.513, val_loss=0.516]Epoch 78:   8%|▊         | 78/1000 [11:16:43<128:22:36, 501.25s/it, lr=3.13e-5, test_MAE=0.566, time=501, train_MAE=0.437, train_loss=0.44, val_MAE=0.513, val_loss=0.516]Epoch 78:   8%|▊         | 78/1000 [11:25:05<128:22:36, 501.25s/it, lr=3.13e-5, test_MAE=0.568, time=502, train_MAE=0.435, train_loss=0.438, val_MAE=0.516, val_loss=0.519]Epoch 78:   8%|▊         | 79/1000 [11:25:05<128:16:11, 501.38s/it, lr=3.13e-5, test_MAE=0.568, time=502, train_MAE=0.435, train_loss=0.438, val_MAE=0.516, val_loss=0.519]Epoch 79:   8%|▊         | 79/1000 [11:25:05<128:16:11, 501.38s/it, lr=3.13e-5, test_MAE=0.568, time=502, train_MAE=0.435, train_loss=0.438, val_MAE=0.516, val_loss=0.519]Epoch 79:   8%|▊         | 79/1000 [11:33:26<128:16:11, 501.38s/it, lr=3.13e-5, test_MAE=0.553, time=501, train_MAE=0.441, train_loss=0.444, val_MAE=0.512, val_loss=0.515]Epoch 79:   8%|▊         | 80/1000 [11:33:26<128:05:00, 501.20s/it, lr=3.13e-5, test_MAE=0.553, time=501, train_MAE=0.441, train_loss=0.444, val_MAE=0.512, val_loss=0.515]Epoch 80:   8%|▊         | 80/1000 [11:33:26<128:05:00, 501.20s/it, lr=3.13e-5, test_MAE=0.553, time=501, train_MAE=0.441, train_loss=0.444, val_MAE=0.512, val_loss=0.515]Epoch 80:   8%|▊         | 80/1000 [11:41:48<128:05:00, 501.20s/it, lr=3.13e-5, test_MAE=0.554, time=502, train_MAE=0.437, train_loss=0.439, val_MAE=0.511, val_loss=0.514]Epoch 80:   8%|▊         | 81/1000 [11:41:48<127:59:15, 501.37s/it, lr=3.13e-5, test_MAE=0.554, time=502, train_MAE=0.437, train_loss=0.439, val_MAE=0.511, val_loss=0.514]Epoch 81:   8%|▊         | 81/1000 [11:41:48<127:59:15, 501.37s/it, lr=3.13e-5, test_MAE=0.554, time=502, train_MAE=0.437, train_loss=0.439, val_MAE=0.511, val_loss=0.514]Epoch 81:   8%|▊         | 81/1000 [11:50:08<127:59:15, 501.37s/it, lr=3.13e-5, test_MAE=0.59, time=501, train_MAE=0.432, train_loss=0.434, val_MAE=0.533, val_loss=0.536] Epoch    82: reducing learning rate of group 0 to 1.5625e-05.
Epoch 81:   8%|▊         | 82/1000 [11:50:08<127:48:30, 501.21s/it, lr=3.13e-5, test_MAE=0.59, time=501, train_MAE=0.432, train_loss=0.434, val_MAE=0.533, val_loss=0.536]Epoch 82:   8%|▊         | 82/1000 [11:50:08<127:48:30, 501.21s/it, lr=3.13e-5, test_MAE=0.59, time=501, train_MAE=0.432, train_loss=0.434, val_MAE=0.533, val_loss=0.536]Epoch 82:   8%|▊         | 82/1000 [11:58:30<127:48:30, 501.21s/it, lr=1.56e-5, test_MAE=0.55, time=501, train_MAE=0.438, train_loss=0.441, val_MAE=0.509, val_loss=0.512]Epoch 82:   8%|▊         | 83/1000 [11:58:30<127:40:40, 501.24s/it, lr=1.56e-5, test_MAE=0.55, time=501, train_MAE=0.438, train_loss=0.441, val_MAE=0.509, val_loss=0.512]Epoch 83:   8%|▊         | 83/1000 [11:58:30<127:40:40, 501.24s/it, lr=1.56e-5, test_MAE=0.55, time=501, train_MAE=0.438, train_loss=0.441, val_MAE=0.509, val_loss=0.512]slurmstepd: error: *** JOB 57072305 ON r108u25n01 CANCELLED AT 2025-08-04T21:34:40 DUE TO TIME LIMIT ***
