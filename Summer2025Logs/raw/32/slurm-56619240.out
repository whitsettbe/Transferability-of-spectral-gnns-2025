I'm echoing to stdout
I'm echoing to stderr
My JobID is 56619240
I have 8 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.1580s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 4, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'rational_vec', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_all', 'num_eigs': 15, 'bias_mode': 'spatial', 'eigval_hidden_dim': 5, 'eigval_num_hidden_layer': 3, 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 1, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/zinc_train_rec_full.csv', 'test': 'supp_data/molecules/zinc_test_rec_full.csv', 'val': 'supp_data/molecules/zinc_val_rec_full.csv'}, 'fixMissingPhi1': False, 'extraOrtho': False, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [02:53<?, ?it/s, lr=0.001, test_MAE=1.57, time=174, train_MAE=1.33, train_loss=1.36, val_MAE=1.51, val_loss=1.54]Epoch 0:   0%|          | 1/1000 [02:54<48:17:20, 174.01s/it, lr=0.001, test_MAE=1.57, time=174, train_MAE=1.33, train_loss=1.36, val_MAE=1.51, val_loss=1.54]Epoch 1:   0%|          | 1/1000 [02:54<48:17:20, 174.01s/it, lr=0.001, test_MAE=1.57, time=174, train_MAE=1.33, train_loss=1.36, val_MAE=1.51, val_loss=1.54]Epoch 1:   0%|          | 1/1000 [05:25<48:17:20, 174.01s/it, lr=0.001, test_MAE=1.34, time=152, train_MAE=0.965, train_loss=0.997, val_MAE=1.26, val_loss=1.29]Epoch 1:   0%|          | 2/1000 [05:25<46:23:26, 167.34s/it, lr=0.001, test_MAE=1.34, time=152, train_MAE=0.965, train_loss=0.997, val_MAE=1.26, val_loss=1.29]Epoch 2:   0%|          | 2/1000 [05:25<46:23:26, 167.34s/it, lr=0.001, test_MAE=1.34, time=152, train_MAE=0.965, train_loss=0.997, val_MAE=1.26, val_loss=1.29]Epoch 2:   0%|          | 2/1000 [07:58<46:23:26, 167.34s/it, lr=0.001, test_MAE=1.04, time=153, train_MAE=0.763, train_loss=0.797, val_MAE=0.952, val_loss=0.987]Epoch 2:   0%|          | 3/1000 [07:58<45:07:30, 162.94s/it, lr=0.001, test_MAE=1.04, time=153, train_MAE=0.763, train_loss=0.797, val_MAE=0.952, val_loss=0.987]Epoch 3:   0%|          | 3/1000 [07:58<45:07:30, 162.94s/it, lr=0.001, test_MAE=1.04, time=153, train_MAE=0.763, train_loss=0.797, val_MAE=0.952, val_loss=0.987]Epoch 3:   0%|          | 3/1000 [10:31<45:07:30, 162.94s/it, lr=0.001, test_MAE=1.04, time=153, train_MAE=0.709, train_loss=0.745, val_MAE=0.978, val_loss=1.01] Epoch 3:   0%|          | 4/1000 [10:31<44:14:09, 159.89s/it, lr=0.001, test_MAE=1.04, time=153, train_MAE=0.709, train_loss=0.745, val_MAE=0.978, val_loss=1.01]Epoch 4:   0%|          | 4/1000 [10:31<44:14:09, 159.89s/it, lr=0.001, test_MAE=1.04, time=153, train_MAE=0.709, train_loss=0.745, val_MAE=0.978, val_loss=1.01]Epoch 4:   0%|          | 4/1000 [13:03<44:14:09, 159.89s/it, lr=0.001, test_MAE=1.09, time=152, train_MAE=0.684, train_loss=0.72, val_MAE=1.05, val_loss=1.09]  Epoch 4:   0%|          | 5/1000 [13:03<43:34:40, 157.67s/it, lr=0.001, test_MAE=1.09, time=152, train_MAE=0.684, train_loss=0.72, val_MAE=1.05, val_loss=1.09]Epoch 5:   0%|          | 5/1000 [13:03<43:34:40, 157.67s/it, lr=0.001, test_MAE=1.09, time=152, train_MAE=0.684, train_loss=0.72, val_MAE=1.05, val_loss=1.09]Epoch 5:   0%|          | 5/1000 [15:37<43:34:40, 157.67s/it, lr=0.001, test_MAE=0.778, time=153, train_MAE=0.674, train_loss=0.71, val_MAE=0.72, val_loss=0.757]Epoch 5:   1%|          | 6/1000 [15:37<43:10:31, 156.37s/it, lr=0.001, test_MAE=0.778, time=153, train_MAE=0.674, train_loss=0.71, val_MAE=0.72, val_loss=0.757]Epoch 6:   1%|          | 6/1000 [15:37<43:10:31, 156.37s/it, lr=0.001, test_MAE=0.778, time=153, train_MAE=0.674, train_loss=0.71, val_MAE=0.72, val_loss=0.757]Epoch 6:   1%|          | 6/1000 [18:10<43:10:31, 156.37s/it, lr=0.001, test_MAE=0.838, time=153, train_MAE=0.653, train_loss=0.69, val_MAE=0.782, val_loss=0.819]Epoch 6:   1%|          | 7/1000 [18:10<42:53:08, 155.48s/it, lr=0.001, test_MAE=0.838, time=153, train_MAE=0.653, train_loss=0.69, val_MAE=0.782, val_loss=0.819]Epoch 7:   1%|          | 7/1000 [18:10<42:53:08, 155.48s/it, lr=0.001, test_MAE=0.838, time=153, train_MAE=0.653, train_loss=0.69, val_MAE=0.782, val_loss=0.819]Epoch 7:   1%|          | 7/1000 [20:42<42:53:08, 155.48s/it, lr=0.001, test_MAE=0.718, time=152, train_MAE=0.648, train_loss=0.685, val_MAE=0.651, val_loss=0.688]Epoch 7:   1%|          | 8/1000 [20:42<42:35:33, 154.57s/it, lr=0.001, test_MAE=0.718, time=152, train_MAE=0.648, train_loss=0.685, val_MAE=0.651, val_loss=0.688]Epoch 8:   1%|          | 8/1000 [20:42<42:35:33, 154.57s/it, lr=0.001, test_MAE=0.718, time=152, train_MAE=0.648, train_loss=0.685, val_MAE=0.651, val_loss=0.688]Epoch 8:   1%|          | 8/1000 [23:14<42:35:33, 154.57s/it, lr=0.001, test_MAE=0.78, time=152, train_MAE=0.641, train_loss=0.679, val_MAE=0.74, val_loss=0.778]  Epoch 8:   1%|          | 9/1000 [23:14<42:20:24, 153.81s/it, lr=0.001, test_MAE=0.78, time=152, train_MAE=0.641, train_loss=0.679, val_MAE=0.74, val_loss=0.778]Epoch 9:   1%|          | 9/1000 [23:14<42:20:24, 153.81s/it, lr=0.001, test_MAE=0.78, time=152, train_MAE=0.641, train_loss=0.679, val_MAE=0.74, val_loss=0.778]Epoch 9:   1%|          | 9/1000 [25:48<42:20:24, 153.81s/it, lr=0.001, test_MAE=0.888, time=153, train_MAE=0.648, train_loss=0.686, val_MAE=0.843, val_loss=0.882]Epoch 9:   1%|          | 10/1000 [25:48<42:15:09, 153.65s/it, lr=0.001, test_MAE=0.888, time=153, train_MAE=0.648, train_loss=0.686, val_MAE=0.843, val_loss=0.882]Epoch 10:   1%|          | 10/1000 [25:48<42:15:09, 153.65s/it, lr=0.001, test_MAE=0.888, time=153, train_MAE=0.648, train_loss=0.686, val_MAE=0.843, val_loss=0.882]Epoch 10:   1%|          | 10/1000 [28:21<42:15:09, 153.65s/it, lr=0.001, test_MAE=0.824, time=153, train_MAE=0.634, train_loss=0.672, val_MAE=0.764, val_loss=0.802]Epoch 10:   1%|          | 11/1000 [28:21<42:10:31, 153.52s/it, lr=0.001, test_MAE=0.824, time=153, train_MAE=0.634, train_loss=0.672, val_MAE=0.764, val_loss=0.802]Epoch 11:   1%|          | 11/1000 [28:21<42:10:31, 153.52s/it, lr=0.001, test_MAE=0.824, time=153, train_MAE=0.634, train_loss=0.672, val_MAE=0.764, val_loss=0.802]Epoch 11:   1%|          | 11/1000 [30:54<42:10:31, 153.52s/it, lr=0.001, test_MAE=0.726, time=153, train_MAE=0.636, train_loss=0.675, val_MAE=0.672, val_loss=0.711]Epoch 11:   1%|          | 12/1000 [30:54<42:05:03, 153.34s/it, lr=0.001, test_MAE=0.726, time=153, train_MAE=0.636, train_loss=0.675, val_MAE=0.672, val_loss=0.711]Epoch 12:   1%|          | 12/1000 [30:54<42:05:03, 153.34s/it, lr=0.001, test_MAE=0.726, time=153, train_MAE=0.636, train_loss=0.675, val_MAE=0.672, val_loss=0.711]Epoch 12:   1%|          | 12/1000 [33:27<42:05:03, 153.34s/it, lr=0.001, test_MAE=1.13, time=154, train_MAE=0.633, train_loss=0.673, val_MAE=1.08, val_loss=1.12]   Epoch 12:   1%|▏         | 13/1000 [33:28<42:04:16, 153.45s/it, lr=0.001, test_MAE=1.13, time=154, train_MAE=0.633, train_loss=0.673, val_MAE=1.08, val_loss=1.12]Epoch 13:   1%|▏         | 13/1000 [33:28<42:04:16, 153.45s/it, lr=0.001, test_MAE=1.13, time=154, train_MAE=0.633, train_loss=0.673, val_MAE=1.08, val_loss=1.12]Epoch 13:   1%|▏         | 13/1000 [36:00<42:04:16, 153.45s/it, lr=0.001, test_MAE=2.79, time=153, train_MAE=0.623, train_loss=0.663, val_MAE=2.77, val_loss=2.81]Epoch    14: reducing learning rate of group 0 to 5.0000e-04.
Epoch 13:   1%|▏         | 14/1000 [36:00<41:57:11, 153.18s/it, lr=0.001, test_MAE=2.79, time=153, train_MAE=0.623, train_loss=0.663, val_MAE=2.77, val_loss=2.81]Epoch 14:   1%|▏         | 14/1000 [36:00<41:57:11, 153.18s/it, lr=0.001, test_MAE=2.79, time=153, train_MAE=0.623, train_loss=0.663, val_MAE=2.77, val_loss=2.81]Epoch 14:   1%|▏         | 14/1000 [38:32<41:57:11, 153.18s/it, lr=0.0005, test_MAE=1.13, time=152, train_MAE=0.614, train_loss=0.653, val_MAE=1.17, val_loss=1.21]Epoch 14:   2%|▏         | 15/1000 [38:32<41:47:18, 152.73s/it, lr=0.0005, test_MAE=1.13, time=152, train_MAE=0.614, train_loss=0.653, val_MAE=1.17, val_loss=1.21]Epoch 15:   2%|▏         | 15/1000 [38:32<41:47:18, 152.73s/it, lr=0.0005, test_MAE=1.13, time=152, train_MAE=0.614, train_loss=0.653, val_MAE=1.17, val_loss=1.21]Epoch 15:   2%|▏         | 15/1000 [41:05<41:47:18, 152.73s/it, lr=0.0005, test_MAE=0.812, time=153, train_MAE=0.593, train_loss=0.632, val_MAE=0.787, val_loss=0.827]Epoch 15:   2%|▏         | 16/1000 [41:05<41:47:07, 152.87s/it, lr=0.0005, test_MAE=0.812, time=153, train_MAE=0.593, train_loss=0.632, val_MAE=0.787, val_loss=0.827]Epoch 16:   2%|▏         | 16/1000 [41:05<41:47:07, 152.87s/it, lr=0.0005, test_MAE=0.812, time=153, train_MAE=0.593, train_loss=0.632, val_MAE=0.787, val_loss=0.827]Epoch 16:   2%|▏         | 16/1000 [43:38<41:47:07, 152.87s/it, lr=0.0005, test_MAE=0.679, time=153, train_MAE=0.598, train_loss=0.638, val_MAE=0.627, val_loss=0.667]Epoch 16:   2%|▏         | 17/1000 [43:38<41:44:44, 152.88s/it, lr=0.0005, test_MAE=0.679, time=153, train_MAE=0.598, train_loss=0.638, val_MAE=0.627, val_loss=0.667]Epoch 17:   2%|▏         | 17/1000 [43:38<41:44:44, 152.88s/it, lr=0.0005, test_MAE=0.679, time=153, train_MAE=0.598, train_loss=0.638, val_MAE=0.627, val_loss=0.667]Epoch 17:   2%|▏         | 17/1000 [46:11<41:44:44, 152.88s/it, lr=0.0005, test_MAE=0.699, time=154, train_MAE=0.598, train_loss=0.638, val_MAE=0.651, val_loss=0.691]Epoch 17:   2%|▏         | 18/1000 [46:12<41:45:47, 153.10s/it, lr=0.0005, test_MAE=0.699, time=154, train_MAE=0.598, train_loss=0.638, val_MAE=0.651, val_loss=0.691]Epoch 18:   2%|▏         | 18/1000 [46:12<41:45:47, 153.10s/it, lr=0.0005, test_MAE=0.699, time=154, train_MAE=0.598, train_loss=0.638, val_MAE=0.651, val_loss=0.691]Epoch 18:   2%|▏         | 18/1000 [48:45<41:45:47, 153.10s/it, lr=0.0005, test_MAE=0.691, time=153, train_MAE=0.59, train_loss=0.63, val_MAE=0.65, val_loss=0.69]    Epoch 18:   2%|▏         | 19/1000 [48:45<41:45:10, 153.22s/it, lr=0.0005, test_MAE=0.691, time=153, train_MAE=0.59, train_loss=0.63, val_MAE=0.65, val_loss=0.69]Epoch 19:   2%|▏         | 19/1000 [48:45<41:45:10, 153.22s/it, lr=0.0005, test_MAE=0.691, time=153, train_MAE=0.59, train_loss=0.63, val_MAE=0.65, val_loss=0.69]Epoch 19:   2%|▏         | 19/1000 [51:18<41:45:10, 153.22s/it, lr=0.0005, test_MAE=0.705, time=153, train_MAE=0.592, train_loss=0.632, val_MAE=0.644, val_loss=0.684]Epoch 19:   2%|▏         | 20/1000 [51:18<41:40:04, 153.07s/it, lr=0.0005, test_MAE=0.705, time=153, train_MAE=0.592, train_loss=0.632, val_MAE=0.644, val_loss=0.684]Epoch 20:   2%|▏         | 20/1000 [51:18<41:40:04, 153.07s/it, lr=0.0005, test_MAE=0.705, time=153, train_MAE=0.592, train_loss=0.632, val_MAE=0.644, val_loss=0.684]Epoch 20:   2%|▏         | 20/1000 [53:51<41:40:04, 153.07s/it, lr=0.0005, test_MAE=0.698, time=153, train_MAE=0.613, train_loss=0.653, val_MAE=0.66, val_loss=0.699] Epoch 20:   2%|▏         | 21/1000 [53:51<41:37:28, 153.06s/it, lr=0.0005, test_MAE=0.698, time=153, train_MAE=0.613, train_loss=0.653, val_MAE=0.66, val_loss=0.699]Epoch 21:   2%|▏         | 21/1000 [53:51<41:37:28, 153.06s/it, lr=0.0005, test_MAE=0.698, time=153, train_MAE=0.613, train_loss=0.653, val_MAE=0.66, val_loss=0.699]Epoch 21:   2%|▏         | 21/1000 [56:24<41:37:28, 153.06s/it, lr=0.0005, test_MAE=0.663, time=153, train_MAE=0.591, train_loss=0.631, val_MAE=0.616, val_loss=0.656]Epoch 21:   2%|▏         | 22/1000 [56:24<41:35:50, 153.12s/it, lr=0.0005, test_MAE=0.663, time=153, train_MAE=0.591, train_loss=0.631, val_MAE=0.616, val_loss=0.656]Epoch 22:   2%|▏         | 22/1000 [56:24<41:35:50, 153.12s/it, lr=0.0005, test_MAE=0.663, time=153, train_MAE=0.591, train_loss=0.631, val_MAE=0.616, val_loss=0.656]Epoch 22:   2%|▏         | 22/1000 [58:57<41:35:50, 153.12s/it, lr=0.0005, test_MAE=0.755, time=153, train_MAE=0.584, train_loss=0.624, val_MAE=0.71, val_loss=0.75]  Epoch 22:   2%|▏         | 23/1000 [58:57<41:31:14, 152.99s/it, lr=0.0005, test_MAE=0.755, time=153, train_MAE=0.584, train_loss=0.624, val_MAE=0.71, val_loss=0.75]Epoch 23:   2%|▏         | 23/1000 [58:57<41:31:14, 152.99s/it, lr=0.0005, test_MAE=0.755, time=153, train_MAE=0.584, train_loss=0.624, val_MAE=0.71, val_loss=0.75]Epoch 23:   2%|▏         | 23/1000 [1:01:30<41:31:14, 152.99s/it, lr=0.0005, test_MAE=0.741, time=154, train_MAE=0.588, train_loss=0.628, val_MAE=0.694, val_loss=0.734]Epoch 23:   2%|▏         | 24/1000 [1:01:31<41:32:34, 153.23s/it, lr=0.0005, test_MAE=0.741, time=154, train_MAE=0.588, train_loss=0.628, val_MAE=0.694, val_loss=0.734]Epoch 24:   2%|▏         | 24/1000 [1:01:31<41:32:34, 153.23s/it, lr=0.0005, test_MAE=0.741, time=154, train_MAE=0.588, train_loss=0.628, val_MAE=0.694, val_loss=0.734]Epoch 24:   2%|▏         | 24/1000 [1:04:02<41:32:34, 153.23s/it, lr=0.0005, test_MAE=0.774, time=151, train_MAE=0.587, train_loss=0.628, val_MAE=0.732, val_loss=0.772]Epoch 24:   2%|▎         | 25/1000 [1:04:02<41:19:29, 152.58s/it, lr=0.0005, test_MAE=0.774, time=151, train_MAE=0.587, train_loss=0.628, val_MAE=0.732, val_loss=0.772]Epoch 25:   2%|▎         | 25/1000 [1:04:02<41:19:29, 152.58s/it, lr=0.0005, test_MAE=0.774, time=151, train_MAE=0.587, train_loss=0.628, val_MAE=0.732, val_loss=0.772]Epoch 25:   2%|▎         | 25/1000 [1:06:30<41:19:29, 152.58s/it, lr=0.0005, test_MAE=0.68, time=148, train_MAE=0.586, train_loss=0.627, val_MAE=0.652, val_loss=0.692] Epoch 25:   3%|▎         | 26/1000 [1:06:30<40:55:26, 151.26s/it, lr=0.0005, test_MAE=0.68, time=148, train_MAE=0.586, train_loss=0.627, val_MAE=0.652, val_loss=0.692]Epoch 26:   3%|▎         | 26/1000 [1:06:30<40:55:26, 151.26s/it, lr=0.0005, test_MAE=0.68, time=148, train_MAE=0.586, train_loss=0.627, val_MAE=0.652, val_loss=0.692]Epoch 26:   3%|▎         | 26/1000 [1:08:57<40:55:26, 151.26s/it, lr=0.0005, test_MAE=0.764, time=147, train_MAE=0.584, train_loss=0.625, val_MAE=0.708, val_loss=0.749]Epoch 26:   3%|▎         | 27/1000 [1:08:57<40:31:48, 149.96s/it, lr=0.0005, test_MAE=0.764, time=147, train_MAE=0.584, train_loss=0.625, val_MAE=0.708, val_loss=0.749]Epoch 27:   3%|▎         | 27/1000 [1:08:57<40:31:48, 149.96s/it, lr=0.0005, test_MAE=0.764, time=147, train_MAE=0.584, train_loss=0.625, val_MAE=0.708, val_loss=0.749]Epoch 27:   3%|▎         | 27/1000 [1:11:24<40:31:48, 149.96s/it, lr=0.0005, test_MAE=0.672, time=148, train_MAE=0.584, train_loss=0.625, val_MAE=0.628, val_loss=0.668]Epoch    28: reducing learning rate of group 0 to 2.5000e-04.
Epoch 27:   3%|▎         | 28/1000 [1:11:24<40:18:12, 149.27s/it, lr=0.0005, test_MAE=0.672, time=148, train_MAE=0.584, train_loss=0.625, val_MAE=0.628, val_loss=0.668]Epoch 28:   3%|▎         | 28/1000 [1:11:24<40:18:12, 149.27s/it, lr=0.0005, test_MAE=0.672, time=148, train_MAE=0.584, train_loss=0.625, val_MAE=0.628, val_loss=0.668]Epoch 28:   3%|▎         | 28/1000 [1:13:51<40:18:12, 149.27s/it, lr=0.00025, test_MAE=0.648, time=147, train_MAE=0.565, train_loss=0.606, val_MAE=0.603, val_loss=0.643]Epoch 28:   3%|▎         | 29/1000 [1:13:51<40:05:07, 148.62s/it, lr=0.00025, test_MAE=0.648, time=147, train_MAE=0.565, train_loss=0.606, val_MAE=0.603, val_loss=0.643]Epoch 29:   3%|▎         | 29/1000 [1:13:51<40:05:07, 148.62s/it, lr=0.00025, test_MAE=0.648, time=147, train_MAE=0.565, train_loss=0.606, val_MAE=0.603, val_loss=0.643]Epoch 29:   3%|▎         | 29/1000 [1:16:19<40:05:07, 148.62s/it, lr=0.00025, test_MAE=0.883, time=148, train_MAE=0.568, train_loss=0.608, val_MAE=0.831, val_loss=0.872]Epoch 29:   3%|▎         | 30/1000 [1:16:19<39:58:27, 148.36s/it, lr=0.00025, test_MAE=0.883, time=148, train_MAE=0.568, train_loss=0.608, val_MAE=0.831, val_loss=0.872]Epoch 30:   3%|▎         | 30/1000 [1:16:19<39:58:27, 148.36s/it, lr=0.00025, test_MAE=0.883, time=148, train_MAE=0.568, train_loss=0.608, val_MAE=0.831, val_loss=0.872]Epoch 30:   3%|▎         | 30/1000 [1:18:46<39:58:27, 148.36s/it, lr=0.00025, test_MAE=0.651, time=147, train_MAE=0.558, train_loss=0.598, val_MAE=0.606, val_loss=0.646]Epoch 30:   3%|▎         | 31/1000 [1:18:46<39:48:23, 147.89s/it, lr=0.00025, test_MAE=0.651, time=147, train_MAE=0.558, train_loss=0.598, val_MAE=0.606, val_loss=0.646]Epoch 31:   3%|▎         | 31/1000 [1:18:46<39:48:23, 147.89s/it, lr=0.00025, test_MAE=0.651, time=147, train_MAE=0.558, train_loss=0.598, val_MAE=0.606, val_loss=0.646]Epoch 31:   3%|▎         | 31/1000 [1:21:11<39:48:23, 147.89s/it, lr=0.00025, test_MAE=0.678, time=145, train_MAE=0.557, train_loss=0.597, val_MAE=0.631, val_loss=0.671]Epoch 31:   3%|▎         | 32/1000 [1:21:11<39:34:26, 147.18s/it, lr=0.00025, test_MAE=0.678, time=145, train_MAE=0.557, train_loss=0.597, val_MAE=0.631, val_loss=0.671]Epoch 32:   3%|▎         | 32/1000 [1:21:11<39:34:26, 147.18s/it, lr=0.00025, test_MAE=0.678, time=145, train_MAE=0.557, train_loss=0.597, val_MAE=0.631, val_loss=0.671]Epoch 32:   3%|▎         | 32/1000 [1:23:37<39:34:26, 147.18s/it, lr=0.00025, test_MAE=0.778, time=146, train_MAE=0.565, train_loss=0.605, val_MAE=0.741, val_loss=0.781]Epoch 32:   3%|▎         | 33/1000 [1:23:37<39:24:24, 146.71s/it, lr=0.00025, test_MAE=0.778, time=146, train_MAE=0.565, train_loss=0.605, val_MAE=0.741, val_loss=0.781]Epoch 33:   3%|▎         | 33/1000 [1:23:37<39:24:24, 146.71s/it, lr=0.00025, test_MAE=0.778, time=146, train_MAE=0.565, train_loss=0.605, val_MAE=0.741, val_loss=0.781]Epoch 33:   3%|▎         | 33/1000 [1:26:02<39:24:24, 146.71s/it, lr=0.00025, test_MAE=1.07, time=145, train_MAE=0.552, train_loss=0.592, val_MAE=1.06, val_loss=1.1]    Epoch 33:   3%|▎         | 34/1000 [1:26:02<39:14:36, 146.25s/it, lr=0.00025, test_MAE=1.07, time=145, train_MAE=0.552, train_loss=0.592, val_MAE=1.06, val_loss=1.1]Epoch 34:   3%|▎         | 34/1000 [1:26:02<39:14:36, 146.25s/it, lr=0.00025, test_MAE=1.07, time=145, train_MAE=0.552, train_loss=0.592, val_MAE=1.06, val_loss=1.1]Epoch 34:   3%|▎         | 34/1000 [1:28:27<39:14:36, 146.25s/it, lr=0.00025, test_MAE=0.69, time=145, train_MAE=0.556, train_loss=0.596, val_MAE=0.666, val_loss=0.706]Epoch    35: reducing learning rate of group 0 to 1.2500e-04.
Epoch 34:   4%|▎         | 35/1000 [1:28:27<39:06:43, 145.91s/it, lr=0.00025, test_MAE=0.69, time=145, train_MAE=0.556, train_loss=0.596, val_MAE=0.666, val_loss=0.706]Epoch 35:   4%|▎         | 35/1000 [1:28:27<39:06:43, 145.91s/it, lr=0.00025, test_MAE=0.69, time=145, train_MAE=0.556, train_loss=0.596, val_MAE=0.666, val_loss=0.706]Epoch 35:   4%|▎         | 35/1000 [1:30:53<39:06:43, 145.91s/it, lr=0.000125, test_MAE=0.715, time=145, train_MAE=0.543, train_loss=0.583, val_MAE=0.684, val_loss=0.724]Epoch 35:   4%|▎         | 36/1000 [1:30:53<39:01:44, 145.75s/it, lr=0.000125, test_MAE=0.715, time=145, train_MAE=0.543, train_loss=0.583, val_MAE=0.684, val_loss=0.724]Epoch 36:   4%|▎         | 36/1000 [1:30:53<39:01:44, 145.75s/it, lr=0.000125, test_MAE=0.715, time=145, train_MAE=0.543, train_loss=0.583, val_MAE=0.684, val_loss=0.724]Epoch 36:   4%|▎         | 36/1000 [1:33:18<39:01:44, 145.75s/it, lr=0.000125, test_MAE=0.636, time=145, train_MAE=0.535, train_loss=0.575, val_MAE=0.597, val_loss=0.637]Epoch 36:   4%|▎         | 37/1000 [1:33:18<38:56:44, 145.59s/it, lr=0.000125, test_MAE=0.636, time=145, train_MAE=0.535, train_loss=0.575, val_MAE=0.597, val_loss=0.637]Epoch 37:   4%|▎         | 37/1000 [1:33:18<38:56:44, 145.59s/it, lr=0.000125, test_MAE=0.636, time=145, train_MAE=0.535, train_loss=0.575, val_MAE=0.597, val_loss=0.637]Epoch 37:   4%|▎         | 37/1000 [1:35:43<38:56:44, 145.59s/it, lr=0.000125, test_MAE=0.669, time=145, train_MAE=0.539, train_loss=0.579, val_MAE=0.625, val_loss=0.665]Epoch 37:   4%|▍         | 38/1000 [1:35:43<38:51:39, 145.43s/it, lr=0.000125, test_MAE=0.669, time=145, train_MAE=0.539, train_loss=0.579, val_MAE=0.625, val_loss=0.665]Epoch 38:   4%|▍         | 38/1000 [1:35:43<38:51:39, 145.43s/it, lr=0.000125, test_MAE=0.669, time=145, train_MAE=0.539, train_loss=0.579, val_MAE=0.625, val_loss=0.665]Epoch 38:   4%|▍         | 38/1000 [1:38:08<38:51:39, 145.43s/it, lr=0.000125, test_MAE=0.658, time=145, train_MAE=0.534, train_loss=0.573, val_MAE=0.609, val_loss=0.649]Epoch 38:   4%|▍         | 39/1000 [1:38:08<38:49:20, 145.43s/it, lr=0.000125, test_MAE=0.658, time=145, train_MAE=0.534, train_loss=0.573, val_MAE=0.609, val_loss=0.649]Epoch 39:   4%|▍         | 39/1000 [1:38:08<38:49:20, 145.43s/it, lr=0.000125, test_MAE=0.658, time=145, train_MAE=0.534, train_loss=0.573, val_MAE=0.609, val_loss=0.649]Epoch 39:   4%|▍         | 39/1000 [1:40:34<38:49:20, 145.43s/it, lr=0.000125, test_MAE=0.74, time=145, train_MAE=0.534, train_loss=0.574, val_MAE=0.708, val_loss=0.748] Epoch 39:   4%|▍         | 40/1000 [1:40:34<38:46:06, 145.38s/it, lr=0.000125, test_MAE=0.74, time=145, train_MAE=0.534, train_loss=0.574, val_MAE=0.708, val_loss=0.748]Epoch 40:   4%|▍         | 40/1000 [1:40:34<38:46:06, 145.38s/it, lr=0.000125, test_MAE=0.74, time=145, train_MAE=0.534, train_loss=0.574, val_MAE=0.708, val_loss=0.748]Epoch 40:   4%|▍         | 40/1000 [1:42:59<38:46:06, 145.38s/it, lr=0.000125, test_MAE=1.26, time=145, train_MAE=0.533, train_loss=0.573, val_MAE=1.18, val_loss=1.22]  Epoch 40:   4%|▍         | 41/1000 [1:42:59<38:43:19, 145.36s/it, lr=0.000125, test_MAE=1.26, time=145, train_MAE=0.533, train_loss=0.573, val_MAE=1.18, val_loss=1.22]Epoch 41:   4%|▍         | 41/1000 [1:42:59<38:43:19, 145.36s/it, lr=0.000125, test_MAE=1.26, time=145, train_MAE=0.533, train_loss=0.573, val_MAE=1.18, val_loss=1.22]Epoch 41:   4%|▍         | 41/1000 [1:45:25<38:43:19, 145.36s/it, lr=0.000125, test_MAE=0.67, time=146, train_MAE=0.531, train_loss=0.57, val_MAE=0.637, val_loss=0.677]Epoch 41:   4%|▍         | 42/1000 [1:45:25<38:43:52, 145.55s/it, lr=0.000125, test_MAE=0.67, time=146, train_MAE=0.531, train_loss=0.57, val_MAE=0.637, val_loss=0.677]Epoch 42:   4%|▍         | 42/1000 [1:45:25<38:43:52, 145.55s/it, lr=0.000125, test_MAE=0.67, time=146, train_MAE=0.531, train_loss=0.57, val_MAE=0.637, val_loss=0.677]Epoch 42:   4%|▍         | 42/1000 [1:47:51<38:43:52, 145.55s/it, lr=0.000125, test_MAE=0.643, time=146, train_MAE=0.534, train_loss=0.574, val_MAE=0.609, val_loss=0.649]Epoch    43: reducing learning rate of group 0 to 6.2500e-05.
Epoch 42:   4%|▍         | 43/1000 [1:47:51<38:41:38, 145.56s/it, lr=0.000125, test_MAE=0.643, time=146, train_MAE=0.534, train_loss=0.574, val_MAE=0.609, val_loss=0.649]Epoch 43:   4%|▍         | 43/1000 [1:47:51<38:41:38, 145.56s/it, lr=0.000125, test_MAE=0.643, time=146, train_MAE=0.534, train_loss=0.574, val_MAE=0.609, val_loss=0.649]Epoch 43:   4%|▍         | 43/1000 [1:50:17<38:41:38, 145.56s/it, lr=6.25e-5, test_MAE=0.627, time=146, train_MAE=0.522, train_loss=0.562, val_MAE=0.593, val_loss=0.633] Epoch 43:   4%|▍         | 44/1000 [1:50:17<38:41:08, 145.68s/it, lr=6.25e-5, test_MAE=0.627, time=146, train_MAE=0.522, train_loss=0.562, val_MAE=0.593, val_loss=0.633]Epoch 44:   4%|▍         | 44/1000 [1:50:17<38:41:08, 145.68s/it, lr=6.25e-5, test_MAE=0.627, time=146, train_MAE=0.522, train_loss=0.562, val_MAE=0.593, val_loss=0.633]Epoch 44:   4%|▍         | 44/1000 [1:52:42<38:41:08, 145.68s/it, lr=6.25e-5, test_MAE=0.641, time=146, train_MAE=0.52, train_loss=0.56, val_MAE=0.599, val_loss=0.639]  Epoch 44:   4%|▍         | 45/1000 [1:52:42<38:39:02, 145.70s/it, lr=6.25e-5, test_MAE=0.641, time=146, train_MAE=0.52, train_loss=0.56, val_MAE=0.599, val_loss=0.639]Epoch 45:   4%|▍         | 45/1000 [1:52:42<38:39:02, 145.70s/it, lr=6.25e-5, test_MAE=0.641, time=146, train_MAE=0.52, train_loss=0.56, val_MAE=0.599, val_loss=0.639]Epoch 45:   4%|▍         | 45/1000 [1:55:08<38:39:02, 145.70s/it, lr=6.25e-5, test_MAE=0.636, time=146, train_MAE=0.523, train_loss=0.562, val_MAE=0.594, val_loss=0.634]Epoch 45:   5%|▍         | 46/1000 [1:55:08<38:37:31, 145.76s/it, lr=6.25e-5, test_MAE=0.636, time=146, train_MAE=0.523, train_loss=0.562, val_MAE=0.594, val_loss=0.634]Epoch 46:   5%|▍         | 46/1000 [1:55:08<38:37:31, 145.76s/it, lr=6.25e-5, test_MAE=0.636, time=146, train_MAE=0.523, train_loss=0.562, val_MAE=0.594, val_loss=0.634]Epoch 46:   5%|▍         | 46/1000 [1:57:34<38:37:31, 145.76s/it, lr=6.25e-5, test_MAE=0.629, time=146, train_MAE=0.515, train_loss=0.555, val_MAE=0.591, val_loss=0.631]Epoch 46:   5%|▍         | 47/1000 [1:57:34<38:35:52, 145.81s/it, lr=6.25e-5, test_MAE=0.629, time=146, train_MAE=0.515, train_loss=0.555, val_MAE=0.591, val_loss=0.631]Epoch 47:   5%|▍         | 47/1000 [1:57:34<38:35:52, 145.81s/it, lr=6.25e-5, test_MAE=0.629, time=146, train_MAE=0.515, train_loss=0.555, val_MAE=0.591, val_loss=0.631]Epoch 47:   5%|▍         | 47/1000 [2:00:00<38:35:52, 145.81s/it, lr=6.25e-5, test_MAE=0.636, time=146, train_MAE=0.51, train_loss=0.55, val_MAE=0.607, val_loss=0.647]  Epoch 47:   5%|▍         | 48/1000 [2:00:00<38:33:52, 145.83s/it, lr=6.25e-5, test_MAE=0.636, time=146, train_MAE=0.51, train_loss=0.55, val_MAE=0.607, val_loss=0.647]Epoch 48:   5%|▍         | 48/1000 [2:00:00<38:33:52, 145.83s/it, lr=6.25e-5, test_MAE=0.636, time=146, train_MAE=0.51, train_loss=0.55, val_MAE=0.607, val_loss=0.647]Epoch 48:   5%|▍         | 48/1000 [2:02:26<38:33:52, 145.83s/it, lr=6.25e-5, test_MAE=0.627, time=146, train_MAE=0.514, train_loss=0.554, val_MAE=0.592, val_loss=0.632]Epoch 48:   5%|▍         | 49/1000 [2:02:26<38:30:40, 145.78s/it, lr=6.25e-5, test_MAE=0.627, time=146, train_MAE=0.514, train_loss=0.554, val_MAE=0.592, val_loss=0.632]Epoch 49:   5%|▍         | 49/1000 [2:02:26<38:30:40, 145.78s/it, lr=6.25e-5, test_MAE=0.627, time=146, train_MAE=0.514, train_loss=0.554, val_MAE=0.592, val_loss=0.632]Epoch 49:   5%|▍         | 49/1000 [2:04:52<38:30:40, 145.78s/it, lr=6.25e-5, test_MAE=1.95, time=146, train_MAE=0.504, train_loss=0.544, val_MAE=1.88, val_loss=1.92]   Epoch 49:   5%|▌         | 50/1000 [2:04:52<38:30:46, 145.94s/it, lr=6.25e-5, test_MAE=1.95, time=146, train_MAE=0.504, train_loss=0.544, val_MAE=1.88, val_loss=1.92]Epoch 50:   5%|▌         | 50/1000 [2:04:52<38:30:46, 145.94s/it, lr=6.25e-5, test_MAE=1.95, time=146, train_MAE=0.504, train_loss=0.544, val_MAE=1.88, val_loss=1.92]Epoch 50:   5%|▌         | 50/1000 [2:07:18<38:30:46, 145.94s/it, lr=6.25e-5, test_MAE=0.63, time=146, train_MAE=0.507, train_loss=0.547, val_MAE=0.596, val_loss=0.635]Epoch 50:   5%|▌         | 51/1000 [2:07:18<38:27:24, 145.88s/it, lr=6.25e-5, test_MAE=0.63, time=146, train_MAE=0.507, train_loss=0.547, val_MAE=0.596, val_loss=0.635]Epoch 51:   5%|▌         | 51/1000 [2:07:18<38:27:24, 145.88s/it, lr=6.25e-5, test_MAE=0.63, time=146, train_MAE=0.507, train_loss=0.547, val_MAE=0.596, val_loss=0.635]Epoch 51:   5%|▌         | 51/1000 [2:09:43<38:27:24, 145.88s/it, lr=6.25e-5, test_MAE=0.625, time=146, train_MAE=0.504, train_loss=0.543, val_MAE=0.583, val_loss=0.623]Epoch 51:   5%|▌         | 52/1000 [2:09:43<38:23:53, 145.82s/it, lr=6.25e-5, test_MAE=0.625, time=146, train_MAE=0.504, train_loss=0.543, val_MAE=0.583, val_loss=0.623]Epoch 52:   5%|▌         | 52/1000 [2:09:43<38:23:53, 145.82s/it, lr=6.25e-5, test_MAE=0.625, time=146, train_MAE=0.504, train_loss=0.543, val_MAE=0.583, val_loss=0.623]Epoch 52:   5%|▌         | 52/1000 [2:12:09<38:23:53, 145.82s/it, lr=6.25e-5, test_MAE=0.751, time=146, train_MAE=0.507, train_loss=0.547, val_MAE=0.678, val_loss=0.717]Epoch 52:   5%|▌         | 53/1000 [2:12:09<38:21:03, 145.79s/it, lr=6.25e-5, test_MAE=0.751, time=146, train_MAE=0.507, train_loss=0.547, val_MAE=0.678, val_loss=0.717]Epoch 53:   5%|▌         | 53/1000 [2:12:09<38:21:03, 145.79s/it, lr=6.25e-5, test_MAE=0.751, time=146, train_MAE=0.507, train_loss=0.547, val_MAE=0.678, val_loss=0.717]Epoch 53:   5%|▌         | 53/1000 [2:14:35<38:21:03, 145.79s/it, lr=6.25e-5, test_MAE=0.639, time=145, train_MAE=0.508, train_loss=0.548, val_MAE=0.583, val_loss=0.622]Epoch 53:   5%|▌         | 54/1000 [2:14:35<38:17:02, 145.69s/it, lr=6.25e-5, test_MAE=0.639, time=145, train_MAE=0.508, train_loss=0.548, val_MAE=0.583, val_loss=0.622]Epoch 54:   5%|▌         | 54/1000 [2:14:35<38:17:02, 145.69s/it, lr=6.25e-5, test_MAE=0.639, time=145, train_MAE=0.508, train_loss=0.548, val_MAE=0.583, val_loss=0.622]Epoch 54:   5%|▌         | 54/1000 [2:17:00<38:17:02, 145.69s/it, lr=6.25e-5, test_MAE=0.631, time=145, train_MAE=0.507, train_loss=0.546, val_MAE=0.589, val_loss=0.629]Epoch 54:   6%|▌         | 55/1000 [2:17:00<38:11:57, 145.52s/it, lr=6.25e-5, test_MAE=0.631, time=145, train_MAE=0.507, train_loss=0.546, val_MAE=0.589, val_loss=0.629]Epoch 55:   6%|▌         | 55/1000 [2:17:00<38:11:57, 145.52s/it, lr=6.25e-5, test_MAE=0.631, time=145, train_MAE=0.507, train_loss=0.546, val_MAE=0.589, val_loss=0.629]Epoch 55:   6%|▌         | 55/1000 [2:19:25<38:11:57, 145.52s/it, lr=6.25e-5, test_MAE=0.703, time=146, train_MAE=0.513, train_loss=0.553, val_MAE=0.674, val_loss=0.714]Epoch 55:   6%|▌         | 56/1000 [2:19:25<38:10:07, 145.56s/it, lr=6.25e-5, test_MAE=0.703, time=146, train_MAE=0.513, train_loss=0.553, val_MAE=0.674, val_loss=0.714]Epoch 56:   6%|▌         | 56/1000 [2:19:25<38:10:07, 145.56s/it, lr=6.25e-5, test_MAE=0.703, time=146, train_MAE=0.513, train_loss=0.553, val_MAE=0.674, val_loss=0.714]Epoch 56:   6%|▌         | 56/1000 [2:21:51<38:10:07, 145.56s/it, lr=6.25e-5, test_MAE=0.687, time=145, train_MAE=0.506, train_loss=0.545, val_MAE=0.624, val_loss=0.664]Epoch 56:   6%|▌         | 57/1000 [2:21:51<38:07:15, 145.53s/it, lr=6.25e-5, test_MAE=0.687, time=145, train_MAE=0.506, train_loss=0.545, val_MAE=0.624, val_loss=0.664]Epoch 57:   6%|▌         | 57/1000 [2:21:51<38:07:15, 145.53s/it, lr=6.25e-5, test_MAE=0.687, time=145, train_MAE=0.506, train_loss=0.545, val_MAE=0.624, val_loss=0.664]Epoch 57:   6%|▌         | 57/1000 [2:24:16<38:07:15, 145.53s/it, lr=6.25e-5, test_MAE=0.707, time=145, train_MAE=0.504, train_loss=0.544, val_MAE=0.66, val_loss=0.7]   Epoch 57:   6%|▌         | 58/1000 [2:24:16<38:03:04, 145.42s/it, lr=6.25e-5, test_MAE=0.707, time=145, train_MAE=0.504, train_loss=0.544, val_MAE=0.66, val_loss=0.7]Epoch 58:   6%|▌         | 58/1000 [2:24:16<38:03:04, 145.42s/it, lr=6.25e-5, test_MAE=0.707, time=145, train_MAE=0.504, train_loss=0.544, val_MAE=0.66, val_loss=0.7]Epoch 58:   6%|▌         | 58/1000 [2:26:42<38:03:04, 145.42s/it, lr=6.25e-5, test_MAE=0.641, time=146, train_MAE=0.505, train_loss=0.545, val_MAE=0.591, val_loss=0.631]Epoch 58:   6%|▌         | 59/1000 [2:26:42<38:01:46, 145.49s/it, lr=6.25e-5, test_MAE=0.641, time=146, train_MAE=0.505, train_loss=0.545, val_MAE=0.591, val_loss=0.631]Epoch 59:   6%|▌         | 59/1000 [2:26:42<38:01:46, 145.49s/it, lr=6.25e-5, test_MAE=0.641, time=146, train_MAE=0.505, train_loss=0.545, val_MAE=0.591, val_loss=0.631]Epoch 59:   6%|▌         | 59/1000 [2:29:07<38:01:46, 145.49s/it, lr=6.25e-5, test_MAE=0.666, time=145, train_MAE=0.504, train_loss=0.543, val_MAE=0.628, val_loss=0.668]Epoch    60: reducing learning rate of group 0 to 3.1250e-05.
Epoch 59:   6%|▌         | 60/1000 [2:29:07<37:59:15, 145.48s/it, lr=6.25e-5, test_MAE=0.666, time=145, train_MAE=0.504, train_loss=0.543, val_MAE=0.628, val_loss=0.668]Epoch 60:   6%|▌         | 60/1000 [2:29:07<37:59:15, 145.48s/it, lr=6.25e-5, test_MAE=0.666, time=145, train_MAE=0.504, train_loss=0.543, val_MAE=0.628, val_loss=0.668]Epoch 60:   6%|▌         | 60/1000 [2:31:32<37:59:15, 145.48s/it, lr=3.13e-5, test_MAE=0.628, time=145, train_MAE=0.498, train_loss=0.537, val_MAE=0.593, val_loss=0.632]Epoch 60:   6%|▌         | 61/1000 [2:31:32<37:56:12, 145.44s/it, lr=3.13e-5, test_MAE=0.628, time=145, train_MAE=0.498, train_loss=0.537, val_MAE=0.593, val_loss=0.632]Epoch 61:   6%|▌         | 61/1000 [2:31:32<37:56:12, 145.44s/it, lr=3.13e-5, test_MAE=0.628, time=145, train_MAE=0.498, train_loss=0.537, val_MAE=0.593, val_loss=0.632]Epoch 61:   6%|▌         | 61/1000 [2:33:58<37:56:12, 145.44s/it, lr=3.13e-5, test_MAE=0.625, time=146, train_MAE=0.49, train_loss=0.529, val_MAE=0.577, val_loss=0.617] Epoch 61:   6%|▌         | 62/1000 [2:33:58<37:55:39, 145.56s/it, lr=3.13e-5, test_MAE=0.625, time=146, train_MAE=0.49, train_loss=0.529, val_MAE=0.577, val_loss=0.617]Epoch 62:   6%|▌         | 62/1000 [2:33:58<37:55:39, 145.56s/it, lr=3.13e-5, test_MAE=0.625, time=146, train_MAE=0.49, train_loss=0.529, val_MAE=0.577, val_loss=0.617]Epoch 62:   6%|▌         | 62/1000 [2:36:24<37:55:39, 145.56s/it, lr=3.13e-5, test_MAE=0.629, time=145, train_MAE=0.499, train_loss=0.539, val_MAE=0.593, val_loss=0.632]Epoch 62:   6%|▋         | 63/1000 [2:36:24<37:52:06, 145.49s/it, lr=3.13e-5, test_MAE=0.629, time=145, train_MAE=0.499, train_loss=0.539, val_MAE=0.593, val_loss=0.632]Epoch 63:   6%|▋         | 63/1000 [2:36:24<37:52:06, 145.49s/it, lr=3.13e-5, test_MAE=0.629, time=145, train_MAE=0.499, train_loss=0.539, val_MAE=0.593, val_loss=0.632]Epoch 63:   6%|▋         | 63/1000 [2:38:49<37:52:06, 145.49s/it, lr=3.13e-5, test_MAE=0.63, time=146, train_MAE=0.49, train_loss=0.529, val_MAE=0.584, val_loss=0.623]  Epoch 63:   6%|▋         | 64/1000 [2:38:49<37:50:51, 145.57s/it, lr=3.13e-5, test_MAE=0.63, time=146, train_MAE=0.49, train_loss=0.529, val_MAE=0.584, val_loss=0.623]Epoch 64:   6%|▋         | 64/1000 [2:38:49<37:50:51, 145.57s/it, lr=3.13e-5, test_MAE=0.63, time=146, train_MAE=0.49, train_loss=0.529, val_MAE=0.584, val_loss=0.623]Epoch 64:   6%|▋         | 64/1000 [2:41:15<37:50:51, 145.57s/it, lr=3.13e-5, test_MAE=0.663, time=145, train_MAE=0.487, train_loss=0.526, val_MAE=0.604, val_loss=0.643]Epoch 64:   6%|▋         | 65/1000 [2:41:15<37:48:09, 145.55s/it, lr=3.13e-5, test_MAE=0.663, time=145, train_MAE=0.487, train_loss=0.526, val_MAE=0.604, val_loss=0.643]Epoch 65:   6%|▋         | 65/1000 [2:41:15<37:48:09, 145.55s/it, lr=3.13e-5, test_MAE=0.663, time=145, train_MAE=0.487, train_loss=0.526, val_MAE=0.604, val_loss=0.643]Epoch 65:   6%|▋         | 65/1000 [2:43:41<37:48:09, 145.55s/it, lr=3.13e-5, test_MAE=0.634, time=146, train_MAE=0.485, train_loss=0.524, val_MAE=0.579, val_loss=0.619]Epoch 65:   7%|▋         | 66/1000 [2:43:41<37:46:07, 145.58s/it, lr=3.13e-5, test_MAE=0.634, time=146, train_MAE=0.485, train_loss=0.524, val_MAE=0.579, val_loss=0.619]Epoch 66:   7%|▋         | 66/1000 [2:43:41<37:46:07, 145.58s/it, lr=3.13e-5, test_MAE=0.634, time=146, train_MAE=0.485, train_loss=0.524, val_MAE=0.579, val_loss=0.619]Epoch 66:   7%|▋         | 66/1000 [2:46:06<37:46:07, 145.58s/it, lr=3.13e-5, test_MAE=0.645, time=146, train_MAE=0.485, train_loss=0.524, val_MAE=0.596, val_loss=0.635]Epoch 66:   7%|▋         | 67/1000 [2:46:06<37:45:05, 145.67s/it, lr=3.13e-5, test_MAE=0.645, time=146, train_MAE=0.485, train_loss=0.524, val_MAE=0.596, val_loss=0.635]Epoch 67:   7%|▋         | 67/1000 [2:46:06<37:45:05, 145.67s/it, lr=3.13e-5, test_MAE=0.645, time=146, train_MAE=0.485, train_loss=0.524, val_MAE=0.596, val_loss=0.635]Epoch 67:   7%|▋         | 67/1000 [2:48:32<37:45:05, 145.67s/it, lr=3.13e-5, test_MAE=0.674, time=145, train_MAE=0.499, train_loss=0.538, val_MAE=0.64, val_loss=0.679] Epoch    68: reducing learning rate of group 0 to 1.5625e-05.
Epoch 67:   7%|▋         | 68/1000 [2:48:32<37:41:47, 145.61s/it, lr=3.13e-5, test_MAE=0.674, time=145, train_MAE=0.499, train_loss=0.538, val_MAE=0.64, val_loss=0.679]Epoch 68:   7%|▋         | 68/1000 [2:48:32<37:41:47, 145.61s/it, lr=3.13e-5, test_MAE=0.674, time=145, train_MAE=0.499, train_loss=0.538, val_MAE=0.64, val_loss=0.679]Epoch 68:   7%|▋         | 68/1000 [2:50:57<37:41:47, 145.61s/it, lr=1.56e-5, test_MAE=0.633, time=145, train_MAE=0.479, train_loss=0.518, val_MAE=0.582, val_loss=0.621]Epoch 68:   7%|▋         | 69/1000 [2:50:57<37:37:47, 145.51s/it, lr=1.56e-5, test_MAE=0.633, time=145, train_MAE=0.479, train_loss=0.518, val_MAE=0.582, val_loss=0.621]Epoch 69:   7%|▋         | 69/1000 [2:50:57<37:37:47, 145.51s/it, lr=1.56e-5, test_MAE=0.633, time=145, train_MAE=0.479, train_loss=0.518, val_MAE=0.582, val_loss=0.621]Epoch 69:   7%|▋         | 69/1000 [2:53:23<37:37:47, 145.51s/it, lr=1.56e-5, test_MAE=0.635, time=146, train_MAE=0.478, train_loss=0.517, val_MAE=0.583, val_loss=0.622]Epoch 69:   7%|▋         | 70/1000 [2:53:23<37:38:21, 145.70s/it, lr=1.56e-5, test_MAE=0.635, time=146, train_MAE=0.478, train_loss=0.517, val_MAE=0.583, val_loss=0.622]Epoch 70:   7%|▋         | 70/1000 [2:53:23<37:38:21, 145.70s/it, lr=1.56e-5, test_MAE=0.635, time=146, train_MAE=0.478, train_loss=0.517, val_MAE=0.583, val_loss=0.622]Epoch 70:   7%|▋         | 70/1000 [2:55:49<37:38:21, 145.70s/it, lr=1.56e-5, test_MAE=0.631, time=146, train_MAE=0.476, train_loss=0.516, val_MAE=0.585, val_loss=0.624]Epoch 70:   7%|▋         | 71/1000 [2:55:49<37:35:25, 145.67s/it, lr=1.56e-5, test_MAE=0.631, time=146, train_MAE=0.476, train_loss=0.516, val_MAE=0.585, val_loss=0.624]Epoch 71:   7%|▋         | 71/1000 [2:55:49<37:35:25, 145.67s/it, lr=1.56e-5, test_MAE=0.631, time=146, train_MAE=0.476, train_loss=0.516, val_MAE=0.585, val_loss=0.624]Epoch 71:   7%|▋         | 71/1000 [2:58:14<37:35:25, 145.67s/it, lr=1.56e-5, test_MAE=0.628, time=145, train_MAE=0.471, train_loss=0.51, val_MAE=0.582, val_loss=0.621] Epoch 71:   7%|▋         | 72/1000 [2:58:14<37:30:17, 145.49s/it, lr=1.56e-5, test_MAE=0.628, time=145, train_MAE=0.471, train_loss=0.51, val_MAE=0.582, val_loss=0.621]Epoch 72:   7%|▋         | 72/1000 [2:58:14<37:30:17, 145.49s/it, lr=1.56e-5, test_MAE=0.628, time=145, train_MAE=0.471, train_loss=0.51, val_MAE=0.582, val_loss=0.621]Epoch 72:   7%|▋         | 72/1000 [3:00:40<37:30:17, 145.49s/it, lr=1.56e-5, test_MAE=0.629, time=146, train_MAE=0.478, train_loss=0.517, val_MAE=0.578, val_loss=0.618]Epoch 72:   7%|▋         | 73/1000 [3:00:40<37:29:04, 145.57s/it, lr=1.56e-5, test_MAE=0.629, time=146, train_MAE=0.478, train_loss=0.517, val_MAE=0.578, val_loss=0.618]Epoch 73:   7%|▋         | 73/1000 [3:00:40<37:29:04, 145.57s/it, lr=1.56e-5, test_MAE=0.629, time=146, train_MAE=0.478, train_loss=0.517, val_MAE=0.578, val_loss=0.618]Epoch 73:   7%|▋         | 73/1000 [3:03:05<37:29:04, 145.57s/it, lr=1.56e-5, test_MAE=0.631, time=145, train_MAE=0.476, train_loss=0.515, val_MAE=0.578, val_loss=0.617]Epoch    74: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 73:   7%|▋         | 73/1000 [3:03:05<38:45:03, 150.49s/it, lr=1.56e-5, test_MAE=0.631, time=145, train_MAE=0.476, train_loss=0.515, val_MAE=0.578, val_loss=0.617]
Test MAE: 0.6306
Train MAE: 0.4547
Convergence Time (Epochs): 73.0000
TOTAL TIME TAKEN: 11050.4127s
AVG TIME PER EPOCH: 148.4349s
