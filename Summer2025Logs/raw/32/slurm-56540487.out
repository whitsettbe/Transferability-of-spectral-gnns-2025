I'm echoing to stdout
I'm echoing to stderr
My JobID is 56540487
I have 8 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.0581s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 4, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'rational_vec', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_all', 'num_eigs': 15, 'bias_mode': 'spatial', 'eigval_hidden_dim': 5, 'eigval_num_hidden_layer': 3, 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 5, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/zinc_train_rec_full.csv', 'test': 'supp_data/molecules/zinc_test_rec_full.csv', 'val': 'supp_data/molecules/zinc_val_rec_full.csv'}, 'fixMissingPhi1': False, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [02:23<?, ?it/s, lr=0.001, test_MAE=1.53, time=143, train_MAE=1.41, train_loss=1.55, val_MAE=1.43, val_loss=1.61]Epoch 0:   0%|          | 1/1000 [02:23<39:46:31, 143.33s/it, lr=0.001, test_MAE=1.53, time=143, train_MAE=1.41, train_loss=1.55, val_MAE=1.43, val_loss=1.61]Epoch 1:   0%|          | 1/1000 [02:23<39:46:31, 143.33s/it, lr=0.001, test_MAE=1.53, time=143, train_MAE=1.41, train_loss=1.55, val_MAE=1.43, val_loss=1.61]Epoch 1:   0%|          | 1/1000 [04:29<39:46:31, 143.33s/it, lr=0.001, test_MAE=1.52, time=126, train_MAE=1.34, train_loss=1.53, val_MAE=1.46, val_loss=1.67]Epoch 1:   0%|          | 2/1000 [04:29<38:17:54, 138.15s/it, lr=0.001, test_MAE=1.52, time=126, train_MAE=1.34, train_loss=1.53, val_MAE=1.46, val_loss=1.67]Epoch 2:   0%|          | 2/1000 [04:29<38:17:54, 138.15s/it, lr=0.001, test_MAE=1.52, time=126, train_MAE=1.34, train_loss=1.53, val_MAE=1.46, val_loss=1.67]Epoch 2:   0%|          | 2/1000 [06:35<38:17:54, 138.15s/it, lr=0.001, test_MAE=1.55, time=126, train_MAE=1.29, train_loss=1.51, val_MAE=1.51, val_loss=1.75]Epoch 2:   0%|          | 3/1000 [06:35<37:16:00, 134.56s/it, lr=0.001, test_MAE=1.55, time=126, train_MAE=1.29, train_loss=1.51, val_MAE=1.51, val_loss=1.75]Epoch 3:   0%|          | 3/1000 [06:35<37:16:00, 134.56s/it, lr=0.001, test_MAE=1.55, time=126, train_MAE=1.29, train_loss=1.51, val_MAE=1.51, val_loss=1.75]Epoch 3:   0%|          | 3/1000 [08:41<37:16:00, 134.56s/it, lr=0.001, test_MAE=1.54, time=126, train_MAE=1.23, train_loss=1.48, val_MAE=1.47, val_loss=1.73]Epoch 3:   0%|          | 4/1000 [08:41<36:32:26, 132.07s/it, lr=0.001, test_MAE=1.54, time=126, train_MAE=1.23, train_loss=1.48, val_MAE=1.47, val_loss=1.73]Epoch 4:   0%|          | 4/1000 [08:41<36:32:26, 132.07s/it, lr=0.001, test_MAE=1.54, time=126, train_MAE=1.23, train_loss=1.48, val_MAE=1.47, val_loss=1.73]Epoch 4:   0%|          | 4/1000 [10:47<36:32:26, 132.07s/it, lr=0.001, test_MAE=1.41, time=126, train_MAE=1.17, train_loss=1.44, val_MAE=1.38, val_loss=1.65]Epoch 4:   0%|          | 5/1000 [10:48<36:00:54, 130.31s/it, lr=0.001, test_MAE=1.41, time=126, train_MAE=1.17, train_loss=1.44, val_MAE=1.38, val_loss=1.65]Epoch 5:   0%|          | 5/1000 [10:48<36:00:54, 130.31s/it, lr=0.001, test_MAE=1.41, time=126, train_MAE=1.17, train_loss=1.44, val_MAE=1.38, val_loss=1.65]Epoch 5:   0%|          | 5/1000 [12:54<36:00:54, 130.31s/it, lr=0.001, test_MAE=1.48, time=126, train_MAE=1.09, train_loss=1.37, val_MAE=1.46, val_loss=1.74]Epoch 5:   1%|          | 6/1000 [12:54<35:38:32, 129.09s/it, lr=0.001, test_MAE=1.48, time=126, train_MAE=1.09, train_loss=1.37, val_MAE=1.46, val_loss=1.74]Epoch 6:   1%|          | 6/1000 [12:54<35:38:32, 129.09s/it, lr=0.001, test_MAE=1.48, time=126, train_MAE=1.09, train_loss=1.37, val_MAE=1.46, val_loss=1.74]Epoch 6:   1%|          | 6/1000 [15:00<35:38:32, 129.09s/it, lr=0.001, test_MAE=1.47, time=127, train_MAE=1.01, train_loss=1.31, val_MAE=1.4, val_loss=1.69] Epoch     7: reducing learning rate of group 0 to 5.0000e-04.
Epoch 6:   1%|          | 7/1000 [15:00<35:24:35, 128.37s/it, lr=0.001, test_MAE=1.47, time=127, train_MAE=1.01, train_loss=1.31, val_MAE=1.4, val_loss=1.69]Epoch 7:   1%|          | 7/1000 [15:00<35:24:35, 128.37s/it, lr=0.001, test_MAE=1.47, time=127, train_MAE=1.01, train_loss=1.31, val_MAE=1.4, val_loss=1.69]Epoch 7:   1%|          | 7/1000 [17:07<35:24:35, 128.37s/it, lr=0.0005, test_MAE=1.72, time=126, train_MAE=0.934, train_loss=1.23, val_MAE=1.64, val_loss=1.94]Epoch 7:   1%|          | 8/1000 [17:07<35:12:29, 127.77s/it, lr=0.0005, test_MAE=1.72, time=126, train_MAE=0.934, train_loss=1.23, val_MAE=1.64, val_loss=1.94]Epoch 8:   1%|          | 8/1000 [17:07<35:12:29, 127.77s/it, lr=0.0005, test_MAE=1.72, time=126, train_MAE=0.934, train_loss=1.23, val_MAE=1.64, val_loss=1.94]Epoch 8:   1%|          | 8/1000 [19:13<35:12:29, 127.77s/it, lr=0.0005, test_MAE=1.39, time=126, train_MAE=0.874, train_loss=1.17, val_MAE=1.3, val_loss=1.6]  Epoch 8:   1%|          | 9/1000 [19:13<35:01:23, 127.23s/it, lr=0.0005, test_MAE=1.39, time=126, train_MAE=0.874, train_loss=1.17, val_MAE=1.3, val_loss=1.6]Epoch 9:   1%|          | 9/1000 [19:13<35:01:23, 127.23s/it, lr=0.0005, test_MAE=1.39, time=126, train_MAE=0.874, train_loss=1.17, val_MAE=1.3, val_loss=1.6]Epoch 9:   1%|          | 9/1000 [21:19<35:01:23, 127.23s/it, lr=0.0005, test_MAE=1.25, time=126, train_MAE=0.849, train_loss=1.15, val_MAE=1.36, val_loss=1.66]Epoch 9:   1%|          | 10/1000 [21:19<34:55:48, 127.02s/it, lr=0.0005, test_MAE=1.25, time=126, train_MAE=0.849, train_loss=1.15, val_MAE=1.36, val_loss=1.66]Epoch 10:   1%|          | 10/1000 [21:19<34:55:48, 127.02s/it, lr=0.0005, test_MAE=1.25, time=126, train_MAE=0.849, train_loss=1.15, val_MAE=1.36, val_loss=1.66]Epoch 10:   1%|          | 10/1000 [23:25<34:55:48, 127.02s/it, lr=0.0005, test_MAE=1.18, time=126, train_MAE=0.815, train_loss=1.12, val_MAE=1.1, val_loss=1.4]  Epoch 10:   1%|          | 11/1000 [23:25<34:48:24, 126.70s/it, lr=0.0005, test_MAE=1.18, time=126, train_MAE=0.815, train_loss=1.12, val_MAE=1.1, val_loss=1.4]Epoch 11:   1%|          | 11/1000 [23:25<34:48:24, 126.70s/it, lr=0.0005, test_MAE=1.18, time=126, train_MAE=0.815, train_loss=1.12, val_MAE=1.1, val_loss=1.4]Epoch 11:   1%|          | 11/1000 [25:33<34:48:24, 126.70s/it, lr=0.0005, test_MAE=1.14, time=128, train_MAE=0.817, train_loss=1.12, val_MAE=1.08, val_loss=1.39]Epoch 11:   1%|          | 12/1000 [25:33<34:50:35, 126.96s/it, lr=0.0005, test_MAE=1.14, time=128, train_MAE=0.817, train_loss=1.12, val_MAE=1.08, val_loss=1.39]Epoch 12:   1%|          | 12/1000 [25:33<34:50:35, 126.96s/it, lr=0.0005, test_MAE=1.14, time=128, train_MAE=0.817, train_loss=1.12, val_MAE=1.08, val_loss=1.39]Epoch 12:   1%|          | 12/1000 [27:41<34:50:35, 126.96s/it, lr=0.0005, test_MAE=1.15, time=128, train_MAE=0.791, train_loss=1.1, val_MAE=1.1, val_loss=1.41]  Epoch 12:   1%|▏         | 13/1000 [27:41<34:53:17, 127.25s/it, lr=0.0005, test_MAE=1.15, time=128, train_MAE=0.791, train_loss=1.1, val_MAE=1.1, val_loss=1.41]Epoch 13:   1%|▏         | 13/1000 [27:41<34:53:17, 127.25s/it, lr=0.0005, test_MAE=1.15, time=128, train_MAE=0.791, train_loss=1.1, val_MAE=1.1, val_loss=1.41]Epoch 13:   1%|▏         | 13/1000 [29:48<34:53:17, 127.25s/it, lr=0.0005, test_MAE=1.33, time=128, train_MAE=0.783, train_loss=1.09, val_MAE=1.23, val_loss=1.54]Epoch 13:   1%|▏         | 14/1000 [29:48<34:53:21, 127.39s/it, lr=0.0005, test_MAE=1.33, time=128, train_MAE=0.783, train_loss=1.09, val_MAE=1.23, val_loss=1.54]Epoch 14:   1%|▏         | 14/1000 [29:48<34:53:21, 127.39s/it, lr=0.0005, test_MAE=1.33, time=128, train_MAE=0.783, train_loss=1.09, val_MAE=1.23, val_loss=1.54]Epoch 14:   1%|▏         | 14/1000 [31:56<34:53:21, 127.39s/it, lr=0.0005, test_MAE=1.16, time=127, train_MAE=0.772, train_loss=1.08, val_MAE=1.06, val_loss=1.37]Epoch 14:   2%|▏         | 15/1000 [31:56<34:51:03, 127.37s/it, lr=0.0005, test_MAE=1.16, time=127, train_MAE=0.772, train_loss=1.08, val_MAE=1.06, val_loss=1.37]Epoch 15:   2%|▏         | 15/1000 [31:56<34:51:03, 127.37s/it, lr=0.0005, test_MAE=1.16, time=127, train_MAE=0.772, train_loss=1.08, val_MAE=1.06, val_loss=1.37]Epoch 15:   2%|▏         | 15/1000 [34:04<34:51:03, 127.37s/it, lr=0.0005, test_MAE=1.14, time=128, train_MAE=0.755, train_loss=1.07, val_MAE=1.07, val_loss=1.38]Epoch 15:   2%|▏         | 16/1000 [34:04<34:52:22, 127.58s/it, lr=0.0005, test_MAE=1.14, time=128, train_MAE=0.755, train_loss=1.07, val_MAE=1.07, val_loss=1.38]Epoch 16:   2%|▏         | 16/1000 [34:04<34:52:22, 127.58s/it, lr=0.0005, test_MAE=1.14, time=128, train_MAE=0.755, train_loss=1.07, val_MAE=1.07, val_loss=1.38]Epoch 16:   2%|▏         | 16/1000 [36:12<34:52:22, 127.58s/it, lr=0.0005, test_MAE=1.14, time=128, train_MAE=0.755, train_loss=1.07, val_MAE=1.07, val_loss=1.38]Epoch 16:   2%|▏         | 17/1000 [36:12<34:51:34, 127.67s/it, lr=0.0005, test_MAE=1.14, time=128, train_MAE=0.755, train_loss=1.07, val_MAE=1.07, val_loss=1.38]Epoch 17:   2%|▏         | 17/1000 [36:12<34:51:34, 127.67s/it, lr=0.0005, test_MAE=1.14, time=128, train_MAE=0.755, train_loss=1.07, val_MAE=1.07, val_loss=1.38]Epoch 17:   2%|▏         | 17/1000 [38:19<34:51:34, 127.67s/it, lr=0.0005, test_MAE=0.989, time=127, train_MAE=0.742, train_loss=1.06, val_MAE=0.932, val_loss=1.25]Epoch 17:   2%|▏         | 18/1000 [38:19<34:48:23, 127.60s/it, lr=0.0005, test_MAE=0.989, time=127, train_MAE=0.742, train_loss=1.06, val_MAE=0.932, val_loss=1.25]Epoch 18:   2%|▏         | 18/1000 [38:19<34:48:23, 127.60s/it, lr=0.0005, test_MAE=0.989, time=127, train_MAE=0.742, train_loss=1.06, val_MAE=0.932, val_loss=1.25]Epoch 18:   2%|▏         | 18/1000 [40:27<34:48:23, 127.60s/it, lr=0.0005, test_MAE=1.03, time=128, train_MAE=0.742, train_loss=1.06, val_MAE=0.987, val_loss=1.3]  Epoch 18:   2%|▏         | 19/1000 [40:27<34:48:47, 127.76s/it, lr=0.0005, test_MAE=1.03, time=128, train_MAE=0.742, train_loss=1.06, val_MAE=0.987, val_loss=1.3]Epoch 19:   2%|▏         | 19/1000 [40:27<34:48:47, 127.76s/it, lr=0.0005, test_MAE=1.03, time=128, train_MAE=0.742, train_loss=1.06, val_MAE=0.987, val_loss=1.3]Epoch 19:   2%|▏         | 19/1000 [42:35<34:48:47, 127.76s/it, lr=0.0005, test_MAE=1.05, time=128, train_MAE=0.734, train_loss=1.05, val_MAE=1.03, val_loss=1.34]Epoch 19:   2%|▏         | 20/1000 [42:35<34:46:37, 127.75s/it, lr=0.0005, test_MAE=1.05, time=128, train_MAE=0.734, train_loss=1.05, val_MAE=1.03, val_loss=1.34]Epoch 20:   2%|▏         | 20/1000 [42:35<34:46:37, 127.75s/it, lr=0.0005, test_MAE=1.05, time=128, train_MAE=0.734, train_loss=1.05, val_MAE=1.03, val_loss=1.34]Epoch 20:   2%|▏         | 20/1000 [44:43<34:46:37, 127.75s/it, lr=0.0005, test_MAE=1.09, time=128, train_MAE=0.752, train_loss=1.07, val_MAE=1.04, val_loss=1.35]Epoch 20:   2%|▏         | 21/1000 [44:43<34:44:28, 127.75s/it, lr=0.0005, test_MAE=1.09, time=128, train_MAE=0.752, train_loss=1.07, val_MAE=1.04, val_loss=1.35]Epoch 21:   2%|▏         | 21/1000 [44:43<34:44:28, 127.75s/it, lr=0.0005, test_MAE=1.09, time=128, train_MAE=0.752, train_loss=1.07, val_MAE=1.04, val_loss=1.35]Epoch 21:   2%|▏         | 21/1000 [46:51<34:44:28, 127.75s/it, lr=0.0005, test_MAE=1.05, time=128, train_MAE=0.726, train_loss=1.05, val_MAE=0.98, val_loss=1.3] Epoch 21:   2%|▏         | 22/1000 [46:51<34:44:48, 127.90s/it, lr=0.0005, test_MAE=1.05, time=128, train_MAE=0.726, train_loss=1.05, val_MAE=0.98, val_loss=1.3]Epoch 22:   2%|▏         | 22/1000 [46:51<34:44:48, 127.90s/it, lr=0.0005, test_MAE=1.05, time=128, train_MAE=0.726, train_loss=1.05, val_MAE=0.98, val_loss=1.3]Epoch 22:   2%|▏         | 22/1000 [48:59<34:44:48, 127.90s/it, lr=0.0005, test_MAE=1.01, time=127, train_MAE=0.723, train_loss=1.04, val_MAE=0.939, val_loss=1.26]Epoch 22:   2%|▏         | 23/1000 [48:59<34:40:30, 127.77s/it, lr=0.0005, test_MAE=1.01, time=127, train_MAE=0.723, train_loss=1.04, val_MAE=0.939, val_loss=1.26]Epoch 23:   2%|▏         | 23/1000 [48:59<34:40:30, 127.77s/it, lr=0.0005, test_MAE=1.01, time=127, train_MAE=0.723, train_loss=1.04, val_MAE=0.939, val_loss=1.26]Epoch 23:   2%|▏         | 23/1000 [51:07<34:40:30, 127.77s/it, lr=0.0005, test_MAE=1.12, time=128, train_MAE=0.717, train_loss=1.04, val_MAE=1.03, val_loss=1.35] Epoch    24: reducing learning rate of group 0 to 2.5000e-04.
Epoch 23:   2%|▏         | 24/1000 [51:07<34:40:12, 127.88s/it, lr=0.0005, test_MAE=1.12, time=128, train_MAE=0.717, train_loss=1.04, val_MAE=1.03, val_loss=1.35]Epoch 24:   2%|▏         | 24/1000 [51:07<34:40:12, 127.88s/it, lr=0.0005, test_MAE=1.12, time=128, train_MAE=0.717, train_loss=1.04, val_MAE=1.03, val_loss=1.35]Epoch 24:   2%|▏         | 24/1000 [53:14<34:40:12, 127.88s/it, lr=0.00025, test_MAE=1.03, time=128, train_MAE=0.712, train_loss=1.04, val_MAE=0.978, val_loss=1.3]Epoch 24:   2%|▎         | 25/1000 [53:14<34:37:42, 127.86s/it, lr=0.00025, test_MAE=1.03, time=128, train_MAE=0.712, train_loss=1.04, val_MAE=0.978, val_loss=1.3]Epoch 25:   2%|▎         | 25/1000 [53:14<34:37:42, 127.86s/it, lr=0.00025, test_MAE=1.03, time=128, train_MAE=0.712, train_loss=1.04, val_MAE=0.978, val_loss=1.3]Epoch 25:   2%|▎         | 25/1000 [55:22<34:37:42, 127.86s/it, lr=0.00025, test_MAE=0.932, time=128, train_MAE=0.711, train_loss=1.03, val_MAE=0.863, val_loss=1.19]Epoch 25:   3%|▎         | 26/1000 [55:22<34:35:26, 127.85s/it, lr=0.00025, test_MAE=0.932, time=128, train_MAE=0.711, train_loss=1.03, val_MAE=0.863, val_loss=1.19]Epoch 26:   3%|▎         | 26/1000 [55:22<34:35:26, 127.85s/it, lr=0.00025, test_MAE=0.932, time=128, train_MAE=0.711, train_loss=1.03, val_MAE=0.863, val_loss=1.19]Epoch 26:   3%|▎         | 26/1000 [57:30<34:35:26, 127.85s/it, lr=0.00025, test_MAE=1.05, time=128, train_MAE=0.698, train_loss=1.02, val_MAE=1.01, val_loss=1.34]  Epoch 26:   3%|▎         | 27/1000 [57:30<34:34:14, 127.91s/it, lr=0.00025, test_MAE=1.05, time=128, train_MAE=0.698, train_loss=1.02, val_MAE=1.01, val_loss=1.34]Epoch 27:   3%|▎         | 27/1000 [57:30<34:34:14, 127.91s/it, lr=0.00025, test_MAE=1.05, time=128, train_MAE=0.698, train_loss=1.02, val_MAE=1.01, val_loss=1.34]Epoch 27:   3%|▎         | 27/1000 [59:38<34:34:14, 127.91s/it, lr=0.00025, test_MAE=1.04, time=128, train_MAE=0.702, train_loss=1.03, val_MAE=0.992, val_loss=1.32]Epoch 27:   3%|▎         | 28/1000 [59:38<34:31:18, 127.86s/it, lr=0.00025, test_MAE=1.04, time=128, train_MAE=0.702, train_loss=1.03, val_MAE=0.992, val_loss=1.32]Epoch 28:   3%|▎         | 28/1000 [59:38<34:31:18, 127.86s/it, lr=0.00025, test_MAE=1.04, time=128, train_MAE=0.702, train_loss=1.03, val_MAE=0.992, val_loss=1.32]Epoch 28:   3%|▎         | 28/1000 [1:01:46<34:31:18, 127.86s/it, lr=0.00025, test_MAE=1.02, time=127, train_MAE=0.696, train_loss=1.02, val_MAE=0.974, val_loss=1.3]Epoch 28:   3%|▎         | 29/1000 [1:01:46<34:27:27, 127.75s/it, lr=0.00025, test_MAE=1.02, time=127, train_MAE=0.696, train_loss=1.02, val_MAE=0.974, val_loss=1.3]Epoch 29:   3%|▎         | 29/1000 [1:01:46<34:27:27, 127.75s/it, lr=0.00025, test_MAE=1.02, time=127, train_MAE=0.696, train_loss=1.02, val_MAE=0.974, val_loss=1.3]Epoch 29:   3%|▎         | 29/1000 [1:03:54<34:27:27, 127.75s/it, lr=0.00025, test_MAE=1.03, time=128, train_MAE=0.695, train_loss=1.02, val_MAE=0.932, val_loss=1.26]Epoch 29:   3%|▎         | 30/1000 [1:03:54<34:28:10, 127.93s/it, lr=0.00025, test_MAE=1.03, time=128, train_MAE=0.695, train_loss=1.02, val_MAE=0.932, val_loss=1.26]Epoch 30:   3%|▎         | 30/1000 [1:03:54<34:28:10, 127.93s/it, lr=0.00025, test_MAE=1.03, time=128, train_MAE=0.695, train_loss=1.02, val_MAE=0.932, val_loss=1.26]Epoch 30:   3%|▎         | 30/1000 [1:06:02<34:28:10, 127.93s/it, lr=0.00025, test_MAE=0.95, time=128, train_MAE=0.695, train_loss=1.02, val_MAE=0.912, val_loss=1.24]Epoch 30:   3%|▎         | 31/1000 [1:06:02<34:25:35, 127.90s/it, lr=0.00025, test_MAE=0.95, time=128, train_MAE=0.695, train_loss=1.02, val_MAE=0.912, val_loss=1.24]Epoch 31:   3%|▎         | 31/1000 [1:06:02<34:25:35, 127.90s/it, lr=0.00025, test_MAE=0.95, time=128, train_MAE=0.695, train_loss=1.02, val_MAE=0.912, val_loss=1.24]Epoch 31:   3%|▎         | 31/1000 [1:08:09<34:25:35, 127.90s/it, lr=0.00025, test_MAE=0.901, time=128, train_MAE=0.692, train_loss=1.02, val_MAE=0.859, val_loss=1.18]Epoch 31:   3%|▎         | 32/1000 [1:08:09<34:21:53, 127.80s/it, lr=0.00025, test_MAE=0.901, time=128, train_MAE=0.692, train_loss=1.02, val_MAE=0.859, val_loss=1.18]Epoch 32:   3%|▎         | 32/1000 [1:08:09<34:21:53, 127.80s/it, lr=0.00025, test_MAE=0.901, time=128, train_MAE=0.692, train_loss=1.02, val_MAE=0.859, val_loss=1.18]Epoch 32:   3%|▎         | 32/1000 [1:10:18<34:21:53, 127.80s/it, lr=0.00025, test_MAE=0.98, time=128, train_MAE=0.701, train_loss=1.03, val_MAE=0.906, val_loss=1.23] Epoch 32:   3%|▎         | 33/1000 [1:10:18<34:22:07, 127.95s/it, lr=0.00025, test_MAE=0.98, time=128, train_MAE=0.701, train_loss=1.03, val_MAE=0.906, val_loss=1.23]Epoch 33:   3%|▎         | 33/1000 [1:10:18<34:22:07, 127.95s/it, lr=0.00025, test_MAE=0.98, time=128, train_MAE=0.701, train_loss=1.03, val_MAE=0.906, val_loss=1.23]Epoch 33:   3%|▎         | 33/1000 [1:12:26<34:22:07, 127.95s/it, lr=0.00025, test_MAE=0.952, time=128, train_MAE=0.685, train_loss=1.01, val_MAE=0.857, val_loss=1.18]Epoch 33:   3%|▎         | 34/1000 [1:12:26<34:19:51, 127.94s/it, lr=0.00025, test_MAE=0.952, time=128, train_MAE=0.685, train_loss=1.01, val_MAE=0.857, val_loss=1.18]Epoch 34:   3%|▎         | 34/1000 [1:12:26<34:19:51, 127.94s/it, lr=0.00025, test_MAE=0.952, time=128, train_MAE=0.685, train_loss=1.01, val_MAE=0.857, val_loss=1.18]Epoch 34:   3%|▎         | 34/1000 [1:14:33<34:19:51, 127.94s/it, lr=0.00025, test_MAE=0.933, time=128, train_MAE=0.69, train_loss=1.02, val_MAE=0.867, val_loss=1.19] Epoch 34:   4%|▎         | 35/1000 [1:14:33<34:15:53, 127.83s/it, lr=0.00025, test_MAE=0.933, time=128, train_MAE=0.69, train_loss=1.02, val_MAE=0.867, val_loss=1.19]Epoch 35:   4%|▎         | 35/1000 [1:14:33<34:15:53, 127.83s/it, lr=0.00025, test_MAE=0.933, time=128, train_MAE=0.69, train_loss=1.02, val_MAE=0.867, val_loss=1.19]Epoch 35:   4%|▎         | 35/1000 [1:16:41<34:15:53, 127.83s/it, lr=0.00025, test_MAE=0.911, time=128, train_MAE=0.688, train_loss=1.01, val_MAE=0.846, val_loss=1.17]Epoch 35:   4%|▎         | 36/1000 [1:16:41<34:15:46, 127.95s/it, lr=0.00025, test_MAE=0.911, time=128, train_MAE=0.688, train_loss=1.01, val_MAE=0.846, val_loss=1.17]Epoch 36:   4%|▎         | 36/1000 [1:16:41<34:15:46, 127.95s/it, lr=0.00025, test_MAE=0.911, time=128, train_MAE=0.688, train_loss=1.01, val_MAE=0.846, val_loss=1.17]Epoch 36:   4%|▎         | 36/1000 [1:18:50<34:15:46, 127.95s/it, lr=0.00025, test_MAE=0.977, time=128, train_MAE=0.679, train_loss=1, val_MAE=0.872, val_loss=1.2]    Epoch 36:   4%|▎         | 37/1000 [1:18:50<34:15:09, 128.05s/it, lr=0.00025, test_MAE=0.977, time=128, train_MAE=0.679, train_loss=1, val_MAE=0.872, val_loss=1.2]Epoch 37:   4%|▎         | 37/1000 [1:18:50<34:15:09, 128.05s/it, lr=0.00025, test_MAE=0.977, time=128, train_MAE=0.679, train_loss=1, val_MAE=0.872, val_loss=1.2]Epoch 37:   4%|▎         | 37/1000 [1:20:57<34:15:09, 128.05s/it, lr=0.00025, test_MAE=0.853, time=128, train_MAE=0.687, train_loss=1.01, val_MAE=0.783, val_loss=1.11]Epoch 37:   4%|▍         | 38/1000 [1:20:58<34:12:07, 127.99s/it, lr=0.00025, test_MAE=0.853, time=128, train_MAE=0.687, train_loss=1.01, val_MAE=0.783, val_loss=1.11]Epoch 38:   4%|▍         | 38/1000 [1:20:58<34:12:07, 127.99s/it, lr=0.00025, test_MAE=0.853, time=128, train_MAE=0.687, train_loss=1.01, val_MAE=0.783, val_loss=1.11]Epoch 38:   4%|▍         | 38/1000 [1:23:06<34:12:07, 127.99s/it, lr=0.00025, test_MAE=0.991, time=128, train_MAE=0.672, train_loss=0.998, val_MAE=0.945, val_loss=1.27]Epoch 38:   4%|▍         | 39/1000 [1:23:06<34:11:26, 128.08s/it, lr=0.00025, test_MAE=0.991, time=128, train_MAE=0.672, train_loss=0.998, val_MAE=0.945, val_loss=1.27]Epoch 39:   4%|▍         | 39/1000 [1:23:06<34:11:26, 128.08s/it, lr=0.00025, test_MAE=0.991, time=128, train_MAE=0.672, train_loss=0.998, val_MAE=0.945, val_loss=1.27]Epoch 39:   4%|▍         | 39/1000 [1:25:14<34:11:26, 128.08s/it, lr=0.00025, test_MAE=0.947, time=128, train_MAE=0.676, train_loss=1, val_MAE=0.882, val_loss=1.21]    Epoch 39:   4%|▍         | 40/1000 [1:25:14<34:09:38, 128.10s/it, lr=0.00025, test_MAE=0.947, time=128, train_MAE=0.676, train_loss=1, val_MAE=0.882, val_loss=1.21]Epoch 40:   4%|▍         | 40/1000 [1:25:14<34:09:38, 128.10s/it, lr=0.00025, test_MAE=0.947, time=128, train_MAE=0.676, train_loss=1, val_MAE=0.882, val_loss=1.21]Epoch 40:   4%|▍         | 40/1000 [1:27:22<34:09:38, 128.10s/it, lr=0.00025, test_MAE=0.908, time=128, train_MAE=0.688, train_loss=1.01, val_MAE=0.849, val_loss=1.17]Epoch 40:   4%|▍         | 41/1000 [1:27:22<34:06:59, 128.07s/it, lr=0.00025, test_MAE=0.908, time=128, train_MAE=0.688, train_loss=1.01, val_MAE=0.849, val_loss=1.17]Epoch 41:   4%|▍         | 41/1000 [1:27:22<34:06:59, 128.07s/it, lr=0.00025, test_MAE=0.908, time=128, train_MAE=0.688, train_loss=1.01, val_MAE=0.849, val_loss=1.17]Epoch 41:   4%|▍         | 41/1000 [1:29:30<34:06:59, 128.07s/it, lr=0.00025, test_MAE=0.901, time=128, train_MAE=0.679, train_loss=1.01, val_MAE=0.862, val_loss=1.19]Epoch 41:   4%|▍         | 42/1000 [1:29:30<34:06:25, 128.17s/it, lr=0.00025, test_MAE=0.901, time=128, train_MAE=0.679, train_loss=1.01, val_MAE=0.862, val_loss=1.19]Epoch 42:   4%|▍         | 42/1000 [1:29:30<34:06:25, 128.17s/it, lr=0.00025, test_MAE=0.901, time=128, train_MAE=0.679, train_loss=1.01, val_MAE=0.862, val_loss=1.19]Epoch 42:   4%|▍         | 42/1000 [1:31:38<34:06:25, 128.17s/it, lr=0.00025, test_MAE=0.933, time=128, train_MAE=0.681, train_loss=1.01, val_MAE=0.869, val_loss=1.2] Epoch 42:   4%|▍         | 43/1000 [1:31:38<34:01:44, 128.01s/it, lr=0.00025, test_MAE=0.933, time=128, train_MAE=0.681, train_loss=1.01, val_MAE=0.869, val_loss=1.2]Epoch 43:   4%|▍         | 43/1000 [1:31:38<34:01:44, 128.01s/it, lr=0.00025, test_MAE=0.933, time=128, train_MAE=0.681, train_loss=1.01, val_MAE=0.869, val_loss=1.2]Epoch 43:   4%|▍         | 43/1000 [1:33:46<34:01:44, 128.01s/it, lr=0.00025, test_MAE=0.924, time=128, train_MAE=0.672, train_loss=0.999, val_MAE=0.885, val_loss=1.21]Epoch    44: reducing learning rate of group 0 to 1.2500e-04.
Epoch 43:   4%|▍         | 44/1000 [1:33:46<34:01:30, 128.13s/it, lr=0.00025, test_MAE=0.924, time=128, train_MAE=0.672, train_loss=0.999, val_MAE=0.885, val_loss=1.21]Epoch 44:   4%|▍         | 44/1000 [1:33:46<34:01:30, 128.13s/it, lr=0.00025, test_MAE=0.924, time=128, train_MAE=0.672, train_loss=0.999, val_MAE=0.885, val_loss=1.21]Epoch 44:   4%|▍         | 44/1000 [1:35:54<34:01:30, 128.13s/it, lr=0.000125, test_MAE=0.933, time=128, train_MAE=0.67, train_loss=0.997, val_MAE=0.859, val_loss=1.19]Epoch 44:   4%|▍         | 45/1000 [1:35:54<33:58:00, 128.04s/it, lr=0.000125, test_MAE=0.933, time=128, train_MAE=0.67, train_loss=0.997, val_MAE=0.859, val_loss=1.19]Epoch 45:   4%|▍         | 45/1000 [1:35:54<33:58:00, 128.04s/it, lr=0.000125, test_MAE=0.933, time=128, train_MAE=0.67, train_loss=0.997, val_MAE=0.859, val_loss=1.19]Epoch 45:   4%|▍         | 45/1000 [1:38:02<33:58:00, 128.04s/it, lr=0.000125, test_MAE=0.797, time=128, train_MAE=0.674, train_loss=1, val_MAE=0.732, val_loss=1.06]   Epoch 45:   5%|▍         | 46/1000 [1:38:02<33:55:22, 128.01s/it, lr=0.000125, test_MAE=0.797, time=128, train_MAE=0.674, train_loss=1, val_MAE=0.732, val_loss=1.06]Epoch 46:   5%|▍         | 46/1000 [1:38:02<33:55:22, 128.01s/it, lr=0.000125, test_MAE=0.797, time=128, train_MAE=0.674, train_loss=1, val_MAE=0.732, val_loss=1.06]Epoch 46:   5%|▍         | 46/1000 [1:40:11<33:55:22, 128.01s/it, lr=0.000125, test_MAE=0.871, time=128, train_MAE=0.668, train_loss=0.995, val_MAE=0.84, val_loss=1.17]Epoch 46:   5%|▍         | 47/1000 [1:40:11<33:55:18, 128.14s/it, lr=0.000125, test_MAE=0.871, time=128, train_MAE=0.668, train_loss=0.995, val_MAE=0.84, val_loss=1.17]Epoch 47:   5%|▍         | 47/1000 [1:40:11<33:55:18, 128.14s/it, lr=0.000125, test_MAE=0.871, time=128, train_MAE=0.668, train_loss=0.995, val_MAE=0.84, val_loss=1.17]Epoch 47:   5%|▍         | 47/1000 [1:42:19<33:55:18, 128.14s/it, lr=0.000125, test_MAE=0.881, time=128, train_MAE=0.661, train_loss=0.988, val_MAE=0.817, val_loss=1.14]Epoch 47:   5%|▍         | 48/1000 [1:42:19<33:52:48, 128.12s/it, lr=0.000125, test_MAE=0.881, time=128, train_MAE=0.661, train_loss=0.988, val_MAE=0.817, val_loss=1.14]Epoch 48:   5%|▍         | 48/1000 [1:42:19<33:52:48, 128.12s/it, lr=0.000125, test_MAE=0.881, time=128, train_MAE=0.661, train_loss=0.988, val_MAE=0.817, val_loss=1.14]Epoch 48:   5%|▍         | 48/1000 [1:44:26<33:52:48, 128.12s/it, lr=0.000125, test_MAE=0.865, time=128, train_MAE=0.655, train_loss=0.982, val_MAE=0.807, val_loss=1.13]Epoch 48:   5%|▍         | 49/1000 [1:44:26<33:48:46, 128.00s/it, lr=0.000125, test_MAE=0.865, time=128, train_MAE=0.655, train_loss=0.982, val_MAE=0.807, val_loss=1.13]Epoch 49:   5%|▍         | 49/1000 [1:44:26<33:48:46, 128.00s/it, lr=0.000125, test_MAE=0.865, time=128, train_MAE=0.655, train_loss=0.982, val_MAE=0.807, val_loss=1.13]Epoch 49:   5%|▍         | 49/1000 [1:46:35<33:48:46, 128.00s/it, lr=0.000125, test_MAE=0.872, time=129, train_MAE=0.658, train_loss=0.984, val_MAE=0.814, val_loss=1.14]Epoch 49:   5%|▌         | 50/1000 [1:46:35<33:49:59, 128.21s/it, lr=0.000125, test_MAE=0.872, time=129, train_MAE=0.658, train_loss=0.984, val_MAE=0.814, val_loss=1.14]Epoch 50:   5%|▌         | 50/1000 [1:46:35<33:49:59, 128.21s/it, lr=0.000125, test_MAE=0.872, time=129, train_MAE=0.658, train_loss=0.984, val_MAE=0.814, val_loss=1.14]Epoch 50:   5%|▌         | 50/1000 [1:48:43<33:49:59, 128.21s/it, lr=0.000125, test_MAE=0.886, time=128, train_MAE=0.664, train_loss=0.991, val_MAE=0.814, val_loss=1.14]Epoch 50:   5%|▌         | 51/1000 [1:48:43<33:47:07, 128.16s/it, lr=0.000125, test_MAE=0.886, time=128, train_MAE=0.664, train_loss=0.991, val_MAE=0.814, val_loss=1.14]Epoch 51:   5%|▌         | 51/1000 [1:48:43<33:47:07, 128.16s/it, lr=0.000125, test_MAE=0.886, time=128, train_MAE=0.664, train_loss=0.991, val_MAE=0.814, val_loss=1.14]Epoch 51:   5%|▌         | 51/1000 [1:50:51<33:47:07, 128.16s/it, lr=0.000125, test_MAE=0.899, time=128, train_MAE=0.656, train_loss=0.983, val_MAE=0.87, val_loss=1.2]  Epoch    52: reducing learning rate of group 0 to 6.2500e-05.
Epoch 51:   5%|▌         | 52/1000 [1:50:51<33:43:50, 128.09s/it, lr=0.000125, test_MAE=0.899, time=128, train_MAE=0.656, train_loss=0.983, val_MAE=0.87, val_loss=1.2]Epoch 52:   5%|▌         | 52/1000 [1:50:51<33:43:50, 128.09s/it, lr=0.000125, test_MAE=0.899, time=128, train_MAE=0.656, train_loss=0.983, val_MAE=0.87, val_loss=1.2]Epoch 52:   5%|▌         | 52/1000 [1:52:59<33:43:50, 128.09s/it, lr=6.25e-5, test_MAE=0.848, time=128, train_MAE=0.651, train_loss=0.977, val_MAE=0.766, val_loss=1.09]Epoch 52:   5%|▌         | 53/1000 [1:53:00<33:43:17, 128.19s/it, lr=6.25e-5, test_MAE=0.848, time=128, train_MAE=0.651, train_loss=0.977, val_MAE=0.766, val_loss=1.09]Epoch 53:   5%|▌         | 53/1000 [1:53:00<33:43:17, 128.19s/it, lr=6.25e-5, test_MAE=0.848, time=128, train_MAE=0.651, train_loss=0.977, val_MAE=0.766, val_loss=1.09]Epoch 53:   5%|▌         | 53/1000 [1:55:08<33:43:17, 128.19s/it, lr=6.25e-5, test_MAE=0.802, time=128, train_MAE=0.648, train_loss=0.975, val_MAE=0.775, val_loss=1.1] Epoch 53:   5%|▌         | 54/1000 [1:55:08<33:41:06, 128.19s/it, lr=6.25e-5, test_MAE=0.802, time=128, train_MAE=0.648, train_loss=0.975, val_MAE=0.775, val_loss=1.1]Epoch 54:   5%|▌         | 54/1000 [1:55:08<33:41:06, 128.19s/it, lr=6.25e-5, test_MAE=0.802, time=128, train_MAE=0.648, train_loss=0.975, val_MAE=0.775, val_loss=1.1]Epoch 54:   5%|▌         | 54/1000 [1:57:15<33:41:06, 128.19s/it, lr=6.25e-5, test_MAE=0.858, time=128, train_MAE=0.653, train_loss=0.979, val_MAE=0.822, val_loss=1.15]Epoch 54:   6%|▌         | 55/1000 [1:57:15<33:36:34, 128.04s/it, lr=6.25e-5, test_MAE=0.858, time=128, train_MAE=0.653, train_loss=0.979, val_MAE=0.822, val_loss=1.15]Epoch 55:   6%|▌         | 55/1000 [1:57:15<33:36:34, 128.04s/it, lr=6.25e-5, test_MAE=0.858, time=128, train_MAE=0.653, train_loss=0.979, val_MAE=0.822, val_loss=1.15]Epoch 55:   6%|▌         | 55/1000 [1:59:24<33:36:34, 128.04s/it, lr=6.25e-5, test_MAE=0.852, time=128, train_MAE=0.657, train_loss=0.983, val_MAE=0.816, val_loss=1.14]Epoch 55:   6%|▌         | 56/1000 [1:59:24<33:35:54, 128.13s/it, lr=6.25e-5, test_MAE=0.852, time=128, train_MAE=0.657, train_loss=0.983, val_MAE=0.816, val_loss=1.14]Epoch 56:   6%|▌         | 56/1000 [1:59:24<33:35:54, 128.13s/it, lr=6.25e-5, test_MAE=0.852, time=128, train_MAE=0.657, train_loss=0.983, val_MAE=0.816, val_loss=1.14]Epoch 56:   6%|▌         | 56/1000 [2:01:32<33:35:54, 128.13s/it, lr=6.25e-5, test_MAE=0.827, time=128, train_MAE=0.649, train_loss=0.975, val_MAE=0.769, val_loss=1.09]Epoch 56:   6%|▌         | 57/1000 [2:01:32<33:33:24, 128.11s/it, lr=6.25e-5, test_MAE=0.827, time=128, train_MAE=0.649, train_loss=0.975, val_MAE=0.769, val_loss=1.09]Epoch 57:   6%|▌         | 57/1000 [2:01:32<33:33:24, 128.11s/it, lr=6.25e-5, test_MAE=0.827, time=128, train_MAE=0.649, train_loss=0.975, val_MAE=0.769, val_loss=1.09]Epoch 57:   6%|▌         | 57/1000 [2:03:39<33:33:24, 128.11s/it, lr=6.25e-5, test_MAE=0.83, time=128, train_MAE=0.645, train_loss=0.971, val_MAE=0.781, val_loss=1.11] Epoch    58: reducing learning rate of group 0 to 3.1250e-05.
Epoch 57:   6%|▌         | 58/1000 [2:03:40<33:29:54, 128.02s/it, lr=6.25e-5, test_MAE=0.83, time=128, train_MAE=0.645, train_loss=0.971, val_MAE=0.781, val_loss=1.11]Epoch 58:   6%|▌         | 58/1000 [2:03:40<33:29:54, 128.02s/it, lr=6.25e-5, test_MAE=0.83, time=128, train_MAE=0.645, train_loss=0.971, val_MAE=0.781, val_loss=1.11]Epoch 58:   6%|▌         | 58/1000 [2:05:48<33:29:54, 128.02s/it, lr=3.13e-5, test_MAE=0.822, time=128, train_MAE=0.644, train_loss=0.97, val_MAE=0.751, val_loss=1.08]Epoch 58:   6%|▌         | 59/1000 [2:05:48<33:29:57, 128.16s/it, lr=3.13e-5, test_MAE=0.822, time=128, train_MAE=0.644, train_loss=0.97, val_MAE=0.751, val_loss=1.08]Epoch 59:   6%|▌         | 59/1000 [2:05:48<33:29:57, 128.16s/it, lr=3.13e-5, test_MAE=0.822, time=128, train_MAE=0.644, train_loss=0.97, val_MAE=0.751, val_loss=1.08]Epoch 59:   6%|▌         | 59/1000 [2:07:56<33:29:57, 128.16s/it, lr=3.13e-5, test_MAE=0.854, time=128, train_MAE=0.645, train_loss=0.971, val_MAE=0.779, val_loss=1.1]Epoch 59:   6%|▌         | 60/1000 [2:07:56<33:28:07, 128.18s/it, lr=3.13e-5, test_MAE=0.854, time=128, train_MAE=0.645, train_loss=0.971, val_MAE=0.779, val_loss=1.1]Epoch 60:   6%|▌         | 60/1000 [2:07:56<33:28:07, 128.18s/it, lr=3.13e-5, test_MAE=0.854, time=128, train_MAE=0.645, train_loss=0.971, val_MAE=0.779, val_loss=1.1]Epoch 60:   6%|▌         | 60/1000 [2:10:03<33:28:07, 128.18s/it, lr=3.13e-5, test_MAE=0.815, time=126, train_MAE=0.644, train_loss=0.97, val_MAE=0.758, val_loss=1.08]Epoch 60:   6%|▌         | 61/1000 [2:10:03<33:17:23, 127.63s/it, lr=3.13e-5, test_MAE=0.815, time=126, train_MAE=0.644, train_loss=0.97, val_MAE=0.758, val_loss=1.08]Epoch 61:   6%|▌         | 61/1000 [2:10:03<33:17:23, 127.63s/it, lr=3.13e-5, test_MAE=0.815, time=126, train_MAE=0.644, train_loss=0.97, val_MAE=0.758, val_loss=1.08]Epoch 61:   6%|▌         | 61/1000 [2:12:05<33:17:23, 127.63s/it, lr=3.13e-5, test_MAE=0.826, time=123, train_MAE=0.638, train_loss=0.964, val_MAE=0.756, val_loss=1.08]Epoch 61:   6%|▌         | 62/1000 [2:12:05<32:51:50, 126.13s/it, lr=3.13e-5, test_MAE=0.826, time=123, train_MAE=0.638, train_loss=0.964, val_MAE=0.756, val_loss=1.08]Epoch 62:   6%|▌         | 62/1000 [2:12:05<32:51:50, 126.13s/it, lr=3.13e-5, test_MAE=0.826, time=123, train_MAE=0.638, train_loss=0.964, val_MAE=0.756, val_loss=1.08]Epoch 62:   6%|▌         | 62/1000 [2:14:07<32:51:50, 126.13s/it, lr=3.13e-5, test_MAE=0.813, time=121, train_MAE=0.644, train_loss=0.97, val_MAE=0.789, val_loss=1.12] Epoch 62:   6%|▋         | 63/1000 [2:14:07<32:27:34, 124.71s/it, lr=3.13e-5, test_MAE=0.813, time=121, train_MAE=0.644, train_loss=0.97, val_MAE=0.789, val_loss=1.12]Epoch 63:   6%|▋         | 63/1000 [2:14:07<32:27:34, 124.71s/it, lr=3.13e-5, test_MAE=0.813, time=121, train_MAE=0.644, train_loss=0.97, val_MAE=0.789, val_loss=1.12]Epoch 63:   6%|▋         | 63/1000 [2:16:08<32:27:34, 124.71s/it, lr=3.13e-5, test_MAE=0.876, time=121, train_MAE=0.643, train_loss=0.969, val_MAE=0.833, val_loss=1.16]Epoch    64: reducing learning rate of group 0 to 1.5625e-05.
Epoch 63:   6%|▋         | 64/1000 [2:16:08<32:09:55, 123.71s/it, lr=3.13e-5, test_MAE=0.876, time=121, train_MAE=0.643, train_loss=0.969, val_MAE=0.833, val_loss=1.16]Epoch 64:   6%|▋         | 64/1000 [2:16:08<32:09:55, 123.71s/it, lr=3.13e-5, test_MAE=0.876, time=121, train_MAE=0.643, train_loss=0.969, val_MAE=0.833, val_loss=1.16]Epoch 64:   6%|▋         | 64/1000 [2:18:09<32:09:55, 123.71s/it, lr=1.56e-5, test_MAE=0.781, time=121, train_MAE=0.644, train_loss=0.97, val_MAE=0.71, val_loss=1.04]  Epoch 64:   6%|▋         | 65/1000 [2:18:09<31:53:59, 122.82s/it, lr=1.56e-5, test_MAE=0.781, time=121, train_MAE=0.644, train_loss=0.97, val_MAE=0.71, val_loss=1.04]Epoch 65:   6%|▋         | 65/1000 [2:18:09<31:53:59, 122.82s/it, lr=1.56e-5, test_MAE=0.781, time=121, train_MAE=0.644, train_loss=0.97, val_MAE=0.71, val_loss=1.04]Epoch 65:   6%|▋         | 65/1000 [2:20:09<31:53:59, 122.82s/it, lr=1.56e-5, test_MAE=0.799, time=120, train_MAE=0.636, train_loss=0.962, val_MAE=0.767, val_loss=1.09]Epoch 65:   7%|▋         | 66/1000 [2:20:09<31:39:50, 122.05s/it, lr=1.56e-5, test_MAE=0.799, time=120, train_MAE=0.636, train_loss=0.962, val_MAE=0.767, val_loss=1.09]Epoch 66:   7%|▋         | 66/1000 [2:20:09<31:39:50, 122.05s/it, lr=1.56e-5, test_MAE=0.799, time=120, train_MAE=0.636, train_loss=0.962, val_MAE=0.767, val_loss=1.09]Epoch 66:   7%|▋         | 66/1000 [2:22:09<31:39:50, 122.05s/it, lr=1.56e-5, test_MAE=0.781, time=120, train_MAE=0.64, train_loss=0.966, val_MAE=0.763, val_loss=1.09] Epoch 66:   7%|▋         | 67/1000 [2:22:09<31:28:12, 121.43s/it, lr=1.56e-5, test_MAE=0.781, time=120, train_MAE=0.64, train_loss=0.966, val_MAE=0.763, val_loss=1.09]Epoch 67:   7%|▋         | 67/1000 [2:22:09<31:28:12, 121.43s/it, lr=1.56e-5, test_MAE=0.781, time=120, train_MAE=0.64, train_loss=0.966, val_MAE=0.763, val_loss=1.09]Epoch 67:   7%|▋         | 67/1000 [2:24:08<31:28:12, 121.43s/it, lr=1.56e-5, test_MAE=0.76, time=119, train_MAE=0.654, train_loss=0.98, val_MAE=0.704, val_loss=1.03] Epoch 67:   7%|▋         | 68/1000 [2:24:08<31:15:39, 120.75s/it, lr=1.56e-5, test_MAE=0.76, time=119, train_MAE=0.654, train_loss=0.98, val_MAE=0.704, val_loss=1.03]Epoch 68:   7%|▋         | 68/1000 [2:24:08<31:15:39, 120.75s/it, lr=1.56e-5, test_MAE=0.76, time=119, train_MAE=0.654, train_loss=0.98, val_MAE=0.704, val_loss=1.03]Epoch 68:   7%|▋         | 68/1000 [2:26:07<31:15:39, 120.75s/it, lr=1.56e-5, test_MAE=0.81, time=118, train_MAE=0.636, train_loss=0.962, val_MAE=0.745, val_loss=1.07]Epoch 68:   7%|▋         | 69/1000 [2:26:07<31:02:27, 120.03s/it, lr=1.56e-5, test_MAE=0.81, time=118, train_MAE=0.636, train_loss=0.962, val_MAE=0.745, val_loss=1.07]Epoch 69:   7%|▋         | 69/1000 [2:26:07<31:02:27, 120.03s/it, lr=1.56e-5, test_MAE=0.81, time=118, train_MAE=0.636, train_loss=0.962, val_MAE=0.745, val_loss=1.07]Epoch 69:   7%|▋         | 69/1000 [2:28:05<31:02:27, 120.03s/it, lr=1.56e-5, test_MAE=0.778, time=119, train_MAE=0.641, train_loss=0.967, val_MAE=0.714, val_loss=1.04]Epoch 69:   7%|▋         | 70/1000 [2:28:05<30:55:13, 119.69s/it, lr=1.56e-5, test_MAE=0.778, time=119, train_MAE=0.641, train_loss=0.967, val_MAE=0.714, val_loss=1.04]Epoch 70:   7%|▋         | 70/1000 [2:28:05<30:55:13, 119.69s/it, lr=1.56e-5, test_MAE=0.778, time=119, train_MAE=0.641, train_loss=0.967, val_MAE=0.714, val_loss=1.04]Epoch 70:   7%|▋         | 70/1000 [2:30:03<30:55:13, 119.69s/it, lr=1.56e-5, test_MAE=0.801, time=118, train_MAE=0.639, train_loss=0.965, val_MAE=0.781, val_loss=1.11]Epoch 70:   7%|▋         | 71/1000 [2:30:03<30:44:46, 119.15s/it, lr=1.56e-5, test_MAE=0.801, time=118, train_MAE=0.639, train_loss=0.965, val_MAE=0.781, val_loss=1.11]Epoch 71:   7%|▋         | 71/1000 [2:30:03<30:44:46, 119.15s/it, lr=1.56e-5, test_MAE=0.801, time=118, train_MAE=0.639, train_loss=0.965, val_MAE=0.781, val_loss=1.11]Epoch 71:   7%|▋         | 71/1000 [2:32:01<30:44:46, 119.15s/it, lr=1.56e-5, test_MAE=0.839, time=117, train_MAE=0.631, train_loss=0.957, val_MAE=0.904, val_loss=1.23]Epoch 71:   7%|▋         | 72/1000 [2:32:01<30:34:12, 118.59s/it, lr=1.56e-5, test_MAE=0.839, time=117, train_MAE=0.631, train_loss=0.957, val_MAE=0.904, val_loss=1.23]Epoch 72:   7%|▋         | 72/1000 [2:32:01<30:34:12, 118.59s/it, lr=1.56e-5, test_MAE=0.839, time=117, train_MAE=0.631, train_loss=0.957, val_MAE=0.904, val_loss=1.23]Epoch 72:   7%|▋         | 72/1000 [2:33:58<30:34:12, 118.59s/it, lr=1.56e-5, test_MAE=0.807, time=118, train_MAE=0.646, train_loss=0.971, val_MAE=0.741, val_loss=1.07]Epoch 72:   7%|▋         | 73/1000 [2:33:58<30:28:39, 118.36s/it, lr=1.56e-5, test_MAE=0.807, time=118, train_MAE=0.646, train_loss=0.971, val_MAE=0.741, val_loss=1.07]Epoch 73:   7%|▋         | 73/1000 [2:33:58<30:28:39, 118.36s/it, lr=1.56e-5, test_MAE=0.807, time=118, train_MAE=0.646, train_loss=0.971, val_MAE=0.741, val_loss=1.07]Epoch 73:   7%|▋         | 73/1000 [2:35:56<30:28:39, 118.36s/it, lr=1.56e-5, test_MAE=0.803, time=118, train_MAE=0.639, train_loss=0.965, val_MAE=0.753, val_loss=1.08]Epoch    74: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 73:   7%|▋         | 73/1000 [2:35:56<33:00:16, 128.17s/it, lr=1.56e-5, test_MAE=0.803, time=118, train_MAE=0.639, train_loss=0.965, val_MAE=0.753, val_loss=1.08]
Test MAE: 0.8028
Train MAE: 0.7169
Convergence Time (Epochs): 73.0000
TOTAL TIME TAKEN: 9414.7854s
AVG TIME PER EPOCH: 126.4166s
