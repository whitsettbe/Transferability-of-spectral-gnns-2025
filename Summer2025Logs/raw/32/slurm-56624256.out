I'm echoing to stdout
I'm echoing to stderr
My JobID is 56624256
I have 8 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.0897s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 4, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'rational_vec', 'normalized_laplacian': True, 'post_normalized': False, 'eigval_norm': '', 'num_eigs': 15, 'bias_mode': 'spatial', 'eigval_hidden_dim': 5, 'eigval_num_hidden_layer': 3, 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 1, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/zinc_train_kway.csv', 'test': 'supp_data/molecules/zinc_test_part_kway.csv', 'val': 'supp_data/molecules/zinc_val_kway.csv'}, 'fixMissingPhi1': True, 'extraOrtho': False, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [02:04<?, ?it/s, lr=0.001, test_MAE=1.57, time=124, train_MAE=1.22, train_loss=1.24, val_MAE=1.53, val_loss=1.55]Epoch 0:   0%|          | 1/1000 [02:04<34:29:46, 124.31s/it, lr=0.001, test_MAE=1.57, time=124, train_MAE=1.22, train_loss=1.24, val_MAE=1.53, val_loss=1.55]Epoch 1:   0%|          | 1/1000 [02:04<34:29:46, 124.31s/it, lr=0.001, test_MAE=1.57, time=124, train_MAE=1.22, train_loss=1.24, val_MAE=1.53, val_loss=1.55]Epoch 1:   0%|          | 1/1000 [03:56<34:29:46, 124.31s/it, lr=0.001, test_MAE=1.27, time=112, train_MAE=0.868, train_loss=0.899, val_MAE=1.17, val_loss=1.2]Epoch 1:   0%|          | 2/1000 [03:56<33:27:52, 120.71s/it, lr=0.001, test_MAE=1.27, time=112, train_MAE=0.868, train_loss=0.899, val_MAE=1.17, val_loss=1.2]Epoch 2:   0%|          | 2/1000 [03:56<33:27:52, 120.71s/it, lr=0.001, test_MAE=1.27, time=112, train_MAE=0.868, train_loss=0.899, val_MAE=1.17, val_loss=1.2]Epoch 2:   0%|          | 2/1000 [05:49<33:27:52, 120.71s/it, lr=0.001, test_MAE=1.19, time=113, train_MAE=0.781, train_loss=0.815, val_MAE=1.11, val_loss=1.14]Epoch 2:   0%|          | 3/1000 [05:49<32:47:22, 118.40s/it, lr=0.001, test_MAE=1.19, time=113, train_MAE=0.781, train_loss=0.815, val_MAE=1.11, val_loss=1.14]Epoch 3:   0%|          | 3/1000 [05:49<32:47:22, 118.40s/it, lr=0.001, test_MAE=1.19, time=113, train_MAE=0.781, train_loss=0.815, val_MAE=1.11, val_loss=1.14]Epoch 3:   0%|          | 3/1000 [07:42<32:47:22, 118.40s/it, lr=0.001, test_MAE=1.24, time=113, train_MAE=0.724, train_loss=0.759, val_MAE=1.16, val_loss=1.2] Epoch 3:   0%|          | 4/1000 [07:42<32:18:35, 116.78s/it, lr=0.001, test_MAE=1.24, time=113, train_MAE=0.724, train_loss=0.759, val_MAE=1.16, val_loss=1.2]Epoch 4:   0%|          | 4/1000 [07:42<32:18:35, 116.78s/it, lr=0.001, test_MAE=1.24, time=113, train_MAE=0.724, train_loss=0.759, val_MAE=1.16, val_loss=1.2]Epoch 4:   0%|          | 4/1000 [09:35<32:18:35, 116.78s/it, lr=0.001, test_MAE=0.885, time=113, train_MAE=0.695, train_loss=0.73, val_MAE=0.83, val_loss=0.866]Epoch 4:   0%|          | 5/1000 [09:35<31:56:02, 115.54s/it, lr=0.001, test_MAE=0.885, time=113, train_MAE=0.695, train_loss=0.73, val_MAE=0.83, val_loss=0.866]Epoch 5:   0%|          | 5/1000 [09:35<31:56:02, 115.54s/it, lr=0.001, test_MAE=0.885, time=113, train_MAE=0.695, train_loss=0.73, val_MAE=0.83, val_loss=0.866]Epoch 5:   0%|          | 5/1000 [11:27<31:56:02, 115.54s/it, lr=0.001, test_MAE=0.97, time=112, train_MAE=0.692, train_loss=0.728, val_MAE=0.909, val_loss=0.946]Epoch 5:   1%|          | 6/1000 [11:27<31:38:15, 114.58s/it, lr=0.001, test_MAE=0.97, time=112, train_MAE=0.692, train_loss=0.728, val_MAE=0.909, val_loss=0.946]Epoch 6:   1%|          | 6/1000 [11:27<31:38:15, 114.58s/it, lr=0.001, test_MAE=0.97, time=112, train_MAE=0.692, train_loss=0.728, val_MAE=0.909, val_loss=0.946]Epoch 6:   1%|          | 6/1000 [13:20<31:38:15, 114.58s/it, lr=0.001, test_MAE=0.82, time=113, train_MAE=0.669, train_loss=0.706, val_MAE=0.698, val_loss=0.735]Epoch 6:   1%|          | 7/1000 [13:20<31:30:04, 114.20s/it, lr=0.001, test_MAE=0.82, time=113, train_MAE=0.669, train_loss=0.706, val_MAE=0.698, val_loss=0.735]Epoch 7:   1%|          | 7/1000 [13:20<31:30:04, 114.20s/it, lr=0.001, test_MAE=0.82, time=113, train_MAE=0.669, train_loss=0.706, val_MAE=0.698, val_loss=0.735]Epoch 7:   1%|          | 7/1000 [15:14<31:30:04, 114.20s/it, lr=0.001, test_MAE=0.769, time=113, train_MAE=0.673, train_loss=0.71, val_MAE=0.713, val_loss=0.75] Epoch 7:   1%|          | 8/1000 [15:14<31:22:36, 113.87s/it, lr=0.001, test_MAE=0.769, time=113, train_MAE=0.673, train_loss=0.71, val_MAE=0.713, val_loss=0.75]Epoch 8:   1%|          | 8/1000 [15:14<31:22:36, 113.87s/it, lr=0.001, test_MAE=0.769, time=113, train_MAE=0.673, train_loss=0.71, val_MAE=0.713, val_loss=0.75]Epoch 8:   1%|          | 8/1000 [17:07<31:22:36, 113.87s/it, lr=0.001, test_MAE=0.833, time=113, train_MAE=0.663, train_loss=0.701, val_MAE=0.788, val_loss=0.825]Epoch 8:   1%|          | 9/1000 [17:07<31:17:22, 113.67s/it, lr=0.001, test_MAE=0.833, time=113, train_MAE=0.663, train_loss=0.701, val_MAE=0.788, val_loss=0.825]Epoch 9:   1%|          | 9/1000 [17:07<31:17:22, 113.67s/it, lr=0.001, test_MAE=0.833, time=113, train_MAE=0.663, train_loss=0.701, val_MAE=0.788, val_loss=0.825]Epoch 9:   1%|          | 9/1000 [19:00<31:17:22, 113.67s/it, lr=0.001, test_MAE=0.777, time=113, train_MAE=0.669, train_loss=0.707, val_MAE=0.723, val_loss=0.761]Epoch 9:   1%|          | 10/1000 [19:00<31:12:38, 113.49s/it, lr=0.001, test_MAE=0.777, time=113, train_MAE=0.669, train_loss=0.707, val_MAE=0.723, val_loss=0.761]Epoch 10:   1%|          | 10/1000 [19:00<31:12:38, 113.49s/it, lr=0.001, test_MAE=0.777, time=113, train_MAE=0.669, train_loss=0.707, val_MAE=0.723, val_loss=0.761]Epoch 10:   1%|          | 10/1000 [20:53<31:12:38, 113.49s/it, lr=0.001, test_MAE=0.78, time=113, train_MAE=0.659, train_loss=0.697, val_MAE=0.719, val_loss=0.758] Epoch 10:   1%|          | 11/1000 [20:53<31:10:39, 113.49s/it, lr=0.001, test_MAE=0.78, time=113, train_MAE=0.659, train_loss=0.697, val_MAE=0.719, val_loss=0.758]Epoch 11:   1%|          | 11/1000 [20:53<31:10:39, 113.49s/it, lr=0.001, test_MAE=0.78, time=113, train_MAE=0.659, train_loss=0.697, val_MAE=0.719, val_loss=0.758]Epoch 11:   1%|          | 11/1000 [22:47<31:10:39, 113.49s/it, lr=0.001, test_MAE=0.73, time=113, train_MAE=0.654, train_loss=0.693, val_MAE=0.666, val_loss=0.705]Epoch 11:   1%|          | 12/1000 [22:47<31:07:45, 113.43s/it, lr=0.001, test_MAE=0.73, time=113, train_MAE=0.654, train_loss=0.693, val_MAE=0.666, val_loss=0.705]Epoch 12:   1%|          | 12/1000 [22:47<31:07:45, 113.43s/it, lr=0.001, test_MAE=0.73, time=113, train_MAE=0.654, train_loss=0.693, val_MAE=0.666, val_loss=0.705]Epoch 12:   1%|          | 12/1000 [24:39<31:07:45, 113.43s/it, lr=0.001, test_MAE=0.719, time=113, train_MAE=0.65, train_loss=0.69, val_MAE=0.662, val_loss=0.702] Epoch 12:   1%|▏         | 13/1000 [24:39<31:02:50, 113.24s/it, lr=0.001, test_MAE=0.719, time=113, train_MAE=0.65, train_loss=0.69, val_MAE=0.662, val_loss=0.702]Epoch 13:   1%|▏         | 13/1000 [24:39<31:02:50, 113.24s/it, lr=0.001, test_MAE=0.719, time=113, train_MAE=0.65, train_loss=0.69, val_MAE=0.662, val_loss=0.702]Epoch 13:   1%|▏         | 13/1000 [26:33<31:02:50, 113.24s/it, lr=0.001, test_MAE=0.71, time=114, train_MAE=0.645, train_loss=0.684, val_MAE=0.662, val_loss=0.701]Epoch 13:   1%|▏         | 14/1000 [26:33<31:03:31, 113.40s/it, lr=0.001, test_MAE=0.71, time=114, train_MAE=0.645, train_loss=0.684, val_MAE=0.662, val_loss=0.701]Epoch 14:   1%|▏         | 14/1000 [26:33<31:03:31, 113.40s/it, lr=0.001, test_MAE=0.71, time=114, train_MAE=0.645, train_loss=0.684, val_MAE=0.662, val_loss=0.701]Epoch 14:   1%|▏         | 14/1000 [28:26<31:03:31, 113.40s/it, lr=0.001, test_MAE=0.739, time=113, train_MAE=0.657, train_loss=0.697, val_MAE=0.673, val_loss=0.713]Epoch 14:   2%|▏         | 15/1000 [28:26<31:01:02, 113.36s/it, lr=0.001, test_MAE=0.739, time=113, train_MAE=0.657, train_loss=0.697, val_MAE=0.673, val_loss=0.713]Epoch 15:   2%|▏         | 15/1000 [28:26<31:01:02, 113.36s/it, lr=0.001, test_MAE=0.739, time=113, train_MAE=0.657, train_loss=0.697, val_MAE=0.673, val_loss=0.713]Epoch 15:   2%|▏         | 15/1000 [30:20<31:01:02, 113.36s/it, lr=0.001, test_MAE=0.707, time=113, train_MAE=0.638, train_loss=0.678, val_MAE=0.663, val_loss=0.704]Epoch 15:   2%|▏         | 16/1000 [30:20<30:58:07, 113.30s/it, lr=0.001, test_MAE=0.707, time=113, train_MAE=0.638, train_loss=0.678, val_MAE=0.663, val_loss=0.704]Epoch 16:   2%|▏         | 16/1000 [30:20<30:58:07, 113.30s/it, lr=0.001, test_MAE=0.707, time=113, train_MAE=0.638, train_loss=0.678, val_MAE=0.663, val_loss=0.704]Epoch 16:   2%|▏         | 16/1000 [32:13<30:58:07, 113.30s/it, lr=0.001, test_MAE=0.724, time=113, train_MAE=0.644, train_loss=0.685, val_MAE=0.686, val_loss=0.727]Epoch 16:   2%|▏         | 17/1000 [32:13<30:55:27, 113.25s/it, lr=0.001, test_MAE=0.724, time=113, train_MAE=0.644, train_loss=0.685, val_MAE=0.686, val_loss=0.727]Epoch 17:   2%|▏         | 17/1000 [32:13<30:55:27, 113.25s/it, lr=0.001, test_MAE=0.724, time=113, train_MAE=0.644, train_loss=0.685, val_MAE=0.686, val_loss=0.727]Epoch 17:   2%|▏         | 17/1000 [34:06<30:55:27, 113.25s/it, lr=0.001, test_MAE=0.851, time=113, train_MAE=0.636, train_loss=0.677, val_MAE=0.822, val_loss=0.863]Epoch 17:   2%|▏         | 18/1000 [34:06<30:54:28, 113.31s/it, lr=0.001, test_MAE=0.851, time=113, train_MAE=0.636, train_loss=0.677, val_MAE=0.822, val_loss=0.863]Epoch 18:   2%|▏         | 18/1000 [34:06<30:54:28, 113.31s/it, lr=0.001, test_MAE=0.851, time=113, train_MAE=0.636, train_loss=0.677, val_MAE=0.822, val_loss=0.863]Epoch 18:   2%|▏         | 18/1000 [35:59<30:54:28, 113.31s/it, lr=0.001, test_MAE=0.723, time=113, train_MAE=0.637, train_loss=0.678, val_MAE=0.674, val_loss=0.715]Epoch 18:   2%|▏         | 19/1000 [35:59<30:50:41, 113.19s/it, lr=0.001, test_MAE=0.723, time=113, train_MAE=0.637, train_loss=0.678, val_MAE=0.674, val_loss=0.715]Epoch 19:   2%|▏         | 19/1000 [35:59<30:50:41, 113.19s/it, lr=0.001, test_MAE=0.723, time=113, train_MAE=0.637, train_loss=0.678, val_MAE=0.674, val_loss=0.715]Epoch 19:   2%|▏         | 19/1000 [37:53<30:50:41, 113.19s/it, lr=0.001, test_MAE=0.84, time=114, train_MAE=0.64, train_loss=0.682, val_MAE=0.784, val_loss=0.825]  Epoch    20: reducing learning rate of group 0 to 5.0000e-04.
Epoch 19:   2%|▏         | 20/1000 [37:53<30:50:49, 113.32s/it, lr=0.001, test_MAE=0.84, time=114, train_MAE=0.64, train_loss=0.682, val_MAE=0.784, val_loss=0.825]Epoch 20:   2%|▏         | 20/1000 [37:53<30:50:49, 113.32s/it, lr=0.001, test_MAE=0.84, time=114, train_MAE=0.64, train_loss=0.682, val_MAE=0.784, val_loss=0.825]Epoch 20:   2%|▏         | 20/1000 [39:46<30:50:49, 113.32s/it, lr=0.0005, test_MAE=0.724, time=113, train_MAE=0.647, train_loss=0.689, val_MAE=0.67, val_loss=0.712]Epoch 20:   2%|▏         | 21/1000 [39:46<30:48:38, 113.30s/it, lr=0.0005, test_MAE=0.724, time=113, train_MAE=0.647, train_loss=0.689, val_MAE=0.67, val_loss=0.712]Epoch 21:   2%|▏         | 21/1000 [39:46<30:48:38, 113.30s/it, lr=0.0005, test_MAE=0.724, time=113, train_MAE=0.647, train_loss=0.689, val_MAE=0.67, val_loss=0.712]Epoch 21:   2%|▏         | 21/1000 [41:38<30:48:38, 113.30s/it, lr=0.0005, test_MAE=0.711, time=112, train_MAE=0.624, train_loss=0.665, val_MAE=0.665, val_loss=0.707]Epoch 21:   2%|▏         | 22/1000 [41:38<30:41:38, 112.98s/it, lr=0.0005, test_MAE=0.711, time=112, train_MAE=0.624, train_loss=0.665, val_MAE=0.665, val_loss=0.707]Epoch 22:   2%|▏         | 22/1000 [41:38<30:41:38, 112.98s/it, lr=0.0005, test_MAE=0.711, time=112, train_MAE=0.624, train_loss=0.665, val_MAE=0.665, val_loss=0.707]Epoch 22:   2%|▏         | 22/1000 [43:30<30:41:38, 112.98s/it, lr=0.0005, test_MAE=0.691, time=112, train_MAE=0.621, train_loss=0.662, val_MAE=0.641, val_loss=0.682]Epoch 22:   2%|▏         | 23/1000 [43:30<30:35:35, 112.73s/it, lr=0.0005, test_MAE=0.691, time=112, train_MAE=0.621, train_loss=0.662, val_MAE=0.641, val_loss=0.682]Epoch 23:   2%|▏         | 23/1000 [43:30<30:35:35, 112.73s/it, lr=0.0005, test_MAE=0.691, time=112, train_MAE=0.621, train_loss=0.662, val_MAE=0.641, val_loss=0.682]Epoch 23:   2%|▏         | 23/1000 [45:23<30:35:35, 112.73s/it, lr=0.0005, test_MAE=0.716, time=113, train_MAE=0.621, train_loss=0.662, val_MAE=0.675, val_loss=0.717]Epoch 23:   2%|▏         | 24/1000 [45:23<30:35:10, 112.82s/it, lr=0.0005, test_MAE=0.716, time=113, train_MAE=0.621, train_loss=0.662, val_MAE=0.675, val_loss=0.717]Epoch 24:   2%|▏         | 24/1000 [45:23<30:35:10, 112.82s/it, lr=0.0005, test_MAE=0.716, time=113, train_MAE=0.621, train_loss=0.662, val_MAE=0.675, val_loss=0.717]Epoch 24:   2%|▏         | 24/1000 [47:16<30:35:10, 112.82s/it, lr=0.0005, test_MAE=0.712, time=112, train_MAE=0.624, train_loss=0.666, val_MAE=0.672, val_loss=0.713]Epoch 24:   2%|▎         | 25/1000 [47:16<30:31:26, 112.70s/it, lr=0.0005, test_MAE=0.712, time=112, train_MAE=0.624, train_loss=0.666, val_MAE=0.672, val_loss=0.713]Epoch 25:   2%|▎         | 25/1000 [47:16<30:31:26, 112.70s/it, lr=0.0005, test_MAE=0.712, time=112, train_MAE=0.624, train_loss=0.666, val_MAE=0.672, val_loss=0.713]Epoch 25:   2%|▎         | 25/1000 [49:08<30:31:26, 112.70s/it, lr=0.0005, test_MAE=0.693, time=112, train_MAE=0.617, train_loss=0.659, val_MAE=0.652, val_loss=0.694]Epoch 25:   3%|▎         | 26/1000 [49:08<30:28:36, 112.65s/it, lr=0.0005, test_MAE=0.693, time=112, train_MAE=0.617, train_loss=0.659, val_MAE=0.652, val_loss=0.694]Epoch 26:   3%|▎         | 26/1000 [49:08<30:28:36, 112.65s/it, lr=0.0005, test_MAE=0.693, time=112, train_MAE=0.617, train_loss=0.659, val_MAE=0.652, val_loss=0.694]Epoch 26:   3%|▎         | 26/1000 [51:01<30:28:36, 112.65s/it, lr=0.0005, test_MAE=0.682, time=112, train_MAE=0.619, train_loss=0.66, val_MAE=0.639, val_loss=0.68]  Epoch 26:   3%|▎         | 27/1000 [51:01<30:25:27, 112.57s/it, lr=0.0005, test_MAE=0.682, time=112, train_MAE=0.619, train_loss=0.66, val_MAE=0.639, val_loss=0.68]Epoch 27:   3%|▎         | 27/1000 [51:01<30:25:27, 112.57s/it, lr=0.0005, test_MAE=0.682, time=112, train_MAE=0.619, train_loss=0.66, val_MAE=0.639, val_loss=0.68]Epoch 27:   3%|▎         | 27/1000 [52:53<30:25:27, 112.57s/it, lr=0.0005, test_MAE=0.749, time=113, train_MAE=0.616, train_loss=0.658, val_MAE=0.681, val_loss=0.722]Epoch 27:   3%|▎         | 28/1000 [52:53<30:24:33, 112.63s/it, lr=0.0005, test_MAE=0.749, time=113, train_MAE=0.616, train_loss=0.658, val_MAE=0.681, val_loss=0.722]Epoch 28:   3%|▎         | 28/1000 [52:53<30:24:33, 112.63s/it, lr=0.0005, test_MAE=0.749, time=113, train_MAE=0.616, train_loss=0.658, val_MAE=0.681, val_loss=0.722]Epoch 28:   3%|▎         | 28/1000 [54:46<30:24:33, 112.63s/it, lr=0.0005, test_MAE=0.726, time=112, train_MAE=0.617, train_loss=0.658, val_MAE=0.67, val_loss=0.712] Epoch 28:   3%|▎         | 29/1000 [54:46<30:21:42, 112.57s/it, lr=0.0005, test_MAE=0.726, time=112, train_MAE=0.617, train_loss=0.658, val_MAE=0.67, val_loss=0.712]Epoch 29:   3%|▎         | 29/1000 [54:46<30:21:42, 112.57s/it, lr=0.0005, test_MAE=0.726, time=112, train_MAE=0.617, train_loss=0.658, val_MAE=0.67, val_loss=0.712]Epoch 29:   3%|▎         | 29/1000 [56:38<30:21:42, 112.57s/it, lr=0.0005, test_MAE=0.684, time=112, train_MAE=0.627, train_loss=0.668, val_MAE=0.644, val_loss=0.686]Epoch 29:   3%|▎         | 30/1000 [56:38<30:19:00, 112.52s/it, lr=0.0005, test_MAE=0.684, time=112, train_MAE=0.627, train_loss=0.668, val_MAE=0.644, val_loss=0.686]Epoch 30:   3%|▎         | 30/1000 [56:38<30:19:00, 112.52s/it, lr=0.0005, test_MAE=0.684, time=112, train_MAE=0.627, train_loss=0.668, val_MAE=0.644, val_loss=0.686]Epoch 30:   3%|▎         | 30/1000 [58:31<30:19:00, 112.52s/it, lr=0.0005, test_MAE=0.692, time=113, train_MAE=0.613, train_loss=0.654, val_MAE=0.64, val_loss=0.682] Epoch 30:   3%|▎         | 31/1000 [58:31<30:18:09, 112.58s/it, lr=0.0005, test_MAE=0.692, time=113, train_MAE=0.613, train_loss=0.654, val_MAE=0.64, val_loss=0.682]Epoch 31:   3%|▎         | 31/1000 [58:31<30:18:09, 112.58s/it, lr=0.0005, test_MAE=0.692, time=113, train_MAE=0.613, train_loss=0.654, val_MAE=0.64, val_loss=0.682]Epoch 31:   3%|▎         | 31/1000 [1:00:23<30:18:09, 112.58s/it, lr=0.0005, test_MAE=0.71, time=112, train_MAE=0.614, train_loss=0.656, val_MAE=0.68, val_loss=0.721]Epoch 31:   3%|▎         | 32/1000 [1:00:23<30:15:33, 112.54s/it, lr=0.0005, test_MAE=0.71, time=112, train_MAE=0.614, train_loss=0.656, val_MAE=0.68, val_loss=0.721]Epoch 32:   3%|▎         | 32/1000 [1:00:23<30:15:33, 112.54s/it, lr=0.0005, test_MAE=0.71, time=112, train_MAE=0.614, train_loss=0.656, val_MAE=0.68, val_loss=0.721]Epoch 32:   3%|▎         | 32/1000 [1:02:16<30:15:33, 112.54s/it, lr=0.0005, test_MAE=0.7, time=112, train_MAE=0.626, train_loss=0.668, val_MAE=0.662, val_loss=0.703]Epoch    33: reducing learning rate of group 0 to 2.5000e-04.
Epoch 32:   3%|▎         | 33/1000 [1:02:16<30:12:54, 112.49s/it, lr=0.0005, test_MAE=0.7, time=112, train_MAE=0.626, train_loss=0.668, val_MAE=0.662, val_loss=0.703]Epoch 33:   3%|▎         | 33/1000 [1:02:16<30:12:54, 112.49s/it, lr=0.0005, test_MAE=0.7, time=112, train_MAE=0.626, train_loss=0.668, val_MAE=0.662, val_loss=0.703]Epoch 33:   3%|▎         | 33/1000 [1:04:08<30:12:54, 112.49s/it, lr=0.00025, test_MAE=0.714, time=112, train_MAE=0.601, train_loss=0.643, val_MAE=0.68, val_loss=0.722]Epoch 33:   3%|▎         | 34/1000 [1:04:08<30:10:33, 112.46s/it, lr=0.00025, test_MAE=0.714, time=112, train_MAE=0.601, train_loss=0.643, val_MAE=0.68, val_loss=0.722]Epoch 34:   3%|▎         | 34/1000 [1:04:08<30:10:33, 112.46s/it, lr=0.00025, test_MAE=0.714, time=112, train_MAE=0.601, train_loss=0.643, val_MAE=0.68, val_loss=0.722]Epoch 34:   3%|▎         | 34/1000 [1:06:01<30:10:33, 112.46s/it, lr=0.00025, test_MAE=0.688, time=113, train_MAE=0.604, train_loss=0.645, val_MAE=0.664, val_loss=0.706]Epoch 34:   4%|▎         | 35/1000 [1:06:01<30:10:19, 112.56s/it, lr=0.00025, test_MAE=0.688, time=113, train_MAE=0.604, train_loss=0.645, val_MAE=0.664, val_loss=0.706]Epoch 35:   4%|▎         | 35/1000 [1:06:01<30:10:19, 112.56s/it, lr=0.00025, test_MAE=0.688, time=113, train_MAE=0.604, train_loss=0.645, val_MAE=0.664, val_loss=0.706]Epoch 35:   4%|▎         | 35/1000 [1:07:53<30:10:19, 112.56s/it, lr=0.00025, test_MAE=0.763, time=112, train_MAE=0.603, train_loss=0.645, val_MAE=0.641, val_loss=0.683]Epoch 35:   4%|▎         | 36/1000 [1:07:53<30:07:40, 112.51s/it, lr=0.00025, test_MAE=0.763, time=112, train_MAE=0.603, train_loss=0.645, val_MAE=0.641, val_loss=0.683]Epoch 36:   4%|▎         | 36/1000 [1:07:53<30:07:40, 112.51s/it, lr=0.00025, test_MAE=0.763, time=112, train_MAE=0.603, train_loss=0.645, val_MAE=0.641, val_loss=0.683]Epoch 36:   4%|▎         | 36/1000 [1:09:46<30:07:40, 112.51s/it, lr=0.00025, test_MAE=0.704, time=112, train_MAE=0.597, train_loss=0.638, val_MAE=0.657, val_loss=0.698]Epoch 36:   4%|▎         | 37/1000 [1:09:46<30:04:52, 112.45s/it, lr=0.00025, test_MAE=0.704, time=112, train_MAE=0.597, train_loss=0.638, val_MAE=0.657, val_loss=0.698]Epoch 37:   4%|▎         | 37/1000 [1:09:46<30:04:52, 112.45s/it, lr=0.00025, test_MAE=0.704, time=112, train_MAE=0.597, train_loss=0.638, val_MAE=0.657, val_loss=0.698]Epoch 37:   4%|▎         | 37/1000 [1:11:38<30:04:52, 112.45s/it, lr=0.00025, test_MAE=0.696, time=113, train_MAE=0.604, train_loss=0.646, val_MAE=0.649, val_loss=0.69] Epoch 37:   4%|▍         | 38/1000 [1:11:38<30:04:02, 112.52s/it, lr=0.00025, test_MAE=0.696, time=113, train_MAE=0.604, train_loss=0.646, val_MAE=0.649, val_loss=0.69]Epoch 38:   4%|▍         | 38/1000 [1:11:38<30:04:02, 112.52s/it, lr=0.00025, test_MAE=0.696, time=113, train_MAE=0.604, train_loss=0.646, val_MAE=0.649, val_loss=0.69]Epoch 38:   4%|▍         | 38/1000 [1:13:31<30:04:02, 112.52s/it, lr=0.00025, test_MAE=0.709, time=112, train_MAE=0.596, train_loss=0.637, val_MAE=0.666, val_loss=0.707]Epoch    39: reducing learning rate of group 0 to 1.2500e-04.
Epoch 38:   4%|▍         | 39/1000 [1:13:31<30:01:05, 112.45s/it, lr=0.00025, test_MAE=0.709, time=112, train_MAE=0.596, train_loss=0.637, val_MAE=0.666, val_loss=0.707]Epoch 39:   4%|▍         | 39/1000 [1:13:31<30:01:05, 112.45s/it, lr=0.00025, test_MAE=0.709, time=112, train_MAE=0.596, train_loss=0.637, val_MAE=0.666, val_loss=0.707]Epoch 39:   4%|▍         | 39/1000 [1:15:23<30:01:05, 112.45s/it, lr=0.000125, test_MAE=0.684, time=112, train_MAE=0.589, train_loss=0.631, val_MAE=0.643, val_loss=0.684]Epoch 39:   4%|▍         | 40/1000 [1:15:23<29:59:02, 112.44s/it, lr=0.000125, test_MAE=0.684, time=112, train_MAE=0.589, train_loss=0.631, val_MAE=0.643, val_loss=0.684]Epoch 40:   4%|▍         | 40/1000 [1:15:23<29:59:02, 112.44s/it, lr=0.000125, test_MAE=0.684, time=112, train_MAE=0.589, train_loss=0.631, val_MAE=0.643, val_loss=0.684]Epoch 40:   4%|▍         | 40/1000 [1:17:15<29:59:02, 112.44s/it, lr=0.000125, test_MAE=0.693, time=112, train_MAE=0.592, train_loss=0.633, val_MAE=0.65, val_loss=0.691] Epoch 40:   4%|▍         | 41/1000 [1:17:15<29:56:41, 112.41s/it, lr=0.000125, test_MAE=0.693, time=112, train_MAE=0.592, train_loss=0.633, val_MAE=0.65, val_loss=0.691]Epoch 41:   4%|▍         | 41/1000 [1:17:15<29:56:41, 112.41s/it, lr=0.000125, test_MAE=0.693, time=112, train_MAE=0.592, train_loss=0.633, val_MAE=0.65, val_loss=0.691]Epoch 41:   4%|▍         | 41/1000 [1:19:08<29:56:41, 112.41s/it, lr=0.000125, test_MAE=0.689, time=113, train_MAE=0.592, train_loss=0.633, val_MAE=0.643, val_loss=0.684]Epoch 41:   4%|▍         | 42/1000 [1:19:08<29:56:21, 112.51s/it, lr=0.000125, test_MAE=0.689, time=113, train_MAE=0.592, train_loss=0.633, val_MAE=0.643, val_loss=0.684]Epoch 42:   4%|▍         | 42/1000 [1:19:08<29:56:21, 112.51s/it, lr=0.000125, test_MAE=0.689, time=113, train_MAE=0.592, train_loss=0.633, val_MAE=0.643, val_loss=0.684]Epoch 42:   4%|▍         | 42/1000 [1:21:01<29:56:21, 112.51s/it, lr=0.000125, test_MAE=0.69, time=112, train_MAE=0.591, train_loss=0.633, val_MAE=0.648, val_loss=0.689] Epoch 42:   4%|▍         | 43/1000 [1:21:01<29:53:49, 112.47s/it, lr=0.000125, test_MAE=0.69, time=112, train_MAE=0.591, train_loss=0.633, val_MAE=0.648, val_loss=0.689]Epoch 43:   4%|▍         | 43/1000 [1:21:01<29:53:49, 112.47s/it, lr=0.000125, test_MAE=0.69, time=112, train_MAE=0.591, train_loss=0.633, val_MAE=0.648, val_loss=0.689]Epoch 43:   4%|▍         | 43/1000 [1:22:53<29:53:49, 112.47s/it, lr=0.000125, test_MAE=0.688, time=112, train_MAE=0.589, train_loss=0.63, val_MAE=0.639, val_loss=0.68] Epoch 43:   4%|▍         | 44/1000 [1:22:53<29:51:24, 112.43s/it, lr=0.000125, test_MAE=0.688, time=112, train_MAE=0.589, train_loss=0.63, val_MAE=0.639, val_loss=0.68]Epoch 44:   4%|▍         | 44/1000 [1:22:53<29:51:24, 112.43s/it, lr=0.000125, test_MAE=0.688, time=112, train_MAE=0.589, train_loss=0.63, val_MAE=0.639, val_loss=0.68]Epoch 44:   4%|▍         | 44/1000 [1:24:46<29:51:24, 112.43s/it, lr=0.000125, test_MAE=0.692, time=113, train_MAE=0.595, train_loss=0.636, val_MAE=0.651, val_loss=0.692]Epoch    45: reducing learning rate of group 0 to 6.2500e-05.
Epoch 44:   4%|▍         | 45/1000 [1:24:46<29:50:31, 112.49s/it, lr=0.000125, test_MAE=0.692, time=113, train_MAE=0.595, train_loss=0.636, val_MAE=0.651, val_loss=0.692]Epoch 45:   4%|▍         | 45/1000 [1:24:46<29:50:31, 112.49s/it, lr=0.000125, test_MAE=0.692, time=113, train_MAE=0.595, train_loss=0.636, val_MAE=0.651, val_loss=0.692]Epoch 45:   4%|▍         | 45/1000 [1:26:38<29:50:31, 112.49s/it, lr=6.25e-5, test_MAE=0.698, time=112, train_MAE=0.59, train_loss=0.631, val_MAE=0.649, val_loss=0.69]   Epoch 45:   5%|▍         | 46/1000 [1:26:38<29:47:55, 112.45s/it, lr=6.25e-5, test_MAE=0.698, time=112, train_MAE=0.59, train_loss=0.631, val_MAE=0.649, val_loss=0.69]Epoch 46:   5%|▍         | 46/1000 [1:26:38<29:47:55, 112.45s/it, lr=6.25e-5, test_MAE=0.698, time=112, train_MAE=0.59, train_loss=0.631, val_MAE=0.649, val_loss=0.69]Epoch 46:   5%|▍         | 46/1000 [1:28:30<29:47:55, 112.45s/it, lr=6.25e-5, test_MAE=0.686, time=112, train_MAE=0.579, train_loss=0.62, val_MAE=0.642, val_loss=0.683]Epoch 46:   5%|▍         | 47/1000 [1:28:30<29:45:29, 112.41s/it, lr=6.25e-5, test_MAE=0.686, time=112, train_MAE=0.579, train_loss=0.62, val_MAE=0.642, val_loss=0.683]Epoch 47:   5%|▍         | 47/1000 [1:28:30<29:45:29, 112.41s/it, lr=6.25e-5, test_MAE=0.686, time=112, train_MAE=0.579, train_loss=0.62, val_MAE=0.642, val_loss=0.683]Epoch 47:   5%|▍         | 47/1000 [1:30:23<29:45:29, 112.41s/it, lr=6.25e-5, test_MAE=0.684, time=112, train_MAE=0.578, train_loss=0.619, val_MAE=0.642, val_loss=0.683]Epoch 47:   5%|▍         | 48/1000 [1:30:23<29:43:30, 112.41s/it, lr=6.25e-5, test_MAE=0.684, time=112, train_MAE=0.578, train_loss=0.619, val_MAE=0.642, val_loss=0.683]Epoch 48:   5%|▍         | 48/1000 [1:30:23<29:43:30, 112.41s/it, lr=6.25e-5, test_MAE=0.684, time=112, train_MAE=0.578, train_loss=0.619, val_MAE=0.642, val_loss=0.683]Epoch 48:   5%|▍         | 48/1000 [1:32:15<29:43:30, 112.41s/it, lr=6.25e-5, test_MAE=0.689, time=113, train_MAE=0.58, train_loss=0.621, val_MAE=0.648, val_loss=0.689] Epoch 48:   5%|▍         | 49/1000 [1:32:15<29:42:45, 112.48s/it, lr=6.25e-5, test_MAE=0.689, time=113, train_MAE=0.58, train_loss=0.621, val_MAE=0.648, val_loss=0.689]Epoch 49:   5%|▍         | 49/1000 [1:32:15<29:42:45, 112.48s/it, lr=6.25e-5, test_MAE=0.689, time=113, train_MAE=0.58, train_loss=0.621, val_MAE=0.648, val_loss=0.689]Epoch 49:   5%|▍         | 49/1000 [1:34:08<29:42:45, 112.48s/it, lr=6.25e-5, test_MAE=0.704, time=112, train_MAE=0.575, train_loss=0.616, val_MAE=0.658, val_loss=0.699]Epoch 49:   5%|▌         | 50/1000 [1:34:08<29:40:40, 112.46s/it, lr=6.25e-5, test_MAE=0.704, time=112, train_MAE=0.575, train_loss=0.616, val_MAE=0.658, val_loss=0.699]Epoch 50:   5%|▌         | 50/1000 [1:34:08<29:40:40, 112.46s/it, lr=6.25e-5, test_MAE=0.704, time=112, train_MAE=0.575, train_loss=0.616, val_MAE=0.658, val_loss=0.699]Epoch 50:   5%|▌         | 50/1000 [1:36:00<29:40:40, 112.46s/it, lr=6.25e-5, test_MAE=0.686, time=112, train_MAE=0.581, train_loss=0.622, val_MAE=0.642, val_loss=0.683]Epoch    51: reducing learning rate of group 0 to 3.1250e-05.
Epoch 50:   5%|▌         | 51/1000 [1:36:00<29:38:35, 112.45s/it, lr=6.25e-5, test_MAE=0.686, time=112, train_MAE=0.581, train_loss=0.622, val_MAE=0.642, val_loss=0.683]Epoch 51:   5%|▌         | 51/1000 [1:36:00<29:38:35, 112.45s/it, lr=6.25e-5, test_MAE=0.686, time=112, train_MAE=0.581, train_loss=0.622, val_MAE=0.642, val_loss=0.683]Epoch 51:   5%|▌         | 51/1000 [1:37:53<29:38:35, 112.45s/it, lr=3.13e-5, test_MAE=0.696, time=113, train_MAE=0.571, train_loss=0.612, val_MAE=0.653, val_loss=0.693]Epoch 51:   5%|▌         | 52/1000 [1:37:53<29:39:15, 112.61s/it, lr=3.13e-5, test_MAE=0.696, time=113, train_MAE=0.571, train_loss=0.612, val_MAE=0.653, val_loss=0.693]Epoch 52:   5%|▌         | 52/1000 [1:37:53<29:39:15, 112.61s/it, lr=3.13e-5, test_MAE=0.696, time=113, train_MAE=0.571, train_loss=0.612, val_MAE=0.653, val_loss=0.693]Epoch 52:   5%|▌         | 52/1000 [1:39:45<29:39:15, 112.61s/it, lr=3.13e-5, test_MAE=0.689, time=112, train_MAE=0.573, train_loss=0.614, val_MAE=0.644, val_loss=0.685]Epoch 52:   5%|▌         | 53/1000 [1:39:45<29:36:29, 112.55s/it, lr=3.13e-5, test_MAE=0.689, time=112, train_MAE=0.573, train_loss=0.614, val_MAE=0.644, val_loss=0.685]Epoch 53:   5%|▌         | 53/1000 [1:39:45<29:36:29, 112.55s/it, lr=3.13e-5, test_MAE=0.689, time=112, train_MAE=0.573, train_loss=0.614, val_MAE=0.644, val_loss=0.685]Epoch 53:   5%|▌         | 53/1000 [1:41:38<29:36:29, 112.55s/it, lr=3.13e-5, test_MAE=0.715, time=112, train_MAE=0.576, train_loss=0.617, val_MAE=0.654, val_loss=0.695]Epoch 53:   5%|▌         | 54/1000 [1:41:38<29:34:06, 112.52s/it, lr=3.13e-5, test_MAE=0.715, time=112, train_MAE=0.576, train_loss=0.617, val_MAE=0.654, val_loss=0.695]Epoch 54:   5%|▌         | 54/1000 [1:41:38<29:34:06, 112.52s/it, lr=3.13e-5, test_MAE=0.715, time=112, train_MAE=0.576, train_loss=0.617, val_MAE=0.654, val_loss=0.695]Epoch 54:   5%|▌         | 54/1000 [1:43:31<29:34:06, 112.52s/it, lr=3.13e-5, test_MAE=0.702, time=113, train_MAE=0.574, train_loss=0.615, val_MAE=0.643, val_loss=0.684]Epoch 54:   6%|▌         | 55/1000 [1:43:31<29:33:00, 112.57s/it, lr=3.13e-5, test_MAE=0.702, time=113, train_MAE=0.574, train_loss=0.615, val_MAE=0.643, val_loss=0.684]Epoch 55:   6%|▌         | 55/1000 [1:43:31<29:33:00, 112.57s/it, lr=3.13e-5, test_MAE=0.702, time=113, train_MAE=0.574, train_loss=0.615, val_MAE=0.643, val_loss=0.684]Epoch 55:   6%|▌         | 55/1000 [1:45:24<29:33:00, 112.57s/it, lr=3.13e-5, test_MAE=0.692, time=113, train_MAE=0.581, train_loss=0.622, val_MAE=0.648, val_loss=0.689]Epoch 55:   6%|▌         | 56/1000 [1:45:24<29:33:20, 112.71s/it, lr=3.13e-5, test_MAE=0.692, time=113, train_MAE=0.581, train_loss=0.622, val_MAE=0.648, val_loss=0.689]Epoch 56:   6%|▌         | 56/1000 [1:45:24<29:33:20, 112.71s/it, lr=3.13e-5, test_MAE=0.692, time=113, train_MAE=0.581, train_loss=0.622, val_MAE=0.648, val_loss=0.689]Epoch 56:   6%|▌         | 56/1000 [1:47:16<29:33:20, 112.71s/it, lr=3.13e-5, test_MAE=0.688, time=113, train_MAE=0.571, train_loss=0.612, val_MAE=0.645, val_loss=0.686]Epoch    57: reducing learning rate of group 0 to 1.5625e-05.
Epoch 56:   6%|▌         | 57/1000 [1:47:16<29:30:54, 112.68s/it, lr=3.13e-5, test_MAE=0.688, time=113, train_MAE=0.571, train_loss=0.612, val_MAE=0.645, val_loss=0.686]Epoch 57:   6%|▌         | 57/1000 [1:47:16<29:30:54, 112.68s/it, lr=3.13e-5, test_MAE=0.688, time=113, train_MAE=0.571, train_loss=0.612, val_MAE=0.645, val_loss=0.686]Epoch 57:   6%|▌         | 57/1000 [1:49:09<29:30:54, 112.68s/it, lr=1.56e-5, test_MAE=0.68, time=112, train_MAE=0.571, train_loss=0.611, val_MAE=0.641, val_loss=0.682] Epoch 57:   6%|▌         | 58/1000 [1:49:09<29:27:18, 112.57s/it, lr=1.56e-5, test_MAE=0.68, time=112, train_MAE=0.571, train_loss=0.611, val_MAE=0.641, val_loss=0.682]Epoch 58:   6%|▌         | 58/1000 [1:49:09<29:27:18, 112.57s/it, lr=1.56e-5, test_MAE=0.68, time=112, train_MAE=0.571, train_loss=0.611, val_MAE=0.641, val_loss=0.682]Epoch 58:   6%|▌         | 58/1000 [1:51:02<29:27:18, 112.57s/it, lr=1.56e-5, test_MAE=0.688, time=113, train_MAE=0.568, train_loss=0.609, val_MAE=0.644, val_loss=0.685]Epoch 58:   6%|▌         | 59/1000 [1:51:02<29:27:29, 112.70s/it, lr=1.56e-5, test_MAE=0.688, time=113, train_MAE=0.568, train_loss=0.609, val_MAE=0.644, val_loss=0.685]Epoch 59:   6%|▌         | 59/1000 [1:51:02<29:27:29, 112.70s/it, lr=1.56e-5, test_MAE=0.688, time=113, train_MAE=0.568, train_loss=0.609, val_MAE=0.644, val_loss=0.685]Epoch 59:   6%|▌         | 59/1000 [1:52:54<29:27:29, 112.70s/it, lr=1.56e-5, test_MAE=0.695, time=112, train_MAE=0.57, train_loss=0.61, val_MAE=0.644, val_loss=0.684]  Epoch 59:   6%|▌         | 60/1000 [1:52:54<29:24:08, 112.60s/it, lr=1.56e-5, test_MAE=0.695, time=112, train_MAE=0.57, train_loss=0.61, val_MAE=0.644, val_loss=0.684]Epoch 60:   6%|▌         | 60/1000 [1:52:54<29:24:08, 112.60s/it, lr=1.56e-5, test_MAE=0.695, time=112, train_MAE=0.57, train_loss=0.61, val_MAE=0.644, val_loss=0.684]Epoch 60:   6%|▌         | 60/1000 [1:54:46<29:24:08, 112.60s/it, lr=1.56e-5, test_MAE=0.706, time=112, train_MAE=0.576, train_loss=0.617, val_MAE=0.647, val_loss=0.688]Epoch 60:   6%|▌         | 61/1000 [1:54:46<29:19:52, 112.45s/it, lr=1.56e-5, test_MAE=0.706, time=112, train_MAE=0.576, train_loss=0.617, val_MAE=0.647, val_loss=0.688]Epoch 61:   6%|▌         | 61/1000 [1:54:46<29:19:52, 112.45s/it, lr=1.56e-5, test_MAE=0.706, time=112, train_MAE=0.576, train_loss=0.617, val_MAE=0.647, val_loss=0.688]Epoch 61:   6%|▌         | 61/1000 [1:56:36<29:19:52, 112.45s/it, lr=1.56e-5, test_MAE=0.687, time=110, train_MAE=0.57, train_loss=0.61, val_MAE=0.641, val_loss=0.681]  Epoch 61:   6%|▌         | 62/1000 [1:56:36<29:08:21, 111.84s/it, lr=1.56e-5, test_MAE=0.687, time=110, train_MAE=0.57, train_loss=0.61, val_MAE=0.641, val_loss=0.681]Epoch 62:   6%|▌         | 62/1000 [1:56:36<29:08:21, 111.84s/it, lr=1.56e-5, test_MAE=0.687, time=110, train_MAE=0.57, train_loss=0.61, val_MAE=0.641, val_loss=0.681]Epoch 62:   6%|▌         | 62/1000 [1:58:24<29:08:21, 111.84s/it, lr=1.56e-5, test_MAE=0.685, time=108, train_MAE=0.574, train_loss=0.615, val_MAE=0.642, val_loss=0.682]Epoch    63: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 62:   6%|▌         | 62/1000 [1:58:24<29:51:30, 114.60s/it, lr=1.56e-5, test_MAE=0.685, time=108, train_MAE=0.574, train_loss=0.615, val_MAE=0.642, val_loss=0.682]
Test MAE: 0.6848
Train MAE: 0.5586
Convergence Time (Epochs): 62.0000
TOTAL TIME TAKEN: 7154.3143s
AVG TIME PER EPOCH: 112.7609s
