I'm echoing to stdout
I'm echoing to stderr
My JobID is 56818226
I have 4 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset SBM_CLUSTER...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 7.4469s
MODEL DETAILS:

MODEL/Total parameters: ChebNet 102535
Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
Number of Classes:  6
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]/vast/palmer/pi/krishnaswamy_smita/bsw38/GraphML/Transferability-of-spectral-gnns-2025/Benchmark-gnn/nets/SBMs_node_classification/ChebNet.py:58: UserWarning: This overload of nonzero is deprecated:
	nonzero()
Consider using one of the following signatures instead:
	nonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629427478/work/torch/csrc/utils/python_arg_parser.cpp:766.)
  label_count = label_count[label_count.nonzero()].squeeze()
Epoch 0:   0%|          | 0/1000 [00:56<?, ?it/s, lr=0.001, test_acc=42.4, time=56.8, train_acc=47.8, train_loss=1.32, val_acc=41.9, val_loss=1.45]Epoch 0:   0%|          | 1/1000 [00:56<15:47:27, 56.90s/it, lr=0.001, test_acc=42.4, time=56.8, train_acc=47.8, train_loss=1.32, val_acc=41.9, val_loss=1.45]Epoch 1:   0%|          | 1/1000 [00:56<15:47:27, 56.90s/it, lr=0.001, test_acc=42.4, time=56.8, train_acc=47.8, train_loss=1.32, val_acc=41.9, val_loss=1.45]Epoch 1:   0%|          | 1/1000 [01:53<15:47:27, 56.90s/it, lr=0.001, test_acc=25.2, time=56.5, train_acc=67.8, train_loss=0.882, val_acc=24.8, val_loss=1.92]Epoch 1:   0%|          | 2/1000 [01:53<15:45:03, 56.82s/it, lr=0.001, test_acc=25.2, time=56.5, train_acc=67.8, train_loss=0.882, val_acc=24.8, val_loss=1.92]Epoch 2:   0%|          | 2/1000 [01:53<15:45:03, 56.82s/it, lr=0.001, test_acc=25.2, time=56.5, train_acc=67.8, train_loss=0.882, val_acc=24.8, val_loss=1.92]Epoch 2:   0%|          | 2/1000 [02:49<15:45:03, 56.82s/it, lr=0.001, test_acc=37.5, time=56.4, train_acc=69.6, train_loss=0.832, val_acc=37.3, val_loss=1.88]Epoch 2:   0%|          | 3/1000 [02:49<15:42:14, 56.70s/it, lr=0.001, test_acc=37.5, time=56.4, train_acc=69.6, train_loss=0.832, val_acc=37.3, val_loss=1.88]Epoch 3:   0%|          | 3/1000 [02:49<15:42:14, 56.70s/it, lr=0.001, test_acc=37.5, time=56.4, train_acc=69.6, train_loss=0.832, val_acc=37.3, val_loss=1.88]Epoch 3:   0%|          | 3/1000 [03:46<15:42:14, 56.70s/it, lr=0.001, test_acc=32.4, time=56.4, train_acc=70.5, train_loss=0.805, val_acc=32.3, val_loss=2.03]Epoch 3:   0%|          | 4/1000 [03:46<15:39:49, 56.62s/it, lr=0.001, test_acc=32.4, time=56.4, train_acc=70.5, train_loss=0.805, val_acc=32.3, val_loss=2.03]Epoch 4:   0%|          | 4/1000 [03:46<15:39:49, 56.62s/it, lr=0.001, test_acc=32.4, time=56.4, train_acc=70.5, train_loss=0.805, val_acc=32.3, val_loss=2.03]Epoch 4:   0%|          | 4/1000 [04:42<15:39:49, 56.62s/it, lr=0.001, test_acc=36.2, time=56.4, train_acc=71.1, train_loss=0.789, val_acc=36.3, val_loss=1.65]Epoch 4:   0%|          | 5/1000 [04:42<15:38:02, 56.57s/it, lr=0.001, test_acc=36.2, time=56.4, train_acc=71.1, train_loss=0.789, val_acc=36.3, val_loss=1.65]Epoch 5:   0%|          | 5/1000 [04:42<15:38:02, 56.57s/it, lr=0.001, test_acc=36.2, time=56.4, train_acc=71.1, train_loss=0.789, val_acc=36.3, val_loss=1.65]Epoch 5:   0%|          | 5/1000 [05:39<15:38:02, 56.57s/it, lr=0.001, test_acc=28.7, time=56.3, train_acc=71.5, train_loss=0.778, val_acc=28.4, val_loss=2.2] Epoch 5:   1%|          | 6/1000 [05:39<15:35:58, 56.50s/it, lr=0.001, test_acc=28.7, time=56.3, train_acc=71.5, train_loss=0.778, val_acc=28.4, val_loss=2.2]Epoch 6:   1%|          | 6/1000 [05:39<15:35:58, 56.50s/it, lr=0.001, test_acc=28.7, time=56.3, train_acc=71.5, train_loss=0.778, val_acc=28.4, val_loss=2.2]Epoch 6:   1%|          | 6/1000 [06:35<15:35:58, 56.50s/it, lr=0.001, test_acc=27.9, time=56.4, train_acc=71.9, train_loss=0.766, val_acc=27.5, val_loss=2.31]Epoch     7: reducing learning rate of group 0 to 5.0000e-04.
Epoch 6:   1%|          | 7/1000 [06:35<15:34:40, 56.48s/it, lr=0.001, test_acc=27.9, time=56.4, train_acc=71.9, train_loss=0.766, val_acc=27.5, val_loss=2.31]Epoch 7:   1%|          | 7/1000 [06:35<15:34:40, 56.48s/it, lr=0.001, test_acc=27.9, time=56.4, train_acc=71.9, train_loss=0.766, val_acc=27.5, val_loss=2.31]Epoch 7:   1%|          | 7/1000 [07:31<15:34:40, 56.48s/it, lr=0.0005, test_acc=44, time=56.3, train_acc=72.5, train_loss=0.751, val_acc=43.4, val_loss=1.48] Epoch 7:   1%|          | 8/1000 [07:32<15:33:27, 56.46s/it, lr=0.0005, test_acc=44, time=56.3, train_acc=72.5, train_loss=0.751, val_acc=43.4, val_loss=1.48]Epoch 8:   1%|          | 8/1000 [07:32<15:33:27, 56.46s/it, lr=0.0005, test_acc=44, time=56.3, train_acc=72.5, train_loss=0.751, val_acc=43.4, val_loss=1.48]Epoch 8:   1%|          | 8/1000 [08:28<15:33:27, 56.46s/it, lr=0.0005, test_acc=44.5, time=56.4, train_acc=72.8, train_loss=0.745, val_acc=43.5, val_loss=1.59]Epoch 8:   1%|          | 9/1000 [08:28<15:32:33, 56.46s/it, lr=0.0005, test_acc=44.5, time=56.4, train_acc=72.8, train_loss=0.745, val_acc=43.5, val_loss=1.59]Epoch 9:   1%|          | 9/1000 [08:28<15:32:33, 56.46s/it, lr=0.0005, test_acc=44.5, time=56.4, train_acc=72.8, train_loss=0.745, val_acc=43.5, val_loss=1.59]Epoch 9:   1%|          | 9/1000 [09:24<15:32:33, 56.46s/it, lr=0.0005, test_acc=59.4, time=56.4, train_acc=72.9, train_loss=0.74, val_acc=58.7, val_loss=1.12] Epoch 9:   1%|          | 10/1000 [09:24<15:31:16, 56.44s/it, lr=0.0005, test_acc=59.4, time=56.4, train_acc=72.9, train_loss=0.74, val_acc=58.7, val_loss=1.12]Epoch 10:   1%|          | 10/1000 [09:24<15:31:16, 56.44s/it, lr=0.0005, test_acc=59.4, time=56.4, train_acc=72.9, train_loss=0.74, val_acc=58.7, val_loss=1.12]Epoch 10:   1%|          | 10/1000 [10:21<15:31:16, 56.44s/it, lr=0.0005, test_acc=38.3, time=56.5, train_acc=72.9, train_loss=0.74, val_acc=37.6, val_loss=1.63]Epoch 10:   1%|          | 11/1000 [10:21<15:30:48, 56.47s/it, lr=0.0005, test_acc=38.3, time=56.5, train_acc=72.9, train_loss=0.74, val_acc=37.6, val_loss=1.63]Epoch 11:   1%|          | 11/1000 [10:21<15:30:48, 56.47s/it, lr=0.0005, test_acc=38.3, time=56.5, train_acc=72.9, train_loss=0.74, val_acc=37.6, val_loss=1.63]Epoch 11:   1%|          | 11/1000 [11:17<15:30:48, 56.47s/it, lr=0.0005, test_acc=56.6, time=56.5, train_acc=73, train_loss=0.735, val_acc=55.8, val_loss=1.26] Epoch 11:   1%|          | 12/1000 [11:17<15:30:00, 56.48s/it, lr=0.0005, test_acc=56.6, time=56.5, train_acc=73, train_loss=0.735, val_acc=55.8, val_loss=1.26]Epoch 12:   1%|          | 12/1000 [11:17<15:30:00, 56.48s/it, lr=0.0005, test_acc=56.6, time=56.5, train_acc=73, train_loss=0.735, val_acc=55.8, val_loss=1.26]Epoch 12:   1%|          | 12/1000 [12:14<15:30:00, 56.48s/it, lr=0.0005, test_acc=59.4, time=56.4, train_acc=73.2, train_loss=0.733, val_acc=59, val_loss=1.17]Epoch 12:   1%|▏         | 13/1000 [12:14<15:28:51, 56.47s/it, lr=0.0005, test_acc=59.4, time=56.4, train_acc=73.2, train_loss=0.733, val_acc=59, val_loss=1.17]Epoch 13:   1%|▏         | 13/1000 [12:14<15:28:51, 56.47s/it, lr=0.0005, test_acc=59.4, time=56.4, train_acc=73.2, train_loss=0.733, val_acc=59, val_loss=1.17]Epoch 13:   1%|▏         | 13/1000 [13:10<15:28:51, 56.47s/it, lr=0.0005, test_acc=32.9, time=56.4, train_acc=73.2, train_loss=0.73, val_acc=32.3, val_loss=1.83]Epoch 13:   1%|▏         | 14/1000 [13:10<15:27:45, 56.46s/it, lr=0.0005, test_acc=32.9, time=56.4, train_acc=73.2, train_loss=0.73, val_acc=32.3, val_loss=1.83]Epoch 14:   1%|▏         | 14/1000 [13:10<15:27:45, 56.46s/it, lr=0.0005, test_acc=32.9, time=56.4, train_acc=73.2, train_loss=0.73, val_acc=32.3, val_loss=1.83]Epoch 14:   1%|▏         | 14/1000 [14:07<15:27:45, 56.46s/it, lr=0.0005, test_acc=53.6, time=56.4, train_acc=73.3, train_loss=0.729, val_acc=52.7, val_loss=1.45]Epoch 14:   2%|▏         | 15/1000 [14:07<15:26:53, 56.46s/it, lr=0.0005, test_acc=53.6, time=56.4, train_acc=73.3, train_loss=0.729, val_acc=52.7, val_loss=1.45]Epoch 15:   2%|▏         | 15/1000 [14:07<15:26:53, 56.46s/it, lr=0.0005, test_acc=53.6, time=56.4, train_acc=73.3, train_loss=0.729, val_acc=52.7, val_loss=1.45]Epoch 15:   2%|▏         | 15/1000 [15:03<15:26:53, 56.46s/it, lr=0.0005, test_acc=47.1, time=56.4, train_acc=73.2, train_loss=0.73, val_acc=46.8, val_loss=1.45] Epoch    16: reducing learning rate of group 0 to 2.5000e-04.
Epoch 15:   2%|▏         | 16/1000 [15:03<15:25:50, 56.45s/it, lr=0.0005, test_acc=47.1, time=56.4, train_acc=73.2, train_loss=0.73, val_acc=46.8, val_loss=1.45]Epoch 16:   2%|▏         | 16/1000 [15:03<15:25:50, 56.45s/it, lr=0.0005, test_acc=47.1, time=56.4, train_acc=73.2, train_loss=0.73, val_acc=46.8, val_loss=1.45]Epoch 16:   2%|▏         | 16/1000 [16:00<15:25:50, 56.45s/it, lr=0.00025, test_acc=67.8, time=56.5, train_acc=73.7, train_loss=0.718, val_acc=67.5, val_loss=0.888]Epoch 16:   2%|▏         | 17/1000 [16:00<15:25:00, 56.46s/it, lr=0.00025, test_acc=67.8, time=56.5, train_acc=73.7, train_loss=0.718, val_acc=67.5, val_loss=0.888]Epoch 17:   2%|▏         | 17/1000 [16:00<15:25:00, 56.46s/it, lr=0.00025, test_acc=67.8, time=56.5, train_acc=73.7, train_loss=0.718, val_acc=67.5, val_loss=0.888]Epoch 17:   2%|▏         | 17/1000 [16:56<15:25:00, 56.46s/it, lr=0.00025, test_acc=51.1, time=56.4, train_acc=73.8, train_loss=0.715, val_acc=50.4, val_loss=1.51] Epoch 17:   2%|▏         | 18/1000 [16:56<15:23:47, 56.44s/it, lr=0.00025, test_acc=51.1, time=56.4, train_acc=73.8, train_loss=0.715, val_acc=50.4, val_loss=1.51]Epoch 18:   2%|▏         | 18/1000 [16:56<15:23:47, 56.44s/it, lr=0.00025, test_acc=51.1, time=56.4, train_acc=73.8, train_loss=0.715, val_acc=50.4, val_loss=1.51]Epoch 18:   2%|▏         | 18/1000 [17:52<15:23:47, 56.44s/it, lr=0.00025, test_acc=52.2, time=56.4, train_acc=73.9, train_loss=0.712, val_acc=51.9, val_loss=1.57]Epoch 18:   2%|▏         | 19/1000 [17:52<15:22:36, 56.43s/it, lr=0.00025, test_acc=52.2, time=56.4, train_acc=73.9, train_loss=0.712, val_acc=51.9, val_loss=1.57]Epoch 19:   2%|▏         | 19/1000 [17:52<15:22:36, 56.43s/it, lr=0.00025, test_acc=52.2, time=56.4, train_acc=73.9, train_loss=0.712, val_acc=51.9, val_loss=1.57]Epoch 19:   2%|▏         | 19/1000 [18:49<15:22:36, 56.43s/it, lr=0.00025, test_acc=58.9, time=56.5, train_acc=73.9, train_loss=0.712, val_acc=59, val_loss=1.11]  Epoch 19:   2%|▏         | 20/1000 [18:49<15:22:07, 56.46s/it, lr=0.00025, test_acc=58.9, time=56.5, train_acc=73.9, train_loss=0.712, val_acc=59, val_loss=1.11]Epoch 20:   2%|▏         | 20/1000 [18:49<15:22:07, 56.46s/it, lr=0.00025, test_acc=58.9, time=56.5, train_acc=73.9, train_loss=0.712, val_acc=59, val_loss=1.11]Epoch 20:   2%|▏         | 20/1000 [19:45<15:22:07, 56.46s/it, lr=0.00025, test_acc=57.8, time=56.4, train_acc=74, train_loss=0.71, val_acc=57.1, val_loss=1.21] Epoch 20:   2%|▏         | 21/1000 [19:45<15:21:01, 56.45s/it, lr=0.00025, test_acc=57.8, time=56.4, train_acc=74, train_loss=0.71, val_acc=57.1, val_loss=1.21]Epoch 21:   2%|▏         | 21/1000 [19:45<15:21:01, 56.45s/it, lr=0.00025, test_acc=57.8, time=56.4, train_acc=74, train_loss=0.71, val_acc=57.1, val_loss=1.21]Epoch 21:   2%|▏         | 21/1000 [20:42<15:21:01, 56.45s/it, lr=0.00025, test_acc=48.2, time=56.4, train_acc=74, train_loss=0.711, val_acc=46.7, val_loss=1.4]Epoch 21:   2%|▏         | 22/1000 [20:42<15:20:05, 56.45s/it, lr=0.00025, test_acc=48.2, time=56.4, train_acc=74, train_loss=0.711, val_acc=46.7, val_loss=1.4]Epoch 22:   2%|▏         | 22/1000 [20:42<15:20:05, 56.45s/it, lr=0.00025, test_acc=48.2, time=56.4, train_acc=74, train_loss=0.711, val_acc=46.7, val_loss=1.4]Epoch 22:   2%|▏         | 22/1000 [21:38<15:20:05, 56.45s/it, lr=0.00025, test_acc=58.1, time=56.4, train_acc=74, train_loss=0.709, val_acc=57.2, val_loss=1.13]Epoch    23: reducing learning rate of group 0 to 1.2500e-04.
Epoch 22:   2%|▏         | 23/1000 [21:38<15:19:00, 56.44s/it, lr=0.00025, test_acc=58.1, time=56.4, train_acc=74, train_loss=0.709, val_acc=57.2, val_loss=1.13]Epoch 23:   2%|▏         | 23/1000 [21:38<15:19:00, 56.44s/it, lr=0.00025, test_acc=58.1, time=56.4, train_acc=74, train_loss=0.709, val_acc=57.2, val_loss=1.13]Epoch 23:   2%|▏         | 23/1000 [22:35<15:19:00, 56.44s/it, lr=0.000125, test_acc=66.5, time=56.3, train_acc=74.3, train_loss=0.703, val_acc=66, val_loss=0.943]Epoch 23:   2%|▏         | 24/1000 [22:35<15:17:37, 56.41s/it, lr=0.000125, test_acc=66.5, time=56.3, train_acc=74.3, train_loss=0.703, val_acc=66, val_loss=0.943]Epoch 24:   2%|▏         | 24/1000 [22:35<15:17:37, 56.41s/it, lr=0.000125, test_acc=66.5, time=56.3, train_acc=74.3, train_loss=0.703, val_acc=66, val_loss=0.943]Epoch 24:   2%|▏         | 24/1000 [23:31<15:17:37, 56.41s/it, lr=0.000125, test_acc=68.5, time=56.5, train_acc=74.3, train_loss=0.701, val_acc=68.8, val_loss=0.858]Epoch 24:   2%|▎         | 25/1000 [23:31<15:17:09, 56.44s/it, lr=0.000125, test_acc=68.5, time=56.5, train_acc=74.3, train_loss=0.701, val_acc=68.8, val_loss=0.858]Epoch 25:   2%|▎         | 25/1000 [23:31<15:17:09, 56.44s/it, lr=0.000125, test_acc=68.5, time=56.5, train_acc=74.3, train_loss=0.701, val_acc=68.8, val_loss=0.858]Epoch 25:   2%|▎         | 25/1000 [24:28<15:17:09, 56.44s/it, lr=0.000125, test_acc=69, time=56.4, train_acc=74.4, train_loss=0.699, val_acc=68.8, val_loss=0.87]   Epoch 25:   3%|▎         | 26/1000 [24:28<15:16:16, 56.44s/it, lr=0.000125, test_acc=69, time=56.4, train_acc=74.4, train_loss=0.699, val_acc=68.8, val_loss=0.87]Epoch 26:   3%|▎         | 26/1000 [24:28<15:16:16, 56.44s/it, lr=0.000125, test_acc=69, time=56.4, train_acc=74.4, train_loss=0.699, val_acc=68.8, val_loss=0.87]Epoch 26:   3%|▎         | 26/1000 [25:24<15:16:16, 56.44s/it, lr=0.000125, test_acc=66.8, time=56.4, train_acc=74.3, train_loss=0.7, val_acc=66.7, val_loss=0.932]Epoch 26:   3%|▎         | 27/1000 [25:24<15:15:12, 56.44s/it, lr=0.000125, test_acc=66.8, time=56.4, train_acc=74.3, train_loss=0.7, val_acc=66.7, val_loss=0.932]Epoch 27:   3%|▎         | 27/1000 [25:24<15:15:12, 56.44s/it, lr=0.000125, test_acc=66.8, time=56.4, train_acc=74.3, train_loss=0.7, val_acc=66.7, val_loss=0.932]Epoch 27:   3%|▎         | 27/1000 [26:20<15:15:12, 56.44s/it, lr=0.000125, test_acc=70.7, time=56.4, train_acc=74.4, train_loss=0.7, val_acc=70.3, val_loss=0.838]Epoch 27:   3%|▎         | 28/1000 [26:20<15:14:21, 56.44s/it, lr=0.000125, test_acc=70.7, time=56.4, train_acc=74.4, train_loss=0.7, val_acc=70.3, val_loss=0.838]Epoch 28:   3%|▎         | 28/1000 [26:20<15:14:21, 56.44s/it, lr=0.000125, test_acc=70.7, time=56.4, train_acc=74.4, train_loss=0.7, val_acc=70.3, val_loss=0.838]Epoch 28:   3%|▎         | 28/1000 [27:17<15:14:21, 56.44s/it, lr=0.000125, test_acc=65, time=56.4, train_acc=74.4, train_loss=0.7, val_acc=65.1, val_loss=0.96]   Epoch 28:   3%|▎         | 29/1000 [27:17<15:13:12, 56.43s/it, lr=0.000125, test_acc=65, time=56.4, train_acc=74.4, train_loss=0.7, val_acc=65.1, val_loss=0.96]Epoch 29:   3%|▎         | 29/1000 [27:17<15:13:12, 56.43s/it, lr=0.000125, test_acc=65, time=56.4, train_acc=74.4, train_loss=0.7, val_acc=65.1, val_loss=0.96]Epoch 29:   3%|▎         | 29/1000 [28:13<15:13:12, 56.43s/it, lr=0.000125, test_acc=56.8, time=56.4, train_acc=74.4, train_loss=0.698, val_acc=55.7, val_loss=1.2]Epoch 29:   3%|▎         | 30/1000 [28:13<15:12:00, 56.41s/it, lr=0.000125, test_acc=56.8, time=56.4, train_acc=74.4, train_loss=0.698, val_acc=55.7, val_loss=1.2]Epoch 30:   3%|▎         | 30/1000 [28:13<15:12:00, 56.41s/it, lr=0.000125, test_acc=56.8, time=56.4, train_acc=74.4, train_loss=0.698, val_acc=55.7, val_loss=1.2]Epoch 30:   3%|▎         | 30/1000 [29:10<15:12:00, 56.41s/it, lr=0.000125, test_acc=62.4, time=56.4, train_acc=74.5, train_loss=0.698, val_acc=62.6, val_loss=1.02]Epoch 30:   3%|▎         | 31/1000 [29:10<15:11:11, 56.42s/it, lr=0.000125, test_acc=62.4, time=56.4, train_acc=74.5, train_loss=0.698, val_acc=62.6, val_loss=1.02]Epoch 31:   3%|▎         | 31/1000 [29:10<15:11:11, 56.42s/it, lr=0.000125, test_acc=62.4, time=56.4, train_acc=74.5, train_loss=0.698, val_acc=62.6, val_loss=1.02]Epoch 31:   3%|▎         | 31/1000 [30:06<15:11:11, 56.42s/it, lr=0.000125, test_acc=63, time=56.6, train_acc=74.4, train_loss=0.698, val_acc=62.8, val_loss=1.02]  Epoch 31:   3%|▎         | 32/1000 [30:06<15:11:04, 56.47s/it, lr=0.000125, test_acc=63, time=56.6, train_acc=74.4, train_loss=0.698, val_acc=62.8, val_loss=1.02]Epoch 32:   3%|▎         | 32/1000 [30:06<15:11:04, 56.47s/it, lr=0.000125, test_acc=63, time=56.6, train_acc=74.4, train_loss=0.698, val_acc=62.8, val_loss=1.02]Epoch 32:   3%|▎         | 32/1000 [31:03<15:11:04, 56.47s/it, lr=0.000125, test_acc=66.8, time=56.5, train_acc=74.5, train_loss=0.696, val_acc=66.2, val_loss=0.906]Epoch 32:   3%|▎         | 33/1000 [31:03<15:10:12, 56.48s/it, lr=0.000125, test_acc=66.8, time=56.5, train_acc=74.5, train_loss=0.696, val_acc=66.2, val_loss=0.906]Epoch 33:   3%|▎         | 33/1000 [31:03<15:10:12, 56.48s/it, lr=0.000125, test_acc=66.8, time=56.5, train_acc=74.5, train_loss=0.696, val_acc=66.2, val_loss=0.906]Epoch 33:   3%|▎         | 33/1000 [31:59<15:10:12, 56.48s/it, lr=0.000125, test_acc=63.3, time=56.3, train_acc=74.5, train_loss=0.697, val_acc=62.8, val_loss=1.04] Epoch    34: reducing learning rate of group 0 to 6.2500e-05.
Epoch 33:   3%|▎         | 34/1000 [31:59<15:08:30, 56.43s/it, lr=0.000125, test_acc=63.3, time=56.3, train_acc=74.5, train_loss=0.697, val_acc=62.8, val_loss=1.04]Epoch 34:   3%|▎         | 34/1000 [31:59<15:08:30, 56.43s/it, lr=0.000125, test_acc=63.3, time=56.3, train_acc=74.5, train_loss=0.697, val_acc=62.8, val_loss=1.04]Epoch 34:   3%|▎         | 34/1000 [32:55<15:08:30, 56.43s/it, lr=6.25e-5, test_acc=69.8, time=56.4, train_acc=74.6, train_loss=0.694, val_acc=69.3, val_loss=0.833]Epoch 34:   4%|▎         | 35/1000 [32:55<15:07:31, 56.43s/it, lr=6.25e-5, test_acc=69.8, time=56.4, train_acc=74.6, train_loss=0.694, val_acc=69.3, val_loss=0.833]Epoch 35:   4%|▎         | 35/1000 [32:55<15:07:31, 56.43s/it, lr=6.25e-5, test_acc=69.8, time=56.4, train_acc=74.6, train_loss=0.694, val_acc=69.3, val_loss=0.833]Epoch 35:   4%|▎         | 35/1000 [33:52<15:07:31, 56.43s/it, lr=6.25e-5, test_acc=70.1, time=56.5, train_acc=74.6, train_loss=0.693, val_acc=70, val_loss=0.843]  Epoch 35:   4%|▎         | 36/1000 [33:52<15:07:06, 56.46s/it, lr=6.25e-5, test_acc=70.1, time=56.5, train_acc=74.6, train_loss=0.693, val_acc=70, val_loss=0.843]Epoch 36:   4%|▎         | 36/1000 [33:52<15:07:06, 56.46s/it, lr=6.25e-5, test_acc=70.1, time=56.5, train_acc=74.6, train_loss=0.693, val_acc=70, val_loss=0.843]Epoch 36:   4%|▎         | 36/1000 [34:48<15:07:06, 56.46s/it, lr=6.25e-5, test_acc=71.1, time=56.4, train_acc=74.6, train_loss=0.694, val_acc=71.1, val_loss=0.786]Epoch 36:   4%|▎         | 37/1000 [34:48<15:06:03, 56.45s/it, lr=6.25e-5, test_acc=71.1, time=56.4, train_acc=74.6, train_loss=0.694, val_acc=71.1, val_loss=0.786]Epoch 37:   4%|▎         | 37/1000 [34:48<15:06:03, 56.45s/it, lr=6.25e-5, test_acc=71.1, time=56.4, train_acc=74.6, train_loss=0.694, val_acc=71.1, val_loss=0.786]Epoch 37:   4%|▎         | 37/1000 [35:45<15:06:03, 56.45s/it, lr=6.25e-5, test_acc=72.3, time=56.4, train_acc=74.6, train_loss=0.693, val_acc=72.3, val_loss=0.764]Epoch 37:   4%|▍         | 38/1000 [35:45<15:04:46, 56.43s/it, lr=6.25e-5, test_acc=72.3, time=56.4, train_acc=74.6, train_loss=0.693, val_acc=72.3, val_loss=0.764]Epoch 38:   4%|▍         | 38/1000 [35:45<15:04:46, 56.43s/it, lr=6.25e-5, test_acc=72.3, time=56.4, train_acc=74.6, train_loss=0.693, val_acc=72.3, val_loss=0.764]Epoch 38:   4%|▍         | 38/1000 [36:41<15:04:46, 56.43s/it, lr=6.25e-5, test_acc=69.5, time=56.4, train_acc=74.7, train_loss=0.691, val_acc=69.4, val_loss=0.834]Epoch 38:   4%|▍         | 39/1000 [36:41<15:03:35, 56.42s/it, lr=6.25e-5, test_acc=69.5, time=56.4, train_acc=74.7, train_loss=0.691, val_acc=69.4, val_loss=0.834]Epoch 39:   4%|▍         | 39/1000 [36:41<15:03:35, 56.42s/it, lr=6.25e-5, test_acc=69.5, time=56.4, train_acc=74.7, train_loss=0.691, val_acc=69.4, val_loss=0.834]Epoch 39:   4%|▍         | 39/1000 [37:38<15:03:35, 56.42s/it, lr=6.25e-5, test_acc=70, time=56.4, train_acc=74.7, train_loss=0.691, val_acc=69.8, val_loss=0.824]  Epoch 39:   4%|▍         | 40/1000 [37:38<15:02:35, 56.41s/it, lr=6.25e-5, test_acc=70, time=56.4, train_acc=74.7, train_loss=0.691, val_acc=69.8, val_loss=0.824]Epoch 40:   4%|▍         | 40/1000 [37:38<15:02:35, 56.41s/it, lr=6.25e-5, test_acc=70, time=56.4, train_acc=74.7, train_loss=0.691, val_acc=69.8, val_loss=0.824]Epoch 40:   4%|▍         | 40/1000 [38:34<15:02:35, 56.41s/it, lr=6.25e-5, test_acc=72.8, time=56.5, train_acc=74.7, train_loss=0.691, val_acc=72.7, val_loss=0.754]Epoch 40:   4%|▍         | 41/1000 [38:34<15:02:11, 56.45s/it, lr=6.25e-5, test_acc=72.8, time=56.5, train_acc=74.7, train_loss=0.691, val_acc=72.7, val_loss=0.754]Epoch 41:   4%|▍         | 41/1000 [38:34<15:02:11, 56.45s/it, lr=6.25e-5, test_acc=72.8, time=56.5, train_acc=74.7, train_loss=0.691, val_acc=72.7, val_loss=0.754]Epoch 41:   4%|▍         | 41/1000 [39:31<15:02:11, 56.45s/it, lr=6.25e-5, test_acc=70.6, time=56.5, train_acc=74.7, train_loss=0.69, val_acc=70.6, val_loss=0.807] Epoch 41:   4%|▍         | 42/1000 [39:31<15:01:39, 56.47s/it, lr=6.25e-5, test_acc=70.6, time=56.5, train_acc=74.7, train_loss=0.69, val_acc=70.6, val_loss=0.807]Epoch 42:   4%|▍         | 42/1000 [39:31<15:01:39, 56.47s/it, lr=6.25e-5, test_acc=70.6, time=56.5, train_acc=74.7, train_loss=0.69, val_acc=70.6, val_loss=0.807]Epoch 42:   4%|▍         | 42/1000 [40:27<15:01:39, 56.47s/it, lr=6.25e-5, test_acc=70.1, time=56.5, train_acc=74.7, train_loss=0.692, val_acc=69.6, val_loss=0.827]Epoch 42:   4%|▍         | 43/1000 [40:27<15:00:46, 56.47s/it, lr=6.25e-5, test_acc=70.1, time=56.5, train_acc=74.7, train_loss=0.692, val_acc=69.6, val_loss=0.827]Epoch 43:   4%|▍         | 43/1000 [40:27<15:00:46, 56.47s/it, lr=6.25e-5, test_acc=70.1, time=56.5, train_acc=74.7, train_loss=0.692, val_acc=69.6, val_loss=0.827]Epoch 43:   4%|▍         | 43/1000 [41:23<15:00:46, 56.47s/it, lr=6.25e-5, test_acc=72, time=56.4, train_acc=74.6, train_loss=0.692, val_acc=71.9, val_loss=0.776]  Epoch 43:   4%|▍         | 44/1000 [41:24<14:59:18, 56.44s/it, lr=6.25e-5, test_acc=72, time=56.4, train_acc=74.6, train_loss=0.692, val_acc=71.9, val_loss=0.776]Epoch 44:   4%|▍         | 44/1000 [41:24<14:59:18, 56.44s/it, lr=6.25e-5, test_acc=72, time=56.4, train_acc=74.6, train_loss=0.692, val_acc=71.9, val_loss=0.776]Epoch 44:   4%|▍         | 44/1000 [42:20<14:59:18, 56.44s/it, lr=6.25e-5, test_acc=70.1, time=56.3, train_acc=74.8, train_loss=0.689, val_acc=70.2, val_loss=0.81]Epoch 44:   4%|▍         | 45/1000 [42:20<14:57:54, 56.41s/it, lr=6.25e-5, test_acc=70.1, time=56.3, train_acc=74.8, train_loss=0.689, val_acc=70.2, val_loss=0.81]Epoch 45:   4%|▍         | 45/1000 [42:20<14:57:54, 56.41s/it, lr=6.25e-5, test_acc=70.1, time=56.3, train_acc=74.8, train_loss=0.689, val_acc=70.2, val_loss=0.81]Epoch 45:   4%|▍         | 45/1000 [43:16<14:57:54, 56.41s/it, lr=6.25e-5, test_acc=71.8, time=56.5, train_acc=74.8, train_loss=0.689, val_acc=71.5, val_loss=0.773]Epoch 45:   5%|▍         | 46/1000 [43:16<14:57:40, 56.46s/it, lr=6.25e-5, test_acc=71.8, time=56.5, train_acc=74.8, train_loss=0.689, val_acc=71.5, val_loss=0.773]Epoch 46:   5%|▍         | 46/1000 [43:16<14:57:40, 56.46s/it, lr=6.25e-5, test_acc=71.8, time=56.5, train_acc=74.8, train_loss=0.689, val_acc=71.5, val_loss=0.773]Epoch 46:   5%|▍         | 46/1000 [44:13<14:57:40, 56.46s/it, lr=6.25e-5, test_acc=71.2, time=56.4, train_acc=74.7, train_loss=0.689, val_acc=70.9, val_loss=0.802]Epoch    47: reducing learning rate of group 0 to 3.1250e-05.
Epoch 46:   5%|▍         | 47/1000 [44:13<14:56:30, 56.44s/it, lr=6.25e-5, test_acc=71.2, time=56.4, train_acc=74.7, train_loss=0.689, val_acc=70.9, val_loss=0.802]Epoch 47:   5%|▍         | 47/1000 [44:13<14:56:30, 56.44s/it, lr=6.25e-5, test_acc=71.2, time=56.4, train_acc=74.7, train_loss=0.689, val_acc=70.9, val_loss=0.802]Epoch 47:   5%|▍         | 47/1000 [45:09<14:56:30, 56.44s/it, lr=3.13e-5, test_acc=72.8, time=56.4, train_acc=74.8, train_loss=0.687, val_acc=72.8, val_loss=0.743]Epoch 47:   5%|▍         | 48/1000 [45:09<14:55:25, 56.43s/it, lr=3.13e-5, test_acc=72.8, time=56.4, train_acc=74.8, train_loss=0.687, val_acc=72.8, val_loss=0.743]Epoch 48:   5%|▍         | 48/1000 [45:09<14:55:25, 56.43s/it, lr=3.13e-5, test_acc=72.8, time=56.4, train_acc=74.8, train_loss=0.687, val_acc=72.8, val_loss=0.743]Epoch 48:   5%|▍         | 48/1000 [46:06<14:55:25, 56.43s/it, lr=3.13e-5, test_acc=72.5, time=56.5, train_acc=74.8, train_loss=0.689, val_acc=72.7, val_loss=0.747]Epoch 48:   5%|▍         | 49/1000 [46:06<14:54:50, 56.46s/it, lr=3.13e-5, test_acc=72.5, time=56.5, train_acc=74.8, train_loss=0.689, val_acc=72.7, val_loss=0.747]Epoch 49:   5%|▍         | 49/1000 [46:06<14:54:50, 56.46s/it, lr=3.13e-5, test_acc=72.5, time=56.5, train_acc=74.8, train_loss=0.689, val_acc=72.7, val_loss=0.747]Epoch 49:   5%|▍         | 49/1000 [47:02<14:54:50, 56.46s/it, lr=3.13e-5, test_acc=73.2, time=56.5, train_acc=74.8, train_loss=0.686, val_acc=73.1, val_loss=0.74] Epoch 49:   5%|▌         | 50/1000 [47:02<14:54:08, 56.47s/it, lr=3.13e-5, test_acc=73.2, time=56.5, train_acc=74.8, train_loss=0.686, val_acc=73.1, val_loss=0.74]Epoch 50:   5%|▌         | 50/1000 [47:02<14:54:08, 56.47s/it, lr=3.13e-5, test_acc=73.2, time=56.5, train_acc=74.8, train_loss=0.686, val_acc=73.1, val_loss=0.74]Epoch 50:   5%|▌         | 50/1000 [47:59<14:54:08, 56.47s/it, lr=3.13e-5, test_acc=73.2, time=56.4, train_acc=74.8, train_loss=0.689, val_acc=73, val_loss=0.745] Epoch 50:   5%|▌         | 51/1000 [47:59<14:53:00, 56.46s/it, lr=3.13e-5, test_acc=73.2, time=56.4, train_acc=74.8, train_loss=0.689, val_acc=73, val_loss=0.745]Epoch 51:   5%|▌         | 51/1000 [47:59<14:53:00, 56.46s/it, lr=3.13e-5, test_acc=73.2, time=56.4, train_acc=74.8, train_loss=0.689, val_acc=73, val_loss=0.745]Epoch 51:   5%|▌         | 51/1000 [48:55<14:53:00, 56.46s/it, lr=3.13e-5, test_acc=73.2, time=56.4, train_acc=74.8, train_loss=0.687, val_acc=73.2, val_loss=0.733]Epoch 51:   5%|▌         | 52/1000 [48:55<14:51:48, 56.44s/it, lr=3.13e-5, test_acc=73.2, time=56.4, train_acc=74.8, train_loss=0.687, val_acc=73.2, val_loss=0.733]Epoch 52:   5%|▌         | 52/1000 [48:55<14:51:48, 56.44s/it, lr=3.13e-5, test_acc=73.2, time=56.4, train_acc=74.8, train_loss=0.687, val_acc=73.2, val_loss=0.733]Epoch 52:   5%|▌         | 52/1000 [49:52<14:51:48, 56.44s/it, lr=3.13e-5, test_acc=72.2, time=56.4, train_acc=74.8, train_loss=0.688, val_acc=72.4, val_loss=0.763]Epoch 52:   5%|▌         | 53/1000 [49:52<14:50:47, 56.44s/it, lr=3.13e-5, test_acc=72.2, time=56.4, train_acc=74.8, train_loss=0.688, val_acc=72.4, val_loss=0.763]Epoch 53:   5%|▌         | 53/1000 [49:52<14:50:47, 56.44s/it, lr=3.13e-5, test_acc=72.2, time=56.4, train_acc=74.8, train_loss=0.688, val_acc=72.4, val_loss=0.763]Epoch 53:   5%|▌         | 53/1000 [50:48<14:50:47, 56.44s/it, lr=3.13e-5, test_acc=72.8, time=56.7, train_acc=74.8, train_loss=0.687, val_acc=72.9, val_loss=0.746]Epoch 53:   5%|▌         | 54/1000 [50:48<14:51:18, 56.53s/it, lr=3.13e-5, test_acc=72.8, time=56.7, train_acc=74.8, train_loss=0.687, val_acc=72.9, val_loss=0.746]Epoch 54:   5%|▌         | 54/1000 [50:48<14:51:18, 56.53s/it, lr=3.13e-5, test_acc=72.8, time=56.7, train_acc=74.8, train_loss=0.687, val_acc=72.9, val_loss=0.746]Epoch 54:   5%|▌         | 54/1000 [51:45<14:51:18, 56.53s/it, lr=3.13e-5, test_acc=71.6, time=56.5, train_acc=74.9, train_loss=0.685, val_acc=71.4, val_loss=0.777]Epoch 54:   6%|▌         | 55/1000 [51:45<14:50:19, 56.53s/it, lr=3.13e-5, test_acc=71.6, time=56.5, train_acc=74.9, train_loss=0.685, val_acc=71.4, val_loss=0.777]Epoch 55:   6%|▌         | 55/1000 [51:45<14:50:19, 56.53s/it, lr=3.13e-5, test_acc=71.6, time=56.5, train_acc=74.9, train_loss=0.685, val_acc=71.4, val_loss=0.777]Epoch 55:   6%|▌         | 55/1000 [52:41<14:50:19, 56.53s/it, lr=3.13e-5, test_acc=72.8, time=56.5, train_acc=74.8, train_loss=0.686, val_acc=72.9, val_loss=0.746]Epoch 55:   6%|▌         | 56/1000 [52:41<14:49:14, 56.52s/it, lr=3.13e-5, test_acc=72.8, time=56.5, train_acc=74.8, train_loss=0.686, val_acc=72.9, val_loss=0.746]Epoch 56:   6%|▌         | 56/1000 [52:41<14:49:14, 56.52s/it, lr=3.13e-5, test_acc=72.8, time=56.5, train_acc=74.8, train_loss=0.686, val_acc=72.9, val_loss=0.746]Epoch 56:   6%|▌         | 56/1000 [53:38<14:49:14, 56.52s/it, lr=3.13e-5, test_acc=72.4, time=56.5, train_acc=74.8, train_loss=0.686, val_acc=72.7, val_loss=0.749]Epoch 56:   6%|▌         | 57/1000 [53:38<14:48:08, 56.51s/it, lr=3.13e-5, test_acc=72.4, time=56.5, train_acc=74.8, train_loss=0.686, val_acc=72.7, val_loss=0.749]Epoch 57:   6%|▌         | 57/1000 [53:38<14:48:08, 56.51s/it, lr=3.13e-5, test_acc=72.4, time=56.5, train_acc=74.8, train_loss=0.686, val_acc=72.7, val_loss=0.749]Epoch 57:   6%|▌         | 57/1000 [54:34<14:48:08, 56.51s/it, lr=3.13e-5, test_acc=72.9, time=56.5, train_acc=74.9, train_loss=0.686, val_acc=72.7, val_loss=0.745]Epoch    58: reducing learning rate of group 0 to 1.5625e-05.
Epoch 57:   6%|▌         | 58/1000 [54:34<14:47:09, 56.51s/it, lr=3.13e-5, test_acc=72.9, time=56.5, train_acc=74.9, train_loss=0.686, val_acc=72.7, val_loss=0.745]Epoch 58:   6%|▌         | 58/1000 [54:34<14:47:09, 56.51s/it, lr=3.13e-5, test_acc=72.9, time=56.5, train_acc=74.9, train_loss=0.686, val_acc=72.7, val_loss=0.745]Epoch 58:   6%|▌         | 58/1000 [55:31<14:47:09, 56.51s/it, lr=1.56e-5, test_acc=73.1, time=56.4, train_acc=74.9, train_loss=0.684, val_acc=73.2, val_loss=0.738]Epoch 58:   6%|▌         | 59/1000 [55:31<14:45:54, 56.49s/it, lr=1.56e-5, test_acc=73.1, time=56.4, train_acc=74.9, train_loss=0.684, val_acc=73.2, val_loss=0.738]Epoch 59:   6%|▌         | 59/1000 [55:31<14:45:54, 56.49s/it, lr=1.56e-5, test_acc=73.1, time=56.4, train_acc=74.9, train_loss=0.684, val_acc=73.2, val_loss=0.738]Epoch 59:   6%|▌         | 59/1000 [56:27<14:45:54, 56.49s/it, lr=1.56e-5, test_acc=73.1, time=56.5, train_acc=74.9, train_loss=0.684, val_acc=73.3, val_loss=0.735]Epoch 59:   6%|▌         | 60/1000 [56:27<14:45:05, 56.50s/it, lr=1.56e-5, test_acc=73.1, time=56.5, train_acc=74.9, train_loss=0.684, val_acc=73.3, val_loss=0.735]Epoch 60:   6%|▌         | 60/1000 [56:27<14:45:05, 56.50s/it, lr=1.56e-5, test_acc=73.1, time=56.5, train_acc=74.9, train_loss=0.684, val_acc=73.3, val_loss=0.735]Epoch 60:   6%|▌         | 60/1000 [57:24<14:45:05, 56.50s/it, lr=1.56e-5, test_acc=73.3, time=56.4, train_acc=74.9, train_loss=0.684, val_acc=73.3, val_loss=0.735]Epoch 60:   6%|▌         | 61/1000 [57:24<14:44:07, 56.49s/it, lr=1.56e-5, test_acc=73.3, time=56.4, train_acc=74.9, train_loss=0.684, val_acc=73.3, val_loss=0.735]Epoch 61:   6%|▌         | 61/1000 [57:24<14:44:07, 56.49s/it, lr=1.56e-5, test_acc=73.3, time=56.4, train_acc=74.9, train_loss=0.684, val_acc=73.3, val_loss=0.735]Epoch 61:   6%|▌         | 61/1000 [58:20<14:44:07, 56.49s/it, lr=1.56e-5, test_acc=73.4, time=56.4, train_acc=74.9, train_loss=0.684, val_acc=73.3, val_loss=0.735]Epoch 61:   6%|▌         | 62/1000 [58:20<14:42:41, 56.46s/it, lr=1.56e-5, test_acc=73.4, time=56.4, train_acc=74.9, train_loss=0.684, val_acc=73.3, val_loss=0.735]Epoch 62:   6%|▌         | 62/1000 [58:20<14:42:41, 56.46s/it, lr=1.56e-5, test_acc=73.4, time=56.4, train_acc=74.9, train_loss=0.684, val_acc=73.3, val_loss=0.735]Epoch 62:   6%|▌         | 62/1000 [59:17<14:42:41, 56.46s/it, lr=1.56e-5, test_acc=72, time=56.4, train_acc=75, train_loss=0.684, val_acc=72.3, val_loss=0.756]    Epoch 62:   6%|▋         | 63/1000 [59:17<14:41:51, 56.47s/it, lr=1.56e-5, test_acc=72, time=56.4, train_acc=75, train_loss=0.684, val_acc=72.3, val_loss=0.756]Epoch 63:   6%|▋         | 63/1000 [59:17<14:41:51, 56.47s/it, lr=1.56e-5, test_acc=72, time=56.4, train_acc=75, train_loss=0.684, val_acc=72.3, val_loss=0.756]Epoch 63:   6%|▋         | 63/1000 [1:00:13<14:41:51, 56.47s/it, lr=1.56e-5, test_acc=73.3, time=56.4, train_acc=74.9, train_loss=0.685, val_acc=73.5, val_loss=0.73]Epoch 63:   6%|▋         | 64/1000 [1:00:13<14:40:46, 56.46s/it, lr=1.56e-5, test_acc=73.3, time=56.4, train_acc=74.9, train_loss=0.685, val_acc=73.5, val_loss=0.73]Epoch 64:   6%|▋         | 64/1000 [1:00:13<14:40:46, 56.46s/it, lr=1.56e-5, test_acc=73.3, time=56.4, train_acc=74.9, train_loss=0.685, val_acc=73.5, val_loss=0.73]Epoch 64:   6%|▋         | 64/1000 [1:01:10<14:40:46, 56.46s/it, lr=1.56e-5, test_acc=73, time=56.6, train_acc=74.9, train_loss=0.684, val_acc=73, val_loss=0.742]   Epoch 64:   6%|▋         | 65/1000 [1:01:10<14:40:39, 56.51s/it, lr=1.56e-5, test_acc=73, time=56.6, train_acc=74.9, train_loss=0.684, val_acc=73, val_loss=0.742]Epoch 65:   6%|▋         | 65/1000 [1:01:10<14:40:39, 56.51s/it, lr=1.56e-5, test_acc=73, time=56.6, train_acc=74.9, train_loss=0.684, val_acc=73, val_loss=0.742]Epoch 65:   6%|▋         | 65/1000 [1:02:06<14:40:39, 56.51s/it, lr=1.56e-5, test_acc=73.3, time=56.4, train_acc=74.9, train_loss=0.685, val_acc=73.4, val_loss=0.729]Epoch 65:   7%|▋         | 66/1000 [1:02:06<14:39:09, 56.48s/it, lr=1.56e-5, test_acc=73.3, time=56.4, train_acc=74.9, train_loss=0.685, val_acc=73.4, val_loss=0.729]Epoch 66:   7%|▋         | 66/1000 [1:02:06<14:39:09, 56.48s/it, lr=1.56e-5, test_acc=73.3, time=56.4, train_acc=74.9, train_loss=0.685, val_acc=73.4, val_loss=0.729]Epoch 66:   7%|▋         | 66/1000 [1:03:02<14:39:09, 56.48s/it, lr=1.56e-5, test_acc=72.7, time=56.4, train_acc=74.9, train_loss=0.683, val_acc=72.5, val_loss=0.751]Epoch 66:   7%|▋         | 67/1000 [1:03:02<14:37:57, 56.46s/it, lr=1.56e-5, test_acc=72.7, time=56.4, train_acc=74.9, train_loss=0.683, val_acc=72.5, val_loss=0.751]Epoch 67:   7%|▋         | 67/1000 [1:03:02<14:37:57, 56.46s/it, lr=1.56e-5, test_acc=72.7, time=56.4, train_acc=74.9, train_loss=0.683, val_acc=72.5, val_loss=0.751]Epoch 67:   7%|▋         | 67/1000 [1:03:59<14:37:57, 56.46s/it, lr=1.56e-5, test_acc=73, time=56.5, train_acc=74.9, train_loss=0.684, val_acc=73.1, val_loss=0.736]  Epoch 67:   7%|▋         | 68/1000 [1:03:59<14:37:07, 56.47s/it, lr=1.56e-5, test_acc=73, time=56.5, train_acc=74.9, train_loss=0.684, val_acc=73.1, val_loss=0.736]Epoch 68:   7%|▋         | 68/1000 [1:03:59<14:37:07, 56.47s/it, lr=1.56e-5, test_acc=73, time=56.5, train_acc=74.9, train_loss=0.684, val_acc=73.1, val_loss=0.736]Epoch 68:   7%|▋         | 68/1000 [1:04:55<14:37:07, 56.47s/it, lr=1.56e-5, test_acc=73, time=56.4, train_acc=74.9, train_loss=0.686, val_acc=73.1, val_loss=0.739]Epoch 68:   7%|▋         | 69/1000 [1:04:55<14:35:50, 56.44s/it, lr=1.56e-5, test_acc=73, time=56.4, train_acc=74.9, train_loss=0.686, val_acc=73.1, val_loss=0.739]Epoch 69:   7%|▋         | 69/1000 [1:04:55<14:35:50, 56.44s/it, lr=1.56e-5, test_acc=73, time=56.4, train_acc=74.9, train_loss=0.686, val_acc=73.1, val_loss=0.739]Epoch 69:   7%|▋         | 69/1000 [1:05:52<14:35:50, 56.44s/it, lr=1.56e-5, test_acc=73, time=56.4, train_acc=74.9, train_loss=0.684, val_acc=73, val_loss=0.737]  Epoch 69:   7%|▋         | 70/1000 [1:05:52<14:34:55, 56.45s/it, lr=1.56e-5, test_acc=73, time=56.4, train_acc=74.9, train_loss=0.684, val_acc=73, val_loss=0.737]Epoch 70:   7%|▋         | 70/1000 [1:05:52<14:34:55, 56.45s/it, lr=1.56e-5, test_acc=73, time=56.4, train_acc=74.9, train_loss=0.684, val_acc=73, val_loss=0.737]Epoch 70:   7%|▋         | 70/1000 [1:06:48<14:34:55, 56.45s/it, lr=1.56e-5, test_acc=73.1, time=56.3, train_acc=74.9, train_loss=0.685, val_acc=73.2, val_loss=0.734]Epoch 70:   7%|▋         | 71/1000 [1:06:48<14:33:44, 56.43s/it, lr=1.56e-5, test_acc=73.1, time=56.3, train_acc=74.9, train_loss=0.685, val_acc=73.2, val_loss=0.734]Epoch 71:   7%|▋         | 71/1000 [1:06:48<14:33:44, 56.43s/it, lr=1.56e-5, test_acc=73.1, time=56.3, train_acc=74.9, train_loss=0.685, val_acc=73.2, val_loss=0.734]Epoch 71:   7%|▋         | 71/1000 [1:07:45<14:33:44, 56.43s/it, lr=1.56e-5, test_acc=73, time=56.4, train_acc=75, train_loss=0.683, val_acc=73.1, val_loss=0.742]    Epoch    72: reducing learning rate of group 0 to 7.8125e-06.

!! LR SMALLER OR EQUAL TO MIN LR THRESHOLD.
Epoch 71:   7%|▋         | 71/1000 [1:07:45<14:46:29, 57.25s/it, lr=1.56e-5, test_acc=73, time=56.4, train_acc=75, train_loss=0.683, val_acc=73.1, val_loss=0.742]
Test Accuracy: 72.9729
Train Accuracy: 74.3832
Convergence Time (Epochs): 71.0000
TOTAL TIME TAKEN: 4092.0483s
AVG TIME PER EPOCH: 56.4335s
