I'm echoing to stdout
I'm echoing to stderr
My JobID is 58311236
I have 4 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset SBM_CLUSTER...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 7.5184s
Dataset: SBM_CLUSTER,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 70, 'out_dim': 70, 'residual': True, 'k': 5, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'cheb02_vec', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_sub', 'num_eigs': 16, 'bias_mode': 'spatial', 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 0.0, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/SBMs/cluster_train_rec.csv', 'test': 'supp_data/SBMs/cluster_test_rec1.csv', 'val': 'supp_data/SBMs/cluster_val_rec1.csv'}, 'fixMissingPhi1': False, 'extraOrtho': False, 'doublePrecision': True, 'eigval_hidden_dim': 100, 'eigval_num_hidden_layer': 3, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'in_dim': 7, 'n_classes': 6, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
Number of Classes:  6
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]/vast/palmer/pi/krishnaswamy_smita/bsw38/GraphML/Transferability-of-spectral-gnns-2025/Benchmark-gnn/nets/SBMs_node_classification/ChebNet.py:74: UserWarning: This overload of nonzero is deprecated:
	nonzero()
Consider using one of the following signatures instead:
	nonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629427478/work/torch/csrc/utils/python_arg_parser.cpp:766.)
  label_count = label_count[label_count.nonzero()].squeeze()
Epoch 0:   0%|          | 0/1000 [09:27<?, ?it/s, lr=0.001, test_acc=48.3, time=568, train_acc=49.2, train_loss=1.42, val_acc=47, val_loss=1.53]Epoch 0:   0%|          | 1/1000 [09:27<157:33:23, 567.77s/it, lr=0.001, test_acc=48.3, time=568, train_acc=49.2, train_loss=1.42, val_acc=47, val_loss=1.53]Epoch 1:   0%|          | 1/1000 [09:27<157:33:23, 567.77s/it, lr=0.001, test_acc=48.3, time=568, train_acc=49.2, train_loss=1.42, val_acc=47, val_loss=1.53]Epoch 1:   0%|          | 1/1000 [12:28<157:33:23, 567.77s/it, lr=0.001, test_acc=51.9, time=180, train_acc=53.2, train_loss=1.29, val_acc=51, val_loss=1.39]Epoch 1:   0%|          | 2/1000 [12:28<125:10:18, 451.52s/it, lr=0.001, test_acc=51.9, time=180, train_acc=53.2, train_loss=1.29, val_acc=51, val_loss=1.39]Epoch 2:   0%|          | 2/1000 [12:28<125:10:18, 451.52s/it, lr=0.001, test_acc=51.9, time=180, train_acc=53.2, train_loss=1.29, val_acc=51, val_loss=1.39]Epoch 2:   0%|          | 2/1000 [15:28<125:10:18, 451.52s/it, lr=0.001, test_acc=53.9, time=180, train_acc=53.6, train_loss=1.27, val_acc=52.6, val_loss=1.31]Epoch 2:   0%|          | 3/1000 [15:28<102:30:03, 370.11s/it, lr=0.001, test_acc=53.9, time=180, train_acc=53.6, train_loss=1.27, val_acc=52.6, val_loss=1.31]Epoch 3:   0%|          | 3/1000 [15:28<102:30:03, 370.11s/it, lr=0.001, test_acc=53.9, time=180, train_acc=53.6, train_loss=1.27, val_acc=52.6, val_loss=1.31]Epoch 3:   0%|          | 3/1000 [18:28<102:30:03, 370.11s/it, lr=0.001, test_acc=52.9, time=180, train_acc=54, train_loss=1.26, val_acc=51.4, val_loss=1.34]  Epoch 3:   0%|          | 4/1000 [18:28<86:38:09, 313.14s/it, lr=0.001, test_acc=52.9, time=180, train_acc=54, train_loss=1.26, val_acc=51.4, val_loss=1.34] Epoch 4:   0%|          | 4/1000 [18:28<86:38:09, 313.14s/it, lr=0.001, test_acc=52.9, time=180, train_acc=54, train_loss=1.26, val_acc=51.4, val_loss=1.34]Epoch 4:   0%|          | 4/1000 [21:28<86:38:09, 313.14s/it, lr=0.001, test_acc=51.8, time=180, train_acc=54.2, train_loss=1.25, val_acc=50.7, val_loss=1.35]Epoch 4:   0%|          | 5/1000 [21:28<75:31:56, 273.28s/it, lr=0.001, test_acc=51.8, time=180, train_acc=54.2, train_loss=1.25, val_acc=50.7, val_loss=1.35]Epoch 5:   0%|          | 5/1000 [21:28<75:31:56, 273.28s/it, lr=0.001, test_acc=51.8, time=180, train_acc=54.2, train_loss=1.25, val_acc=50.7, val_loss=1.35]Epoch 5:   0%|          | 5/1000 [24:28<75:31:56, 273.28s/it, lr=0.001, test_acc=54, time=180, train_acc=54.6, train_loss=1.24, val_acc=52.4, val_loss=1.31]  Epoch 5:   1%|          | 6/1000 [24:28<67:44:53, 245.37s/it, lr=0.001, test_acc=54, time=180, train_acc=54.6, train_loss=1.24, val_acc=52.4, val_loss=1.31]Epoch 6:   1%|          | 6/1000 [24:28<67:44:53, 245.37s/it, lr=0.001, test_acc=54, time=180, train_acc=54.6, train_loss=1.24, val_acc=52.4, val_loss=1.31]Epoch 6:   1%|          | 6/1000 [27:29<67:44:53, 245.37s/it, lr=0.001, test_acc=53.7, time=180, train_acc=54.9, train_loss=1.23, val_acc=52.7, val_loss=1.31]Epoch 6:   1%|          | 7/1000 [27:29<62:17:32, 225.83s/it, lr=0.001, test_acc=53.7, time=180, train_acc=54.9, train_loss=1.23, val_acc=52.7, val_loss=1.31]Epoch 7:   1%|          | 7/1000 [27:29<62:17:32, 225.83s/it, lr=0.001, test_acc=53.7, time=180, train_acc=54.9, train_loss=1.23, val_acc=52.7, val_loss=1.31]Epoch 7:   1%|          | 7/1000 [30:29<62:17:32, 225.83s/it, lr=0.001, test_acc=52.9, time=180, train_acc=55.1, train_loss=1.23, val_acc=52, val_loss=1.32]  Epoch 7:   1%|          | 8/1000 [30:29<58:27:44, 212.16s/it, lr=0.001, test_acc=52.9, time=180, train_acc=55.1, train_loss=1.23, val_acc=52, val_loss=1.32]Epoch 8:   1%|          | 8/1000 [30:29<58:27:44, 212.16s/it, lr=0.001, test_acc=52.9, time=180, train_acc=55.1, train_loss=1.23, val_acc=52, val_loss=1.32]Epoch 8:   1%|          | 8/1000 [33:29<58:27:44, 212.16s/it, lr=0.001, test_acc=49.1, time=180, train_acc=55.3, train_loss=1.22, val_acc=48.1, val_loss=1.39]Epoch 8:   1%|          | 9/1000 [33:29<55:46:24, 202.61s/it, lr=0.001, test_acc=49.1, time=180, train_acc=55.3, train_loss=1.22, val_acc=48.1, val_loss=1.39]Epoch 9:   1%|          | 9/1000 [33:29<55:46:24, 202.61s/it, lr=0.001, test_acc=49.1, time=180, train_acc=55.3, train_loss=1.22, val_acc=48.1, val_loss=1.39]Epoch 9:   1%|          | 9/1000 [36:28<55:46:24, 202.61s/it, lr=0.001, test_acc=44.8, time=179, train_acc=55.7, train_loss=1.22, val_acc=43.8, val_loss=1.51]Epoch 9:   1%|          | 10/1000 [36:28<53:46:57, 195.57s/it, lr=0.001, test_acc=44.8, time=179, train_acc=55.7, train_loss=1.22, val_acc=43.8, val_loss=1.51]Epoch 10:   1%|          | 10/1000 [36:28<53:46:57, 195.57s/it, lr=0.001, test_acc=44.8, time=179, train_acc=55.7, train_loss=1.22, val_acc=43.8, val_loss=1.51]Epoch 10:   1%|          | 10/1000 [39:26<53:46:57, 195.57s/it, lr=0.001, test_acc=42.8, time=177, train_acc=55.8, train_loss=1.21, val_acc=42, val_loss=1.52]  Epoch 10:   1%|          | 11/1000 [39:26<52:13:40, 190.11s/it, lr=0.001, test_acc=42.8, time=177, train_acc=55.8, train_loss=1.21, val_acc=42, val_loss=1.52]Epoch 11:   1%|          | 11/1000 [39:26<52:13:40, 190.11s/it, lr=0.001, test_acc=42.8, time=177, train_acc=55.8, train_loss=1.21, val_acc=42, val_loss=1.52]Epoch 11:   1%|          | 11/1000 [42:21<52:13:40, 190.11s/it, lr=0.001, test_acc=47.6, time=175, train_acc=55.9, train_loss=1.21, val_acc=47.1, val_loss=1.44]Epoch 11:   1%|          | 12/1000 [42:21<50:58:07, 185.72s/it, lr=0.001, test_acc=47.6, time=175, train_acc=55.9, train_loss=1.21, val_acc=47.1, val_loss=1.44]Epoch 12:   1%|          | 12/1000 [42:21<50:58:07, 185.72s/it, lr=0.001, test_acc=47.6, time=175, train_acc=55.9, train_loss=1.21, val_acc=47.1, val_loss=1.44]Epoch 12:   1%|          | 12/1000 [45:15<50:58:07, 185.72s/it, lr=0.001, test_acc=54.3, time=174, train_acc=56.3, train_loss=1.21, val_acc=52.8, val_loss=1.3] Epoch 12:   1%|▏         | 13/1000 [45:15<49:55:56, 182.12s/it, lr=0.001, test_acc=54.3, time=174, train_acc=56.3, train_loss=1.21, val_acc=52.8, val_loss=1.3]Epoch 13:   1%|▏         | 13/1000 [45:15<49:55:56, 182.12s/it, lr=0.001, test_acc=54.3, time=174, train_acc=56.3, train_loss=1.21, val_acc=52.8, val_loss=1.3]Epoch 13:   1%|▏         | 13/1000 [48:07<49:55:56, 182.12s/it, lr=0.001, test_acc=42.5, time=172, train_acc=56.4, train_loss=1.2, val_acc=41.2, val_loss=1.62]Epoch 13:   1%|▏         | 14/1000 [48:07<49:03:49, 179.14s/it, lr=0.001, test_acc=42.5, time=172, train_acc=56.4, train_loss=1.2, val_acc=41.2, val_loss=1.62]Epoch 14:   1%|▏         | 14/1000 [48:07<49:03:49, 179.14s/it, lr=0.001, test_acc=42.5, time=172, train_acc=56.4, train_loss=1.2, val_acc=41.2, val_loss=1.62]Epoch 14:   1%|▏         | 14/1000 [50:58<49:03:49, 179.14s/it, lr=0.001, test_acc=48.7, time=171, train_acc=56.5, train_loss=1.2, val_acc=47.6, val_loss=1.42]Epoch 14:   2%|▏         | 15/1000 [50:58<48:19:41, 176.63s/it, lr=0.001, test_acc=48.7, time=171, train_acc=56.5, train_loss=1.2, val_acc=47.6, val_loss=1.42]Epoch 15:   2%|▏         | 15/1000 [50:58<48:19:41, 176.63s/it, lr=0.001, test_acc=48.7, time=171, train_acc=56.5, train_loss=1.2, val_acc=47.6, val_loss=1.42]Epoch 15:   2%|▏         | 15/1000 [53:47<48:19:41, 176.63s/it, lr=0.001, test_acc=48.1, time=169, train_acc=56.6, train_loss=1.2, val_acc=47.6, val_loss=1.46]Epoch 15:   2%|▏         | 16/1000 [53:47<47:41:13, 174.46s/it, lr=0.001, test_acc=48.1, time=169, train_acc=56.6, train_loss=1.2, val_acc=47.6, val_loss=1.46]Epoch 16:   2%|▏         | 16/1000 [53:47<47:41:13, 174.46s/it, lr=0.001, test_acc=48.1, time=169, train_acc=56.6, train_loss=1.2, val_acc=47.6, val_loss=1.46]Epoch 16:   2%|▏         | 16/1000 [56:35<47:41:13, 174.46s/it, lr=0.001, test_acc=50.1, time=168, train_acc=56.7, train_loss=1.2, val_acc=48.9, val_loss=1.5] Epoch 16:   2%|▏         | 17/1000 [56:35<47:06:21, 172.51s/it, lr=0.001, test_acc=50.1, time=168, train_acc=56.7, train_loss=1.2, val_acc=48.9, val_loss=1.5]Epoch 17:   2%|▏         | 17/1000 [56:35<47:06:21, 172.51s/it, lr=0.001, test_acc=50.1, time=168, train_acc=56.7, train_loss=1.2, val_acc=48.9, val_loss=1.5]Epoch 17:   2%|▏         | 17/1000 [59:22<47:06:21, 172.51s/it, lr=0.001, test_acc=50.7, time=166, train_acc=56.9, train_loss=1.19, val_acc=49.3, val_loss=1.39]Epoch 17:   2%|▏         | 18/1000 [59:22<46:33:58, 170.71s/it, lr=0.001, test_acc=50.7, time=166, train_acc=56.9, train_loss=1.19, val_acc=49.3, val_loss=1.39]Epoch 18:   2%|▏         | 18/1000 [59:22<46:33:58, 170.71s/it, lr=0.001, test_acc=50.7, time=166, train_acc=56.9, train_loss=1.19, val_acc=49.3, val_loss=1.39]Epoch 18:   2%|▏         | 18/1000 [1:02:06<46:33:58, 170.71s/it, lr=0.001, test_acc=50.6, time=165, train_acc=57, train_loss=1.19, val_acc=49.6, val_loss=1.4] Epoch    19: reducing learning rate of group 0 to 5.0000e-04.
Epoch 18:   2%|▏         | 19/1000 [1:02:06<46:01:34, 168.90s/it, lr=0.001, test_acc=50.6, time=165, train_acc=57, train_loss=1.19, val_acc=49.6, val_loss=1.4]Epoch 19:   2%|▏         | 19/1000 [1:02:06<46:01:34, 168.90s/it, lr=0.001, test_acc=50.6, time=165, train_acc=57, train_loss=1.19, val_acc=49.6, val_loss=1.4]Epoch 19:   2%|▏         | 19/1000 [1:04:49<46:01:34, 168.90s/it, lr=0.0005, test_acc=53.3, time=163, train_acc=57.3, train_loss=1.18, val_acc=51.8, val_loss=1.34]Epoch 19:   2%|▏         | 20/1000 [1:04:49<45:29:49, 167.13s/it, lr=0.0005, test_acc=53.3, time=163, train_acc=57.3, train_loss=1.18, val_acc=51.8, val_loss=1.34]Epoch 20:   2%|▏         | 20/1000 [1:04:49<45:29:49, 167.13s/it, lr=0.0005, test_acc=53.3, time=163, train_acc=57.3, train_loss=1.18, val_acc=51.8, val_loss=1.34]Epoch 20:   2%|▏         | 20/1000 [1:07:32<45:29:49, 167.13s/it, lr=0.0005, test_acc=52.8, time=163, train_acc=57.5, train_loss=1.18, val_acc=51.5, val_loss=1.33]Epoch 20:   2%|▏         | 21/1000 [1:07:32<45:05:40, 165.82s/it, lr=0.0005, test_acc=52.8, time=163, train_acc=57.5, train_loss=1.18, val_acc=51.5, val_loss=1.33]Epoch 21:   2%|▏         | 21/1000 [1:07:32<45:05:40, 165.82s/it, lr=0.0005, test_acc=52.8, time=163, train_acc=57.5, train_loss=1.18, val_acc=51.5, val_loss=1.33]Epoch 21:   2%|▏         | 21/1000 [1:10:15<45:05:40, 165.82s/it, lr=0.0005, test_acc=55.3, time=163, train_acc=57.6, train_loss=1.18, val_acc=53.7, val_loss=1.28]Epoch 21:   2%|▏         | 22/1000 [1:10:15<44:47:31, 164.88s/it, lr=0.0005, test_acc=55.3, time=163, train_acc=57.6, train_loss=1.18, val_acc=53.7, val_loss=1.28]Epoch 22:   2%|▏         | 22/1000 [1:10:15<44:47:31, 164.88s/it, lr=0.0005, test_acc=55.3, time=163, train_acc=57.6, train_loss=1.18, val_acc=53.7, val_loss=1.28]Epoch 22:   2%|▏         | 22/1000 [1:12:58<44:47:31, 164.88s/it, lr=0.0005, test_acc=51.6, time=163, train_acc=57.7, train_loss=1.17, val_acc=50.8, val_loss=1.38]Epoch 22:   2%|▏         | 23/1000 [1:12:58<44:33:38, 164.20s/it, lr=0.0005, test_acc=51.6, time=163, train_acc=57.7, train_loss=1.17, val_acc=50.8, val_loss=1.38]Epoch 23:   2%|▏         | 23/1000 [1:12:58<44:33:38, 164.20s/it, lr=0.0005, test_acc=51.6, time=163, train_acc=57.7, train_loss=1.17, val_acc=50.8, val_loss=1.38]Epoch 23:   2%|▏         | 23/1000 [1:15:40<44:33:38, 164.20s/it, lr=0.0005, test_acc=52.2, time=163, train_acc=57.7, train_loss=1.18, val_acc=50.7, val_loss=1.36]Epoch 23:   2%|▏         | 24/1000 [1:15:40<44:23:22, 163.73s/it, lr=0.0005, test_acc=52.2, time=163, train_acc=57.7, train_loss=1.18, val_acc=50.7, val_loss=1.36]Epoch 24:   2%|▏         | 24/1000 [1:15:40<44:23:22, 163.73s/it, lr=0.0005, test_acc=52.2, time=163, train_acc=57.7, train_loss=1.18, val_acc=50.7, val_loss=1.36]Epoch 24:   2%|▏         | 24/1000 [1:18:23<44:23:22, 163.73s/it, lr=0.0005, test_acc=49.2, time=163, train_acc=57.8, train_loss=1.17, val_acc=48.6, val_loss=1.42]Epoch 24:   2%|▎         | 25/1000 [1:18:23<44:15:10, 163.40s/it, lr=0.0005, test_acc=49.2, time=163, train_acc=57.8, train_loss=1.17, val_acc=48.6, val_loss=1.42]Epoch 25:   2%|▎         | 25/1000 [1:18:23<44:15:10, 163.40s/it, lr=0.0005, test_acc=49.2, time=163, train_acc=57.8, train_loss=1.17, val_acc=48.6, val_loss=1.42]Epoch 25:   2%|▎         | 25/1000 [1:21:05<44:15:10, 163.40s/it, lr=0.0005, test_acc=50.4, time=163, train_acc=57.9, train_loss=1.17, val_acc=49.4, val_loss=1.41]Epoch 25:   3%|▎         | 26/1000 [1:21:05<44:09:03, 163.19s/it, lr=0.0005, test_acc=50.4, time=163, train_acc=57.9, train_loss=1.17, val_acc=49.4, val_loss=1.41]Epoch 26:   3%|▎         | 26/1000 [1:21:05<44:09:03, 163.19s/it, lr=0.0005, test_acc=50.4, time=163, train_acc=57.9, train_loss=1.17, val_acc=49.4, val_loss=1.41]Epoch 26:   3%|▎         | 26/1000 [1:23:48<44:09:03, 163.19s/it, lr=0.0005, test_acc=48.9, time=163, train_acc=57.9, train_loss=1.17, val_acc=47, val_loss=1.5]   Epoch 26:   3%|▎         | 27/1000 [1:23:48<44:03:37, 163.02s/it, lr=0.0005, test_acc=48.9, time=163, train_acc=57.9, train_loss=1.17, val_acc=47, val_loss=1.5]Epoch 27:   3%|▎         | 27/1000 [1:23:48<44:03:37, 163.02s/it, lr=0.0005, test_acc=48.9, time=163, train_acc=57.9, train_loss=1.17, val_acc=47, val_loss=1.5]Epoch 27:   3%|▎         | 27/1000 [1:26:31<44:03:37, 163.02s/it, lr=0.0005, test_acc=53.4, time=163, train_acc=57.9, train_loss=1.17, val_acc=52.1, val_loss=1.34]Epoch    28: reducing learning rate of group 0 to 2.5000e-04.
Epoch 27:   3%|▎         | 28/1000 [1:26:31<43:59:15, 162.92s/it, lr=0.0005, test_acc=53.4, time=163, train_acc=57.9, train_loss=1.17, val_acc=52.1, val_loss=1.34]Epoch 28:   3%|▎         | 28/1000 [1:26:31<43:59:15, 162.92s/it, lr=0.0005, test_acc=53.4, time=163, train_acc=57.9, train_loss=1.17, val_acc=52.1, val_loss=1.34]Epoch 28:   3%|▎         | 28/1000 [1:29:13<43:59:15, 162.92s/it, lr=0.00025, test_acc=55, time=163, train_acc=58.3, train_loss=1.16, val_acc=52.9, val_loss=1.31] Epoch 28:   3%|▎         | 29/1000 [1:29:13<43:55:12, 162.83s/it, lr=0.00025, test_acc=55, time=163, train_acc=58.3, train_loss=1.16, val_acc=52.9, val_loss=1.31]Epoch 29:   3%|▎         | 29/1000 [1:29:13<43:55:12, 162.83s/it, lr=0.00025, test_acc=55, time=163, train_acc=58.3, train_loss=1.16, val_acc=52.9, val_loss=1.31]Epoch 29:   3%|▎         | 29/1000 [1:31:56<43:55:12, 162.83s/it, lr=0.00025, test_acc=54.5, time=163, train_acc=58.4, train_loss=1.16, val_acc=52.7, val_loss=1.3]Epoch 29:   3%|▎         | 30/1000 [1:31:56<43:51:40, 162.78s/it, lr=0.00025, test_acc=54.5, time=163, train_acc=58.4, train_loss=1.16, val_acc=52.7, val_loss=1.3]Epoch 30:   3%|▎         | 30/1000 [1:31:56<43:51:40, 162.78s/it, lr=0.00025, test_acc=54.5, time=163, train_acc=58.4, train_loss=1.16, val_acc=52.7, val_loss=1.3]Epoch 30:   3%|▎         | 30/1000 [1:34:39<43:51:40, 162.78s/it, lr=0.00025, test_acc=52.5, time=163, train_acc=58.5, train_loss=1.16, val_acc=51.1, val_loss=1.34]Epoch 30:   3%|▎         | 31/1000 [1:34:39<43:48:29, 162.75s/it, lr=0.00025, test_acc=52.5, time=163, train_acc=58.5, train_loss=1.16, val_acc=51.1, val_loss=1.34]Epoch 31:   3%|▎         | 31/1000 [1:34:39<43:48:29, 162.75s/it, lr=0.00025, test_acc=52.5, time=163, train_acc=58.5, train_loss=1.16, val_acc=51.1, val_loss=1.34]Epoch 31:   3%|▎         | 31/1000 [1:37:21<43:48:29, 162.75s/it, lr=0.00025, test_acc=53.8, time=163, train_acc=58.5, train_loss=1.16, val_acc=52.2, val_loss=1.33]Epoch 31:   3%|▎         | 32/1000 [1:37:21<43:45:17, 162.72s/it, lr=0.00025, test_acc=53.8, time=163, train_acc=58.5, train_loss=1.16, val_acc=52.2, val_loss=1.33]Epoch 32:   3%|▎         | 32/1000 [1:37:21<43:45:17, 162.72s/it, lr=0.00025, test_acc=53.8, time=163, train_acc=58.5, train_loss=1.16, val_acc=52.2, val_loss=1.33]Epoch 32:   3%|▎         | 32/1000 [1:40:04<43:45:17, 162.72s/it, lr=0.00025, test_acc=54.8, time=163, train_acc=58.6, train_loss=1.16, val_acc=53.4, val_loss=1.3] Epoch 32:   3%|▎         | 33/1000 [1:40:04<43:42:42, 162.73s/it, lr=0.00025, test_acc=54.8, time=163, train_acc=58.6, train_loss=1.16, val_acc=53.4, val_loss=1.3]Epoch 33:   3%|▎         | 33/1000 [1:40:04<43:42:42, 162.73s/it, lr=0.00025, test_acc=54.8, time=163, train_acc=58.6, train_loss=1.16, val_acc=53.4, val_loss=1.3]Epoch 33:   3%|▎         | 33/1000 [1:42:47<43:42:42, 162.73s/it, lr=0.00025, test_acc=54.5, time=163, train_acc=58.5, train_loss=1.16, val_acc=53, val_loss=1.29] Epoch    34: reducing learning rate of group 0 to 1.2500e-04.
Epoch 33:   3%|▎         | 34/1000 [1:42:47<43:39:19, 162.69s/it, lr=0.00025, test_acc=54.5, time=163, train_acc=58.5, train_loss=1.16, val_acc=53, val_loss=1.29]Epoch 34:   3%|▎         | 34/1000 [1:42:47<43:39:19, 162.69s/it, lr=0.00025, test_acc=54.5, time=163, train_acc=58.5, train_loss=1.16, val_acc=53, val_loss=1.29]Epoch 34:   3%|▎         | 34/1000 [1:45:29<43:39:19, 162.69s/it, lr=0.000125, test_acc=55.1, time=163, train_acc=58.7, train_loss=1.15, val_acc=53.7, val_loss=1.27]Epoch 34:   4%|▎         | 35/1000 [1:45:30<43:36:44, 162.70s/it, lr=0.000125, test_acc=55.1, time=163, train_acc=58.7, train_loss=1.15, val_acc=53.7, val_loss=1.27]Epoch 35:   4%|▎         | 35/1000 [1:45:30<43:36:44, 162.70s/it, lr=0.000125, test_acc=55.1, time=163, train_acc=58.7, train_loss=1.15, val_acc=53.7, val_loss=1.27]Epoch 35:   4%|▎         | 35/1000 [1:48:12<43:36:44, 162.70s/it, lr=0.000125, test_acc=54.7, time=163, train_acc=58.8, train_loss=1.15, val_acc=53.5, val_loss=1.28]Epoch 35:   4%|▎         | 36/1000 [1:48:12<43:33:52, 162.69s/it, lr=0.000125, test_acc=54.7, time=163, train_acc=58.8, train_loss=1.15, val_acc=53.5, val_loss=1.28]Epoch 36:   4%|▎         | 36/1000 [1:48:12<43:33:52, 162.69s/it, lr=0.000125, test_acc=54.7, time=163, train_acc=58.8, train_loss=1.15, val_acc=53.5, val_loss=1.28]Epoch 36:   4%|▎         | 36/1000 [1:50:55<43:33:52, 162.69s/it, lr=0.000125, test_acc=55.8, time=163, train_acc=59, train_loss=1.15, val_acc=54.4, val_loss=1.26]  Epoch 36:   4%|▎         | 37/1000 [1:50:55<43:31:27, 162.71s/it, lr=0.000125, test_acc=55.8, time=163, train_acc=59, train_loss=1.15, val_acc=54.4, val_loss=1.26]Epoch 37:   4%|▎         | 37/1000 [1:50:55<43:31:27, 162.71s/it, lr=0.000125, test_acc=55.8, time=163, train_acc=59, train_loss=1.15, val_acc=54.4, val_loss=1.26]Epoch 37:   4%|▎         | 37/1000 [1:53:38<43:31:27, 162.71s/it, lr=0.000125, test_acc=54.2, time=163, train_acc=58.9, train_loss=1.15, val_acc=52.5, val_loss=1.3]Epoch 37:   4%|▍         | 38/1000 [1:53:38<43:28:37, 162.70s/it, lr=0.000125, test_acc=54.2, time=163, train_acc=58.9, train_loss=1.15, val_acc=52.5, val_loss=1.3]Epoch 38:   4%|▍         | 38/1000 [1:53:38<43:28:37, 162.70s/it, lr=0.000125, test_acc=54.2, time=163, train_acc=58.9, train_loss=1.15, val_acc=52.5, val_loss=1.3]Epoch 38:   4%|▍         | 38/1000 [1:56:20<43:28:37, 162.70s/it, lr=0.000125, test_acc=53.7, time=163, train_acc=59, train_loss=1.15, val_acc=52.2, val_loss=1.31] Epoch 38:   4%|▍         | 39/1000 [1:56:20<43:25:34, 162.68s/it, lr=0.000125, test_acc=53.7, time=163, train_acc=59, train_loss=1.15, val_acc=52.2, val_loss=1.31]Epoch 39:   4%|▍         | 39/1000 [1:56:20<43:25:34, 162.68s/it, lr=0.000125, test_acc=53.7, time=163, train_acc=59, train_loss=1.15, val_acc=52.2, val_loss=1.31]Epoch 39:   4%|▍         | 39/1000 [1:59:03<43:25:34, 162.68s/it, lr=0.000125, test_acc=54.7, time=163, train_acc=59, train_loss=1.15, val_acc=53.3, val_loss=1.29]Epoch 39:   4%|▍         | 40/1000 [1:59:03<43:22:51, 162.68s/it, lr=0.000125, test_acc=54.7, time=163, train_acc=59, train_loss=1.15, val_acc=53.3, val_loss=1.29]Epoch 40:   4%|▍         | 40/1000 [1:59:03<43:22:51, 162.68s/it, lr=0.000125, test_acc=54.7, time=163, train_acc=59, train_loss=1.15, val_acc=53.3, val_loss=1.29]Epoch 40:   4%|▍         | 40/1000 [2:01:46<43:22:51, 162.68s/it, lr=0.000125, test_acc=55.9, time=163, train_acc=58.9, train_loss=1.15, val_acc=54, val_loss=1.27]Epoch 40:   4%|▍         | 41/1000 [2:01:46<43:20:11, 162.68s/it, lr=0.000125, test_acc=55.9, time=163, train_acc=58.9, train_loss=1.15, val_acc=54, val_loss=1.27]Epoch 41:   4%|▍         | 41/1000 [2:01:46<43:20:11, 162.68s/it, lr=0.000125, test_acc=55.9, time=163, train_acc=58.9, train_loss=1.15, val_acc=54, val_loss=1.27]Epoch 41:   4%|▍         | 41/1000 [2:04:28<43:20:11, 162.68s/it, lr=0.000125, test_acc=55.5, time=163, train_acc=59, train_loss=1.15, val_acc=53.9, val_loss=1.27]Epoch 41:   4%|▍         | 42/1000 [2:04:28<43:17:19, 162.67s/it, lr=0.000125, test_acc=55.5, time=163, train_acc=59, train_loss=1.15, val_acc=53.9, val_loss=1.27]Epoch 42:   4%|▍         | 42/1000 [2:04:28<43:17:19, 162.67s/it, lr=0.000125, test_acc=55.5, time=163, train_acc=59, train_loss=1.15, val_acc=53.9, val_loss=1.27]Epoch 42:   4%|▍         | 42/1000 [2:07:11<43:17:19, 162.67s/it, lr=0.000125, test_acc=55.9, time=163, train_acc=59.1, train_loss=1.15, val_acc=53.9, val_loss=1.27]Epoch    43: reducing learning rate of group 0 to 6.2500e-05.
Epoch 42:   4%|▍         | 43/1000 [2:07:11<43:14:15, 162.65s/it, lr=0.000125, test_acc=55.9, time=163, train_acc=59.1, train_loss=1.15, val_acc=53.9, val_loss=1.27]Epoch 43:   4%|▍         | 43/1000 [2:07:11<43:14:15, 162.65s/it, lr=0.000125, test_acc=55.9, time=163, train_acc=59.1, train_loss=1.15, val_acc=53.9, val_loss=1.27]Epoch 43:   4%|▍         | 43/1000 [2:09:54<43:14:15, 162.65s/it, lr=6.25e-5, test_acc=56.3, time=163, train_acc=59.1, train_loss=1.15, val_acc=54.4, val_loss=1.25] Epoch 43:   4%|▍         | 44/1000 [2:09:54<43:11:43, 162.66s/it, lr=6.25e-5, test_acc=56.3, time=163, train_acc=59.1, train_loss=1.15, val_acc=54.4, val_loss=1.25]Epoch 44:   4%|▍         | 44/1000 [2:09:54<43:11:43, 162.66s/it, lr=6.25e-5, test_acc=56.3, time=163, train_acc=59.1, train_loss=1.15, val_acc=54.4, val_loss=1.25]Epoch 44:   4%|▍         | 44/1000 [2:12:36<43:11:43, 162.66s/it, lr=6.25e-5, test_acc=56.3, time=163, train_acc=59.1, train_loss=1.15, val_acc=54.7, val_loss=1.25]Epoch 44:   4%|▍         | 45/1000 [2:12:36<43:08:56, 162.66s/it, lr=6.25e-5, test_acc=56.3, time=163, train_acc=59.1, train_loss=1.15, val_acc=54.7, val_loss=1.25]Epoch 45:   4%|▍         | 45/1000 [2:12:36<43:08:56, 162.66s/it, lr=6.25e-5, test_acc=56.3, time=163, train_acc=59.1, train_loss=1.15, val_acc=54.7, val_loss=1.25]Epoch 45:   4%|▍         | 45/1000 [2:15:19<43:08:56, 162.66s/it, lr=6.25e-5, test_acc=55.5, time=163, train_acc=59.2, train_loss=1.15, val_acc=54.3, val_loss=1.26]Epoch 45:   5%|▍         | 46/1000 [2:15:19<43:06:12, 162.66s/it, lr=6.25e-5, test_acc=55.5, time=163, train_acc=59.2, train_loss=1.15, val_acc=54.3, val_loss=1.26]Epoch 46:   5%|▍         | 46/1000 [2:15:19<43:06:12, 162.66s/it, lr=6.25e-5, test_acc=55.5, time=163, train_acc=59.2, train_loss=1.15, val_acc=54.3, val_loss=1.26]Epoch 46:   5%|▍         | 46/1000 [2:18:01<43:06:12, 162.66s/it, lr=6.25e-5, test_acc=56.4, time=163, train_acc=59.2, train_loss=1.14, val_acc=54.8, val_loss=1.25]Epoch 46:   5%|▍         | 47/1000 [2:18:01<43:03:20, 162.65s/it, lr=6.25e-5, test_acc=56.4, time=163, train_acc=59.2, train_loss=1.14, val_acc=54.8, val_loss=1.25]Epoch 47:   5%|▍         | 47/1000 [2:18:01<43:03:20, 162.65s/it, lr=6.25e-5, test_acc=56.4, time=163, train_acc=59.2, train_loss=1.14, val_acc=54.8, val_loss=1.25]Epoch 47:   5%|▍         | 47/1000 [2:20:44<43:03:20, 162.65s/it, lr=6.25e-5, test_acc=56.3, time=163, train_acc=59.2, train_loss=1.14, val_acc=54.6, val_loss=1.25]Epoch 47:   5%|▍         | 48/1000 [2:20:44<43:00:49, 162.66s/it, lr=6.25e-5, test_acc=56.3, time=163, train_acc=59.2, train_loss=1.14, val_acc=54.6, val_loss=1.25]Epoch 48:   5%|▍         | 48/1000 [2:20:44<43:00:49, 162.66s/it, lr=6.25e-5, test_acc=56.3, time=163, train_acc=59.2, train_loss=1.14, val_acc=54.6, val_loss=1.25]Epoch 48:   5%|▍         | 48/1000 [2:23:27<43:00:49, 162.66s/it, lr=6.25e-5, test_acc=55.7, time=163, train_acc=59.2, train_loss=1.15, val_acc=54, val_loss=1.27]  Epoch 48:   5%|▍         | 49/1000 [2:23:27<42:57:59, 162.65s/it, lr=6.25e-5, test_acc=55.7, time=163, train_acc=59.2, train_loss=1.15, val_acc=54, val_loss=1.27]Epoch 49:   5%|▍         | 49/1000 [2:23:27<42:57:59, 162.65s/it, lr=6.25e-5, test_acc=55.7, time=163, train_acc=59.2, train_loss=1.15, val_acc=54, val_loss=1.27]Epoch 49:   5%|▍         | 49/1000 [2:26:10<42:57:59, 162.65s/it, lr=6.25e-5, test_acc=56.1, time=163, train_acc=59.2, train_loss=1.14, val_acc=54.4, val_loss=1.26]Epoch 49:   5%|▌         | 50/1000 [2:26:10<42:56:39, 162.74s/it, lr=6.25e-5, test_acc=56.1, time=163, train_acc=59.2, train_loss=1.14, val_acc=54.4, val_loss=1.26]Epoch 50:   5%|▌         | 50/1000 [2:26:10<42:56:39, 162.74s/it, lr=6.25e-5, test_acc=56.1, time=163, train_acc=59.2, train_loss=1.14, val_acc=54.4, val_loss=1.26]Epoch 50:   5%|▌         | 50/1000 [2:28:52<42:56:39, 162.74s/it, lr=6.25e-5, test_acc=55.8, time=162, train_acc=59.2, train_loss=1.14, val_acc=54.2, val_loss=1.27]Epoch    51: reducing learning rate of group 0 to 3.1250e-05.
Epoch 50:   5%|▌         | 51/1000 [2:28:52<42:52:00, 162.61s/it, lr=6.25e-5, test_acc=55.8, time=162, train_acc=59.2, train_loss=1.14, val_acc=54.2, val_loss=1.27]Epoch 51:   5%|▌         | 51/1000 [2:28:52<42:52:00, 162.61s/it, lr=6.25e-5, test_acc=55.8, time=162, train_acc=59.2, train_loss=1.14, val_acc=54.2, val_loss=1.27]Epoch 51:   5%|▌         | 51/1000 [2:31:35<42:52:00, 162.61s/it, lr=3.13e-5, test_acc=56.4, time=163, train_acc=59.2, train_loss=1.14, val_acc=54.7, val_loss=1.25]Epoch 51:   5%|▌         | 52/1000 [2:31:35<42:49:18, 162.61s/it, lr=3.13e-5, test_acc=56.4, time=163, train_acc=59.2, train_loss=1.14, val_acc=54.7, val_loss=1.25]Epoch 52:   5%|▌         | 52/1000 [2:31:35<42:49:18, 162.61s/it, lr=3.13e-5, test_acc=56.4, time=163, train_acc=59.2, train_loss=1.14, val_acc=54.7, val_loss=1.25]Epoch 52:   5%|▌         | 52/1000 [2:34:17<42:49:18, 162.61s/it, lr=3.13e-5, test_acc=56.4, time=163, train_acc=59.4, train_loss=1.14, val_acc=54.6, val_loss=1.25]Epoch 52:   5%|▌         | 53/1000 [2:34:17<42:46:31, 162.61s/it, lr=3.13e-5, test_acc=56.4, time=163, train_acc=59.4, train_loss=1.14, val_acc=54.6, val_loss=1.25]Epoch 53:   5%|▌         | 53/1000 [2:34:17<42:46:31, 162.61s/it, lr=3.13e-5, test_acc=56.4, time=163, train_acc=59.4, train_loss=1.14, val_acc=54.6, val_loss=1.25]Epoch 53:   5%|▌         | 53/1000 [2:37:00<42:46:31, 162.61s/it, lr=3.13e-5, test_acc=56.5, time=163, train_acc=59.3, train_loss=1.14, val_acc=54.7, val_loss=1.25]Epoch 53:   5%|▌         | 54/1000 [2:37:00<42:44:02, 162.62s/it, lr=3.13e-5, test_acc=56.5, time=163, train_acc=59.3, train_loss=1.14, val_acc=54.7, val_loss=1.25]Epoch 54:   5%|▌         | 54/1000 [2:37:00<42:44:02, 162.62s/it, lr=3.13e-5, test_acc=56.5, time=163, train_acc=59.3, train_loss=1.14, val_acc=54.7, val_loss=1.25]Epoch 54:   5%|▌         | 54/1000 [2:39:43<42:44:02, 162.62s/it, lr=3.13e-5, test_acc=56.5, time=163, train_acc=59.4, train_loss=1.14, val_acc=54.8, val_loss=1.25]Epoch 54:   6%|▌         | 55/1000 [2:39:43<42:41:31, 162.64s/it, lr=3.13e-5, test_acc=56.5, time=163, train_acc=59.4, train_loss=1.14, val_acc=54.8, val_loss=1.25]Epoch 55:   6%|▌         | 55/1000 [2:39:43<42:41:31, 162.64s/it, lr=3.13e-5, test_acc=56.5, time=163, train_acc=59.4, train_loss=1.14, val_acc=54.8, val_loss=1.25]Epoch 55:   6%|▌         | 55/1000 [2:42:25<42:41:31, 162.64s/it, lr=3.13e-5, test_acc=56.5, time=163, train_acc=59.3, train_loss=1.14, val_acc=54.8, val_loss=1.25]Epoch 55:   6%|▌         | 56/1000 [2:42:25<42:38:31, 162.62s/it, lr=3.13e-5, test_acc=56.5, time=163, train_acc=59.3, train_loss=1.14, val_acc=54.8, val_loss=1.25]Epoch 56:   6%|▌         | 56/1000 [2:42:25<42:38:31, 162.62s/it, lr=3.13e-5, test_acc=56.5, time=163, train_acc=59.3, train_loss=1.14, val_acc=54.8, val_loss=1.25]Epoch 56:   6%|▌         | 56/1000 [2:45:08<42:38:31, 162.62s/it, lr=3.13e-5, test_acc=56.3, time=163, train_acc=59.4, train_loss=1.14, val_acc=54.5, val_loss=1.25]Epoch    57: reducing learning rate of group 0 to 1.5625e-05.
Epoch 56:   6%|▌         | 57/1000 [2:45:08<42:37:25, 162.72s/it, lr=3.13e-5, test_acc=56.3, time=163, train_acc=59.4, train_loss=1.14, val_acc=54.5, val_loss=1.25]Epoch 57:   6%|▌         | 57/1000 [2:45:08<42:37:25, 162.72s/it, lr=3.13e-5, test_acc=56.3, time=163, train_acc=59.4, train_loss=1.14, val_acc=54.5, val_loss=1.25]Epoch 57:   6%|▌         | 57/1000 [2:47:51<42:37:25, 162.72s/it, lr=1.56e-5, test_acc=56.5, time=163, train_acc=59.4, train_loss=1.14, val_acc=54.9, val_loss=1.25]Epoch 57:   6%|▌         | 58/1000 [2:47:51<42:34:25, 162.70s/it, lr=1.56e-5, test_acc=56.5, time=163, train_acc=59.4, train_loss=1.14, val_acc=54.9, val_loss=1.25]Epoch 58:   6%|▌         | 58/1000 [2:47:51<42:34:25, 162.70s/it, lr=1.56e-5, test_acc=56.5, time=163, train_acc=59.4, train_loss=1.14, val_acc=54.9, val_loss=1.25]Epoch 58:   6%|▌         | 58/1000 [2:50:33<42:34:25, 162.70s/it, lr=1.56e-5, test_acc=56.7, time=163, train_acc=59.4, train_loss=1.14, val_acc=54.7, val_loss=1.25]Epoch 58:   6%|▌         | 59/1000 [2:50:33<42:31:28, 162.69s/it, lr=1.56e-5, test_acc=56.7, time=163, train_acc=59.4, train_loss=1.14, val_acc=54.7, val_loss=1.25]Epoch 59:   6%|▌         | 59/1000 [2:50:33<42:31:28, 162.69s/it, lr=1.56e-5, test_acc=56.7, time=163, train_acc=59.4, train_loss=1.14, val_acc=54.7, val_loss=1.25]Epoch 59:   6%|▌         | 59/1000 [2:53:16<42:31:28, 162.69s/it, lr=1.56e-5, test_acc=56.6, time=163, train_acc=59.4, train_loss=1.14, val_acc=54.8, val_loss=1.25]Epoch 59:   6%|▌         | 60/1000 [2:53:16<42:28:11, 162.65s/it, lr=1.56e-5, test_acc=56.6, time=163, train_acc=59.4, train_loss=1.14, val_acc=54.8, val_loss=1.25]Epoch 60:   6%|▌         | 60/1000 [2:53:16<42:28:11, 162.65s/it, lr=1.56e-5, test_acc=56.6, time=163, train_acc=59.4, train_loss=1.14, val_acc=54.8, val_loss=1.25]Epoch 60:   6%|▌         | 60/1000 [2:55:59<42:28:11, 162.65s/it, lr=1.56e-5, test_acc=56.6, time=163, train_acc=59.4, train_loss=1.14, val_acc=54.9, val_loss=1.25]Epoch 60:   6%|▌         | 61/1000 [2:55:59<42:25:20, 162.64s/it, lr=1.56e-5, test_acc=56.6, time=163, train_acc=59.4, train_loss=1.14, val_acc=54.9, val_loss=1.25]Epoch 61:   6%|▌         | 61/1000 [2:55:59<42:25:20, 162.64s/it, lr=1.56e-5, test_acc=56.6, time=163, train_acc=59.4, train_loss=1.14, val_acc=54.9, val_loss=1.25]Epoch 61:   6%|▌         | 61/1000 [2:58:41<42:25:20, 162.64s/it, lr=1.56e-5, test_acc=56.4, time=163, train_acc=59.4, train_loss=1.14, val_acc=54.7, val_loss=1.25]Epoch 61:   6%|▌         | 62/1000 [2:58:41<42:22:48, 162.65s/it, lr=1.56e-5, test_acc=56.4, time=163, train_acc=59.4, train_loss=1.14, val_acc=54.7, val_loss=1.25]Epoch 62:   6%|▌         | 62/1000 [2:58:41<42:22:48, 162.65s/it, lr=1.56e-5, test_acc=56.4, time=163, train_acc=59.4, train_loss=1.14, val_acc=54.7, val_loss=1.25]Epoch 62:   6%|▌         | 62/1000 [3:01:24<42:22:48, 162.65s/it, lr=1.56e-5, test_acc=56.6, time=163, train_acc=59.5, train_loss=1.14, val_acc=54.8, val_loss=1.25]Epoch 62:   6%|▋         | 63/1000 [3:01:24<42:20:11, 162.66s/it, lr=1.56e-5, test_acc=56.6, time=163, train_acc=59.5, train_loss=1.14, val_acc=54.8, val_loss=1.25]Epoch 63:   6%|▋         | 63/1000 [3:01:24<42:20:11, 162.66s/it, lr=1.56e-5, test_acc=56.6, time=163, train_acc=59.5, train_loss=1.14, val_acc=54.8, val_loss=1.25]Epoch 63:   6%|▋         | 63/1000 [3:04:07<42:20:11, 162.66s/it, lr=1.56e-5, test_acc=56.6, time=163, train_acc=59.5, train_loss=1.14, val_acc=54.9, val_loss=1.24]Epoch 63:   6%|▋         | 64/1000 [3:04:07<42:17:25, 162.66s/it, lr=1.56e-5, test_acc=56.6, time=163, train_acc=59.5, train_loss=1.14, val_acc=54.9, val_loss=1.24]Epoch 64:   6%|▋         | 64/1000 [3:04:07<42:17:25, 162.66s/it, lr=1.56e-5, test_acc=56.6, time=163, train_acc=59.5, train_loss=1.14, val_acc=54.9, val_loss=1.24]Epoch 64:   6%|▋         | 64/1000 [3:06:49<42:17:25, 162.66s/it, lr=1.56e-5, test_acc=56.5, time=163, train_acc=59.4, train_loss=1.14, val_acc=54.8, val_loss=1.25]Epoch 64:   6%|▋         | 65/1000 [3:06:49<42:14:44, 162.66s/it, lr=1.56e-5, test_acc=56.5, time=163, train_acc=59.4, train_loss=1.14, val_acc=54.8, val_loss=1.25]Epoch 65:   6%|▋         | 65/1000 [3:06:49<42:14:44, 162.66s/it, lr=1.56e-5, test_acc=56.5, time=163, train_acc=59.4, train_loss=1.14, val_acc=54.8, val_loss=1.25]Epoch 65:   6%|▋         | 65/1000 [3:09:32<42:14:44, 162.66s/it, lr=1.56e-5, test_acc=56.7, time=163, train_acc=59.4, train_loss=1.14, val_acc=54.8, val_loss=1.25]Epoch 65:   7%|▋         | 66/1000 [3:09:32<42:11:54, 162.65s/it, lr=1.56e-5, test_acc=56.7, time=163, train_acc=59.4, train_loss=1.14, val_acc=54.8, val_loss=1.25]Epoch 66:   7%|▋         | 66/1000 [3:09:32<42:11:54, 162.65s/it, lr=1.56e-5, test_acc=56.7, time=163, train_acc=59.4, train_loss=1.14, val_acc=54.8, val_loss=1.25]Epoch 66:   7%|▋         | 66/1000 [3:12:15<42:11:54, 162.65s/it, lr=1.56e-5, test_acc=56.5, time=163, train_acc=59.5, train_loss=1.14, val_acc=54.8, val_loss=1.25]Epoch 66:   7%|▋         | 67/1000 [3:12:15<42:09:40, 162.68s/it, lr=1.56e-5, test_acc=56.5, time=163, train_acc=59.5, train_loss=1.14, val_acc=54.8, val_loss=1.25]Epoch 67:   7%|▋         | 67/1000 [3:12:15<42:09:40, 162.68s/it, lr=1.56e-5, test_acc=56.5, time=163, train_acc=59.5, train_loss=1.14, val_acc=54.8, val_loss=1.25]Epoch 67:   7%|▋         | 67/1000 [3:14:57<42:09:40, 162.68s/it, lr=1.56e-5, test_acc=56.5, time=163, train_acc=59.4, train_loss=1.14, val_acc=54.8, val_loss=1.25]Epoch 67:   7%|▋         | 68/1000 [3:14:57<42:06:52, 162.67s/it, lr=1.56e-5, test_acc=56.5, time=163, train_acc=59.4, train_loss=1.14, val_acc=54.8, val_loss=1.25]Epoch 68:   7%|▋         | 68/1000 [3:14:57<42:06:52, 162.67s/it, lr=1.56e-5, test_acc=56.5, time=163, train_acc=59.4, train_loss=1.14, val_acc=54.8, val_loss=1.25]Epoch 68:   7%|▋         | 68/1000 [3:17:40<42:06:52, 162.67s/it, lr=1.56e-5, test_acc=56.5, time=163, train_acc=59.4, train_loss=1.14, val_acc=54.8, val_loss=1.25]Epoch 68:   7%|▋         | 69/1000 [3:17:40<42:04:11, 162.68s/it, lr=1.56e-5, test_acc=56.5, time=163, train_acc=59.4, train_loss=1.14, val_acc=54.8, val_loss=1.25]Epoch 69:   7%|▋         | 69/1000 [3:17:40<42:04:11, 162.68s/it, lr=1.56e-5, test_acc=56.5, time=163, train_acc=59.4, train_loss=1.14, val_acc=54.8, val_loss=1.25]Epoch 69:   7%|▋         | 69/1000 [3:20:23<42:04:11, 162.68s/it, lr=1.56e-5, test_acc=56.4, time=163, train_acc=59.5, train_loss=1.14, val_acc=54.7, val_loss=1.25]Epoch    70: reducing learning rate of group 0 to 7.8125e-06.

!! LR SMALLER OR EQUAL TO MIN LR THRESHOLD.
Epoch 69:   7%|▋         | 69/1000 [3:20:23<45:03:45, 174.25s/it, lr=1.56e-5, test_acc=56.4, time=163, train_acc=59.5, train_loss=1.14, val_acc=54.7, val_loss=1.25]
Test Accuracy: 56.3786
Train Accuracy: 59.3475
Convergence Time (Epochs): 69.0000
TOTAL TIME TAKEN: 12144.5697s
AVG TIME PER EPOCH: 171.7427s
