I'm echoing to stdout
I'm echoing to stderr
My JobID is 56818351
I have 4 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset SBM_CLUSTER...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 7.4757s
MODEL DETAILS:

MODEL/Total parameters: ChebNet 102535
Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
Number of Classes:  6
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]/vast/palmer/pi/krishnaswamy_smita/bsw38/GraphML/Transferability-of-spectral-gnns-2025/Benchmark-gnn/nets/SBMs_node_classification/ChebNet.py:58: UserWarning: This overload of nonzero is deprecated:
	nonzero()
Consider using one of the following signatures instead:
	nonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629427478/work/torch/csrc/utils/python_arg_parser.cpp:766.)
  label_count = label_count[label_count.nonzero()].squeeze()
Epoch 0:   0%|          | 0/1000 [00:56<?, ?it/s, lr=0.001, test_acc=34.3, time=56.5, train_acc=42.9, train_loss=1.41, val_acc=33.7, val_loss=1.67]Epoch 0:   0%|          | 1/1000 [00:56<15:40:49, 56.51s/it, lr=0.001, test_acc=34.3, time=56.5, train_acc=42.9, train_loss=1.41, val_acc=33.7, val_loss=1.67]Epoch 1:   0%|          | 1/1000 [00:56<15:40:49, 56.51s/it, lr=0.001, test_acc=34.3, time=56.5, train_acc=42.9, train_loss=1.41, val_acc=33.7, val_loss=1.67]Epoch 1:   0%|          | 1/1000 [01:52<15:40:49, 56.51s/it, lr=0.001, test_acc=32.4, time=56.1, train_acc=68.2, train_loss=0.879, val_acc=31.7, val_loss=1.71]Epoch 1:   0%|          | 2/1000 [01:52<15:37:47, 56.38s/it, lr=0.001, test_acc=32.4, time=56.1, train_acc=68.2, train_loss=0.879, val_acc=31.7, val_loss=1.71]Epoch 2:   0%|          | 2/1000 [01:52<15:37:47, 56.38s/it, lr=0.001, test_acc=32.4, time=56.1, train_acc=68.2, train_loss=0.879, val_acc=31.7, val_loss=1.71]Epoch 2:   0%|          | 2/1000 [02:48<15:37:47, 56.38s/it, lr=0.001, test_acc=26.2, time=56.1, train_acc=70.2, train_loss=0.815, val_acc=26, val_loss=1.68]  Epoch 2:   0%|          | 3/1000 [02:48<15:35:34, 56.30s/it, lr=0.001, test_acc=26.2, time=56.1, train_acc=70.2, train_loss=0.815, val_acc=26, val_loss=1.68]Epoch 3:   0%|          | 3/1000 [02:48<15:35:34, 56.30s/it, lr=0.001, test_acc=26.2, time=56.1, train_acc=70.2, train_loss=0.815, val_acc=26, val_loss=1.68]Epoch 3:   0%|          | 3/1000 [03:44<15:35:34, 56.30s/it, lr=0.001, test_acc=22.2, time=56, train_acc=71, train_loss=0.794, val_acc=22.2, val_loss=1.76]  Epoch 3:   0%|          | 4/1000 [03:44<15:33:11, 56.22s/it, lr=0.001, test_acc=22.2, time=56, train_acc=71, train_loss=0.794, val_acc=22.2, val_loss=1.76]Epoch 4:   0%|          | 4/1000 [03:44<15:33:11, 56.22s/it, lr=0.001, test_acc=22.2, time=56, train_acc=71, train_loss=0.794, val_acc=22.2, val_loss=1.76]Epoch 4:   0%|          | 4/1000 [04:40<15:33:11, 56.22s/it, lr=0.001, test_acc=38.7, time=56, train_acc=71.6, train_loss=0.777, val_acc=38.7, val_loss=1.47]Epoch 4:   0%|          | 5/1000 [04:40<15:31:25, 56.17s/it, lr=0.001, test_acc=38.7, time=56, train_acc=71.6, train_loss=0.777, val_acc=38.7, val_loss=1.47]Epoch 5:   0%|          | 5/1000 [04:40<15:31:25, 56.17s/it, lr=0.001, test_acc=38.7, time=56, train_acc=71.6, train_loss=0.777, val_acc=38.7, val_loss=1.47]Epoch 5:   0%|          | 5/1000 [05:36<15:31:25, 56.17s/it, lr=0.001, test_acc=38.3, time=55.9, train_acc=71.9, train_loss=0.767, val_acc=37.7, val_loss=1.53]Epoch 5:   1%|          | 6/1000 [05:36<15:29:30, 56.11s/it, lr=0.001, test_acc=38.3, time=55.9, train_acc=71.9, train_loss=0.767, val_acc=37.7, val_loss=1.53]Epoch 6:   1%|          | 6/1000 [05:36<15:29:30, 56.11s/it, lr=0.001, test_acc=38.3, time=55.9, train_acc=71.9, train_loss=0.767, val_acc=37.7, val_loss=1.53]Epoch 6:   1%|          | 6/1000 [06:32<15:29:30, 56.11s/it, lr=0.001, test_acc=48.9, time=56, train_acc=72.3, train_loss=0.755, val_acc=48.2, val_loss=1.42]  Epoch 6:   1%|          | 7/1000 [06:32<15:28:05, 56.08s/it, lr=0.001, test_acc=48.9, time=56, train_acc=72.3, train_loss=0.755, val_acc=48.2, val_loss=1.42]Epoch 7:   1%|          | 7/1000 [06:32<15:28:05, 56.08s/it, lr=0.001, test_acc=48.9, time=56, train_acc=72.3, train_loss=0.755, val_acc=48.2, val_loss=1.42]Epoch 7:   1%|          | 7/1000 [07:28<15:28:05, 56.08s/it, lr=0.001, test_acc=33.2, time=55.9, train_acc=72.5, train_loss=0.751, val_acc=33.3, val_loss=2.51]Epoch 7:   1%|          | 8/1000 [07:28<15:26:41, 56.05s/it, lr=0.001, test_acc=33.2, time=55.9, train_acc=72.5, train_loss=0.751, val_acc=33.3, val_loss=2.51]Epoch 8:   1%|          | 8/1000 [07:28<15:26:41, 56.05s/it, lr=0.001, test_acc=33.2, time=55.9, train_acc=72.5, train_loss=0.751, val_acc=33.3, val_loss=2.51]Epoch 8:   1%|          | 8/1000 [08:24<15:26:41, 56.05s/it, lr=0.001, test_acc=45.8, time=56, train_acc=72.8, train_loss=0.744, val_acc=45.3, val_loss=1.46]  Epoch 8:   1%|          | 9/1000 [08:24<15:25:30, 56.03s/it, lr=0.001, test_acc=45.8, time=56, train_acc=72.8, train_loss=0.744, val_acc=45.3, val_loss=1.46]Epoch 9:   1%|          | 9/1000 [08:24<15:25:30, 56.03s/it, lr=0.001, test_acc=45.8, time=56, train_acc=72.8, train_loss=0.744, val_acc=45.3, val_loss=1.46]Epoch 9:   1%|          | 9/1000 [09:20<15:25:30, 56.03s/it, lr=0.001, test_acc=61.1, time=56, train_acc=73.1, train_loss=0.738, val_acc=60.6, val_loss=1.06]Epoch 9:   1%|          | 10/1000 [09:20<15:24:35, 56.04s/it, lr=0.001, test_acc=61.1, time=56, train_acc=73.1, train_loss=0.738, val_acc=60.6, val_loss=1.06]Epoch 10:   1%|          | 10/1000 [09:20<15:24:35, 56.04s/it, lr=0.001, test_acc=61.1, time=56, train_acc=73.1, train_loss=0.738, val_acc=60.6, val_loss=1.06]Epoch 10:   1%|          | 10/1000 [10:16<15:24:35, 56.04s/it, lr=0.001, test_acc=26.4, time=56, train_acc=73.2, train_loss=0.735, val_acc=26.2, val_loss=2.03]Epoch 10:   1%|          | 11/1000 [10:16<15:23:52, 56.05s/it, lr=0.001, test_acc=26.4, time=56, train_acc=73.2, train_loss=0.735, val_acc=26.2, val_loss=2.03]Epoch 11:   1%|          | 11/1000 [10:16<15:23:52, 56.05s/it, lr=0.001, test_acc=26.4, time=56, train_acc=73.2, train_loss=0.735, val_acc=26.2, val_loss=2.03]Epoch 11:   1%|          | 11/1000 [11:12<15:23:52, 56.05s/it, lr=0.001, test_acc=35.9, time=56, train_acc=73.3, train_loss=0.729, val_acc=35.6, val_loss=2.33]Epoch 11:   1%|          | 12/1000 [11:12<15:23:02, 56.06s/it, lr=0.001, test_acc=35.9, time=56, train_acc=73.3, train_loss=0.729, val_acc=35.6, val_loss=2.33]Epoch 12:   1%|          | 12/1000 [11:12<15:23:02, 56.06s/it, lr=0.001, test_acc=35.9, time=56, train_acc=73.3, train_loss=0.729, val_acc=35.6, val_loss=2.33]Epoch 12:   1%|          | 12/1000 [12:08<15:23:02, 56.06s/it, lr=0.001, test_acc=43.8, time=55.9, train_acc=73.4, train_loss=0.727, val_acc=43.5, val_loss=1.51]Epoch 12:   1%|▏         | 13/1000 [12:08<15:21:34, 56.02s/it, lr=0.001, test_acc=43.8, time=55.9, train_acc=73.4, train_loss=0.727, val_acc=43.5, val_loss=1.51]Epoch 13:   1%|▏         | 13/1000 [12:08<15:21:34, 56.02s/it, lr=0.001, test_acc=43.8, time=55.9, train_acc=73.4, train_loss=0.727, val_acc=43.5, val_loss=1.51]Epoch 13:   1%|▏         | 13/1000 [13:04<15:21:34, 56.02s/it, lr=0.001, test_acc=52.6, time=56, train_acc=73.5, train_loss=0.725, val_acc=52, val_loss=1.29]    Epoch 13:   1%|▏         | 14/1000 [13:04<15:20:41, 56.03s/it, lr=0.001, test_acc=52.6, time=56, train_acc=73.5, train_loss=0.725, val_acc=52, val_loss=1.29]Epoch 14:   1%|▏         | 14/1000 [13:04<15:20:41, 56.03s/it, lr=0.001, test_acc=52.6, time=56, train_acc=73.5, train_loss=0.725, val_acc=52, val_loss=1.29]Epoch 14:   1%|▏         | 14/1000 [14:00<15:20:41, 56.03s/it, lr=0.001, test_acc=51.2, time=55.9, train_acc=73.6, train_loss=0.722, val_acc=50.7, val_loss=1.64]Epoch 14:   2%|▏         | 15/1000 [14:00<15:19:22, 56.00s/it, lr=0.001, test_acc=51.2, time=55.9, train_acc=73.6, train_loss=0.722, val_acc=50.7, val_loss=1.64]Epoch 15:   2%|▏         | 15/1000 [14:00<15:19:22, 56.00s/it, lr=0.001, test_acc=51.2, time=55.9, train_acc=73.6, train_loss=0.722, val_acc=50.7, val_loss=1.64]Epoch 15:   2%|▏         | 15/1000 [14:56<15:19:22, 56.00s/it, lr=0.001, test_acc=37.5, time=55.9, train_acc=73.6, train_loss=0.722, val_acc=37, val_loss=1.61]  Epoch    16: reducing learning rate of group 0 to 5.0000e-04.
Epoch 15:   2%|▏         | 16/1000 [14:56<15:18:24, 56.00s/it, lr=0.001, test_acc=37.5, time=55.9, train_acc=73.6, train_loss=0.722, val_acc=37, val_loss=1.61]Epoch 16:   2%|▏         | 16/1000 [14:56<15:18:24, 56.00s/it, lr=0.001, test_acc=37.5, time=55.9, train_acc=73.6, train_loss=0.722, val_acc=37, val_loss=1.61]Epoch 16:   2%|▏         | 16/1000 [15:52<15:18:24, 56.00s/it, lr=0.0005, test_acc=69.5, time=56.1, train_acc=74.1, train_loss=0.707, val_acc=69.4, val_loss=0.852]Epoch 16:   2%|▏         | 17/1000 [15:52<15:18:00, 56.03s/it, lr=0.0005, test_acc=69.5, time=56.1, train_acc=74.1, train_loss=0.707, val_acc=69.4, val_loss=0.852]Epoch 17:   2%|▏         | 17/1000 [15:52<15:18:00, 56.03s/it, lr=0.0005, test_acc=69.5, time=56.1, train_acc=74.1, train_loss=0.707, val_acc=69.4, val_loss=0.852]Epoch 17:   2%|▏         | 17/1000 [16:48<15:18:00, 56.03s/it, lr=0.0005, test_acc=47.3, time=56, train_acc=74.3, train_loss=0.702, val_acc=46.5, val_loss=1.54]   Epoch 17:   2%|▏         | 18/1000 [16:48<15:16:55, 56.02s/it, lr=0.0005, test_acc=47.3, time=56, train_acc=74.3, train_loss=0.702, val_acc=46.5, val_loss=1.54]Epoch 18:   2%|▏         | 18/1000 [16:48<15:16:55, 56.02s/it, lr=0.0005, test_acc=47.3, time=56, train_acc=74.3, train_loss=0.702, val_acc=46.5, val_loss=1.54]Epoch 18:   2%|▏         | 18/1000 [17:44<15:16:55, 56.02s/it, lr=0.0005, test_acc=49.4, time=56, train_acc=74.4, train_loss=0.699, val_acc=48.3, val_loss=1.67]Epoch 18:   2%|▏         | 19/1000 [17:44<15:15:48, 56.01s/it, lr=0.0005, test_acc=49.4, time=56, train_acc=74.4, train_loss=0.699, val_acc=48.3, val_loss=1.67]Epoch 19:   2%|▏         | 19/1000 [17:44<15:15:48, 56.01s/it, lr=0.0005, test_acc=49.4, time=56, train_acc=74.4, train_loss=0.699, val_acc=48.3, val_loss=1.67]Epoch 19:   2%|▏         | 19/1000 [18:41<15:15:48, 56.01s/it, lr=0.0005, test_acc=63.7, time=56.1, train_acc=74.5, train_loss=0.698, val_acc=63.4, val_loss=0.983]Epoch 19:   2%|▏         | 20/1000 [18:41<15:15:25, 56.05s/it, lr=0.0005, test_acc=63.7, time=56.1, train_acc=74.5, train_loss=0.698, val_acc=63.4, val_loss=0.983]Epoch 20:   2%|▏         | 20/1000 [18:41<15:15:25, 56.05s/it, lr=0.0005, test_acc=63.7, time=56.1, train_acc=74.5, train_loss=0.698, val_acc=63.4, val_loss=0.983]Epoch 20:   2%|▏         | 20/1000 [19:37<15:15:25, 56.05s/it, lr=0.0005, test_acc=52.7, time=56.1, train_acc=74.5, train_loss=0.697, val_acc=52, val_loss=1.44]   Epoch 20:   2%|▏         | 21/1000 [19:37<15:14:49, 56.07s/it, lr=0.0005, test_acc=52.7, time=56.1, train_acc=74.5, train_loss=0.697, val_acc=52, val_loss=1.44]Epoch 21:   2%|▏         | 21/1000 [19:37<15:14:49, 56.07s/it, lr=0.0005, test_acc=52.7, time=56.1, train_acc=74.5, train_loss=0.697, val_acc=52, val_loss=1.44]Epoch 21:   2%|▏         | 21/1000 [20:33<15:14:49, 56.07s/it, lr=0.0005, test_acc=56.6, time=56, train_acc=74.5, train_loss=0.696, val_acc=55.4, val_loss=1.28]Epoch 21:   2%|▏         | 22/1000 [20:33<15:13:39, 56.05s/it, lr=0.0005, test_acc=56.6, time=56, train_acc=74.5, train_loss=0.696, val_acc=55.4, val_loss=1.28]Epoch 22:   2%|▏         | 22/1000 [20:33<15:13:39, 56.05s/it, lr=0.0005, test_acc=56.6, time=56, train_acc=74.5, train_loss=0.696, val_acc=55.4, val_loss=1.28]Epoch 22:   2%|▏         | 22/1000 [21:29<15:13:39, 56.05s/it, lr=0.0005, test_acc=57.5, time=56, train_acc=74.5, train_loss=0.696, val_acc=56.5, val_loss=1.16]Epoch    23: reducing learning rate of group 0 to 2.5000e-04.
Epoch 22:   2%|▏         | 23/1000 [21:29<15:12:29, 56.04s/it, lr=0.0005, test_acc=57.5, time=56, train_acc=74.5, train_loss=0.696, val_acc=56.5, val_loss=1.16]Epoch 23:   2%|▏         | 23/1000 [21:29<15:12:29, 56.04s/it, lr=0.0005, test_acc=57.5, time=56, train_acc=74.5, train_loss=0.696, val_acc=56.5, val_loss=1.16]Epoch 23:   2%|▏         | 23/1000 [22:25<15:12:29, 56.04s/it, lr=0.00025, test_acc=63.3, time=55.9, train_acc=74.9, train_loss=0.687, val_acc=63.4, val_loss=0.974]Epoch 23:   2%|▏         | 24/1000 [22:25<15:10:59, 56.00s/it, lr=0.00025, test_acc=63.3, time=55.9, train_acc=74.9, train_loss=0.687, val_acc=63.4, val_loss=0.974]Epoch 24:   2%|▏         | 24/1000 [22:25<15:10:59, 56.00s/it, lr=0.00025, test_acc=63.3, time=55.9, train_acc=74.9, train_loss=0.687, val_acc=63.4, val_loss=0.974]Epoch 24:   2%|▏         | 24/1000 [23:21<15:10:59, 56.00s/it, lr=0.00025, test_acc=67.6, time=56.1, train_acc=75, train_loss=0.684, val_acc=67.6, val_loss=0.881]  Epoch 24:   2%|▎         | 25/1000 [23:21<15:10:33, 56.03s/it, lr=0.00025, test_acc=67.6, time=56.1, train_acc=75, train_loss=0.684, val_acc=67.6, val_loss=0.881]Epoch 25:   2%|▎         | 25/1000 [23:21<15:10:33, 56.03s/it, lr=0.00025, test_acc=67.6, time=56.1, train_acc=75, train_loss=0.684, val_acc=67.6, val_loss=0.881]Epoch 25:   2%|▎         | 25/1000 [24:17<15:10:33, 56.03s/it, lr=0.00025, test_acc=69.8, time=56, train_acc=75.1, train_loss=0.682, val_acc=69.5, val_loss=0.845]Epoch 25:   3%|▎         | 26/1000 [24:17<15:09:38, 56.04s/it, lr=0.00025, test_acc=69.8, time=56, train_acc=75.1, train_loss=0.682, val_acc=69.5, val_loss=0.845]Epoch 26:   3%|▎         | 26/1000 [24:17<15:09:38, 56.04s/it, lr=0.00025, test_acc=69.8, time=56, train_acc=75.1, train_loss=0.682, val_acc=69.5, val_loss=0.845]Epoch 26:   3%|▎         | 26/1000 [25:13<15:09:38, 56.04s/it, lr=0.00025, test_acc=68.8, time=56, train_acc=75, train_loss=0.683, val_acc=68.6, val_loss=0.871]  Epoch 26:   3%|▎         | 27/1000 [25:13<15:08:22, 56.01s/it, lr=0.00025, test_acc=68.8, time=56, train_acc=75, train_loss=0.683, val_acc=68.6, val_loss=0.871]Epoch 27:   3%|▎         | 27/1000 [25:13<15:08:22, 56.01s/it, lr=0.00025, test_acc=68.8, time=56, train_acc=75, train_loss=0.683, val_acc=68.6, val_loss=0.871]Epoch 27:   3%|▎         | 27/1000 [26:09<15:08:22, 56.01s/it, lr=0.00025, test_acc=69.6, time=56, train_acc=75.1, train_loss=0.682, val_acc=68.9, val_loss=0.878]Epoch 27:   3%|▎         | 28/1000 [26:09<15:07:24, 56.01s/it, lr=0.00025, test_acc=69.6, time=56, train_acc=75.1, train_loss=0.682, val_acc=68.9, val_loss=0.878]Epoch 28:   3%|▎         | 28/1000 [26:09<15:07:24, 56.01s/it, lr=0.00025, test_acc=69.6, time=56, train_acc=75.1, train_loss=0.682, val_acc=68.9, val_loss=0.878]Epoch 28:   3%|▎         | 28/1000 [27:05<15:07:24, 56.01s/it, lr=0.00025, test_acc=67.4, time=56.2, train_acc=75, train_loss=0.682, val_acc=67.1, val_loss=0.927]Epoch 28:   3%|▎         | 29/1000 [27:05<15:07:17, 56.06s/it, lr=0.00025, test_acc=67.4, time=56.2, train_acc=75, train_loss=0.682, val_acc=67.1, val_loss=0.927]Epoch 29:   3%|▎         | 29/1000 [27:05<15:07:17, 56.06s/it, lr=0.00025, test_acc=67.4, time=56.2, train_acc=75, train_loss=0.682, val_acc=67.1, val_loss=0.927]Epoch 29:   3%|▎         | 29/1000 [28:01<15:07:17, 56.06s/it, lr=0.00025, test_acc=63.4, time=56, train_acc=75.1, train_loss=0.68, val_acc=63.2, val_loss=1.04]  Epoch 29:   3%|▎         | 30/1000 [28:01<15:06:07, 56.05s/it, lr=0.00025, test_acc=63.4, time=56, train_acc=75.1, train_loss=0.68, val_acc=63.2, val_loss=1.04]Epoch 30:   3%|▎         | 30/1000 [28:01<15:06:07, 56.05s/it, lr=0.00025, test_acc=63.4, time=56, train_acc=75.1, train_loss=0.68, val_acc=63.2, val_loss=1.04]Epoch 30:   3%|▎         | 30/1000 [28:57<15:06:07, 56.05s/it, lr=0.00025, test_acc=66.9, time=55.9, train_acc=75.1, train_loss=0.68, val_acc=66.4, val_loss=0.898]Epoch 30:   3%|▎         | 31/1000 [28:57<15:04:39, 56.02s/it, lr=0.00025, test_acc=66.9, time=55.9, train_acc=75.1, train_loss=0.68, val_acc=66.4, val_loss=0.898]Epoch 31:   3%|▎         | 31/1000 [28:57<15:04:39, 56.02s/it, lr=0.00025, test_acc=66.9, time=55.9, train_acc=75.1, train_loss=0.68, val_acc=66.4, val_loss=0.898]Epoch 31:   3%|▎         | 31/1000 [29:53<15:04:39, 56.02s/it, lr=0.00025, test_acc=63.4, time=56.1, train_acc=75.1, train_loss=0.68, val_acc=62.8, val_loss=0.999]Epoch    32: reducing learning rate of group 0 to 1.2500e-04.
Epoch 31:   3%|▎         | 32/1000 [29:53<15:04:17, 56.05s/it, lr=0.00025, test_acc=63.4, time=56.1, train_acc=75.1, train_loss=0.68, val_acc=62.8, val_loss=0.999]Epoch 32:   3%|▎         | 32/1000 [29:53<15:04:17, 56.05s/it, lr=0.00025, test_acc=63.4, time=56.1, train_acc=75.1, train_loss=0.68, val_acc=62.8, val_loss=0.999]Epoch 32:   3%|▎         | 32/1000 [30:49<15:04:17, 56.05s/it, lr=0.000125, test_acc=71.5, time=56, train_acc=75.4, train_loss=0.674, val_acc=71.7, val_loss=0.771]Epoch 32:   3%|▎         | 33/1000 [30:49<15:03:11, 56.04s/it, lr=0.000125, test_acc=71.5, time=56, train_acc=75.4, train_loss=0.674, val_acc=71.7, val_loss=0.771]Epoch 33:   3%|▎         | 33/1000 [30:49<15:03:11, 56.04s/it, lr=0.000125, test_acc=71.5, time=56, train_acc=75.4, train_loss=0.674, val_acc=71.7, val_loss=0.771]Epoch 33:   3%|▎         | 33/1000 [31:45<15:03:11, 56.04s/it, lr=0.000125, test_acc=69.1, time=55.9, train_acc=75.3, train_loss=0.675, val_acc=68.8, val_loss=0.868]Epoch 33:   3%|▎         | 34/1000 [31:45<15:01:54, 56.02s/it, lr=0.000125, test_acc=69.1, time=55.9, train_acc=75.3, train_loss=0.675, val_acc=68.8, val_loss=0.868]Epoch 34:   3%|▎         | 34/1000 [31:45<15:01:54, 56.02s/it, lr=0.000125, test_acc=69.1, time=55.9, train_acc=75.3, train_loss=0.675, val_acc=68.8, val_loss=0.868]Epoch 34:   3%|▎         | 34/1000 [32:41<15:01:54, 56.02s/it, lr=0.000125, test_acc=72.4, time=56, train_acc=75.4, train_loss=0.674, val_acc=72.5, val_loss=0.755]  Epoch 34:   4%|▎         | 35/1000 [32:41<15:00:46, 56.01s/it, lr=0.000125, test_acc=72.4, time=56, train_acc=75.4, train_loss=0.674, val_acc=72.5, val_loss=0.755]Epoch 35:   4%|▎         | 35/1000 [32:41<15:00:46, 56.01s/it, lr=0.000125, test_acc=72.4, time=56, train_acc=75.4, train_loss=0.674, val_acc=72.5, val_loss=0.755]Epoch 35:   4%|▎         | 35/1000 [33:37<15:00:46, 56.01s/it, lr=0.000125, test_acc=68.3, time=56, train_acc=75.5, train_loss=0.672, val_acc=67.8, val_loss=0.905]Epoch 35:   4%|▎         | 36/1000 [33:37<15:00:05, 56.02s/it, lr=0.000125, test_acc=68.3, time=56, train_acc=75.5, train_loss=0.672, val_acc=67.8, val_loss=0.905]Epoch 36:   4%|▎         | 36/1000 [33:37<15:00:05, 56.02s/it, lr=0.000125, test_acc=68.3, time=56, train_acc=75.5, train_loss=0.672, val_acc=67.8, val_loss=0.905]Epoch 36:   4%|▎         | 36/1000 [34:33<15:00:05, 56.02s/it, lr=0.000125, test_acc=70.6, time=56, train_acc=75.4, train_loss=0.674, val_acc=70.6, val_loss=0.817]Epoch 36:   4%|▎         | 37/1000 [34:33<14:58:57, 56.01s/it, lr=0.000125, test_acc=70.6, time=56, train_acc=75.4, train_loss=0.674, val_acc=70.6, val_loss=0.817]Epoch 37:   4%|▎         | 37/1000 [34:33<14:58:57, 56.01s/it, lr=0.000125, test_acc=70.6, time=56, train_acc=75.4, train_loss=0.674, val_acc=70.6, val_loss=0.817]Epoch 37:   4%|▎         | 37/1000 [35:29<14:58:57, 56.01s/it, lr=0.000125, test_acc=64.4, time=55.9, train_acc=75.4, train_loss=0.672, val_acc=64.6, val_loss=0.976]Epoch 37:   4%|▍         | 38/1000 [35:29<14:57:45, 55.99s/it, lr=0.000125, test_acc=64.4, time=55.9, train_acc=75.4, train_loss=0.672, val_acc=64.6, val_loss=0.976]Epoch 38:   4%|▍         | 38/1000 [35:29<14:57:45, 55.99s/it, lr=0.000125, test_acc=64.4, time=55.9, train_acc=75.4, train_loss=0.672, val_acc=64.6, val_loss=0.976]Epoch 38:   4%|▍         | 38/1000 [36:25<14:57:45, 55.99s/it, lr=0.000125, test_acc=66.6, time=55.9, train_acc=75.5, train_loss=0.67, val_acc=66.3, val_loss=0.925] Epoch 38:   4%|▍         | 39/1000 [36:25<14:56:25, 55.97s/it, lr=0.000125, test_acc=66.6, time=55.9, train_acc=75.5, train_loss=0.67, val_acc=66.3, val_loss=0.925]Epoch 39:   4%|▍         | 39/1000 [36:25<14:56:25, 55.97s/it, lr=0.000125, test_acc=66.6, time=55.9, train_acc=75.5, train_loss=0.67, val_acc=66.3, val_loss=0.925]Epoch 39:   4%|▍         | 39/1000 [37:21<14:56:25, 55.97s/it, lr=0.000125, test_acc=70, time=55.9, train_acc=75.4, train_loss=0.671, val_acc=69.7, val_loss=0.825] Epoch 39:   4%|▍         | 40/1000 [37:21<14:55:22, 55.96s/it, lr=0.000125, test_acc=70, time=55.9, train_acc=75.4, train_loss=0.671, val_acc=69.7, val_loss=0.825]Epoch 40:   4%|▍         | 40/1000 [37:21<14:55:22, 55.96s/it, lr=0.000125, test_acc=70, time=55.9, train_acc=75.4, train_loss=0.671, val_acc=69.7, val_loss=0.825]Epoch 40:   4%|▍         | 40/1000 [38:17<14:55:22, 55.96s/it, lr=0.000125, test_acc=72.3, time=56.1, train_acc=75.4, train_loss=0.67, val_acc=72.2, val_loss=0.796]Epoch    41: reducing learning rate of group 0 to 6.2500e-05.
Epoch 40:   4%|▍         | 41/1000 [38:17<14:55:14, 56.01s/it, lr=0.000125, test_acc=72.3, time=56.1, train_acc=75.4, train_loss=0.67, val_acc=72.2, val_loss=0.796]Epoch 41:   4%|▍         | 41/1000 [38:17<14:55:14, 56.01s/it, lr=0.000125, test_acc=72.3, time=56.1, train_acc=75.4, train_loss=0.67, val_acc=72.2, val_loss=0.796]Epoch 41:   4%|▍         | 41/1000 [39:13<14:55:14, 56.01s/it, lr=6.25e-5, test_acc=72.7, time=56.1, train_acc=75.6, train_loss=0.667, val_acc=72.6, val_loss=0.748]Epoch 41:   4%|▍         | 42/1000 [39:13<14:54:38, 56.03s/it, lr=6.25e-5, test_acc=72.7, time=56.1, train_acc=75.6, train_loss=0.667, val_acc=72.6, val_loss=0.748]Epoch 42:   4%|▍         | 42/1000 [39:13<14:54:38, 56.03s/it, lr=6.25e-5, test_acc=72.7, time=56.1, train_acc=75.6, train_loss=0.667, val_acc=72.6, val_loss=0.748]Epoch 42:   4%|▍         | 42/1000 [40:09<14:54:38, 56.03s/it, lr=6.25e-5, test_acc=72.8, time=56, train_acc=75.6, train_loss=0.668, val_acc=73.1, val_loss=0.736]  Epoch 42:   4%|▍         | 43/1000 [40:09<14:53:35, 56.02s/it, lr=6.25e-5, test_acc=72.8, time=56, train_acc=75.6, train_loss=0.668, val_acc=73.1, val_loss=0.736]Epoch 43:   4%|▍         | 43/1000 [40:09<14:53:35, 56.02s/it, lr=6.25e-5, test_acc=72.8, time=56, train_acc=75.6, train_loss=0.668, val_acc=73.1, val_loss=0.736]Epoch 43:   4%|▍         | 43/1000 [41:05<14:53:35, 56.02s/it, lr=6.25e-5, test_acc=72.9, time=55.9, train_acc=75.6, train_loss=0.668, val_acc=72.7, val_loss=0.753]Epoch 43:   4%|▍         | 44/1000 [41:05<14:52:12, 56.00s/it, lr=6.25e-5, test_acc=72.9, time=55.9, train_acc=75.6, train_loss=0.668, val_acc=72.7, val_loss=0.753]Epoch 44:   4%|▍         | 44/1000 [41:05<14:52:12, 56.00s/it, lr=6.25e-5, test_acc=72.9, time=55.9, train_acc=75.6, train_loss=0.668, val_acc=72.7, val_loss=0.753]Epoch 44:   4%|▍         | 44/1000 [42:01<14:52:12, 56.00s/it, lr=6.25e-5, test_acc=71.3, time=55.9, train_acc=75.7, train_loss=0.665, val_acc=71.6, val_loss=0.775]Epoch 44:   4%|▍         | 45/1000 [42:01<14:51:03, 55.98s/it, lr=6.25e-5, test_acc=71.3, time=55.9, train_acc=75.7, train_loss=0.665, val_acc=71.6, val_loss=0.775]Epoch 45:   4%|▍         | 45/1000 [42:01<14:51:03, 55.98s/it, lr=6.25e-5, test_acc=71.3, time=55.9, train_acc=75.7, train_loss=0.665, val_acc=71.6, val_loss=0.775]Epoch 45:   4%|▍         | 45/1000 [42:57<14:51:03, 55.98s/it, lr=6.25e-5, test_acc=72.6, time=56, train_acc=75.7, train_loss=0.665, val_acc=72.4, val_loss=0.756]  Epoch 45:   5%|▍         | 46/1000 [42:57<14:50:30, 56.01s/it, lr=6.25e-5, test_acc=72.6, time=56, train_acc=75.7, train_loss=0.665, val_acc=72.4, val_loss=0.756]Epoch 46:   5%|▍         | 46/1000 [42:57<14:50:30, 56.01s/it, lr=6.25e-5, test_acc=72.6, time=56, train_acc=75.7, train_loss=0.665, val_acc=72.4, val_loss=0.756]Epoch 46:   5%|▍         | 46/1000 [43:53<14:50:30, 56.01s/it, lr=6.25e-5, test_acc=72.7, time=55.9, train_acc=75.6, train_loss=0.666, val_acc=72.6, val_loss=0.752]Epoch 46:   5%|▍         | 47/1000 [43:53<14:49:10, 55.98s/it, lr=6.25e-5, test_acc=72.7, time=55.9, train_acc=75.6, train_loss=0.666, val_acc=72.6, val_loss=0.752]Epoch 47:   5%|▍         | 47/1000 [43:53<14:49:10, 55.98s/it, lr=6.25e-5, test_acc=72.7, time=55.9, train_acc=75.6, train_loss=0.666, val_acc=72.6, val_loss=0.752]Epoch 47:   5%|▍         | 47/1000 [44:49<14:49:10, 55.98s/it, lr=6.25e-5, test_acc=71.7, time=55.9, train_acc=75.6, train_loss=0.665, val_acc=72, val_loss=0.763]  Epoch 47:   5%|▍         | 48/1000 [44:49<14:48:08, 55.98s/it, lr=6.25e-5, test_acc=71.7, time=55.9, train_acc=75.6, train_loss=0.665, val_acc=72, val_loss=0.763]Epoch 48:   5%|▍         | 48/1000 [44:49<14:48:08, 55.98s/it, lr=6.25e-5, test_acc=71.7, time=55.9, train_acc=75.6, train_loss=0.665, val_acc=72, val_loss=0.763]Epoch 48:   5%|▍         | 48/1000 [45:45<14:48:08, 55.98s/it, lr=6.25e-5, test_acc=72.2, time=56, train_acc=75.6, train_loss=0.668, val_acc=72.5, val_loss=0.764]Epoch    49: reducing learning rate of group 0 to 3.1250e-05.
Epoch 48:   5%|▍         | 49/1000 [45:45<14:47:20, 55.98s/it, lr=6.25e-5, test_acc=72.2, time=56, train_acc=75.6, train_loss=0.668, val_acc=72.5, val_loss=0.764]Epoch 49:   5%|▍         | 49/1000 [45:45<14:47:20, 55.98s/it, lr=6.25e-5, test_acc=72.2, time=56, train_acc=75.6, train_loss=0.668, val_acc=72.5, val_loss=0.764]Epoch 49:   5%|▍         | 49/1000 [46:41<14:47:20, 55.98s/it, lr=3.13e-5, test_acc=73.3, time=56.3, train_acc=75.7, train_loss=0.663, val_acc=73.4, val_loss=0.728]Epoch 49:   5%|▌         | 50/1000 [46:41<14:47:50, 56.07s/it, lr=3.13e-5, test_acc=73.3, time=56.3, train_acc=75.7, train_loss=0.663, val_acc=73.4, val_loss=0.728]Epoch 50:   5%|▌         | 50/1000 [46:41<14:47:50, 56.07s/it, lr=3.13e-5, test_acc=73.3, time=56.3, train_acc=75.7, train_loss=0.663, val_acc=73.4, val_loss=0.728]Epoch 50:   5%|▌         | 50/1000 [47:37<14:47:50, 56.07s/it, lr=3.13e-5, test_acc=73.6, time=56, train_acc=75.7, train_loss=0.666, val_acc=73.7, val_loss=0.727]  Epoch 50:   5%|▌         | 51/1000 [47:37<14:46:47, 56.07s/it, lr=3.13e-5, test_acc=73.6, time=56, train_acc=75.7, train_loss=0.666, val_acc=73.7, val_loss=0.727]Epoch 51:   5%|▌         | 51/1000 [47:37<14:46:47, 56.07s/it, lr=3.13e-5, test_acc=73.6, time=56, train_acc=75.7, train_loss=0.666, val_acc=73.7, val_loss=0.727]Epoch 51:   5%|▌         | 51/1000 [48:33<14:46:47, 56.07s/it, lr=3.13e-5, test_acc=73.6, time=56, train_acc=75.7, train_loss=0.663, val_acc=73.7, val_loss=0.723]Epoch 51:   5%|▌         | 52/1000 [48:33<14:45:27, 56.04s/it, lr=3.13e-5, test_acc=73.6, time=56, train_acc=75.7, train_loss=0.663, val_acc=73.7, val_loss=0.723]Epoch 52:   5%|▌         | 52/1000 [48:33<14:45:27, 56.04s/it, lr=3.13e-5, test_acc=73.6, time=56, train_acc=75.7, train_loss=0.663, val_acc=73.7, val_loss=0.723]Epoch 52:   5%|▌         | 52/1000 [49:29<14:45:27, 56.04s/it, lr=3.13e-5, test_acc=73.2, time=56, train_acc=75.7, train_loss=0.665, val_acc=73.3, val_loss=0.737]Epoch 52:   5%|▌         | 53/1000 [49:29<14:44:29, 56.04s/it, lr=3.13e-5, test_acc=73.2, time=56, train_acc=75.7, train_loss=0.665, val_acc=73.3, val_loss=0.737]Epoch 53:   5%|▌         | 53/1000 [49:29<14:44:29, 56.04s/it, lr=3.13e-5, test_acc=73.2, time=56, train_acc=75.7, train_loss=0.665, val_acc=73.3, val_loss=0.737]Epoch 53:   5%|▌         | 53/1000 [50:25<14:44:29, 56.04s/it, lr=3.13e-5, test_acc=73.3, time=56.2, train_acc=75.7, train_loss=0.664, val_acc=73.4, val_loss=0.73]Epoch 53:   5%|▌         | 54/1000 [50:25<14:44:27, 56.10s/it, lr=3.13e-5, test_acc=73.3, time=56.2, train_acc=75.7, train_loss=0.664, val_acc=73.4, val_loss=0.73]Epoch 54:   5%|▌         | 54/1000 [50:25<14:44:27, 56.10s/it, lr=3.13e-5, test_acc=73.3, time=56.2, train_acc=75.7, train_loss=0.664, val_acc=73.4, val_loss=0.73]Epoch 54:   5%|▌         | 54/1000 [51:22<14:44:27, 56.10s/it, lr=3.13e-5, test_acc=73.2, time=56.1, train_acc=75.8, train_loss=0.662, val_acc=73.4, val_loss=0.728]Epoch 54:   6%|▌         | 55/1000 [51:22<14:43:23, 56.09s/it, lr=3.13e-5, test_acc=73.2, time=56.1, train_acc=75.8, train_loss=0.662, val_acc=73.4, val_loss=0.728]Epoch 55:   6%|▌         | 55/1000 [51:22<14:43:23, 56.09s/it, lr=3.13e-5, test_acc=73.2, time=56.1, train_acc=75.8, train_loss=0.662, val_acc=73.4, val_loss=0.728]Epoch 55:   6%|▌         | 55/1000 [52:18<14:43:23, 56.09s/it, lr=3.13e-5, test_acc=73.4, time=56.1, train_acc=75.7, train_loss=0.663, val_acc=73.3, val_loss=0.731]Epoch 55:   6%|▌         | 56/1000 [52:18<14:42:24, 56.09s/it, lr=3.13e-5, test_acc=73.4, time=56.1, train_acc=75.7, train_loss=0.663, val_acc=73.3, val_loss=0.731]Epoch 56:   6%|▌         | 56/1000 [52:18<14:42:24, 56.09s/it, lr=3.13e-5, test_acc=73.4, time=56.1, train_acc=75.7, train_loss=0.663, val_acc=73.3, val_loss=0.731]Epoch 56:   6%|▌         | 56/1000 [53:14<14:42:24, 56.09s/it, lr=3.13e-5, test_acc=73.4, time=56, train_acc=75.7, train_loss=0.663, val_acc=73.6, val_loss=0.726]  Epoch 56:   6%|▌         | 57/1000 [53:14<14:41:11, 56.07s/it, lr=3.13e-5, test_acc=73.4, time=56, train_acc=75.7, train_loss=0.663, val_acc=73.6, val_loss=0.726]Epoch 57:   6%|▌         | 57/1000 [53:14<14:41:11, 56.07s/it, lr=3.13e-5, test_acc=73.4, time=56, train_acc=75.7, train_loss=0.663, val_acc=73.6, val_loss=0.726]Epoch 57:   6%|▌         | 57/1000 [54:10<14:41:11, 56.07s/it, lr=3.13e-5, test_acc=72.9, time=56.1, train_acc=75.7, train_loss=0.663, val_acc=72.9, val_loss=0.741]Epoch    58: reducing learning rate of group 0 to 1.5625e-05.
Epoch 57:   6%|▌         | 58/1000 [54:10<14:40:45, 56.10s/it, lr=3.13e-5, test_acc=72.9, time=56.1, train_acc=75.7, train_loss=0.663, val_acc=72.9, val_loss=0.741]Epoch 58:   6%|▌         | 58/1000 [54:10<14:40:45, 56.10s/it, lr=3.13e-5, test_acc=72.9, time=56.1, train_acc=75.7, train_loss=0.663, val_acc=72.9, val_loss=0.741]Epoch 58:   6%|▌         | 58/1000 [55:06<14:40:45, 56.10s/it, lr=1.56e-5, test_acc=73.7, time=56, train_acc=75.8, train_loss=0.661, val_acc=73.8, val_loss=0.719]  Epoch 58:   6%|▌         | 59/1000 [55:06<14:39:35, 56.08s/it, lr=1.56e-5, test_acc=73.7, time=56, train_acc=75.8, train_loss=0.661, val_acc=73.8, val_loss=0.719]Epoch 59:   6%|▌         | 59/1000 [55:06<14:39:35, 56.08s/it, lr=1.56e-5, test_acc=73.7, time=56, train_acc=75.8, train_loss=0.661, val_acc=73.8, val_loss=0.719]Epoch 59:   6%|▌         | 59/1000 [56:02<14:39:35, 56.08s/it, lr=1.56e-5, test_acc=73.4, time=56.1, train_acc=75.8, train_loss=0.662, val_acc=73.6, val_loss=0.725]Epoch 59:   6%|▌         | 60/1000 [56:02<14:38:50, 56.10s/it, lr=1.56e-5, test_acc=73.4, time=56.1, train_acc=75.8, train_loss=0.662, val_acc=73.6, val_loss=0.725]Epoch 60:   6%|▌         | 60/1000 [56:02<14:38:50, 56.10s/it, lr=1.56e-5, test_acc=73.4, time=56.1, train_acc=75.8, train_loss=0.662, val_acc=73.6, val_loss=0.725]Epoch 60:   6%|▌         | 60/1000 [56:58<14:38:50, 56.10s/it, lr=1.56e-5, test_acc=73.4, time=56.1, train_acc=75.8, train_loss=0.661, val_acc=73.6, val_loss=0.722]Epoch 60:   6%|▌         | 61/1000 [56:58<14:37:50, 56.09s/it, lr=1.56e-5, test_acc=73.4, time=56.1, train_acc=75.8, train_loss=0.661, val_acc=73.6, val_loss=0.722]Epoch 61:   6%|▌         | 61/1000 [56:58<14:37:50, 56.09s/it, lr=1.56e-5, test_acc=73.4, time=56.1, train_acc=75.8, train_loss=0.661, val_acc=73.6, val_loss=0.722]Epoch 61:   6%|▌         | 61/1000 [57:54<14:37:50, 56.09s/it, lr=1.56e-5, test_acc=73.8, time=56.1, train_acc=75.8, train_loss=0.661, val_acc=73.7, val_loss=0.719]Epoch 61:   6%|▌         | 62/1000 [57:54<14:37:22, 56.12s/it, lr=1.56e-5, test_acc=73.8, time=56.1, train_acc=75.8, train_loss=0.661, val_acc=73.7, val_loss=0.719]Epoch 62:   6%|▌         | 62/1000 [57:54<14:37:22, 56.12s/it, lr=1.56e-5, test_acc=73.8, time=56.1, train_acc=75.8, train_loss=0.661, val_acc=73.7, val_loss=0.719]Epoch 62:   6%|▌         | 62/1000 [58:50<14:37:22, 56.12s/it, lr=1.56e-5, test_acc=73.4, time=56.2, train_acc=75.8, train_loss=0.661, val_acc=73.6, val_loss=0.723]Epoch 62:   6%|▋         | 63/1000 [58:50<14:36:40, 56.14s/it, lr=1.56e-5, test_acc=73.4, time=56.2, train_acc=75.8, train_loss=0.661, val_acc=73.6, val_loss=0.723]Epoch 63:   6%|▋         | 63/1000 [58:50<14:36:40, 56.14s/it, lr=1.56e-5, test_acc=73.4, time=56.2, train_acc=75.8, train_loss=0.661, val_acc=73.6, val_loss=0.723]Epoch 63:   6%|▋         | 63/1000 [59:46<14:36:40, 56.14s/it, lr=1.56e-5, test_acc=73.6, time=56, train_acc=75.8, train_loss=0.662, val_acc=73.7, val_loss=0.72]   Epoch 63:   6%|▋         | 64/1000 [59:46<14:35:15, 56.11s/it, lr=1.56e-5, test_acc=73.6, time=56, train_acc=75.8, train_loss=0.662, val_acc=73.7, val_loss=0.72]Epoch 64:   6%|▋         | 64/1000 [59:46<14:35:15, 56.11s/it, lr=1.56e-5, test_acc=73.6, time=56, train_acc=75.8, train_loss=0.662, val_acc=73.7, val_loss=0.72]Epoch 64:   6%|▋         | 64/1000 [1:00:43<14:35:15, 56.11s/it, lr=1.56e-5, test_acc=73.6, time=56.3, train_acc=75.8, train_loss=0.661, val_acc=73.8, val_loss=0.719]Epoch    65: reducing learning rate of group 0 to 7.8125e-06.

!! LR SMALLER OR EQUAL TO MIN LR THRESHOLD.
Epoch 64:   6%|▋         | 64/1000 [1:00:43<14:48:03, 56.93s/it, lr=1.56e-5, test_acc=73.6, time=56.3, train_acc=75.8, train_loss=0.661, val_acc=73.8, val_loss=0.719]
Test Accuracy: 73.5924
Train Accuracy: 75.7222
Convergence Time (Epochs): 64.0000
TOTAL TIME TAKEN: 3670.1098s
AVG TIME PER EPOCH: 56.0290s
