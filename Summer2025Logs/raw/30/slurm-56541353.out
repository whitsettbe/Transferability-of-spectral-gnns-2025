I'm echoing to stdout
I'm echoing to stderr
My JobID is 56541353
I have 8 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.2492s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 4, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'rational_vec', 'normalized_laplacian': True, 'post_normalized': False, 'eigval_norm': '', 'num_eigs': 15, 'bias_mode': 'spatial', 'eigval_hidden_dim': 5, 'eigval_num_hidden_layer': 3, 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 5, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/zinc_train_rec_full.csv', 'test': 'supp_data/molecules/zinc_test_rec_full.csv', 'val': 'supp_data/molecules/zinc_val_rec_full.csv'}, 'fixMissingPhi1': False, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [02:48<?, ?it/s, lr=0.001, test_MAE=1.45, time=169, train_MAE=1.35, train_loss=1.46, val_MAE=1.37, val_loss=1.51]Epoch 0:   0%|          | 1/1000 [02:48<46:53:15, 168.96s/it, lr=0.001, test_MAE=1.45, time=169, train_MAE=1.35, train_loss=1.46, val_MAE=1.37, val_loss=1.51]Epoch 1:   0%|          | 1/1000 [02:48<46:53:15, 168.96s/it, lr=0.001, test_MAE=1.45, time=169, train_MAE=1.35, train_loss=1.46, val_MAE=1.37, val_loss=1.51]Epoch 1:   0%|          | 1/1000 [05:17<46:53:15, 168.96s/it, lr=0.001, test_MAE=1.45, time=149, train_MAE=1.13, train_loss=1.28, val_MAE=1.36, val_loss=1.52]Epoch 1:   0%|          | 2/1000 [05:17<45:09:21, 162.89s/it, lr=0.001, test_MAE=1.45, time=149, train_MAE=1.13, train_loss=1.28, val_MAE=1.36, val_loss=1.52]Epoch 2:   0%|          | 2/1000 [05:17<45:09:21, 162.89s/it, lr=0.001, test_MAE=1.45, time=149, train_MAE=1.13, train_loss=1.28, val_MAE=1.36, val_loss=1.52]Epoch 2:   0%|          | 2/1000 [07:47<45:09:21, 162.89s/it, lr=0.001, test_MAE=1.53, time=150, train_MAE=0.971, train_loss=1.14, val_MAE=1.52, val_loss=1.69]Epoch 2:   0%|          | 3/1000 [07:47<44:00:13, 158.89s/it, lr=0.001, test_MAE=1.53, time=150, train_MAE=0.971, train_loss=1.14, val_MAE=1.52, val_loss=1.69]Epoch 3:   0%|          | 3/1000 [07:47<44:00:13, 158.89s/it, lr=0.001, test_MAE=1.53, time=150, train_MAE=0.971, train_loss=1.14, val_MAE=1.52, val_loss=1.69]Epoch 3:   0%|          | 3/1000 [10:15<44:00:13, 158.89s/it, lr=0.001, test_MAE=1.43, time=148, train_MAE=0.879, train_loss=1.05, val_MAE=1.43, val_loss=1.61]Epoch 3:   0%|          | 4/1000 [10:15<43:03:39, 155.64s/it, lr=0.001, test_MAE=1.43, time=148, train_MAE=0.879, train_loss=1.05, val_MAE=1.43, val_loss=1.61]Epoch 4:   0%|          | 4/1000 [10:15<43:03:39, 155.64s/it, lr=0.001, test_MAE=1.43, time=148, train_MAE=0.879, train_loss=1.05, val_MAE=1.43, val_loss=1.61]Epoch 4:   0%|          | 4/1000 [12:42<43:03:39, 155.64s/it, lr=0.001, test_MAE=1.43, time=147, train_MAE=0.816, train_loss=0.998, val_MAE=1.39, val_loss=1.57]Epoch 4:   0%|          | 5/1000 [12:42<42:17:26, 153.01s/it, lr=0.001, test_MAE=1.43, time=147, train_MAE=0.816, train_loss=0.998, val_MAE=1.39, val_loss=1.57]Epoch 5:   0%|          | 5/1000 [12:42<42:17:26, 153.01s/it, lr=0.001, test_MAE=1.43, time=147, train_MAE=0.816, train_loss=0.998, val_MAE=1.39, val_loss=1.57]Epoch 5:   0%|          | 5/1000 [15:09<42:17:26, 153.01s/it, lr=0.001, test_MAE=1.26, time=148, train_MAE=0.785, train_loss=0.974, val_MAE=1.18, val_loss=1.37]Epoch 5:   1%|          | 6/1000 [15:09<41:48:48, 151.44s/it, lr=0.001, test_MAE=1.26, time=148, train_MAE=0.785, train_loss=0.974, val_MAE=1.18, val_loss=1.37]Epoch 6:   1%|          | 6/1000 [15:09<41:48:48, 151.44s/it, lr=0.001, test_MAE=1.26, time=148, train_MAE=0.785, train_loss=0.974, val_MAE=1.18, val_loss=1.37]Epoch 6:   1%|          | 6/1000 [17:40<41:48:48, 151.44s/it, lr=0.001, test_MAE=1.13, time=151, train_MAE=0.746, train_loss=0.94, val_MAE=1.05, val_loss=1.25] Epoch 6:   1%|          | 7/1000 [17:40<41:42:58, 151.24s/it, lr=0.001, test_MAE=1.13, time=151, train_MAE=0.746, train_loss=0.94, val_MAE=1.05, val_loss=1.25]Epoch 7:   1%|          | 7/1000 [17:40<41:42:58, 151.24s/it, lr=0.001, test_MAE=1.13, time=151, train_MAE=0.746, train_loss=0.94, val_MAE=1.05, val_loss=1.25]Epoch 7:   1%|          | 7/1000 [20:09<41:42:58, 151.24s/it, lr=0.001, test_MAE=1.05, time=149, train_MAE=0.725, train_loss=0.923, val_MAE=0.989, val_loss=1.19]Epoch 7:   1%|          | 8/1000 [20:09<41:29:29, 150.57s/it, lr=0.001, test_MAE=1.05, time=149, train_MAE=0.725, train_loss=0.923, val_MAE=0.989, val_loss=1.19]Epoch 8:   1%|          | 8/1000 [20:09<41:29:29, 150.57s/it, lr=0.001, test_MAE=1.05, time=149, train_MAE=0.725, train_loss=0.923, val_MAE=0.989, val_loss=1.19]Epoch 8:   1%|          | 8/1000 [22:36<41:29:29, 150.57s/it, lr=0.001, test_MAE=1.01, time=147, train_MAE=0.719, train_loss=0.92, val_MAE=0.943, val_loss=1.15] Epoch 8:   1%|          | 9/1000 [22:36<41:09:33, 149.52s/it, lr=0.001, test_MAE=1.01, time=147, train_MAE=0.719, train_loss=0.92, val_MAE=0.943, val_loss=1.15]Epoch 9:   1%|          | 9/1000 [22:36<41:09:33, 149.52s/it, lr=0.001, test_MAE=1.01, time=147, train_MAE=0.719, train_loss=0.92, val_MAE=0.943, val_loss=1.15]Epoch 9:   1%|          | 9/1000 [25:06<41:09:33, 149.52s/it, lr=0.001, test_MAE=0.979, time=150, train_MAE=0.707, train_loss=0.912, val_MAE=0.928, val_loss=1.13]Epoch 9:   1%|          | 10/1000 [25:06<41:07:05, 149.52s/it, lr=0.001, test_MAE=0.979, time=150, train_MAE=0.707, train_loss=0.912, val_MAE=0.928, val_loss=1.13]Epoch 10:   1%|          | 10/1000 [25:06<41:07:05, 149.52s/it, lr=0.001, test_MAE=0.979, time=150, train_MAE=0.707, train_loss=0.912, val_MAE=0.928, val_loss=1.13]Epoch 10:   1%|          | 10/1000 [27:35<41:07:05, 149.52s/it, lr=0.001, test_MAE=0.892, time=149, train_MAE=0.699, train_loss=0.906, val_MAE=0.828, val_loss=1.04]Epoch 10:   1%|          | 11/1000 [27:35<41:03:33, 149.46s/it, lr=0.001, test_MAE=0.892, time=149, train_MAE=0.699, train_loss=0.906, val_MAE=0.828, val_loss=1.04]Epoch 11:   1%|          | 11/1000 [27:35<41:03:33, 149.46s/it, lr=0.001, test_MAE=0.892, time=149, train_MAE=0.699, train_loss=0.906, val_MAE=0.828, val_loss=1.04]Epoch 11:   1%|          | 11/1000 [30:03<41:03:33, 149.46s/it, lr=0.001, test_MAE=0.823, time=148, train_MAE=0.694, train_loss=0.905, val_MAE=0.788, val_loss=0.999]Epoch 11:   1%|          | 12/1000 [30:03<40:54:36, 149.07s/it, lr=0.001, test_MAE=0.823, time=148, train_MAE=0.694, train_loss=0.905, val_MAE=0.788, val_loss=0.999]Epoch 12:   1%|          | 12/1000 [30:03<40:54:36, 149.07s/it, lr=0.001, test_MAE=0.823, time=148, train_MAE=0.694, train_loss=0.905, val_MAE=0.788, val_loss=0.999]Epoch 12:   1%|          | 12/1000 [32:35<40:54:36, 149.07s/it, lr=0.001, test_MAE=0.862, time=152, train_MAE=0.684, train_loss=0.897, val_MAE=0.815, val_loss=1.03] Epoch 12:   1%|▏         | 13/1000 [32:35<41:07:36, 150.01s/it, lr=0.001, test_MAE=0.862, time=152, train_MAE=0.684, train_loss=0.897, val_MAE=0.815, val_loss=1.03]Epoch 13:   1%|▏         | 13/1000 [32:35<41:07:36, 150.01s/it, lr=0.001, test_MAE=0.862, time=152, train_MAE=0.684, train_loss=0.897, val_MAE=0.815, val_loss=1.03]Epoch 13:   1%|▏         | 13/1000 [35:05<41:07:36, 150.01s/it, lr=0.001, test_MAE=0.966, time=150, train_MAE=0.669, train_loss=0.885, val_MAE=0.921, val_loss=1.14]Epoch 13:   1%|▏         | 14/1000 [35:05<41:04:09, 149.95s/it, lr=0.001, test_MAE=0.966, time=150, train_MAE=0.669, train_loss=0.885, val_MAE=0.921, val_loss=1.14]Epoch 14:   1%|▏         | 14/1000 [35:05<41:04:09, 149.95s/it, lr=0.001, test_MAE=0.966, time=150, train_MAE=0.669, train_loss=0.885, val_MAE=0.921, val_loss=1.14]Epoch 14:   1%|▏         | 14/1000 [37:33<41:04:09, 149.95s/it, lr=0.001, test_MAE=0.826, time=148, train_MAE=0.681, train_loss=0.9, val_MAE=0.759, val_loss=0.979] Epoch 14:   2%|▏         | 15/1000 [37:33<40:51:00, 149.30s/it, lr=0.001, test_MAE=0.826, time=148, train_MAE=0.681, train_loss=0.9, val_MAE=0.759, val_loss=0.979]Epoch 15:   2%|▏         | 15/1000 [37:33<40:51:00, 149.30s/it, lr=0.001, test_MAE=0.826, time=148, train_MAE=0.681, train_loss=0.9, val_MAE=0.759, val_loss=0.979]Epoch 15:   2%|▏         | 15/1000 [40:02<40:51:00, 149.30s/it, lr=0.001, test_MAE=0.806, time=149, train_MAE=0.659, train_loss=0.881, val_MAE=0.75, val_loss=0.972]Epoch 15:   2%|▏         | 16/1000 [40:02<40:48:05, 149.27s/it, lr=0.001, test_MAE=0.806, time=149, train_MAE=0.659, train_loss=0.881, val_MAE=0.75, val_loss=0.972]Epoch 16:   2%|▏         | 16/1000 [40:02<40:48:05, 149.27s/it, lr=0.001, test_MAE=0.806, time=149, train_MAE=0.659, train_loss=0.881, val_MAE=0.75, val_loss=0.972]Epoch 16:   2%|▏         | 16/1000 [42:31<40:48:05, 149.27s/it, lr=0.001, test_MAE=0.987, time=149, train_MAE=0.67, train_loss=0.894, val_MAE=0.943, val_loss=1.17] Epoch 16:   2%|▏         | 17/1000 [42:31<40:44:15, 149.19s/it, lr=0.001, test_MAE=0.987, time=149, train_MAE=0.67, train_loss=0.894, val_MAE=0.943, val_loss=1.17]Epoch 17:   2%|▏         | 17/1000 [42:31<40:44:15, 149.19s/it, lr=0.001, test_MAE=0.987, time=149, train_MAE=0.67, train_loss=0.894, val_MAE=0.943, val_loss=1.17]Epoch 17:   2%|▏         | 17/1000 [45:01<40:44:15, 149.19s/it, lr=0.001, test_MAE=0.898, time=150, train_MAE=0.66, train_loss=0.886, val_MAE=0.848, val_loss=1.08]Epoch 17:   2%|▏         | 18/1000 [45:01<40:43:25, 149.29s/it, lr=0.001, test_MAE=0.898, time=150, train_MAE=0.66, train_loss=0.886, val_MAE=0.848, val_loss=1.08]Epoch 18:   2%|▏         | 18/1000 [45:01<40:43:25, 149.29s/it, lr=0.001, test_MAE=0.898, time=150, train_MAE=0.66, train_loss=0.886, val_MAE=0.848, val_loss=1.08]Epoch 18:   2%|▏         | 18/1000 [47:29<40:43:25, 149.29s/it, lr=0.001, test_MAE=0.828, time=149, train_MAE=0.665, train_loss=0.893, val_MAE=0.778, val_loss=1.01]Epoch 18:   2%|▏         | 19/1000 [47:29<40:37:33, 149.09s/it, lr=0.001, test_MAE=0.828, time=149, train_MAE=0.665, train_loss=0.893, val_MAE=0.778, val_loss=1.01]Epoch 19:   2%|▏         | 19/1000 [47:29<40:37:33, 149.09s/it, lr=0.001, test_MAE=0.828, time=149, train_MAE=0.665, train_loss=0.893, val_MAE=0.778, val_loss=1.01]Epoch 19:   2%|▏         | 19/1000 [49:58<40:37:33, 149.09s/it, lr=0.001, test_MAE=0.83, time=149, train_MAE=0.66, train_loss=0.891, val_MAE=0.793, val_loss=1.03]  Epoch 19:   2%|▏         | 20/1000 [49:58<40:34:22, 149.04s/it, lr=0.001, test_MAE=0.83, time=149, train_MAE=0.66, train_loss=0.891, val_MAE=0.793, val_loss=1.03]Epoch 20:   2%|▏         | 20/1000 [49:58<40:34:22, 149.04s/it, lr=0.001, test_MAE=0.83, time=149, train_MAE=0.66, train_loss=0.891, val_MAE=0.793, val_loss=1.03]Epoch 20:   2%|▏         | 20/1000 [52:29<40:34:22, 149.04s/it, lr=0.001, test_MAE=0.811, time=150, train_MAE=0.681, train_loss=0.914, val_MAE=0.755, val_loss=0.989]Epoch 20:   2%|▏         | 21/1000 [52:29<40:37:46, 149.40s/it, lr=0.001, test_MAE=0.811, time=150, train_MAE=0.681, train_loss=0.914, val_MAE=0.755, val_loss=0.989]Epoch 21:   2%|▏         | 21/1000 [52:29<40:37:46, 149.40s/it, lr=0.001, test_MAE=0.811, time=150, train_MAE=0.681, train_loss=0.914, val_MAE=0.755, val_loss=0.989]Epoch 21:   2%|▏         | 21/1000 [54:55<40:37:46, 149.40s/it, lr=0.001, test_MAE=0.823, time=146, train_MAE=0.659, train_loss=0.894, val_MAE=0.778, val_loss=1.01] Epoch    22: reducing learning rate of group 0 to 5.0000e-04.
Epoch 21:   2%|▏         | 22/1000 [54:55<40:18:12, 148.36s/it, lr=0.001, test_MAE=0.823, time=146, train_MAE=0.659, train_loss=0.894, val_MAE=0.778, val_loss=1.01]Epoch 22:   2%|▏         | 22/1000 [54:55<40:18:12, 148.36s/it, lr=0.001, test_MAE=0.823, time=146, train_MAE=0.659, train_loss=0.894, val_MAE=0.778, val_loss=1.01]Epoch 22:   2%|▏         | 22/1000 [57:17<40:18:12, 148.36s/it, lr=0.0005, test_MAE=0.732, time=142, train_MAE=0.645, train_loss=0.881, val_MAE=0.675, val_loss=0.91]Epoch 22:   2%|▏         | 23/1000 [57:17<39:45:01, 146.47s/it, lr=0.0005, test_MAE=0.732, time=142, train_MAE=0.645, train_loss=0.881, val_MAE=0.675, val_loss=0.91]Epoch 23:   2%|▏         | 23/1000 [57:17<39:45:01, 146.47s/it, lr=0.0005, test_MAE=0.732, time=142, train_MAE=0.645, train_loss=0.881, val_MAE=0.675, val_loss=0.91]Epoch 23:   2%|▏         | 23/1000 [59:52<39:45:01, 146.47s/it, lr=0.0005, test_MAE=0.849, time=155, train_MAE=0.645, train_loss=0.88, val_MAE=0.816, val_loss=1.05] Epoch 23:   2%|▏         | 24/1000 [59:52<40:26:36, 149.18s/it, lr=0.0005, test_MAE=0.849, time=155, train_MAE=0.645, train_loss=0.88, val_MAE=0.816, val_loss=1.05]Epoch 24:   2%|▏         | 24/1000 [59:52<40:26:36, 149.18s/it, lr=0.0005, test_MAE=0.849, time=155, train_MAE=0.645, train_loss=0.88, val_MAE=0.816, val_loss=1.05]Epoch 24:   2%|▏         | 24/1000 [1:02:11<40:26:36, 149.18s/it, lr=0.0005, test_MAE=0.759, time=139, train_MAE=0.646, train_loss=0.882, val_MAE=0.718, val_loss=0.954]Epoch 24:   2%|▎         | 25/1000 [1:02:11<39:33:56, 146.09s/it, lr=0.0005, test_MAE=0.759, time=139, train_MAE=0.646, train_loss=0.882, val_MAE=0.718, val_loss=0.954]Epoch 25:   2%|▎         | 25/1000 [1:02:11<39:33:56, 146.09s/it, lr=0.0005, test_MAE=0.759, time=139, train_MAE=0.646, train_loss=0.882, val_MAE=0.718, val_loss=0.954]Epoch 25:   2%|▎         | 25/1000 [1:04:36<39:33:56, 146.09s/it, lr=0.0005, test_MAE=0.72, time=145, train_MAE=0.644, train_loss=0.88, val_MAE=0.653, val_loss=0.89]   Epoch 25:   3%|▎         | 26/1000 [1:04:36<39:24:04, 145.63s/it, lr=0.0005, test_MAE=0.72, time=145, train_MAE=0.644, train_loss=0.88, val_MAE=0.653, val_loss=0.89]Epoch 26:   3%|▎         | 26/1000 [1:04:36<39:24:04, 145.63s/it, lr=0.0005, test_MAE=0.72, time=145, train_MAE=0.644, train_loss=0.88, val_MAE=0.653, val_loss=0.89]Epoch 26:   3%|▎         | 26/1000 [1:07:04<39:24:04, 145.63s/it, lr=0.0005, test_MAE=0.739, time=148, train_MAE=0.637, train_loss=0.873, val_MAE=0.695, val_loss=0.931]Epoch 26:   3%|▎         | 27/1000 [1:07:04<39:33:16, 146.35s/it, lr=0.0005, test_MAE=0.739, time=148, train_MAE=0.637, train_loss=0.873, val_MAE=0.695, val_loss=0.931]Epoch 27:   3%|▎         | 27/1000 [1:07:04<39:33:16, 146.35s/it, lr=0.0005, test_MAE=0.739, time=148, train_MAE=0.637, train_loss=0.873, val_MAE=0.695, val_loss=0.931]Epoch 27:   3%|▎         | 27/1000 [1:09:27<39:33:16, 146.35s/it, lr=0.0005, test_MAE=0.766, time=144, train_MAE=0.64, train_loss=0.877, val_MAE=0.693, val_loss=0.929] Epoch 27:   3%|▎         | 28/1000 [1:09:27<39:17:21, 145.52s/it, lr=0.0005, test_MAE=0.766, time=144, train_MAE=0.64, train_loss=0.877, val_MAE=0.693, val_loss=0.929]Epoch 28:   3%|▎         | 28/1000 [1:09:27<39:17:21, 145.52s/it, lr=0.0005, test_MAE=0.766, time=144, train_MAE=0.64, train_loss=0.877, val_MAE=0.693, val_loss=0.929]Epoch 28:   3%|▎         | 28/1000 [1:12:03<39:17:21, 145.52s/it, lr=0.0005, test_MAE=0.823, time=156, train_MAE=0.638, train_loss=0.874, val_MAE=0.775, val_loss=1.01]Epoch 28:   3%|▎         | 29/1000 [1:12:03<40:06:35, 148.71s/it, lr=0.0005, test_MAE=0.823, time=156, train_MAE=0.638, train_loss=0.874, val_MAE=0.775, val_loss=1.01]Epoch 29:   3%|▎         | 29/1000 [1:12:03<40:06:35, 148.71s/it, lr=0.0005, test_MAE=0.823, time=156, train_MAE=0.638, train_loss=0.874, val_MAE=0.775, val_loss=1.01]Epoch 29:   3%|▎         | 29/1000 [1:14:41<40:06:35, 148.71s/it, lr=0.0005, test_MAE=0.847, time=157, train_MAE=0.647, train_loss=0.884, val_MAE=0.793, val_loss=1.03]Epoch 29:   3%|▎         | 30/1000 [1:14:41<40:46:22, 151.32s/it, lr=0.0005, test_MAE=0.847, time=157, train_MAE=0.647, train_loss=0.884, val_MAE=0.793, val_loss=1.03]Epoch 30:   3%|▎         | 30/1000 [1:14:41<40:46:22, 151.32s/it, lr=0.0005, test_MAE=0.847, time=157, train_MAE=0.647, train_loss=0.884, val_MAE=0.793, val_loss=1.03]Epoch 30:   3%|▎         | 30/1000 [1:17:15<40:46:22, 151.32s/it, lr=0.0005, test_MAE=0.725, time=154, train_MAE=0.636, train_loss=0.873, val_MAE=0.676, val_loss=0.913]Epoch 30:   3%|▎         | 31/1000 [1:17:15<40:58:43, 152.24s/it, lr=0.0005, test_MAE=0.725, time=154, train_MAE=0.636, train_loss=0.873, val_MAE=0.676, val_loss=0.913]Epoch 31:   3%|▎         | 31/1000 [1:17:15<40:58:43, 152.24s/it, lr=0.0005, test_MAE=0.725, time=154, train_MAE=0.636, train_loss=0.873, val_MAE=0.676, val_loss=0.913]Epoch 31:   3%|▎         | 31/1000 [1:19:45<40:58:43, 152.24s/it, lr=0.0005, test_MAE=0.77, time=150, train_MAE=0.639, train_loss=0.876, val_MAE=0.726, val_loss=0.963] Epoch    32: reducing learning rate of group 0 to 2.5000e-04.
Epoch 31:   3%|▎         | 32/1000 [1:19:45<40:46:22, 151.63s/it, lr=0.0005, test_MAE=0.77, time=150, train_MAE=0.639, train_loss=0.876, val_MAE=0.726, val_loss=0.963]Epoch 32:   3%|▎         | 32/1000 [1:19:45<40:46:22, 151.63s/it, lr=0.0005, test_MAE=0.77, time=150, train_MAE=0.639, train_loss=0.876, val_MAE=0.726, val_loss=0.963]Epoch 32:   3%|▎         | 32/1000 [1:22:26<40:46:22, 151.63s/it, lr=0.00025, test_MAE=0.713, time=160, train_MAE=0.637, train_loss=0.875, val_MAE=0.667, val_loss=0.905]Epoch 32:   3%|▎         | 33/1000 [1:22:26<41:26:15, 154.27s/it, lr=0.00025, test_MAE=0.713, time=160, train_MAE=0.637, train_loss=0.875, val_MAE=0.667, val_loss=0.905]Epoch 33:   3%|▎         | 33/1000 [1:22:26<41:26:15, 154.27s/it, lr=0.00025, test_MAE=0.713, time=160, train_MAE=0.637, train_loss=0.875, val_MAE=0.667, val_loss=0.905]Epoch 33:   3%|▎         | 33/1000 [1:25:01<41:26:15, 154.27s/it, lr=0.00025, test_MAE=0.718, time=155, train_MAE=0.627, train_loss=0.864, val_MAE=0.672, val_loss=0.909]Epoch 33:   3%|▎         | 34/1000 [1:25:01<41:28:13, 154.55s/it, lr=0.00025, test_MAE=0.718, time=155, train_MAE=0.627, train_loss=0.864, val_MAE=0.672, val_loss=0.909]Epoch 34:   3%|▎         | 34/1000 [1:25:01<41:28:13, 154.55s/it, lr=0.00025, test_MAE=0.718, time=155, train_MAE=0.627, train_loss=0.864, val_MAE=0.672, val_loss=0.909]Epoch 34:   3%|▎         | 34/1000 [1:27:25<41:28:13, 154.55s/it, lr=0.00025, test_MAE=0.742, time=144, train_MAE=0.632, train_loss=0.869, val_MAE=0.7, val_loss=0.937]  Epoch 34:   4%|▎         | 35/1000 [1:27:25<40:33:44, 151.32s/it, lr=0.00025, test_MAE=0.742, time=144, train_MAE=0.632, train_loss=0.869, val_MAE=0.7, val_loss=0.937]Epoch 35:   4%|▎         | 35/1000 [1:27:25<40:33:44, 151.32s/it, lr=0.00025, test_MAE=0.742, time=144, train_MAE=0.632, train_loss=0.869, val_MAE=0.7, val_loss=0.937]Epoch 35:   4%|▎         | 35/1000 [1:29:49<40:33:44, 151.32s/it, lr=0.00025, test_MAE=0.723, time=144, train_MAE=0.632, train_loss=0.869, val_MAE=0.67, val_loss=0.906]Epoch 35:   4%|▎         | 36/1000 [1:29:49<39:55:38, 149.11s/it, lr=0.00025, test_MAE=0.723, time=144, train_MAE=0.632, train_loss=0.869, val_MAE=0.67, val_loss=0.906]Epoch 36:   4%|▎         | 36/1000 [1:29:49<39:55:38, 149.11s/it, lr=0.00025, test_MAE=0.723, time=144, train_MAE=0.632, train_loss=0.869, val_MAE=0.67, val_loss=0.906]Epoch 36:   4%|▎         | 36/1000 [1:32:23<39:55:38, 149.11s/it, lr=0.00025, test_MAE=0.713, time=155, train_MAE=0.624, train_loss=0.861, val_MAE=0.666, val_loss=0.903]Epoch 36:   4%|▎         | 37/1000 [1:32:23<40:20:43, 150.82s/it, lr=0.00025, test_MAE=0.713, time=155, train_MAE=0.624, train_loss=0.861, val_MAE=0.666, val_loss=0.903]Epoch 37:   4%|▎         | 37/1000 [1:32:23<40:20:43, 150.82s/it, lr=0.00025, test_MAE=0.713, time=155, train_MAE=0.624, train_loss=0.861, val_MAE=0.666, val_loss=0.903]Epoch 37:   4%|▎         | 37/1000 [1:35:00<40:20:43, 150.82s/it, lr=0.00025, test_MAE=0.717, time=157, train_MAE=0.632, train_loss=0.869, val_MAE=0.677, val_loss=0.914]Epoch    38: reducing learning rate of group 0 to 1.2500e-04.
Epoch 37:   4%|▍         | 38/1000 [1:35:00<40:46:10, 152.57s/it, lr=0.00025, test_MAE=0.717, time=157, train_MAE=0.632, train_loss=0.869, val_MAE=0.677, val_loss=0.914]Epoch 38:   4%|▍         | 38/1000 [1:35:00<40:46:10, 152.57s/it, lr=0.00025, test_MAE=0.717, time=157, train_MAE=0.632, train_loss=0.869, val_MAE=0.677, val_loss=0.914]Epoch 38:   4%|▍         | 38/1000 [1:37:38<40:46:10, 152.57s/it, lr=0.000125, test_MAE=0.775, time=158, train_MAE=0.622, train_loss=0.858, val_MAE=0.735, val_loss=0.971]Epoch 38:   4%|▍         | 39/1000 [1:37:38<41:08:00, 154.09s/it, lr=0.000125, test_MAE=0.775, time=158, train_MAE=0.622, train_loss=0.858, val_MAE=0.735, val_loss=0.971]Epoch 39:   4%|▍         | 39/1000 [1:37:38<41:08:00, 154.09s/it, lr=0.000125, test_MAE=0.775, time=158, train_MAE=0.622, train_loss=0.858, val_MAE=0.735, val_loss=0.971]Epoch 39:   4%|▍         | 39/1000 [1:40:00<41:08:00, 154.09s/it, lr=0.000125, test_MAE=0.701, time=143, train_MAE=0.623, train_loss=0.86, val_MAE=0.655, val_loss=0.892] Epoch 39:   4%|▍         | 40/1000 [1:40:00<40:10:24, 150.65s/it, lr=0.000125, test_MAE=0.701, time=143, train_MAE=0.623, train_loss=0.86, val_MAE=0.655, val_loss=0.892]Epoch 40:   4%|▍         | 40/1000 [1:40:00<40:10:24, 150.65s/it, lr=0.000125, test_MAE=0.701, time=143, train_MAE=0.623, train_loss=0.86, val_MAE=0.655, val_loss=0.892]Epoch 40:   4%|▍         | 40/1000 [1:42:26<40:10:24, 150.65s/it, lr=0.000125, test_MAE=0.714, time=146, train_MAE=0.623, train_loss=0.86, val_MAE=0.666, val_loss=0.902]Epoch 40:   4%|▍         | 41/1000 [1:42:26<39:44:32, 149.19s/it, lr=0.000125, test_MAE=0.714, time=146, train_MAE=0.623, train_loss=0.86, val_MAE=0.666, val_loss=0.902]Epoch 41:   4%|▍         | 41/1000 [1:42:26<39:44:32, 149.19s/it, lr=0.000125, test_MAE=0.714, time=146, train_MAE=0.623, train_loss=0.86, val_MAE=0.666, val_loss=0.902]Epoch 41:   4%|▍         | 41/1000 [1:44:49<39:44:32, 149.19s/it, lr=0.000125, test_MAE=0.74, time=142, train_MAE=0.626, train_loss=0.862, val_MAE=0.7, val_loss=0.936]  Epoch 41:   4%|▍         | 42/1000 [1:44:49<39:10:00, 147.18s/it, lr=0.000125, test_MAE=0.74, time=142, train_MAE=0.626, train_loss=0.862, val_MAE=0.7, val_loss=0.936]Epoch 42:   4%|▍         | 42/1000 [1:44:49<39:10:00, 147.18s/it, lr=0.000125, test_MAE=0.74, time=142, train_MAE=0.626, train_loss=0.862, val_MAE=0.7, val_loss=0.936]Epoch 42:   4%|▍         | 42/1000 [1:47:15<39:10:00, 147.18s/it, lr=0.000125, test_MAE=0.738, time=147, train_MAE=0.625, train_loss=0.861, val_MAE=0.68, val_loss=0.916]Epoch 42:   4%|▍         | 43/1000 [1:47:15<39:04:56, 147.02s/it, lr=0.000125, test_MAE=0.738, time=147, train_MAE=0.625, train_loss=0.861, val_MAE=0.68, val_loss=0.916]Epoch 43:   4%|▍         | 43/1000 [1:47:15<39:04:56, 147.02s/it, lr=0.000125, test_MAE=0.738, time=147, train_MAE=0.625, train_loss=0.861, val_MAE=0.68, val_loss=0.916]Epoch 43:   4%|▍         | 43/1000 [1:49:53<39:04:56, 147.02s/it, lr=0.000125, test_MAE=0.719, time=158, train_MAE=0.622, train_loss=0.858, val_MAE=0.656, val_loss=0.891]Epoch    44: reducing learning rate of group 0 to 6.2500e-05.
Epoch 43:   4%|▍         | 44/1000 [1:49:53<39:54:39, 150.29s/it, lr=0.000125, test_MAE=0.719, time=158, train_MAE=0.622, train_loss=0.858, val_MAE=0.656, val_loss=0.891]Epoch 44:   4%|▍         | 44/1000 [1:49:53<39:54:39, 150.29s/it, lr=0.000125, test_MAE=0.719, time=158, train_MAE=0.622, train_loss=0.858, val_MAE=0.656, val_loss=0.891]Epoch 44:   4%|▍         | 44/1000 [1:52:28<39:54:39, 150.29s/it, lr=6.25e-5, test_MAE=0.708, time=155, train_MAE=0.624, train_loss=0.859, val_MAE=0.663, val_loss=0.899] Epoch 44:   4%|▍         | 45/1000 [1:52:28<40:12:22, 151.56s/it, lr=6.25e-5, test_MAE=0.708, time=155, train_MAE=0.624, train_loss=0.859, val_MAE=0.663, val_loss=0.899]Epoch 45:   4%|▍         | 45/1000 [1:52:28<40:12:22, 151.56s/it, lr=6.25e-5, test_MAE=0.708, time=155, train_MAE=0.624, train_loss=0.859, val_MAE=0.663, val_loss=0.899]Epoch 45:   4%|▍         | 45/1000 [1:54:55<40:12:22, 151.56s/it, lr=6.25e-5, test_MAE=0.689, time=147, train_MAE=0.626, train_loss=0.861, val_MAE=0.642, val_loss=0.877]Epoch 45:   5%|▍         | 46/1000 [1:54:55<39:49:03, 150.25s/it, lr=6.25e-5, test_MAE=0.689, time=147, train_MAE=0.626, train_loss=0.861, val_MAE=0.642, val_loss=0.877]Epoch 46:   5%|▍         | 46/1000 [1:54:55<39:49:03, 150.25s/it, lr=6.25e-5, test_MAE=0.689, time=147, train_MAE=0.626, train_loss=0.861, val_MAE=0.642, val_loss=0.877]Epoch 46:   5%|▍         | 46/1000 [1:57:27<39:49:03, 150.25s/it, lr=6.25e-5, test_MAE=0.716, time=152, train_MAE=0.616, train_loss=0.851, val_MAE=0.671, val_loss=0.907]Epoch 46:   5%|▍         | 47/1000 [1:57:27<39:56:08, 150.86s/it, lr=6.25e-5, test_MAE=0.716, time=152, train_MAE=0.616, train_loss=0.851, val_MAE=0.671, val_loss=0.907]Epoch 47:   5%|▍         | 47/1000 [1:57:27<39:56:08, 150.86s/it, lr=6.25e-5, test_MAE=0.716, time=152, train_MAE=0.616, train_loss=0.851, val_MAE=0.671, val_loss=0.907]Epoch 47:   5%|▍         | 47/1000 [1:59:55<39:56:08, 150.86s/it, lr=6.25e-5, test_MAE=0.702, time=148, train_MAE=0.615, train_loss=0.85, val_MAE=0.662, val_loss=0.897] Epoch 47:   5%|▍         | 48/1000 [1:59:55<39:39:01, 149.94s/it, lr=6.25e-5, test_MAE=0.702, time=148, train_MAE=0.615, train_loss=0.85, val_MAE=0.662, val_loss=0.897]Epoch 48:   5%|▍         | 48/1000 [1:59:55<39:39:01, 149.94s/it, lr=6.25e-5, test_MAE=0.702, time=148, train_MAE=0.615, train_loss=0.85, val_MAE=0.662, val_loss=0.897]Epoch 48:   5%|▍         | 48/1000 [2:02:35<39:39:01, 149.94s/it, lr=6.25e-5, test_MAE=0.708, time=159, train_MAE=0.618, train_loss=0.853, val_MAE=0.659, val_loss=0.894]Epoch 48:   5%|▍         | 49/1000 [2:02:35<40:22:03, 152.81s/it, lr=6.25e-5, test_MAE=0.708, time=159, train_MAE=0.618, train_loss=0.853, val_MAE=0.659, val_loss=0.894]Epoch 49:   5%|▍         | 49/1000 [2:02:35<40:22:03, 152.81s/it, lr=6.25e-5, test_MAE=0.708, time=159, train_MAE=0.618, train_loss=0.853, val_MAE=0.659, val_loss=0.894]Epoch 49:   5%|▍         | 49/1000 [2:04:56<40:22:03, 152.81s/it, lr=6.25e-5, test_MAE=0.699, time=141, train_MAE=0.614, train_loss=0.849, val_MAE=0.654, val_loss=0.889]Epoch 49:   5%|▌         | 50/1000 [2:04:56<39:25:44, 149.41s/it, lr=6.25e-5, test_MAE=0.699, time=141, train_MAE=0.614, train_loss=0.849, val_MAE=0.654, val_loss=0.889]Epoch 50:   5%|▌         | 50/1000 [2:04:56<39:25:44, 149.41s/it, lr=6.25e-5, test_MAE=0.699, time=141, train_MAE=0.614, train_loss=0.849, val_MAE=0.654, val_loss=0.889]Epoch 50:   5%|▌         | 50/1000 [2:07:17<39:25:44, 149.41s/it, lr=6.25e-5, test_MAE=0.697, time=141, train_MAE=0.619, train_loss=0.854, val_MAE=0.656, val_loss=0.891]Epoch 50:   5%|▌         | 51/1000 [2:07:17<38:45:26, 147.02s/it, lr=6.25e-5, test_MAE=0.697, time=141, train_MAE=0.619, train_loss=0.854, val_MAE=0.656, val_loss=0.891]Epoch 51:   5%|▌         | 51/1000 [2:07:17<38:45:26, 147.02s/it, lr=6.25e-5, test_MAE=0.697, time=141, train_MAE=0.619, train_loss=0.854, val_MAE=0.656, val_loss=0.891]Epoch 51:   5%|▌         | 51/1000 [2:09:42<38:45:26, 147.02s/it, lr=6.25e-5, test_MAE=0.692, time=144, train_MAE=0.612, train_loss=0.846, val_MAE=0.65, val_loss=0.885] Epoch    52: reducing learning rate of group 0 to 3.1250e-05.
Epoch 51:   5%|▌         | 52/1000 [2:09:42<38:29:56, 146.20s/it, lr=6.25e-5, test_MAE=0.692, time=144, train_MAE=0.612, train_loss=0.846, val_MAE=0.65, val_loss=0.885]Epoch 52:   5%|▌         | 52/1000 [2:09:42<38:29:56, 146.20s/it, lr=6.25e-5, test_MAE=0.692, time=144, train_MAE=0.612, train_loss=0.846, val_MAE=0.65, val_loss=0.885]Epoch 52:   5%|▌         | 52/1000 [2:12:22<38:29:56, 146.20s/it, lr=3.13e-5, test_MAE=0.694, time=160, train_MAE=0.615, train_loss=0.85, val_MAE=0.65, val_loss=0.885] Epoch 52:   5%|▌         | 53/1000 [2:12:22<39:35:09, 150.49s/it, lr=3.13e-5, test_MAE=0.694, time=160, train_MAE=0.615, train_loss=0.85, val_MAE=0.65, val_loss=0.885]Epoch 53:   5%|▌         | 53/1000 [2:12:22<39:35:09, 150.49s/it, lr=3.13e-5, test_MAE=0.694, time=160, train_MAE=0.615, train_loss=0.85, val_MAE=0.65, val_loss=0.885]Epoch 53:   5%|▌         | 53/1000 [2:14:44<39:35:09, 150.49s/it, lr=3.13e-5, test_MAE=0.705, time=142, train_MAE=0.616, train_loss=0.85, val_MAE=0.711, val_loss=0.945]Epoch 53:   5%|▌         | 54/1000 [2:14:44<38:51:01, 147.85s/it, lr=3.13e-5, test_MAE=0.705, time=142, train_MAE=0.616, train_loss=0.85, val_MAE=0.711, val_loss=0.945]Epoch 54:   5%|▌         | 54/1000 [2:14:44<38:51:01, 147.85s/it, lr=3.13e-5, test_MAE=0.705, time=142, train_MAE=0.616, train_loss=0.85, val_MAE=0.711, val_loss=0.945]Epoch 54:   5%|▌         | 54/1000 [2:17:06<38:51:01, 147.85s/it, lr=3.13e-5, test_MAE=0.701, time=142, train_MAE=0.616, train_loss=0.85, val_MAE=0.661, val_loss=0.895]Epoch 54:   6%|▌         | 55/1000 [2:17:06<38:19:29, 146.00s/it, lr=3.13e-5, test_MAE=0.701, time=142, train_MAE=0.616, train_loss=0.85, val_MAE=0.661, val_loss=0.895]Epoch 55:   6%|▌         | 55/1000 [2:17:06<38:19:29, 146.00s/it, lr=3.13e-5, test_MAE=0.701, time=142, train_MAE=0.616, train_loss=0.85, val_MAE=0.661, val_loss=0.895]Epoch 55:   6%|▌         | 55/1000 [2:19:27<38:19:29, 146.00s/it, lr=3.13e-5, test_MAE=0.69, time=142, train_MAE=0.624, train_loss=0.859, val_MAE=0.647, val_loss=0.882]Epoch 55:   6%|▌         | 56/1000 [2:19:27<37:56:52, 144.72s/it, lr=3.13e-5, test_MAE=0.69, time=142, train_MAE=0.624, train_loss=0.859, val_MAE=0.647, val_loss=0.882]Epoch 56:   6%|▌         | 56/1000 [2:19:27<37:56:52, 144.72s/it, lr=3.13e-5, test_MAE=0.69, time=142, train_MAE=0.624, train_loss=0.859, val_MAE=0.647, val_loss=0.882]Epoch 56:   6%|▌         | 56/1000 [2:21:50<37:56:52, 144.72s/it, lr=3.13e-5, test_MAE=0.707, time=143, train_MAE=0.61, train_loss=0.845, val_MAE=0.657, val_loss=0.891]Epoch 56:   6%|▌         | 57/1000 [2:21:50<37:45:44, 144.16s/it, lr=3.13e-5, test_MAE=0.707, time=143, train_MAE=0.61, train_loss=0.845, val_MAE=0.657, val_loss=0.891]Epoch 57:   6%|▌         | 57/1000 [2:21:50<37:45:44, 144.16s/it, lr=3.13e-5, test_MAE=0.707, time=143, train_MAE=0.61, train_loss=0.845, val_MAE=0.657, val_loss=0.891]Epoch 57:   6%|▌         | 57/1000 [2:24:13<37:45:44, 144.16s/it, lr=3.13e-5, test_MAE=0.714, time=143, train_MAE=0.615, train_loss=0.849, val_MAE=0.668, val_loss=0.902]Epoch    58: reducing learning rate of group 0 to 1.5625e-05.
Epoch 57:   6%|▌         | 58/1000 [2:24:13<37:37:43, 143.80s/it, lr=3.13e-5, test_MAE=0.714, time=143, train_MAE=0.615, train_loss=0.849, val_MAE=0.668, val_loss=0.902]Epoch 58:   6%|▌         | 58/1000 [2:24:13<37:37:43, 143.80s/it, lr=3.13e-5, test_MAE=0.714, time=143, train_MAE=0.615, train_loss=0.849, val_MAE=0.668, val_loss=0.902]Epoch 58:   6%|▌         | 58/1000 [2:26:37<37:37:43, 143.80s/it, lr=1.56e-5, test_MAE=0.686, time=144, train_MAE=0.615, train_loss=0.849, val_MAE=0.655, val_loss=0.889]Epoch 58:   6%|▌         | 59/1000 [2:26:37<37:34:33, 143.76s/it, lr=1.56e-5, test_MAE=0.686, time=144, train_MAE=0.615, train_loss=0.849, val_MAE=0.655, val_loss=0.889]Epoch 59:   6%|▌         | 59/1000 [2:26:37<37:34:33, 143.76s/it, lr=1.56e-5, test_MAE=0.686, time=144, train_MAE=0.615, train_loss=0.849, val_MAE=0.655, val_loss=0.889]Epoch 59:   6%|▌         | 59/1000 [2:29:00<37:34:33, 143.76s/it, lr=1.56e-5, test_MAE=0.703, time=144, train_MAE=0.609, train_loss=0.843, val_MAE=0.655, val_loss=0.889]Epoch 59:   6%|▌         | 60/1000 [2:29:00<37:31:24, 143.71s/it, lr=1.56e-5, test_MAE=0.703, time=144, train_MAE=0.609, train_loss=0.843, val_MAE=0.655, val_loss=0.889]Epoch 60:   6%|▌         | 60/1000 [2:29:00<37:31:24, 143.71s/it, lr=1.56e-5, test_MAE=0.703, time=144, train_MAE=0.609, train_loss=0.843, val_MAE=0.655, val_loss=0.889]Epoch 60:   6%|▌         | 60/1000 [2:31:24<37:31:24, 143.71s/it, lr=1.56e-5, test_MAE=0.702, time=143, train_MAE=0.617, train_loss=0.852, val_MAE=0.674, val_loss=0.908]Epoch 60:   6%|▌         | 61/1000 [2:31:24<37:27:36, 143.62s/it, lr=1.56e-5, test_MAE=0.702, time=143, train_MAE=0.617, train_loss=0.852, val_MAE=0.674, val_loss=0.908]Epoch 61:   6%|▌         | 61/1000 [2:31:24<37:27:36, 143.62s/it, lr=1.56e-5, test_MAE=0.702, time=143, train_MAE=0.617, train_loss=0.852, val_MAE=0.674, val_loss=0.908]Epoch 61:   6%|▌         | 61/1000 [2:33:44<37:27:36, 143.62s/it, lr=1.56e-5, test_MAE=0.695, time=140, train_MAE=0.613, train_loss=0.847, val_MAE=0.646, val_loss=0.88] Epoch 61:   6%|▌         | 62/1000 [2:33:44<37:08:12, 142.53s/it, lr=1.56e-5, test_MAE=0.695, time=140, train_MAE=0.613, train_loss=0.847, val_MAE=0.646, val_loss=0.88]Epoch 62:   6%|▌         | 62/1000 [2:33:44<37:08:12, 142.53s/it, lr=1.56e-5, test_MAE=0.695, time=140, train_MAE=0.613, train_loss=0.847, val_MAE=0.646, val_loss=0.88]Epoch 62:   6%|▌         | 62/1000 [2:36:00<37:08:12, 142.53s/it, lr=1.56e-5, test_MAE=0.698, time=137, train_MAE=0.615, train_loss=0.849, val_MAE=0.641, val_loss=0.875]Epoch 62:   6%|▋         | 63/1000 [2:36:00<36:38:26, 140.78s/it, lr=1.56e-5, test_MAE=0.698, time=137, train_MAE=0.615, train_loss=0.849, val_MAE=0.641, val_loss=0.875]Epoch 63:   6%|▋         | 63/1000 [2:36:00<36:38:26, 140.78s/it, lr=1.56e-5, test_MAE=0.698, time=137, train_MAE=0.615, train_loss=0.849, val_MAE=0.641, val_loss=0.875]Epoch 63:   6%|▋         | 63/1000 [2:38:16<36:38:26, 140.78s/it, lr=1.56e-5, test_MAE=0.696, time=135, train_MAE=0.614, train_loss=0.848, val_MAE=0.657, val_loss=0.891]Epoch 63:   6%|▋         | 64/1000 [2:38:16<36:09:51, 139.09s/it, lr=1.56e-5, test_MAE=0.696, time=135, train_MAE=0.614, train_loss=0.848, val_MAE=0.657, val_loss=0.891]Epoch 64:   6%|▋         | 64/1000 [2:38:16<36:09:51, 139.09s/it, lr=1.56e-5, test_MAE=0.696, time=135, train_MAE=0.614, train_loss=0.848, val_MAE=0.657, val_loss=0.891]Epoch 64:   6%|▋         | 64/1000 [2:40:30<36:09:51, 139.09s/it, lr=1.56e-5, test_MAE=0.69, time=134, train_MAE=0.612, train_loss=0.846, val_MAE=0.637, val_loss=0.871] Epoch 64:   6%|▋         | 65/1000 [2:40:30<35:43:43, 137.57s/it, lr=1.56e-5, test_MAE=0.69, time=134, train_MAE=0.612, train_loss=0.846, val_MAE=0.637, val_loss=0.871]Epoch 65:   6%|▋         | 65/1000 [2:40:30<35:43:43, 137.57s/it, lr=1.56e-5, test_MAE=0.69, time=134, train_MAE=0.612, train_loss=0.846, val_MAE=0.637, val_loss=0.871]Epoch 65:   6%|▋         | 65/1000 [2:42:44<35:43:43, 137.57s/it, lr=1.56e-5, test_MAE=0.697, time=134, train_MAE=0.613, train_loss=0.847, val_MAE=0.65, val_loss=0.883]Epoch 65:   7%|▋         | 66/1000 [2:42:44<35:25:03, 136.51s/it, lr=1.56e-5, test_MAE=0.697, time=134, train_MAE=0.613, train_loss=0.847, val_MAE=0.65, val_loss=0.883]Epoch 66:   7%|▋         | 66/1000 [2:42:44<35:25:03, 136.51s/it, lr=1.56e-5, test_MAE=0.697, time=134, train_MAE=0.613, train_loss=0.847, val_MAE=0.65, val_loss=0.883]Epoch 66:   7%|▋         | 66/1000 [2:44:58<35:25:03, 136.51s/it, lr=1.56e-5, test_MAE=0.693, time=134, train_MAE=0.612, train_loss=0.846, val_MAE=0.654, val_loss=0.887]Epoch 66:   7%|▋         | 67/1000 [2:44:58<35:13:22, 135.91s/it, lr=1.56e-5, test_MAE=0.693, time=134, train_MAE=0.612, train_loss=0.846, val_MAE=0.654, val_loss=0.887]Epoch 67:   7%|▋         | 67/1000 [2:44:58<35:13:22, 135.91s/it, lr=1.56e-5, test_MAE=0.693, time=134, train_MAE=0.612, train_loss=0.846, val_MAE=0.654, val_loss=0.887]Epoch 67:   7%|▋         | 67/1000 [2:47:11<35:13:22, 135.91s/it, lr=1.56e-5, test_MAE=0.697, time=133, train_MAE=0.63, train_loss=0.864, val_MAE=0.649, val_loss=0.883] Epoch 67:   7%|▋         | 68/1000 [2:47:11<34:58:22, 135.09s/it, lr=1.56e-5, test_MAE=0.697, time=133, train_MAE=0.63, train_loss=0.864, val_MAE=0.649, val_loss=0.883]Epoch 68:   7%|▋         | 68/1000 [2:47:11<34:58:22, 135.09s/it, lr=1.56e-5, test_MAE=0.697, time=133, train_MAE=0.63, train_loss=0.864, val_MAE=0.649, val_loss=0.883]Epoch 68:   7%|▋         | 68/1000 [2:49:24<34:58:22, 135.09s/it, lr=1.56e-5, test_MAE=0.688, time=132, train_MAE=0.612, train_loss=0.846, val_MAE=0.647, val_loss=0.881]Epoch 68:   7%|▋         | 69/1000 [2:49:24<34:43:25, 134.27s/it, lr=1.56e-5, test_MAE=0.688, time=132, train_MAE=0.612, train_loss=0.846, val_MAE=0.647, val_loss=0.881]Epoch 69:   7%|▋         | 69/1000 [2:49:24<34:43:25, 134.27s/it, lr=1.56e-5, test_MAE=0.688, time=132, train_MAE=0.612, train_loss=0.846, val_MAE=0.647, val_loss=0.881]Epoch 69:   7%|▋         | 69/1000 [2:51:36<34:43:25, 134.27s/it, lr=1.56e-5, test_MAE=0.699, time=133, train_MAE=0.615, train_loss=0.848, val_MAE=0.652, val_loss=0.886]Epoch 69:   7%|▋         | 70/1000 [2:51:36<34:33:59, 133.81s/it, lr=1.56e-5, test_MAE=0.699, time=133, train_MAE=0.615, train_loss=0.848, val_MAE=0.652, val_loss=0.886]Epoch 70:   7%|▋         | 70/1000 [2:51:36<34:33:59, 133.81s/it, lr=1.56e-5, test_MAE=0.699, time=133, train_MAE=0.615, train_loss=0.848, val_MAE=0.652, val_loss=0.886]Epoch 70:   7%|▋         | 70/1000 [2:53:47<34:33:59, 133.81s/it, lr=1.56e-5, test_MAE=0.694, time=131, train_MAE=0.614, train_loss=0.848, val_MAE=0.653, val_loss=0.887]Epoch    71: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 70:   7%|▋         | 70/1000 [2:53:47<38:28:57, 148.96s/it, lr=1.56e-5, test_MAE=0.694, time=131, train_MAE=0.614, train_loss=0.848, val_MAE=0.653, val_loss=0.887]
Test MAE: 0.6940
Train MAE: 0.6365
Convergence Time (Epochs): 70.0000
TOTAL TIME TAKEN: 10484.7317s
AVG TIME PER EPOCH: 146.8470s
