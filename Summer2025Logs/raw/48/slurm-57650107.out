I'm echoing to stdout
I'm echoing to stderr
My JobID is 57650107
I have 8 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 4.9309s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': False, 'readout': 'mean', 'k': 4, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'rational_vec', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_all', 'num_eigs': 16, 'bias_mode': 'spatial', 'eigval_hidden_dim': 5, 'eigval_num_hidden_layer': 3, 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 0.0, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/aug07/zinc_train_rec.csv', 'test': 'supp_data/molecules/aug07/zinc_test_rec.csv', 'val': 'supp_data/molecules/aug07/zinc_val_rec.csv'}, 'fixMissingPhi1': False, 'extraOrtho': False, 'doublePrecision': True, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [03:22<?, ?it/s, lr=0.001, test_MAE=1.55, time=203, train_MAE=1.48, train_loss=1.48, val_MAE=1.44, val_loss=1.44]Epoch 0:   0%|          | 1/1000 [03:22<56:15:57, 202.76s/it, lr=0.001, test_MAE=1.55, time=203, train_MAE=1.48, train_loss=1.48, val_MAE=1.44, val_loss=1.44]Epoch 1:   0%|          | 1/1000 [03:22<56:15:57, 202.76s/it, lr=0.001, test_MAE=1.55, time=203, train_MAE=1.48, train_loss=1.48, val_MAE=1.44, val_loss=1.44]Epoch 1:   0%|          | 1/1000 [06:27<56:15:57, 202.76s/it, lr=0.001, test_MAE=1.51, time=185, train_MAE=1.26, train_loss=1.26, val_MAE=1.41, val_loss=1.41]Epoch 1:   0%|          | 2/1000 [06:27<54:44:51, 197.49s/it, lr=0.001, test_MAE=1.51, time=185, train_MAE=1.26, train_loss=1.26, val_MAE=1.41, val_loss=1.41]Epoch 2:   0%|          | 2/1000 [06:27<54:44:51, 197.49s/it, lr=0.001, test_MAE=1.51, time=185, train_MAE=1.26, train_loss=1.26, val_MAE=1.41, val_loss=1.41]Epoch 2:   0%|          | 2/1000 [09:33<54:44:51, 197.49s/it, lr=0.001, test_MAE=1.98, time=185, train_MAE=0.902, train_loss=0.902, val_MAE=1.89, val_loss=1.89]Epoch 2:   0%|          | 3/1000 [09:33<53:40:34, 193.82s/it, lr=0.001, test_MAE=1.98, time=185, train_MAE=0.902, train_loss=0.902, val_MAE=1.89, val_loss=1.89]Epoch 3:   0%|          | 3/1000 [09:33<53:40:34, 193.82s/it, lr=0.001, test_MAE=1.98, time=185, train_MAE=0.902, train_loss=0.902, val_MAE=1.89, val_loss=1.89]Epoch 3:   0%|          | 3/1000 [12:38<53:40:34, 193.82s/it, lr=0.001, test_MAE=1.25, time=185, train_MAE=0.767, train_loss=0.767, val_MAE=1.17, val_loss=1.17]Epoch 3:   0%|          | 4/1000 [12:38<52:54:32, 191.24s/it, lr=0.001, test_MAE=1.25, time=185, train_MAE=0.767, train_loss=0.767, val_MAE=1.17, val_loss=1.17]Epoch 4:   0%|          | 4/1000 [12:38<52:54:32, 191.24s/it, lr=0.001, test_MAE=1.25, time=185, train_MAE=0.767, train_loss=0.767, val_MAE=1.17, val_loss=1.17]Epoch 4:   0%|          | 4/1000 [15:43<52:54:32, 191.24s/it, lr=0.001, test_MAE=0.9, time=186, train_MAE=0.703, train_loss=0.703, val_MAE=0.897, val_loss=0.897]Epoch 4:   0%|          | 5/1000 [15:43<52:23:00, 189.53s/it, lr=0.001, test_MAE=0.9, time=186, train_MAE=0.703, train_loss=0.703, val_MAE=0.897, val_loss=0.897]Epoch 5:   0%|          | 5/1000 [15:43<52:23:00, 189.53s/it, lr=0.001, test_MAE=0.9, time=186, train_MAE=0.703, train_loss=0.703, val_MAE=0.897, val_loss=0.897]Epoch 5:   0%|          | 5/1000 [18:49<52:23:00, 189.53s/it, lr=0.001, test_MAE=0.86, time=185, train_MAE=0.674, train_loss=0.674, val_MAE=0.801, val_loss=0.801]Epoch 5:   1%|          | 6/1000 [18:49<51:58:41, 188.25s/it, lr=0.001, test_MAE=0.86, time=185, train_MAE=0.674, train_loss=0.674, val_MAE=0.801, val_loss=0.801]Epoch 6:   1%|          | 6/1000 [18:49<51:58:41, 188.25s/it, lr=0.001, test_MAE=0.86, time=185, train_MAE=0.674, train_loss=0.674, val_MAE=0.801, val_loss=0.801]Epoch 6:   1%|          | 6/1000 [21:54<51:58:41, 188.25s/it, lr=0.001, test_MAE=0.77, time=186, train_MAE=0.661, train_loss=0.661, val_MAE=0.713, val_loss=0.713]Epoch 6:   1%|          | 7/1000 [21:54<51:42:18, 187.45s/it, lr=0.001, test_MAE=0.77, time=186, train_MAE=0.661, train_loss=0.661, val_MAE=0.713, val_loss=0.713]Epoch 7:   1%|          | 7/1000 [21:54<51:42:18, 187.45s/it, lr=0.001, test_MAE=0.77, time=186, train_MAE=0.661, train_loss=0.661, val_MAE=0.713, val_loss=0.713]Epoch 7:   1%|          | 7/1000 [25:00<51:42:18, 187.45s/it, lr=0.001, test_MAE=0.806, time=185, train_MAE=0.658, train_loss=0.658, val_MAE=0.754, val_loss=0.754]Epoch 7:   1%|          | 8/1000 [25:00<51:29:16, 186.85s/it, lr=0.001, test_MAE=0.806, time=185, train_MAE=0.658, train_loss=0.658, val_MAE=0.754, val_loss=0.754]Epoch 8:   1%|          | 8/1000 [25:00<51:29:16, 186.85s/it, lr=0.001, test_MAE=0.806, time=185, train_MAE=0.658, train_loss=0.658, val_MAE=0.754, val_loss=0.754]Epoch 8:   1%|          | 8/1000 [28:05<51:29:16, 186.85s/it, lr=0.001, test_MAE=0.785, time=185, train_MAE=0.649, train_loss=0.649, val_MAE=0.793, val_loss=0.793]Epoch 8:   1%|          | 9/1000 [28:05<51:18:24, 186.38s/it, lr=0.001, test_MAE=0.785, time=185, train_MAE=0.649, train_loss=0.649, val_MAE=0.793, val_loss=0.793]Epoch 9:   1%|          | 9/1000 [28:05<51:18:24, 186.38s/it, lr=0.001, test_MAE=0.785, time=185, train_MAE=0.649, train_loss=0.649, val_MAE=0.793, val_loss=0.793]Epoch 9:   1%|          | 9/1000 [31:11<51:18:24, 186.38s/it, lr=0.001, test_MAE=1.18, time=186, train_MAE=0.633, train_loss=0.633, val_MAE=1.13, val_loss=1.13]   Epoch 9:   1%|          | 10/1000 [31:11<51:11:10, 186.13s/it, lr=0.001, test_MAE=1.18, time=186, train_MAE=0.633, train_loss=0.633, val_MAE=1.13, val_loss=1.13]Epoch 10:   1%|          | 10/1000 [31:11<51:11:10, 186.13s/it, lr=0.001, test_MAE=1.18, time=186, train_MAE=0.633, train_loss=0.633, val_MAE=1.13, val_loss=1.13]Epoch 10:   1%|          | 10/1000 [34:16<51:11:10, 186.13s/it, lr=0.001, test_MAE=0.77, time=186, train_MAE=0.624, train_loss=0.624, val_MAE=0.699, val_loss=0.699]Epoch 10:   1%|          | 11/1000 [34:16<51:05:15, 185.96s/it, lr=0.001, test_MAE=0.77, time=186, train_MAE=0.624, train_loss=0.624, val_MAE=0.699, val_loss=0.699]Epoch 11:   1%|          | 11/1000 [34:16<51:05:15, 185.96s/it, lr=0.001, test_MAE=0.77, time=186, train_MAE=0.624, train_loss=0.624, val_MAE=0.699, val_loss=0.699]Epoch 11:   1%|          | 11/1000 [37:21<51:05:15, 185.96s/it, lr=0.001, test_MAE=0.873, time=185, train_MAE=0.625, train_loss=0.625, val_MAE=0.772, val_loss=0.772]Epoch 11:   1%|          | 12/1000 [37:21<50:56:05, 185.59s/it, lr=0.001, test_MAE=0.873, time=185, train_MAE=0.625, train_loss=0.625, val_MAE=0.772, val_loss=0.772]Epoch 12:   1%|          | 12/1000 [37:21<50:56:05, 185.59s/it, lr=0.001, test_MAE=0.873, time=185, train_MAE=0.625, train_loss=0.625, val_MAE=0.772, val_loss=0.772]Epoch 12:   1%|          | 12/1000 [40:26<50:56:05, 185.59s/it, lr=0.001, test_MAE=0.749, time=186, train_MAE=0.634, train_loss=0.634, val_MAE=0.696, val_loss=0.696]Epoch 12:   1%|▏         | 13/1000 [40:26<50:52:51, 185.58s/it, lr=0.001, test_MAE=0.749, time=186, train_MAE=0.634, train_loss=0.634, val_MAE=0.696, val_loss=0.696]Epoch 13:   1%|▏         | 13/1000 [40:26<50:52:51, 185.58s/it, lr=0.001, test_MAE=0.749, time=186, train_MAE=0.634, train_loss=0.634, val_MAE=0.696, val_loss=0.696]Epoch 13:   1%|▏         | 13/1000 [43:32<50:52:51, 185.58s/it, lr=0.001, test_MAE=0.698, time=185, train_MAE=0.618, train_loss=0.618, val_MAE=0.666, val_loss=0.666]Epoch 13:   1%|▏         | 14/1000 [43:32<50:48:48, 185.53s/it, lr=0.001, test_MAE=0.698, time=185, train_MAE=0.618, train_loss=0.618, val_MAE=0.666, val_loss=0.666]Epoch 14:   1%|▏         | 14/1000 [43:32<50:48:48, 185.53s/it, lr=0.001, test_MAE=0.698, time=185, train_MAE=0.618, train_loss=0.618, val_MAE=0.666, val_loss=0.666]Epoch 14:   1%|▏         | 14/1000 [46:37<50:48:48, 185.53s/it, lr=0.001, test_MAE=0.731, time=185, train_MAE=0.606, train_loss=0.606, val_MAE=0.689, val_loss=0.689]Epoch 14:   2%|▏         | 15/1000 [46:37<50:43:05, 185.37s/it, lr=0.001, test_MAE=0.731, time=185, train_MAE=0.606, train_loss=0.606, val_MAE=0.689, val_loss=0.689]Epoch 15:   2%|▏         | 15/1000 [46:37<50:43:05, 185.37s/it, lr=0.001, test_MAE=0.731, time=185, train_MAE=0.606, train_loss=0.606, val_MAE=0.689, val_loss=0.689]Epoch 15:   2%|▏         | 15/1000 [49:42<50:43:05, 185.37s/it, lr=0.001, test_MAE=0.874, time=186, train_MAE=0.607, train_loss=0.607, val_MAE=0.838, val_loss=0.838]Epoch 15:   2%|▏         | 16/1000 [49:42<50:41:21, 185.45s/it, lr=0.001, test_MAE=0.874, time=186, train_MAE=0.607, train_loss=0.607, val_MAE=0.838, val_loss=0.838]Epoch 16:   2%|▏         | 16/1000 [49:42<50:41:21, 185.45s/it, lr=0.001, test_MAE=0.874, time=186, train_MAE=0.607, train_loss=0.607, val_MAE=0.838, val_loss=0.838]Epoch 16:   2%|▏         | 16/1000 [52:48<50:41:21, 185.45s/it, lr=0.001, test_MAE=0.721, time=185, train_MAE=0.619, train_loss=0.619, val_MAE=0.688, val_loss=0.688]Epoch 16:   2%|▏         | 17/1000 [52:48<50:38:01, 185.43s/it, lr=0.001, test_MAE=0.721, time=185, train_MAE=0.619, train_loss=0.619, val_MAE=0.688, val_loss=0.688]Epoch 17:   2%|▏         | 17/1000 [52:48<50:38:01, 185.43s/it, lr=0.001, test_MAE=0.721, time=185, train_MAE=0.619, train_loss=0.619, val_MAE=0.688, val_loss=0.688]Epoch 17:   2%|▏         | 17/1000 [55:53<50:38:01, 185.43s/it, lr=0.001, test_MAE=0.712, time=185, train_MAE=0.603, train_loss=0.603, val_MAE=0.702, val_loss=0.702]Epoch 17:   2%|▏         | 18/1000 [55:53<50:32:26, 185.28s/it, lr=0.001, test_MAE=0.712, time=185, train_MAE=0.603, train_loss=0.603, val_MAE=0.702, val_loss=0.702]Epoch 18:   2%|▏         | 18/1000 [55:53<50:32:26, 185.28s/it, lr=0.001, test_MAE=0.712, time=185, train_MAE=0.603, train_loss=0.603, val_MAE=0.702, val_loss=0.702]Epoch 18:   2%|▏         | 18/1000 [58:58<50:32:26, 185.28s/it, lr=0.001, test_MAE=0.783, time=185, train_MAE=0.616, train_loss=0.616, val_MAE=0.755, val_loss=0.755]Epoch 18:   2%|▏         | 19/1000 [58:58<50:30:27, 185.35s/it, lr=0.001, test_MAE=0.783, time=185, train_MAE=0.616, train_loss=0.616, val_MAE=0.755, val_loss=0.755]Epoch 19:   2%|▏         | 19/1000 [58:58<50:30:27, 185.35s/it, lr=0.001, test_MAE=0.783, time=185, train_MAE=0.616, train_loss=0.616, val_MAE=0.755, val_loss=0.755]Epoch 19:   2%|▏         | 19/1000 [1:02:04<50:30:27, 185.35s/it, lr=0.001, test_MAE=0.726, time=185, train_MAE=0.601, train_loss=0.601, val_MAE=0.689, val_loss=0.689]Epoch    20: reducing learning rate of group 0 to 5.0000e-04.
Epoch 19:   2%|▏         | 20/1000 [1:02:04<50:27:51, 185.38s/it, lr=0.001, test_MAE=0.726, time=185, train_MAE=0.601, train_loss=0.601, val_MAE=0.689, val_loss=0.689]Epoch 20:   2%|▏         | 20/1000 [1:02:04<50:27:51, 185.38s/it, lr=0.001, test_MAE=0.726, time=185, train_MAE=0.601, train_loss=0.601, val_MAE=0.689, val_loss=0.689]Epoch 20:   2%|▏         | 20/1000 [1:05:09<50:27:51, 185.38s/it, lr=0.0005, test_MAE=0.683, time=185, train_MAE=0.582, train_loss=0.582, val_MAE=0.653, val_loss=0.653]Epoch 20:   2%|▏         | 21/1000 [1:05:09<50:24:20, 185.35s/it, lr=0.0005, test_MAE=0.683, time=185, train_MAE=0.582, train_loss=0.582, val_MAE=0.653, val_loss=0.653]Epoch 21:   2%|▏         | 21/1000 [1:05:09<50:24:20, 185.35s/it, lr=0.0005, test_MAE=0.683, time=185, train_MAE=0.582, train_loss=0.582, val_MAE=0.653, val_loss=0.653]Epoch 21:   2%|▏         | 21/1000 [1:08:14<50:24:20, 185.35s/it, lr=0.0005, test_MAE=0.77, time=185, train_MAE=0.573, train_loss=0.573, val_MAE=0.729, val_loss=0.729] Epoch 21:   2%|▏         | 22/1000 [1:08:14<50:20:53, 185.33s/it, lr=0.0005, test_MAE=0.77, time=185, train_MAE=0.573, train_loss=0.573, val_MAE=0.729, val_loss=0.729]Epoch 22:   2%|▏         | 22/1000 [1:08:14<50:20:53, 185.33s/it, lr=0.0005, test_MAE=0.77, time=185, train_MAE=0.573, train_loss=0.573, val_MAE=0.729, val_loss=0.729]Epoch 22:   2%|▏         | 22/1000 [1:11:19<50:20:53, 185.33s/it, lr=0.0005, test_MAE=0.765, time=185, train_MAE=0.577, train_loss=0.577, val_MAE=0.711, val_loss=0.711]Epoch 22:   2%|▏         | 23/1000 [1:11:19<50:16:01, 185.22s/it, lr=0.0005, test_MAE=0.765, time=185, train_MAE=0.577, train_loss=0.577, val_MAE=0.711, val_loss=0.711]Epoch 23:   2%|▏         | 23/1000 [1:11:19<50:16:01, 185.22s/it, lr=0.0005, test_MAE=0.765, time=185, train_MAE=0.577, train_loss=0.577, val_MAE=0.711, val_loss=0.711]Epoch 23:   2%|▏         | 23/1000 [1:14:25<50:16:01, 185.22s/it, lr=0.0005, test_MAE=0.624, time=186, train_MAE=0.574, train_loss=0.574, val_MAE=0.587, val_loss=0.587]Epoch 23:   2%|▏         | 24/1000 [1:14:25<50:14:59, 185.35s/it, lr=0.0005, test_MAE=0.624, time=186, train_MAE=0.574, train_loss=0.574, val_MAE=0.587, val_loss=0.587]Epoch 24:   2%|▏         | 24/1000 [1:14:25<50:14:59, 185.35s/it, lr=0.0005, test_MAE=0.624, time=186, train_MAE=0.574, train_loss=0.574, val_MAE=0.587, val_loss=0.587]Epoch 24:   2%|▏         | 24/1000 [1:17:30<50:14:59, 185.35s/it, lr=0.0005, test_MAE=0.727, time=185, train_MAE=0.57, train_loss=0.57, val_MAE=0.689, val_loss=0.689]  Epoch 24:   2%|▎         | 25/1000 [1:17:30<50:11:37, 185.33s/it, lr=0.0005, test_MAE=0.727, time=185, train_MAE=0.57, train_loss=0.57, val_MAE=0.689, val_loss=0.689]Epoch 25:   2%|▎         | 25/1000 [1:17:30<50:11:37, 185.33s/it, lr=0.0005, test_MAE=0.727, time=185, train_MAE=0.57, train_loss=0.57, val_MAE=0.689, val_loss=0.689]Epoch 25:   2%|▎         | 25/1000 [1:20:35<50:11:37, 185.33s/it, lr=0.0005, test_MAE=0.624, time=185, train_MAE=0.57, train_loss=0.57, val_MAE=0.579, val_loss=0.579]Epoch 25:   3%|▎         | 26/1000 [1:20:35<50:07:53, 185.29s/it, lr=0.0005, test_MAE=0.624, time=185, train_MAE=0.57, train_loss=0.57, val_MAE=0.579, val_loss=0.579]Epoch 26:   3%|▎         | 26/1000 [1:20:35<50:07:53, 185.29s/it, lr=0.0005, test_MAE=0.624, time=185, train_MAE=0.57, train_loss=0.57, val_MAE=0.579, val_loss=0.579]Epoch 26:   3%|▎         | 26/1000 [1:23:41<50:07:53, 185.29s/it, lr=0.0005, test_MAE=0.701, time=186, train_MAE=0.575, train_loss=0.575, val_MAE=0.677, val_loss=0.677]Epoch 26:   3%|▎         | 27/1000 [1:23:41<50:06:22, 185.39s/it, lr=0.0005, test_MAE=0.701, time=186, train_MAE=0.575, train_loss=0.575, val_MAE=0.677, val_loss=0.677]Epoch 27:   3%|▎         | 27/1000 [1:23:41<50:06:22, 185.39s/it, lr=0.0005, test_MAE=0.701, time=186, train_MAE=0.575, train_loss=0.575, val_MAE=0.677, val_loss=0.677]Epoch 27:   3%|▎         | 27/1000 [1:26:46<50:06:22, 185.39s/it, lr=0.0005, test_MAE=0.638, time=185, train_MAE=0.567, train_loss=0.567, val_MAE=0.602, val_loss=0.602]Epoch 27:   3%|▎         | 28/1000 [1:26:46<50:01:44, 185.29s/it, lr=0.0005, test_MAE=0.638, time=185, train_MAE=0.567, train_loss=0.567, val_MAE=0.602, val_loss=0.602]Epoch 28:   3%|▎         | 28/1000 [1:26:46<50:01:44, 185.29s/it, lr=0.0005, test_MAE=0.638, time=185, train_MAE=0.567, train_loss=0.567, val_MAE=0.602, val_loss=0.602]Epoch 28:   3%|▎         | 28/1000 [1:29:51<50:01:44, 185.29s/it, lr=0.0005, test_MAE=1.52, time=185, train_MAE=0.561, train_loss=0.561, val_MAE=1.51, val_loss=1.51]   Epoch 28:   3%|▎         | 29/1000 [1:29:51<49:57:37, 185.23s/it, lr=0.0005, test_MAE=1.52, time=185, train_MAE=0.561, train_loss=0.561, val_MAE=1.51, val_loss=1.51]Epoch 29:   3%|▎         | 29/1000 [1:29:51<49:57:37, 185.23s/it, lr=0.0005, test_MAE=1.52, time=185, train_MAE=0.561, train_loss=0.561, val_MAE=1.51, val_loss=1.51]Epoch 29:   3%|▎         | 29/1000 [1:32:57<49:57:37, 185.23s/it, lr=0.0005, test_MAE=0.749, time=186, train_MAE=0.565, train_loss=0.565, val_MAE=0.706, val_loss=0.706]Epoch 29:   3%|▎         | 30/1000 [1:32:57<49:56:52, 185.37s/it, lr=0.0005, test_MAE=0.749, time=186, train_MAE=0.565, train_loss=0.565, val_MAE=0.706, val_loss=0.706]Epoch 30:   3%|▎         | 30/1000 [1:32:57<49:56:52, 185.37s/it, lr=0.0005, test_MAE=0.749, time=186, train_MAE=0.565, train_loss=0.565, val_MAE=0.706, val_loss=0.706]Epoch 30:   3%|▎         | 30/1000 [1:36:02<49:56:52, 185.37s/it, lr=0.0005, test_MAE=0.68, time=185, train_MAE=0.556, train_loss=0.556, val_MAE=0.655, val_loss=0.655] Epoch 30:   3%|▎         | 31/1000 [1:36:02<49:53:39, 185.37s/it, lr=0.0005, test_MAE=0.68, time=185, train_MAE=0.556, train_loss=0.556, val_MAE=0.655, val_loss=0.655]Epoch 31:   3%|▎         | 31/1000 [1:36:02<49:53:39, 185.37s/it, lr=0.0005, test_MAE=0.68, time=185, train_MAE=0.556, train_loss=0.556, val_MAE=0.655, val_loss=0.655]Epoch 31:   3%|▎         | 31/1000 [1:39:08<49:53:39, 185.37s/it, lr=0.0005, test_MAE=0.69, time=185, train_MAE=0.563, train_loss=0.563, val_MAE=0.663, val_loss=0.663]Epoch    32: reducing learning rate of group 0 to 2.5000e-04.
Epoch 31:   3%|▎         | 32/1000 [1:39:08<49:50:23, 185.36s/it, lr=0.0005, test_MAE=0.69, time=185, train_MAE=0.563, train_loss=0.563, val_MAE=0.663, val_loss=0.663]Epoch 32:   3%|▎         | 32/1000 [1:39:08<49:50:23, 185.36s/it, lr=0.0005, test_MAE=0.69, time=185, train_MAE=0.563, train_loss=0.563, val_MAE=0.663, val_loss=0.663]Epoch 32:   3%|▎         | 32/1000 [1:42:13<49:50:23, 185.36s/it, lr=0.00025, test_MAE=0.613, time=185, train_MAE=0.544, train_loss=0.544, val_MAE=0.571, val_loss=0.571]Epoch 32:   3%|▎         | 33/1000 [1:42:13<49:47:45, 185.38s/it, lr=0.00025, test_MAE=0.613, time=185, train_MAE=0.544, train_loss=0.544, val_MAE=0.571, val_loss=0.571]Epoch 33:   3%|▎         | 33/1000 [1:42:13<49:47:45, 185.38s/it, lr=0.00025, test_MAE=0.613, time=185, train_MAE=0.544, train_loss=0.544, val_MAE=0.571, val_loss=0.571]Epoch 33:   3%|▎         | 33/1000 [1:45:18<49:47:45, 185.38s/it, lr=0.00025, test_MAE=0.636, time=185, train_MAE=0.538, train_loss=0.538, val_MAE=0.601, val_loss=0.601]Epoch 33:   3%|▎         | 34/1000 [1:45:18<49:44:26, 185.37s/it, lr=0.00025, test_MAE=0.636, time=185, train_MAE=0.538, train_loss=0.538, val_MAE=0.601, val_loss=0.601]Epoch 34:   3%|▎         | 34/1000 [1:45:18<49:44:26, 185.37s/it, lr=0.00025, test_MAE=0.636, time=185, train_MAE=0.538, train_loss=0.538, val_MAE=0.601, val_loss=0.601]Epoch 34:   3%|▎         | 34/1000 [1:48:23<49:44:26, 185.37s/it, lr=0.00025, test_MAE=0.667, time=185, train_MAE=0.546, train_loss=0.546, val_MAE=0.629, val_loss=0.629]Epoch 34:   4%|▎         | 35/1000 [1:48:23<49:40:08, 185.29s/it, lr=0.00025, test_MAE=0.667, time=185, train_MAE=0.546, train_loss=0.546, val_MAE=0.629, val_loss=0.629]Epoch 35:   4%|▎         | 35/1000 [1:48:23<49:40:08, 185.29s/it, lr=0.00025, test_MAE=0.667, time=185, train_MAE=0.546, train_loss=0.546, val_MAE=0.629, val_loss=0.629]Epoch 35:   4%|▎         | 35/1000 [1:51:29<49:40:08, 185.29s/it, lr=0.00025, test_MAE=0.703, time=186, train_MAE=0.533, train_loss=0.533, val_MAE=0.661, val_loss=0.661]Epoch 35:   4%|▎         | 36/1000 [1:51:29<49:39:14, 185.43s/it, lr=0.00025, test_MAE=0.703, time=186, train_MAE=0.533, train_loss=0.533, val_MAE=0.661, val_loss=0.661]Epoch 36:   4%|▎         | 36/1000 [1:51:29<49:39:14, 185.43s/it, lr=0.00025, test_MAE=0.703, time=186, train_MAE=0.533, train_loss=0.533, val_MAE=0.661, val_loss=0.661]Epoch 36:   4%|▎         | 36/1000 [1:54:34<49:39:14, 185.43s/it, lr=0.00025, test_MAE=0.668, time=185, train_MAE=0.528, train_loss=0.528, val_MAE=0.628, val_loss=0.628]Epoch 36:   4%|▎         | 37/1000 [1:54:34<49:35:08, 185.37s/it, lr=0.00025, test_MAE=0.668, time=185, train_MAE=0.528, train_loss=0.528, val_MAE=0.628, val_loss=0.628]Epoch 37:   4%|▎         | 37/1000 [1:54:34<49:35:08, 185.37s/it, lr=0.00025, test_MAE=0.668, time=185, train_MAE=0.528, train_loss=0.528, val_MAE=0.628, val_loss=0.628]Epoch 37:   4%|▎         | 37/1000 [1:57:40<49:35:08, 185.37s/it, lr=0.00025, test_MAE=0.822, time=185, train_MAE=0.527, train_loss=0.527, val_MAE=0.703, val_loss=0.703]Epoch 37:   4%|▍         | 38/1000 [1:57:40<49:30:54, 185.30s/it, lr=0.00025, test_MAE=0.822, time=185, train_MAE=0.527, train_loss=0.527, val_MAE=0.703, val_loss=0.703]Epoch 38:   4%|▍         | 38/1000 [1:57:40<49:30:54, 185.30s/it, lr=0.00025, test_MAE=0.822, time=185, train_MAE=0.527, train_loss=0.527, val_MAE=0.703, val_loss=0.703]Epoch 38:   4%|▍         | 38/1000 [2:00:45<49:30:54, 185.30s/it, lr=0.00025, test_MAE=0.655, time=186, train_MAE=0.532, train_loss=0.532, val_MAE=0.625, val_loss=0.625]Epoch    39: reducing learning rate of group 0 to 1.2500e-04.
Epoch 38:   4%|▍         | 39/1000 [2:00:45<49:29:46, 185.42s/it, lr=0.00025, test_MAE=0.655, time=186, train_MAE=0.532, train_loss=0.532, val_MAE=0.625, val_loss=0.625]Epoch 39:   4%|▍         | 39/1000 [2:00:45<49:29:46, 185.42s/it, lr=0.00025, test_MAE=0.655, time=186, train_MAE=0.532, train_loss=0.532, val_MAE=0.625, val_loss=0.625]Epoch 39:   4%|▍         | 39/1000 [2:03:51<49:29:46, 185.42s/it, lr=0.000125, test_MAE=0.614, time=185, train_MAE=0.515, train_loss=0.515, val_MAE=0.574, val_loss=0.574]Epoch 39:   4%|▍         | 40/1000 [2:03:51<49:26:19, 185.39s/it, lr=0.000125, test_MAE=0.614, time=185, train_MAE=0.515, train_loss=0.515, val_MAE=0.574, val_loss=0.574]Epoch 40:   4%|▍         | 40/1000 [2:03:51<49:26:19, 185.39s/it, lr=0.000125, test_MAE=0.614, time=185, train_MAE=0.515, train_loss=0.515, val_MAE=0.574, val_loss=0.574]Epoch 40:   4%|▍         | 40/1000 [2:06:56<49:26:19, 185.39s/it, lr=0.000125, test_MAE=0.618, time=185, train_MAE=0.507, train_loss=0.507, val_MAE=0.585, val_loss=0.585]Epoch 40:   4%|▍         | 41/1000 [2:06:56<49:23:48, 185.43s/it, lr=0.000125, test_MAE=0.618, time=185, train_MAE=0.507, train_loss=0.507, val_MAE=0.585, val_loss=0.585]Epoch 41:   4%|▍         | 41/1000 [2:06:56<49:23:48, 185.43s/it, lr=0.000125, test_MAE=0.618, time=185, train_MAE=0.507, train_loss=0.507, val_MAE=0.585, val_loss=0.585]Epoch 41:   4%|▍         | 41/1000 [2:10:02<49:23:48, 185.43s/it, lr=0.000125, test_MAE=0.627, time=186, train_MAE=0.506, train_loss=0.506, val_MAE=0.576, val_loss=0.576]Epoch 41:   4%|▍         | 42/1000 [2:10:02<49:22:05, 185.52s/it, lr=0.000125, test_MAE=0.627, time=186, train_MAE=0.506, train_loss=0.506, val_MAE=0.576, val_loss=0.576]Epoch 42:   4%|▍         | 42/1000 [2:10:02<49:22:05, 185.52s/it, lr=0.000125, test_MAE=0.627, time=186, train_MAE=0.506, train_loss=0.506, val_MAE=0.576, val_loss=0.576]Epoch 42:   4%|▍         | 42/1000 [2:13:07<49:22:05, 185.52s/it, lr=0.000125, test_MAE=0.613, time=185, train_MAE=0.517, train_loss=0.517, val_MAE=0.599, val_loss=0.599]Epoch 42:   4%|▍         | 43/1000 [2:13:07<49:16:13, 185.34s/it, lr=0.000125, test_MAE=0.613, time=185, train_MAE=0.517, train_loss=0.517, val_MAE=0.599, val_loss=0.599]Epoch 43:   4%|▍         | 43/1000 [2:13:07<49:16:13, 185.34s/it, lr=0.000125, test_MAE=0.613, time=185, train_MAE=0.517, train_loss=0.517, val_MAE=0.599, val_loss=0.599]Epoch 43:   4%|▍         | 43/1000 [2:16:12<49:16:13, 185.34s/it, lr=0.000125, test_MAE=0.6, time=186, train_MAE=0.501, train_loss=0.501, val_MAE=0.568, val_loss=0.568]  Epoch 43:   4%|▍         | 44/1000 [2:16:12<49:14:10, 185.41s/it, lr=0.000125, test_MAE=0.6, time=186, train_MAE=0.501, train_loss=0.501, val_MAE=0.568, val_loss=0.568]Epoch 44:   4%|▍         | 44/1000 [2:16:12<49:14:10, 185.41s/it, lr=0.000125, test_MAE=0.6, time=186, train_MAE=0.501, train_loss=0.501, val_MAE=0.568, val_loss=0.568]Epoch 44:   4%|▍         | 44/1000 [2:19:17<49:14:10, 185.41s/it, lr=0.000125, test_MAE=0.607, time=185, train_MAE=0.506, train_loss=0.506, val_MAE=0.575, val_loss=0.575]Epoch 44:   4%|▍         | 45/1000 [2:19:17<49:09:46, 185.33s/it, lr=0.000125, test_MAE=0.607, time=185, train_MAE=0.506, train_loss=0.506, val_MAE=0.575, val_loss=0.575]Epoch 45:   4%|▍         | 45/1000 [2:19:17<49:09:46, 185.33s/it, lr=0.000125, test_MAE=0.607, time=185, train_MAE=0.506, train_loss=0.506, val_MAE=0.575, val_loss=0.575]Epoch 45:   4%|▍         | 45/1000 [2:22:24<49:09:46, 185.33s/it, lr=0.000125, test_MAE=0.598, time=186, train_MAE=0.502, train_loss=0.502, val_MAE=0.562, val_loss=0.562]Epoch 45:   5%|▍         | 46/1000 [2:22:24<49:10:35, 185.57s/it, lr=0.000125, test_MAE=0.598, time=186, train_MAE=0.502, train_loss=0.502, val_MAE=0.562, val_loss=0.562]Epoch 46:   5%|▍         | 46/1000 [2:22:24<49:10:35, 185.57s/it, lr=0.000125, test_MAE=0.598, time=186, train_MAE=0.502, train_loss=0.502, val_MAE=0.562, val_loss=0.562]Epoch 46:   5%|▍         | 46/1000 [2:25:30<49:10:35, 185.57s/it, lr=0.000125, test_MAE=0.691, time=186, train_MAE=0.506, train_loss=0.506, val_MAE=0.654, val_loss=0.654]Epoch 46:   5%|▍         | 47/1000 [2:25:30<49:09:50, 185.72s/it, lr=0.000125, test_MAE=0.691, time=186, train_MAE=0.506, train_loss=0.506, val_MAE=0.654, val_loss=0.654]Epoch 47:   5%|▍         | 47/1000 [2:25:30<49:09:50, 185.72s/it, lr=0.000125, test_MAE=0.691, time=186, train_MAE=0.506, train_loss=0.506, val_MAE=0.654, val_loss=0.654]Epoch 47:   5%|▍         | 47/1000 [2:28:35<49:09:50, 185.72s/it, lr=0.000125, test_MAE=0.62, time=185, train_MAE=0.505, train_loss=0.505, val_MAE=0.577, val_loss=0.577] Epoch 47:   5%|▍         | 48/1000 [2:28:35<49:05:47, 185.66s/it, lr=0.000125, test_MAE=0.62, time=185, train_MAE=0.505, train_loss=0.505, val_MAE=0.577, val_loss=0.577]Epoch 48:   5%|▍         | 48/1000 [2:28:35<49:05:47, 185.66s/it, lr=0.000125, test_MAE=0.62, time=185, train_MAE=0.505, train_loss=0.505, val_MAE=0.577, val_loss=0.577]Epoch 48:   5%|▍         | 48/1000 [2:31:40<49:05:47, 185.66s/it, lr=0.000125, test_MAE=0.616, time=185, train_MAE=0.508, train_loss=0.508, val_MAE=0.567, val_loss=0.567]Epoch 48:   5%|▍         | 49/1000 [2:31:40<49:00:52, 185.54s/it, lr=0.000125, test_MAE=0.616, time=185, train_MAE=0.508, train_loss=0.508, val_MAE=0.567, val_loss=0.567]Epoch 49:   5%|▍         | 49/1000 [2:31:40<49:00:52, 185.54s/it, lr=0.000125, test_MAE=0.616, time=185, train_MAE=0.508, train_loss=0.508, val_MAE=0.567, val_loss=0.567]Epoch 49:   5%|▍         | 49/1000 [2:34:46<49:00:52, 185.54s/it, lr=0.000125, test_MAE=0.757, time=186, train_MAE=0.508, train_loss=0.508, val_MAE=0.654, val_loss=0.654]Epoch 49:   5%|▌         | 50/1000 [2:34:46<48:58:37, 185.60s/it, lr=0.000125, test_MAE=0.757, time=186, train_MAE=0.508, train_loss=0.508, val_MAE=0.654, val_loss=0.654]Epoch 50:   5%|▌         | 50/1000 [2:34:46<48:58:37, 185.60s/it, lr=0.000125, test_MAE=0.757, time=186, train_MAE=0.508, train_loss=0.508, val_MAE=0.654, val_loss=0.654]Epoch 50:   5%|▌         | 50/1000 [2:37:52<48:58:37, 185.60s/it, lr=0.000125, test_MAE=0.658, time=186, train_MAE=0.497, train_loss=0.497, val_MAE=0.609, val_loss=0.609]Epoch 50:   5%|▌         | 51/1000 [2:37:52<48:55:33, 185.60s/it, lr=0.000125, test_MAE=0.658, time=186, train_MAE=0.497, train_loss=0.497, val_MAE=0.609, val_loss=0.609]Epoch 51:   5%|▌         | 51/1000 [2:37:52<48:55:33, 185.60s/it, lr=0.000125, test_MAE=0.658, time=186, train_MAE=0.497, train_loss=0.497, val_MAE=0.609, val_loss=0.609]Epoch 51:   5%|▌         | 51/1000 [2:40:57<48:55:33, 185.60s/it, lr=0.000125, test_MAE=0.636, time=185, train_MAE=0.501, train_loss=0.501, val_MAE=0.575, val_loss=0.575]Epoch    52: reducing learning rate of group 0 to 6.2500e-05.
Epoch 51:   5%|▌         | 52/1000 [2:40:57<48:49:56, 185.44s/it, lr=0.000125, test_MAE=0.636, time=185, train_MAE=0.501, train_loss=0.501, val_MAE=0.575, val_loss=0.575]Epoch 52:   5%|▌         | 52/1000 [2:40:57<48:49:56, 185.44s/it, lr=0.000125, test_MAE=0.636, time=185, train_MAE=0.501, train_loss=0.501, val_MAE=0.575, val_loss=0.575]Epoch 52:   5%|▌         | 52/1000 [2:44:03<48:49:56, 185.44s/it, lr=6.25e-5, test_MAE=0.597, time=186, train_MAE=0.497, train_loss=0.497, val_MAE=0.554, val_loss=0.554] Epoch 52:   5%|▌         | 53/1000 [2:44:03<48:49:25, 185.60s/it, lr=6.25e-5, test_MAE=0.597, time=186, train_MAE=0.497, train_loss=0.497, val_MAE=0.554, val_loss=0.554]Epoch 53:   5%|▌         | 53/1000 [2:44:03<48:49:25, 185.60s/it, lr=6.25e-5, test_MAE=0.597, time=186, train_MAE=0.497, train_loss=0.497, val_MAE=0.554, val_loss=0.554]Epoch 53:   5%|▌         | 53/1000 [2:47:09<48:49:25, 185.60s/it, lr=6.25e-5, test_MAE=0.611, time=186, train_MAE=0.483, train_loss=0.483, val_MAE=0.574, val_loss=0.574]Epoch 53:   5%|▌         | 54/1000 [2:47:09<48:48:12, 185.72s/it, lr=6.25e-5, test_MAE=0.611, time=186, train_MAE=0.483, train_loss=0.483, val_MAE=0.574, val_loss=0.574]Epoch 54:   5%|▌         | 54/1000 [2:47:09<48:48:12, 185.72s/it, lr=6.25e-5, test_MAE=0.611, time=186, train_MAE=0.483, train_loss=0.483, val_MAE=0.574, val_loss=0.574]Epoch 54:   5%|▌         | 54/1000 [2:50:14<48:48:12, 185.72s/it, lr=6.25e-5, test_MAE=0.625, time=185, train_MAE=0.471, train_loss=0.471, val_MAE=0.575, val_loss=0.575]Epoch 54:   6%|▌         | 55/1000 [2:50:14<48:42:56, 185.58s/it, lr=6.25e-5, test_MAE=0.625, time=185, train_MAE=0.471, train_loss=0.471, val_MAE=0.575, val_loss=0.575]Epoch 55:   6%|▌         | 55/1000 [2:50:14<48:42:56, 185.58s/it, lr=6.25e-5, test_MAE=0.625, time=185, train_MAE=0.471, train_loss=0.471, val_MAE=0.575, val_loss=0.575]Epoch 55:   6%|▌         | 55/1000 [2:53:20<48:42:56, 185.58s/it, lr=6.25e-5, test_MAE=0.589, time=186, train_MAE=0.475, train_loss=0.475, val_MAE=0.55, val_loss=0.55]  Epoch 55:   6%|▌         | 56/1000 [2:53:20<48:40:23, 185.62s/it, lr=6.25e-5, test_MAE=0.589, time=186, train_MAE=0.475, train_loss=0.475, val_MAE=0.55, val_loss=0.55]Epoch 56:   6%|▌         | 56/1000 [2:53:20<48:40:23, 185.62s/it, lr=6.25e-5, test_MAE=0.589, time=186, train_MAE=0.475, train_loss=0.475, val_MAE=0.55, val_loss=0.55]Epoch 56:   6%|▌         | 56/1000 [2:56:24<48:40:23, 185.62s/it, lr=6.25e-5, test_MAE=0.616, time=184, train_MAE=0.473, train_loss=0.473, val_MAE=0.578, val_loss=0.578]Epoch 56:   6%|▌         | 57/1000 [2:56:24<48:29:35, 185.13s/it, lr=6.25e-5, test_MAE=0.616, time=184, train_MAE=0.473, train_loss=0.473, val_MAE=0.578, val_loss=0.578]Epoch 57:   6%|▌         | 57/1000 [2:56:24<48:29:35, 185.13s/it, lr=6.25e-5, test_MAE=0.616, time=184, train_MAE=0.473, train_loss=0.473, val_MAE=0.578, val_loss=0.578]Epoch 57:   6%|▌         | 57/1000 [2:59:23<48:29:35, 185.13s/it, lr=6.25e-5, test_MAE=0.613, time=179, train_MAE=0.475, train_loss=0.475, val_MAE=0.579, val_loss=0.579]Epoch 57:   6%|▌         | 58/1000 [2:59:23<47:58:41, 183.36s/it, lr=6.25e-5, test_MAE=0.613, time=179, train_MAE=0.475, train_loss=0.475, val_MAE=0.579, val_loss=0.579]Epoch 58:   6%|▌         | 58/1000 [2:59:23<47:58:41, 183.36s/it, lr=6.25e-5, test_MAE=0.613, time=179, train_MAE=0.475, train_loss=0.475, val_MAE=0.579, val_loss=0.579]Epoch 58:   6%|▌         | 58/1000 [3:02:22<47:58:41, 183.36s/it, lr=6.25e-5, test_MAE=0.605, time=179, train_MAE=0.477, train_loss=0.477, val_MAE=0.552, val_loss=0.552]Epoch 58:   6%|▌         | 59/1000 [3:02:22<47:35:02, 182.04s/it, lr=6.25e-5, test_MAE=0.605, time=179, train_MAE=0.477, train_loss=0.477, val_MAE=0.552, val_loss=0.552]Epoch 59:   6%|▌         | 59/1000 [3:02:22<47:35:02, 182.04s/it, lr=6.25e-5, test_MAE=0.605, time=179, train_MAE=0.477, train_loss=0.477, val_MAE=0.552, val_loss=0.552]Epoch 59:   6%|▌         | 59/1000 [3:05:22<47:35:02, 182.04s/it, lr=6.25e-5, test_MAE=0.608, time=180, train_MAE=0.468, train_loss=0.468, val_MAE=0.569, val_loss=0.569]Epoch 59:   6%|▌         | 60/1000 [3:05:22<47:20:10, 181.29s/it, lr=6.25e-5, test_MAE=0.608, time=180, train_MAE=0.468, train_loss=0.468, val_MAE=0.569, val_loss=0.569]Epoch 60:   6%|▌         | 60/1000 [3:05:22<47:20:10, 181.29s/it, lr=6.25e-5, test_MAE=0.608, time=180, train_MAE=0.468, train_loss=0.468, val_MAE=0.569, val_loss=0.569]Epoch 60:   6%|▌         | 60/1000 [3:08:20<47:20:10, 181.29s/it, lr=6.25e-5, test_MAE=0.661, time=178, train_MAE=0.47, train_loss=0.47, val_MAE=0.625, val_loss=0.625]  Epoch 60:   6%|▌         | 61/1000 [3:08:20<47:02:38, 180.36s/it, lr=6.25e-5, test_MAE=0.661, time=178, train_MAE=0.47, train_loss=0.47, val_MAE=0.625, val_loss=0.625]Epoch 61:   6%|▌         | 61/1000 [3:08:20<47:02:38, 180.36s/it, lr=6.25e-5, test_MAE=0.661, time=178, train_MAE=0.47, train_loss=0.47, val_MAE=0.625, val_loss=0.625]Epoch 61:   6%|▌         | 61/1000 [3:11:18<47:02:38, 180.36s/it, lr=6.25e-5, test_MAE=0.665, time=178, train_MAE=0.473, train_loss=0.473, val_MAE=0.609, val_loss=0.609]Epoch    62: reducing learning rate of group 0 to 3.1250e-05.
Epoch 61:   6%|▌         | 62/1000 [3:11:18<46:48:56, 179.68s/it, lr=6.25e-5, test_MAE=0.665, time=178, train_MAE=0.473, train_loss=0.473, val_MAE=0.609, val_loss=0.609]Epoch 62:   6%|▌         | 62/1000 [3:11:18<46:48:56, 179.68s/it, lr=6.25e-5, test_MAE=0.665, time=178, train_MAE=0.473, train_loss=0.473, val_MAE=0.609, val_loss=0.609]Epoch 62:   6%|▌         | 62/1000 [3:14:15<46:48:56, 179.68s/it, lr=3.13e-5, test_MAE=0.606, time=177, train_MAE=0.469, train_loss=0.469, val_MAE=0.566, val_loss=0.566]Epoch 62:   6%|▋         | 63/1000 [3:14:15<46:34:42, 178.96s/it, lr=3.13e-5, test_MAE=0.606, time=177, train_MAE=0.469, train_loss=0.469, val_MAE=0.566, val_loss=0.566]Epoch 63:   6%|▋         | 63/1000 [3:14:15<46:34:42, 178.96s/it, lr=3.13e-5, test_MAE=0.606, time=177, train_MAE=0.469, train_loss=0.469, val_MAE=0.566, val_loss=0.566]Epoch 63:   6%|▋         | 63/1000 [3:17:13<46:34:42, 178.96s/it, lr=3.13e-5, test_MAE=0.6, time=177, train_MAE=0.458, train_loss=0.458, val_MAE=0.55, val_loss=0.55]    Epoch 63:   6%|▋         | 64/1000 [3:17:13<46:24:47, 178.51s/it, lr=3.13e-5, test_MAE=0.6, time=177, train_MAE=0.458, train_loss=0.458, val_MAE=0.55, val_loss=0.55]Epoch 64:   6%|▋         | 64/1000 [3:17:13<46:24:47, 178.51s/it, lr=3.13e-5, test_MAE=0.6, time=177, train_MAE=0.458, train_loss=0.458, val_MAE=0.55, val_loss=0.55]Epoch 64:   6%|▋         | 64/1000 [3:20:10<46:24:47, 178.51s/it, lr=3.13e-5, test_MAE=0.601, time=177, train_MAE=0.455, train_loss=0.455, val_MAE=0.551, val_loss=0.551]Epoch 64:   6%|▋         | 65/1000 [3:20:10<46:16:23, 178.16s/it, lr=3.13e-5, test_MAE=0.601, time=177, train_MAE=0.455, train_loss=0.455, val_MAE=0.551, val_loss=0.551]Epoch 65:   6%|▋         | 65/1000 [3:20:10<46:16:23, 178.16s/it, lr=3.13e-5, test_MAE=0.601, time=177, train_MAE=0.455, train_loss=0.455, val_MAE=0.551, val_loss=0.551]Epoch 65:   6%|▋         | 65/1000 [3:23:07<46:16:23, 178.16s/it, lr=3.13e-5, test_MAE=0.61, time=177, train_MAE=0.454, train_loss=0.454, val_MAE=0.557, val_loss=0.557] Epoch 65:   7%|▋         | 66/1000 [3:23:07<46:10:14, 177.96s/it, lr=3.13e-5, test_MAE=0.61, time=177, train_MAE=0.454, train_loss=0.454, val_MAE=0.557, val_loss=0.557]Epoch 66:   7%|▋         | 66/1000 [3:23:07<46:10:14, 177.96s/it, lr=3.13e-5, test_MAE=0.61, time=177, train_MAE=0.454, train_loss=0.454, val_MAE=0.557, val_loss=0.557]Epoch 66:   7%|▋         | 66/1000 [3:26:05<46:10:14, 177.96s/it, lr=3.13e-5, test_MAE=0.604, time=177, train_MAE=0.46, train_loss=0.46, val_MAE=0.558, val_loss=0.558] Epoch 66:   7%|▋         | 67/1000 [3:26:05<46:03:50, 177.74s/it, lr=3.13e-5, test_MAE=0.604, time=177, train_MAE=0.46, train_loss=0.46, val_MAE=0.558, val_loss=0.558]Epoch 67:   7%|▋         | 67/1000 [3:26:05<46:03:50, 177.74s/it, lr=3.13e-5, test_MAE=0.604, time=177, train_MAE=0.46, train_loss=0.46, val_MAE=0.558, val_loss=0.558]Epoch 67:   7%|▋         | 67/1000 [3:29:02<46:03:50, 177.74s/it, lr=3.13e-5, test_MAE=0.627, time=178, train_MAE=0.455, train_loss=0.455, val_MAE=0.589, val_loss=0.589]Epoch    68: reducing learning rate of group 0 to 1.5625e-05.
Epoch 67:   7%|▋         | 68/1000 [3:29:02<46:00:26, 177.71s/it, lr=3.13e-5, test_MAE=0.627, time=178, train_MAE=0.455, train_loss=0.455, val_MAE=0.589, val_loss=0.589]Epoch 68:   7%|▋         | 68/1000 [3:29:02<46:00:26, 177.71s/it, lr=3.13e-5, test_MAE=0.627, time=178, train_MAE=0.455, train_loss=0.455, val_MAE=0.589, val_loss=0.589]Epoch 68:   7%|▋         | 68/1000 [3:32:00<46:00:26, 177.71s/it, lr=1.56e-5, test_MAE=0.605, time=178, train_MAE=0.444, train_loss=0.444, val_MAE=0.557, val_loss=0.557]Epoch 68:   7%|▋         | 69/1000 [3:32:00<45:59:00, 177.81s/it, lr=1.56e-5, test_MAE=0.605, time=178, train_MAE=0.444, train_loss=0.444, val_MAE=0.557, val_loss=0.557]Epoch 69:   7%|▋         | 69/1000 [3:32:00<45:59:00, 177.81s/it, lr=1.56e-5, test_MAE=0.605, time=178, train_MAE=0.444, train_loss=0.444, val_MAE=0.557, val_loss=0.557]Epoch 69:   7%|▋         | 69/1000 [3:34:59<45:59:00, 177.81s/it, lr=1.56e-5, test_MAE=0.599, time=179, train_MAE=0.439, train_loss=0.439, val_MAE=0.551, val_loss=0.551]Epoch 69:   7%|▋         | 70/1000 [3:34:59<46:00:51, 178.12s/it, lr=1.56e-5, test_MAE=0.599, time=179, train_MAE=0.439, train_loss=0.439, val_MAE=0.551, val_loss=0.551]Epoch 70:   7%|▋         | 70/1000 [3:34:59<46:00:51, 178.12s/it, lr=1.56e-5, test_MAE=0.599, time=179, train_MAE=0.439, train_loss=0.439, val_MAE=0.551, val_loss=0.551]Epoch 70:   7%|▋         | 70/1000 [3:37:57<46:00:51, 178.12s/it, lr=1.56e-5, test_MAE=0.605, time=178, train_MAE=0.433, train_loss=0.433, val_MAE=0.555, val_loss=0.555]Epoch 70:   7%|▋         | 71/1000 [3:37:57<45:55:54, 177.99s/it, lr=1.56e-5, test_MAE=0.605, time=178, train_MAE=0.433, train_loss=0.433, val_MAE=0.555, val_loss=0.555]Epoch 71:   7%|▋         | 71/1000 [3:37:57<45:55:54, 177.99s/it, lr=1.56e-5, test_MAE=0.605, time=178, train_MAE=0.433, train_loss=0.433, val_MAE=0.555, val_loss=0.555]Epoch 71:   7%|▋         | 71/1000 [3:40:54<45:55:54, 177.99s/it, lr=1.56e-5, test_MAE=0.606, time=177, train_MAE=0.451, train_loss=0.451, val_MAE=0.561, val_loss=0.561]Epoch 71:   7%|▋         | 72/1000 [3:40:54<45:50:31, 177.84s/it, lr=1.56e-5, test_MAE=0.606, time=177, train_MAE=0.451, train_loss=0.451, val_MAE=0.561, val_loss=0.561]Epoch 72:   7%|▋         | 72/1000 [3:40:54<45:50:31, 177.84s/it, lr=1.56e-5, test_MAE=0.606, time=177, train_MAE=0.451, train_loss=0.451, val_MAE=0.561, val_loss=0.561]Epoch 72:   7%|▋         | 72/1000 [3:43:52<45:50:31, 177.84s/it, lr=1.56e-5, test_MAE=0.597, time=178, train_MAE=0.439, train_loss=0.439, val_MAE=0.552, val_loss=0.552]Epoch 72:   7%|▋         | 73/1000 [3:43:52<45:48:10, 177.88s/it, lr=1.56e-5, test_MAE=0.597, time=178, train_MAE=0.439, train_loss=0.439, val_MAE=0.552, val_loss=0.552]Epoch 73:   7%|▋         | 73/1000 [3:43:52<45:48:10, 177.88s/it, lr=1.56e-5, test_MAE=0.597, time=178, train_MAE=0.439, train_loss=0.439, val_MAE=0.552, val_loss=0.552]Epoch 73:   7%|▋         | 73/1000 [3:46:51<45:48:10, 177.88s/it, lr=1.56e-5, test_MAE=0.605, time=179, train_MAE=0.437, train_loss=0.437, val_MAE=0.558, val_loss=0.558]Epoch    74: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 73:   7%|▋         | 73/1000 [3:46:51<48:00:45, 186.46s/it, lr=1.56e-5, test_MAE=0.605, time=179, train_MAE=0.437, train_loss=0.437, val_MAE=0.558, val_loss=0.558]
Test MAE: 0.6054
Train MAE: 0.4189
Convergence Time (Epochs): 73.0000
TOTAL TIME TAKEN: 13688.0084s
AVG TIME PER EPOCH: 183.9164s
