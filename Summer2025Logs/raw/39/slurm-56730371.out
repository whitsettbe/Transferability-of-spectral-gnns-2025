I'm echoing to stdout
I'm echoing to stderr
My JobID is 56730371
I have 8 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.0458s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 2, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'cheb02_vec', 'normalized_laplacian': True, 'post_normalized': False, 'eigval_norm': '', 'num_eigs': 64, 'bias_mode': 'spatial', 'eigval_hidden_dim': 5, 'eigval_num_hidden_layer': 3, 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 0.0, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/zinc_train_rec_full.csv', 'test': 'supp_data/molecules/zinc_test_rec_full.csv', 'val': 'supp_data/molecules/zinc_val_rec_full.csv'}, 'fixMissingPhi1': False, 'extraOrtho': True, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [03:13<?, ?it/s, lr=0.001, test_MAE=0.85, time=194, train_MAE=0.831, train_loss=0.831, val_MAE=0.813, val_loss=0.813]Epoch 0:   0%|          | 1/1000 [03:13<53:42:52, 193.57s/it, lr=0.001, test_MAE=0.85, time=194, train_MAE=0.831, train_loss=0.831, val_MAE=0.813, val_loss=0.813]Epoch 1:   0%|          | 1/1000 [03:13<53:42:52, 193.57s/it, lr=0.001, test_MAE=0.85, time=194, train_MAE=0.831, train_loss=0.831, val_MAE=0.813, val_loss=0.813]Epoch 1:   0%|          | 1/1000 [04:01<53:42:52, 193.57s/it, lr=0.001, test_MAE=1.16, time=48.3, train_MAE=0.713, train_loss=0.713, val_MAE=1.15, val_loss=1.15] Epoch 1:   0%|          | 2/1000 [04:01<41:34:53, 149.99s/it, lr=0.001, test_MAE=1.16, time=48.3, train_MAE=0.713, train_loss=0.713, val_MAE=1.15, val_loss=1.15]Epoch 2:   0%|          | 2/1000 [04:01<41:34:53, 149.99s/it, lr=0.001, test_MAE=1.16, time=48.3, train_MAE=0.713, train_loss=0.713, val_MAE=1.15, val_loss=1.15]Epoch 2:   0%|          | 2/1000 [04:50<41:34:53, 149.99s/it, lr=0.001, test_MAE=0.732, time=49, train_MAE=0.692, train_loss=0.692, val_MAE=0.689, val_loss=0.689]Epoch 2:   0%|          | 3/1000 [04:50<33:08:55, 119.69s/it, lr=0.001, test_MAE=0.732, time=49, train_MAE=0.692, train_loss=0.692, val_MAE=0.689, val_loss=0.689]Epoch 3:   0%|          | 3/1000 [04:50<33:08:55, 119.69s/it, lr=0.001, test_MAE=0.732, time=49, train_MAE=0.692, train_loss=0.692, val_MAE=0.689, val_loss=0.689]Epoch 3:   0%|          | 3/1000 [05:39<33:08:55, 119.69s/it, lr=0.001, test_MAE=0.945, time=48.9, train_MAE=0.702, train_loss=0.702, val_MAE=0.899, val_loss=0.899]Epoch 3:   0%|          | 4/1000 [05:39<27:14:35, 98.47s/it, lr=0.001, test_MAE=0.945, time=48.9, train_MAE=0.702, train_loss=0.702, val_MAE=0.899, val_loss=0.899] Epoch 4:   0%|          | 4/1000 [05:39<27:14:35, 98.47s/it, lr=0.001, test_MAE=0.945, time=48.9, train_MAE=0.702, train_loss=0.702, val_MAE=0.899, val_loss=0.899]Epoch 4:   0%|          | 4/1000 [06:28<27:14:35, 98.47s/it, lr=0.001, test_MAE=0.916, time=48.7, train_MAE=0.679, train_loss=0.679, val_MAE=0.855, val_loss=0.855]Epoch 4:   0%|          | 5/1000 [06:28<23:05:13, 83.53s/it, lr=0.001, test_MAE=0.916, time=48.7, train_MAE=0.679, train_loss=0.679, val_MAE=0.855, val_loss=0.855]Epoch 5:   0%|          | 5/1000 [06:28<23:05:13, 83.53s/it, lr=0.001, test_MAE=0.916, time=48.7, train_MAE=0.679, train_loss=0.679, val_MAE=0.855, val_loss=0.855]Epoch 5:   0%|          | 5/1000 [07:16<23:05:13, 83.53s/it, lr=0.001, test_MAE=0.857, time=48.4, train_MAE=0.669, train_loss=0.669, val_MAE=0.778, val_loss=0.778]Epoch 5:   1%|          | 6/1000 [07:16<20:09:05, 72.98s/it, lr=0.001, test_MAE=0.857, time=48.4, train_MAE=0.669, train_loss=0.669, val_MAE=0.778, val_loss=0.778]Epoch 6:   1%|          | 6/1000 [07:16<20:09:05, 72.98s/it, lr=0.001, test_MAE=0.857, time=48.4, train_MAE=0.669, train_loss=0.669, val_MAE=0.778, val_loss=0.778]Epoch 6:   1%|          | 6/1000 [08:06<20:09:05, 72.98s/it, lr=0.001, test_MAE=0.725, time=49.2, train_MAE=0.665, train_loss=0.665, val_MAE=0.667, val_loss=0.667]Epoch 6:   1%|          | 7/1000 [08:06<18:09:54, 65.86s/it, lr=0.001, test_MAE=0.725, time=49.2, train_MAE=0.665, train_loss=0.665, val_MAE=0.667, val_loss=0.667]Epoch 7:   1%|          | 7/1000 [08:06<18:09:54, 65.86s/it, lr=0.001, test_MAE=0.725, time=49.2, train_MAE=0.665, train_loss=0.665, val_MAE=0.667, val_loss=0.667]Epoch 7:   1%|          | 7/1000 [08:54<18:09:54, 65.86s/it, lr=0.001, test_MAE=0.899, time=48.6, train_MAE=0.654, train_loss=0.654, val_MAE=0.866, val_loss=0.866]Epoch 7:   1%|          | 8/1000 [08:54<16:43:25, 60.69s/it, lr=0.001, test_MAE=0.899, time=48.6, train_MAE=0.654, train_loss=0.654, val_MAE=0.866, val_loss=0.866]Epoch 8:   1%|          | 8/1000 [08:54<16:43:25, 60.69s/it, lr=0.001, test_MAE=0.899, time=48.6, train_MAE=0.654, train_loss=0.654, val_MAE=0.866, val_loss=0.866]Epoch 8:   1%|          | 8/1000 [09:43<16:43:25, 60.69s/it, lr=0.001, test_MAE=0.736, time=48.7, train_MAE=0.658, train_loss=0.658, val_MAE=0.695, val_loss=0.695]Epoch 8:   1%|          | 9/1000 [09:43<15:42:54, 57.09s/it, lr=0.001, test_MAE=0.736, time=48.7, train_MAE=0.658, train_loss=0.658, val_MAE=0.695, val_loss=0.695]Epoch 9:   1%|          | 9/1000 [09:43<15:42:54, 57.09s/it, lr=0.001, test_MAE=0.736, time=48.7, train_MAE=0.658, train_loss=0.658, val_MAE=0.695, val_loss=0.695]Epoch 9:   1%|          | 9/1000 [10:32<15:42:54, 57.09s/it, lr=0.001, test_MAE=0.738, time=48.7, train_MAE=0.652, train_loss=0.652, val_MAE=0.691, val_loss=0.691]Epoch 9:   1%|          | 10/1000 [10:32<15:00:26, 54.57s/it, lr=0.001, test_MAE=0.738, time=48.7, train_MAE=0.652, train_loss=0.652, val_MAE=0.691, val_loss=0.691]Epoch 10:   1%|          | 10/1000 [10:32<15:00:26, 54.57s/it, lr=0.001, test_MAE=0.738, time=48.7, train_MAE=0.652, train_loss=0.652, val_MAE=0.691, val_loss=0.691]Epoch 10:   1%|          | 10/1000 [11:21<15:00:26, 54.57s/it, lr=0.001, test_MAE=0.721, time=49, train_MAE=0.646, train_loss=0.646, val_MAE=0.659, val_loss=0.659]  Epoch 10:   1%|          | 11/1000 [11:21<14:31:52, 52.89s/it, lr=0.001, test_MAE=0.721, time=49, train_MAE=0.646, train_loss=0.646, val_MAE=0.659, val_loss=0.659]Epoch 11:   1%|          | 11/1000 [11:21<14:31:52, 52.89s/it, lr=0.001, test_MAE=0.721, time=49, train_MAE=0.646, train_loss=0.646, val_MAE=0.659, val_loss=0.659]Epoch 11:   1%|          | 11/1000 [12:09<14:31:52, 52.89s/it, lr=0.001, test_MAE=0.713, time=48.6, train_MAE=0.646, train_loss=0.646, val_MAE=0.663, val_loss=0.663]Epoch 11:   1%|          | 12/1000 [12:09<14:10:01, 51.62s/it, lr=0.001, test_MAE=0.713, time=48.6, train_MAE=0.646, train_loss=0.646, val_MAE=0.663, val_loss=0.663]Epoch 12:   1%|          | 12/1000 [12:09<14:10:01, 51.62s/it, lr=0.001, test_MAE=0.713, time=48.6, train_MAE=0.646, train_loss=0.646, val_MAE=0.663, val_loss=0.663]Epoch 12:   1%|          | 12/1000 [12:57<14:10:01, 51.62s/it, lr=0.001, test_MAE=0.695, time=48.2, train_MAE=0.649, train_loss=0.649, val_MAE=0.649, val_loss=0.649]Epoch 12:   1%|▏         | 13/1000 [12:57<13:52:14, 50.59s/it, lr=0.001, test_MAE=0.695, time=48.2, train_MAE=0.649, train_loss=0.649, val_MAE=0.649, val_loss=0.649]Epoch 13:   1%|▏         | 13/1000 [12:57<13:52:14, 50.59s/it, lr=0.001, test_MAE=0.695, time=48.2, train_MAE=0.649, train_loss=0.649, val_MAE=0.649, val_loss=0.649]Epoch 13:   1%|▏         | 13/1000 [13:46<13:52:14, 50.59s/it, lr=0.001, test_MAE=0.752, time=48.9, train_MAE=0.644, train_loss=0.644, val_MAE=0.704, val_loss=0.704]Epoch 13:   1%|▏         | 14/1000 [13:46<13:42:57, 50.08s/it, lr=0.001, test_MAE=0.752, time=48.9, train_MAE=0.644, train_loss=0.644, val_MAE=0.704, val_loss=0.704]Epoch 14:   1%|▏         | 14/1000 [13:46<13:42:57, 50.08s/it, lr=0.001, test_MAE=0.752, time=48.9, train_MAE=0.644, train_loss=0.644, val_MAE=0.704, val_loss=0.704]Epoch 14:   1%|▏         | 14/1000 [14:34<13:42:57, 50.08s/it, lr=0.001, test_MAE=0.732, time=47.9, train_MAE=0.634, train_loss=0.634, val_MAE=0.671, val_loss=0.671]Epoch 14:   2%|▏         | 15/1000 [14:34<13:31:18, 49.42s/it, lr=0.001, test_MAE=0.732, time=47.9, train_MAE=0.634, train_loss=0.634, val_MAE=0.671, val_loss=0.671]Epoch 15:   2%|▏         | 15/1000 [14:34<13:31:18, 49.42s/it, lr=0.001, test_MAE=0.732, time=47.9, train_MAE=0.634, train_loss=0.634, val_MAE=0.671, val_loss=0.671]Epoch 15:   2%|▏         | 15/1000 [15:21<13:31:18, 49.42s/it, lr=0.001, test_MAE=0.778, time=47.2, train_MAE=0.642, train_loss=0.642, val_MAE=0.732, val_loss=0.732]Epoch 15:   2%|▏         | 16/1000 [15:21<13:19:50, 48.77s/it, lr=0.001, test_MAE=0.778, time=47.2, train_MAE=0.642, train_loss=0.642, val_MAE=0.732, val_loss=0.732]Epoch 16:   2%|▏         | 16/1000 [15:21<13:19:50, 48.77s/it, lr=0.001, test_MAE=0.778, time=47.2, train_MAE=0.642, train_loss=0.642, val_MAE=0.732, val_loss=0.732]Epoch 16:   2%|▏         | 16/1000 [16:08<13:19:50, 48.77s/it, lr=0.001, test_MAE=0.746, time=46.3, train_MAE=0.634, train_loss=0.634, val_MAE=0.691, val_loss=0.691]Epoch 16:   2%|▏         | 17/1000 [16:08<13:06:48, 48.03s/it, lr=0.001, test_MAE=0.746, time=46.3, train_MAE=0.634, train_loss=0.634, val_MAE=0.691, val_loss=0.691]Epoch 17:   2%|▏         | 17/1000 [16:08<13:06:48, 48.03s/it, lr=0.001, test_MAE=0.746, time=46.3, train_MAE=0.634, train_loss=0.634, val_MAE=0.691, val_loss=0.691]Epoch 17:   2%|▏         | 17/1000 [16:54<13:06:48, 48.03s/it, lr=0.001, test_MAE=0.721, time=46.1, train_MAE=0.63, train_loss=0.63, val_MAE=0.67, val_loss=0.67]    Epoch 17:   2%|▏         | 18/1000 [16:54<12:56:29, 47.44s/it, lr=0.001, test_MAE=0.721, time=46.1, train_MAE=0.63, train_loss=0.63, val_MAE=0.67, val_loss=0.67]Epoch 18:   2%|▏         | 18/1000 [16:54<12:56:29, 47.44s/it, lr=0.001, test_MAE=0.721, time=46.1, train_MAE=0.63, train_loss=0.63, val_MAE=0.67, val_loss=0.67]Epoch 18:   2%|▏         | 18/1000 [17:39<12:56:29, 47.44s/it, lr=0.001, test_MAE=0.714, time=45.4, train_MAE=0.633, train_loss=0.633, val_MAE=0.652, val_loss=0.652]Epoch    19: reducing learning rate of group 0 to 5.0000e-04.
Epoch 18:   2%|▏         | 19/1000 [17:39<12:45:46, 46.84s/it, lr=0.001, test_MAE=0.714, time=45.4, train_MAE=0.633, train_loss=0.633, val_MAE=0.652, val_loss=0.652]Epoch 19:   2%|▏         | 19/1000 [17:39<12:45:46, 46.84s/it, lr=0.001, test_MAE=0.714, time=45.4, train_MAE=0.633, train_loss=0.633, val_MAE=0.652, val_loss=0.652]Epoch 19:   2%|▏         | 19/1000 [18:25<12:45:46, 46.84s/it, lr=0.0005, test_MAE=0.766, time=45.8, train_MAE=0.616, train_loss=0.616, val_MAE=0.709, val_loss=0.709]Epoch 19:   2%|▏         | 20/1000 [18:25<12:40:06, 46.54s/it, lr=0.0005, test_MAE=0.766, time=45.8, train_MAE=0.616, train_loss=0.616, val_MAE=0.709, val_loss=0.709]Epoch 20:   2%|▏         | 20/1000 [18:25<12:40:06, 46.54s/it, lr=0.0005, test_MAE=0.766, time=45.8, train_MAE=0.616, train_loss=0.616, val_MAE=0.709, val_loss=0.709]Epoch 20:   2%|▏         | 20/1000 [19:11<12:40:06, 46.54s/it, lr=0.0005, test_MAE=0.701, time=45.8, train_MAE=0.609, train_loss=0.609, val_MAE=0.649, val_loss=0.649]Epoch 20:   2%|▏         | 21/1000 [19:11<12:35:52, 46.33s/it, lr=0.0005, test_MAE=0.701, time=45.8, train_MAE=0.609, train_loss=0.609, val_MAE=0.649, val_loss=0.649]Epoch 21:   2%|▏         | 21/1000 [19:11<12:35:52, 46.33s/it, lr=0.0005, test_MAE=0.701, time=45.8, train_MAE=0.609, train_loss=0.609, val_MAE=0.649, val_loss=0.649]Epoch 21:   2%|▏         | 21/1000 [19:56<12:35:52, 46.33s/it, lr=0.0005, test_MAE=0.704, time=45.5, train_MAE=0.613, train_loss=0.613, val_MAE=0.657, val_loss=0.657]Epoch 21:   2%|▏         | 22/1000 [19:56<12:31:04, 46.08s/it, lr=0.0005, test_MAE=0.704, time=45.5, train_MAE=0.613, train_loss=0.613, val_MAE=0.657, val_loss=0.657]Epoch 22:   2%|▏         | 22/1000 [19:56<12:31:04, 46.08s/it, lr=0.0005, test_MAE=0.704, time=45.5, train_MAE=0.613, train_loss=0.613, val_MAE=0.657, val_loss=0.657]Epoch 22:   2%|▏         | 22/1000 [20:42<12:31:04, 46.08s/it, lr=0.0005, test_MAE=0.704, time=45.3, train_MAE=0.611, train_loss=0.611, val_MAE=0.64, val_loss=0.64]  Epoch 22:   2%|▏         | 23/1000 [20:42<12:26:28, 45.84s/it, lr=0.0005, test_MAE=0.704, time=45.3, train_MAE=0.611, train_loss=0.611, val_MAE=0.64, val_loss=0.64]Epoch 23:   2%|▏         | 23/1000 [20:42<12:26:28, 45.84s/it, lr=0.0005, test_MAE=0.704, time=45.3, train_MAE=0.611, train_loss=0.611, val_MAE=0.64, val_loss=0.64]Epoch 23:   2%|▏         | 23/1000 [21:28<12:26:28, 45.84s/it, lr=0.0005, test_MAE=0.706, time=46, train_MAE=0.607, train_loss=0.607, val_MAE=0.64, val_loss=0.64]  Epoch 23:   2%|▏         | 24/1000 [21:28<12:26:39, 45.90s/it, lr=0.0005, test_MAE=0.706, time=46, train_MAE=0.607, train_loss=0.607, val_MAE=0.64, val_loss=0.64]Epoch 24:   2%|▏         | 24/1000 [21:28<12:26:39, 45.90s/it, lr=0.0005, test_MAE=0.706, time=46, train_MAE=0.607, train_loss=0.607, val_MAE=0.64, val_loss=0.64]Epoch 24:   2%|▏         | 24/1000 [22:13<12:26:39, 45.90s/it, lr=0.0005, test_MAE=0.688, time=45.6, train_MAE=0.614, train_loss=0.614, val_MAE=0.637, val_loss=0.637]Epoch 24:   2%|▎         | 25/1000 [22:13<12:24:18, 45.80s/it, lr=0.0005, test_MAE=0.688, time=45.6, train_MAE=0.614, train_loss=0.614, val_MAE=0.637, val_loss=0.637]Epoch 25:   2%|▎         | 25/1000 [22:13<12:24:18, 45.80s/it, lr=0.0005, test_MAE=0.688, time=45.6, train_MAE=0.614, train_loss=0.614, val_MAE=0.637, val_loss=0.637]Epoch 25:   2%|▎         | 25/1000 [22:59<12:24:18, 45.80s/it, lr=0.0005, test_MAE=0.72, time=45.5, train_MAE=0.608, train_loss=0.608, val_MAE=0.665, val_loss=0.665] Epoch 25:   3%|▎         | 26/1000 [22:59<12:22:03, 45.71s/it, lr=0.0005, test_MAE=0.72, time=45.5, train_MAE=0.608, train_loss=0.608, val_MAE=0.665, val_loss=0.665]Epoch 26:   3%|▎         | 26/1000 [22:59<12:22:03, 45.71s/it, lr=0.0005, test_MAE=0.72, time=45.5, train_MAE=0.608, train_loss=0.608, val_MAE=0.665, val_loss=0.665]Epoch 26:   3%|▎         | 26/1000 [23:44<12:22:03, 45.71s/it, lr=0.0005, test_MAE=0.716, time=45.5, train_MAE=0.605, train_loss=0.605, val_MAE=0.676, val_loss=0.676]Epoch 26:   3%|▎         | 27/1000 [23:44<12:20:34, 45.67s/it, lr=0.0005, test_MAE=0.716, time=45.5, train_MAE=0.605, train_loss=0.605, val_MAE=0.676, val_loss=0.676]Epoch 27:   3%|▎         | 27/1000 [23:44<12:20:34, 45.67s/it, lr=0.0005, test_MAE=0.716, time=45.5, train_MAE=0.605, train_loss=0.605, val_MAE=0.676, val_loss=0.676]Epoch 27:   3%|▎         | 27/1000 [24:30<12:20:34, 45.67s/it, lr=0.0005, test_MAE=0.805, time=45.7, train_MAE=0.6, train_loss=0.6, val_MAE=0.739, val_loss=0.739]    Epoch 27:   3%|▎         | 28/1000 [24:30<12:20:18, 45.70s/it, lr=0.0005, test_MAE=0.805, time=45.7, train_MAE=0.6, train_loss=0.6, val_MAE=0.739, val_loss=0.739]Epoch 28:   3%|▎         | 28/1000 [24:30<12:20:18, 45.70s/it, lr=0.0005, test_MAE=0.805, time=45.7, train_MAE=0.6, train_loss=0.6, val_MAE=0.739, val_loss=0.739]Epoch 28:   3%|▎         | 28/1000 [25:16<12:20:18, 45.70s/it, lr=0.0005, test_MAE=0.748, time=45.5, train_MAE=0.601, train_loss=0.601, val_MAE=0.697, val_loss=0.697]Epoch 28:   3%|▎         | 29/1000 [25:16<12:18:42, 45.65s/it, lr=0.0005, test_MAE=0.748, time=45.5, train_MAE=0.601, train_loss=0.601, val_MAE=0.697, val_loss=0.697]Epoch 29:   3%|▎         | 29/1000 [25:16<12:18:42, 45.65s/it, lr=0.0005, test_MAE=0.748, time=45.5, train_MAE=0.601, train_loss=0.601, val_MAE=0.697, val_loss=0.697]Epoch 29:   3%|▎         | 29/1000 [26:01<12:18:42, 45.65s/it, lr=0.0005, test_MAE=0.736, time=45.5, train_MAE=0.614, train_loss=0.614, val_MAE=0.68, val_loss=0.68]  Epoch 29:   3%|▎         | 30/1000 [26:01<12:17:03, 45.59s/it, lr=0.0005, test_MAE=0.736, time=45.5, train_MAE=0.614, train_loss=0.614, val_MAE=0.68, val_loss=0.68]Epoch 30:   3%|▎         | 30/1000 [26:01<12:17:03, 45.59s/it, lr=0.0005, test_MAE=0.736, time=45.5, train_MAE=0.614, train_loss=0.614, val_MAE=0.68, val_loss=0.68]Epoch 30:   3%|▎         | 30/1000 [26:47<12:17:03, 45.59s/it, lr=0.0005, test_MAE=0.738, time=45.7, train_MAE=0.607, train_loss=0.607, val_MAE=0.68, val_loss=0.68]Epoch    31: reducing learning rate of group 0 to 2.5000e-04.
Epoch 30:   3%|▎         | 31/1000 [26:47<12:17:03, 45.64s/it, lr=0.0005, test_MAE=0.738, time=45.7, train_MAE=0.607, train_loss=0.607, val_MAE=0.68, val_loss=0.68]Epoch 31:   3%|▎         | 31/1000 [26:47<12:17:03, 45.64s/it, lr=0.0005, test_MAE=0.738, time=45.7, train_MAE=0.607, train_loss=0.607, val_MAE=0.68, val_loss=0.68]Epoch 31:   3%|▎         | 31/1000 [27:32<12:17:03, 45.64s/it, lr=0.00025, test_MAE=0.701, time=45.5, train_MAE=0.587, train_loss=0.587, val_MAE=0.647, val_loss=0.647]Epoch 31:   3%|▎         | 32/1000 [27:32<12:15:46, 45.61s/it, lr=0.00025, test_MAE=0.701, time=45.5, train_MAE=0.587, train_loss=0.587, val_MAE=0.647, val_loss=0.647]Epoch 32:   3%|▎         | 32/1000 [27:32<12:15:46, 45.61s/it, lr=0.00025, test_MAE=0.701, time=45.5, train_MAE=0.587, train_loss=0.587, val_MAE=0.647, val_loss=0.647]Epoch 32:   3%|▎         | 32/1000 [28:18<12:15:46, 45.61s/it, lr=0.00025, test_MAE=0.702, time=45.5, train_MAE=0.586, train_loss=0.586, val_MAE=0.636, val_loss=0.636]Epoch 32:   3%|▎         | 33/1000 [28:18<12:14:32, 45.58s/it, lr=0.00025, test_MAE=0.702, time=45.5, train_MAE=0.586, train_loss=0.586, val_MAE=0.636, val_loss=0.636]Epoch 33:   3%|▎         | 33/1000 [28:18<12:14:32, 45.58s/it, lr=0.00025, test_MAE=0.702, time=45.5, train_MAE=0.586, train_loss=0.586, val_MAE=0.636, val_loss=0.636]Epoch 33:   3%|▎         | 33/1000 [29:03<12:14:32, 45.58s/it, lr=0.00025, test_MAE=0.71, time=45.5, train_MAE=0.583, train_loss=0.583, val_MAE=0.643, val_loss=0.643] Epoch 33:   3%|▎         | 34/1000 [29:03<12:13:18, 45.55s/it, lr=0.00025, test_MAE=0.71, time=45.5, train_MAE=0.583, train_loss=0.583, val_MAE=0.643, val_loss=0.643]Epoch 34:   3%|▎         | 34/1000 [29:03<12:13:18, 45.55s/it, lr=0.00025, test_MAE=0.71, time=45.5, train_MAE=0.583, train_loss=0.583, val_MAE=0.643, val_loss=0.643]Epoch 34:   3%|▎         | 34/1000 [29:49<12:13:18, 45.55s/it, lr=0.00025, test_MAE=0.736, time=45.8, train_MAE=0.583, train_loss=0.583, val_MAE=0.658, val_loss=0.658]Epoch 34:   4%|▎         | 35/1000 [29:49<12:13:45, 45.62s/it, lr=0.00025, test_MAE=0.736, time=45.8, train_MAE=0.583, train_loss=0.583, val_MAE=0.658, val_loss=0.658]Epoch 35:   4%|▎         | 35/1000 [29:49<12:13:45, 45.62s/it, lr=0.00025, test_MAE=0.736, time=45.8, train_MAE=0.583, train_loss=0.583, val_MAE=0.658, val_loss=0.658]Epoch 35:   4%|▎         | 35/1000 [30:35<12:13:45, 45.62s/it, lr=0.00025, test_MAE=0.692, time=45.5, train_MAE=0.582, train_loss=0.582, val_MAE=0.631, val_loss=0.631]Epoch 35:   4%|▎         | 36/1000 [30:35<12:12:36, 45.60s/it, lr=0.00025, test_MAE=0.692, time=45.5, train_MAE=0.582, train_loss=0.582, val_MAE=0.631, val_loss=0.631]Epoch 36:   4%|▎         | 36/1000 [30:35<12:12:36, 45.60s/it, lr=0.00025, test_MAE=0.692, time=45.5, train_MAE=0.582, train_loss=0.582, val_MAE=0.631, val_loss=0.631]Epoch 36:   4%|▎         | 36/1000 [31:20<12:12:36, 45.60s/it, lr=0.00025, test_MAE=0.7, time=45.5, train_MAE=0.588, train_loss=0.588, val_MAE=0.644, val_loss=0.644]  Epoch 36:   4%|▎         | 37/1000 [31:20<12:11:32, 45.58s/it, lr=0.00025, test_MAE=0.7, time=45.5, train_MAE=0.588, train_loss=0.588, val_MAE=0.644, val_loss=0.644]Epoch 37:   4%|▎         | 37/1000 [31:20<12:11:32, 45.58s/it, lr=0.00025, test_MAE=0.7, time=45.5, train_MAE=0.588, train_loss=0.588, val_MAE=0.644, val_loss=0.644]Epoch 37:   4%|▎         | 37/1000 [32:06<12:11:32, 45.58s/it, lr=0.00025, test_MAE=0.713, time=45.7, train_MAE=0.581, train_loss=0.581, val_MAE=0.638, val_loss=0.638]Epoch 37:   4%|▍         | 38/1000 [32:06<12:11:28, 45.62s/it, lr=0.00025, test_MAE=0.713, time=45.7, train_MAE=0.581, train_loss=0.581, val_MAE=0.638, val_loss=0.638]Epoch 38:   4%|▍         | 38/1000 [32:06<12:11:28, 45.62s/it, lr=0.00025, test_MAE=0.713, time=45.7, train_MAE=0.581, train_loss=0.581, val_MAE=0.638, val_loss=0.638]Epoch 38:   4%|▍         | 38/1000 [32:52<12:11:28, 45.62s/it, lr=0.00025, test_MAE=0.731, time=45.5, train_MAE=0.577, train_loss=0.577, val_MAE=0.658, val_loss=0.658]Epoch 38:   4%|▍         | 39/1000 [32:52<12:10:21, 45.60s/it, lr=0.00025, test_MAE=0.731, time=45.5, train_MAE=0.577, train_loss=0.577, val_MAE=0.658, val_loss=0.658]Epoch 39:   4%|▍         | 39/1000 [32:52<12:10:21, 45.60s/it, lr=0.00025, test_MAE=0.731, time=45.5, train_MAE=0.577, train_loss=0.577, val_MAE=0.658, val_loss=0.658]Epoch 39:   4%|▍         | 39/1000 [33:37<12:10:21, 45.60s/it, lr=0.00025, test_MAE=0.716, time=45.5, train_MAE=0.582, train_loss=0.582, val_MAE=0.639, val_loss=0.639]Epoch 39:   4%|▍         | 40/1000 [33:37<12:09:13, 45.58s/it, lr=0.00025, test_MAE=0.716, time=45.5, train_MAE=0.582, train_loss=0.582, val_MAE=0.639, val_loss=0.639]Epoch 40:   4%|▍         | 40/1000 [33:37<12:09:13, 45.58s/it, lr=0.00025, test_MAE=0.716, time=45.5, train_MAE=0.582, train_loss=0.582, val_MAE=0.639, val_loss=0.639]Epoch 40:   4%|▍         | 40/1000 [34:23<12:09:13, 45.58s/it, lr=0.00025, test_MAE=0.706, time=45.5, train_MAE=0.59, train_loss=0.59, val_MAE=0.637, val_loss=0.637]  Epoch 40:   4%|▍         | 41/1000 [34:23<12:08:19, 45.57s/it, lr=0.00025, test_MAE=0.706, time=45.5, train_MAE=0.59, train_loss=0.59, val_MAE=0.637, val_loss=0.637]Epoch 41:   4%|▍         | 41/1000 [34:23<12:08:19, 45.57s/it, lr=0.00025, test_MAE=0.706, time=45.5, train_MAE=0.59, train_loss=0.59, val_MAE=0.637, val_loss=0.637]Epoch 41:   4%|▍         | 41/1000 [35:08<12:08:19, 45.57s/it, lr=0.00025, test_MAE=0.712, time=45.7, train_MAE=0.569, train_loss=0.569, val_MAE=0.652, val_loss=0.652]Epoch    42: reducing learning rate of group 0 to 1.2500e-04.
Epoch 41:   4%|▍         | 42/1000 [35:08<12:08:23, 45.62s/it, lr=0.00025, test_MAE=0.712, time=45.7, train_MAE=0.569, train_loss=0.569, val_MAE=0.652, val_loss=0.652]Epoch 42:   4%|▍         | 42/1000 [35:08<12:08:23, 45.62s/it, lr=0.00025, test_MAE=0.712, time=45.7, train_MAE=0.569, train_loss=0.569, val_MAE=0.652, val_loss=0.652]Epoch 42:   4%|▍         | 42/1000 [35:54<12:08:23, 45.62s/it, lr=0.000125, test_MAE=0.696, time=45.5, train_MAE=0.563, train_loss=0.563, val_MAE=0.63, val_loss=0.63] Epoch 42:   4%|▍         | 43/1000 [35:54<12:07:14, 45.59s/it, lr=0.000125, test_MAE=0.696, time=45.5, train_MAE=0.563, train_loss=0.563, val_MAE=0.63, val_loss=0.63]Epoch 43:   4%|▍         | 43/1000 [35:54<12:07:14, 45.59s/it, lr=0.000125, test_MAE=0.696, time=45.5, train_MAE=0.563, train_loss=0.563, val_MAE=0.63, val_loss=0.63]Epoch 43:   4%|▍         | 43/1000 [36:39<12:07:14, 45.59s/it, lr=0.000125, test_MAE=0.695, time=45.5, train_MAE=0.564, train_loss=0.564, val_MAE=0.63, val_loss=0.63]Epoch 43:   4%|▍         | 44/1000 [36:39<12:06:13, 45.58s/it, lr=0.000125, test_MAE=0.695, time=45.5, train_MAE=0.564, train_loss=0.564, val_MAE=0.63, val_loss=0.63]Epoch 44:   4%|▍         | 44/1000 [36:39<12:06:13, 45.58s/it, lr=0.000125, test_MAE=0.695, time=45.5, train_MAE=0.564, train_loss=0.564, val_MAE=0.63, val_loss=0.63]Epoch 44:   4%|▍         | 44/1000 [37:25<12:06:13, 45.58s/it, lr=0.000125, test_MAE=0.7, time=45.8, train_MAE=0.56, train_loss=0.56, val_MAE=0.631, val_loss=0.631]  Epoch 44:   4%|▍         | 45/1000 [37:25<12:06:40, 45.65s/it, lr=0.000125, test_MAE=0.7, time=45.8, train_MAE=0.56, train_loss=0.56, val_MAE=0.631, val_loss=0.631]Epoch 45:   4%|▍         | 45/1000 [37:25<12:06:40, 45.65s/it, lr=0.000125, test_MAE=0.7, time=45.8, train_MAE=0.56, train_loss=0.56, val_MAE=0.631, val_loss=0.631]Epoch 45:   4%|▍         | 45/1000 [38:11<12:06:40, 45.65s/it, lr=0.000125, test_MAE=0.699, time=45.5, train_MAE=0.556, train_loss=0.556, val_MAE=0.63, val_loss=0.63]Epoch 45:   5%|▍         | 46/1000 [38:11<12:05:16, 45.61s/it, lr=0.000125, test_MAE=0.699, time=45.5, train_MAE=0.556, train_loss=0.556, val_MAE=0.63, val_loss=0.63]Epoch 46:   5%|▍         | 46/1000 [38:11<12:05:16, 45.61s/it, lr=0.000125, test_MAE=0.699, time=45.5, train_MAE=0.556, train_loss=0.556, val_MAE=0.63, val_loss=0.63]Epoch 46:   5%|▍         | 46/1000 [38:56<12:05:16, 45.61s/it, lr=0.000125, test_MAE=0.7, time=45.5, train_MAE=0.558, train_loss=0.558, val_MAE=0.638, val_loss=0.638]Epoch 46:   5%|▍         | 47/1000 [38:56<12:03:51, 45.57s/it, lr=0.000125, test_MAE=0.7, time=45.5, train_MAE=0.558, train_loss=0.558, val_MAE=0.638, val_loss=0.638]Epoch 47:   5%|▍         | 47/1000 [38:56<12:03:51, 45.57s/it, lr=0.000125, test_MAE=0.7, time=45.5, train_MAE=0.558, train_loss=0.558, val_MAE=0.638, val_loss=0.638]Epoch 47:   5%|▍         | 47/1000 [39:42<12:03:51, 45.57s/it, lr=0.000125, test_MAE=0.705, time=45.5, train_MAE=0.557, train_loss=0.557, val_MAE=0.642, val_loss=0.642]Epoch 47:   5%|▍         | 48/1000 [39:42<12:02:51, 45.56s/it, lr=0.000125, test_MAE=0.705, time=45.5, train_MAE=0.557, train_loss=0.557, val_MAE=0.642, val_loss=0.642]Epoch 48:   5%|▍         | 48/1000 [39:42<12:02:51, 45.56s/it, lr=0.000125, test_MAE=0.705, time=45.5, train_MAE=0.557, train_loss=0.557, val_MAE=0.642, val_loss=0.642]Epoch 48:   5%|▍         | 48/1000 [40:28<12:02:51, 45.56s/it, lr=0.000125, test_MAE=0.7, time=45.8, train_MAE=0.557, train_loss=0.557, val_MAE=0.632, val_loss=0.632]  Epoch    49: reducing learning rate of group 0 to 6.2500e-05.
Epoch 48:   5%|▍         | 49/1000 [40:28<12:03:03, 45.62s/it, lr=0.000125, test_MAE=0.7, time=45.8, train_MAE=0.557, train_loss=0.557, val_MAE=0.632, val_loss=0.632]Epoch 49:   5%|▍         | 49/1000 [40:28<12:03:03, 45.62s/it, lr=0.000125, test_MAE=0.7, time=45.8, train_MAE=0.557, train_loss=0.557, val_MAE=0.632, val_loss=0.632]Epoch 49:   5%|▍         | 49/1000 [41:13<12:03:03, 45.62s/it, lr=6.25e-5, test_MAE=0.702, time=45.6, train_MAE=0.553, train_loss=0.553, val_MAE=0.633, val_loss=0.633]Epoch 49:   5%|▌         | 50/1000 [41:13<12:02:04, 45.61s/it, lr=6.25e-5, test_MAE=0.702, time=45.6, train_MAE=0.553, train_loss=0.553, val_MAE=0.633, val_loss=0.633]Epoch 50:   5%|▌         | 50/1000 [41:13<12:02:04, 45.61s/it, lr=6.25e-5, test_MAE=0.702, time=45.6, train_MAE=0.553, train_loss=0.553, val_MAE=0.633, val_loss=0.633]Epoch 50:   5%|▌         | 50/1000 [41:59<12:02:04, 45.61s/it, lr=6.25e-5, test_MAE=0.701, time=45.5, train_MAE=0.548, train_loss=0.548, val_MAE=0.631, val_loss=0.631]Epoch 50:   5%|▌         | 51/1000 [41:59<12:00:42, 45.57s/it, lr=6.25e-5, test_MAE=0.701, time=45.5, train_MAE=0.548, train_loss=0.548, val_MAE=0.631, val_loss=0.631]Epoch 51:   5%|▌         | 51/1000 [41:59<12:00:42, 45.57s/it, lr=6.25e-5, test_MAE=0.701, time=45.5, train_MAE=0.548, train_loss=0.548, val_MAE=0.631, val_loss=0.631]Epoch 51:   5%|▌         | 51/1000 [42:44<12:00:42, 45.57s/it, lr=6.25e-5, test_MAE=0.703, time=45.8, train_MAE=0.554, train_loss=0.554, val_MAE=0.634, val_loss=0.634]Epoch 51:   5%|▌         | 52/1000 [42:44<12:01:20, 45.65s/it, lr=6.25e-5, test_MAE=0.703, time=45.8, train_MAE=0.554, train_loss=0.554, val_MAE=0.634, val_loss=0.634]Epoch 52:   5%|▌         | 52/1000 [42:44<12:01:20, 45.65s/it, lr=6.25e-5, test_MAE=0.703, time=45.8, train_MAE=0.554, train_loss=0.554, val_MAE=0.634, val_loss=0.634]Epoch 52:   5%|▌         | 52/1000 [43:30<12:01:20, 45.65s/it, lr=6.25e-5, test_MAE=0.696, time=45.5, train_MAE=0.548, train_loss=0.548, val_MAE=0.633, val_loss=0.633]Epoch 52:   5%|▌         | 53/1000 [43:30<11:59:44, 45.60s/it, lr=6.25e-5, test_MAE=0.696, time=45.5, train_MAE=0.548, train_loss=0.548, val_MAE=0.633, val_loss=0.633]Epoch 53:   5%|▌         | 53/1000 [43:30<11:59:44, 45.60s/it, lr=6.25e-5, test_MAE=0.696, time=45.5, train_MAE=0.548, train_loss=0.548, val_MAE=0.633, val_loss=0.633]Epoch 53:   5%|▌         | 53/1000 [44:15<11:59:44, 45.60s/it, lr=6.25e-5, test_MAE=0.697, time=45.5, train_MAE=0.577, train_loss=0.577, val_MAE=0.633, val_loss=0.633]Epoch 53:   5%|▌         | 54/1000 [44:15<11:58:35, 45.58s/it, lr=6.25e-5, test_MAE=0.697, time=45.5, train_MAE=0.577, train_loss=0.577, val_MAE=0.633, val_loss=0.633]Epoch 54:   5%|▌         | 54/1000 [44:15<11:58:35, 45.58s/it, lr=6.25e-5, test_MAE=0.697, time=45.5, train_MAE=0.577, train_loss=0.577, val_MAE=0.633, val_loss=0.633]Epoch 54:   5%|▌         | 54/1000 [45:01<11:58:35, 45.58s/it, lr=6.25e-5, test_MAE=0.698, time=45.5, train_MAE=0.549, train_loss=0.549, val_MAE=0.63, val_loss=0.63]  Epoch    55: reducing learning rate of group 0 to 3.1250e-05.
Epoch 54:   6%|▌         | 55/1000 [45:01<11:57:28, 45.55s/it, lr=6.25e-5, test_MAE=0.698, time=45.5, train_MAE=0.549, train_loss=0.549, val_MAE=0.63, val_loss=0.63]Epoch 55:   6%|▌         | 55/1000 [45:01<11:57:28, 45.55s/it, lr=6.25e-5, test_MAE=0.698, time=45.5, train_MAE=0.549, train_loss=0.549, val_MAE=0.63, val_loss=0.63]Epoch 55:   6%|▌         | 55/1000 [45:47<11:57:28, 45.55s/it, lr=3.13e-5, test_MAE=0.702, time=45.8, train_MAE=0.544, train_loss=0.544, val_MAE=0.632, val_loss=0.632]Epoch 55:   6%|▌         | 56/1000 [45:47<11:57:44, 45.62s/it, lr=3.13e-5, test_MAE=0.702, time=45.8, train_MAE=0.544, train_loss=0.544, val_MAE=0.632, val_loss=0.632]Epoch 56:   6%|▌         | 56/1000 [45:47<11:57:44, 45.62s/it, lr=3.13e-5, test_MAE=0.702, time=45.8, train_MAE=0.544, train_loss=0.544, val_MAE=0.632, val_loss=0.632]Epoch 56:   6%|▌         | 56/1000 [46:32<11:57:44, 45.62s/it, lr=3.13e-5, test_MAE=0.697, time=45.5, train_MAE=0.54, train_loss=0.54, val_MAE=0.632, val_loss=0.632]  Epoch 56:   6%|▌         | 57/1000 [46:32<11:56:34, 45.59s/it, lr=3.13e-5, test_MAE=0.697, time=45.5, train_MAE=0.54, train_loss=0.54, val_MAE=0.632, val_loss=0.632]Epoch 57:   6%|▌         | 57/1000 [46:32<11:56:34, 45.59s/it, lr=3.13e-5, test_MAE=0.697, time=45.5, train_MAE=0.54, train_loss=0.54, val_MAE=0.632, val_loss=0.632]Epoch 57:   6%|▌         | 57/1000 [47:18<11:56:34, 45.59s/it, lr=3.13e-5, test_MAE=0.698, time=45.5, train_MAE=0.546, train_loss=0.546, val_MAE=0.634, val_loss=0.634]Epoch 57:   6%|▌         | 58/1000 [47:18<11:55:28, 45.57s/it, lr=3.13e-5, test_MAE=0.698, time=45.5, train_MAE=0.546, train_loss=0.546, val_MAE=0.634, val_loss=0.634]Epoch 58:   6%|▌         | 58/1000 [47:18<11:55:28, 45.57s/it, lr=3.13e-5, test_MAE=0.698, time=45.5, train_MAE=0.546, train_loss=0.546, val_MAE=0.634, val_loss=0.634]Epoch 58:   6%|▌         | 58/1000 [48:04<11:55:28, 45.57s/it, lr=3.13e-5, test_MAE=0.699, time=45.7, train_MAE=0.543, train_loss=0.543, val_MAE=0.633, val_loss=0.633]Epoch 58:   6%|▌         | 59/1000 [48:04<11:55:32, 45.62s/it, lr=3.13e-5, test_MAE=0.699, time=45.7, train_MAE=0.543, train_loss=0.543, val_MAE=0.633, val_loss=0.633]Epoch 59:   6%|▌         | 59/1000 [48:04<11:55:32, 45.62s/it, lr=3.13e-5, test_MAE=0.699, time=45.7, train_MAE=0.543, train_loss=0.543, val_MAE=0.633, val_loss=0.633]Epoch 59:   6%|▌         | 59/1000 [48:49<11:55:32, 45.62s/it, lr=3.13e-5, test_MAE=0.697, time=45.5, train_MAE=0.538, train_loss=0.538, val_MAE=0.632, val_loss=0.632]Epoch 59:   6%|▌         | 60/1000 [48:49<11:54:07, 45.58s/it, lr=3.13e-5, test_MAE=0.697, time=45.5, train_MAE=0.538, train_loss=0.538, val_MAE=0.632, val_loss=0.632]Epoch 60:   6%|▌         | 60/1000 [48:49<11:54:07, 45.58s/it, lr=3.13e-5, test_MAE=0.697, time=45.5, train_MAE=0.538, train_loss=0.538, val_MAE=0.632, val_loss=0.632]Epoch 60:   6%|▌         | 60/1000 [49:35<11:54:07, 45.58s/it, lr=3.13e-5, test_MAE=0.7, time=45.5, train_MAE=0.544, train_loss=0.544, val_MAE=0.634, val_loss=0.634]  Epoch    61: reducing learning rate of group 0 to 1.5625e-05.
Epoch 60:   6%|▌         | 61/1000 [49:35<11:53:12, 45.57s/it, lr=3.13e-5, test_MAE=0.7, time=45.5, train_MAE=0.544, train_loss=0.544, val_MAE=0.634, val_loss=0.634]Epoch 61:   6%|▌         | 61/1000 [49:35<11:53:12, 45.57s/it, lr=3.13e-5, test_MAE=0.7, time=45.5, train_MAE=0.544, train_loss=0.544, val_MAE=0.634, val_loss=0.634]Epoch 61:   6%|▌         | 61/1000 [50:20<11:53:12, 45.57s/it, lr=1.56e-5, test_MAE=0.698, time=45.5, train_MAE=0.538, train_loss=0.538, val_MAE=0.632, val_loss=0.632]Epoch 61:   6%|▌         | 62/1000 [50:20<11:52:13, 45.56s/it, lr=1.56e-5, test_MAE=0.698, time=45.5, train_MAE=0.538, train_loss=0.538, val_MAE=0.632, val_loss=0.632]Epoch 62:   6%|▌         | 62/1000 [50:20<11:52:13, 45.56s/it, lr=1.56e-5, test_MAE=0.698, time=45.5, train_MAE=0.538, train_loss=0.538, val_MAE=0.632, val_loss=0.632]Epoch 62:   6%|▌         | 62/1000 [51:06<11:52:13, 45.56s/it, lr=1.56e-5, test_MAE=0.7, time=45.7, train_MAE=0.536, train_loss=0.536, val_MAE=0.631, val_loss=0.631]  Epoch 62:   6%|▋         | 63/1000 [51:06<11:52:16, 45.61s/it, lr=1.56e-5, test_MAE=0.7, time=45.7, train_MAE=0.536, train_loss=0.536, val_MAE=0.631, val_loss=0.631]Epoch 63:   6%|▋         | 63/1000 [51:06<11:52:16, 45.61s/it, lr=1.56e-5, test_MAE=0.7, time=45.7, train_MAE=0.536, train_loss=0.536, val_MAE=0.631, val_loss=0.631]Epoch 63:   6%|▋         | 63/1000 [51:51<11:52:16, 45.61s/it, lr=1.56e-5, test_MAE=0.699, time=45.5, train_MAE=0.541, train_loss=0.541, val_MAE=0.631, val_loss=0.631]Epoch 63:   6%|▋         | 64/1000 [51:51<11:51:07, 45.58s/it, lr=1.56e-5, test_MAE=0.699, time=45.5, train_MAE=0.541, train_loss=0.541, val_MAE=0.631, val_loss=0.631]Epoch 64:   6%|▋         | 64/1000 [51:51<11:51:07, 45.58s/it, lr=1.56e-5, test_MAE=0.699, time=45.5, train_MAE=0.541, train_loss=0.541, val_MAE=0.631, val_loss=0.631]Epoch 64:   6%|▋         | 64/1000 [52:37<11:51:07, 45.58s/it, lr=1.56e-5, test_MAE=0.699, time=45.5, train_MAE=0.538, train_loss=0.538, val_MAE=0.63, val_loss=0.63]  Epoch 64:   6%|▋         | 65/1000 [52:37<11:50:02, 45.56s/it, lr=1.56e-5, test_MAE=0.699, time=45.5, train_MAE=0.538, train_loss=0.538, val_MAE=0.63, val_loss=0.63]Epoch 65:   6%|▋         | 65/1000 [52:37<11:50:02, 45.56s/it, lr=1.56e-5, test_MAE=0.699, time=45.5, train_MAE=0.538, train_loss=0.538, val_MAE=0.63, val_loss=0.63]Epoch 65:   6%|▋         | 65/1000 [53:23<11:50:02, 45.56s/it, lr=1.56e-5, test_MAE=0.698, time=45.8, train_MAE=0.538, train_loss=0.538, val_MAE=0.632, val_loss=0.632]Epoch 65:   7%|▋         | 66/1000 [53:23<11:50:28, 45.64s/it, lr=1.56e-5, test_MAE=0.698, time=45.8, train_MAE=0.538, train_loss=0.538, val_MAE=0.632, val_loss=0.632]Epoch 66:   7%|▋         | 66/1000 [53:23<11:50:28, 45.64s/it, lr=1.56e-5, test_MAE=0.698, time=45.8, train_MAE=0.538, train_loss=0.538, val_MAE=0.632, val_loss=0.632]Epoch 66:   7%|▋         | 66/1000 [54:08<11:50:28, 45.64s/it, lr=1.56e-5, test_MAE=0.701, time=45.4, train_MAE=0.539, train_loss=0.539, val_MAE=0.633, val_loss=0.633]Epoch    67: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 66:   7%|▋         | 66/1000 [54:08<12:46:13, 49.22s/it, lr=1.56e-5, test_MAE=0.701, time=45.4, train_MAE=0.539, train_loss=0.539, val_MAE=0.633, val_loss=0.633]
Test MAE: 0.7009
Train MAE: 0.5276
Convergence Time (Epochs): 66.0000
TOTAL TIME TAKEN: 3275.3386s
AVG TIME PER EPOCH: 48.4714s
