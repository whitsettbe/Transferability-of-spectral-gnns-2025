I'm echoing to stdout
I'm echoing to stderr
My JobID is 56766303
I have 8 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.6230s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 2, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'parallel_dense_simp', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_all', 'num_eigs': 64, 'bias_mode': '', 'eigval_hidden_dim': 5, 'eigval_num_hidden_layer': 3, 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 0.1, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/zinc_train_rec_full.csv', 'test': 'supp_data/molecules/zinc_test_rec_full.csv', 'val': 'supp_data/molecules/zinc_val_rec_full.csv'}, 'fixMissingPhi1': False, 'extraOrtho': True, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [04:34<?, ?it/s, lr=0.001, test_MAE=1.44, time=274, train_MAE=1.02, train_loss=1.02, val_MAE=1.39, val_loss=1.39]Epoch 0:   0%|          | 1/1000 [04:34<76:09:27, 274.44s/it, lr=0.001, test_MAE=1.44, time=274, train_MAE=1.02, train_loss=1.02, val_MAE=1.39, val_loss=1.39]Epoch 1:   0%|          | 1/1000 [04:34<76:09:27, 274.44s/it, lr=0.001, test_MAE=1.44, time=274, train_MAE=1.02, train_loss=1.02, val_MAE=1.39, val_loss=1.39]Epoch 1:   0%|          | 1/1000 [05:35<76:09:27, 274.44s/it, lr=0.001, test_MAE=0.716, time=60.7, train_MAE=0.696, train_loss=0.699, val_MAE=0.68, val_loss=0.683]Epoch 1:   0%|          | 2/1000 [05:35<58:18:25, 210.33s/it, lr=0.001, test_MAE=0.716, time=60.7, train_MAE=0.696, train_loss=0.699, val_MAE=0.68, val_loss=0.683]Epoch 2:   0%|          | 2/1000 [05:35<58:18:25, 210.33s/it, lr=0.001, test_MAE=0.716, time=60.7, train_MAE=0.696, train_loss=0.699, val_MAE=0.68, val_loss=0.683]Epoch 2:   0%|          | 2/1000 [06:35<58:18:25, 210.33s/it, lr=0.001, test_MAE=0.932, time=60.6, train_MAE=0.655, train_loss=0.659, val_MAE=0.892, val_loss=0.896]Epoch 2:   0%|          | 3/1000 [06:35<45:48:51, 165.43s/it, lr=0.001, test_MAE=0.932, time=60.6, train_MAE=0.655, train_loss=0.659, val_MAE=0.892, val_loss=0.896]Epoch 3:   0%|          | 3/1000 [06:35<45:48:51, 165.43s/it, lr=0.001, test_MAE=0.932, time=60.6, train_MAE=0.655, train_loss=0.659, val_MAE=0.892, val_loss=0.896]Epoch 3:   0%|          | 3/1000 [07:36<45:48:51, 165.43s/it, lr=0.001, test_MAE=0.915, time=60.7, train_MAE=0.624, train_loss=0.629, val_MAE=0.869, val_loss=0.874]Epoch 3:   0%|          | 4/1000 [07:36<37:04:25, 134.00s/it, lr=0.001, test_MAE=0.915, time=60.7, train_MAE=0.624, train_loss=0.629, val_MAE=0.869, val_loss=0.874]Epoch 4:   0%|          | 4/1000 [07:36<37:04:25, 134.00s/it, lr=0.001, test_MAE=0.915, time=60.7, train_MAE=0.624, train_loss=0.629, val_MAE=0.869, val_loss=0.874]Epoch 4:   0%|          | 4/1000 [08:37<37:04:25, 134.00s/it, lr=0.001, test_MAE=0.694, time=60.7, train_MAE=0.606, train_loss=0.611, val_MAE=0.644, val_loss=0.649]Epoch 4:   0%|          | 5/1000 [08:37<30:57:35, 112.02s/it, lr=0.001, test_MAE=0.694, time=60.7, train_MAE=0.606, train_loss=0.611, val_MAE=0.644, val_loss=0.649]Epoch 5:   0%|          | 5/1000 [08:37<30:57:35, 112.02s/it, lr=0.001, test_MAE=0.694, time=60.7, train_MAE=0.606, train_loss=0.611, val_MAE=0.644, val_loss=0.649]Epoch 5:   0%|          | 5/1000 [09:38<30:57:35, 112.02s/it, lr=0.001, test_MAE=0.729, time=60.8, train_MAE=0.603, train_loss=0.608, val_MAE=0.691, val_loss=0.696]Epoch 5:   1%|          | 6/1000 [09:38<26:41:10, 96.65s/it, lr=0.001, test_MAE=0.729, time=60.8, train_MAE=0.603, train_loss=0.608, val_MAE=0.691, val_loss=0.696] Epoch 6:   1%|          | 6/1000 [09:38<26:41:10, 96.65s/it, lr=0.001, test_MAE=0.729, time=60.8, train_MAE=0.603, train_loss=0.608, val_MAE=0.691, val_loss=0.696]Epoch 6:   1%|          | 6/1000 [10:39<26:41:10, 96.65s/it, lr=0.001, test_MAE=0.755, time=61.2, train_MAE=0.578, train_loss=0.583, val_MAE=0.7, val_loss=0.705]  Epoch 6:   1%|          | 7/1000 [10:39<23:43:30, 86.01s/it, lr=0.001, test_MAE=0.755, time=61.2, train_MAE=0.578, train_loss=0.583, val_MAE=0.7, val_loss=0.705]Epoch 7:   1%|          | 7/1000 [10:39<23:43:30, 86.01s/it, lr=0.001, test_MAE=0.755, time=61.2, train_MAE=0.578, train_loss=0.583, val_MAE=0.7, val_loss=0.705]Epoch 7:   1%|          | 7/1000 [11:40<23:43:30, 86.01s/it, lr=0.001, test_MAE=0.709, time=60.9, train_MAE=0.566, train_loss=0.571, val_MAE=0.643, val_loss=0.648]Epoch 7:   1%|          | 8/1000 [11:40<21:37:27, 78.48s/it, lr=0.001, test_MAE=0.709, time=60.9, train_MAE=0.566, train_loss=0.571, val_MAE=0.643, val_loss=0.648]Epoch 8:   1%|          | 8/1000 [11:40<21:37:27, 78.48s/it, lr=0.001, test_MAE=0.709, time=60.9, train_MAE=0.566, train_loss=0.571, val_MAE=0.643, val_loss=0.648]Epoch 8:   1%|          | 8/1000 [12:40<21:37:27, 78.48s/it, lr=0.001, test_MAE=0.695, time=60.9, train_MAE=0.562, train_loss=0.568, val_MAE=0.626, val_loss=0.632]Epoch 8:   1%|          | 9/1000 [12:40<20:08:52, 73.19s/it, lr=0.001, test_MAE=0.695, time=60.9, train_MAE=0.562, train_loss=0.568, val_MAE=0.626, val_loss=0.632]Epoch 9:   1%|          | 9/1000 [12:40<20:08:52, 73.19s/it, lr=0.001, test_MAE=0.695, time=60.9, train_MAE=0.562, train_loss=0.568, val_MAE=0.626, val_loss=0.632]Epoch 9:   1%|          | 9/1000 [13:42<20:08:52, 73.19s/it, lr=0.001, test_MAE=0.751, time=61.1, train_MAE=0.538, train_loss=0.544, val_MAE=0.692, val_loss=0.698]Epoch 9:   1%|          | 10/1000 [13:42<19:07:41, 69.56s/it, lr=0.001, test_MAE=0.751, time=61.1, train_MAE=0.538, train_loss=0.544, val_MAE=0.692, val_loss=0.698]Epoch 10:   1%|          | 10/1000 [13:42<19:07:41, 69.56s/it, lr=0.001, test_MAE=0.751, time=61.1, train_MAE=0.538, train_loss=0.544, val_MAE=0.692, val_loss=0.698]Epoch 10:   1%|          | 10/1000 [14:42<19:07:41, 69.56s/it, lr=0.001, test_MAE=0.741, time=60.8, train_MAE=0.544, train_loss=0.551, val_MAE=0.694, val_loss=0.701]Epoch 10:   1%|          | 11/1000 [14:42<18:23:22, 66.94s/it, lr=0.001, test_MAE=0.741, time=60.8, train_MAE=0.544, train_loss=0.551, val_MAE=0.694, val_loss=0.701]Epoch 11:   1%|          | 11/1000 [14:42<18:23:22, 66.94s/it, lr=0.001, test_MAE=0.741, time=60.8, train_MAE=0.544, train_loss=0.551, val_MAE=0.694, val_loss=0.701]Epoch 11:   1%|          | 11/1000 [15:43<18:23:22, 66.94s/it, lr=0.001, test_MAE=0.763, time=60.5, train_MAE=0.528, train_loss=0.535, val_MAE=0.726, val_loss=0.733]Epoch 11:   1%|          | 12/1000 [15:43<17:50:34, 65.01s/it, lr=0.001, test_MAE=0.763, time=60.5, train_MAE=0.528, train_loss=0.535, val_MAE=0.726, val_loss=0.733]Epoch 12:   1%|          | 12/1000 [15:43<17:50:34, 65.01s/it, lr=0.001, test_MAE=0.763, time=60.5, train_MAE=0.528, train_loss=0.535, val_MAE=0.726, val_loss=0.733]Epoch 12:   1%|          | 12/1000 [16:44<17:50:34, 65.01s/it, lr=0.001, test_MAE=0.813, time=61, train_MAE=0.516, train_loss=0.523, val_MAE=0.767, val_loss=0.774]  Epoch 12:   1%|▏         | 13/1000 [16:44<17:29:51, 63.82s/it, lr=0.001, test_MAE=0.813, time=61, train_MAE=0.516, train_loss=0.523, val_MAE=0.767, val_loss=0.774]Epoch 13:   1%|▏         | 13/1000 [16:44<17:29:51, 63.82s/it, lr=0.001, test_MAE=0.813, time=61, train_MAE=0.516, train_loss=0.523, val_MAE=0.767, val_loss=0.774]Epoch 13:   1%|▏         | 13/1000 [17:45<17:29:51, 63.82s/it, lr=0.001, test_MAE=0.684, time=61, train_MAE=0.506, train_loss=0.513, val_MAE=0.635, val_loss=0.642]Epoch 13:   1%|▏         | 14/1000 [17:45<17:14:58, 62.98s/it, lr=0.001, test_MAE=0.684, time=61, train_MAE=0.506, train_loss=0.513, val_MAE=0.635, val_loss=0.642]Epoch 14:   1%|▏         | 14/1000 [17:45<17:14:58, 62.98s/it, lr=0.001, test_MAE=0.684, time=61, train_MAE=0.506, train_loss=0.513, val_MAE=0.635, val_loss=0.642]Epoch 14:   1%|▏         | 14/1000 [18:45<17:14:58, 62.98s/it, lr=0.001, test_MAE=0.725, time=60.5, train_MAE=0.489, train_loss=0.497, val_MAE=0.679, val_loss=0.686]Epoch    15: reducing learning rate of group 0 to 5.0000e-04.
Epoch 14:   2%|▏         | 15/1000 [18:45<17:01:51, 62.25s/it, lr=0.001, test_MAE=0.725, time=60.5, train_MAE=0.489, train_loss=0.497, val_MAE=0.679, val_loss=0.686]Epoch 15:   2%|▏         | 15/1000 [18:45<17:01:51, 62.25s/it, lr=0.001, test_MAE=0.725, time=60.5, train_MAE=0.489, train_loss=0.497, val_MAE=0.679, val_loss=0.686]Epoch 15:   2%|▏         | 15/1000 [19:47<17:01:51, 62.25s/it, lr=0.0005, test_MAE=0.691, time=61.1, train_MAE=0.458, train_loss=0.465, val_MAE=0.634, val_loss=0.641]Epoch 15:   2%|▏         | 16/1000 [19:47<16:55:16, 61.91s/it, lr=0.0005, test_MAE=0.691, time=61.1, train_MAE=0.458, train_loss=0.465, val_MAE=0.634, val_loss=0.641]Epoch 16:   2%|▏         | 16/1000 [19:47<16:55:16, 61.91s/it, lr=0.0005, test_MAE=0.691, time=61.1, train_MAE=0.458, train_loss=0.465, val_MAE=0.634, val_loss=0.641]Epoch 16:   2%|▏         | 16/1000 [20:47<16:55:16, 61.91s/it, lr=0.0005, test_MAE=0.683, time=60.6, train_MAE=0.436, train_loss=0.444, val_MAE=0.623, val_loss=0.631]Epoch 16:   2%|▏         | 17/1000 [20:47<16:47:49, 61.52s/it, lr=0.0005, test_MAE=0.683, time=60.6, train_MAE=0.436, train_loss=0.444, val_MAE=0.623, val_loss=0.631]Epoch 17:   2%|▏         | 17/1000 [20:47<16:47:49, 61.52s/it, lr=0.0005, test_MAE=0.683, time=60.6, train_MAE=0.436, train_loss=0.444, val_MAE=0.623, val_loss=0.631]Epoch 17:   2%|▏         | 17/1000 [21:48<16:47:49, 61.52s/it, lr=0.0005, test_MAE=0.748, time=60.6, train_MAE=0.421, train_loss=0.429, val_MAE=0.698, val_loss=0.706]Epoch 17:   2%|▏         | 18/1000 [21:48<16:42:25, 61.25s/it, lr=0.0005, test_MAE=0.748, time=60.6, train_MAE=0.421, train_loss=0.429, val_MAE=0.698, val_loss=0.706]Epoch 18:   2%|▏         | 18/1000 [21:48<16:42:25, 61.25s/it, lr=0.0005, test_MAE=0.748, time=60.6, train_MAE=0.421, train_loss=0.429, val_MAE=0.698, val_loss=0.706]Epoch 18:   2%|▏         | 18/1000 [22:49<16:42:25, 61.25s/it, lr=0.0005, test_MAE=0.722, time=61.3, train_MAE=0.419, train_loss=0.427, val_MAE=0.662, val_loss=0.67] Epoch 18:   2%|▏         | 19/1000 [22:49<16:41:33, 61.26s/it, lr=0.0005, test_MAE=0.722, time=61.3, train_MAE=0.419, train_loss=0.427, val_MAE=0.662, val_loss=0.67]Epoch 19:   2%|▏         | 19/1000 [22:49<16:41:33, 61.26s/it, lr=0.0005, test_MAE=0.722, time=61.3, train_MAE=0.419, train_loss=0.427, val_MAE=0.662, val_loss=0.67]Epoch 19:   2%|▏         | 19/1000 [23:50<16:41:33, 61.26s/it, lr=0.0005, test_MAE=0.756, time=60.9, train_MAE=0.413, train_loss=0.421, val_MAE=0.718, val_loss=0.726]Epoch 19:   2%|▏         | 20/1000 [23:50<16:38:37, 61.14s/it, lr=0.0005, test_MAE=0.756, time=60.9, train_MAE=0.413, train_loss=0.421, val_MAE=0.718, val_loss=0.726]Epoch 20:   2%|▏         | 20/1000 [23:50<16:38:37, 61.14s/it, lr=0.0005, test_MAE=0.756, time=60.9, train_MAE=0.413, train_loss=0.421, val_MAE=0.718, val_loss=0.726]Epoch 20:   2%|▏         | 20/1000 [24:51<16:38:37, 61.14s/it, lr=0.0005, test_MAE=0.774, time=61, train_MAE=0.414, train_loss=0.422, val_MAE=0.727, val_loss=0.735]  Epoch 20:   2%|▏         | 21/1000 [24:51<16:36:47, 61.09s/it, lr=0.0005, test_MAE=0.774, time=61, train_MAE=0.414, train_loss=0.422, val_MAE=0.727, val_loss=0.735]Epoch 21:   2%|▏         | 21/1000 [24:51<16:36:47, 61.09s/it, lr=0.0005, test_MAE=0.774, time=61, train_MAE=0.414, train_loss=0.422, val_MAE=0.727, val_loss=0.735]Epoch 21:   2%|▏         | 21/1000 [25:52<16:36:47, 61.09s/it, lr=0.0005, test_MAE=0.735, time=61.4, train_MAE=0.39, train_loss=0.398, val_MAE=0.673, val_loss=0.681]Epoch 21:   2%|▏         | 22/1000 [25:52<16:37:16, 61.18s/it, lr=0.0005, test_MAE=0.735, time=61.4, train_MAE=0.39, train_loss=0.398, val_MAE=0.673, val_loss=0.681]Epoch 22:   2%|▏         | 22/1000 [25:52<16:37:16, 61.18s/it, lr=0.0005, test_MAE=0.735, time=61.4, train_MAE=0.39, train_loss=0.398, val_MAE=0.673, val_loss=0.681]Epoch 22:   2%|▏         | 22/1000 [26:53<16:37:16, 61.18s/it, lr=0.0005, test_MAE=0.697, time=60.9, train_MAE=0.4, train_loss=0.408, val_MAE=0.662, val_loss=0.67]  Epoch    23: reducing learning rate of group 0 to 2.5000e-04.
Epoch 22:   2%|▏         | 23/1000 [26:53<16:34:47, 61.09s/it, lr=0.0005, test_MAE=0.697, time=60.9, train_MAE=0.4, train_loss=0.408, val_MAE=0.662, val_loss=0.67]Epoch 23:   2%|▏         | 23/1000 [26:53<16:34:47, 61.09s/it, lr=0.0005, test_MAE=0.697, time=60.9, train_MAE=0.4, train_loss=0.408, val_MAE=0.662, val_loss=0.67]Epoch 23:   2%|▏         | 23/1000 [27:54<16:34:47, 61.09s/it, lr=0.00025, test_MAE=0.701, time=61, train_MAE=0.373, train_loss=0.381, val_MAE=0.646, val_loss=0.653]Epoch 23:   2%|▏         | 24/1000 [27:54<16:33:35, 61.08s/it, lr=0.00025, test_MAE=0.701, time=61, train_MAE=0.373, train_loss=0.381, val_MAE=0.646, val_loss=0.653]Epoch 24:   2%|▏         | 24/1000 [27:54<16:33:35, 61.08s/it, lr=0.00025, test_MAE=0.701, time=61, train_MAE=0.373, train_loss=0.381, val_MAE=0.646, val_loss=0.653]Epoch 24:   2%|▏         | 24/1000 [28:53<16:33:35, 61.08s/it, lr=0.00025, test_MAE=0.709, time=58.8, train_MAE=0.356, train_loss=0.364, val_MAE=0.644, val_loss=0.651]Epoch 24:   2%|▎         | 25/1000 [28:53<16:21:18, 60.39s/it, lr=0.00025, test_MAE=0.709, time=58.8, train_MAE=0.356, train_loss=0.364, val_MAE=0.644, val_loss=0.651]Epoch 25:   2%|▎         | 25/1000 [28:53<16:21:18, 60.39s/it, lr=0.00025, test_MAE=0.709, time=58.8, train_MAE=0.356, train_loss=0.364, val_MAE=0.644, val_loss=0.651]Epoch 25:   2%|▎         | 25/1000 [29:47<16:21:18, 60.39s/it, lr=0.00025, test_MAE=0.711, time=53.5, train_MAE=0.336, train_loss=0.344, val_MAE=0.649, val_loss=0.657]Epoch 25:   3%|▎         | 26/1000 [29:47<15:46:59, 58.34s/it, lr=0.00025, test_MAE=0.711, time=53.5, train_MAE=0.336, train_loss=0.344, val_MAE=0.649, val_loss=0.657]Epoch 26:   3%|▎         | 26/1000 [29:47<15:46:59, 58.34s/it, lr=0.00025, test_MAE=0.711, time=53.5, train_MAE=0.336, train_loss=0.344, val_MAE=0.649, val_loss=0.657]Epoch 26:   3%|▎         | 26/1000 [30:39<15:46:59, 58.34s/it, lr=0.00025, test_MAE=0.705, time=52, train_MAE=0.326, train_loss=0.334, val_MAE=0.659, val_loss=0.667]  Epoch 26:   3%|▎         | 27/1000 [30:39<15:15:03, 56.43s/it, lr=0.00025, test_MAE=0.705, time=52, train_MAE=0.326, train_loss=0.334, val_MAE=0.659, val_loss=0.667]Epoch 27:   3%|▎         | 27/1000 [30:39<15:15:03, 56.43s/it, lr=0.00025, test_MAE=0.705, time=52, train_MAE=0.326, train_loss=0.334, val_MAE=0.659, val_loss=0.667]Epoch 27:   3%|▎         | 27/1000 [31:30<15:15:03, 56.43s/it, lr=0.00025, test_MAE=0.729, time=51.3, train_MAE=0.331, train_loss=0.339, val_MAE=0.67, val_loss=0.678]Epoch 27:   3%|▎         | 28/1000 [31:30<14:49:17, 54.89s/it, lr=0.00025, test_MAE=0.729, time=51.3, train_MAE=0.331, train_loss=0.339, val_MAE=0.67, val_loss=0.678]Epoch 28:   3%|▎         | 28/1000 [31:30<14:49:17, 54.89s/it, lr=0.00025, test_MAE=0.729, time=51.3, train_MAE=0.331, train_loss=0.339, val_MAE=0.67, val_loss=0.678]Epoch 28:   3%|▎         | 28/1000 [32:21<14:49:17, 54.89s/it, lr=0.00025, test_MAE=0.759, time=51, train_MAE=0.334, train_loss=0.342, val_MAE=0.727, val_loss=0.735] Epoch    29: reducing learning rate of group 0 to 1.2500e-04.
Epoch 28:   3%|▎         | 29/1000 [32:21<14:29:45, 53.74s/it, lr=0.00025, test_MAE=0.759, time=51, train_MAE=0.334, train_loss=0.342, val_MAE=0.727, val_loss=0.735]Epoch 29:   3%|▎         | 29/1000 [32:21<14:29:45, 53.74s/it, lr=0.00025, test_MAE=0.759, time=51, train_MAE=0.334, train_loss=0.342, val_MAE=0.727, val_loss=0.735]Epoch 29:   3%|▎         | 29/1000 [33:13<14:29:45, 53.74s/it, lr=0.000125, test_MAE=0.708, time=52, train_MAE=0.321, train_loss=0.329, val_MAE=0.661, val_loss=0.669]Epoch 29:   3%|▎         | 30/1000 [33:13<14:20:34, 53.23s/it, lr=0.000125, test_MAE=0.708, time=52, train_MAE=0.321, train_loss=0.329, val_MAE=0.661, val_loss=0.669]Epoch 30:   3%|▎         | 30/1000 [33:13<14:20:34, 53.23s/it, lr=0.000125, test_MAE=0.708, time=52, train_MAE=0.321, train_loss=0.329, val_MAE=0.661, val_loss=0.669]Epoch 30:   3%|▎         | 30/1000 [34:04<14:20:34, 53.23s/it, lr=0.000125, test_MAE=0.72, time=51.3, train_MAE=0.304, train_loss=0.311, val_MAE=0.671, val_loss=0.678]Epoch 30:   3%|▎         | 31/1000 [34:04<14:10:26, 52.66s/it, lr=0.000125, test_MAE=0.72, time=51.3, train_MAE=0.304, train_loss=0.311, val_MAE=0.671, val_loss=0.678]Epoch 31:   3%|▎         | 31/1000 [34:04<14:10:26, 52.66s/it, lr=0.000125, test_MAE=0.72, time=51.3, train_MAE=0.304, train_loss=0.311, val_MAE=0.671, val_loss=0.678]Epoch 31:   3%|▎         | 31/1000 [34:55<14:10:26, 52.66s/it, lr=0.000125, test_MAE=0.716, time=50.4, train_MAE=0.315, train_loss=0.323, val_MAE=0.665, val_loss=0.673]Epoch 31:   3%|▎         | 32/1000 [34:55<13:58:43, 51.99s/it, lr=0.000125, test_MAE=0.716, time=50.4, train_MAE=0.315, train_loss=0.323, val_MAE=0.665, val_loss=0.673]Epoch 32:   3%|▎         | 32/1000 [34:55<13:58:43, 51.99s/it, lr=0.000125, test_MAE=0.716, time=50.4, train_MAE=0.315, train_loss=0.323, val_MAE=0.665, val_loss=0.673]Epoch 32:   3%|▎         | 32/1000 [35:45<13:58:43, 51.99s/it, lr=0.000125, test_MAE=0.725, time=50.4, train_MAE=0.312, train_loss=0.32, val_MAE=0.679, val_loss=0.687] Epoch 32:   3%|▎         | 33/1000 [35:45<13:50:25, 51.53s/it, lr=0.000125, test_MAE=0.725, time=50.4, train_MAE=0.312, train_loss=0.32, val_MAE=0.679, val_loss=0.687]Epoch 33:   3%|▎         | 33/1000 [35:45<13:50:25, 51.53s/it, lr=0.000125, test_MAE=0.725, time=50.4, train_MAE=0.312, train_loss=0.32, val_MAE=0.679, val_loss=0.687]Epoch 33:   3%|▎         | 33/1000 [36:35<13:50:25, 51.53s/it, lr=0.000125, test_MAE=0.715, time=49.5, train_MAE=0.303, train_loss=0.31, val_MAE=0.667, val_loss=0.675]Epoch 33:   3%|▎         | 34/1000 [36:35<13:39:37, 50.91s/it, lr=0.000125, test_MAE=0.715, time=49.5, train_MAE=0.303, train_loss=0.31, val_MAE=0.667, val_loss=0.675]Epoch 34:   3%|▎         | 34/1000 [36:35<13:39:37, 50.91s/it, lr=0.000125, test_MAE=0.715, time=49.5, train_MAE=0.303, train_loss=0.31, val_MAE=0.667, val_loss=0.675]Epoch 34:   3%|▎         | 34/1000 [37:23<13:39:37, 50.91s/it, lr=0.000125, test_MAE=0.716, time=48.2, train_MAE=0.297, train_loss=0.305, val_MAE=0.668, val_loss=0.676]Epoch    35: reducing learning rate of group 0 to 6.2500e-05.
Epoch 34:   4%|▎         | 35/1000 [37:23<13:25:48, 50.10s/it, lr=0.000125, test_MAE=0.716, time=48.2, train_MAE=0.297, train_loss=0.305, val_MAE=0.668, val_loss=0.676]Epoch 35:   4%|▎         | 35/1000 [37:23<13:25:48, 50.10s/it, lr=0.000125, test_MAE=0.716, time=48.2, train_MAE=0.297, train_loss=0.305, val_MAE=0.668, val_loss=0.676]Epoch 35:   4%|▎         | 35/1000 [38:11<13:25:48, 50.10s/it, lr=6.25e-5, test_MAE=0.715, time=48.4, train_MAE=0.285, train_loss=0.293, val_MAE=0.666, val_loss=0.673] Epoch 35:   4%|▎         | 36/1000 [38:11<13:16:43, 49.59s/it, lr=6.25e-5, test_MAE=0.715, time=48.4, train_MAE=0.285, train_loss=0.293, val_MAE=0.666, val_loss=0.673]Epoch 36:   4%|▎         | 36/1000 [38:11<13:16:43, 49.59s/it, lr=6.25e-5, test_MAE=0.715, time=48.4, train_MAE=0.285, train_loss=0.293, val_MAE=0.666, val_loss=0.673]Epoch 36:   4%|▎         | 36/1000 [38:59<13:16:43, 49.59s/it, lr=6.25e-5, test_MAE=0.719, time=47.9, train_MAE=0.285, train_loss=0.293, val_MAE=0.672, val_loss=0.68] Epoch 36:   4%|▎         | 37/1000 [38:59<13:07:55, 49.09s/it, lr=6.25e-5, test_MAE=0.719, time=47.9, train_MAE=0.285, train_loss=0.293, val_MAE=0.672, val_loss=0.68]Epoch 37:   4%|▎         | 37/1000 [38:59<13:07:55, 49.09s/it, lr=6.25e-5, test_MAE=0.719, time=47.9, train_MAE=0.285, train_loss=0.293, val_MAE=0.672, val_loss=0.68]Epoch 37:   4%|▎         | 37/1000 [39:47<13:07:55, 49.09s/it, lr=6.25e-5, test_MAE=0.712, time=47.6, train_MAE=0.283, train_loss=0.291, val_MAE=0.663, val_loss=0.67]Epoch 37:   4%|▍         | 38/1000 [39:47<12:59:52, 48.64s/it, lr=6.25e-5, test_MAE=0.712, time=47.6, train_MAE=0.283, train_loss=0.291, val_MAE=0.663, val_loss=0.67]Epoch 38:   4%|▍         | 38/1000 [39:47<12:59:52, 48.64s/it, lr=6.25e-5, test_MAE=0.712, time=47.6, train_MAE=0.283, train_loss=0.291, val_MAE=0.663, val_loss=0.67]Epoch 38:   4%|▍         | 38/1000 [40:35<12:59:52, 48.64s/it, lr=6.25e-5, test_MAE=0.716, time=48.1, train_MAE=0.283, train_loss=0.29, val_MAE=0.669, val_loss=0.677]Epoch 38:   4%|▍         | 39/1000 [40:35<12:56:30, 48.48s/it, lr=6.25e-5, test_MAE=0.716, time=48.1, train_MAE=0.283, train_loss=0.29, val_MAE=0.669, val_loss=0.677]Epoch 39:   4%|▍         | 39/1000 [40:35<12:56:30, 48.48s/it, lr=6.25e-5, test_MAE=0.716, time=48.1, train_MAE=0.283, train_loss=0.29, val_MAE=0.669, val_loss=0.677]Epoch 39:   4%|▍         | 39/1000 [41:23<12:56:30, 48.48s/it, lr=6.25e-5, test_MAE=0.716, time=47.7, train_MAE=0.281, train_loss=0.289, val_MAE=0.665, val_loss=0.672]Epoch 39:   4%|▍         | 40/1000 [41:23<12:52:06, 48.26s/it, lr=6.25e-5, test_MAE=0.716, time=47.7, train_MAE=0.281, train_loss=0.289, val_MAE=0.665, val_loss=0.672]Epoch 40:   4%|▍         | 40/1000 [41:23<12:52:06, 48.26s/it, lr=6.25e-5, test_MAE=0.716, time=47.7, train_MAE=0.281, train_loss=0.289, val_MAE=0.665, val_loss=0.672]Epoch 40:   4%|▍         | 40/1000 [42:10<12:52:06, 48.26s/it, lr=6.25e-5, test_MAE=0.718, time=47.6, train_MAE=0.286, train_loss=0.293, val_MAE=0.665, val_loss=0.673]Epoch    41: reducing learning rate of group 0 to 3.1250e-05.
Epoch 40:   4%|▍         | 41/1000 [42:10<12:48:00, 48.05s/it, lr=6.25e-5, test_MAE=0.718, time=47.6, train_MAE=0.286, train_loss=0.293, val_MAE=0.665, val_loss=0.673]Epoch 41:   4%|▍         | 41/1000 [42:10<12:48:00, 48.05s/it, lr=6.25e-5, test_MAE=0.718, time=47.6, train_MAE=0.286, train_loss=0.293, val_MAE=0.665, val_loss=0.673]Epoch 41:   4%|▍         | 41/1000 [42:58<12:48:00, 48.05s/it, lr=3.13e-5, test_MAE=0.716, time=47.7, train_MAE=0.267, train_loss=0.275, val_MAE=0.667, val_loss=0.675]Epoch 41:   4%|▍         | 42/1000 [42:58<12:45:35, 47.95s/it, lr=3.13e-5, test_MAE=0.716, time=47.7, train_MAE=0.267, train_loss=0.275, val_MAE=0.667, val_loss=0.675]Epoch 42:   4%|▍         | 42/1000 [42:58<12:45:35, 47.95s/it, lr=3.13e-5, test_MAE=0.716, time=47.7, train_MAE=0.267, train_loss=0.275, val_MAE=0.667, val_loss=0.675]Epoch 42:   4%|▍         | 42/1000 [43:45<12:45:35, 47.95s/it, lr=3.13e-5, test_MAE=0.723, time=47.1, train_MAE=0.277, train_loss=0.285, val_MAE=0.675, val_loss=0.682]Epoch 42:   4%|▍         | 43/1000 [43:45<12:40:43, 47.69s/it, lr=3.13e-5, test_MAE=0.723, time=47.1, train_MAE=0.277, train_loss=0.285, val_MAE=0.675, val_loss=0.682]Epoch 43:   4%|▍         | 43/1000 [43:45<12:40:43, 47.69s/it, lr=3.13e-5, test_MAE=0.723, time=47.1, train_MAE=0.277, train_loss=0.285, val_MAE=0.675, val_loss=0.682]Epoch 43:   4%|▍         | 43/1000 [44:33<12:40:43, 47.69s/it, lr=3.13e-5, test_MAE=0.716, time=48.3, train_MAE=0.274, train_loss=0.281, val_MAE=0.667, val_loss=0.675]Epoch 43:   4%|▍         | 44/1000 [44:33<12:42:46, 47.87s/it, lr=3.13e-5, test_MAE=0.716, time=48.3, train_MAE=0.274, train_loss=0.281, val_MAE=0.667, val_loss=0.675]Epoch 44:   4%|▍         | 44/1000 [44:33<12:42:46, 47.87s/it, lr=3.13e-5, test_MAE=0.716, time=48.3, train_MAE=0.274, train_loss=0.281, val_MAE=0.667, val_loss=0.675]Epoch 44:   4%|▍         | 44/1000 [45:21<12:42:46, 47.87s/it, lr=3.13e-5, test_MAE=0.721, time=48.1, train_MAE=0.263, train_loss=0.271, val_MAE=0.676, val_loss=0.684]Epoch 44:   4%|▍         | 45/1000 [45:21<12:42:56, 47.93s/it, lr=3.13e-5, test_MAE=0.721, time=48.1, train_MAE=0.263, train_loss=0.271, val_MAE=0.676, val_loss=0.684]Epoch 45:   4%|▍         | 45/1000 [45:21<12:42:56, 47.93s/it, lr=3.13e-5, test_MAE=0.721, time=48.1, train_MAE=0.263, train_loss=0.271, val_MAE=0.676, val_loss=0.684]Epoch 45:   4%|▍         | 45/1000 [46:10<12:42:56, 47.93s/it, lr=3.13e-5, test_MAE=0.717, time=48.3, train_MAE=0.257, train_loss=0.265, val_MAE=0.669, val_loss=0.676]Epoch 45:   5%|▍         | 46/1000 [46:10<12:43:59, 48.05s/it, lr=3.13e-5, test_MAE=0.717, time=48.3, train_MAE=0.257, train_loss=0.265, val_MAE=0.669, val_loss=0.676]Epoch 46:   5%|▍         | 46/1000 [46:10<12:43:59, 48.05s/it, lr=3.13e-5, test_MAE=0.717, time=48.3, train_MAE=0.257, train_loss=0.265, val_MAE=0.669, val_loss=0.676]Epoch 46:   5%|▍         | 46/1000 [46:58<12:43:59, 48.05s/it, lr=3.13e-5, test_MAE=0.719, time=48.4, train_MAE=0.26, train_loss=0.268, val_MAE=0.672, val_loss=0.68]  Epoch    47: reducing learning rate of group 0 to 1.5625e-05.
Epoch 46:   5%|▍         | 47/1000 [46:58<12:44:44, 48.15s/it, lr=3.13e-5, test_MAE=0.719, time=48.4, train_MAE=0.26, train_loss=0.268, val_MAE=0.672, val_loss=0.68]Epoch 47:   5%|▍         | 47/1000 [46:58<12:44:44, 48.15s/it, lr=3.13e-5, test_MAE=0.719, time=48.4, train_MAE=0.26, train_loss=0.268, val_MAE=0.672, val_loss=0.68]Epoch 47:   5%|▍         | 47/1000 [47:46<12:44:44, 48.15s/it, lr=1.56e-5, test_MAE=0.72, time=47.9, train_MAE=0.258, train_loss=0.266, val_MAE=0.671, val_loss=0.678]Epoch 47:   5%|▍         | 48/1000 [47:46<12:42:48, 48.08s/it, lr=1.56e-5, test_MAE=0.72, time=47.9, train_MAE=0.258, train_loss=0.266, val_MAE=0.671, val_loss=0.678]Epoch 48:   5%|▍         | 48/1000 [47:46<12:42:48, 48.08s/it, lr=1.56e-5, test_MAE=0.72, time=47.9, train_MAE=0.258, train_loss=0.266, val_MAE=0.671, val_loss=0.678]Epoch 48:   5%|▍         | 48/1000 [48:34<12:42:48, 48.08s/it, lr=1.56e-5, test_MAE=0.732, time=47.6, train_MAE=0.268, train_loss=0.275, val_MAE=0.689, val_loss=0.697]Epoch 48:   5%|▍         | 49/1000 [48:34<12:39:57, 47.95s/it, lr=1.56e-5, test_MAE=0.732, time=47.6, train_MAE=0.268, train_loss=0.275, val_MAE=0.689, val_loss=0.697]Epoch 49:   5%|▍         | 49/1000 [48:34<12:39:57, 47.95s/it, lr=1.56e-5, test_MAE=0.732, time=47.6, train_MAE=0.268, train_loss=0.275, val_MAE=0.689, val_loss=0.697]Epoch 49:   5%|▍         | 49/1000 [49:22<12:39:57, 47.95s/it, lr=1.56e-5, test_MAE=0.717, time=48.4, train_MAE=0.253, train_loss=0.261, val_MAE=0.669, val_loss=0.676]Epoch 49:   5%|▌         | 50/1000 [49:22<12:41:32, 48.10s/it, lr=1.56e-5, test_MAE=0.717, time=48.4, train_MAE=0.253, train_loss=0.261, val_MAE=0.669, val_loss=0.676]Epoch 50:   5%|▌         | 50/1000 [49:22<12:41:32, 48.10s/it, lr=1.56e-5, test_MAE=0.717, time=48.4, train_MAE=0.253, train_loss=0.261, val_MAE=0.669, val_loss=0.676]Epoch 50:   5%|▌         | 50/1000 [50:10<12:41:32, 48.10s/it, lr=1.56e-5, test_MAE=0.723, time=47.9, train_MAE=0.263, train_loss=0.27, val_MAE=0.675, val_loss=0.683] Epoch 50:   5%|▌         | 51/1000 [50:10<12:39:41, 48.03s/it, lr=1.56e-5, test_MAE=0.723, time=47.9, train_MAE=0.263, train_loss=0.27, val_MAE=0.675, val_loss=0.683]Epoch 51:   5%|▌         | 51/1000 [50:10<12:39:41, 48.03s/it, lr=1.56e-5, test_MAE=0.723, time=47.9, train_MAE=0.263, train_loss=0.27, val_MAE=0.675, val_loss=0.683]Epoch 51:   5%|▌         | 51/1000 [50:58<12:39:41, 48.03s/it, lr=1.56e-5, test_MAE=0.722, time=47.6, train_MAE=0.259, train_loss=0.266, val_MAE=0.676, val_loss=0.683]Epoch 51:   5%|▌         | 52/1000 [50:58<12:36:49, 47.90s/it, lr=1.56e-5, test_MAE=0.722, time=47.6, train_MAE=0.259, train_loss=0.266, val_MAE=0.676, val_loss=0.683]Epoch 52:   5%|▌         | 52/1000 [50:58<12:36:49, 47.90s/it, lr=1.56e-5, test_MAE=0.722, time=47.6, train_MAE=0.259, train_loss=0.266, val_MAE=0.676, val_loss=0.683]Epoch 52:   5%|▌         | 52/1000 [51:46<12:36:49, 47.90s/it, lr=1.56e-5, test_MAE=0.718, time=48.3, train_MAE=0.254, train_loss=0.261, val_MAE=0.668, val_loss=0.676]Epoch    53: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 52:   5%|▌         | 52/1000 [51:46<15:43:50, 59.74s/it, lr=1.56e-5, test_MAE=0.718, time=48.3, train_MAE=0.254, train_loss=0.261, val_MAE=0.668, val_loss=0.676]
Test MAE: 0.7179
Train MAE: 0.2218
Convergence Time (Epochs): 52.0000
TOTAL TIME TAKEN: 3138.9053s
AVG TIME PER EPOCH: 58.5982s
