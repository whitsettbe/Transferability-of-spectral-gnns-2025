I'm echoing to stdout
I'm echoing to stderr
My JobID is 56809628
I have 8 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.0633s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 16, 'out_dim': 16, 'residual': True, 'readout': 'mean', 'k': 2, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'parallel_dense_simp', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_all', 'num_eigs': 64, 'bias_mode': '', 'eigval_hidden_dim': 5, 'eigval_num_hidden_layer': 3, 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 0.0, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/zinc_train_rec_full.csv', 'test': 'supp_data/molecules/zinc_test_rec_full.csv', 'val': 'supp_data/molecules/zinc_val_rec_full.csv'}, 'fixMissingPhi1': False, 'extraOrtho': True, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [03:11<?, ?it/s, lr=0.001, test_MAE=1.55, time=191, train_MAE=1.49, train_loss=1.49, val_MAE=1.45, val_loss=1.45]Epoch 0:   0%|          | 1/1000 [03:11<53:05:53, 191.34s/it, lr=0.001, test_MAE=1.55, time=191, train_MAE=1.49, train_loss=1.49, val_MAE=1.45, val_loss=1.45]Epoch 1:   0%|          | 1/1000 [03:11<53:05:53, 191.34s/it, lr=0.001, test_MAE=1.55, time=191, train_MAE=1.49, train_loss=1.49, val_MAE=1.45, val_loss=1.45]Epoch 1:   0%|          | 1/1000 [03:57<53:05:53, 191.34s/it, lr=0.001, test_MAE=1.31, time=45.7, train_MAE=1.24, train_loss=1.24, val_MAE=1.23, val_loss=1.23]Epoch 1:   0%|          | 2/1000 [03:57<40:56:00, 147.66s/it, lr=0.001, test_MAE=1.31, time=45.7, train_MAE=1.24, train_loss=1.24, val_MAE=1.23, val_loss=1.23]Epoch 2:   0%|          | 2/1000 [03:57<40:56:00, 147.66s/it, lr=0.001, test_MAE=1.31, time=45.7, train_MAE=1.24, train_loss=1.24, val_MAE=1.23, val_loss=1.23]Epoch 2:   0%|          | 2/1000 [04:42<40:56:00, 147.66s/it, lr=0.001, test_MAE=0.782, time=45.4, train_MAE=0.847, train_loss=0.847, val_MAE=0.739, val_loss=0.739]Epoch 2:   0%|          | 3/1000 [04:42<32:23:49, 116.98s/it, lr=0.001, test_MAE=0.782, time=45.4, train_MAE=0.847, train_loss=0.847, val_MAE=0.739, val_loss=0.739]Epoch 3:   0%|          | 3/1000 [04:42<32:23:49, 116.98s/it, lr=0.001, test_MAE=0.782, time=45.4, train_MAE=0.847, train_loss=0.847, val_MAE=0.739, val_loss=0.739]Epoch 3:   0%|          | 3/1000 [05:28<32:23:49, 116.98s/it, lr=0.001, test_MAE=1.06, time=45.7, train_MAE=0.705, train_loss=0.705, val_MAE=1.02, val_loss=1.02]   Epoch 3:   0%|          | 4/1000 [05:28<26:26:50, 95.59s/it, lr=0.001, test_MAE=1.06, time=45.7, train_MAE=0.705, train_loss=0.705, val_MAE=1.02, val_loss=1.02] Epoch 4:   0%|          | 4/1000 [05:28<26:26:50, 95.59s/it, lr=0.001, test_MAE=1.06, time=45.7, train_MAE=0.705, train_loss=0.705, val_MAE=1.02, val_loss=1.02]Epoch 4:   0%|          | 4/1000 [06:13<26:26:50, 95.59s/it, lr=0.001, test_MAE=0.801, time=45.8, train_MAE=0.672, train_loss=0.672, val_MAE=0.738, val_loss=0.738]Epoch 4:   0%|          | 5/1000 [06:13<22:17:39, 80.66s/it, lr=0.001, test_MAE=0.801, time=45.8, train_MAE=0.672, train_loss=0.672, val_MAE=0.738, val_loss=0.738]Epoch 5:   0%|          | 5/1000 [06:13<22:17:39, 80.66s/it, lr=0.001, test_MAE=0.801, time=45.8, train_MAE=0.672, train_loss=0.672, val_MAE=0.738, val_loss=0.738]Epoch 5:   0%|          | 5/1000 [06:59<22:17:39, 80.66s/it, lr=0.001, test_MAE=0.761, time=45.6, train_MAE=0.671, train_loss=0.671, val_MAE=0.715, val_loss=0.715]Epoch 5:   1%|          | 6/1000 [06:59<19:22:11, 70.15s/it, lr=0.001, test_MAE=0.761, time=45.6, train_MAE=0.671, train_loss=0.671, val_MAE=0.715, val_loss=0.715]Epoch 6:   1%|          | 6/1000 [06:59<19:22:11, 70.15s/it, lr=0.001, test_MAE=0.761, time=45.6, train_MAE=0.671, train_loss=0.671, val_MAE=0.715, val_loss=0.715]Epoch 6:   1%|          | 6/1000 [07:45<19:22:11, 70.15s/it, lr=0.001, test_MAE=1.15, time=46.1, train_MAE=0.658, train_loss=0.658, val_MAE=1.14, val_loss=1.14]   Epoch 6:   1%|          | 7/1000 [07:45<17:21:40, 62.94s/it, lr=0.001, test_MAE=1.15, time=46.1, train_MAE=0.658, train_loss=0.658, val_MAE=1.14, val_loss=1.14]Epoch 7:   1%|          | 7/1000 [07:45<17:21:40, 62.94s/it, lr=0.001, test_MAE=1.15, time=46.1, train_MAE=0.658, train_loss=0.658, val_MAE=1.14, val_loss=1.14]Epoch 7:   1%|          | 7/1000 [08:31<17:21:40, 62.94s/it, lr=0.001, test_MAE=1.57, time=45.5, train_MAE=0.64, train_loss=0.64, val_MAE=1.52, val_loss=1.52]  Epoch 7:   1%|          | 8/1000 [08:31<15:54:33, 57.73s/it, lr=0.001, test_MAE=1.57, time=45.5, train_MAE=0.64, train_loss=0.64, val_MAE=1.52, val_loss=1.52]Epoch 8:   1%|          | 8/1000 [08:31<15:54:33, 57.73s/it, lr=0.001, test_MAE=1.57, time=45.5, train_MAE=0.64, train_loss=0.64, val_MAE=1.52, val_loss=1.52]Epoch 8:   1%|          | 8/1000 [09:17<15:54:33, 57.73s/it, lr=0.001, test_MAE=1.03, time=45.8, train_MAE=0.625, train_loss=0.625, val_MAE=0.978, val_loss=0.978]Epoch 8:   1%|          | 9/1000 [09:17<14:54:21, 54.15s/it, lr=0.001, test_MAE=1.03, time=45.8, train_MAE=0.625, train_loss=0.625, val_MAE=0.978, val_loss=0.978]Epoch 9:   1%|          | 9/1000 [09:17<14:54:21, 54.15s/it, lr=0.001, test_MAE=1.03, time=45.8, train_MAE=0.625, train_loss=0.625, val_MAE=0.978, val_loss=0.978]Epoch 9:   1%|          | 9/1000 [10:03<14:54:21, 54.15s/it, lr=0.001, test_MAE=0.719, time=46.3, train_MAE=0.626, train_loss=0.626, val_MAE=0.667, val_loss=0.667]Epoch 9:   1%|          | 10/1000 [10:03<14:14:42, 51.80s/it, lr=0.001, test_MAE=0.719, time=46.3, train_MAE=0.626, train_loss=0.626, val_MAE=0.667, val_loss=0.667]Epoch 10:   1%|          | 10/1000 [10:03<14:14:42, 51.80s/it, lr=0.001, test_MAE=0.719, time=46.3, train_MAE=0.626, train_loss=0.626, val_MAE=0.667, val_loss=0.667]Epoch 10:   1%|          | 10/1000 [10:49<14:14:42, 51.80s/it, lr=0.001, test_MAE=0.988, time=45.7, train_MAE=0.631, train_loss=0.631, val_MAE=0.972, val_loss=0.972]Epoch 10:   1%|          | 11/1000 [10:49<13:43:53, 49.98s/it, lr=0.001, test_MAE=0.988, time=45.7, train_MAE=0.631, train_loss=0.631, val_MAE=0.972, val_loss=0.972]Epoch 11:   1%|          | 11/1000 [10:49<13:43:53, 49.98s/it, lr=0.001, test_MAE=0.988, time=45.7, train_MAE=0.631, train_loss=0.631, val_MAE=0.972, val_loss=0.972]Epoch 11:   1%|          | 11/1000 [11:34<13:43:53, 49.98s/it, lr=0.001, test_MAE=0.714, time=45.2, train_MAE=0.612, train_loss=0.612, val_MAE=0.678, val_loss=0.678]Epoch 11:   1%|          | 12/1000 [11:34<13:19:42, 48.57s/it, lr=0.001, test_MAE=0.714, time=45.2, train_MAE=0.612, train_loss=0.612, val_MAE=0.678, val_loss=0.678]Epoch 12:   1%|          | 12/1000 [11:34<13:19:42, 48.57s/it, lr=0.001, test_MAE=0.714, time=45.2, train_MAE=0.612, train_loss=0.612, val_MAE=0.678, val_loss=0.678]Epoch 12:   1%|          | 12/1000 [12:20<13:19:42, 48.57s/it, lr=0.001, test_MAE=0.882, time=45.7, train_MAE=0.613, train_loss=0.613, val_MAE=0.854, val_loss=0.854]Epoch 12:   1%|▏         | 13/1000 [12:20<13:04:46, 47.71s/it, lr=0.001, test_MAE=0.882, time=45.7, train_MAE=0.613, train_loss=0.613, val_MAE=0.854, val_loss=0.854]Epoch 13:   1%|▏         | 13/1000 [12:20<13:04:46, 47.71s/it, lr=0.001, test_MAE=0.882, time=45.7, train_MAE=0.613, train_loss=0.613, val_MAE=0.854, val_loss=0.854]Epoch 13:   1%|▏         | 13/1000 [13:05<13:04:46, 47.71s/it, lr=0.001, test_MAE=0.739, time=45.8, train_MAE=0.606, train_loss=0.606, val_MAE=0.693, val_loss=0.693]Epoch 13:   1%|▏         | 14/1000 [13:05<12:54:52, 47.15s/it, lr=0.001, test_MAE=0.739, time=45.8, train_MAE=0.606, train_loss=0.606, val_MAE=0.693, val_loss=0.693]Epoch 14:   1%|▏         | 14/1000 [13:05<12:54:52, 47.15s/it, lr=0.001, test_MAE=0.739, time=45.8, train_MAE=0.606, train_loss=0.606, val_MAE=0.693, val_loss=0.693]Epoch 14:   1%|▏         | 14/1000 [13:51<12:54:52, 47.15s/it, lr=0.001, test_MAE=0.766, time=45.4, train_MAE=0.6, train_loss=0.6, val_MAE=0.713, val_loss=0.713]    Epoch 14:   2%|▏         | 15/1000 [13:51<12:45:41, 46.64s/it, lr=0.001, test_MAE=0.766, time=45.4, train_MAE=0.6, train_loss=0.6, val_MAE=0.713, val_loss=0.713]Epoch 15:   2%|▏         | 15/1000 [13:51<12:45:41, 46.64s/it, lr=0.001, test_MAE=0.766, time=45.4, train_MAE=0.6, train_loss=0.6, val_MAE=0.713, val_loss=0.713]Epoch 15:   2%|▏         | 15/1000 [14:37<12:45:41, 46.64s/it, lr=0.001, test_MAE=0.754, time=45.8, train_MAE=0.596, train_loss=0.596, val_MAE=0.726, val_loss=0.726]Epoch    16: reducing learning rate of group 0 to 5.0000e-04.
Epoch 15:   2%|▏         | 16/1000 [14:37<12:41:03, 46.41s/it, lr=0.001, test_MAE=0.754, time=45.8, train_MAE=0.596, train_loss=0.596, val_MAE=0.726, val_loss=0.726]Epoch 16:   2%|▏         | 16/1000 [14:37<12:41:03, 46.41s/it, lr=0.001, test_MAE=0.754, time=45.8, train_MAE=0.596, train_loss=0.596, val_MAE=0.726, val_loss=0.726]Epoch 16:   2%|▏         | 16/1000 [15:22<12:41:03, 46.41s/it, lr=0.0005, test_MAE=0.69, time=45.6, train_MAE=0.593, train_loss=0.593, val_MAE=0.653, val_loss=0.653]Epoch 16:   2%|▏         | 17/1000 [15:22<12:36:29, 46.17s/it, lr=0.0005, test_MAE=0.69, time=45.6, train_MAE=0.593, train_loss=0.593, val_MAE=0.653, val_loss=0.653]Epoch 17:   2%|▏         | 17/1000 [15:22<12:36:29, 46.17s/it, lr=0.0005, test_MAE=0.69, time=45.6, train_MAE=0.593, train_loss=0.593, val_MAE=0.653, val_loss=0.653]Epoch 17:   2%|▏         | 17/1000 [16:07<12:36:29, 46.17s/it, lr=0.0005, test_MAE=0.745, time=45, train_MAE=0.587, train_loss=0.587, val_MAE=0.725, val_loss=0.725] Epoch 17:   2%|▏         | 18/1000 [16:08<12:30:32, 45.86s/it, lr=0.0005, test_MAE=0.745, time=45, train_MAE=0.587, train_loss=0.587, val_MAE=0.725, val_loss=0.725]Epoch 18:   2%|▏         | 18/1000 [16:08<12:30:32, 45.86s/it, lr=0.0005, test_MAE=0.745, time=45, train_MAE=0.587, train_loss=0.587, val_MAE=0.725, val_loss=0.725]Epoch 18:   2%|▏         | 18/1000 [16:53<12:30:32, 45.86s/it, lr=0.0005, test_MAE=0.71, time=45.8, train_MAE=0.573, train_loss=0.573, val_MAE=0.664, val_loss=0.664]Epoch 18:   2%|▏         | 19/1000 [16:53<12:29:34, 45.85s/it, lr=0.0005, test_MAE=0.71, time=45.8, train_MAE=0.573, train_loss=0.573, val_MAE=0.664, val_loss=0.664]Epoch 19:   2%|▏         | 19/1000 [16:53<12:29:34, 45.85s/it, lr=0.0005, test_MAE=0.71, time=45.8, train_MAE=0.573, train_loss=0.573, val_MAE=0.664, val_loss=0.664]Epoch 19:   2%|▏         | 19/1000 [17:39<12:29:34, 45.85s/it, lr=0.0005, test_MAE=0.7, time=45.4, train_MAE=0.571, train_loss=0.571, val_MAE=0.658, val_loss=0.658] Epoch 19:   2%|▏         | 20/1000 [17:39<12:26:41, 45.72s/it, lr=0.0005, test_MAE=0.7, time=45.4, train_MAE=0.571, train_loss=0.571, val_MAE=0.658, val_loss=0.658]Epoch 20:   2%|▏         | 20/1000 [17:39<12:26:41, 45.72s/it, lr=0.0005, test_MAE=0.7, time=45.4, train_MAE=0.571, train_loss=0.571, val_MAE=0.658, val_loss=0.658]Epoch 20:   2%|▏         | 20/1000 [18:24<12:26:41, 45.72s/it, lr=0.0005, test_MAE=0.82, time=45.4, train_MAE=0.573, train_loss=0.573, val_MAE=0.798, val_loss=0.798]Epoch 20:   2%|▏         | 21/1000 [18:24<12:24:17, 45.62s/it, lr=0.0005, test_MAE=0.82, time=45.4, train_MAE=0.573, train_loss=0.573, val_MAE=0.798, val_loss=0.798]Epoch 21:   2%|▏         | 21/1000 [18:24<12:24:17, 45.62s/it, lr=0.0005, test_MAE=0.82, time=45.4, train_MAE=0.573, train_loss=0.573, val_MAE=0.798, val_loss=0.798]Epoch 21:   2%|▏         | 21/1000 [19:10<12:24:17, 45.62s/it, lr=0.0005, test_MAE=0.827, time=45.8, train_MAE=0.579, train_loss=0.579, val_MAE=0.781, val_loss=0.781]Epoch 21:   2%|▏         | 22/1000 [19:10<12:24:47, 45.69s/it, lr=0.0005, test_MAE=0.827, time=45.8, train_MAE=0.579, train_loss=0.579, val_MAE=0.781, val_loss=0.781]Epoch 22:   2%|▏         | 22/1000 [19:10<12:24:47, 45.69s/it, lr=0.0005, test_MAE=0.827, time=45.8, train_MAE=0.579, train_loss=0.579, val_MAE=0.781, val_loss=0.781]Epoch 22:   2%|▏         | 22/1000 [19:55<12:24:47, 45.69s/it, lr=0.0005, test_MAE=0.789, time=45.1, train_MAE=0.586, train_loss=0.586, val_MAE=0.769, val_loss=0.769]Epoch    23: reducing learning rate of group 0 to 2.5000e-04.
Epoch 22:   2%|▏         | 23/1000 [19:55<12:21:10, 45.52s/it, lr=0.0005, test_MAE=0.789, time=45.1, train_MAE=0.586, train_loss=0.586, val_MAE=0.769, val_loss=0.769]Epoch 23:   2%|▏         | 23/1000 [19:55<12:21:10, 45.52s/it, lr=0.0005, test_MAE=0.789, time=45.1, train_MAE=0.586, train_loss=0.586, val_MAE=0.769, val_loss=0.769]Epoch 23:   2%|▏         | 23/1000 [20:41<12:21:10, 45.52s/it, lr=0.00025, test_MAE=0.696, time=45.7, train_MAE=0.561, train_loss=0.561, val_MAE=0.657, val_loss=0.657]Epoch 23:   2%|▏         | 24/1000 [20:41<12:21:38, 45.59s/it, lr=0.00025, test_MAE=0.696, time=45.7, train_MAE=0.561, train_loss=0.561, val_MAE=0.657, val_loss=0.657]Epoch 24:   2%|▏         | 24/1000 [20:41<12:21:38, 45.59s/it, lr=0.00025, test_MAE=0.696, time=45.7, train_MAE=0.561, train_loss=0.561, val_MAE=0.657, val_loss=0.657]Epoch 24:   2%|▏         | 24/1000 [21:26<12:21:38, 45.59s/it, lr=0.00025, test_MAE=0.701, time=45.4, train_MAE=0.566, train_loss=0.566, val_MAE=0.661, val_loss=0.661]Epoch 24:   2%|▎         | 25/1000 [21:26<12:20:04, 45.54s/it, lr=0.00025, test_MAE=0.701, time=45.4, train_MAE=0.566, train_loss=0.566, val_MAE=0.661, val_loss=0.661]Epoch 25:   2%|▎         | 25/1000 [21:26<12:20:04, 45.54s/it, lr=0.00025, test_MAE=0.701, time=45.4, train_MAE=0.566, train_loss=0.566, val_MAE=0.661, val_loss=0.661]Epoch 25:   2%|▎         | 25/1000 [22:12<12:20:04, 45.54s/it, lr=0.00025, test_MAE=0.689, time=45.4, train_MAE=0.56, train_loss=0.56, val_MAE=0.65, val_loss=0.65]    Epoch 25:   3%|▎         | 26/1000 [22:12<12:18:52, 45.52s/it, lr=0.00025, test_MAE=0.689, time=45.4, train_MAE=0.56, train_loss=0.56, val_MAE=0.65, val_loss=0.65]Epoch 26:   3%|▎         | 26/1000 [22:12<12:18:52, 45.52s/it, lr=0.00025, test_MAE=0.689, time=45.4, train_MAE=0.56, train_loss=0.56, val_MAE=0.65, val_loss=0.65]Epoch 26:   3%|▎         | 26/1000 [22:58<12:18:52, 45.52s/it, lr=0.00025, test_MAE=0.796, time=45.7, train_MAE=0.559, train_loss=0.559, val_MAE=0.747, val_loss=0.747]Epoch 26:   3%|▎         | 27/1000 [22:58<12:19:23, 45.59s/it, lr=0.00025, test_MAE=0.796, time=45.7, train_MAE=0.559, train_loss=0.559, val_MAE=0.747, val_loss=0.747]Epoch 27:   3%|▎         | 27/1000 [22:58<12:19:23, 45.59s/it, lr=0.00025, test_MAE=0.796, time=45.7, train_MAE=0.559, train_loss=0.559, val_MAE=0.747, val_loss=0.747]Epoch 27:   3%|▎         | 27/1000 [23:43<12:19:23, 45.59s/it, lr=0.00025, test_MAE=0.697, time=45.6, train_MAE=0.559, train_loss=0.559, val_MAE=0.656, val_loss=0.656]Epoch 27:   3%|▎         | 28/1000 [23:43<12:18:51, 45.61s/it, lr=0.00025, test_MAE=0.697, time=45.6, train_MAE=0.559, train_loss=0.559, val_MAE=0.656, val_loss=0.656]Epoch 28:   3%|▎         | 28/1000 [23:43<12:18:51, 45.61s/it, lr=0.00025, test_MAE=0.697, time=45.6, train_MAE=0.559, train_loss=0.559, val_MAE=0.656, val_loss=0.656]Epoch 28:   3%|▎         | 28/1000 [24:28<12:18:51, 45.61s/it, lr=0.00025, test_MAE=0.697, time=45.3, train_MAE=0.557, train_loss=0.557, val_MAE=0.659, val_loss=0.659]Epoch 28:   3%|▎         | 29/1000 [24:29<12:16:41, 45.52s/it, lr=0.00025, test_MAE=0.697, time=45.3, train_MAE=0.557, train_loss=0.557, val_MAE=0.659, val_loss=0.659]Epoch 29:   3%|▎         | 29/1000 [24:29<12:16:41, 45.52s/it, lr=0.00025, test_MAE=0.697, time=45.3, train_MAE=0.557, train_loss=0.557, val_MAE=0.659, val_loss=0.659]Epoch 29:   3%|▎         | 29/1000 [25:15<12:16:41, 45.52s/it, lr=0.00025, test_MAE=0.691, time=46.2, train_MAE=0.556, train_loss=0.556, val_MAE=0.65, val_loss=0.65]  Epoch 29:   3%|▎         | 30/1000 [25:15<12:19:21, 45.73s/it, lr=0.00025, test_MAE=0.691, time=46.2, train_MAE=0.556, train_loss=0.556, val_MAE=0.65, val_loss=0.65]Epoch 30:   3%|▎         | 30/1000 [25:15<12:19:21, 45.73s/it, lr=0.00025, test_MAE=0.691, time=46.2, train_MAE=0.556, train_loss=0.556, val_MAE=0.65, val_loss=0.65]Epoch 30:   3%|▎         | 30/1000 [26:00<12:19:21, 45.73s/it, lr=0.00025, test_MAE=0.703, time=45.6, train_MAE=0.555, train_loss=0.555, val_MAE=0.66, val_loss=0.66]Epoch 30:   3%|▎         | 31/1000 [26:00<12:18:31, 45.73s/it, lr=0.00025, test_MAE=0.703, time=45.6, train_MAE=0.555, train_loss=0.555, val_MAE=0.66, val_loss=0.66]Epoch 31:   3%|▎         | 31/1000 [26:00<12:18:31, 45.73s/it, lr=0.00025, test_MAE=0.703, time=45.6, train_MAE=0.555, train_loss=0.555, val_MAE=0.66, val_loss=0.66]Epoch 31:   3%|▎         | 31/1000 [26:46<12:18:31, 45.73s/it, lr=0.00025, test_MAE=0.7, time=45.2, train_MAE=0.557, train_loss=0.557, val_MAE=0.657, val_loss=0.657]Epoch    32: reducing learning rate of group 0 to 1.2500e-04.
Epoch 31:   3%|▎         | 32/1000 [26:46<12:15:36, 45.60s/it, lr=0.00025, test_MAE=0.7, time=45.2, train_MAE=0.557, train_loss=0.557, val_MAE=0.657, val_loss=0.657]Epoch 32:   3%|▎         | 32/1000 [26:46<12:15:36, 45.60s/it, lr=0.00025, test_MAE=0.7, time=45.2, train_MAE=0.557, train_loss=0.557, val_MAE=0.657, val_loss=0.657]Epoch 32:   3%|▎         | 32/1000 [27:32<12:15:36, 45.60s/it, lr=0.000125, test_MAE=0.691, time=45.9, train_MAE=0.553, train_loss=0.553, val_MAE=0.652, val_loss=0.652]Epoch 32:   3%|▎         | 33/1000 [27:32<12:16:25, 45.69s/it, lr=0.000125, test_MAE=0.691, time=45.9, train_MAE=0.553, train_loss=0.553, val_MAE=0.652, val_loss=0.652]Epoch 33:   3%|▎         | 33/1000 [27:32<12:16:25, 45.69s/it, lr=0.000125, test_MAE=0.691, time=45.9, train_MAE=0.553, train_loss=0.553, val_MAE=0.652, val_loss=0.652]Epoch 33:   3%|▎         | 33/1000 [28:17<12:16:25, 45.69s/it, lr=0.000125, test_MAE=0.691, time=45.7, train_MAE=0.541, train_loss=0.541, val_MAE=0.654, val_loss=0.654]Epoch 33:   3%|▎         | 34/1000 [28:17<12:15:37, 45.69s/it, lr=0.000125, test_MAE=0.691, time=45.7, train_MAE=0.541, train_loss=0.541, val_MAE=0.654, val_loss=0.654]Epoch 34:   3%|▎         | 34/1000 [28:17<12:15:37, 45.69s/it, lr=0.000125, test_MAE=0.691, time=45.7, train_MAE=0.541, train_loss=0.541, val_MAE=0.654, val_loss=0.654]Epoch 34:   3%|▎         | 34/1000 [29:03<12:15:37, 45.69s/it, lr=0.000125, test_MAE=0.692, time=45.2, train_MAE=0.553, train_loss=0.553, val_MAE=0.656, val_loss=0.656]Epoch 34:   4%|▎         | 35/1000 [29:03<12:12:44, 45.56s/it, lr=0.000125, test_MAE=0.692, time=45.2, train_MAE=0.553, train_loss=0.553, val_MAE=0.656, val_loss=0.656]Epoch 35:   4%|▎         | 35/1000 [29:03<12:12:44, 45.56s/it, lr=0.000125, test_MAE=0.692, time=45.2, train_MAE=0.553, train_loss=0.553, val_MAE=0.656, val_loss=0.656]Epoch 35:   4%|▎         | 35/1000 [29:48<12:12:44, 45.56s/it, lr=0.000125, test_MAE=0.698, time=45.9, train_MAE=0.55, train_loss=0.55, val_MAE=0.661, val_loss=0.661]  Epoch 35:   4%|▎         | 36/1000 [29:48<12:13:33, 45.66s/it, lr=0.000125, test_MAE=0.698, time=45.9, train_MAE=0.55, train_loss=0.55, val_MAE=0.661, val_loss=0.661]Epoch 36:   4%|▎         | 36/1000 [29:48<12:13:33, 45.66s/it, lr=0.000125, test_MAE=0.698, time=45.9, train_MAE=0.55, train_loss=0.55, val_MAE=0.661, val_loss=0.661]Epoch 36:   4%|▎         | 36/1000 [30:34<12:13:33, 45.66s/it, lr=0.000125, test_MAE=0.691, time=45.7, train_MAE=0.546, train_loss=0.546, val_MAE=0.656, val_loss=0.656]Epoch 36:   4%|▎         | 37/1000 [30:34<12:13:00, 45.67s/it, lr=0.000125, test_MAE=0.691, time=45.7, train_MAE=0.546, train_loss=0.546, val_MAE=0.656, val_loss=0.656]Epoch 37:   4%|▎         | 37/1000 [30:34<12:13:00, 45.67s/it, lr=0.000125, test_MAE=0.691, time=45.7, train_MAE=0.546, train_loss=0.546, val_MAE=0.656, val_loss=0.656]Epoch 37:   4%|▎         | 37/1000 [31:19<12:13:00, 45.67s/it, lr=0.000125, test_MAE=0.7, time=45.2, train_MAE=0.548, train_loss=0.548, val_MAE=0.658, val_loss=0.658]  Epoch    38: reducing learning rate of group 0 to 6.2500e-05.
Epoch 37:   4%|▍         | 38/1000 [31:19<12:10:04, 45.53s/it, lr=0.000125, test_MAE=0.7, time=45.2, train_MAE=0.548, train_loss=0.548, val_MAE=0.658, val_loss=0.658]Epoch 38:   4%|▍         | 38/1000 [31:19<12:10:04, 45.53s/it, lr=0.000125, test_MAE=0.7, time=45.2, train_MAE=0.548, train_loss=0.548, val_MAE=0.658, val_loss=0.658]Epoch 38:   4%|▍         | 38/1000 [32:05<12:10:04, 45.53s/it, lr=6.25e-5, test_MAE=0.691, time=45.9, train_MAE=0.548, train_loss=0.548, val_MAE=0.652, val_loss=0.652]Epoch 38:   4%|▍         | 39/1000 [32:05<12:11:22, 45.66s/it, lr=6.25e-5, test_MAE=0.691, time=45.9, train_MAE=0.548, train_loss=0.548, val_MAE=0.652, val_loss=0.652]Epoch 39:   4%|▍         | 39/1000 [32:05<12:11:22, 45.66s/it, lr=6.25e-5, test_MAE=0.691, time=45.9, train_MAE=0.548, train_loss=0.548, val_MAE=0.652, val_loss=0.652]Epoch 39:   4%|▍         | 39/1000 [32:51<12:11:22, 45.66s/it, lr=6.25e-5, test_MAE=0.694, time=45.5, train_MAE=0.543, train_loss=0.543, val_MAE=0.656, val_loss=0.656]Epoch 39:   4%|▍         | 40/1000 [32:51<12:10:06, 45.63s/it, lr=6.25e-5, test_MAE=0.694, time=45.5, train_MAE=0.543, train_loss=0.543, val_MAE=0.656, val_loss=0.656]Epoch 40:   4%|▍         | 40/1000 [32:51<12:10:06, 45.63s/it, lr=6.25e-5, test_MAE=0.694, time=45.5, train_MAE=0.543, train_loss=0.543, val_MAE=0.656, val_loss=0.656]Epoch 40:   4%|▍         | 40/1000 [33:37<12:10:06, 45.63s/it, lr=6.25e-5, test_MAE=0.691, time=45.6, train_MAE=0.542, train_loss=0.542, val_MAE=0.65, val_loss=0.65]  Epoch 40:   4%|▍         | 41/1000 [33:37<12:09:27, 45.64s/it, lr=6.25e-5, test_MAE=0.691, time=45.6, train_MAE=0.542, train_loss=0.542, val_MAE=0.65, val_loss=0.65]Epoch 41:   4%|▍         | 41/1000 [33:37<12:09:27, 45.64s/it, lr=6.25e-5, test_MAE=0.691, time=45.6, train_MAE=0.542, train_loss=0.542, val_MAE=0.65, val_loss=0.65]Epoch 41:   4%|▍         | 41/1000 [34:23<12:09:27, 45.64s/it, lr=6.25e-5, test_MAE=0.696, time=46, train_MAE=0.543, train_loss=0.543, val_MAE=0.653, val_loss=0.653]Epoch 41:   4%|▍         | 42/1000 [34:23<12:10:42, 45.77s/it, lr=6.25e-5, test_MAE=0.696, time=46, train_MAE=0.543, train_loss=0.543, val_MAE=0.653, val_loss=0.653]Epoch 42:   4%|▍         | 42/1000 [34:23<12:10:42, 45.77s/it, lr=6.25e-5, test_MAE=0.696, time=46, train_MAE=0.543, train_loss=0.543, val_MAE=0.653, val_loss=0.653]Epoch 42:   4%|▍         | 42/1000 [35:08<12:10:42, 45.77s/it, lr=6.25e-5, test_MAE=0.693, time=45.3, train_MAE=0.545, train_loss=0.545, val_MAE=0.653, val_loss=0.653]Epoch 42:   4%|▍         | 43/1000 [35:08<12:08:02, 45.65s/it, lr=6.25e-5, test_MAE=0.693, time=45.3, train_MAE=0.545, train_loss=0.545, val_MAE=0.653, val_loss=0.653]Epoch 43:   4%|▍         | 43/1000 [35:08<12:08:02, 45.65s/it, lr=6.25e-5, test_MAE=0.693, time=45.3, train_MAE=0.545, train_loss=0.545, val_MAE=0.653, val_loss=0.653]Epoch 43:   4%|▍         | 43/1000 [35:54<12:08:02, 45.65s/it, lr=6.25e-5, test_MAE=0.693, time=46, train_MAE=0.544, train_loss=0.544, val_MAE=0.653, val_loss=0.653]  Epoch    44: reducing learning rate of group 0 to 3.1250e-05.
Epoch 43:   4%|▍         | 44/1000 [35:54<12:09:03, 45.76s/it, lr=6.25e-5, test_MAE=0.693, time=46, train_MAE=0.544, train_loss=0.544, val_MAE=0.653, val_loss=0.653]Epoch 44:   4%|▍         | 44/1000 [35:54<12:09:03, 45.76s/it, lr=6.25e-5, test_MAE=0.693, time=46, train_MAE=0.544, train_loss=0.544, val_MAE=0.653, val_loss=0.653]Epoch 44:   4%|▍         | 44/1000 [36:40<12:09:03, 45.76s/it, lr=3.13e-5, test_MAE=0.693, time=45.6, train_MAE=0.544, train_loss=0.544, val_MAE=0.654, val_loss=0.654]Epoch 44:   4%|▍         | 45/1000 [36:40<12:07:32, 45.71s/it, lr=3.13e-5, test_MAE=0.693, time=45.6, train_MAE=0.544, train_loss=0.544, val_MAE=0.654, val_loss=0.654]Epoch 45:   4%|▍         | 45/1000 [36:40<12:07:32, 45.71s/it, lr=3.13e-5, test_MAE=0.693, time=45.6, train_MAE=0.544, train_loss=0.544, val_MAE=0.654, val_loss=0.654]Epoch 45:   4%|▍         | 45/1000 [37:25<12:07:32, 45.71s/it, lr=3.13e-5, test_MAE=0.699, time=45.6, train_MAE=0.543, train_loss=0.543, val_MAE=0.656, val_loss=0.656]Epoch 45:   5%|▍         | 46/1000 [37:25<12:06:31, 45.69s/it, lr=3.13e-5, test_MAE=0.699, time=45.6, train_MAE=0.543, train_loss=0.543, val_MAE=0.656, val_loss=0.656]Epoch 46:   5%|▍         | 46/1000 [37:25<12:06:31, 45.69s/it, lr=3.13e-5, test_MAE=0.699, time=45.6, train_MAE=0.543, train_loss=0.543, val_MAE=0.656, val_loss=0.656]Epoch 46:   5%|▍         | 46/1000 [38:11<12:06:31, 45.69s/it, lr=3.13e-5, test_MAE=0.692, time=46, train_MAE=0.543, train_loss=0.543, val_MAE=0.652, val_loss=0.652]  Epoch 46:   5%|▍         | 47/1000 [38:11<12:07:23, 45.80s/it, lr=3.13e-5, test_MAE=0.692, time=46, train_MAE=0.543, train_loss=0.543, val_MAE=0.652, val_loss=0.652]Epoch 47:   5%|▍         | 47/1000 [38:11<12:07:23, 45.80s/it, lr=3.13e-5, test_MAE=0.692, time=46, train_MAE=0.543, train_loss=0.543, val_MAE=0.652, val_loss=0.652]Epoch 47:   5%|▍         | 47/1000 [38:57<12:07:23, 45.80s/it, lr=3.13e-5, test_MAE=0.7, time=45.6, train_MAE=0.541, train_loss=0.541, val_MAE=0.659, val_loss=0.659]Epoch 47:   5%|▍         | 48/1000 [38:57<12:05:55, 45.75s/it, lr=3.13e-5, test_MAE=0.7, time=45.6, train_MAE=0.541, train_loss=0.541, val_MAE=0.659, val_loss=0.659]Epoch 48:   5%|▍         | 48/1000 [38:57<12:05:55, 45.75s/it, lr=3.13e-5, test_MAE=0.7, time=45.6, train_MAE=0.541, train_loss=0.541, val_MAE=0.659, val_loss=0.659]Epoch 48:   5%|▍         | 48/1000 [39:42<12:05:55, 45.75s/it, lr=3.13e-5, test_MAE=0.694, time=45.3, train_MAE=0.545, train_loss=0.545, val_MAE=0.653, val_loss=0.653]Epoch 48:   5%|▍         | 49/1000 [39:42<12:03:14, 45.63s/it, lr=3.13e-5, test_MAE=0.694, time=45.3, train_MAE=0.545, train_loss=0.545, val_MAE=0.653, val_loss=0.653]Epoch 49:   5%|▍         | 49/1000 [39:42<12:03:14, 45.63s/it, lr=3.13e-5, test_MAE=0.694, time=45.3, train_MAE=0.545, train_loss=0.545, val_MAE=0.653, val_loss=0.653]Epoch 49:   5%|▍         | 49/1000 [40:29<12:03:14, 45.63s/it, lr=3.13e-5, test_MAE=0.693, time=46.2, train_MAE=0.545, train_loss=0.545, val_MAE=0.652, val_loss=0.652]Epoch    50: reducing learning rate of group 0 to 1.5625e-05.
Epoch 49:   5%|▌         | 50/1000 [40:29<12:05:16, 45.81s/it, lr=3.13e-5, test_MAE=0.693, time=46.2, train_MAE=0.545, train_loss=0.545, val_MAE=0.652, val_loss=0.652]Epoch 50:   5%|▌         | 50/1000 [40:29<12:05:16, 45.81s/it, lr=3.13e-5, test_MAE=0.693, time=46.2, train_MAE=0.545, train_loss=0.545, val_MAE=0.652, val_loss=0.652]Epoch 50:   5%|▌         | 50/1000 [41:14<12:05:16, 45.81s/it, lr=1.56e-5, test_MAE=0.693, time=45.6, train_MAE=0.544, train_loss=0.544, val_MAE=0.656, val_loss=0.656]Epoch 50:   5%|▌         | 51/1000 [41:14<12:03:52, 45.77s/it, lr=1.56e-5, test_MAE=0.693, time=45.6, train_MAE=0.544, train_loss=0.544, val_MAE=0.656, val_loss=0.656]Epoch 51:   5%|▌         | 51/1000 [41:14<12:03:52, 45.77s/it, lr=1.56e-5, test_MAE=0.693, time=45.6, train_MAE=0.544, train_loss=0.544, val_MAE=0.656, val_loss=0.656]Epoch 51:   5%|▌         | 51/1000 [41:59<12:03:52, 45.77s/it, lr=1.56e-5, test_MAE=0.692, time=45.2, train_MAE=0.542, train_loss=0.542, val_MAE=0.653, val_loss=0.653]Epoch 51:   5%|▌         | 52/1000 [41:59<12:00:39, 45.61s/it, lr=1.56e-5, test_MAE=0.692, time=45.2, train_MAE=0.542, train_loss=0.542, val_MAE=0.653, val_loss=0.653]Epoch 52:   5%|▌         | 52/1000 [41:59<12:00:39, 45.61s/it, lr=1.56e-5, test_MAE=0.692, time=45.2, train_MAE=0.542, train_loss=0.542, val_MAE=0.653, val_loss=0.653]Epoch 52:   5%|▌         | 52/1000 [42:46<12:00:39, 45.61s/it, lr=1.56e-5, test_MAE=0.692, time=46.1, train_MAE=0.543, train_loss=0.543, val_MAE=0.654, val_loss=0.654]Epoch 52:   5%|▌         | 53/1000 [42:46<12:02:06, 45.75s/it, lr=1.56e-5, test_MAE=0.692, time=46.1, train_MAE=0.543, train_loss=0.543, val_MAE=0.654, val_loss=0.654]Epoch 53:   5%|▌         | 53/1000 [42:46<12:02:06, 45.75s/it, lr=1.56e-5, test_MAE=0.692, time=46.1, train_MAE=0.543, train_loss=0.543, val_MAE=0.654, val_loss=0.654]Epoch 53:   5%|▌         | 53/1000 [43:31<12:02:06, 45.75s/it, lr=1.56e-5, test_MAE=0.696, time=45.7, train_MAE=0.543, train_loss=0.543, val_MAE=0.654, val_loss=0.654]Epoch 53:   5%|▌         | 54/1000 [43:31<12:01:28, 45.76s/it, lr=1.56e-5, test_MAE=0.696, time=45.7, train_MAE=0.543, train_loss=0.543, val_MAE=0.654, val_loss=0.654]Epoch 54:   5%|▌         | 54/1000 [43:31<12:01:28, 45.76s/it, lr=1.56e-5, test_MAE=0.696, time=45.7, train_MAE=0.543, train_loss=0.543, val_MAE=0.654, val_loss=0.654]Epoch 54:   5%|▌         | 54/1000 [44:17<12:01:28, 45.76s/it, lr=1.56e-5, test_MAE=0.694, time=45.3, train_MAE=0.539, train_loss=0.539, val_MAE=0.655, val_loss=0.655]Epoch 54:   6%|▌         | 55/1000 [44:17<11:58:44, 45.63s/it, lr=1.56e-5, test_MAE=0.694, time=45.3, train_MAE=0.539, train_loss=0.539, val_MAE=0.655, val_loss=0.655]Epoch 55:   6%|▌         | 55/1000 [44:17<11:58:44, 45.63s/it, lr=1.56e-5, test_MAE=0.694, time=45.3, train_MAE=0.539, train_loss=0.539, val_MAE=0.655, val_loss=0.655]Epoch 55:   6%|▌         | 55/1000 [45:03<11:58:44, 45.63s/it, lr=1.56e-5, test_MAE=0.693, time=45.9, train_MAE=0.54, train_loss=0.54, val_MAE=0.654, val_loss=0.654]  Epoch    56: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 55:   6%|▌         | 55/1000 [45:03<12:54:03, 49.15s/it, lr=1.56e-5, test_MAE=0.693, time=45.9, train_MAE=0.54, train_loss=0.54, val_MAE=0.654, val_loss=0.654]
Test MAE: 0.6935
Train MAE: 0.5164
Convergence Time (Epochs): 55.0000
TOTAL TIME TAKEN: 2734.9363s
AVG TIME PER EPOCH: 48.2343s
