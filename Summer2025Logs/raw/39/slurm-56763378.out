I'm echoing to stdout
I'm echoing to stderr
My JobID is 56763378
I have 8 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.1497s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 2, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'parallel_dense_simp', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_all', 'num_eigs': 15, 'bias_mode': '', 'eigval_hidden_dim': 5, 'eigval_num_hidden_layer': 3, 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 0.0, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/zinc_train_rec_full.csv', 'test': 'supp_data/molecules/zinc_test_rec_full.csv', 'val': 'supp_data/molecules/zinc_val_rec_full.csv'}, 'fixMissingPhi1': False, 'extraOrtho': True, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [03:15<?, ?it/s, lr=0.001, test_MAE=1.49, time=195, train_MAE=0.928, train_loss=0.928, val_MAE=1.43, val_loss=1.43]Epoch 0:   0%|          | 1/1000 [03:15<54:09:35, 195.17s/it, lr=0.001, test_MAE=1.49, time=195, train_MAE=0.928, train_loss=0.928, val_MAE=1.43, val_loss=1.43]Epoch 1:   0%|          | 1/1000 [03:15<54:09:35, 195.17s/it, lr=0.001, test_MAE=1.49, time=195, train_MAE=0.928, train_loss=0.928, val_MAE=1.43, val_loss=1.43]Epoch 1:   0%|          | 1/1000 [04:04<54:09:35, 195.17s/it, lr=0.001, test_MAE=0.816, time=49.5, train_MAE=0.678, train_loss=0.678, val_MAE=0.767, val_loss=0.767]Epoch 1:   0%|          | 2/1000 [04:04<41:59:13, 151.46s/it, lr=0.001, test_MAE=0.816, time=49.5, train_MAE=0.678, train_loss=0.678, val_MAE=0.767, val_loss=0.767]Epoch 2:   0%|          | 2/1000 [04:04<41:59:13, 151.46s/it, lr=0.001, test_MAE=0.816, time=49.5, train_MAE=0.678, train_loss=0.678, val_MAE=0.767, val_loss=0.767]Epoch 2:   0%|          | 2/1000 [04:54<41:59:13, 151.46s/it, lr=0.001, test_MAE=1.42, time=49.4, train_MAE=0.657, train_loss=0.657, val_MAE=1.37, val_loss=1.37]   Epoch 2:   0%|          | 3/1000 [04:54<33:28:10, 120.85s/it, lr=0.001, test_MAE=1.42, time=49.4, train_MAE=0.657, train_loss=0.657, val_MAE=1.37, val_loss=1.37]Epoch 3:   0%|          | 3/1000 [04:54<33:28:10, 120.85s/it, lr=0.001, test_MAE=1.42, time=49.4, train_MAE=0.657, train_loss=0.657, val_MAE=1.37, val_loss=1.37]Epoch 3:   0%|          | 3/1000 [05:43<33:28:10, 120.85s/it, lr=0.001, test_MAE=0.704, time=49.4, train_MAE=0.638, train_loss=0.638, val_MAE=0.649, val_loss=0.649]Epoch 3:   0%|          | 4/1000 [05:43<27:30:12, 99.41s/it, lr=0.001, test_MAE=0.704, time=49.4, train_MAE=0.638, train_loss=0.638, val_MAE=0.649, val_loss=0.649] Epoch 4:   0%|          | 4/1000 [05:43<27:30:12, 99.41s/it, lr=0.001, test_MAE=0.704, time=49.4, train_MAE=0.638, train_loss=0.638, val_MAE=0.649, val_loss=0.649]Epoch 4:   0%|          | 4/1000 [06:32<27:30:12, 99.41s/it, lr=0.001, test_MAE=1.12, time=49.4, train_MAE=0.621, train_loss=0.621, val_MAE=1.08, val_loss=1.08]   Epoch 4:   0%|          | 5/1000 [06:32<23:19:57, 84.42s/it, lr=0.001, test_MAE=1.12, time=49.4, train_MAE=0.621, train_loss=0.621, val_MAE=1.08, val_loss=1.08]Epoch 5:   0%|          | 5/1000 [06:32<23:19:57, 84.42s/it, lr=0.001, test_MAE=1.12, time=49.4, train_MAE=0.621, train_loss=0.621, val_MAE=1.08, val_loss=1.08]Epoch 5:   0%|          | 5/1000 [07:22<23:19:57, 84.42s/it, lr=0.001, test_MAE=0.708, time=49.4, train_MAE=0.614, train_loss=0.614, val_MAE=0.655, val_loss=0.655]Epoch 5:   1%|          | 6/1000 [07:22<20:24:45, 73.93s/it, lr=0.001, test_MAE=0.708, time=49.4, train_MAE=0.614, train_loss=0.614, val_MAE=0.655, val_loss=0.655]Epoch 6:   1%|          | 6/1000 [07:22<20:24:45, 73.93s/it, lr=0.001, test_MAE=0.708, time=49.4, train_MAE=0.614, train_loss=0.614, val_MAE=0.655, val_loss=0.655]Epoch 6:   1%|          | 6/1000 [08:12<20:24:45, 73.93s/it, lr=0.001, test_MAE=0.893, time=49.7, train_MAE=0.618, train_loss=0.618, val_MAE=0.855, val_loss=0.855]Epoch 6:   1%|          | 7/1000 [08:12<18:23:18, 66.67s/it, lr=0.001, test_MAE=0.893, time=49.7, train_MAE=0.618, train_loss=0.618, val_MAE=0.855, val_loss=0.855]Epoch 7:   1%|          | 7/1000 [08:12<18:23:18, 66.67s/it, lr=0.001, test_MAE=0.893, time=49.7, train_MAE=0.618, train_loss=0.618, val_MAE=0.855, val_loss=0.855]Epoch 7:   1%|          | 7/1000 [09:01<18:23:18, 66.67s/it, lr=0.001, test_MAE=0.878, time=49.3, train_MAE=0.598, train_loss=0.598, val_MAE=0.82, val_loss=0.82]  Epoch 7:   1%|          | 8/1000 [09:01<16:56:11, 61.46s/it, lr=0.001, test_MAE=0.878, time=49.3, train_MAE=0.598, train_loss=0.598, val_MAE=0.82, val_loss=0.82]Epoch 8:   1%|          | 8/1000 [09:01<16:56:11, 61.46s/it, lr=0.001, test_MAE=0.878, time=49.3, train_MAE=0.598, train_loss=0.598, val_MAE=0.82, val_loss=0.82]Epoch 8:   1%|          | 8/1000 [09:50<16:56:11, 61.46s/it, lr=0.001, test_MAE=0.702, time=49.4, train_MAE=0.588, train_loss=0.588, val_MAE=0.633, val_loss=0.633]Epoch 8:   1%|          | 9/1000 [09:50<15:55:25, 57.85s/it, lr=0.001, test_MAE=0.702, time=49.4, train_MAE=0.588, train_loss=0.588, val_MAE=0.633, val_loss=0.633]Epoch 9:   1%|          | 9/1000 [09:50<15:55:25, 57.85s/it, lr=0.001, test_MAE=0.702, time=49.4, train_MAE=0.588, train_loss=0.588, val_MAE=0.633, val_loss=0.633]Epoch 9:   1%|          | 9/1000 [10:40<15:55:25, 57.85s/it, lr=0.001, test_MAE=0.854, time=49.6, train_MAE=0.581, train_loss=0.581, val_MAE=0.787, val_loss=0.787]Epoch 9:   1%|          | 10/1000 [10:40<15:13:51, 55.39s/it, lr=0.001, test_MAE=0.854, time=49.6, train_MAE=0.581, train_loss=0.581, val_MAE=0.787, val_loss=0.787]Epoch 10:   1%|          | 10/1000 [10:40<15:13:51, 55.39s/it, lr=0.001, test_MAE=0.854, time=49.6, train_MAE=0.581, train_loss=0.581, val_MAE=0.787, val_loss=0.787]Epoch 10:   1%|          | 10/1000 [11:29<15:13:51, 55.39s/it, lr=0.001, test_MAE=0.697, time=49.5, train_MAE=0.568, train_loss=0.568, val_MAE=0.638, val_loss=0.638]Epoch 10:   1%|          | 11/1000 [11:29<14:43:40, 53.61s/it, lr=0.001, test_MAE=0.697, time=49.5, train_MAE=0.568, train_loss=0.568, val_MAE=0.638, val_loss=0.638]Epoch 11:   1%|          | 11/1000 [11:29<14:43:40, 53.61s/it, lr=0.001, test_MAE=0.697, time=49.5, train_MAE=0.568, train_loss=0.568, val_MAE=0.638, val_loss=0.638]Epoch 11:   1%|          | 11/1000 [12:19<14:43:40, 53.61s/it, lr=0.001, test_MAE=0.69, time=49.3, train_MAE=0.569, train_loss=0.569, val_MAE=0.626, val_loss=0.626] Epoch 11:   1%|          | 12/1000 [12:19<14:21:31, 52.32s/it, lr=0.001, test_MAE=0.69, time=49.3, train_MAE=0.569, train_loss=0.569, val_MAE=0.626, val_loss=0.626]Epoch 12:   1%|          | 12/1000 [12:19<14:21:31, 52.32s/it, lr=0.001, test_MAE=0.69, time=49.3, train_MAE=0.569, train_loss=0.569, val_MAE=0.626, val_loss=0.626]Epoch 12:   1%|          | 12/1000 [13:11<14:21:31, 52.32s/it, lr=0.001, test_MAE=0.98, time=52.7, train_MAE=0.554, train_loss=0.554, val_MAE=0.915, val_loss=0.915]Epoch 12:   1%|▏         | 13/1000 [13:11<14:22:42, 52.44s/it, lr=0.001, test_MAE=0.98, time=52.7, train_MAE=0.554, train_loss=0.554, val_MAE=0.915, val_loss=0.915]Epoch 13:   1%|▏         | 13/1000 [13:11<14:22:42, 52.44s/it, lr=0.001, test_MAE=0.98, time=52.7, train_MAE=0.554, train_loss=0.554, val_MAE=0.915, val_loss=0.915]Epoch 13:   1%|▏         | 13/1000 [14:01<14:22:42, 52.44s/it, lr=0.001, test_MAE=0.845, time=49.4, train_MAE=0.559, train_loss=0.559, val_MAE=0.77, val_loss=0.77] Epoch 13:   1%|▏         | 14/1000 [14:01<14:06:45, 51.53s/it, lr=0.001, test_MAE=0.845, time=49.4, train_MAE=0.559, train_loss=0.559, val_MAE=0.77, val_loss=0.77]Epoch 14:   1%|▏         | 14/1000 [14:01<14:06:45, 51.53s/it, lr=0.001, test_MAE=0.845, time=49.4, train_MAE=0.559, train_loss=0.559, val_MAE=0.77, val_loss=0.77]Epoch 14:   1%|▏         | 14/1000 [14:49<14:06:45, 51.53s/it, lr=0.001, test_MAE=0.763, time=47.9, train_MAE=0.551, train_loss=0.551, val_MAE=0.702, val_loss=0.702]Epoch 14:   2%|▏         | 15/1000 [14:49<13:47:50, 50.43s/it, lr=0.001, test_MAE=0.763, time=47.9, train_MAE=0.551, train_loss=0.551, val_MAE=0.702, val_loss=0.702]Epoch 15:   2%|▏         | 15/1000 [14:49<13:47:50, 50.43s/it, lr=0.001, test_MAE=0.763, time=47.9, train_MAE=0.551, train_loss=0.551, val_MAE=0.702, val_loss=0.702]Epoch 15:   2%|▏         | 15/1000 [15:37<13:47:50, 50.43s/it, lr=0.001, test_MAE=0.744, time=48, train_MAE=0.539, train_loss=0.539, val_MAE=0.689, val_loss=0.689]  Epoch 15:   2%|▏         | 16/1000 [15:37<13:35:16, 49.71s/it, lr=0.001, test_MAE=0.744, time=48, train_MAE=0.539, train_loss=0.539, val_MAE=0.689, val_loss=0.689]Epoch 16:   2%|▏         | 16/1000 [15:37<13:35:16, 49.71s/it, lr=0.001, test_MAE=0.744, time=48, train_MAE=0.539, train_loss=0.539, val_MAE=0.689, val_loss=0.689]Epoch 16:   2%|▏         | 16/1000 [16:24<13:35:16, 49.71s/it, lr=0.001, test_MAE=0.756, time=47.7, train_MAE=0.524, train_loss=0.524, val_MAE=0.705, val_loss=0.705]Epoch 16:   2%|▏         | 17/1000 [16:24<13:24:39, 49.11s/it, lr=0.001, test_MAE=0.756, time=47.7, train_MAE=0.524, train_loss=0.524, val_MAE=0.705, val_loss=0.705]Epoch 17:   2%|▏         | 17/1000 [16:24<13:24:39, 49.11s/it, lr=0.001, test_MAE=0.756, time=47.7, train_MAE=0.524, train_loss=0.524, val_MAE=0.705, val_loss=0.705]Epoch 17:   2%|▏         | 17/1000 [17:12<13:24:39, 49.11s/it, lr=0.001, test_MAE=0.726, time=47.5, train_MAE=0.515, train_loss=0.515, val_MAE=0.685, val_loss=0.685]Epoch    18: reducing learning rate of group 0 to 5.0000e-04.
Epoch 17:   2%|▏         | 18/1000 [17:12<13:15:46, 48.62s/it, lr=0.001, test_MAE=0.726, time=47.5, train_MAE=0.515, train_loss=0.515, val_MAE=0.685, val_loss=0.685]Epoch 18:   2%|▏         | 18/1000 [17:12<13:15:46, 48.62s/it, lr=0.001, test_MAE=0.726, time=47.5, train_MAE=0.515, train_loss=0.515, val_MAE=0.685, val_loss=0.685]Epoch 18:   2%|▏         | 18/1000 [18:00<13:15:46, 48.62s/it, lr=0.0005, test_MAE=0.69, time=48.1, train_MAE=0.489, train_loss=0.489, val_MAE=0.638, val_loss=0.638]Epoch 18:   2%|▏         | 19/1000 [18:00<13:12:22, 48.46s/it, lr=0.0005, test_MAE=0.69, time=48.1, train_MAE=0.489, train_loss=0.489, val_MAE=0.638, val_loss=0.638]Epoch 19:   2%|▏         | 19/1000 [18:00<13:12:22, 48.46s/it, lr=0.0005, test_MAE=0.69, time=48.1, train_MAE=0.489, train_loss=0.489, val_MAE=0.638, val_loss=0.638]Epoch 19:   2%|▏         | 19/1000 [18:48<13:12:22, 48.46s/it, lr=0.0005, test_MAE=0.69, time=48, train_MAE=0.468, train_loss=0.468, val_MAE=0.64, val_loss=0.64]    Epoch 19:   2%|▏         | 20/1000 [18:48<13:09:07, 48.31s/it, lr=0.0005, test_MAE=0.69, time=48, train_MAE=0.468, train_loss=0.468, val_MAE=0.64, val_loss=0.64]Epoch 20:   2%|▏         | 20/1000 [18:48<13:09:07, 48.31s/it, lr=0.0005, test_MAE=0.69, time=48, train_MAE=0.468, train_loss=0.468, val_MAE=0.64, val_loss=0.64]Epoch 20:   2%|▏         | 20/1000 [19:36<13:09:07, 48.31s/it, lr=0.0005, test_MAE=0.809, time=47.8, train_MAE=0.465, train_loss=0.465, val_MAE=0.76, val_loss=0.76]Epoch 20:   2%|▏         | 21/1000 [19:36<13:05:58, 48.17s/it, lr=0.0005, test_MAE=0.809, time=47.8, train_MAE=0.465, train_loss=0.465, val_MAE=0.76, val_loss=0.76]Epoch 21:   2%|▏         | 21/1000 [19:36<13:05:58, 48.17s/it, lr=0.0005, test_MAE=0.809, time=47.8, train_MAE=0.465, train_loss=0.465, val_MAE=0.76, val_loss=0.76]Epoch 21:   2%|▏         | 21/1000 [20:24<13:05:58, 48.17s/it, lr=0.0005, test_MAE=0.729, time=48, train_MAE=0.465, train_loss=0.465, val_MAE=0.666, val_loss=0.666]Epoch 21:   2%|▏         | 22/1000 [20:24<13:04:25, 48.12s/it, lr=0.0005, test_MAE=0.729, time=48, train_MAE=0.465, train_loss=0.465, val_MAE=0.666, val_loss=0.666]Epoch 22:   2%|▏         | 22/1000 [20:24<13:04:25, 48.12s/it, lr=0.0005, test_MAE=0.729, time=48, train_MAE=0.465, train_loss=0.465, val_MAE=0.666, val_loss=0.666]Epoch 22:   2%|▏         | 22/1000 [21:11<13:04:25, 48.12s/it, lr=0.0005, test_MAE=0.725, time=47.5, train_MAE=0.452, train_loss=0.452, val_MAE=0.674, val_loss=0.674]Epoch 22:   2%|▏         | 23/1000 [21:11<13:00:23, 47.93s/it, lr=0.0005, test_MAE=0.725, time=47.5, train_MAE=0.452, train_loss=0.452, val_MAE=0.674, val_loss=0.674]Epoch 23:   2%|▏         | 23/1000 [21:11<13:00:23, 47.93s/it, lr=0.0005, test_MAE=0.725, time=47.5, train_MAE=0.452, train_loss=0.452, val_MAE=0.674, val_loss=0.674]Epoch 23:   2%|▏         | 23/1000 [21:59<13:00:23, 47.93s/it, lr=0.0005, test_MAE=0.745, time=48.1, train_MAE=0.455, train_loss=0.455, val_MAE=0.716, val_loss=0.716]Epoch    24: reducing learning rate of group 0 to 2.5000e-04.
Epoch 23:   2%|▏         | 24/1000 [21:59<13:00:43, 48.00s/it, lr=0.0005, test_MAE=0.745, time=48.1, train_MAE=0.455, train_loss=0.455, val_MAE=0.716, val_loss=0.716]Epoch 24:   2%|▏         | 24/1000 [21:59<13:00:43, 48.00s/it, lr=0.0005, test_MAE=0.745, time=48.1, train_MAE=0.455, train_loss=0.455, val_MAE=0.716, val_loss=0.716]Epoch 24:   2%|▏         | 24/1000 [22:47<13:00:43, 48.00s/it, lr=0.00025, test_MAE=0.689, time=47.9, train_MAE=0.418, train_loss=0.418, val_MAE=0.645, val_loss=0.645]Epoch 24:   2%|▎         | 25/1000 [22:47<12:59:18, 47.96s/it, lr=0.00025, test_MAE=0.689, time=47.9, train_MAE=0.418, train_loss=0.418, val_MAE=0.645, val_loss=0.645]Epoch 25:   2%|▎         | 25/1000 [22:47<12:59:18, 47.96s/it, lr=0.00025, test_MAE=0.689, time=47.9, train_MAE=0.418, train_loss=0.418, val_MAE=0.645, val_loss=0.645]Epoch 25:   2%|▎         | 25/1000 [23:35<12:59:18, 47.96s/it, lr=0.00025, test_MAE=0.732, time=47.7, train_MAE=0.409, train_loss=0.409, val_MAE=0.676, val_loss=0.676]Epoch 25:   3%|▎         | 26/1000 [23:35<12:57:28, 47.89s/it, lr=0.00025, test_MAE=0.732, time=47.7, train_MAE=0.409, train_loss=0.409, val_MAE=0.676, val_loss=0.676]Epoch 26:   3%|▎         | 26/1000 [23:35<12:57:28, 47.89s/it, lr=0.00025, test_MAE=0.732, time=47.7, train_MAE=0.409, train_loss=0.409, val_MAE=0.676, val_loss=0.676]Epoch 26:   3%|▎         | 26/1000 [24:23<12:57:28, 47.89s/it, lr=0.00025, test_MAE=0.699, time=48, train_MAE=0.413, train_loss=0.413, val_MAE=0.654, val_loss=0.654]  Epoch 26:   3%|▎         | 27/1000 [24:23<12:57:13, 47.93s/it, lr=0.00025, test_MAE=0.699, time=48, train_MAE=0.413, train_loss=0.413, val_MAE=0.654, val_loss=0.654]Epoch 27:   3%|▎         | 27/1000 [24:23<12:57:13, 47.93s/it, lr=0.00025, test_MAE=0.699, time=48, train_MAE=0.413, train_loss=0.413, val_MAE=0.654, val_loss=0.654]Epoch 27:   3%|▎         | 27/1000 [25:11<12:57:13, 47.93s/it, lr=0.00025, test_MAE=0.702, time=47.7, train_MAE=0.398, train_loss=0.398, val_MAE=0.667, val_loss=0.667]Epoch 27:   3%|▎         | 28/1000 [25:11<12:55:32, 47.87s/it, lr=0.00025, test_MAE=0.702, time=47.7, train_MAE=0.398, train_loss=0.398, val_MAE=0.667, val_loss=0.667]Epoch 28:   3%|▎         | 28/1000 [25:11<12:55:32, 47.87s/it, lr=0.00025, test_MAE=0.702, time=47.7, train_MAE=0.398, train_loss=0.398, val_MAE=0.667, val_loss=0.667]Epoch 28:   3%|▎         | 28/1000 [25:58<12:55:32, 47.87s/it, lr=0.00025, test_MAE=0.702, time=47.4, train_MAE=0.411, train_loss=0.411, val_MAE=0.655, val_loss=0.655]Epoch 28:   3%|▎         | 29/1000 [25:58<12:52:42, 47.75s/it, lr=0.00025, test_MAE=0.702, time=47.4, train_MAE=0.411, train_loss=0.411, val_MAE=0.655, val_loss=0.655]Epoch 29:   3%|▎         | 29/1000 [25:58<12:52:42, 47.75s/it, lr=0.00025, test_MAE=0.702, time=47.4, train_MAE=0.411, train_loss=0.411, val_MAE=0.655, val_loss=0.655]Epoch 29:   3%|▎         | 29/1000 [26:47<12:52:42, 47.75s/it, lr=0.00025, test_MAE=0.782, time=48.3, train_MAE=0.396, train_loss=0.396, val_MAE=0.72, val_loss=0.72]  Epoch    30: reducing learning rate of group 0 to 1.2500e-04.
Epoch 29:   3%|▎         | 30/1000 [26:47<12:54:30, 47.91s/it, lr=0.00025, test_MAE=0.782, time=48.3, train_MAE=0.396, train_loss=0.396, val_MAE=0.72, val_loss=0.72]Epoch 30:   3%|▎         | 30/1000 [26:47<12:54:30, 47.91s/it, lr=0.00025, test_MAE=0.782, time=48.3, train_MAE=0.396, train_loss=0.396, val_MAE=0.72, val_loss=0.72]Epoch 30:   3%|▎         | 30/1000 [27:34<12:54:30, 47.91s/it, lr=0.000125, test_MAE=0.707, time=47.7, train_MAE=0.377, train_loss=0.377, val_MAE=0.658, val_loss=0.658]Epoch 30:   3%|▎         | 31/1000 [27:34<12:52:55, 47.86s/it, lr=0.000125, test_MAE=0.707, time=47.7, train_MAE=0.377, train_loss=0.377, val_MAE=0.658, val_loss=0.658]Epoch 31:   3%|▎         | 31/1000 [27:34<12:52:55, 47.86s/it, lr=0.000125, test_MAE=0.707, time=47.7, train_MAE=0.377, train_loss=0.377, val_MAE=0.658, val_loss=0.658]Epoch 31:   3%|▎         | 31/1000 [28:22<12:52:55, 47.86s/it, lr=0.000125, test_MAE=0.704, time=47.5, train_MAE=0.363, train_loss=0.363, val_MAE=0.662, val_loss=0.662]Epoch 31:   3%|▎         | 32/1000 [28:22<12:50:33, 47.76s/it, lr=0.000125, test_MAE=0.704, time=47.5, train_MAE=0.363, train_loss=0.363, val_MAE=0.662, val_loss=0.662]Epoch 32:   3%|▎         | 32/1000 [28:22<12:50:33, 47.76s/it, lr=0.000125, test_MAE=0.704, time=47.5, train_MAE=0.363, train_loss=0.363, val_MAE=0.662, val_loss=0.662]Epoch 32:   3%|▎         | 32/1000 [29:10<12:50:33, 47.76s/it, lr=0.000125, test_MAE=0.711, time=48, train_MAE=0.362, train_loss=0.362, val_MAE=0.67, val_loss=0.67]    Epoch 32:   3%|▎         | 33/1000 [29:10<12:51:11, 47.85s/it, lr=0.000125, test_MAE=0.711, time=48, train_MAE=0.362, train_loss=0.362, val_MAE=0.67, val_loss=0.67]Epoch 33:   3%|▎         | 33/1000 [29:10<12:51:11, 47.85s/it, lr=0.000125, test_MAE=0.711, time=48, train_MAE=0.362, train_loss=0.362, val_MAE=0.67, val_loss=0.67]Epoch 33:   3%|▎         | 33/1000 [29:58<12:51:11, 47.85s/it, lr=0.000125, test_MAE=0.714, time=47.9, train_MAE=0.359, train_loss=0.359, val_MAE=0.675, val_loss=0.675]Epoch 33:   3%|▎         | 34/1000 [29:58<12:50:34, 47.86s/it, lr=0.000125, test_MAE=0.714, time=47.9, train_MAE=0.359, train_loss=0.359, val_MAE=0.675, val_loss=0.675]Epoch 34:   3%|▎         | 34/1000 [29:58<12:50:34, 47.86s/it, lr=0.000125, test_MAE=0.714, time=47.9, train_MAE=0.359, train_loss=0.359, val_MAE=0.675, val_loss=0.675]Epoch 34:   3%|▎         | 34/1000 [30:45<12:50:34, 47.86s/it, lr=0.000125, test_MAE=0.708, time=47.6, train_MAE=0.358, train_loss=0.358, val_MAE=0.663, val_loss=0.663]Epoch 34:   4%|▎         | 35/1000 [30:45<12:48:47, 47.80s/it, lr=0.000125, test_MAE=0.708, time=47.6, train_MAE=0.358, train_loss=0.358, val_MAE=0.663, val_loss=0.663]Epoch 35:   4%|▎         | 35/1000 [30:45<12:48:47, 47.80s/it, lr=0.000125, test_MAE=0.708, time=47.6, train_MAE=0.358, train_loss=0.358, val_MAE=0.663, val_loss=0.663]Epoch 35:   4%|▎         | 35/1000 [31:33<12:48:47, 47.80s/it, lr=0.000125, test_MAE=0.726, time=48, train_MAE=0.362, train_loss=0.362, val_MAE=0.672, val_loss=0.672]  Epoch    36: reducing learning rate of group 0 to 6.2500e-05.
Epoch 35:   4%|▎         | 36/1000 [31:33<12:49:02, 47.87s/it, lr=0.000125, test_MAE=0.726, time=48, train_MAE=0.362, train_loss=0.362, val_MAE=0.672, val_loss=0.672]Epoch 36:   4%|▎         | 36/1000 [31:33<12:49:02, 47.87s/it, lr=0.000125, test_MAE=0.726, time=48, train_MAE=0.362, train_loss=0.362, val_MAE=0.672, val_loss=0.672]Epoch 36:   4%|▎         | 36/1000 [32:21<12:49:02, 47.87s/it, lr=6.25e-5, test_MAE=0.702, time=47.7, train_MAE=0.348, train_loss=0.348, val_MAE=0.665, val_loss=0.665]Epoch 36:   4%|▎         | 37/1000 [32:21<12:47:23, 47.81s/it, lr=6.25e-5, test_MAE=0.702, time=47.7, train_MAE=0.348, train_loss=0.348, val_MAE=0.665, val_loss=0.665]Epoch 37:   4%|▎         | 37/1000 [32:21<12:47:23, 47.81s/it, lr=6.25e-5, test_MAE=0.702, time=47.7, train_MAE=0.348, train_loss=0.348, val_MAE=0.665, val_loss=0.665]Epoch 37:   4%|▎         | 37/1000 [33:08<12:47:23, 47.81s/it, lr=6.25e-5, test_MAE=0.708, time=46.8, train_MAE=0.341, train_loss=0.341, val_MAE=0.666, val_loss=0.666]Epoch 37:   4%|▍         | 38/1000 [33:08<12:42:00, 47.53s/it, lr=6.25e-5, test_MAE=0.708, time=46.8, train_MAE=0.341, train_loss=0.341, val_MAE=0.666, val_loss=0.666]Epoch 38:   4%|▍         | 38/1000 [33:08<12:42:00, 47.53s/it, lr=6.25e-5, test_MAE=0.708, time=46.8, train_MAE=0.341, train_loss=0.341, val_MAE=0.666, val_loss=0.666]Epoch 38:   4%|▍         | 38/1000 [33:55<12:42:00, 47.53s/it, lr=6.25e-5, test_MAE=0.705, time=47.2, train_MAE=0.35, train_loss=0.35, val_MAE=0.663, val_loss=0.663]  Epoch 38:   4%|▍         | 39/1000 [33:55<12:39:50, 47.44s/it, lr=6.25e-5, test_MAE=0.705, time=47.2, train_MAE=0.35, train_loss=0.35, val_MAE=0.663, val_loss=0.663]Epoch 39:   4%|▍         | 39/1000 [33:55<12:39:50, 47.44s/it, lr=6.25e-5, test_MAE=0.705, time=47.2, train_MAE=0.35, train_loss=0.35, val_MAE=0.663, val_loss=0.663]Epoch 39:   4%|▍         | 39/1000 [34:42<12:39:50, 47.44s/it, lr=6.25e-5, test_MAE=0.705, time=46.9, train_MAE=0.338, train_loss=0.338, val_MAE=0.662, val_loss=0.662]Epoch 39:   4%|▍         | 40/1000 [34:42<12:36:22, 47.27s/it, lr=6.25e-5, test_MAE=0.705, time=46.9, train_MAE=0.338, train_loss=0.338, val_MAE=0.662, val_loss=0.662]Epoch 40:   4%|▍         | 40/1000 [34:42<12:36:22, 47.27s/it, lr=6.25e-5, test_MAE=0.705, time=46.9, train_MAE=0.338, train_loss=0.338, val_MAE=0.662, val_loss=0.662]Epoch 40:   4%|▍         | 40/1000 [35:31<12:36:22, 47.27s/it, lr=6.25e-5, test_MAE=0.711, time=48.9, train_MAE=0.37, train_loss=0.37, val_MAE=0.671, val_loss=0.671]  Epoch 40:   4%|▍         | 41/1000 [35:31<12:43:19, 47.76s/it, lr=6.25e-5, test_MAE=0.711, time=48.9, train_MAE=0.37, train_loss=0.37, val_MAE=0.671, val_loss=0.671]Epoch 41:   4%|▍         | 41/1000 [35:31<12:43:19, 47.76s/it, lr=6.25e-5, test_MAE=0.711, time=48.9, train_MAE=0.37, train_loss=0.37, val_MAE=0.671, val_loss=0.671]Epoch 41:   4%|▍         | 41/1000 [36:21<12:43:19, 47.76s/it, lr=6.25e-5, test_MAE=0.716, time=49.8, train_MAE=0.344, train_loss=0.344, val_MAE=0.669, val_loss=0.669]Epoch    42: reducing learning rate of group 0 to 3.1250e-05.
Epoch 41:   4%|▍         | 42/1000 [36:21<12:52:11, 48.36s/it, lr=6.25e-5, test_MAE=0.716, time=49.8, train_MAE=0.344, train_loss=0.344, val_MAE=0.669, val_loss=0.669]Epoch 42:   4%|▍         | 42/1000 [36:21<12:52:11, 48.36s/it, lr=6.25e-5, test_MAE=0.716, time=49.8, train_MAE=0.344, train_loss=0.344, val_MAE=0.669, val_loss=0.669]Epoch 42:   4%|▍         | 42/1000 [37:10<12:52:11, 48.36s/it, lr=3.13e-5, test_MAE=0.709, time=49.1, train_MAE=0.335, train_loss=0.335, val_MAE=0.672, val_loss=0.672]Epoch 42:   4%|▍         | 43/1000 [37:10<12:55:02, 48.59s/it, lr=3.13e-5, test_MAE=0.709, time=49.1, train_MAE=0.335, train_loss=0.335, val_MAE=0.672, val_loss=0.672]Epoch 43:   4%|▍         | 43/1000 [37:10<12:55:02, 48.59s/it, lr=3.13e-5, test_MAE=0.709, time=49.1, train_MAE=0.335, train_loss=0.335, val_MAE=0.672, val_loss=0.672]Epoch 43:   4%|▍         | 43/1000 [38:00<12:55:02, 48.59s/it, lr=3.13e-5, test_MAE=0.713, time=49.8, train_MAE=0.338, train_loss=0.338, val_MAE=0.677, val_loss=0.677]Epoch 43:   4%|▍         | 44/1000 [38:00<13:00:07, 48.96s/it, lr=3.13e-5, test_MAE=0.713, time=49.8, train_MAE=0.338, train_loss=0.338, val_MAE=0.677, val_loss=0.677]Epoch 44:   4%|▍         | 44/1000 [38:00<13:00:07, 48.96s/it, lr=3.13e-5, test_MAE=0.713, time=49.8, train_MAE=0.338, train_loss=0.338, val_MAE=0.677, val_loss=0.677]Epoch 44:   4%|▍         | 44/1000 [38:49<13:00:07, 48.96s/it, lr=3.13e-5, test_MAE=0.713, time=49.2, train_MAE=0.337, train_loss=0.337, val_MAE=0.672, val_loss=0.672]Epoch 44:   4%|▍         | 45/1000 [38:49<13:00:28, 49.03s/it, lr=3.13e-5, test_MAE=0.713, time=49.2, train_MAE=0.337, train_loss=0.337, val_MAE=0.672, val_loss=0.672]Epoch 45:   4%|▍         | 45/1000 [38:49<13:00:28, 49.03s/it, lr=3.13e-5, test_MAE=0.713, time=49.2, train_MAE=0.337, train_loss=0.337, val_MAE=0.672, val_loss=0.672]Epoch 45:   4%|▍         | 45/1000 [39:38<13:00:28, 49.03s/it, lr=3.13e-5, test_MAE=0.707, time=49.4, train_MAE=0.336, train_loss=0.336, val_MAE=0.669, val_loss=0.669]Epoch 45:   5%|▍         | 46/1000 [39:38<13:01:27, 49.15s/it, lr=3.13e-5, test_MAE=0.707, time=49.4, train_MAE=0.336, train_loss=0.336, val_MAE=0.669, val_loss=0.669]Epoch 46:   5%|▍         | 46/1000 [39:38<13:01:27, 49.15s/it, lr=3.13e-5, test_MAE=0.707, time=49.4, train_MAE=0.336, train_loss=0.336, val_MAE=0.669, val_loss=0.669]Epoch 46:   5%|▍         | 46/1000 [40:28<13:01:27, 49.15s/it, lr=3.13e-5, test_MAE=0.713, time=49.5, train_MAE=0.332, train_loss=0.332, val_MAE=0.677, val_loss=0.677]Epoch 46:   5%|▍         | 47/1000 [40:28<13:02:10, 49.25s/it, lr=3.13e-5, test_MAE=0.713, time=49.5, train_MAE=0.332, train_loss=0.332, val_MAE=0.677, val_loss=0.677]Epoch 47:   5%|▍         | 47/1000 [40:28<13:02:10, 49.25s/it, lr=3.13e-5, test_MAE=0.713, time=49.5, train_MAE=0.332, train_loss=0.332, val_MAE=0.677, val_loss=0.677]Epoch 47:   5%|▍         | 47/1000 [41:17<13:02:10, 49.25s/it, lr=3.13e-5, test_MAE=0.711, time=49.6, train_MAE=0.332, train_loss=0.332, val_MAE=0.672, val_loss=0.672]Epoch    48: reducing learning rate of group 0 to 1.5625e-05.
Epoch 47:   5%|▍         | 48/1000 [41:17<13:03:03, 49.35s/it, lr=3.13e-5, test_MAE=0.711, time=49.6, train_MAE=0.332, train_loss=0.332, val_MAE=0.672, val_loss=0.672]Epoch 48:   5%|▍         | 48/1000 [41:17<13:03:03, 49.35s/it, lr=3.13e-5, test_MAE=0.711, time=49.6, train_MAE=0.332, train_loss=0.332, val_MAE=0.672, val_loss=0.672]Epoch 48:   5%|▍         | 48/1000 [42:06<13:03:03, 49.35s/it, lr=1.56e-5, test_MAE=0.716, time=48.7, train_MAE=0.335, train_loss=0.335, val_MAE=0.675, val_loss=0.675]Epoch 48:   5%|▍         | 49/1000 [42:06<12:59:17, 49.17s/it, lr=1.56e-5, test_MAE=0.716, time=48.7, train_MAE=0.335, train_loss=0.335, val_MAE=0.675, val_loss=0.675]Epoch 49:   5%|▍         | 49/1000 [42:06<12:59:17, 49.17s/it, lr=1.56e-5, test_MAE=0.716, time=48.7, train_MAE=0.335, train_loss=0.335, val_MAE=0.675, val_loss=0.675]Epoch 49:   5%|▍         | 49/1000 [42:56<12:59:17, 49.17s/it, lr=1.56e-5, test_MAE=0.715, time=49.7, train_MAE=0.328, train_loss=0.328, val_MAE=0.679, val_loss=0.679]Epoch 49:   5%|▌         | 50/1000 [42:56<13:01:04, 49.33s/it, lr=1.56e-5, test_MAE=0.715, time=49.7, train_MAE=0.328, train_loss=0.328, val_MAE=0.679, val_loss=0.679]Epoch 50:   5%|▌         | 50/1000 [42:56<13:01:04, 49.33s/it, lr=1.56e-5, test_MAE=0.715, time=49.7, train_MAE=0.328, train_loss=0.328, val_MAE=0.679, val_loss=0.679]Epoch 50:   5%|▌         | 50/1000 [43:45<13:01:04, 49.33s/it, lr=1.56e-5, test_MAE=0.715, time=49.1, train_MAE=0.322, train_loss=0.322, val_MAE=0.675, val_loss=0.675]Epoch 50:   5%|▌         | 51/1000 [43:45<12:59:03, 49.26s/it, lr=1.56e-5, test_MAE=0.715, time=49.1, train_MAE=0.322, train_loss=0.322, val_MAE=0.675, val_loss=0.675]Epoch 51:   5%|▌         | 51/1000 [43:45<12:59:03, 49.26s/it, lr=1.56e-5, test_MAE=0.715, time=49.1, train_MAE=0.322, train_loss=0.322, val_MAE=0.675, val_loss=0.675]Epoch 51:   5%|▌         | 51/1000 [44:34<12:59:03, 49.26s/it, lr=1.56e-5, test_MAE=0.713, time=49, train_MAE=0.329, train_loss=0.329, val_MAE=0.673, val_loss=0.673]  Epoch 51:   5%|▌         | 52/1000 [44:34<12:57:08, 49.19s/it, lr=1.56e-5, test_MAE=0.713, time=49, train_MAE=0.329, train_loss=0.329, val_MAE=0.673, val_loss=0.673]Epoch 52:   5%|▌         | 52/1000 [44:34<12:57:08, 49.19s/it, lr=1.56e-5, test_MAE=0.713, time=49, train_MAE=0.329, train_loss=0.329, val_MAE=0.673, val_loss=0.673]Epoch 52:   5%|▌         | 52/1000 [45:23<12:57:08, 49.19s/it, lr=1.56e-5, test_MAE=0.712, time=49.4, train_MAE=0.323, train_loss=0.323, val_MAE=0.671, val_loss=0.671]Epoch 52:   5%|▌         | 53/1000 [45:23<12:57:08, 49.24s/it, lr=1.56e-5, test_MAE=0.712, time=49.4, train_MAE=0.323, train_loss=0.323, val_MAE=0.671, val_loss=0.671]Epoch 53:   5%|▌         | 53/1000 [45:23<12:57:08, 49.24s/it, lr=1.56e-5, test_MAE=0.712, time=49.4, train_MAE=0.323, train_loss=0.323, val_MAE=0.671, val_loss=0.671]Epoch 53:   5%|▌         | 53/1000 [46:12<12:57:08, 49.24s/it, lr=1.56e-5, test_MAE=0.717, time=48.9, train_MAE=0.323, train_loss=0.323, val_MAE=0.682, val_loss=0.682]Epoch    54: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 53:   5%|▌         | 53/1000 [46:12<13:45:43, 52.32s/it, lr=1.56e-5, test_MAE=0.717, time=48.9, train_MAE=0.323, train_loss=0.323, val_MAE=0.682, val_loss=0.682]
Test MAE: 0.7172
Train MAE: 0.2935
Convergence Time (Epochs): 53.0000
TOTAL TIME TAKEN: 2805.9373s
AVG TIME PER EPOCH: 51.3379s
