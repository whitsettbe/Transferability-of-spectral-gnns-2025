I'm echoing to stdout
I'm echoing to stderr
My JobID is 55799839
I have 4 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.1634s
Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [01:03<?, ?it/s, lr=0.001, test_MAE=1.25, time=63.8, train_MAE=1.37, train_loss=1.37, val_MAE=1.17, val_loss=1.17]Epoch 0:   0%|          | 1/1000 [01:03<17:42:23, 63.81s/it, lr=0.001, test_MAE=1.25, time=63.8, train_MAE=1.37, train_loss=1.37, val_MAE=1.17, val_loss=1.17]Epoch 1:   0%|          | 1/1000 [01:03<17:42:23, 63.81s/it, lr=0.001, test_MAE=1.25, time=63.8, train_MAE=1.37, train_loss=1.37, val_MAE=1.17, val_loss=1.17]Epoch 1:   0%|          | 1/1000 [02:02<17:42:23, 63.81s/it, lr=0.001, test_MAE=1.06, time=58.8, train_MAE=1.07, train_loss=1.07, val_MAE=0.979, val_loss=0.979]Epoch 1:   0%|          | 2/1000 [02:02<17:16:34, 62.32s/it, lr=0.001, test_MAE=1.06, time=58.8, train_MAE=1.07, train_loss=1.07, val_MAE=0.979, val_loss=0.979]Epoch 2:   0%|          | 2/1000 [02:02<17:16:34, 62.32s/it, lr=0.001, test_MAE=1.06, time=58.8, train_MAE=1.07, train_loss=1.07, val_MAE=0.979, val_loss=0.979]Epoch 2:   0%|          | 2/1000 [03:01<17:16:34, 62.32s/it, lr=0.001, test_MAE=1.1, time=58.5, train_MAE=0.966, train_loss=0.966, val_MAE=1.05, val_loss=1.05] Epoch 2:   0%|          | 3/1000 [03:01<16:56:27, 61.17s/it, lr=0.001, test_MAE=1.1, time=58.5, train_MAE=0.966, train_loss=0.966, val_MAE=1.05, val_loss=1.05]Epoch 3:   0%|          | 3/1000 [03:01<16:56:27, 61.17s/it, lr=0.001, test_MAE=1.1, time=58.5, train_MAE=0.966, train_loss=0.966, val_MAE=1.05, val_loss=1.05]Epoch 3:   0%|          | 3/1000 [03:59<16:56:27, 61.17s/it, lr=0.001, test_MAE=0.964, time=58.2, train_MAE=0.901, train_loss=0.901, val_MAE=0.903, val_loss=0.903]Epoch 3:   0%|          | 4/1000 [03:59<16:40:54, 60.30s/it, lr=0.001, test_MAE=0.964, time=58.2, train_MAE=0.901, train_loss=0.901, val_MAE=0.903, val_loss=0.903]Epoch 4:   0%|          | 4/1000 [03:59<16:40:54, 60.30s/it, lr=0.001, test_MAE=0.964, time=58.2, train_MAE=0.901, train_loss=0.901, val_MAE=0.903, val_loss=0.903]Epoch 4:   0%|          | 4/1000 [04:56<16:40:54, 60.30s/it, lr=0.001, test_MAE=0.923, time=57.2, train_MAE=0.87, train_loss=0.87, val_MAE=0.871, val_loss=0.871]  Epoch 4:   0%|          | 5/1000 [04:56<16:24:29, 59.37s/it, lr=0.001, test_MAE=0.923, time=57.2, train_MAE=0.87, train_loss=0.87, val_MAE=0.871, val_loss=0.871]Epoch 5:   0%|          | 5/1000 [04:56<16:24:29, 59.37s/it, lr=0.001, test_MAE=0.923, time=57.2, train_MAE=0.87, train_loss=0.87, val_MAE=0.871, val_loss=0.871]Epoch 5:   0%|          | 5/1000 [05:54<16:24:29, 59.37s/it, lr=0.001, test_MAE=0.9, time=58.1, train_MAE=0.829, train_loss=0.829, val_MAE=0.847, val_loss=0.847]Epoch 5:   1%|          | 6/1000 [05:54<16:17:15, 58.99s/it, lr=0.001, test_MAE=0.9, time=58.1, train_MAE=0.829, train_loss=0.829, val_MAE=0.847, val_loss=0.847]Epoch 6:   1%|          | 6/1000 [05:54<16:17:15, 58.99s/it, lr=0.001, test_MAE=0.9, time=58.1, train_MAE=0.829, train_loss=0.829, val_MAE=0.847, val_loss=0.847]Epoch 6:   1%|          | 6/1000 [06:53<16:17:15, 58.99s/it, lr=0.001, test_MAE=0.834, time=58.8, train_MAE=0.809, train_loss=0.809, val_MAE=0.773, val_loss=0.773]Epoch 6:   1%|          | 7/1000 [06:53<16:15:16, 58.93s/it, lr=0.001, test_MAE=0.834, time=58.8, train_MAE=0.809, train_loss=0.809, val_MAE=0.773, val_loss=0.773]Epoch 7:   1%|          | 7/1000 [06:53<16:15:16, 58.93s/it, lr=0.001, test_MAE=0.834, time=58.8, train_MAE=0.809, train_loss=0.809, val_MAE=0.773, val_loss=0.773]Epoch 7:   1%|          | 7/1000 [07:52<16:15:16, 58.93s/it, lr=0.001, test_MAE=0.854, time=59, train_MAE=0.785, train_loss=0.785, val_MAE=0.798, val_loss=0.798]  Epoch 7:   1%|          | 8/1000 [07:52<16:14:54, 58.97s/it, lr=0.001, test_MAE=0.854, time=59, train_MAE=0.785, train_loss=0.785, val_MAE=0.798, val_loss=0.798]Epoch 8:   1%|          | 8/1000 [07:52<16:14:54, 58.97s/it, lr=0.001, test_MAE=0.854, time=59, train_MAE=0.785, train_loss=0.785, val_MAE=0.798, val_loss=0.798]Epoch 8:   1%|          | 8/1000 [08:51<16:14:54, 58.97s/it, lr=0.001, test_MAE=0.868, time=58.5, train_MAE=0.763, train_loss=0.763, val_MAE=0.823, val_loss=0.823]Epoch 8:   1%|          | 9/1000 [08:51<16:11:46, 58.84s/it, lr=0.001, test_MAE=0.868, time=58.5, train_MAE=0.763, train_loss=0.763, val_MAE=0.823, val_loss=0.823]Epoch 9:   1%|          | 9/1000 [08:51<16:11:46, 58.84s/it, lr=0.001, test_MAE=0.868, time=58.5, train_MAE=0.763, train_loss=0.763, val_MAE=0.823, val_loss=0.823]Epoch 9:   1%|          | 9/1000 [09:49<16:11:46, 58.84s/it, lr=0.001, test_MAE=0.848, time=58.4, train_MAE=0.752, train_loss=0.752, val_MAE=0.799, val_loss=0.799]Epoch 9:   1%|          | 10/1000 [09:49<16:08:55, 58.72s/it, lr=0.001, test_MAE=0.848, time=58.4, train_MAE=0.752, train_loss=0.752, val_MAE=0.799, val_loss=0.799]Epoch 10:   1%|          | 10/1000 [09:49<16:08:55, 58.72s/it, lr=0.001, test_MAE=0.848, time=58.4, train_MAE=0.752, train_loss=0.752, val_MAE=0.799, val_loss=0.799]Epoch 10:   1%|          | 10/1000 [10:49<16:08:55, 58.72s/it, lr=0.001, test_MAE=0.828, time=59.9, train_MAE=0.739, train_loss=0.739, val_MAE=0.788, val_loss=0.788]Epoch 10:   1%|          | 11/1000 [10:49<16:13:52, 59.08s/it, lr=0.001, test_MAE=0.828, time=59.9, train_MAE=0.739, train_loss=0.739, val_MAE=0.788, val_loss=0.788]Epoch 11:   1%|          | 11/1000 [10:49<16:13:52, 59.08s/it, lr=0.001, test_MAE=0.828, time=59.9, train_MAE=0.739, train_loss=0.739, val_MAE=0.788, val_loss=0.788]Epoch 11:   1%|          | 11/1000 [11:49<16:13:52, 59.08s/it, lr=0.001, test_MAE=0.915, time=60, train_MAE=0.729, train_loss=0.729, val_MAE=0.875, val_loss=0.875]  Epoch 11:   1%|          | 12/1000 [11:49<16:17:28, 59.36s/it, lr=0.001, test_MAE=0.915, time=60, train_MAE=0.729, train_loss=0.729, val_MAE=0.875, val_loss=0.875]Epoch 12:   1%|          | 12/1000 [11:49<16:17:28, 59.36s/it, lr=0.001, test_MAE=0.915, time=60, train_MAE=0.729, train_loss=0.729, val_MAE=0.875, val_loss=0.875]Epoch 12:   1%|          | 12/1000 [12:49<16:17:28, 59.36s/it, lr=0.001, test_MAE=0.904, time=60.4, train_MAE=0.714, train_loss=0.714, val_MAE=0.866, val_loss=0.866]Epoch    13: reducing learning rate of group 0 to 5.0000e-04.
Epoch 12:   1%|▏         | 13/1000 [12:49<16:21:40, 59.68s/it, lr=0.001, test_MAE=0.904, time=60.4, train_MAE=0.714, train_loss=0.714, val_MAE=0.866, val_loss=0.866]Epoch 13:   1%|▏         | 13/1000 [12:49<16:21:40, 59.68s/it, lr=0.001, test_MAE=0.904, time=60.4, train_MAE=0.714, train_loss=0.714, val_MAE=0.866, val_loss=0.866]Epoch 13:   1%|▏         | 13/1000 [13:49<16:21:40, 59.68s/it, lr=0.0005, test_MAE=0.769, time=59.8, train_MAE=0.702, train_loss=0.702, val_MAE=0.723, val_loss=0.723]Epoch 13:   1%|▏         | 14/1000 [13:49<16:21:10, 59.71s/it, lr=0.0005, test_MAE=0.769, time=59.8, train_MAE=0.702, train_loss=0.702, val_MAE=0.723, val_loss=0.723]Epoch 14:   1%|▏         | 14/1000 [13:49<16:21:10, 59.71s/it, lr=0.0005, test_MAE=0.769, time=59.8, train_MAE=0.702, train_loss=0.702, val_MAE=0.723, val_loss=0.723]Epoch 14:   1%|▏         | 14/1000 [14:48<16:21:10, 59.71s/it, lr=0.0005, test_MAE=0.789, time=59.3, train_MAE=0.693, train_loss=0.693, val_MAE=0.743, val_loss=0.743]Epoch 14:   2%|▏         | 15/1000 [14:48<16:18:17, 59.59s/it, lr=0.0005, test_MAE=0.789, time=59.3, train_MAE=0.693, train_loss=0.693, val_MAE=0.743, val_loss=0.743]Epoch 15:   2%|▏         | 15/1000 [14:48<16:18:17, 59.59s/it, lr=0.0005, test_MAE=0.789, time=59.3, train_MAE=0.693, train_loss=0.693, val_MAE=0.743, val_loss=0.743]Epoch 15:   2%|▏         | 15/1000 [15:48<16:18:17, 59.59s/it, lr=0.0005, test_MAE=0.777, time=59.7, train_MAE=0.681, train_loss=0.681, val_MAE=0.729, val_loss=0.729]Epoch 15:   2%|▏         | 16/1000 [15:48<16:18:04, 59.64s/it, lr=0.0005, test_MAE=0.777, time=59.7, train_MAE=0.681, train_loss=0.681, val_MAE=0.729, val_loss=0.729]Epoch 16:   2%|▏         | 16/1000 [15:48<16:18:04, 59.64s/it, lr=0.0005, test_MAE=0.777, time=59.7, train_MAE=0.681, train_loss=0.681, val_MAE=0.729, val_loss=0.729]Epoch 16:   2%|▏         | 16/1000 [16:47<16:18:04, 59.64s/it, lr=0.0005, test_MAE=0.767, time=59.1, train_MAE=0.682, train_loss=0.682, val_MAE=0.725, val_loss=0.725]Epoch 16:   2%|▏         | 17/1000 [16:47<16:14:29, 59.48s/it, lr=0.0005, test_MAE=0.767, time=59.1, train_MAE=0.682, train_loss=0.682, val_MAE=0.725, val_loss=0.725]Epoch 17:   2%|▏         | 17/1000 [16:47<16:14:29, 59.48s/it, lr=0.0005, test_MAE=0.767, time=59.1, train_MAE=0.682, train_loss=0.682, val_MAE=0.725, val_loss=0.725]Epoch 17:   2%|▏         | 17/1000 [17:45<16:14:29, 59.48s/it, lr=0.0005, test_MAE=0.785, time=57.5, train_MAE=0.68, train_loss=0.68, val_MAE=0.749, val_loss=0.749]  Epoch 17:   2%|▏         | 18/1000 [17:45<16:04:05, 58.91s/it, lr=0.0005, test_MAE=0.785, time=57.5, train_MAE=0.68, train_loss=0.68, val_MAE=0.749, val_loss=0.749]Epoch 18:   2%|▏         | 18/1000 [17:45<16:04:05, 58.91s/it, lr=0.0005, test_MAE=0.785, time=57.5, train_MAE=0.68, train_loss=0.68, val_MAE=0.749, val_loss=0.749]Epoch 18:   2%|▏         | 18/1000 [18:44<16:04:05, 58.91s/it, lr=0.0005, test_MAE=0.817, time=59, train_MAE=0.669, train_loss=0.669, val_MAE=0.779, val_loss=0.779]Epoch 18:   2%|▏         | 19/1000 [18:44<16:03:54, 58.95s/it, lr=0.0005, test_MAE=0.817, time=59, train_MAE=0.669, train_loss=0.669, val_MAE=0.779, val_loss=0.779]Epoch 19:   2%|▏         | 19/1000 [18:44<16:03:54, 58.95s/it, lr=0.0005, test_MAE=0.817, time=59, train_MAE=0.669, train_loss=0.669, val_MAE=0.779, val_loss=0.779]Epoch 19:   2%|▏         | 19/1000 [19:43<16:03:54, 58.95s/it, lr=0.0005, test_MAE=0.762, time=59, train_MAE=0.675, train_loss=0.675, val_MAE=0.72, val_loss=0.72]  Epoch 19:   2%|▏         | 20/1000 [19:43<16:03:24, 58.98s/it, lr=0.0005, test_MAE=0.762, time=59, train_MAE=0.675, train_loss=0.675, val_MAE=0.72, val_loss=0.72]Epoch 20:   2%|▏         | 20/1000 [19:43<16:03:24, 58.98s/it, lr=0.0005, test_MAE=0.762, time=59, train_MAE=0.675, train_loss=0.675, val_MAE=0.72, val_loss=0.72]Epoch 20:   2%|▏         | 20/1000 [20:43<16:03:24, 58.98s/it, lr=0.0005, test_MAE=0.803, time=59.5, train_MAE=0.679, train_loss=0.679, val_MAE=0.767, val_loss=0.767]Epoch 20:   2%|▏         | 21/1000 [20:43<16:04:54, 59.14s/it, lr=0.0005, test_MAE=0.803, time=59.5, train_MAE=0.679, train_loss=0.679, val_MAE=0.767, val_loss=0.767]Epoch 21:   2%|▏         | 21/1000 [20:43<16:04:54, 59.14s/it, lr=0.0005, test_MAE=0.803, time=59.5, train_MAE=0.679, train_loss=0.679, val_MAE=0.767, val_loss=0.767]Epoch 21:   2%|▏         | 21/1000 [21:40<16:04:54, 59.14s/it, lr=0.0005, test_MAE=0.791, time=57, train_MAE=0.672, train_loss=0.672, val_MAE=0.755, val_loss=0.755]  Epoch 21:   2%|▏         | 22/1000 [21:40<15:53:27, 58.49s/it, lr=0.0005, test_MAE=0.791, time=57, train_MAE=0.672, train_loss=0.672, val_MAE=0.755, val_loss=0.755]Epoch 22:   2%|▏         | 22/1000 [21:40<15:53:27, 58.49s/it, lr=0.0005, test_MAE=0.791, time=57, train_MAE=0.672, train_loss=0.672, val_MAE=0.755, val_loss=0.755]Epoch 22:   2%|▏         | 22/1000 [22:38<15:53:27, 58.49s/it, lr=0.0005, test_MAE=0.754, time=58.7, train_MAE=0.661, train_loss=0.661, val_MAE=0.716, val_loss=0.716]Epoch 22:   2%|▏         | 23/1000 [22:38<15:53:38, 58.57s/it, lr=0.0005, test_MAE=0.754, time=58.7, train_MAE=0.661, train_loss=0.661, val_MAE=0.716, val_loss=0.716]Epoch 23:   2%|▏         | 23/1000 [22:38<15:53:38, 58.57s/it, lr=0.0005, test_MAE=0.754, time=58.7, train_MAE=0.661, train_loss=0.661, val_MAE=0.716, val_loss=0.716]Epoch 23:   2%|▏         | 23/1000 [23:38<15:53:38, 58.57s/it, lr=0.0005, test_MAE=0.799, time=59.9, train_MAE=0.649, train_loss=0.649, val_MAE=0.761, val_loss=0.761]Epoch 23:   2%|▏         | 24/1000 [23:38<15:59:07, 58.96s/it, lr=0.0005, test_MAE=0.799, time=59.9, train_MAE=0.649, train_loss=0.649, val_MAE=0.761, val_loss=0.761]Epoch 24:   2%|▏         | 24/1000 [23:38<15:59:07, 58.96s/it, lr=0.0005, test_MAE=0.799, time=59.9, train_MAE=0.649, train_loss=0.649, val_MAE=0.761, val_loss=0.761]Epoch 24:   2%|▏         | 24/1000 [24:38<15:59:07, 58.96s/it, lr=0.0005, test_MAE=0.739, time=59.9, train_MAE=0.648, train_loss=0.648, val_MAE=0.7, val_loss=0.7]    Epoch 24:   2%|▎         | 25/1000 [24:38<16:02:49, 59.25s/it, lr=0.0005, test_MAE=0.739, time=59.9, train_MAE=0.648, train_loss=0.648, val_MAE=0.7, val_loss=0.7]Epoch 25:   2%|▎         | 25/1000 [24:38<16:02:49, 59.25s/it, lr=0.0005, test_MAE=0.739, time=59.9, train_MAE=0.648, train_loss=0.648, val_MAE=0.7, val_loss=0.7]Epoch 25:   2%|▎         | 25/1000 [25:37<16:02:49, 59.25s/it, lr=0.0005, test_MAE=0.789, time=59.1, train_MAE=0.642, train_loss=0.642, val_MAE=0.754, val_loss=0.754]Epoch 25:   3%|▎         | 26/1000 [25:37<16:01:05, 59.20s/it, lr=0.0005, test_MAE=0.789, time=59.1, train_MAE=0.642, train_loss=0.642, val_MAE=0.754, val_loss=0.754]Epoch 26:   3%|▎         | 26/1000 [25:37<16:01:05, 59.20s/it, lr=0.0005, test_MAE=0.789, time=59.1, train_MAE=0.642, train_loss=0.642, val_MAE=0.754, val_loss=0.754]Epoch 26:   3%|▎         | 26/1000 [26:35<16:01:05, 59.20s/it, lr=0.0005, test_MAE=0.758, time=58.2, train_MAE=0.643, train_loss=0.643, val_MAE=0.721, val_loss=0.721]Epoch 26:   3%|▎         | 27/1000 [26:35<15:55:17, 58.91s/it, lr=0.0005, test_MAE=0.758, time=58.2, train_MAE=0.643, train_loss=0.643, val_MAE=0.721, val_loss=0.721]Epoch 27:   3%|▎         | 27/1000 [26:35<15:55:17, 58.91s/it, lr=0.0005, test_MAE=0.758, time=58.2, train_MAE=0.643, train_loss=0.643, val_MAE=0.721, val_loss=0.721]Epoch 27:   3%|▎         | 27/1000 [27:35<15:55:17, 58.91s/it, lr=0.0005, test_MAE=0.755, time=59.9, train_MAE=0.64, train_loss=0.64, val_MAE=0.719, val_loss=0.719]  Epoch 27:   3%|▎         | 28/1000 [27:35<15:59:21, 59.22s/it, lr=0.0005, test_MAE=0.755, time=59.9, train_MAE=0.64, train_loss=0.64, val_MAE=0.719, val_loss=0.719]Epoch 28:   3%|▎         | 28/1000 [27:35<15:59:21, 59.22s/it, lr=0.0005, test_MAE=0.755, time=59.9, train_MAE=0.64, train_loss=0.64, val_MAE=0.719, val_loss=0.719]Epoch 28:   3%|▎         | 28/1000 [28:35<15:59:21, 59.22s/it, lr=0.0005, test_MAE=0.803, time=60, train_MAE=0.636, train_loss=0.636, val_MAE=0.765, val_loss=0.765]Epoch 28:   3%|▎         | 29/1000 [28:35<16:02:10, 59.45s/it, lr=0.0005, test_MAE=0.803, time=60, train_MAE=0.636, train_loss=0.636, val_MAE=0.765, val_loss=0.765]Epoch 29:   3%|▎         | 29/1000 [28:35<16:02:10, 59.45s/it, lr=0.0005, test_MAE=0.803, time=60, train_MAE=0.636, train_loss=0.636, val_MAE=0.765, val_loss=0.765]Epoch 29:   3%|▎         | 29/1000 [29:34<16:02:10, 59.45s/it, lr=0.0005, test_MAE=0.754, time=59, train_MAE=0.628, train_loss=0.628, val_MAE=0.72, val_loss=0.72]  Epoch 29:   3%|▎         | 30/1000 [29:34<15:59:02, 59.32s/it, lr=0.0005, test_MAE=0.754, time=59, train_MAE=0.628, train_loss=0.628, val_MAE=0.72, val_loss=0.72]Epoch 30:   3%|▎         | 30/1000 [29:34<15:59:02, 59.32s/it, lr=0.0005, test_MAE=0.754, time=59, train_MAE=0.628, train_loss=0.628, val_MAE=0.72, val_loss=0.72]Epoch 30:   3%|▎         | 30/1000 [30:33<15:59:02, 59.32s/it, lr=0.0005, test_MAE=0.794, time=58.2, train_MAE=0.639, train_loss=0.639, val_MAE=0.756, val_loss=0.756]Epoch    31: reducing learning rate of group 0 to 2.5000e-04.
Epoch 30:   3%|▎         | 31/1000 [30:33<15:52:34, 58.98s/it, lr=0.0005, test_MAE=0.794, time=58.2, train_MAE=0.639, train_loss=0.639, val_MAE=0.756, val_loss=0.756]Epoch 31:   3%|▎         | 31/1000 [30:33<15:52:34, 58.98s/it, lr=0.0005, test_MAE=0.794, time=58.2, train_MAE=0.639, train_loss=0.639, val_MAE=0.756, val_loss=0.756]Epoch 31:   3%|▎         | 31/1000 [31:33<15:52:34, 58.98s/it, lr=0.00025, test_MAE=0.751, time=60.1, train_MAE=0.628, train_loss=0.628, val_MAE=0.714, val_loss=0.714]Epoch 31:   3%|▎         | 32/1000 [31:33<15:57:20, 59.34s/it, lr=0.00025, test_MAE=0.751, time=60.1, train_MAE=0.628, train_loss=0.628, val_MAE=0.714, val_loss=0.714]Epoch 32:   3%|▎         | 32/1000 [31:33<15:57:20, 59.34s/it, lr=0.00025, test_MAE=0.751, time=60.1, train_MAE=0.628, train_loss=0.628, val_MAE=0.714, val_loss=0.714]Epoch 32:   3%|▎         | 32/1000 [32:32<15:57:20, 59.34s/it, lr=0.00025, test_MAE=0.747, time=59.4, train_MAE=0.628, train_loss=0.628, val_MAE=0.711, val_loss=0.711]Epoch 32:   3%|▎         | 33/1000 [32:32<15:56:41, 59.36s/it, lr=0.00025, test_MAE=0.747, time=59.4, train_MAE=0.628, train_loss=0.628, val_MAE=0.711, val_loss=0.711]Epoch 33:   3%|▎         | 33/1000 [32:32<15:56:41, 59.36s/it, lr=0.00025, test_MAE=0.747, time=59.4, train_MAE=0.628, train_loss=0.628, val_MAE=0.711, val_loss=0.711]Epoch 33:   3%|▎         | 33/1000 [33:31<15:56:41, 59.36s/it, lr=0.00025, test_MAE=0.734, time=59.3, train_MAE=0.627, train_loss=0.627, val_MAE=0.698, val_loss=0.698]Epoch 33:   3%|▎         | 34/1000 [33:31<15:55:36, 59.35s/it, lr=0.00025, test_MAE=0.734, time=59.3, train_MAE=0.627, train_loss=0.627, val_MAE=0.698, val_loss=0.698]Epoch 34:   3%|▎         | 34/1000 [33:31<15:55:36, 59.35s/it, lr=0.00025, test_MAE=0.734, time=59.3, train_MAE=0.627, train_loss=0.627, val_MAE=0.698, val_loss=0.698]Epoch 34:   3%|▎         | 34/1000 [34:29<15:55:36, 59.35s/it, lr=0.00025, test_MAE=0.789, time=57.5, train_MAE=0.62, train_loss=0.62, val_MAE=0.753, val_loss=0.753]  Epoch 34:   4%|▎         | 35/1000 [34:29<15:45:52, 58.81s/it, lr=0.00025, test_MAE=0.789, time=57.5, train_MAE=0.62, train_loss=0.62, val_MAE=0.753, val_loss=0.753]Epoch 35:   4%|▎         | 35/1000 [34:29<15:45:52, 58.81s/it, lr=0.00025, test_MAE=0.789, time=57.5, train_MAE=0.62, train_loss=0.62, val_MAE=0.753, val_loss=0.753]Epoch 35:   4%|▎         | 35/1000 [35:28<15:45:52, 58.81s/it, lr=0.00025, test_MAE=0.751, time=58.8, train_MAE=0.625, train_loss=0.625, val_MAE=0.716, val_loss=0.716]Epoch 35:   4%|▎         | 36/1000 [35:28<15:45:02, 58.82s/it, lr=0.00025, test_MAE=0.751, time=58.8, train_MAE=0.625, train_loss=0.625, val_MAE=0.716, val_loss=0.716]Epoch 36:   4%|▎         | 36/1000 [35:28<15:45:02, 58.82s/it, lr=0.00025, test_MAE=0.751, time=58.8, train_MAE=0.625, train_loss=0.625, val_MAE=0.716, val_loss=0.716]Epoch 36:   4%|▎         | 36/1000 [36:28<15:45:02, 58.82s/it, lr=0.00025, test_MAE=0.726, time=59.7, train_MAE=0.621, train_loss=0.621, val_MAE=0.69, val_loss=0.69]  Epoch 36:   4%|▎         | 37/1000 [36:28<15:48:38, 59.10s/it, lr=0.00025, test_MAE=0.726, time=59.7, train_MAE=0.621, train_loss=0.621, val_MAE=0.69, val_loss=0.69]Epoch 37:   4%|▎         | 37/1000 [36:28<15:48:38, 59.10s/it, lr=0.00025, test_MAE=0.726, time=59.7, train_MAE=0.621, train_loss=0.621, val_MAE=0.69, val_loss=0.69]Epoch 37:   4%|▎         | 37/1000 [37:26<15:48:38, 59.10s/it, lr=0.00025, test_MAE=0.749, time=58.8, train_MAE=0.623, train_loss=0.623, val_MAE=0.712, val_loss=0.712]Epoch 37:   4%|▍         | 38/1000 [37:26<15:46:32, 59.04s/it, lr=0.00025, test_MAE=0.749, time=58.8, train_MAE=0.623, train_loss=0.623, val_MAE=0.712, val_loss=0.712]Epoch 38:   4%|▍         | 38/1000 [37:26<15:46:32, 59.04s/it, lr=0.00025, test_MAE=0.749, time=58.8, train_MAE=0.623, train_loss=0.623, val_MAE=0.712, val_loss=0.712]Epoch 38:   4%|▍         | 38/1000 [38:26<15:46:32, 59.04s/it, lr=0.00025, test_MAE=0.751, time=59.3, train_MAE=0.624, train_loss=0.624, val_MAE=0.713, val_loss=0.713]Epoch 38:   4%|▍         | 39/1000 [38:26<15:46:44, 59.11s/it, lr=0.00025, test_MAE=0.751, time=59.3, train_MAE=0.624, train_loss=0.624, val_MAE=0.713, val_loss=0.713]Epoch 39:   4%|▍         | 39/1000 [38:26<15:46:44, 59.11s/it, lr=0.00025, test_MAE=0.751, time=59.3, train_MAE=0.624, train_loss=0.624, val_MAE=0.713, val_loss=0.713]Epoch 39:   4%|▍         | 39/1000 [39:25<15:46:44, 59.11s/it, lr=0.00025, test_MAE=0.733, time=59.2, train_MAE=0.62, train_loss=0.62, val_MAE=0.697, val_loss=0.697]  Epoch 39:   4%|▍         | 40/1000 [39:25<15:46:13, 59.14s/it, lr=0.00025, test_MAE=0.733, time=59.2, train_MAE=0.62, train_loss=0.62, val_MAE=0.697, val_loss=0.697]Epoch 40:   4%|▍         | 40/1000 [39:25<15:46:13, 59.14s/it, lr=0.00025, test_MAE=0.733, time=59.2, train_MAE=0.62, train_loss=0.62, val_MAE=0.697, val_loss=0.697]Epoch 40:   4%|▍         | 40/1000 [40:24<15:46:13, 59.14s/it, lr=0.00025, test_MAE=0.762, time=59.3, train_MAE=0.618, train_loss=0.618, val_MAE=0.724, val_loss=0.724]Epoch 40:   4%|▍         | 41/1000 [40:24<15:46:04, 59.19s/it, lr=0.00025, test_MAE=0.762, time=59.3, train_MAE=0.618, train_loss=0.618, val_MAE=0.724, val_loss=0.724]Epoch 41:   4%|▍         | 41/1000 [40:24<15:46:04, 59.19s/it, lr=0.00025, test_MAE=0.762, time=59.3, train_MAE=0.618, train_loss=0.618, val_MAE=0.724, val_loss=0.724]Epoch 41:   4%|▍         | 41/1000 [41:23<15:46:04, 59.19s/it, lr=0.00025, test_MAE=0.777, time=58.3, train_MAE=0.622, train_loss=0.622, val_MAE=0.738, val_loss=0.738]Epoch 41:   4%|▍         | 42/1000 [41:23<15:40:46, 58.92s/it, lr=0.00025, test_MAE=0.777, time=58.3, train_MAE=0.622, train_loss=0.622, val_MAE=0.738, val_loss=0.738]Epoch 42:   4%|▍         | 42/1000 [41:23<15:40:46, 58.92s/it, lr=0.00025, test_MAE=0.777, time=58.3, train_MAE=0.622, train_loss=0.622, val_MAE=0.738, val_loss=0.738]Epoch 42:   4%|▍         | 42/1000 [42:19<15:40:46, 58.92s/it, lr=0.00025, test_MAE=0.737, time=56.6, train_MAE=0.608, train_loss=0.608, val_MAE=0.7, val_loss=0.7]    Epoch    43: reducing learning rate of group 0 to 1.2500e-04.
Epoch 42:   4%|▍         | 43/1000 [42:19<15:29:02, 58.25s/it, lr=0.00025, test_MAE=0.737, time=56.6, train_MAE=0.608, train_loss=0.608, val_MAE=0.7, val_loss=0.7]Epoch 43:   4%|▍         | 43/1000 [42:19<15:29:02, 58.25s/it, lr=0.00025, test_MAE=0.737, time=56.6, train_MAE=0.608, train_loss=0.608, val_MAE=0.7, val_loss=0.7]Epoch 43:   4%|▍         | 43/1000 [43:18<15:29:02, 58.25s/it, lr=0.000125, test_MAE=0.75, time=59.1, train_MAE=0.61, train_loss=0.61, val_MAE=0.713, val_loss=0.713]Epoch 43:   4%|▍         | 44/1000 [43:18<15:32:02, 58.50s/it, lr=0.000125, test_MAE=0.75, time=59.1, train_MAE=0.61, train_loss=0.61, val_MAE=0.713, val_loss=0.713]Epoch 44:   4%|▍         | 44/1000 [43:18<15:32:02, 58.50s/it, lr=0.000125, test_MAE=0.75, time=59.1, train_MAE=0.61, train_loss=0.61, val_MAE=0.713, val_loss=0.713]Epoch 44:   4%|▍         | 44/1000 [44:17<15:32:02, 58.50s/it, lr=0.000125, test_MAE=0.75, time=58.8, train_MAE=0.611, train_loss=0.611, val_MAE=0.715, val_loss=0.715]Epoch 44:   4%|▍         | 45/1000 [44:17<15:32:38, 58.59s/it, lr=0.000125, test_MAE=0.75, time=58.8, train_MAE=0.611, train_loss=0.611, val_MAE=0.715, val_loss=0.715]Epoch 45:   4%|▍         | 45/1000 [44:17<15:32:38, 58.59s/it, lr=0.000125, test_MAE=0.75, time=58.8, train_MAE=0.611, train_loss=0.611, val_MAE=0.715, val_loss=0.715]Epoch 45:   4%|▍         | 45/1000 [45:16<15:32:38, 58.59s/it, lr=0.000125, test_MAE=0.75, time=58.5, train_MAE=0.611, train_loss=0.611, val_MAE=0.713, val_loss=0.713]Epoch 45:   5%|▍         | 46/1000 [45:16<15:31:17, 58.57s/it, lr=0.000125, test_MAE=0.75, time=58.5, train_MAE=0.611, train_loss=0.611, val_MAE=0.713, val_loss=0.713]Epoch 46:   5%|▍         | 46/1000 [45:16<15:31:17, 58.57s/it, lr=0.000125, test_MAE=0.75, time=58.5, train_MAE=0.611, train_loss=0.611, val_MAE=0.713, val_loss=0.713]Epoch 46:   5%|▍         | 46/1000 [46:13<15:31:17, 58.57s/it, lr=0.000125, test_MAE=0.747, time=57.3, train_MAE=0.62, train_loss=0.62, val_MAE=0.713, val_loss=0.713] Epoch 46:   5%|▍         | 47/1000 [46:13<15:24:17, 58.19s/it, lr=0.000125, test_MAE=0.747, time=57.3, train_MAE=0.62, train_loss=0.62, val_MAE=0.713, val_loss=0.713]Epoch 47:   5%|▍         | 47/1000 [46:13<15:24:17, 58.19s/it, lr=0.000125, test_MAE=0.747, time=57.3, train_MAE=0.62, train_loss=0.62, val_MAE=0.713, val_loss=0.713]Epoch 47:   5%|▍         | 47/1000 [47:10<15:24:17, 58.19s/it, lr=0.000125, test_MAE=0.765, time=56.9, train_MAE=0.607, train_loss=0.607, val_MAE=0.729, val_loss=0.729]Epoch 47:   5%|▍         | 48/1000 [47:10<15:17:06, 57.80s/it, lr=0.000125, test_MAE=0.765, time=56.9, train_MAE=0.607, train_loss=0.607, val_MAE=0.729, val_loss=0.729]Epoch 48:   5%|▍         | 48/1000 [47:10<15:17:06, 57.80s/it, lr=0.000125, test_MAE=0.765, time=56.9, train_MAE=0.607, train_loss=0.607, val_MAE=0.729, val_loss=0.729]Epoch 48:   5%|▍         | 48/1000 [48:09<15:17:06, 57.80s/it, lr=0.000125, test_MAE=0.745, time=58.8, train_MAE=0.608, train_loss=0.608, val_MAE=0.709, val_loss=0.709]Epoch    49: reducing learning rate of group 0 to 6.2500e-05.
Epoch 48:   5%|▍         | 49/1000 [48:09<15:21:10, 58.12s/it, lr=0.000125, test_MAE=0.745, time=58.8, train_MAE=0.608, train_loss=0.608, val_MAE=0.709, val_loss=0.709]Epoch 49:   5%|▍         | 49/1000 [48:09<15:21:10, 58.12s/it, lr=0.000125, test_MAE=0.745, time=58.8, train_MAE=0.608, train_loss=0.608, val_MAE=0.709, val_loss=0.709]Epoch 49:   5%|▍         | 49/1000 [49:07<15:21:10, 58.12s/it, lr=6.25e-5, test_MAE=0.744, time=58.7, train_MAE=0.611, train_loss=0.611, val_MAE=0.708, val_loss=0.708] Epoch 49:   5%|▌         | 50/1000 [49:07<15:22:52, 58.29s/it, lr=6.25e-5, test_MAE=0.744, time=58.7, train_MAE=0.611, train_loss=0.611, val_MAE=0.708, val_loss=0.708]Epoch 50:   5%|▌         | 50/1000 [49:07<15:22:52, 58.29s/it, lr=6.25e-5, test_MAE=0.744, time=58.7, train_MAE=0.611, train_loss=0.611, val_MAE=0.708, val_loss=0.708]Epoch 50:   5%|▌         | 50/1000 [50:06<15:22:52, 58.29s/it, lr=6.25e-5, test_MAE=0.743, time=58.9, train_MAE=0.601, train_loss=0.601, val_MAE=0.707, val_loss=0.707]Epoch 50:   5%|▌         | 51/1000 [50:06<15:24:57, 58.48s/it, lr=6.25e-5, test_MAE=0.743, time=58.9, train_MAE=0.601, train_loss=0.601, val_MAE=0.707, val_loss=0.707]Epoch 51:   5%|▌         | 51/1000 [50:06<15:24:57, 58.48s/it, lr=6.25e-5, test_MAE=0.743, time=58.9, train_MAE=0.601, train_loss=0.601, val_MAE=0.707, val_loss=0.707]Epoch 51:   5%|▌         | 51/1000 [51:05<15:24:57, 58.48s/it, lr=6.25e-5, test_MAE=0.745, time=58.8, train_MAE=0.604, train_loss=0.604, val_MAE=0.71, val_loss=0.71]  Epoch 51:   5%|▌         | 52/1000 [51:05<15:25:34, 58.58s/it, lr=6.25e-5, test_MAE=0.745, time=58.8, train_MAE=0.604, train_loss=0.604, val_MAE=0.71, val_loss=0.71]Epoch 52:   5%|▌         | 52/1000 [51:05<15:25:34, 58.58s/it, lr=6.25e-5, test_MAE=0.745, time=58.8, train_MAE=0.604, train_loss=0.604, val_MAE=0.71, val_loss=0.71]Epoch 52:   5%|▌         | 52/1000 [52:05<15:25:34, 58.58s/it, lr=6.25e-5, test_MAE=0.74, time=60.3, train_MAE=0.605, train_loss=0.605, val_MAE=0.704, val_loss=0.704]Epoch 52:   5%|▌         | 53/1000 [52:05<15:32:48, 59.10s/it, lr=6.25e-5, test_MAE=0.74, time=60.3, train_MAE=0.605, train_loss=0.605, val_MAE=0.704, val_loss=0.704]Epoch 53:   5%|▌         | 53/1000 [52:05<15:32:48, 59.10s/it, lr=6.25e-5, test_MAE=0.74, time=60.3, train_MAE=0.605, train_loss=0.605, val_MAE=0.704, val_loss=0.704]Epoch 53:   5%|▌         | 53/1000 [53:06<15:32:48, 59.10s/it, lr=6.25e-5, test_MAE=0.737, time=60.4, train_MAE=0.601, train_loss=0.601, val_MAE=0.703, val_loss=0.703]Epoch 53:   5%|▌         | 54/1000 [53:06<15:37:59, 59.49s/it, lr=6.25e-5, test_MAE=0.737, time=60.4, train_MAE=0.601, train_loss=0.601, val_MAE=0.703, val_loss=0.703]Epoch 54:   5%|▌         | 54/1000 [53:06<15:37:59, 59.49s/it, lr=6.25e-5, test_MAE=0.737, time=60.4, train_MAE=0.601, train_loss=0.601, val_MAE=0.703, val_loss=0.703]Epoch 54:   5%|▌         | 54/1000 [54:06<15:37:59, 59.49s/it, lr=6.25e-5, test_MAE=0.741, time=59.9, train_MAE=0.604, train_loss=0.604, val_MAE=0.705, val_loss=0.705]Epoch    55: reducing learning rate of group 0 to 3.1250e-05.
Epoch 54:   6%|▌         | 55/1000 [54:06<15:38:53, 59.61s/it, lr=6.25e-5, test_MAE=0.741, time=59.9, train_MAE=0.604, train_loss=0.604, val_MAE=0.705, val_loss=0.705]Epoch 55:   6%|▌         | 55/1000 [54:06<15:38:53, 59.61s/it, lr=6.25e-5, test_MAE=0.741, time=59.9, train_MAE=0.604, train_loss=0.604, val_MAE=0.705, val_loss=0.705]Epoch 55:   6%|▌         | 55/1000 [55:06<15:38:53, 59.61s/it, lr=3.13e-5, test_MAE=0.757, time=60, train_MAE=0.604, train_loss=0.604, val_MAE=0.721, val_loss=0.721]  Epoch 55:   6%|▌         | 56/1000 [55:06<15:40:03, 59.75s/it, lr=3.13e-5, test_MAE=0.757, time=60, train_MAE=0.604, train_loss=0.604, val_MAE=0.721, val_loss=0.721]Epoch 56:   6%|▌         | 56/1000 [55:06<15:40:03, 59.75s/it, lr=3.13e-5, test_MAE=0.757, time=60, train_MAE=0.604, train_loss=0.604, val_MAE=0.721, val_loss=0.721]Epoch 56:   6%|▌         | 56/1000 [56:07<15:40:03, 59.75s/it, lr=3.13e-5, test_MAE=0.755, time=61.2, train_MAE=0.605, train_loss=0.605, val_MAE=0.718, val_loss=0.718]Epoch 56:   6%|▌         | 57/1000 [56:07<15:45:53, 60.18s/it, lr=3.13e-5, test_MAE=0.755, time=61.2, train_MAE=0.605, train_loss=0.605, val_MAE=0.718, val_loss=0.718]Epoch 57:   6%|▌         | 57/1000 [56:07<15:45:53, 60.18s/it, lr=3.13e-5, test_MAE=0.755, time=61.2, train_MAE=0.605, train_loss=0.605, val_MAE=0.718, val_loss=0.718]Epoch 57:   6%|▌         | 57/1000 [57:08<15:45:53, 60.18s/it, lr=3.13e-5, test_MAE=0.746, time=60.5, train_MAE=0.61, train_loss=0.61, val_MAE=0.71, val_loss=0.71]    Epoch 57:   6%|▌         | 58/1000 [57:08<15:46:40, 60.30s/it, lr=3.13e-5, test_MAE=0.746, time=60.5, train_MAE=0.61, train_loss=0.61, val_MAE=0.71, val_loss=0.71]Epoch 58:   6%|▌         | 58/1000 [57:08<15:46:40, 60.30s/it, lr=3.13e-5, test_MAE=0.746, time=60.5, train_MAE=0.61, train_loss=0.61, val_MAE=0.71, val_loss=0.71]Epoch 58:   6%|▌         | 58/1000 [58:09<15:46:40, 60.30s/it, lr=3.13e-5, test_MAE=0.764, time=61.1, train_MAE=0.606, train_loss=0.606, val_MAE=0.726, val_loss=0.726]Epoch 58:   6%|▌         | 59/1000 [58:09<15:49:34, 60.55s/it, lr=3.13e-5, test_MAE=0.764, time=61.1, train_MAE=0.606, train_loss=0.606, val_MAE=0.726, val_loss=0.726]Epoch 59:   6%|▌         | 59/1000 [58:09<15:49:34, 60.55s/it, lr=3.13e-5, test_MAE=0.764, time=61.1, train_MAE=0.606, train_loss=0.606, val_MAE=0.726, val_loss=0.726]Epoch 59:   6%|▌         | 59/1000 [59:09<15:49:34, 60.55s/it, lr=3.13e-5, test_MAE=0.765, time=60.8, train_MAE=0.605, train_loss=0.605, val_MAE=0.728, val_loss=0.728]Epoch 59:   6%|▌         | 60/1000 [59:09<15:49:39, 60.62s/it, lr=3.13e-5, test_MAE=0.765, time=60.8, train_MAE=0.605, train_loss=0.605, val_MAE=0.728, val_loss=0.728]Epoch 60:   6%|▌         | 60/1000 [59:09<15:49:39, 60.62s/it, lr=3.13e-5, test_MAE=0.765, time=60.8, train_MAE=0.605, train_loss=0.605, val_MAE=0.728, val_loss=0.728]Epoch 60:   6%|▌         | 60/1000 [1:00:09<15:49:39, 60.62s/it, lr=3.13e-5, test_MAE=0.745, time=59.9, train_MAE=0.612, train_loss=0.612, val_MAE=0.708, val_loss=0.708]Epoch    61: reducing learning rate of group 0 to 1.5625e-05.
Epoch 60:   6%|▌         | 61/1000 [1:00:09<15:45:15, 60.40s/it, lr=3.13e-5, test_MAE=0.745, time=59.9, train_MAE=0.612, train_loss=0.612, val_MAE=0.708, val_loss=0.708]Epoch 61:   6%|▌         | 61/1000 [1:00:09<15:45:15, 60.40s/it, lr=3.13e-5, test_MAE=0.745, time=59.9, train_MAE=0.612, train_loss=0.612, val_MAE=0.708, val_loss=0.708]Epoch 61:   6%|▌         | 61/1000 [1:01:09<15:45:15, 60.40s/it, lr=1.56e-5, test_MAE=0.737, time=59.4, train_MAE=0.602, train_loss=0.602, val_MAE=0.701, val_loss=0.701]Epoch 61:   6%|▌         | 62/1000 [1:01:09<15:39:50, 60.12s/it, lr=1.56e-5, test_MAE=0.737, time=59.4, train_MAE=0.602, train_loss=0.602, val_MAE=0.701, val_loss=0.701]Epoch 62:   6%|▌         | 62/1000 [1:01:09<15:39:50, 60.12s/it, lr=1.56e-5, test_MAE=0.737, time=59.4, train_MAE=0.602, train_loss=0.602, val_MAE=0.701, val_loss=0.701]Epoch 62:   6%|▌         | 62/1000 [1:02:08<15:39:50, 60.12s/it, lr=1.56e-5, test_MAE=0.742, time=59.2, train_MAE=0.598, train_loss=0.598, val_MAE=0.705, val_loss=0.705]Epoch 62:   6%|▋         | 63/1000 [1:02:08<15:34:47, 59.86s/it, lr=1.56e-5, test_MAE=0.742, time=59.2, train_MAE=0.598, train_loss=0.598, val_MAE=0.705, val_loss=0.705]Epoch 63:   6%|▋         | 63/1000 [1:02:08<15:34:47, 59.86s/it, lr=1.56e-5, test_MAE=0.742, time=59.2, train_MAE=0.598, train_loss=0.598, val_MAE=0.705, val_loss=0.705]Epoch 63:   6%|▋         | 63/1000 [1:03:07<15:34:47, 59.86s/it, lr=1.56e-5, test_MAE=0.759, time=58.9, train_MAE=0.614, train_loss=0.614, val_MAE=0.722, val_loss=0.722]Epoch 63:   6%|▋         | 64/1000 [1:03:07<15:29:21, 59.57s/it, lr=1.56e-5, test_MAE=0.759, time=58.9, train_MAE=0.614, train_loss=0.614, val_MAE=0.722, val_loss=0.722]Epoch 64:   6%|▋         | 64/1000 [1:03:07<15:29:21, 59.57s/it, lr=1.56e-5, test_MAE=0.759, time=58.9, train_MAE=0.614, train_loss=0.614, val_MAE=0.722, val_loss=0.722]Epoch 64:   6%|▋         | 64/1000 [1:04:06<15:29:21, 59.57s/it, lr=1.56e-5, test_MAE=0.736, time=58.8, train_MAE=0.603, train_loss=0.603, val_MAE=0.699, val_loss=0.699]Epoch 64:   6%|▋         | 65/1000 [1:04:06<15:25:02, 59.36s/it, lr=1.56e-5, test_MAE=0.736, time=58.8, train_MAE=0.603, train_loss=0.603, val_MAE=0.699, val_loss=0.699]Epoch 65:   6%|▋         | 65/1000 [1:04:06<15:25:02, 59.36s/it, lr=1.56e-5, test_MAE=0.736, time=58.8, train_MAE=0.603, train_loss=0.603, val_MAE=0.699, val_loss=0.699]Epoch 65:   6%|▋         | 65/1000 [1:05:04<15:25:02, 59.36s/it, lr=1.56e-5, test_MAE=0.751, time=58.1, train_MAE=0.601, train_loss=0.601, val_MAE=0.714, val_loss=0.714]Epoch 65:   7%|▋         | 66/1000 [1:05:04<15:18:13, 58.99s/it, lr=1.56e-5, test_MAE=0.751, time=58.1, train_MAE=0.601, train_loss=0.601, val_MAE=0.714, val_loss=0.714]Epoch 66:   7%|▋         | 66/1000 [1:05:04<15:18:13, 58.99s/it, lr=1.56e-5, test_MAE=0.751, time=58.1, train_MAE=0.601, train_loss=0.601, val_MAE=0.714, val_loss=0.714]Epoch 66:   7%|▋         | 66/1000 [1:06:02<15:18:13, 58.99s/it, lr=1.56e-5, test_MAE=0.755, time=58.3, train_MAE=0.609, train_loss=0.609, val_MAE=0.719, val_loss=0.719]Epoch    67: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 66:   7%|▋         | 66/1000 [1:06:02<15:34:39, 60.04s/it, lr=1.56e-5, test_MAE=0.755, time=58.3, train_MAE=0.609, train_loss=0.609, val_MAE=0.719, val_loss=0.719]
Test MAE: 0.7553
Train MAE: 0.6186
Convergence Time (Epochs): 66.0000
TOTAL TIME TAKEN: 3992.2335s
AVG TIME PER EPOCH: 59.1187s
Traceback (most recent call last):
  File "main_molecules_graph_regression.py", line 398, in <module>
    main()
  File "main_molecules_graph_regression.py", line 395, in main
    train_val_pipeline(MODEL_NAME, dataset, params, net_params, dirs)
  File "main_molecules_graph_regression.py", line 217, in train_val_pipeline
    test_mae, train_mae, epoch, (time.time() - t0) / 3600, np.mean(per_epoch_time)))
  File "/home/bsw38/.conda/envs/benchmark_gnn_2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1347, in __repr__
    mod_str = repr(module)
  File "/home/bsw38/.conda/envs/benchmark_gnn_2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1347, in __repr__
    mod_str = repr(module)
  File "/vast/palmer/pi/krishnaswamy_smita/bsw38/GraphML/ChebNetGNNs/Benchmark-gnn/layers/Spec_layer.py", line 228, in __repr__
    self.__class__.__name__, self.in_channels, self.out_channels, self._k)
  File "/home/bsw38/.conda/envs/benchmark_gnn_2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 772, in __getattr__
    type(self).__name__, name))
torch.nn.modules.module.ModuleAttributeError: 'SpecLayer' object has no attribute '_k'
