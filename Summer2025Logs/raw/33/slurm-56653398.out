I'm echoing to stdout
I'm echoing to stderr
My JobID is 56653398
I have 8 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.0704s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 4, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'rational_vec', 'normalized_laplacian': True, 'post_normalized': False, 'eigval_norm': '', 'num_eigs': 15, 'bias_mode': 'spatial', 'eigval_hidden_dim': 5, 'eigval_num_hidden_layer': 3, 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 1, 'eigmod': '', 'eigInFiles': {'train': 'supp_data/molecules/zinc_train_kway.csv', 'test': 'supp_data/molecules/zinc_test_part_kway.csv', 'val': 'supp_data/molecules/zinc_val_kway.csv'}, 'fixMissingPhi1': True, 'extraOrtho': False, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [02:00<?, ?it/s, lr=0.001, test_MAE=1.86, time=120, train_MAE=1.21, train_loss=1.23, val_MAE=1.85, val_loss=1.88]Epoch 0:   0%|          | 1/1000 [02:00<33:23:37, 120.34s/it, lr=0.001, test_MAE=1.86, time=120, train_MAE=1.21, train_loss=1.23, val_MAE=1.85, val_loss=1.88]Epoch 1:   0%|          | 1/1000 [02:00<33:23:37, 120.34s/it, lr=0.001, test_MAE=1.86, time=120, train_MAE=1.21, train_loss=1.23, val_MAE=1.85, val_loss=1.88]Epoch 1:   0%|          | 1/1000 [03:53<33:23:37, 120.34s/it, lr=0.001, test_MAE=1.23, time=113, train_MAE=0.882, train_loss=0.915, val_MAE=1.14, val_loss=1.18]Epoch 1:   0%|          | 2/1000 [03:53<32:46:44, 118.24s/it, lr=0.001, test_MAE=1.23, time=113, train_MAE=0.882, train_loss=0.915, val_MAE=1.14, val_loss=1.18]Epoch 2:   0%|          | 2/1000 [03:53<32:46:44, 118.24s/it, lr=0.001, test_MAE=1.23, time=113, train_MAE=0.882, train_loss=0.915, val_MAE=1.14, val_loss=1.18]Epoch 2:   0%|          | 2/1000 [05:46<32:46:44, 118.24s/it, lr=0.001, test_MAE=1.06, time=113, train_MAE=0.736, train_loss=0.77, val_MAE=0.997, val_loss=1.03]Epoch 2:   0%|          | 3/1000 [05:46<32:20:11, 116.76s/it, lr=0.001, test_MAE=1.06, time=113, train_MAE=0.736, train_loss=0.77, val_MAE=0.997, val_loss=1.03]Epoch 3:   0%|          | 3/1000 [05:46<32:20:11, 116.76s/it, lr=0.001, test_MAE=1.06, time=113, train_MAE=0.736, train_loss=0.77, val_MAE=0.997, val_loss=1.03]Epoch 3:   0%|          | 3/1000 [07:40<32:20:11, 116.76s/it, lr=0.001, test_MAE=0.935, time=113, train_MAE=0.675, train_loss=0.71, val_MAE=0.868, val_loss=0.903]Epoch 3:   0%|          | 4/1000 [07:40<32:01:53, 115.78s/it, lr=0.001, test_MAE=0.935, time=113, train_MAE=0.675, train_loss=0.71, val_MAE=0.868, val_loss=0.903]Epoch 4:   0%|          | 4/1000 [07:40<32:01:53, 115.78s/it, lr=0.001, test_MAE=0.935, time=113, train_MAE=0.675, train_loss=0.71, val_MAE=0.868, val_loss=0.903]Epoch 4:   0%|          | 4/1000 [09:33<32:01:53, 115.78s/it, lr=0.001, test_MAE=0.798, time=113, train_MAE=0.642, train_loss=0.678, val_MAE=0.754, val_loss=0.79]Epoch 4:   0%|          | 5/1000 [09:33<31:45:32, 114.91s/it, lr=0.001, test_MAE=0.798, time=113, train_MAE=0.642, train_loss=0.678, val_MAE=0.754, val_loss=0.79]Epoch 5:   0%|          | 5/1000 [09:33<31:45:32, 114.91s/it, lr=0.001, test_MAE=0.798, time=113, train_MAE=0.642, train_loss=0.678, val_MAE=0.754, val_loss=0.79]Epoch 5:   0%|          | 5/1000 [11:26<31:45:32, 114.91s/it, lr=0.001, test_MAE=0.984, time=114, train_MAE=0.631, train_loss=0.668, val_MAE=0.941, val_loss=0.978]Epoch 5:   1%|          | 6/1000 [11:26<31:36:47, 114.49s/it, lr=0.001, test_MAE=0.984, time=114, train_MAE=0.631, train_loss=0.668, val_MAE=0.941, val_loss=0.978]Epoch 6:   1%|          | 6/1000 [11:26<31:36:47, 114.49s/it, lr=0.001, test_MAE=0.984, time=114, train_MAE=0.631, train_loss=0.668, val_MAE=0.941, val_loss=0.978]Epoch 6:   1%|          | 6/1000 [13:20<31:36:47, 114.49s/it, lr=0.001, test_MAE=0.71, time=114, train_MAE=0.606, train_loss=0.643, val_MAE=0.678, val_loss=0.716] Epoch 6:   1%|          | 7/1000 [13:20<31:30:11, 114.21s/it, lr=0.001, test_MAE=0.71, time=114, train_MAE=0.606, train_loss=0.643, val_MAE=0.678, val_loss=0.716]Epoch 7:   1%|          | 7/1000 [13:20<31:30:11, 114.21s/it, lr=0.001, test_MAE=0.71, time=114, train_MAE=0.606, train_loss=0.643, val_MAE=0.678, val_loss=0.716]Epoch 7:   1%|          | 7/1000 [15:13<31:30:11, 114.21s/it, lr=0.001, test_MAE=0.954, time=113, train_MAE=0.598, train_loss=0.636, val_MAE=0.915, val_loss=0.953]Epoch 7:   1%|          | 8/1000 [15:13<31:24:05, 113.96s/it, lr=0.001, test_MAE=0.954, time=113, train_MAE=0.598, train_loss=0.636, val_MAE=0.915, val_loss=0.953]Epoch 8:   1%|          | 8/1000 [15:13<31:24:05, 113.96s/it, lr=0.001, test_MAE=0.954, time=113, train_MAE=0.598, train_loss=0.636, val_MAE=0.915, val_loss=0.953]Epoch 8:   1%|          | 8/1000 [17:06<31:24:05, 113.96s/it, lr=0.001, test_MAE=0.943, time=113, train_MAE=0.591, train_loss=0.629, val_MAE=0.904, val_loss=0.942]Epoch 8:   1%|          | 9/1000 [17:06<31:16:56, 113.64s/it, lr=0.001, test_MAE=0.943, time=113, train_MAE=0.591, train_loss=0.629, val_MAE=0.904, val_loss=0.942]Epoch 9:   1%|          | 9/1000 [17:06<31:16:56, 113.64s/it, lr=0.001, test_MAE=0.943, time=113, train_MAE=0.591, train_loss=0.629, val_MAE=0.904, val_loss=0.942]Epoch 9:   1%|          | 9/1000 [19:00<31:16:56, 113.64s/it, lr=0.001, test_MAE=0.658, time=114, train_MAE=0.599, train_loss=0.638, val_MAE=0.636, val_loss=0.675]Epoch 9:   1%|          | 10/1000 [19:00<31:15:53, 113.69s/it, lr=0.001, test_MAE=0.658, time=114, train_MAE=0.599, train_loss=0.638, val_MAE=0.636, val_loss=0.675]Epoch 10:   1%|          | 10/1000 [19:00<31:15:53, 113.69s/it, lr=0.001, test_MAE=0.658, time=114, train_MAE=0.599, train_loss=0.638, val_MAE=0.636, val_loss=0.675]Epoch 10:   1%|          | 10/1000 [20:53<31:15:53, 113.69s/it, lr=0.001, test_MAE=0.78, time=113, train_MAE=0.592, train_loss=0.631, val_MAE=0.734, val_loss=0.773] Epoch 10:   1%|          | 11/1000 [20:53<31:11:31, 113.54s/it, lr=0.001, test_MAE=0.78, time=113, train_MAE=0.592, train_loss=0.631, val_MAE=0.734, val_loss=0.773]Epoch 11:   1%|          | 11/1000 [20:53<31:11:31, 113.54s/it, lr=0.001, test_MAE=0.78, time=113, train_MAE=0.592, train_loss=0.631, val_MAE=0.734, val_loss=0.773]Epoch 11:   1%|          | 11/1000 [22:46<31:11:31, 113.54s/it, lr=0.001, test_MAE=0.607, time=113, train_MAE=0.576, train_loss=0.615, val_MAE=0.583, val_loss=0.623]Epoch 11:   1%|          | 12/1000 [22:46<31:07:45, 113.43s/it, lr=0.001, test_MAE=0.607, time=113, train_MAE=0.576, train_loss=0.615, val_MAE=0.583, val_loss=0.623]Epoch 12:   1%|          | 12/1000 [22:46<31:07:45, 113.43s/it, lr=0.001, test_MAE=0.607, time=113, train_MAE=0.576, train_loss=0.615, val_MAE=0.583, val_loss=0.623]Epoch 12:   1%|          | 12/1000 [24:39<31:07:45, 113.43s/it, lr=0.001, test_MAE=0.651, time=113, train_MAE=0.566, train_loss=0.606, val_MAE=0.594, val_loss=0.634]Epoch 12:   1%|▏         | 13/1000 [24:39<31:04:04, 113.32s/it, lr=0.001, test_MAE=0.651, time=113, train_MAE=0.566, train_loss=0.606, val_MAE=0.594, val_loss=0.634]Epoch 13:   1%|▏         | 13/1000 [24:39<31:04:04, 113.32s/it, lr=0.001, test_MAE=0.651, time=113, train_MAE=0.566, train_loss=0.606, val_MAE=0.594, val_loss=0.634]Epoch 13:   1%|▏         | 13/1000 [26:33<31:04:04, 113.32s/it, lr=0.001, test_MAE=0.776, time=113, train_MAE=0.559, train_loss=0.599, val_MAE=0.738, val_loss=0.779]Epoch 13:   1%|▏         | 14/1000 [26:33<31:02:51, 113.36s/it, lr=0.001, test_MAE=0.776, time=113, train_MAE=0.559, train_loss=0.599, val_MAE=0.738, val_loss=0.779]Epoch 14:   1%|▏         | 14/1000 [26:33<31:02:51, 113.36s/it, lr=0.001, test_MAE=0.776, time=113, train_MAE=0.559, train_loss=0.599, val_MAE=0.738, val_loss=0.779]Epoch 14:   1%|▏         | 14/1000 [28:26<31:02:51, 113.36s/it, lr=0.001, test_MAE=0.691, time=113, train_MAE=0.567, train_loss=0.607, val_MAE=0.622, val_loss=0.663]Epoch 14:   2%|▏         | 15/1000 [28:26<31:00:30, 113.33s/it, lr=0.001, test_MAE=0.691, time=113, train_MAE=0.567, train_loss=0.607, val_MAE=0.622, val_loss=0.663]Epoch 15:   2%|▏         | 15/1000 [28:26<31:00:30, 113.33s/it, lr=0.001, test_MAE=0.691, time=113, train_MAE=0.567, train_loss=0.607, val_MAE=0.622, val_loss=0.663]Epoch 15:   2%|▏         | 15/1000 [30:19<31:00:30, 113.33s/it, lr=0.001, test_MAE=0.625, time=113, train_MAE=0.541, train_loss=0.581, val_MAE=0.591, val_loss=0.632]Epoch 15:   2%|▏         | 16/1000 [30:19<30:58:07, 113.30s/it, lr=0.001, test_MAE=0.625, time=113, train_MAE=0.541, train_loss=0.581, val_MAE=0.591, val_loss=0.632]Epoch 16:   2%|▏         | 16/1000 [30:19<30:58:07, 113.30s/it, lr=0.001, test_MAE=0.625, time=113, train_MAE=0.541, train_loss=0.581, val_MAE=0.591, val_loss=0.632]Epoch 16:   2%|▏         | 16/1000 [32:13<30:58:07, 113.30s/it, lr=0.001, test_MAE=0.638, time=114, train_MAE=0.553, train_loss=0.594, val_MAE=0.609, val_loss=0.65] Epoch 16:   2%|▏         | 17/1000 [32:13<30:57:36, 113.38s/it, lr=0.001, test_MAE=0.638, time=114, train_MAE=0.553, train_loss=0.594, val_MAE=0.609, val_loss=0.65]Epoch 17:   2%|▏         | 17/1000 [32:13<30:57:36, 113.38s/it, lr=0.001, test_MAE=0.638, time=114, train_MAE=0.553, train_loss=0.594, val_MAE=0.609, val_loss=0.65]Epoch 17:   2%|▏         | 17/1000 [34:06<30:57:36, 113.38s/it, lr=0.001, test_MAE=0.617, time=113, train_MAE=0.532, train_loss=0.574, val_MAE=0.585, val_loss=0.626]Epoch    18: reducing learning rate of group 0 to 5.0000e-04.
Epoch 17:   2%|▏         | 18/1000 [34:06<30:55:45, 113.39s/it, lr=0.001, test_MAE=0.617, time=113, train_MAE=0.532, train_loss=0.574, val_MAE=0.585, val_loss=0.626]Epoch 18:   2%|▏         | 18/1000 [34:06<30:55:45, 113.39s/it, lr=0.001, test_MAE=0.617, time=113, train_MAE=0.532, train_loss=0.574, val_MAE=0.585, val_loss=0.626]Epoch 18:   2%|▏         | 18/1000 [36:00<30:55:45, 113.39s/it, lr=0.0005, test_MAE=0.594, time=113, train_MAE=0.519, train_loss=0.56, val_MAE=0.564, val_loss=0.605]Epoch 18:   2%|▏         | 19/1000 [36:00<30:54:06, 113.40s/it, lr=0.0005, test_MAE=0.594, time=113, train_MAE=0.519, train_loss=0.56, val_MAE=0.564, val_loss=0.605]Epoch 19:   2%|▏         | 19/1000 [36:00<30:54:06, 113.40s/it, lr=0.0005, test_MAE=0.594, time=113, train_MAE=0.519, train_loss=0.56, val_MAE=0.564, val_loss=0.605]Epoch 19:   2%|▏         | 19/1000 [37:53<30:54:06, 113.40s/it, lr=0.0005, test_MAE=0.555, time=113, train_MAE=0.516, train_loss=0.558, val_MAE=0.54, val_loss=0.581]Epoch 19:   2%|▏         | 20/1000 [37:53<30:51:37, 113.36s/it, lr=0.0005, test_MAE=0.555, time=113, train_MAE=0.516, train_loss=0.558, val_MAE=0.54, val_loss=0.581]Epoch 20:   2%|▏         | 20/1000 [37:53<30:51:37, 113.36s/it, lr=0.0005, test_MAE=0.555, time=113, train_MAE=0.516, train_loss=0.558, val_MAE=0.54, val_loss=0.581]Epoch 20:   2%|▏         | 20/1000 [39:47<30:51:37, 113.36s/it, lr=0.0005, test_MAE=0.647, time=114, train_MAE=0.531, train_loss=0.572, val_MAE=0.622, val_loss=0.663]Epoch 20:   2%|▏         | 21/1000 [39:47<30:50:49, 113.43s/it, lr=0.0005, test_MAE=0.647, time=114, train_MAE=0.531, train_loss=0.572, val_MAE=0.622, val_loss=0.663]Epoch 21:   2%|▏         | 21/1000 [39:47<30:50:49, 113.43s/it, lr=0.0005, test_MAE=0.647, time=114, train_MAE=0.531, train_loss=0.572, val_MAE=0.622, val_loss=0.663]Epoch 21:   2%|▏         | 21/1000 [41:39<30:50:49, 113.43s/it, lr=0.0005, test_MAE=0.576, time=113, train_MAE=0.51, train_loss=0.551, val_MAE=0.544, val_loss=0.585] Epoch 21:   2%|▏         | 22/1000 [41:40<30:46:10, 113.26s/it, lr=0.0005, test_MAE=0.576, time=113, train_MAE=0.51, train_loss=0.551, val_MAE=0.544, val_loss=0.585]Epoch 22:   2%|▏         | 22/1000 [41:40<30:46:10, 113.26s/it, lr=0.0005, test_MAE=0.576, time=113, train_MAE=0.51, train_loss=0.551, val_MAE=0.544, val_loss=0.585]Epoch 22:   2%|▏         | 22/1000 [43:33<30:46:10, 113.26s/it, lr=0.0005, test_MAE=0.591, time=114, train_MAE=0.497, train_loss=0.538, val_MAE=0.578, val_loss=0.62]Epoch 22:   2%|▏         | 23/1000 [43:33<30:45:48, 113.36s/it, lr=0.0005, test_MAE=0.591, time=114, train_MAE=0.497, train_loss=0.538, val_MAE=0.578, val_loss=0.62]Epoch 23:   2%|▏         | 23/1000 [43:33<30:45:48, 113.36s/it, lr=0.0005, test_MAE=0.591, time=114, train_MAE=0.497, train_loss=0.538, val_MAE=0.578, val_loss=0.62]Epoch 23:   2%|▏         | 23/1000 [45:27<30:45:48, 113.36s/it, lr=0.0005, test_MAE=0.646, time=113, train_MAE=0.498, train_loss=0.54, val_MAE=0.622, val_loss=0.664]Epoch 23:   2%|▏         | 24/1000 [45:27<30:44:34, 113.40s/it, lr=0.0005, test_MAE=0.646, time=113, train_MAE=0.498, train_loss=0.54, val_MAE=0.622, val_loss=0.664]Epoch 24:   2%|▏         | 24/1000 [45:27<30:44:34, 113.40s/it, lr=0.0005, test_MAE=0.646, time=113, train_MAE=0.498, train_loss=0.54, val_MAE=0.622, val_loss=0.664]Epoch 24:   2%|▏         | 24/1000 [47:20<30:44:34, 113.40s/it, lr=0.0005, test_MAE=0.844, time=113, train_MAE=0.505, train_loss=0.546, val_MAE=0.802, val_loss=0.844]Epoch 24:   2%|▎         | 25/1000 [47:20<30:41:26, 113.32s/it, lr=0.0005, test_MAE=0.844, time=113, train_MAE=0.505, train_loss=0.546, val_MAE=0.802, val_loss=0.844]Epoch 25:   2%|▎         | 25/1000 [47:20<30:41:26, 113.32s/it, lr=0.0005, test_MAE=0.844, time=113, train_MAE=0.505, train_loss=0.546, val_MAE=0.802, val_loss=0.844]Epoch 25:   2%|▎         | 25/1000 [49:13<30:41:26, 113.32s/it, lr=0.0005, test_MAE=0.573, time=113, train_MAE=0.495, train_loss=0.536, val_MAE=0.565, val_loss=0.606]Epoch    26: reducing learning rate of group 0 to 2.5000e-04.
Epoch 25:   3%|▎         | 26/1000 [49:13<30:37:25, 113.19s/it, lr=0.0005, test_MAE=0.573, time=113, train_MAE=0.495, train_loss=0.536, val_MAE=0.565, val_loss=0.606]Epoch 26:   3%|▎         | 26/1000 [49:13<30:37:25, 113.19s/it, lr=0.0005, test_MAE=0.573, time=113, train_MAE=0.495, train_loss=0.536, val_MAE=0.565, val_loss=0.606]Epoch 26:   3%|▎         | 26/1000 [51:06<30:37:25, 113.19s/it, lr=0.00025, test_MAE=0.539, time=114, train_MAE=0.482, train_loss=0.524, val_MAE=0.502, val_loss=0.544]Epoch 26:   3%|▎         | 27/1000 [51:06<30:38:37, 113.38s/it, lr=0.00025, test_MAE=0.539, time=114, train_MAE=0.482, train_loss=0.524, val_MAE=0.502, val_loss=0.544]Epoch 27:   3%|▎         | 27/1000 [51:06<30:38:37, 113.38s/it, lr=0.00025, test_MAE=0.539, time=114, train_MAE=0.482, train_loss=0.524, val_MAE=0.502, val_loss=0.544]Epoch 27:   3%|▎         | 27/1000 [53:00<30:38:37, 113.38s/it, lr=0.00025, test_MAE=0.59, time=113, train_MAE=0.473, train_loss=0.515, val_MAE=0.552, val_loss=0.593] Epoch 27:   3%|▎         | 28/1000 [53:00<30:36:28, 113.36s/it, lr=0.00025, test_MAE=0.59, time=113, train_MAE=0.473, train_loss=0.515, val_MAE=0.552, val_loss=0.593]Epoch 28:   3%|▎         | 28/1000 [53:00<30:36:28, 113.36s/it, lr=0.00025, test_MAE=0.59, time=113, train_MAE=0.473, train_loss=0.515, val_MAE=0.552, val_loss=0.593]Epoch 28:   3%|▎         | 28/1000 [54:53<30:36:28, 113.36s/it, lr=0.00025, test_MAE=0.566, time=113, train_MAE=0.466, train_loss=0.508, val_MAE=0.537, val_loss=0.578]Epoch 28:   3%|▎         | 29/1000 [54:53<30:33:30, 113.30s/it, lr=0.00025, test_MAE=0.566, time=113, train_MAE=0.466, train_loss=0.508, val_MAE=0.537, val_loss=0.578]Epoch 29:   3%|▎         | 29/1000 [54:53<30:33:30, 113.30s/it, lr=0.00025, test_MAE=0.566, time=113, train_MAE=0.466, train_loss=0.508, val_MAE=0.537, val_loss=0.578]Epoch 29:   3%|▎         | 29/1000 [56:46<30:33:30, 113.30s/it, lr=0.00025, test_MAE=0.522, time=113, train_MAE=0.481, train_loss=0.522, val_MAE=0.497, val_loss=0.538]Epoch 29:   3%|▎         | 30/1000 [56:46<30:30:55, 113.25s/it, lr=0.00025, test_MAE=0.522, time=113, train_MAE=0.481, train_loss=0.522, val_MAE=0.497, val_loss=0.538]Epoch 30:   3%|▎         | 30/1000 [56:46<30:30:55, 113.25s/it, lr=0.00025, test_MAE=0.522, time=113, train_MAE=0.481, train_loss=0.522, val_MAE=0.497, val_loss=0.538]Epoch 30:   3%|▎         | 30/1000 [58:39<30:30:55, 113.25s/it, lr=0.00025, test_MAE=0.511, time=113, train_MAE=0.465, train_loss=0.506, val_MAE=0.485, val_loss=0.526]Epoch 30:   3%|▎         | 31/1000 [58:40<30:30:06, 113.32s/it, lr=0.00025, test_MAE=0.511, time=113, train_MAE=0.465, train_loss=0.506, val_MAE=0.485, val_loss=0.526]Epoch 31:   3%|▎         | 31/1000 [58:40<30:30:06, 113.32s/it, lr=0.00025, test_MAE=0.511, time=113, train_MAE=0.465, train_loss=0.506, val_MAE=0.485, val_loss=0.526]Epoch 31:   3%|▎         | 31/1000 [1:00:33<30:30:06, 113.32s/it, lr=0.00025, test_MAE=0.523, time=113, train_MAE=0.464, train_loss=0.506, val_MAE=0.503, val_loss=0.545]Epoch 31:   3%|▎         | 32/1000 [1:00:33<30:27:23, 113.27s/it, lr=0.00025, test_MAE=0.523, time=113, train_MAE=0.464, train_loss=0.506, val_MAE=0.503, val_loss=0.545]Epoch 32:   3%|▎         | 32/1000 [1:00:33<30:27:23, 113.27s/it, lr=0.00025, test_MAE=0.523, time=113, train_MAE=0.464, train_loss=0.506, val_MAE=0.503, val_loss=0.545]Epoch 32:   3%|▎         | 32/1000 [1:02:26<30:27:23, 113.27s/it, lr=0.00025, test_MAE=0.535, time=113, train_MAE=0.479, train_loss=0.52, val_MAE=0.494, val_loss=0.536] Epoch 32:   3%|▎         | 33/1000 [1:02:26<30:24:35, 113.21s/it, lr=0.00025, test_MAE=0.535, time=113, train_MAE=0.479, train_loss=0.52, val_MAE=0.494, val_loss=0.536]Epoch 33:   3%|▎         | 33/1000 [1:02:26<30:24:35, 113.21s/it, lr=0.00025, test_MAE=0.535, time=113, train_MAE=0.479, train_loss=0.52, val_MAE=0.494, val_loss=0.536]Epoch 33:   3%|▎         | 33/1000 [1:04:19<30:24:35, 113.21s/it, lr=0.00025, test_MAE=0.654, time=113, train_MAE=0.457, train_loss=0.499, val_MAE=0.632, val_loss=0.674]Epoch 33:   3%|▎         | 34/1000 [1:04:19<30:23:51, 113.28s/it, lr=0.00025, test_MAE=0.654, time=113, train_MAE=0.457, train_loss=0.499, val_MAE=0.632, val_loss=0.674]Epoch 34:   3%|▎         | 34/1000 [1:04:19<30:23:51, 113.28s/it, lr=0.00025, test_MAE=0.654, time=113, train_MAE=0.457, train_loss=0.499, val_MAE=0.632, val_loss=0.674]Epoch 34:   3%|▎         | 34/1000 [1:06:12<30:23:51, 113.28s/it, lr=0.00025, test_MAE=0.519, time=113, train_MAE=0.453, train_loss=0.495, val_MAE=0.509, val_loss=0.551]Epoch 34:   4%|▎         | 35/1000 [1:06:12<30:20:51, 113.21s/it, lr=0.00025, test_MAE=0.519, time=113, train_MAE=0.453, train_loss=0.495, val_MAE=0.509, val_loss=0.551]Epoch 35:   4%|▎         | 35/1000 [1:06:12<30:20:51, 113.21s/it, lr=0.00025, test_MAE=0.519, time=113, train_MAE=0.453, train_loss=0.495, val_MAE=0.509, val_loss=0.551]Epoch 35:   4%|▎         | 35/1000 [1:08:05<30:20:51, 113.21s/it, lr=0.00025, test_MAE=0.597, time=113, train_MAE=0.458, train_loss=0.5, val_MAE=0.571, val_loss=0.612]  Epoch 35:   4%|▎         | 36/1000 [1:08:05<30:19:00, 113.22s/it, lr=0.00025, test_MAE=0.597, time=113, train_MAE=0.458, train_loss=0.5, val_MAE=0.571, val_loss=0.612]Epoch 36:   4%|▎         | 36/1000 [1:08:05<30:19:00, 113.22s/it, lr=0.00025, test_MAE=0.597, time=113, train_MAE=0.458, train_loss=0.5, val_MAE=0.571, val_loss=0.612]Epoch 36:   4%|▎         | 36/1000 [1:09:59<30:19:00, 113.22s/it, lr=0.00025, test_MAE=0.569, time=114, train_MAE=0.441, train_loss=0.482, val_MAE=0.55, val_loss=0.591]Epoch    37: reducing learning rate of group 0 to 1.2500e-04.
Epoch 36:   4%|▎         | 37/1000 [1:09:59<30:19:50, 113.39s/it, lr=0.00025, test_MAE=0.569, time=114, train_MAE=0.441, train_loss=0.482, val_MAE=0.55, val_loss=0.591]Epoch 37:   4%|▎         | 37/1000 [1:09:59<30:19:50, 113.39s/it, lr=0.00025, test_MAE=0.569, time=114, train_MAE=0.441, train_loss=0.482, val_MAE=0.55, val_loss=0.591]Epoch 37:   4%|▎         | 37/1000 [1:11:53<30:19:50, 113.39s/it, lr=0.000125, test_MAE=0.503, time=113, train_MAE=0.443, train_loss=0.484, val_MAE=0.479, val_loss=0.52]Epoch 37:   4%|▍         | 38/1000 [1:11:53<30:17:47, 113.38s/it, lr=0.000125, test_MAE=0.503, time=113, train_MAE=0.443, train_loss=0.484, val_MAE=0.479, val_loss=0.52]Epoch 38:   4%|▍         | 38/1000 [1:11:53<30:17:47, 113.38s/it, lr=0.000125, test_MAE=0.503, time=113, train_MAE=0.443, train_loss=0.484, val_MAE=0.479, val_loss=0.52]Epoch 38:   4%|▍         | 38/1000 [1:13:46<30:17:47, 113.38s/it, lr=0.000125, test_MAE=0.502, time=113, train_MAE=0.426, train_loss=0.468, val_MAE=0.468, val_loss=0.509]Epoch 38:   4%|▍         | 39/1000 [1:13:46<30:15:41, 113.36s/it, lr=0.000125, test_MAE=0.502, time=113, train_MAE=0.426, train_loss=0.468, val_MAE=0.468, val_loss=0.509]Epoch 39:   4%|▍         | 39/1000 [1:13:46<30:15:41, 113.36s/it, lr=0.000125, test_MAE=0.502, time=113, train_MAE=0.426, train_loss=0.468, val_MAE=0.468, val_loss=0.509]Epoch 39:   4%|▍         | 39/1000 [1:15:39<30:15:41, 113.36s/it, lr=0.000125, test_MAE=0.524, time=113, train_MAE=0.428, train_loss=0.469, val_MAE=0.501, val_loss=0.543]Epoch 39:   4%|▍         | 40/1000 [1:15:39<30:13:18, 113.33s/it, lr=0.000125, test_MAE=0.524, time=113, train_MAE=0.428, train_loss=0.469, val_MAE=0.501, val_loss=0.543]Epoch 40:   4%|▍         | 40/1000 [1:15:39<30:13:18, 113.33s/it, lr=0.000125, test_MAE=0.524, time=113, train_MAE=0.428, train_loss=0.469, val_MAE=0.501, val_loss=0.543]Epoch 40:   4%|▍         | 40/1000 [1:17:33<30:13:18, 113.33s/it, lr=0.000125, test_MAE=0.481, time=114, train_MAE=0.431, train_loss=0.472, val_MAE=0.459, val_loss=0.5]  Epoch 40:   4%|▍         | 41/1000 [1:17:33<30:12:46, 113.42s/it, lr=0.000125, test_MAE=0.481, time=114, train_MAE=0.431, train_loss=0.472, val_MAE=0.459, val_loss=0.5]Epoch 41:   4%|▍         | 41/1000 [1:17:33<30:12:46, 113.42s/it, lr=0.000125, test_MAE=0.481, time=114, train_MAE=0.431, train_loss=0.472, val_MAE=0.459, val_loss=0.5]Epoch 41:   4%|▍         | 41/1000 [1:19:26<30:12:46, 113.42s/it, lr=0.000125, test_MAE=0.525, time=113, train_MAE=0.427, train_loss=0.468, val_MAE=0.506, val_loss=0.547]Epoch 41:   4%|▍         | 42/1000 [1:19:26<30:10:31, 113.39s/it, lr=0.000125, test_MAE=0.525, time=113, train_MAE=0.427, train_loss=0.468, val_MAE=0.506, val_loss=0.547]Epoch 42:   4%|▍         | 42/1000 [1:19:26<30:10:31, 113.39s/it, lr=0.000125, test_MAE=0.525, time=113, train_MAE=0.427, train_loss=0.468, val_MAE=0.506, val_loss=0.547]Epoch 42:   4%|▍         | 42/1000 [1:21:19<30:10:31, 113.39s/it, lr=0.000125, test_MAE=0.517, time=113, train_MAE=0.425, train_loss=0.466, val_MAE=0.494, val_loss=0.536]Epoch 42:   4%|▍         | 43/1000 [1:21:19<30:08:21, 113.38s/it, lr=0.000125, test_MAE=0.517, time=113, train_MAE=0.425, train_loss=0.466, val_MAE=0.494, val_loss=0.536]Epoch 43:   4%|▍         | 43/1000 [1:21:19<30:08:21, 113.38s/it, lr=0.000125, test_MAE=0.517, time=113, train_MAE=0.425, train_loss=0.466, val_MAE=0.494, val_loss=0.536]Epoch 43:   4%|▍         | 43/1000 [1:23:13<30:08:21, 113.38s/it, lr=0.000125, test_MAE=0.641, time=114, train_MAE=0.428, train_loss=0.469, val_MAE=0.595, val_loss=0.636]Epoch 43:   4%|▍         | 44/1000 [1:23:13<30:07:13, 113.42s/it, lr=0.000125, test_MAE=0.641, time=114, train_MAE=0.428, train_loss=0.469, val_MAE=0.595, val_loss=0.636]Epoch 44:   4%|▍         | 44/1000 [1:23:13<30:07:13, 113.42s/it, lr=0.000125, test_MAE=0.641, time=114, train_MAE=0.428, train_loss=0.469, val_MAE=0.595, val_loss=0.636]Epoch 44:   4%|▍         | 44/1000 [1:25:06<30:07:13, 113.42s/it, lr=0.000125, test_MAE=0.506, time=113, train_MAE=0.428, train_loss=0.469, val_MAE=0.478, val_loss=0.519]Epoch 44:   4%|▍         | 45/1000 [1:25:06<30:04:49, 113.39s/it, lr=0.000125, test_MAE=0.506, time=113, train_MAE=0.428, train_loss=0.469, val_MAE=0.478, val_loss=0.519]Epoch 45:   4%|▍         | 45/1000 [1:25:06<30:04:49, 113.39s/it, lr=0.000125, test_MAE=0.506, time=113, train_MAE=0.428, train_loss=0.469, val_MAE=0.478, val_loss=0.519]Epoch 45:   4%|▍         | 45/1000 [1:27:00<30:04:49, 113.39s/it, lr=0.000125, test_MAE=0.5, time=113, train_MAE=0.429, train_loss=0.47, val_MAE=0.46, val_loss=0.501]    Epoch 45:   5%|▍         | 46/1000 [1:27:00<30:02:28, 113.36s/it, lr=0.000125, test_MAE=0.5, time=113, train_MAE=0.429, train_loss=0.47, val_MAE=0.46, val_loss=0.501]Epoch 46:   5%|▍         | 46/1000 [1:27:00<30:02:28, 113.36s/it, lr=0.000125, test_MAE=0.5, time=113, train_MAE=0.429, train_loss=0.47, val_MAE=0.46, val_loss=0.501]Epoch 46:   5%|▍         | 46/1000 [1:28:53<30:02:28, 113.36s/it, lr=0.000125, test_MAE=0.47, time=113, train_MAE=0.421, train_loss=0.462, val_MAE=0.447, val_loss=0.488]Epoch 46:   5%|▍         | 47/1000 [1:28:53<30:00:40, 113.37s/it, lr=0.000125, test_MAE=0.47, time=113, train_MAE=0.421, train_loss=0.462, val_MAE=0.447, val_loss=0.488]Epoch 47:   5%|▍         | 47/1000 [1:28:53<30:00:40, 113.37s/it, lr=0.000125, test_MAE=0.47, time=113, train_MAE=0.421, train_loss=0.462, val_MAE=0.447, val_loss=0.488]Epoch 47:   5%|▍         | 47/1000 [1:30:47<30:00:40, 113.37s/it, lr=0.000125, test_MAE=0.499, time=114, train_MAE=0.416, train_loss=0.458, val_MAE=0.479, val_loss=0.52]Epoch 47:   5%|▍         | 48/1000 [1:30:47<30:00:14, 113.46s/it, lr=0.000125, test_MAE=0.499, time=114, train_MAE=0.416, train_loss=0.458, val_MAE=0.479, val_loss=0.52]Epoch 48:   5%|▍         | 48/1000 [1:30:47<30:00:14, 113.46s/it, lr=0.000125, test_MAE=0.499, time=114, train_MAE=0.416, train_loss=0.458, val_MAE=0.479, val_loss=0.52]Epoch 48:   5%|▍         | 48/1000 [1:32:40<30:00:14, 113.46s/it, lr=0.000125, test_MAE=0.485, time=113, train_MAE=0.415, train_loss=0.456, val_MAE=0.469, val_loss=0.51]Epoch 48:   5%|▍         | 49/1000 [1:32:40<29:57:53, 113.43s/it, lr=0.000125, test_MAE=0.485, time=113, train_MAE=0.415, train_loss=0.456, val_MAE=0.469, val_loss=0.51]Epoch 49:   5%|▍         | 49/1000 [1:32:40<29:57:53, 113.43s/it, lr=0.000125, test_MAE=0.485, time=113, train_MAE=0.415, train_loss=0.456, val_MAE=0.469, val_loss=0.51]Epoch 49:   5%|▍         | 49/1000 [1:34:33<29:57:53, 113.43s/it, lr=0.000125, test_MAE=0.925, time=113, train_MAE=0.412, train_loss=0.454, val_MAE=0.905, val_loss=0.946]Epoch 49:   5%|▌         | 50/1000 [1:34:33<29:55:29, 113.40s/it, lr=0.000125, test_MAE=0.925, time=113, train_MAE=0.412, train_loss=0.454, val_MAE=0.905, val_loss=0.946]Epoch 50:   5%|▌         | 50/1000 [1:34:33<29:55:29, 113.40s/it, lr=0.000125, test_MAE=0.925, time=113, train_MAE=0.412, train_loss=0.454, val_MAE=0.905, val_loss=0.946]Epoch 50:   5%|▌         | 50/1000 [1:36:27<29:55:29, 113.40s/it, lr=0.000125, test_MAE=0.486, time=113, train_MAE=0.418, train_loss=0.459, val_MAE=0.457, val_loss=0.498]Epoch 50:   5%|▌         | 51/1000 [1:36:27<29:54:03, 113.43s/it, lr=0.000125, test_MAE=0.486, time=113, train_MAE=0.418, train_loss=0.459, val_MAE=0.457, val_loss=0.498]Epoch 51:   5%|▌         | 51/1000 [1:36:27<29:54:03, 113.43s/it, lr=0.000125, test_MAE=0.486, time=113, train_MAE=0.418, train_loss=0.459, val_MAE=0.457, val_loss=0.498]Epoch 51:   5%|▌         | 51/1000 [1:38:19<29:54:03, 113.43s/it, lr=0.000125, test_MAE=0.492, time=112, train_MAE=0.414, train_loss=0.455, val_MAE=0.456, val_loss=0.498]Epoch 51:   5%|▌         | 52/1000 [1:38:19<29:45:01, 112.98s/it, lr=0.000125, test_MAE=0.492, time=112, train_MAE=0.414, train_loss=0.455, val_MAE=0.456, val_loss=0.498]Epoch 52:   5%|▌         | 52/1000 [1:38:19<29:45:01, 112.98s/it, lr=0.000125, test_MAE=0.492, time=112, train_MAE=0.414, train_loss=0.455, val_MAE=0.456, val_loss=0.498]Epoch 52:   5%|▌         | 52/1000 [1:40:08<29:45:01, 112.98s/it, lr=0.000125, test_MAE=0.52, time=109, train_MAE=0.418, train_loss=0.459, val_MAE=0.478, val_loss=0.519] Epoch    53: reducing learning rate of group 0 to 6.2500e-05.
Epoch 52:   5%|▌         | 53/1000 [1:40:08<29:23:48, 111.75s/it, lr=0.000125, test_MAE=0.52, time=109, train_MAE=0.418, train_loss=0.459, val_MAE=0.478, val_loss=0.519]Epoch 53:   5%|▌         | 53/1000 [1:40:08<29:23:48, 111.75s/it, lr=0.000125, test_MAE=0.52, time=109, train_MAE=0.418, train_loss=0.459, val_MAE=0.478, val_loss=0.519]Epoch 53:   5%|▌         | 53/1000 [1:41:56<29:23:48, 111.75s/it, lr=6.25e-5, test_MAE=0.492, time=108, train_MAE=0.407, train_loss=0.448, val_MAE=0.457, val_loss=0.498]Epoch 53:   5%|▌         | 54/1000 [1:41:56<29:04:32, 110.65s/it, lr=6.25e-5, test_MAE=0.492, time=108, train_MAE=0.407, train_loss=0.448, val_MAE=0.457, val_loss=0.498]Epoch 54:   5%|▌         | 54/1000 [1:41:56<29:04:32, 110.65s/it, lr=6.25e-5, test_MAE=0.492, time=108, train_MAE=0.407, train_loss=0.448, val_MAE=0.457, val_loss=0.498]Epoch 54:   5%|▌         | 54/1000 [1:43:44<29:04:32, 110.65s/it, lr=6.25e-5, test_MAE=0.477, time=108, train_MAE=0.401, train_loss=0.443, val_MAE=0.445, val_loss=0.486]Epoch 54:   6%|▌         | 55/1000 [1:43:44<28:51:43, 109.95s/it, lr=6.25e-5, test_MAE=0.477, time=108, train_MAE=0.401, train_loss=0.443, val_MAE=0.445, val_loss=0.486]Epoch 55:   6%|▌         | 55/1000 [1:43:44<28:51:43, 109.95s/it, lr=6.25e-5, test_MAE=0.477, time=108, train_MAE=0.401, train_loss=0.443, val_MAE=0.445, val_loss=0.486]Epoch 55:   6%|▌         | 55/1000 [1:45:31<28:51:43, 109.95s/it, lr=6.25e-5, test_MAE=0.503, time=107, train_MAE=0.406, train_loss=0.447, val_MAE=0.471, val_loss=0.512]Epoch 55:   6%|▌         | 56/1000 [1:45:31<28:36:07, 109.08s/it, lr=6.25e-5, test_MAE=0.503, time=107, train_MAE=0.406, train_loss=0.447, val_MAE=0.471, val_loss=0.512]Epoch 56:   6%|▌         | 56/1000 [1:45:31<28:36:07, 109.08s/it, lr=6.25e-5, test_MAE=0.503, time=107, train_MAE=0.406, train_loss=0.447, val_MAE=0.471, val_loss=0.512]Epoch 56:   6%|▌         | 56/1000 [1:47:18<28:36:07, 109.08s/it, lr=6.25e-5, test_MAE=0.558, time=107, train_MAE=0.397, train_loss=0.438, val_MAE=0.53, val_loss=0.571] Epoch 56:   6%|▌         | 57/1000 [1:47:18<28:23:08, 108.37s/it, lr=6.25e-5, test_MAE=0.558, time=107, train_MAE=0.397, train_loss=0.438, val_MAE=0.53, val_loss=0.571]Epoch 57:   6%|▌         | 57/1000 [1:47:18<28:23:08, 108.37s/it, lr=6.25e-5, test_MAE=0.558, time=107, train_MAE=0.397, train_loss=0.438, val_MAE=0.53, val_loss=0.571]Epoch 57:   6%|▌         | 57/1000 [1:49:04<28:23:08, 108.37s/it, lr=6.25e-5, test_MAE=0.461, time=106, train_MAE=0.394, train_loss=0.435, val_MAE=0.439, val_loss=0.48]Epoch 57:   6%|▌         | 58/1000 [1:49:04<28:12:32, 107.81s/it, lr=6.25e-5, test_MAE=0.461, time=106, train_MAE=0.394, train_loss=0.435, val_MAE=0.439, val_loss=0.48]Epoch 58:   6%|▌         | 58/1000 [1:49:04<28:12:32, 107.81s/it, lr=6.25e-5, test_MAE=0.461, time=106, train_MAE=0.394, train_loss=0.435, val_MAE=0.439, val_loss=0.48]Epoch 58:   6%|▌         | 58/1000 [1:50:50<28:12:32, 107.81s/it, lr=6.25e-5, test_MAE=0.569, time=106, train_MAE=0.397, train_loss=0.438, val_MAE=0.542, val_loss=0.583]Epoch 58:   6%|▌         | 59/1000 [1:50:50<28:01:39, 107.23s/it, lr=6.25e-5, test_MAE=0.569, time=106, train_MAE=0.397, train_loss=0.438, val_MAE=0.542, val_loss=0.583]Epoch 59:   6%|▌         | 59/1000 [1:50:50<28:01:39, 107.23s/it, lr=6.25e-5, test_MAE=0.569, time=106, train_MAE=0.397, train_loss=0.438, val_MAE=0.542, val_loss=0.583]Epoch 59:   6%|▌         | 59/1000 [1:52:36<28:01:39, 107.23s/it, lr=6.25e-5, test_MAE=0.742, time=106, train_MAE=0.39, train_loss=0.431, val_MAE=0.702, val_loss=0.743] Epoch 59:   6%|▌         | 60/1000 [1:52:36<27:51:55, 106.72s/it, lr=6.25e-5, test_MAE=0.742, time=106, train_MAE=0.39, train_loss=0.431, val_MAE=0.702, val_loss=0.743]Epoch 60:   6%|▌         | 60/1000 [1:52:36<27:51:55, 106.72s/it, lr=6.25e-5, test_MAE=0.742, time=106, train_MAE=0.39, train_loss=0.431, val_MAE=0.702, val_loss=0.743]Epoch 60:   6%|▌         | 60/1000 [1:54:21<27:51:55, 106.72s/it, lr=6.25e-5, test_MAE=0.554, time=105, train_MAE=0.396, train_loss=0.437, val_MAE=0.528, val_loss=0.569]Epoch 60:   6%|▌         | 61/1000 [1:54:21<27:41:37, 106.17s/it, lr=6.25e-5, test_MAE=0.554, time=105, train_MAE=0.396, train_loss=0.437, val_MAE=0.528, val_loss=0.569]Epoch 61:   6%|▌         | 61/1000 [1:54:21<27:41:37, 106.17s/it, lr=6.25e-5, test_MAE=0.554, time=105, train_MAE=0.396, train_loss=0.437, val_MAE=0.528, val_loss=0.569]Epoch 61:   6%|▌         | 61/1000 [1:56:05<27:41:37, 106.17s/it, lr=6.25e-5, test_MAE=0.477, time=105, train_MAE=0.397, train_loss=0.438, val_MAE=0.443, val_loss=0.484]Epoch 61:   6%|▌         | 62/1000 [1:56:05<27:32:42, 105.72s/it, lr=6.25e-5, test_MAE=0.477, time=105, train_MAE=0.397, train_loss=0.438, val_MAE=0.443, val_loss=0.484]Epoch 62:   6%|▌         | 62/1000 [1:56:05<27:32:42, 105.72s/it, lr=6.25e-5, test_MAE=0.477, time=105, train_MAE=0.397, train_loss=0.438, val_MAE=0.443, val_loss=0.484]Epoch 62:   6%|▌         | 62/1000 [1:57:49<27:32:42, 105.72s/it, lr=6.25e-5, test_MAE=0.525, time=104, train_MAE=0.403, train_loss=0.444, val_MAE=0.499, val_loss=0.54] Epoch 62:   6%|▋         | 63/1000 [1:57:49<27:23:12, 105.22s/it, lr=6.25e-5, test_MAE=0.525, time=104, train_MAE=0.403, train_loss=0.444, val_MAE=0.499, val_loss=0.54]Epoch 63:   6%|▋         | 63/1000 [1:57:49<27:23:12, 105.22s/it, lr=6.25e-5, test_MAE=0.525, time=104, train_MAE=0.403, train_loss=0.444, val_MAE=0.499, val_loss=0.54]Epoch 63:   6%|▋         | 63/1000 [1:59:33<27:23:12, 105.22s/it, lr=6.25e-5, test_MAE=0.491, time=104, train_MAE=0.394, train_loss=0.435, val_MAE=0.468, val_loss=0.509]Epoch    64: reducing learning rate of group 0 to 3.1250e-05.
Epoch 63:   6%|▋         | 64/1000 [1:59:33<27:15:43, 104.85s/it, lr=6.25e-5, test_MAE=0.491, time=104, train_MAE=0.394, train_loss=0.435, val_MAE=0.468, val_loss=0.509]Epoch 64:   6%|▋         | 64/1000 [1:59:33<27:15:43, 104.85s/it, lr=6.25e-5, test_MAE=0.491, time=104, train_MAE=0.394, train_loss=0.435, val_MAE=0.468, val_loss=0.509]Epoch 64:   6%|▋         | 64/1000 [2:01:18<27:15:43, 104.85s/it, lr=3.13e-5, test_MAE=0.466, time=104, train_MAE=0.381, train_loss=0.421, val_MAE=0.439, val_loss=0.48] Epoch 64:   6%|▋         | 65/1000 [2:01:18<27:11:38, 104.70s/it, lr=3.13e-5, test_MAE=0.466, time=104, train_MAE=0.381, train_loss=0.421, val_MAE=0.439, val_loss=0.48]Epoch 65:   6%|▋         | 65/1000 [2:01:18<27:11:38, 104.70s/it, lr=3.13e-5, test_MAE=0.466, time=104, train_MAE=0.381, train_loss=0.421, val_MAE=0.439, val_loss=0.48]Epoch 65:   6%|▋         | 65/1000 [2:03:02<27:11:38, 104.70s/it, lr=3.13e-5, test_MAE=0.453, time=104, train_MAE=0.375, train_loss=0.416, val_MAE=0.428, val_loss=0.468]Epoch 65:   7%|▋         | 66/1000 [2:03:02<27:06:39, 104.50s/it, lr=3.13e-5, test_MAE=0.453, time=104, train_MAE=0.375, train_loss=0.416, val_MAE=0.428, val_loss=0.468]Epoch 66:   7%|▋         | 66/1000 [2:03:02<27:06:39, 104.50s/it, lr=3.13e-5, test_MAE=0.453, time=104, train_MAE=0.375, train_loss=0.416, val_MAE=0.428, val_loss=0.468]Epoch 66:   7%|▋         | 66/1000 [2:04:46<27:06:39, 104.50s/it, lr=3.13e-5, test_MAE=0.472, time=104, train_MAE=0.378, train_loss=0.419, val_MAE=0.441, val_loss=0.482]Epoch 66:   7%|▋         | 67/1000 [2:04:46<27:02:17, 104.33s/it, lr=3.13e-5, test_MAE=0.472, time=104, train_MAE=0.378, train_loss=0.419, val_MAE=0.441, val_loss=0.482]Epoch 67:   7%|▋         | 67/1000 [2:04:46<27:02:17, 104.33s/it, lr=3.13e-5, test_MAE=0.472, time=104, train_MAE=0.378, train_loss=0.419, val_MAE=0.441, val_loss=0.482]Epoch 67:   7%|▋         | 67/1000 [2:06:30<27:02:17, 104.33s/it, lr=3.13e-5, test_MAE=0.466, time=105, train_MAE=0.398, train_loss=0.439, val_MAE=0.449, val_loss=0.489]Epoch 67:   7%|▋         | 68/1000 [2:06:30<27:01:33, 104.39s/it, lr=3.13e-5, test_MAE=0.466, time=105, train_MAE=0.398, train_loss=0.439, val_MAE=0.449, val_loss=0.489]Epoch 68:   7%|▋         | 68/1000 [2:06:30<27:01:33, 104.39s/it, lr=3.13e-5, test_MAE=0.466, time=105, train_MAE=0.398, train_loss=0.439, val_MAE=0.449, val_loss=0.489]Epoch 68:   7%|▋         | 68/1000 [2:08:15<27:01:33, 104.39s/it, lr=3.13e-5, test_MAE=0.462, time=105, train_MAE=0.376, train_loss=0.417, val_MAE=0.444, val_loss=0.485]Epoch 68:   7%|▋         | 69/1000 [2:08:15<27:03:01, 104.60s/it, lr=3.13e-5, test_MAE=0.462, time=105, train_MAE=0.376, train_loss=0.417, val_MAE=0.444, val_loss=0.485]Epoch 69:   7%|▋         | 69/1000 [2:08:15<27:03:01, 104.60s/it, lr=3.13e-5, test_MAE=0.462, time=105, train_MAE=0.376, train_loss=0.417, val_MAE=0.444, val_loss=0.485]Epoch 69:   7%|▋         | 69/1000 [2:10:00<27:03:01, 104.60s/it, lr=3.13e-5, test_MAE=0.478, time=105, train_MAE=0.38, train_loss=0.421, val_MAE=0.457, val_loss=0.497] Epoch 69:   7%|▋         | 70/1000 [2:10:00<27:01:24, 104.61s/it, lr=3.13e-5, test_MAE=0.478, time=105, train_MAE=0.38, train_loss=0.421, val_MAE=0.457, val_loss=0.497]Epoch 70:   7%|▋         | 70/1000 [2:10:00<27:01:24, 104.61s/it, lr=3.13e-5, test_MAE=0.478, time=105, train_MAE=0.38, train_loss=0.421, val_MAE=0.457, val_loss=0.497]Epoch 70:   7%|▋         | 70/1000 [2:11:44<27:01:24, 104.61s/it, lr=3.13e-5, test_MAE=0.467, time=105, train_MAE=0.377, train_loss=0.418, val_MAE=0.434, val_loss=0.475]Epoch 70:   7%|▋         | 71/1000 [2:11:44<26:59:31, 104.60s/it, lr=3.13e-5, test_MAE=0.467, time=105, train_MAE=0.377, train_loss=0.418, val_MAE=0.434, val_loss=0.475]Epoch 71:   7%|▋         | 71/1000 [2:11:44<26:59:31, 104.60s/it, lr=3.13e-5, test_MAE=0.467, time=105, train_MAE=0.377, train_loss=0.418, val_MAE=0.434, val_loss=0.475]Epoch 71:   7%|▋         | 71/1000 [2:13:29<26:59:31, 104.60s/it, lr=3.13e-5, test_MAE=0.534, time=105, train_MAE=0.372, train_loss=0.413, val_MAE=0.511, val_loss=0.552]Epoch    72: reducing learning rate of group 0 to 1.5625e-05.
Epoch 71:   7%|▋         | 72/1000 [2:13:29<26:59:34, 104.71s/it, lr=3.13e-5, test_MAE=0.534, time=105, train_MAE=0.372, train_loss=0.413, val_MAE=0.511, val_loss=0.552]Epoch 72:   7%|▋         | 72/1000 [2:13:29<26:59:34, 104.71s/it, lr=3.13e-5, test_MAE=0.534, time=105, train_MAE=0.372, train_loss=0.413, val_MAE=0.511, val_loss=0.552]Epoch 72:   7%|▋         | 72/1000 [2:15:14<26:59:34, 104.71s/it, lr=1.56e-5, test_MAE=0.456, time=105, train_MAE=0.374, train_loss=0.415, val_MAE=0.438, val_loss=0.479]Epoch 72:   7%|▋         | 73/1000 [2:15:14<26:58:16, 104.74s/it, lr=1.56e-5, test_MAE=0.456, time=105, train_MAE=0.374, train_loss=0.415, val_MAE=0.438, val_loss=0.479]Epoch 73:   7%|▋         | 73/1000 [2:15:14<26:58:16, 104.74s/it, lr=1.56e-5, test_MAE=0.456, time=105, train_MAE=0.374, train_loss=0.415, val_MAE=0.438, val_loss=0.479]Epoch 73:   7%|▋         | 73/1000 [2:16:59<26:58:16, 104.74s/it, lr=1.56e-5, test_MAE=0.451, time=105, train_MAE=0.367, train_loss=0.408, val_MAE=0.433, val_loss=0.474]Epoch 73:   7%|▋         | 74/1000 [2:16:59<26:56:16, 104.73s/it, lr=1.56e-5, test_MAE=0.451, time=105, train_MAE=0.367, train_loss=0.408, val_MAE=0.433, val_loss=0.474]Epoch 74:   7%|▋         | 74/1000 [2:16:59<26:56:16, 104.73s/it, lr=1.56e-5, test_MAE=0.451, time=105, train_MAE=0.367, train_loss=0.408, val_MAE=0.433, val_loss=0.474]Epoch 74:   7%|▋         | 74/1000 [2:18:44<26:56:16, 104.73s/it, lr=1.56e-5, test_MAE=0.448, time=105, train_MAE=0.368, train_loss=0.408, val_MAE=0.429, val_loss=0.47] Epoch 74:   8%|▊         | 75/1000 [2:18:44<26:54:11, 104.70s/it, lr=1.56e-5, test_MAE=0.448, time=105, train_MAE=0.368, train_loss=0.408, val_MAE=0.429, val_loss=0.47]Epoch 75:   8%|▊         | 75/1000 [2:18:44<26:54:11, 104.70s/it, lr=1.56e-5, test_MAE=0.448, time=105, train_MAE=0.368, train_loss=0.408, val_MAE=0.429, val_loss=0.47]Epoch 75:   8%|▊         | 75/1000 [2:20:29<26:54:11, 104.70s/it, lr=1.56e-5, test_MAE=0.475, time=105, train_MAE=0.361, train_loss=0.402, val_MAE=0.452, val_loss=0.492]Epoch 75:   8%|▊         | 76/1000 [2:20:29<26:54:25, 104.83s/it, lr=1.56e-5, test_MAE=0.475, time=105, train_MAE=0.361, train_loss=0.402, val_MAE=0.452, val_loss=0.492]Epoch 76:   8%|▊         | 76/1000 [2:20:29<26:54:25, 104.83s/it, lr=1.56e-5, test_MAE=0.475, time=105, train_MAE=0.361, train_loss=0.402, val_MAE=0.452, val_loss=0.492]Epoch 76:   8%|▊         | 76/1000 [2:22:14<26:54:25, 104.83s/it, lr=1.56e-5, test_MAE=0.467, time=105, train_MAE=0.368, train_loss=0.408, val_MAE=0.435, val_loss=0.476]Epoch 76:   8%|▊         | 77/1000 [2:22:14<26:54:07, 104.93s/it, lr=1.56e-5, test_MAE=0.467, time=105, train_MAE=0.368, train_loss=0.408, val_MAE=0.435, val_loss=0.476]Epoch 77:   8%|▊         | 77/1000 [2:22:14<26:54:07, 104.93s/it, lr=1.56e-5, test_MAE=0.467, time=105, train_MAE=0.368, train_loss=0.408, val_MAE=0.435, val_loss=0.476]Epoch 77:   8%|▊         | 77/1000 [2:23:59<26:54:07, 104.93s/it, lr=1.56e-5, test_MAE=0.457, time=105, train_MAE=0.354, train_loss=0.395, val_MAE=0.435, val_loss=0.476]Epoch    78: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 77:   8%|▊         | 77/1000 [2:23:59<28:46:02, 112.20s/it, lr=1.56e-5, test_MAE=0.457, time=105, train_MAE=0.354, train_loss=0.395, val_MAE=0.435, val_loss=0.476]
Test MAE: 0.4572
Train MAE: 0.3637
Convergence Time (Epochs): 77.0000
TOTAL TIME TAKEN: 8687.8254s
AVG TIME PER EPOCH: 110.7461s
