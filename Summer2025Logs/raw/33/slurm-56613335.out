I'm echoing to stdout
I'm echoing to stderr
My JobID is 56613335
I have 8 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.1321s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 4, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'rational_vec', 'normalized_laplacian': True, 'post_normalized': False, 'eigval_norm': '', 'num_eigs': 15, 'bias_mode': 'spatial', 'eigval_hidden_dim': 5, 'eigval_num_hidden_layer': 3, 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 1, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/zinc_train_rec_full.csv', 'test': 'supp_data/molecules/zinc_test_rec_full.csv', 'val': 'supp_data/molecules/zinc_val_rec_full.csv'}, 'fixMissingPhi1': False, 'extraOrtho': True, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [04:17<?, ?it/s, lr=0.001, test_MAE=1.53, time=258, train_MAE=1.34, train_loss=1.36, val_MAE=1.47, val_loss=1.5]Epoch 0:   0%|          | 1/1000 [04:17<71:30:15, 257.67s/it, lr=0.001, test_MAE=1.53, time=258, train_MAE=1.34, train_loss=1.36, val_MAE=1.47, val_loss=1.5]Epoch 1:   0%|          | 1/1000 [04:17<71:30:15, 257.67s/it, lr=0.001, test_MAE=1.53, time=258, train_MAE=1.34, train_loss=1.36, val_MAE=1.47, val_loss=1.5]Epoch 1:   0%|          | 1/1000 [06:09<71:30:15, 257.67s/it, lr=0.001, test_MAE=1.5, time=112, train_MAE=1.02, train_loss=1.05, val_MAE=1.45, val_loss=1.49]Epoch 1:   0%|          | 2/1000 [06:09<59:16:47, 213.84s/it, lr=0.001, test_MAE=1.5, time=112, train_MAE=1.02, train_loss=1.05, val_MAE=1.45, val_loss=1.49]Epoch 2:   0%|          | 2/1000 [06:09<59:16:47, 213.84s/it, lr=0.001, test_MAE=1.5, time=112, train_MAE=1.02, train_loss=1.05, val_MAE=1.45, val_loss=1.49]Epoch 2:   0%|          | 2/1000 [08:01<59:16:47, 213.84s/it, lr=0.001, test_MAE=1.24, time=113, train_MAE=0.817, train_loss=0.851, val_MAE=1.06, val_loss=1.1]Epoch 2:   0%|          | 3/1000 [08:01<50:49:00, 183.49s/it, lr=0.001, test_MAE=1.24, time=113, train_MAE=0.817, train_loss=0.851, val_MAE=1.06, val_loss=1.1]Epoch 3:   0%|          | 3/1000 [08:01<50:49:00, 183.49s/it, lr=0.001, test_MAE=1.24, time=113, train_MAE=0.817, train_loss=0.851, val_MAE=1.06, val_loss=1.1]Epoch 3:   0%|          | 3/1000 [09:54<50:49:00, 183.49s/it, lr=0.001, test_MAE=1.21, time=113, train_MAE=0.737, train_loss=0.773, val_MAE=1.2, val_loss=1.24]Epoch 3:   0%|          | 4/1000 [09:54<44:54:16, 162.31s/it, lr=0.001, test_MAE=1.21, time=113, train_MAE=0.737, train_loss=0.773, val_MAE=1.2, val_loss=1.24]Epoch 4:   0%|          | 4/1000 [09:54<44:54:16, 162.31s/it, lr=0.001, test_MAE=1.21, time=113, train_MAE=0.737, train_loss=0.773, val_MAE=1.2, val_loss=1.24]Epoch 4:   0%|          | 4/1000 [11:46<44:54:16, 162.31s/it, lr=0.001, test_MAE=0.906, time=112, train_MAE=0.708, train_loss=0.745, val_MAE=0.849, val_loss=0.886]Epoch 4:   0%|          | 5/1000 [11:46<40:41:53, 147.25s/it, lr=0.001, test_MAE=0.906, time=112, train_MAE=0.708, train_loss=0.745, val_MAE=0.849, val_loss=0.886]Epoch 5:   0%|          | 5/1000 [11:46<40:41:53, 147.25s/it, lr=0.001, test_MAE=0.906, time=112, train_MAE=0.708, train_loss=0.745, val_MAE=0.849, val_loss=0.886]Epoch 5:   0%|          | 5/1000 [13:38<40:41:53, 147.25s/it, lr=0.001, test_MAE=0.825, time=112, train_MAE=0.698, train_loss=0.735, val_MAE=0.754, val_loss=0.792]Epoch 5:   1%|          | 6/1000 [13:38<37:44:03, 136.66s/it, lr=0.001, test_MAE=0.825, time=112, train_MAE=0.698, train_loss=0.735, val_MAE=0.754, val_loss=0.792]Epoch 6:   1%|          | 6/1000 [13:38<37:44:03, 136.66s/it, lr=0.001, test_MAE=0.825, time=112, train_MAE=0.698, train_loss=0.735, val_MAE=0.754, val_loss=0.792]Epoch 6:   1%|          | 6/1000 [15:31<37:44:03, 136.66s/it, lr=0.001, test_MAE=0.819, time=113, train_MAE=0.672, train_loss=0.709, val_MAE=0.772, val_loss=0.81] Epoch 6:   1%|          | 7/1000 [15:31<35:43:47, 129.53s/it, lr=0.001, test_MAE=0.819, time=113, train_MAE=0.672, train_loss=0.709, val_MAE=0.772, val_loss=0.81]Epoch 7:   1%|          | 7/1000 [15:31<35:43:47, 129.53s/it, lr=0.001, test_MAE=0.819, time=113, train_MAE=0.672, train_loss=0.709, val_MAE=0.772, val_loss=0.81]Epoch 7:   1%|          | 7/1000 [17:24<35:43:47, 129.53s/it, lr=0.001, test_MAE=0.935, time=112, train_MAE=0.67, train_loss=0.708, val_MAE=0.891, val_loss=0.929]Epoch 7:   1%|          | 8/1000 [17:24<34:16:32, 124.39s/it, lr=0.001, test_MAE=0.935, time=112, train_MAE=0.67, train_loss=0.708, val_MAE=0.891, val_loss=0.929]Epoch 8:   1%|          | 8/1000 [17:24<34:16:32, 124.39s/it, lr=0.001, test_MAE=0.935, time=112, train_MAE=0.67, train_loss=0.708, val_MAE=0.891, val_loss=0.929]Epoch 8:   1%|          | 8/1000 [19:18<34:16:32, 124.39s/it, lr=0.001, test_MAE=0.805, time=115, train_MAE=0.66, train_loss=0.698, val_MAE=0.768, val_loss=0.806]Epoch 8:   1%|          | 9/1000 [19:18<33:26:03, 121.46s/it, lr=0.001, test_MAE=0.805, time=115, train_MAE=0.66, train_loss=0.698, val_MAE=0.768, val_loss=0.806]Epoch 9:   1%|          | 9/1000 [19:18<33:26:03, 121.46s/it, lr=0.001, test_MAE=0.805, time=115, train_MAE=0.66, train_loss=0.698, val_MAE=0.768, val_loss=0.806]Epoch 9:   1%|          | 9/1000 [21:13<33:26:03, 121.46s/it, lr=0.001, test_MAE=0.71, time=114, train_MAE=0.661, train_loss=0.7, val_MAE=0.665, val_loss=0.704]  Epoch 9:   1%|          | 10/1000 [21:13<32:49:11, 119.34s/it, lr=0.001, test_MAE=0.71, time=114, train_MAE=0.661, train_loss=0.7, val_MAE=0.665, val_loss=0.704]Epoch 10:   1%|          | 10/1000 [21:13<32:49:11, 119.34s/it, lr=0.001, test_MAE=0.71, time=114, train_MAE=0.661, train_loss=0.7, val_MAE=0.665, val_loss=0.704]Epoch 10:   1%|          | 10/1000 [23:04<32:49:11, 119.34s/it, lr=0.001, test_MAE=0.743, time=112, train_MAE=0.661, train_loss=0.7, val_MAE=0.701, val_loss=0.74]Epoch 10:   1%|          | 11/1000 [23:05<32:10:19, 117.11s/it, lr=0.001, test_MAE=0.743, time=112, train_MAE=0.661, train_loss=0.7, val_MAE=0.701, val_loss=0.74]Epoch 11:   1%|          | 11/1000 [23:05<32:10:19, 117.11s/it, lr=0.001, test_MAE=0.743, time=112, train_MAE=0.661, train_loss=0.7, val_MAE=0.701, val_loss=0.74]Epoch 11:   1%|          | 11/1000 [24:57<32:10:19, 117.11s/it, lr=0.001, test_MAE=0.727, time=112, train_MAE=0.651, train_loss=0.69, val_MAE=0.677, val_loss=0.717]Epoch 11:   1%|          | 12/1000 [24:57<31:44:32, 115.66s/it, lr=0.001, test_MAE=0.727, time=112, train_MAE=0.651, train_loss=0.69, val_MAE=0.677, val_loss=0.717]Epoch 12:   1%|          | 12/1000 [24:57<31:44:32, 115.66s/it, lr=0.001, test_MAE=0.727, time=112, train_MAE=0.651, train_loss=0.69, val_MAE=0.677, val_loss=0.717]Epoch 12:   1%|          | 12/1000 [26:49<31:44:32, 115.66s/it, lr=0.001, test_MAE=0.781, time=112, train_MAE=0.645, train_loss=0.685, val_MAE=0.723, val_loss=0.763]Epoch 12:   1%|▏         | 13/1000 [26:49<31:24:33, 114.56s/it, lr=0.001, test_MAE=0.781, time=112, train_MAE=0.645, train_loss=0.685, val_MAE=0.723, val_loss=0.763]Epoch 13:   1%|▏         | 13/1000 [26:49<31:24:33, 114.56s/it, lr=0.001, test_MAE=0.781, time=112, train_MAE=0.645, train_loss=0.685, val_MAE=0.723, val_loss=0.763]Epoch 13:   1%|▏         | 13/1000 [28:43<31:24:33, 114.56s/it, lr=0.001, test_MAE=0.768, time=114, train_MAE=0.646, train_loss=0.685, val_MAE=0.745, val_loss=0.785]Epoch 13:   1%|▏         | 14/1000 [28:43<31:20:50, 114.45s/it, lr=0.001, test_MAE=0.768, time=114, train_MAE=0.646, train_loss=0.685, val_MAE=0.745, val_loss=0.785]Epoch 14:   1%|▏         | 14/1000 [28:43<31:20:50, 114.45s/it, lr=0.001, test_MAE=0.768, time=114, train_MAE=0.646, train_loss=0.685, val_MAE=0.745, val_loss=0.785]Epoch 14:   1%|▏         | 14/1000 [30:37<31:20:50, 114.45s/it, lr=0.001, test_MAE=0.73, time=114, train_MAE=0.648, train_loss=0.688, val_MAE=0.671, val_loss=0.711] Epoch 14:   2%|▏         | 15/1000 [30:37<31:15:40, 114.25s/it, lr=0.001, test_MAE=0.73, time=114, train_MAE=0.648, train_loss=0.688, val_MAE=0.671, val_loss=0.711]Epoch 15:   2%|▏         | 15/1000 [30:37<31:15:40, 114.25s/it, lr=0.001, test_MAE=0.73, time=114, train_MAE=0.648, train_loss=0.688, val_MAE=0.671, val_loss=0.711]Epoch 15:   2%|▏         | 15/1000 [32:29<31:15:40, 114.25s/it, lr=0.001, test_MAE=0.71, time=112, train_MAE=0.631, train_loss=0.671, val_MAE=0.691, val_loss=0.731]Epoch    16: reducing learning rate of group 0 to 5.0000e-04.
Epoch 15:   2%|▏         | 16/1000 [32:29<31:04:51, 113.71s/it, lr=0.001, test_MAE=0.71, time=112, train_MAE=0.631, train_loss=0.671, val_MAE=0.691, val_loss=0.731]Epoch 16:   2%|▏         | 16/1000 [32:29<31:04:51, 113.71s/it, lr=0.001, test_MAE=0.71, time=112, train_MAE=0.631, train_loss=0.671, val_MAE=0.691, val_loss=0.731]Epoch 16:   2%|▏         | 16/1000 [34:22<31:04:51, 113.71s/it, lr=0.0005, test_MAE=0.685, time=113, train_MAE=0.631, train_loss=0.671, val_MAE=0.646, val_loss=0.686]Epoch 16:   2%|▏         | 17/1000 [34:22<30:58:33, 113.44s/it, lr=0.0005, test_MAE=0.685, time=113, train_MAE=0.631, train_loss=0.671, val_MAE=0.646, val_loss=0.686]Epoch 17:   2%|▏         | 17/1000 [34:22<30:58:33, 113.44s/it, lr=0.0005, test_MAE=0.685, time=113, train_MAE=0.631, train_loss=0.671, val_MAE=0.646, val_loss=0.686]Epoch 17:   2%|▏         | 17/1000 [36:15<30:58:33, 113.44s/it, lr=0.0005, test_MAE=0.725, time=113, train_MAE=0.624, train_loss=0.664, val_MAE=0.68, val_loss=0.72]  Epoch 17:   2%|▏         | 18/1000 [36:15<30:53:14, 113.23s/it, lr=0.0005, test_MAE=0.725, time=113, train_MAE=0.624, train_loss=0.664, val_MAE=0.68, val_loss=0.72]Epoch 18:   2%|▏         | 18/1000 [36:15<30:53:14, 113.23s/it, lr=0.0005, test_MAE=0.725, time=113, train_MAE=0.624, train_loss=0.664, val_MAE=0.68, val_loss=0.72]Epoch 18:   2%|▏         | 18/1000 [38:07<30:53:14, 113.23s/it, lr=0.0005, test_MAE=0.677, time=112, train_MAE=0.625, train_loss=0.665, val_MAE=0.64, val_loss=0.68]Epoch 18:   2%|▏         | 19/1000 [38:07<30:44:01, 112.78s/it, lr=0.0005, test_MAE=0.677, time=112, train_MAE=0.625, train_loss=0.665, val_MAE=0.64, val_loss=0.68]Epoch 19:   2%|▏         | 19/1000 [38:07<30:44:01, 112.78s/it, lr=0.0005, test_MAE=0.677, time=112, train_MAE=0.625, train_loss=0.665, val_MAE=0.64, val_loss=0.68]Epoch 19:   2%|▏         | 19/1000 [39:59<30:44:01, 112.78s/it, lr=0.0005, test_MAE=0.779, time=113, train_MAE=0.626, train_loss=0.666, val_MAE=0.736, val_loss=0.776]Epoch 19:   2%|▏         | 20/1000 [39:59<30:40:58, 112.71s/it, lr=0.0005, test_MAE=0.779, time=113, train_MAE=0.626, train_loss=0.666, val_MAE=0.736, val_loss=0.776]Epoch 20:   2%|▏         | 20/1000 [39:59<30:40:58, 112.71s/it, lr=0.0005, test_MAE=0.779, time=113, train_MAE=0.626, train_loss=0.666, val_MAE=0.736, val_loss=0.776]Epoch 20:   2%|▏         | 20/1000 [41:52<30:40:58, 112.71s/it, lr=0.0005, test_MAE=0.706, time=112, train_MAE=0.646, train_loss=0.686, val_MAE=0.661, val_loss=0.701]Epoch 20:   2%|▏         | 21/1000 [41:52<30:37:43, 112.63s/it, lr=0.0005, test_MAE=0.706, time=112, train_MAE=0.646, train_loss=0.686, val_MAE=0.661, val_loss=0.701]Epoch 21:   2%|▏         | 21/1000 [41:52<30:37:43, 112.63s/it, lr=0.0005, test_MAE=0.706, time=112, train_MAE=0.646, train_loss=0.686, val_MAE=0.661, val_loss=0.701]Epoch 21:   2%|▏         | 21/1000 [43:45<30:37:43, 112.63s/it, lr=0.0005, test_MAE=0.757, time=114, train_MAE=0.627, train_loss=0.667, val_MAE=0.732, val_loss=0.772]Epoch 21:   2%|▏         | 22/1000 [43:45<30:41:17, 112.96s/it, lr=0.0005, test_MAE=0.757, time=114, train_MAE=0.627, train_loss=0.667, val_MAE=0.732, val_loss=0.772]Epoch 22:   2%|▏         | 22/1000 [43:45<30:41:17, 112.96s/it, lr=0.0005, test_MAE=0.757, time=114, train_MAE=0.627, train_loss=0.667, val_MAE=0.732, val_loss=0.772]Epoch 22:   2%|▏         | 22/1000 [45:40<30:41:17, 112.96s/it, lr=0.0005, test_MAE=0.752, time=114, train_MAE=0.62, train_loss=0.66, val_MAE=0.7, val_loss=0.74]     Epoch 22:   2%|▏         | 23/1000 [45:40<30:46:11, 113.38s/it, lr=0.0005, test_MAE=0.752, time=114, train_MAE=0.62, train_loss=0.66, val_MAE=0.7, val_loss=0.74]Epoch 23:   2%|▏         | 23/1000 [45:40<30:46:11, 113.38s/it, lr=0.0005, test_MAE=0.752, time=114, train_MAE=0.62, train_loss=0.66, val_MAE=0.7, val_loss=0.74]Epoch 23:   2%|▏         | 23/1000 [47:33<30:46:11, 113.38s/it, lr=0.0005, test_MAE=0.748, time=114, train_MAE=0.62, train_loss=0.66, val_MAE=0.709, val_loss=0.749]Epoch 23:   2%|▏         | 24/1000 [47:33<30:45:00, 113.42s/it, lr=0.0005, test_MAE=0.748, time=114, train_MAE=0.62, train_loss=0.66, val_MAE=0.709, val_loss=0.749]Epoch 24:   2%|▏         | 24/1000 [47:33<30:45:00, 113.42s/it, lr=0.0005, test_MAE=0.748, time=114, train_MAE=0.62, train_loss=0.66, val_MAE=0.709, val_loss=0.749]Epoch 24:   2%|▏         | 24/1000 [49:26<30:45:00, 113.42s/it, lr=0.0005, test_MAE=0.674, time=113, train_MAE=0.624, train_loss=0.664, val_MAE=0.622, val_loss=0.662]Epoch 24:   2%|▎         | 25/1000 [49:26<30:40:08, 113.24s/it, lr=0.0005, test_MAE=0.674, time=113, train_MAE=0.624, train_loss=0.664, val_MAE=0.622, val_loss=0.662]Epoch 25:   2%|▎         | 25/1000 [49:26<30:40:08, 113.24s/it, lr=0.0005, test_MAE=0.674, time=113, train_MAE=0.624, train_loss=0.664, val_MAE=0.622, val_loss=0.662]Epoch 25:   2%|▎         | 25/1000 [51:19<30:40:08, 113.24s/it, lr=0.0005, test_MAE=0.673, time=113, train_MAE=0.617, train_loss=0.657, val_MAE=0.638, val_loss=0.678]Epoch 25:   3%|▎         | 26/1000 [51:19<30:36:04, 113.10s/it, lr=0.0005, test_MAE=0.673, time=113, train_MAE=0.617, train_loss=0.657, val_MAE=0.638, val_loss=0.678]Epoch 26:   3%|▎         | 26/1000 [51:19<30:36:04, 113.10s/it, lr=0.0005, test_MAE=0.673, time=113, train_MAE=0.617, train_loss=0.657, val_MAE=0.638, val_loss=0.678]Epoch 26:   3%|▎         | 26/1000 [53:11<30:36:04, 113.10s/it, lr=0.0005, test_MAE=0.689, time=113, train_MAE=0.618, train_loss=0.658, val_MAE=0.632, val_loss=0.672]Epoch 26:   3%|▎         | 27/1000 [53:11<30:31:48, 112.96s/it, lr=0.0005, test_MAE=0.689, time=113, train_MAE=0.618, train_loss=0.658, val_MAE=0.632, val_loss=0.672]Epoch 27:   3%|▎         | 27/1000 [53:11<30:31:48, 112.96s/it, lr=0.0005, test_MAE=0.689, time=113, train_MAE=0.618, train_loss=0.658, val_MAE=0.632, val_loss=0.672]Epoch 27:   3%|▎         | 27/1000 [55:04<30:31:48, 112.96s/it, lr=0.0005, test_MAE=0.686, time=113, train_MAE=0.618, train_loss=0.658, val_MAE=0.636, val_loss=0.676]Epoch 27:   3%|▎         | 28/1000 [55:04<30:28:25, 112.87s/it, lr=0.0005, test_MAE=0.686, time=113, train_MAE=0.618, train_loss=0.658, val_MAE=0.636, val_loss=0.676]Epoch 28:   3%|▎         | 28/1000 [55:04<30:28:25, 112.87s/it, lr=0.0005, test_MAE=0.686, time=113, train_MAE=0.618, train_loss=0.658, val_MAE=0.636, val_loss=0.676]Epoch 28:   3%|▎         | 28/1000 [56:56<30:28:25, 112.87s/it, lr=0.0005, test_MAE=0.68, time=112, train_MAE=0.614, train_loss=0.654, val_MAE=0.634, val_loss=0.674] Epoch 28:   3%|▎         | 29/1000 [56:56<30:23:19, 112.67s/it, lr=0.0005, test_MAE=0.68, time=112, train_MAE=0.614, train_loss=0.654, val_MAE=0.634, val_loss=0.674]Epoch 29:   3%|▎         | 29/1000 [56:56<30:23:19, 112.67s/it, lr=0.0005, test_MAE=0.68, time=112, train_MAE=0.614, train_loss=0.654, val_MAE=0.634, val_loss=0.674]Epoch 29:   3%|▎         | 29/1000 [58:48<30:23:19, 112.67s/it, lr=0.0005, test_MAE=0.678, time=112, train_MAE=0.623, train_loss=0.664, val_MAE=0.639, val_loss=0.679]Epoch 29:   3%|▎         | 30/1000 [58:48<30:19:16, 112.53s/it, lr=0.0005, test_MAE=0.678, time=112, train_MAE=0.623, train_loss=0.664, val_MAE=0.639, val_loss=0.679]Epoch 30:   3%|▎         | 30/1000 [58:48<30:19:16, 112.53s/it, lr=0.0005, test_MAE=0.678, time=112, train_MAE=0.623, train_loss=0.664, val_MAE=0.639, val_loss=0.679]Epoch 30:   3%|▎         | 30/1000 [1:00:41<30:19:16, 112.53s/it, lr=0.0005, test_MAE=0.712, time=113, train_MAE=0.609, train_loss=0.65, val_MAE=0.709, val_loss=0.749]Epoch    31: reducing learning rate of group 0 to 2.5000e-04.
Epoch 30:   3%|▎         | 31/1000 [1:00:41<30:17:56, 112.57s/it, lr=0.0005, test_MAE=0.712, time=113, train_MAE=0.609, train_loss=0.65, val_MAE=0.709, val_loss=0.749]Epoch 31:   3%|▎         | 31/1000 [1:00:41<30:17:56, 112.57s/it, lr=0.0005, test_MAE=0.712, time=113, train_MAE=0.609, train_loss=0.65, val_MAE=0.709, val_loss=0.749]Epoch 31:   3%|▎         | 31/1000 [1:02:34<30:17:56, 112.57s/it, lr=0.00025, test_MAE=0.669, time=113, train_MAE=0.61, train_loss=0.65, val_MAE=0.644, val_loss=0.684]Epoch 31:   3%|▎         | 32/1000 [1:02:34<30:17:12, 112.64s/it, lr=0.00025, test_MAE=0.669, time=113, train_MAE=0.61, train_loss=0.65, val_MAE=0.644, val_loss=0.684]Epoch 32:   3%|▎         | 32/1000 [1:02:34<30:17:12, 112.64s/it, lr=0.00025, test_MAE=0.669, time=113, train_MAE=0.61, train_loss=0.65, val_MAE=0.644, val_loss=0.684]Epoch 32:   3%|▎         | 32/1000 [1:04:29<30:17:12, 112.64s/it, lr=0.00025, test_MAE=0.687, time=115, train_MAE=0.613, train_loss=0.654, val_MAE=0.644, val_loss=0.684]Epoch 32:   3%|▎         | 33/1000 [1:04:29<30:26:02, 113.30s/it, lr=0.00025, test_MAE=0.687, time=115, train_MAE=0.613, train_loss=0.654, val_MAE=0.644, val_loss=0.684]Epoch 33:   3%|▎         | 33/1000 [1:04:29<30:26:02, 113.30s/it, lr=0.00025, test_MAE=0.687, time=115, train_MAE=0.613, train_loss=0.654, val_MAE=0.644, val_loss=0.684]Epoch 33:   3%|▎         | 33/1000 [1:06:22<30:26:02, 113.30s/it, lr=0.00025, test_MAE=0.689, time=113, train_MAE=0.603, train_loss=0.643, val_MAE=0.644, val_loss=0.684]Epoch 33:   3%|▎         | 34/1000 [1:06:22<30:25:08, 113.36s/it, lr=0.00025, test_MAE=0.689, time=113, train_MAE=0.603, train_loss=0.643, val_MAE=0.644, val_loss=0.684]Epoch 34:   3%|▎         | 34/1000 [1:06:22<30:25:08, 113.36s/it, lr=0.00025, test_MAE=0.689, time=113, train_MAE=0.603, train_loss=0.643, val_MAE=0.644, val_loss=0.684]Epoch 34:   3%|▎         | 34/1000 [1:08:14<30:25:08, 113.36s/it, lr=0.00025, test_MAE=0.679, time=111, train_MAE=0.606, train_loss=0.646, val_MAE=0.645, val_loss=0.685]Epoch 34:   4%|▎         | 35/1000 [1:08:14<30:14:14, 112.80s/it, lr=0.00025, test_MAE=0.679, time=111, train_MAE=0.606, train_loss=0.646, val_MAE=0.645, val_loss=0.685]Epoch 35:   4%|▎         | 35/1000 [1:08:14<30:14:14, 112.80s/it, lr=0.00025, test_MAE=0.679, time=111, train_MAE=0.606, train_loss=0.646, val_MAE=0.645, val_loss=0.685]Epoch 35:   4%|▎         | 35/1000 [1:10:06<30:14:14, 112.80s/it, lr=0.00025, test_MAE=0.671, time=112, train_MAE=0.603, train_loss=0.643, val_MAE=0.635, val_loss=0.675]Epoch 35:   4%|▎         | 36/1000 [1:10:06<30:09:38, 112.63s/it, lr=0.00025, test_MAE=0.671, time=112, train_MAE=0.603, train_loss=0.643, val_MAE=0.635, val_loss=0.675]Epoch 36:   4%|▎         | 36/1000 [1:10:06<30:09:38, 112.63s/it, lr=0.00025, test_MAE=0.671, time=112, train_MAE=0.603, train_loss=0.643, val_MAE=0.635, val_loss=0.675]Epoch 36:   4%|▎         | 36/1000 [1:12:00<30:09:38, 112.63s/it, lr=0.00025, test_MAE=0.688, time=114, train_MAE=0.599, train_loss=0.639, val_MAE=0.654, val_loss=0.694]Epoch    37: reducing learning rate of group 0 to 1.2500e-04.
Epoch 36:   4%|▎         | 37/1000 [1:12:00<30:12:02, 112.90s/it, lr=0.00025, test_MAE=0.688, time=114, train_MAE=0.599, train_loss=0.639, val_MAE=0.654, val_loss=0.694]Epoch 37:   4%|▎         | 37/1000 [1:12:00<30:12:02, 112.90s/it, lr=0.00025, test_MAE=0.688, time=114, train_MAE=0.599, train_loss=0.639, val_MAE=0.654, val_loss=0.694]Epoch 37:   4%|▎         | 37/1000 [1:13:55<30:12:02, 112.90s/it, lr=0.000125, test_MAE=0.687, time=115, train_MAE=0.602, train_loss=0.642, val_MAE=0.648, val_loss=0.688]Epoch 37:   4%|▍         | 38/1000 [1:13:55<30:21:00, 113.58s/it, lr=0.000125, test_MAE=0.687, time=115, train_MAE=0.602, train_loss=0.642, val_MAE=0.648, val_loss=0.688]Epoch 38:   4%|▍         | 38/1000 [1:13:55<30:21:00, 113.58s/it, lr=0.000125, test_MAE=0.687, time=115, train_MAE=0.602, train_loss=0.642, val_MAE=0.648, val_loss=0.688]Epoch 38:   4%|▍         | 38/1000 [1:15:48<30:21:00, 113.58s/it, lr=0.000125, test_MAE=0.664, time=113, train_MAE=0.595, train_loss=0.635, val_MAE=0.623, val_loss=0.663]Epoch 38:   4%|▍         | 39/1000 [1:15:48<30:16:47, 113.43s/it, lr=0.000125, test_MAE=0.664, time=113, train_MAE=0.595, train_loss=0.635, val_MAE=0.623, val_loss=0.663]Epoch 39:   4%|▍         | 39/1000 [1:15:48<30:16:47, 113.43s/it, lr=0.000125, test_MAE=0.664, time=113, train_MAE=0.595, train_loss=0.635, val_MAE=0.623, val_loss=0.663]Epoch 39:   4%|▍         | 39/1000 [1:17:41<30:16:47, 113.43s/it, lr=0.000125, test_MAE=0.686, time=113, train_MAE=0.596, train_loss=0.636, val_MAE=0.643, val_loss=0.683]Epoch 39:   4%|▍         | 40/1000 [1:17:41<30:12:33, 113.29s/it, lr=0.000125, test_MAE=0.686, time=113, train_MAE=0.596, train_loss=0.636, val_MAE=0.643, val_loss=0.683]Epoch 40:   4%|▍         | 40/1000 [1:17:41<30:12:33, 113.29s/it, lr=0.000125, test_MAE=0.686, time=113, train_MAE=0.596, train_loss=0.636, val_MAE=0.643, val_loss=0.683]Epoch 40:   4%|▍         | 40/1000 [1:19:34<30:12:33, 113.29s/it, lr=0.000125, test_MAE=0.659, time=114, train_MAE=0.597, train_loss=0.637, val_MAE=0.637, val_loss=0.677]Epoch 40:   4%|▍         | 41/1000 [1:19:34<30:12:35, 113.41s/it, lr=0.000125, test_MAE=0.659, time=114, train_MAE=0.597, train_loss=0.637, val_MAE=0.637, val_loss=0.677]Epoch 41:   4%|▍         | 41/1000 [1:19:34<30:12:35, 113.41s/it, lr=0.000125, test_MAE=0.659, time=114, train_MAE=0.597, train_loss=0.637, val_MAE=0.637, val_loss=0.677]Epoch 41:   4%|▍         | 41/1000 [1:21:28<30:12:35, 113.41s/it, lr=0.000125, test_MAE=0.668, time=114, train_MAE=0.597, train_loss=0.636, val_MAE=0.632, val_loss=0.672]Epoch 41:   4%|▍         | 42/1000 [1:21:28<30:12:50, 113.54s/it, lr=0.000125, test_MAE=0.668, time=114, train_MAE=0.597, train_loss=0.636, val_MAE=0.632, val_loss=0.672]Epoch 42:   4%|▍         | 42/1000 [1:21:28<30:12:50, 113.54s/it, lr=0.000125, test_MAE=0.668, time=114, train_MAE=0.597, train_loss=0.636, val_MAE=0.632, val_loss=0.672]Epoch 42:   4%|▍         | 42/1000 [1:23:21<30:12:50, 113.54s/it, lr=0.000125, test_MAE=0.693, time=113, train_MAE=0.596, train_loss=0.635, val_MAE=0.634, val_loss=0.674]Epoch    43: reducing learning rate of group 0 to 6.2500e-05.
Epoch 42:   4%|▍         | 43/1000 [1:23:21<30:08:01, 113.36s/it, lr=0.000125, test_MAE=0.693, time=113, train_MAE=0.596, train_loss=0.635, val_MAE=0.634, val_loss=0.674]Epoch 43:   4%|▍         | 43/1000 [1:23:21<30:08:01, 113.36s/it, lr=0.000125, test_MAE=0.693, time=113, train_MAE=0.596, train_loss=0.635, val_MAE=0.634, val_loss=0.674]Epoch 43:   4%|▍         | 43/1000 [1:25:14<30:08:01, 113.36s/it, lr=6.25e-5, test_MAE=0.662, time=113, train_MAE=0.589, train_loss=0.629, val_MAE=0.628, val_loss=0.667] Epoch 43:   4%|▍         | 44/1000 [1:25:14<30:04:08, 113.23s/it, lr=6.25e-5, test_MAE=0.662, time=113, train_MAE=0.589, train_loss=0.629, val_MAE=0.628, val_loss=0.667]Epoch 44:   4%|▍         | 44/1000 [1:25:14<30:04:08, 113.23s/it, lr=6.25e-5, test_MAE=0.662, time=113, train_MAE=0.589, train_loss=0.629, val_MAE=0.628, val_loss=0.667]Epoch 44:   4%|▍         | 44/1000 [1:27:08<30:04:08, 113.23s/it, lr=6.25e-5, test_MAE=0.667, time=114, train_MAE=0.593, train_loss=0.632, val_MAE=0.635, val_loss=0.675]Epoch 44:   4%|▍         | 45/1000 [1:27:08<30:03:52, 113.33s/it, lr=6.25e-5, test_MAE=0.667, time=114, train_MAE=0.593, train_loss=0.632, val_MAE=0.635, val_loss=0.675]Epoch 45:   4%|▍         | 45/1000 [1:27:08<30:03:52, 113.33s/it, lr=6.25e-5, test_MAE=0.667, time=114, train_MAE=0.593, train_loss=0.632, val_MAE=0.635, val_loss=0.675]Epoch 45:   4%|▍         | 45/1000 [1:29:01<30:03:52, 113.33s/it, lr=6.25e-5, test_MAE=0.673, time=113, train_MAE=0.596, train_loss=0.636, val_MAE=0.632, val_loss=0.671]Epoch 45:   5%|▍         | 46/1000 [1:29:01<30:00:11, 113.22s/it, lr=6.25e-5, test_MAE=0.673, time=113, train_MAE=0.596, train_loss=0.636, val_MAE=0.632, val_loss=0.671]Epoch 46:   5%|▍         | 46/1000 [1:29:01<30:00:11, 113.22s/it, lr=6.25e-5, test_MAE=0.673, time=113, train_MAE=0.596, train_loss=0.636, val_MAE=0.632, val_loss=0.671]Epoch 46:   5%|▍         | 46/1000 [1:30:52<30:00:11, 113.22s/it, lr=6.25e-5, test_MAE=0.662, time=111, train_MAE=0.587, train_loss=0.626, val_MAE=0.628, val_loss=0.668]Epoch 46:   5%|▍         | 47/1000 [1:30:52<29:49:37, 112.67s/it, lr=6.25e-5, test_MAE=0.662, time=111, train_MAE=0.587, train_loss=0.626, val_MAE=0.628, val_loss=0.668]Epoch 47:   5%|▍         | 47/1000 [1:30:52<29:49:37, 112.67s/it, lr=6.25e-5, test_MAE=0.662, time=111, train_MAE=0.587, train_loss=0.626, val_MAE=0.628, val_loss=0.668]Epoch 47:   5%|▍         | 47/1000 [1:32:44<29:49:37, 112.67s/it, lr=6.25e-5, test_MAE=0.659, time=112, train_MAE=0.585, train_loss=0.625, val_MAE=0.626, val_loss=0.665]Epoch 47:   5%|▍         | 48/1000 [1:32:44<29:45:29, 112.53s/it, lr=6.25e-5, test_MAE=0.659, time=112, train_MAE=0.585, train_loss=0.625, val_MAE=0.626, val_loss=0.665]Epoch 48:   5%|▍         | 48/1000 [1:32:44<29:45:29, 112.53s/it, lr=6.25e-5, test_MAE=0.659, time=112, train_MAE=0.585, train_loss=0.625, val_MAE=0.626, val_loss=0.665]Epoch 48:   5%|▍         | 48/1000 [1:34:38<29:45:29, 112.53s/it, lr=6.25e-5, test_MAE=0.663, time=114, train_MAE=0.589, train_loss=0.629, val_MAE=0.627, val_loss=0.667]Epoch    49: reducing learning rate of group 0 to 3.1250e-05.
Epoch 48:   5%|▍         | 49/1000 [1:34:38<29:48:43, 112.85s/it, lr=6.25e-5, test_MAE=0.663, time=114, train_MAE=0.589, train_loss=0.629, val_MAE=0.627, val_loss=0.667]Epoch 49:   5%|▍         | 49/1000 [1:34:38<29:48:43, 112.85s/it, lr=6.25e-5, test_MAE=0.663, time=114, train_MAE=0.589, train_loss=0.629, val_MAE=0.627, val_loss=0.667]Epoch 49:   5%|▍         | 49/1000 [1:36:30<29:48:43, 112.85s/it, lr=3.13e-5, test_MAE=0.669, time=112, train_MAE=0.582, train_loss=0.622, val_MAE=0.632, val_loss=0.671]Epoch 49:   5%|▌         | 50/1000 [1:36:30<29:44:15, 112.69s/it, lr=3.13e-5, test_MAE=0.669, time=112, train_MAE=0.582, train_loss=0.622, val_MAE=0.632, val_loss=0.671]Epoch 50:   5%|▌         | 50/1000 [1:36:30<29:44:15, 112.69s/it, lr=3.13e-5, test_MAE=0.669, time=112, train_MAE=0.582, train_loss=0.622, val_MAE=0.632, val_loss=0.671]Epoch 50:   5%|▌         | 50/1000 [1:38:23<29:44:15, 112.69s/it, lr=3.13e-5, test_MAE=0.664, time=113, train_MAE=0.584, train_loss=0.623, val_MAE=0.631, val_loss=0.671]Epoch 50:   5%|▌         | 51/1000 [1:38:23<29:45:14, 112.87s/it, lr=3.13e-5, test_MAE=0.664, time=113, train_MAE=0.584, train_loss=0.623, val_MAE=0.631, val_loss=0.671]Epoch 51:   5%|▌         | 51/1000 [1:38:23<29:45:14, 112.87s/it, lr=3.13e-5, test_MAE=0.664, time=113, train_MAE=0.584, train_loss=0.623, val_MAE=0.631, val_loss=0.671]Epoch 51:   5%|▌         | 51/1000 [1:40:16<29:45:14, 112.87s/it, lr=3.13e-5, test_MAE=0.663, time=113, train_MAE=0.579, train_loss=0.619, val_MAE=0.623, val_loss=0.662]Epoch 51:   5%|▌         | 52/1000 [1:40:16<29:43:25, 112.87s/it, lr=3.13e-5, test_MAE=0.663, time=113, train_MAE=0.579, train_loss=0.619, val_MAE=0.623, val_loss=0.662]Epoch 52:   5%|▌         | 52/1000 [1:40:16<29:43:25, 112.87s/it, lr=3.13e-5, test_MAE=0.663, time=113, train_MAE=0.579, train_loss=0.619, val_MAE=0.623, val_loss=0.662]Epoch 52:   5%|▌         | 52/1000 [1:42:09<29:43:25, 112.87s/it, lr=3.13e-5, test_MAE=0.661, time=113, train_MAE=0.585, train_loss=0.624, val_MAE=0.619, val_loss=0.659]Epoch 52:   5%|▌         | 53/1000 [1:42:09<29:42:28, 112.93s/it, lr=3.13e-5, test_MAE=0.661, time=113, train_MAE=0.585, train_loss=0.624, val_MAE=0.619, val_loss=0.659]Epoch 53:   5%|▌         | 53/1000 [1:42:09<29:42:28, 112.93s/it, lr=3.13e-5, test_MAE=0.661, time=113, train_MAE=0.585, train_loss=0.624, val_MAE=0.619, val_loss=0.659]Epoch 53:   5%|▌         | 53/1000 [1:44:02<29:42:28, 112.93s/it, lr=3.13e-5, test_MAE=0.676, time=113, train_MAE=0.581, train_loss=0.621, val_MAE=0.636, val_loss=0.676]Epoch 53:   5%|▌         | 54/1000 [1:44:02<29:39:21, 112.86s/it, lr=3.13e-5, test_MAE=0.676, time=113, train_MAE=0.581, train_loss=0.621, val_MAE=0.636, val_loss=0.676]Epoch 54:   5%|▌         | 54/1000 [1:44:02<29:39:21, 112.86s/it, lr=3.13e-5, test_MAE=0.676, time=113, train_MAE=0.581, train_loss=0.621, val_MAE=0.636, val_loss=0.676]Epoch 54:   5%|▌         | 54/1000 [1:45:54<29:39:21, 112.86s/it, lr=3.13e-5, test_MAE=0.663, time=111, train_MAE=0.581, train_loss=0.621, val_MAE=0.626, val_loss=0.665]Epoch 54:   6%|▌         | 55/1000 [1:45:54<29:30:49, 112.43s/it, lr=3.13e-5, test_MAE=0.663, time=111, train_MAE=0.581, train_loss=0.621, val_MAE=0.626, val_loss=0.665]Epoch 55:   6%|▌         | 55/1000 [1:45:54<29:30:49, 112.43s/it, lr=3.13e-5, test_MAE=0.663, time=111, train_MAE=0.581, train_loss=0.621, val_MAE=0.626, val_loss=0.665]Epoch 55:   6%|▌         | 55/1000 [1:47:42<29:30:49, 112.43s/it, lr=3.13e-5, test_MAE=0.664, time=108, train_MAE=0.589, train_loss=0.629, val_MAE=0.626, val_loss=0.666]Epoch 55:   6%|▌         | 56/1000 [1:47:42<29:09:35, 111.20s/it, lr=3.13e-5, test_MAE=0.664, time=108, train_MAE=0.589, train_loss=0.629, val_MAE=0.626, val_loss=0.666]Epoch 56:   6%|▌         | 56/1000 [1:47:42<29:09:35, 111.20s/it, lr=3.13e-5, test_MAE=0.664, time=108, train_MAE=0.589, train_loss=0.629, val_MAE=0.626, val_loss=0.666]Epoch 56:   6%|▌         | 56/1000 [1:49:29<29:09:35, 111.20s/it, lr=3.13e-5, test_MAE=0.669, time=107, train_MAE=0.58, train_loss=0.619, val_MAE=0.633, val_loss=0.673] Epoch 56:   6%|▌         | 57/1000 [1:49:29<28:48:26, 109.98s/it, lr=3.13e-5, test_MAE=0.669, time=107, train_MAE=0.58, train_loss=0.619, val_MAE=0.633, val_loss=0.673]Epoch 57:   6%|▌         | 57/1000 [1:49:29<28:48:26, 109.98s/it, lr=3.13e-5, test_MAE=0.669, time=107, train_MAE=0.58, train_loss=0.619, val_MAE=0.633, val_loss=0.673]Epoch 57:   6%|▌         | 57/1000 [1:51:16<28:48:26, 109.98s/it, lr=3.13e-5, test_MAE=0.664, time=107, train_MAE=0.58, train_loss=0.619, val_MAE=0.629, val_loss=0.669]Epoch 57:   6%|▌         | 58/1000 [1:51:16<28:31:21, 109.00s/it, lr=3.13e-5, test_MAE=0.664, time=107, train_MAE=0.58, train_loss=0.619, val_MAE=0.629, val_loss=0.669]Epoch 58:   6%|▌         | 58/1000 [1:51:16<28:31:21, 109.00s/it, lr=3.13e-5, test_MAE=0.664, time=107, train_MAE=0.58, train_loss=0.619, val_MAE=0.629, val_loss=0.669]Epoch 58:   6%|▌         | 58/1000 [1:53:02<28:31:21, 109.00s/it, lr=3.13e-5, test_MAE=0.67, time=107, train_MAE=0.581, train_loss=0.62, val_MAE=0.626, val_loss=0.666] Epoch    59: reducing learning rate of group 0 to 1.5625e-05.
Epoch 58:   6%|▌         | 59/1000 [1:53:02<28:18:33, 108.30s/it, lr=3.13e-5, test_MAE=0.67, time=107, train_MAE=0.581, train_loss=0.62, val_MAE=0.626, val_loss=0.666]Epoch 59:   6%|▌         | 59/1000 [1:53:02<28:18:33, 108.30s/it, lr=3.13e-5, test_MAE=0.67, time=107, train_MAE=0.581, train_loss=0.62, val_MAE=0.626, val_loss=0.666]Epoch 59:   6%|▌         | 59/1000 [1:54:48<28:18:33, 108.30s/it, lr=1.56e-5, test_MAE=0.664, time=106, train_MAE=0.579, train_loss=0.618, val_MAE=0.625, val_loss=0.664]Epoch 59:   6%|▌         | 60/1000 [1:54:48<28:05:43, 107.60s/it, lr=1.56e-5, test_MAE=0.664, time=106, train_MAE=0.579, train_loss=0.618, val_MAE=0.625, val_loss=0.664]Epoch 60:   6%|▌         | 60/1000 [1:54:48<28:05:43, 107.60s/it, lr=1.56e-5, test_MAE=0.664, time=106, train_MAE=0.579, train_loss=0.618, val_MAE=0.625, val_loss=0.664]Epoch 60:   6%|▌         | 60/1000 [1:56:34<28:05:43, 107.60s/it, lr=1.56e-5, test_MAE=0.66, time=106, train_MAE=0.583, train_loss=0.622, val_MAE=0.628, val_loss=0.667] Epoch 60:   6%|▌         | 61/1000 [1:56:34<27:56:36, 107.13s/it, lr=1.56e-5, test_MAE=0.66, time=106, train_MAE=0.583, train_loss=0.622, val_MAE=0.628, val_loss=0.667]Epoch 61:   6%|▌         | 61/1000 [1:56:34<27:56:36, 107.13s/it, lr=1.56e-5, test_MAE=0.66, time=106, train_MAE=0.583, train_loss=0.622, val_MAE=0.628, val_loss=0.667]Epoch 61:   6%|▌         | 61/1000 [1:58:21<27:56:36, 107.13s/it, lr=1.56e-5, test_MAE=0.658, time=107, train_MAE=0.58, train_loss=0.619, val_MAE=0.627, val_loss=0.666]Epoch 61:   6%|▌         | 62/1000 [1:58:21<27:53:17, 107.03s/it, lr=1.56e-5, test_MAE=0.658, time=107, train_MAE=0.58, train_loss=0.619, val_MAE=0.627, val_loss=0.666]Epoch 62:   6%|▌         | 62/1000 [1:58:21<27:53:17, 107.03s/it, lr=1.56e-5, test_MAE=0.658, time=107, train_MAE=0.58, train_loss=0.619, val_MAE=0.627, val_loss=0.666]Epoch 62:   6%|▌         | 62/1000 [2:00:08<27:53:17, 107.03s/it, lr=1.56e-5, test_MAE=0.66, time=107, train_MAE=0.585, train_loss=0.624, val_MAE=0.622, val_loss=0.661]Epoch 62:   6%|▋         | 63/1000 [2:00:08<27:49:48, 106.92s/it, lr=1.56e-5, test_MAE=0.66, time=107, train_MAE=0.585, train_loss=0.624, val_MAE=0.622, val_loss=0.661]Epoch 63:   6%|▋         | 63/1000 [2:00:08<27:49:48, 106.92s/it, lr=1.56e-5, test_MAE=0.66, time=107, train_MAE=0.585, train_loss=0.624, val_MAE=0.622, val_loss=0.661]Epoch 63:   6%|▋         | 63/1000 [2:01:54<27:49:48, 106.92s/it, lr=1.56e-5, test_MAE=0.663, time=106, train_MAE=0.58, train_loss=0.62, val_MAE=0.623, val_loss=0.663] Epoch 63:   6%|▋         | 64/1000 [2:01:54<27:45:38, 106.77s/it, lr=1.56e-5, test_MAE=0.663, time=106, train_MAE=0.58, train_loss=0.62, val_MAE=0.623, val_loss=0.663]Epoch 64:   6%|▋         | 64/1000 [2:01:54<27:45:38, 106.77s/it, lr=1.56e-5, test_MAE=0.663, time=106, train_MAE=0.58, train_loss=0.62, val_MAE=0.623, val_loss=0.663]Epoch 64:   6%|▋         | 64/1000 [2:03:39<27:45:38, 106.77s/it, lr=1.56e-5, test_MAE=0.658, time=104, train_MAE=0.58, train_loss=0.619, val_MAE=0.625, val_loss=0.665]Epoch    65: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 64:   6%|▋         | 64/1000 [2:03:39<30:08:26, 115.93s/it, lr=1.56e-5, test_MAE=0.658, time=104, train_MAE=0.58, train_loss=0.619, val_MAE=0.625, val_loss=0.665]
Test MAE: 0.6578
Train MAE: 0.5683
Convergence Time (Epochs): 64.0000
TOTAL TIME TAKEN: 7468.9261s
AVG TIME PER EPOCH: 114.1201s
