I'm echoing to stdout
I'm echoing to stderr
My JobID is 56540140
I have 8 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.2045s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 4, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'rational_vec', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_all', 'num_eigs': 64, 'bias_mode': 'spatial', 'eigval_hidden_dim': 5, 'eigval_num_hidden_layer': 3, 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 1, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/zinc_train_rec_full.csv', 'test': 'supp_data/molecules/zinc_test_rec_full.csv', 'val': 'supp_data/molecules/zinc_val_rec_full.csv'}, 'fixMissingPhi1': False, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [07:21<?, ?it/s, lr=0.001, test_MAE=1.5, time=441, train_MAE=1.42, train_loss=1.45, val_MAE=1.41, val_loss=1.44]Epoch 0:   0%|          | 1/1000 [07:21<122:25:10, 441.15s/it, lr=0.001, test_MAE=1.5, time=441, train_MAE=1.42, train_loss=1.45, val_MAE=1.41, val_loss=1.44]Epoch 1:   0%|          | 1/1000 [07:21<122:25:10, 441.15s/it, lr=0.001, test_MAE=1.5, time=441, train_MAE=1.42, train_loss=1.45, val_MAE=1.41, val_loss=1.44]Epoch 1:   0%|          | 1/1000 [14:34<122:25:10, 441.15s/it, lr=0.001, test_MAE=1.49, time=433, train_MAE=1.34, train_loss=1.38, val_MAE=1.41, val_loss=1.45]Epoch 1:   0%|          | 2/1000 [14:34<121:38:55, 438.81s/it, lr=0.001, test_MAE=1.49, time=433, train_MAE=1.34, train_loss=1.38, val_MAE=1.41, val_loss=1.45]Epoch 2:   0%|          | 2/1000 [14:34<121:38:55, 438.81s/it, lr=0.001, test_MAE=1.49, time=433, train_MAE=1.34, train_loss=1.38, val_MAE=1.41, val_loss=1.45]Epoch 2:   0%|          | 2/1000 [21:49<121:38:55, 438.81s/it, lr=0.001, test_MAE=1.48, time=435, train_MAE=1.28, train_loss=1.32, val_MAE=1.44, val_loss=1.48]Epoch 2:   0%|          | 3/1000 [21:49<121:14:31, 437.78s/it, lr=0.001, test_MAE=1.48, time=435, train_MAE=1.28, train_loss=1.32, val_MAE=1.44, val_loss=1.48]Epoch 3:   0%|          | 3/1000 [21:49<121:14:31, 437.78s/it, lr=0.001, test_MAE=1.48, time=435, train_MAE=1.28, train_loss=1.32, val_MAE=1.44, val_loss=1.48]Epoch 3:   0%|          | 3/1000 [28:55<121:14:31, 437.78s/it, lr=0.001, test_MAE=1.42, time=425, train_MAE=1.19, train_loss=1.24, val_MAE=1.39, val_loss=1.44]Epoch 3:   0%|          | 4/1000 [28:55<120:05:25, 434.06s/it, lr=0.001, test_MAE=1.42, time=425, train_MAE=1.19, train_loss=1.24, val_MAE=1.39, val_loss=1.44]Epoch 4:   0%|          | 4/1000 [28:55<120:05:25, 434.06s/it, lr=0.001, test_MAE=1.42, time=425, train_MAE=1.19, train_loss=1.24, val_MAE=1.39, val_loss=1.44]Epoch 4:   0%|          | 4/1000 [35:50<120:05:25, 434.06s/it, lr=0.001, test_MAE=1.41, time=415, train_MAE=1.11, train_loss=1.16, val_MAE=1.32, val_loss=1.38]Epoch 4:   0%|          | 5/1000 [35:50<118:24:56, 428.44s/it, lr=0.001, test_MAE=1.41, time=415, train_MAE=1.11, train_loss=1.16, val_MAE=1.32, val_loss=1.38]Epoch 5:   0%|          | 5/1000 [35:50<118:24:56, 428.44s/it, lr=0.001, test_MAE=1.41, time=415, train_MAE=1.11, train_loss=1.16, val_MAE=1.32, val_loss=1.38]Epoch 5:   0%|          | 5/1000 [42:45<118:24:56, 428.44s/it, lr=0.001, test_MAE=1.41, time=415, train_MAE=1.03, train_loss=1.09, val_MAE=1.36, val_loss=1.41]Epoch 5:   1%|          | 6/1000 [42:45<117:11:19, 424.43s/it, lr=0.001, test_MAE=1.41, time=415, train_MAE=1.03, train_loss=1.09, val_MAE=1.36, val_loss=1.41]Epoch 6:   1%|          | 6/1000 [42:45<117:11:19, 424.43s/it, lr=0.001, test_MAE=1.41, time=415, train_MAE=1.03, train_loss=1.09, val_MAE=1.36, val_loss=1.41]Epoch 6:   1%|          | 6/1000 [49:41<117:11:19, 424.43s/it, lr=0.001, test_MAE=1.34, time=416, train_MAE=0.947, train_loss=1, val_MAE=1.29, val_loss=1.35]  Epoch 6:   1%|          | 7/1000 [49:41<116:20:13, 421.77s/it, lr=0.001, test_MAE=1.34, time=416, train_MAE=0.947, train_loss=1, val_MAE=1.29, val_loss=1.35]Epoch 7:   1%|          | 7/1000 [49:41<116:20:13, 421.77s/it, lr=0.001, test_MAE=1.34, time=416, train_MAE=0.947, train_loss=1, val_MAE=1.29, val_loss=1.35]Epoch 7:   1%|          | 7/1000 [56:36<116:20:13, 421.77s/it, lr=0.001, test_MAE=1.38, time=415, train_MAE=0.893, train_loss=0.952, val_MAE=1.34, val_loss=1.4]Epoch 7:   1%|          | 8/1000 [56:36<115:39:29, 419.73s/it, lr=0.001, test_MAE=1.38, time=415, train_MAE=0.893, train_loss=0.952, val_MAE=1.34, val_loss=1.4]Epoch 8:   1%|          | 8/1000 [56:36<115:39:29, 419.73s/it, lr=0.001, test_MAE=1.38, time=415, train_MAE=0.893, train_loss=0.952, val_MAE=1.34, val_loss=1.4]Epoch 8:   1%|          | 8/1000 [1:03:29<115:39:29, 419.73s/it, lr=0.001, test_MAE=1.33, time=413, train_MAE=0.854, train_loss=0.915, val_MAE=1.29, val_loss=1.35]Epoch 8:   1%|          | 9/1000 [1:03:29<114:59:40, 417.74s/it, lr=0.001, test_MAE=1.33, time=413, train_MAE=0.854, train_loss=0.915, val_MAE=1.29, val_loss=1.35]Epoch 9:   1%|          | 9/1000 [1:03:29<114:59:40, 417.74s/it, lr=0.001, test_MAE=1.33, time=413, train_MAE=0.854, train_loss=0.915, val_MAE=1.29, val_loss=1.35]Epoch 9:   1%|          | 9/1000 [1:10:22<114:59:40, 417.74s/it, lr=0.001, test_MAE=1.11, time=414, train_MAE=0.831, train_loss=0.893, val_MAE=1.07, val_loss=1.13]Epoch 9:   1%|          | 10/1000 [1:10:22<114:32:29, 416.51s/it, lr=0.001, test_MAE=1.11, time=414, train_MAE=0.831, train_loss=0.893, val_MAE=1.07, val_loss=1.13]Epoch 10:   1%|          | 10/1000 [1:10:22<114:32:29, 416.51s/it, lr=0.001, test_MAE=1.11, time=414, train_MAE=0.831, train_loss=0.893, val_MAE=1.07, val_loss=1.13]Epoch 10:   1%|          | 10/1000 [1:17:16<114:32:29, 416.51s/it, lr=0.001, test_MAE=1.34, time=414, train_MAE=0.801, train_loss=0.864, val_MAE=1.31, val_loss=1.37]Epoch 10:   1%|          | 11/1000 [1:17:16<114:10:53, 415.63s/it, lr=0.001, test_MAE=1.34, time=414, train_MAE=0.801, train_loss=0.864, val_MAE=1.31, val_loss=1.37]Epoch 11:   1%|          | 11/1000 [1:17:16<114:10:53, 415.63s/it, lr=0.001, test_MAE=1.34, time=414, train_MAE=0.801, train_loss=0.864, val_MAE=1.31, val_loss=1.37]Epoch 11:   1%|          | 11/1000 [1:24:09<114:10:53, 415.63s/it, lr=0.001, test_MAE=1.06, time=413, train_MAE=0.788, train_loss=0.853, val_MAE=1.01, val_loss=1.07]Epoch 11:   1%|          | 12/1000 [1:24:09<113:50:58, 414.84s/it, lr=0.001, test_MAE=1.06, time=413, train_MAE=0.788, train_loss=0.853, val_MAE=1.01, val_loss=1.07]Epoch 12:   1%|          | 12/1000 [1:24:09<113:50:58, 414.84s/it, lr=0.001, test_MAE=1.06, time=413, train_MAE=0.788, train_loss=0.853, val_MAE=1.01, val_loss=1.07]Epoch 12:   1%|          | 12/1000 [1:31:03<113:50:58, 414.84s/it, lr=0.001, test_MAE=1.1, time=414, train_MAE=0.765, train_loss=0.831, val_MAE=1.08, val_loss=1.15] Epoch 12:   1%|▏         | 13/1000 [1:31:03<113:39:42, 414.57s/it, lr=0.001, test_MAE=1.1, time=414, train_MAE=0.765, train_loss=0.831, val_MAE=1.08, val_loss=1.15]Epoch 13:   1%|▏         | 13/1000 [1:31:03<113:39:42, 414.57s/it, lr=0.001, test_MAE=1.1, time=414, train_MAE=0.765, train_loss=0.831, val_MAE=1.08, val_loss=1.15]Epoch 13:   1%|▏         | 13/1000 [1:37:58<113:39:42, 414.57s/it, lr=0.001, test_MAE=1.21, time=415, train_MAE=0.75, train_loss=0.817, val_MAE=1.16, val_loss=1.23]Epoch 13:   1%|▏         | 14/1000 [1:37:58<113:37:23, 414.85s/it, lr=0.001, test_MAE=1.21, time=415, train_MAE=0.75, train_loss=0.817, val_MAE=1.16, val_loss=1.23]Epoch 14:   1%|▏         | 14/1000 [1:37:58<113:37:23, 414.85s/it, lr=0.001, test_MAE=1.21, time=415, train_MAE=0.75, train_loss=0.817, val_MAE=1.16, val_loss=1.23]Epoch 14:   1%|▏         | 14/1000 [1:44:51<113:37:23, 414.85s/it, lr=0.001, test_MAE=1.16, time=412, train_MAE=0.736, train_loss=0.803, val_MAE=1.12, val_loss=1.19]Epoch 14:   2%|▏         | 15/1000 [1:44:51<113:18:01, 414.09s/it, lr=0.001, test_MAE=1.16, time=412, train_MAE=0.736, train_loss=0.803, val_MAE=1.12, val_loss=1.19]Epoch 15:   2%|▏         | 15/1000 [1:44:51<113:18:01, 414.09s/it, lr=0.001, test_MAE=1.16, time=412, train_MAE=0.736, train_loss=0.803, val_MAE=1.12, val_loss=1.19]Epoch 15:   2%|▏         | 15/1000 [1:51:46<113:18:01, 414.09s/it, lr=0.001, test_MAE=1.18, time=415, train_MAE=0.732, train_loss=0.8, val_MAE=1.14, val_loss=1.2]   Epoch 15:   2%|▏         | 16/1000 [1:51:46<113:16:41, 414.43s/it, lr=0.001, test_MAE=1.18, time=415, train_MAE=0.732, train_loss=0.8, val_MAE=1.14, val_loss=1.2]Epoch 16:   2%|▏         | 16/1000 [1:51:46<113:16:41, 414.43s/it, lr=0.001, test_MAE=1.18, time=415, train_MAE=0.732, train_loss=0.8, val_MAE=1.14, val_loss=1.2]Epoch 16:   2%|▏         | 16/1000 [1:58:36<113:16:41, 414.43s/it, lr=0.001, test_MAE=1.02, time=410, train_MAE=0.73, train_loss=0.799, val_MAE=0.977, val_loss=1.05]Epoch 16:   2%|▏         | 17/1000 [1:58:36<112:50:25, 413.25s/it, lr=0.001, test_MAE=1.02, time=410, train_MAE=0.73, train_loss=0.799, val_MAE=0.977, val_loss=1.05]Epoch 17:   2%|▏         | 17/1000 [1:58:36<112:50:25, 413.25s/it, lr=0.001, test_MAE=1.02, time=410, train_MAE=0.73, train_loss=0.799, val_MAE=0.977, val_loss=1.05]Epoch 17:   2%|▏         | 17/1000 [2:05:32<112:50:25, 413.25s/it, lr=0.001, test_MAE=1.12, time=416, train_MAE=0.713, train_loss=0.783, val_MAE=1.06, val_loss=1.13]Epoch 17:   2%|▏         | 18/1000 [2:05:32<112:56:34, 414.05s/it, lr=0.001, test_MAE=1.12, time=416, train_MAE=0.713, train_loss=0.783, val_MAE=1.06, val_loss=1.13]Epoch 18:   2%|▏         | 18/1000 [2:05:32<112:56:34, 414.05s/it, lr=0.001, test_MAE=1.12, time=416, train_MAE=0.713, train_loss=0.783, val_MAE=1.06, val_loss=1.13]Epoch 18:   2%|▏         | 18/1000 [2:12:23<112:56:34, 414.05s/it, lr=0.001, test_MAE=1, time=410, train_MAE=0.708, train_loss=0.778, val_MAE=0.976, val_loss=1.05]  Epoch 18:   2%|▏         | 19/1000 [2:12:23<112:32:16, 412.98s/it, lr=0.001, test_MAE=1, time=410, train_MAE=0.708, train_loss=0.778, val_MAE=0.976, val_loss=1.05]Epoch 19:   2%|▏         | 19/1000 [2:12:23<112:32:16, 412.98s/it, lr=0.001, test_MAE=1, time=410, train_MAE=0.708, train_loss=0.778, val_MAE=0.976, val_loss=1.05]Epoch 19:   2%|▏         | 19/1000 [2:19:17<112:32:16, 412.98s/it, lr=0.001, test_MAE=0.986, time=414, train_MAE=0.711, train_loss=0.782, val_MAE=0.948, val_loss=1.02]Epoch 19:   2%|▏         | 20/1000 [2:19:17<112:30:23, 413.29s/it, lr=0.001, test_MAE=0.986, time=414, train_MAE=0.711, train_loss=0.782, val_MAE=0.948, val_loss=1.02]Epoch 20:   2%|▏         | 20/1000 [2:19:17<112:30:23, 413.29s/it, lr=0.001, test_MAE=0.986, time=414, train_MAE=0.711, train_loss=0.782, val_MAE=0.948, val_loss=1.02]Epoch 20:   2%|▏         | 20/1000 [2:26:08<112:30:23, 413.29s/it, lr=0.001, test_MAE=1.01, time=411, train_MAE=0.716, train_loss=0.787, val_MAE=0.962, val_loss=1.03] Epoch 20:   2%|▏         | 21/1000 [2:26:08<112:14:36, 412.74s/it, lr=0.001, test_MAE=1.01, time=411, train_MAE=0.716, train_loss=0.787, val_MAE=0.962, val_loss=1.03]Epoch 21:   2%|▏         | 21/1000 [2:26:08<112:14:36, 412.74s/it, lr=0.001, test_MAE=1.01, time=411, train_MAE=0.716, train_loss=0.787, val_MAE=0.962, val_loss=1.03]Epoch 21:   2%|▏         | 21/1000 [2:32:56<112:14:36, 412.74s/it, lr=0.001, test_MAE=1.03, time=408, train_MAE=0.697, train_loss=0.769, val_MAE=0.997, val_loss=1.07]Epoch 21:   2%|▏         | 22/1000 [2:32:56<111:44:12, 411.30s/it, lr=0.001, test_MAE=1.03, time=408, train_MAE=0.697, train_loss=0.769, val_MAE=0.997, val_loss=1.07]Epoch 22:   2%|▏         | 22/1000 [2:32:56<111:44:12, 411.30s/it, lr=0.001, test_MAE=1.03, time=408, train_MAE=0.697, train_loss=0.769, val_MAE=0.997, val_loss=1.07]Epoch 22:   2%|▏         | 22/1000 [2:39:45<111:44:12, 411.30s/it, lr=0.001, test_MAE=0.895, time=409, train_MAE=0.69, train_loss=0.763, val_MAE=0.811, val_loss=0.884]Epoch 22:   2%|▏         | 23/1000 [2:39:45<111:24:26, 410.51s/it, lr=0.001, test_MAE=0.895, time=409, train_MAE=0.69, train_loss=0.763, val_MAE=0.811, val_loss=0.884]Epoch 23:   2%|▏         | 23/1000 [2:39:45<111:24:26, 410.51s/it, lr=0.001, test_MAE=0.895, time=409, train_MAE=0.69, train_loss=0.763, val_MAE=0.811, val_loss=0.884]Epoch 23:   2%|▏         | 23/1000 [2:46:35<111:24:26, 410.51s/it, lr=0.001, test_MAE=1.08, time=410, train_MAE=0.686, train_loss=0.759, val_MAE=1.05, val_loss=1.12]  Epoch 23:   2%|▏         | 24/1000 [2:46:35<111:13:42, 410.27s/it, lr=0.001, test_MAE=1.08, time=410, train_MAE=0.686, train_loss=0.759, val_MAE=1.05, val_loss=1.12]Epoch 24:   2%|▏         | 24/1000 [2:46:35<111:13:42, 410.27s/it, lr=0.001, test_MAE=1.08, time=410, train_MAE=0.686, train_loss=0.759, val_MAE=1.05, val_loss=1.12]Epoch 24:   2%|▏         | 24/1000 [2:53:22<111:13:42, 410.27s/it, lr=0.001, test_MAE=0.966, time=407, train_MAE=0.683, train_loss=0.756, val_MAE=0.91, val_loss=0.984]Epoch 24:   2%|▎         | 25/1000 [2:53:22<110:53:03, 409.42s/it, lr=0.001, test_MAE=0.966, time=407, train_MAE=0.683, train_loss=0.756, val_MAE=0.91, val_loss=0.984]Epoch 25:   2%|▎         | 25/1000 [2:53:22<110:53:03, 409.42s/it, lr=0.001, test_MAE=0.966, time=407, train_MAE=0.683, train_loss=0.756, val_MAE=0.91, val_loss=0.984]Epoch 25:   2%|▎         | 25/1000 [3:00:09<110:53:03, 409.42s/it, lr=0.001, test_MAE=0.962, time=407, train_MAE=0.684, train_loss=0.758, val_MAE=0.927, val_loss=1]   Epoch 25:   3%|▎         | 26/1000 [3:00:09<110:34:42, 408.71s/it, lr=0.001, test_MAE=0.962, time=407, train_MAE=0.684, train_loss=0.758, val_MAE=0.927, val_loss=1]Epoch 26:   3%|▎         | 26/1000 [3:00:09<110:34:42, 408.71s/it, lr=0.001, test_MAE=0.962, time=407, train_MAE=0.684, train_loss=0.758, val_MAE=0.927, val_loss=1]Epoch 26:   3%|▎         | 26/1000 [3:07:03<110:34:42, 408.71s/it, lr=0.001, test_MAE=1.08, time=413, train_MAE=0.686, train_loss=0.76, val_MAE=1.04, val_loss=1.11]Epoch 26:   3%|▎         | 27/1000 [3:07:03<110:51:05, 410.14s/it, lr=0.001, test_MAE=1.08, time=413, train_MAE=0.686, train_loss=0.76, val_MAE=1.04, val_loss=1.11]Epoch 27:   3%|▎         | 27/1000 [3:07:03<110:51:05, 410.14s/it, lr=0.001, test_MAE=1.08, time=413, train_MAE=0.686, train_loss=0.76, val_MAE=1.04, val_loss=1.11]Epoch 27:   3%|▎         | 27/1000 [3:13:52<110:51:05, 410.14s/it, lr=0.001, test_MAE=0.892, time=410, train_MAE=0.675, train_loss=0.75, val_MAE=0.844, val_loss=0.92]Epoch 27:   3%|▎         | 28/1000 [3:13:52<110:42:35, 410.04s/it, lr=0.001, test_MAE=0.892, time=410, train_MAE=0.675, train_loss=0.75, val_MAE=0.844, val_loss=0.92]Epoch 28:   3%|▎         | 28/1000 [3:13:52<110:42:35, 410.04s/it, lr=0.001, test_MAE=0.892, time=410, train_MAE=0.675, train_loss=0.75, val_MAE=0.844, val_loss=0.92]Epoch 28:   3%|▎         | 28/1000 [3:20:40<110:42:35, 410.04s/it, lr=0.001, test_MAE=0.837, time=408, train_MAE=0.671, train_loss=0.747, val_MAE=0.808, val_loss=0.884]Epoch    29: reducing learning rate of group 0 to 5.0000e-04.
Epoch 28:   3%|▎         | 29/1000 [3:20:40<110:24:47, 409.36s/it, lr=0.001, test_MAE=0.837, time=408, train_MAE=0.671, train_loss=0.747, val_MAE=0.808, val_loss=0.884]Epoch 29:   3%|▎         | 29/1000 [3:20:40<110:24:47, 409.36s/it, lr=0.001, test_MAE=0.837, time=408, train_MAE=0.671, train_loss=0.747, val_MAE=0.808, val_loss=0.884]Epoch 29:   3%|▎         | 29/1000 [3:27:26<110:24:47, 409.36s/it, lr=0.0005, test_MAE=1.04, time=406, train_MAE=0.669, train_loss=0.746, val_MAE=0.985, val_loss=1.06] Epoch 29:   3%|▎         | 30/1000 [3:27:26<110:00:56, 408.31s/it, lr=0.0005, test_MAE=1.04, time=406, train_MAE=0.669, train_loss=0.746, val_MAE=0.985, val_loss=1.06]Epoch 30:   3%|▎         | 30/1000 [3:27:26<110:00:56, 408.31s/it, lr=0.0005, test_MAE=1.04, time=406, train_MAE=0.669, train_loss=0.746, val_MAE=0.985, val_loss=1.06]Epoch 30:   3%|▎         | 30/1000 [3:34:14<110:00:56, 408.31s/it, lr=0.0005, test_MAE=0.855, time=408, train_MAE=0.652, train_loss=0.728, val_MAE=0.81, val_loss=0.886]Epoch 30:   3%|▎         | 31/1000 [3:34:14<109:54:18, 408.32s/it, lr=0.0005, test_MAE=0.855, time=408, train_MAE=0.652, train_loss=0.728, val_MAE=0.81, val_loss=0.886]Epoch 31:   3%|▎         | 31/1000 [3:34:14<109:54:18, 408.32s/it, lr=0.0005, test_MAE=0.855, time=408, train_MAE=0.652, train_loss=0.728, val_MAE=0.81, val_loss=0.886]Epoch 31:   3%|▎         | 31/1000 [3:41:00<109:54:18, 408.32s/it, lr=0.0005, test_MAE=0.91, time=406, train_MAE=0.648, train_loss=0.725, val_MAE=0.844, val_loss=0.921]Epoch 31:   3%|▎         | 32/1000 [3:41:00<109:34:53, 407.53s/it, lr=0.0005, test_MAE=0.91, time=406, train_MAE=0.648, train_loss=0.725, val_MAE=0.844, val_loss=0.921]Epoch 32:   3%|▎         | 32/1000 [3:41:00<109:34:53, 407.53s/it, lr=0.0005, test_MAE=0.91, time=406, train_MAE=0.648, train_loss=0.725, val_MAE=0.844, val_loss=0.921]Epoch 32:   3%|▎         | 32/1000 [3:47:55<109:34:53, 407.53s/it, lr=0.0005, test_MAE=1.29, time=415, train_MAE=0.663, train_loss=0.74, val_MAE=1.27, val_loss=1.34]   Epoch 32:   3%|▎         | 33/1000 [3:47:55<110:05:25, 409.85s/it, lr=0.0005, test_MAE=1.29, time=415, train_MAE=0.663, train_loss=0.74, val_MAE=1.27, val_loss=1.34]Epoch 33:   3%|▎         | 33/1000 [3:47:55<110:05:25, 409.85s/it, lr=0.0005, test_MAE=1.29, time=415, train_MAE=0.663, train_loss=0.74, val_MAE=1.27, val_loss=1.34]Epoch 33:   3%|▎         | 33/1000 [3:54:47<110:05:25, 409.85s/it, lr=0.0005, test_MAE=0.839, time=412, train_MAE=0.647, train_loss=0.723, val_MAE=0.805, val_loss=0.881]Epoch 33:   3%|▎         | 34/1000 [3:54:47<110:06:52, 410.36s/it, lr=0.0005, test_MAE=0.839, time=412, train_MAE=0.647, train_loss=0.723, val_MAE=0.805, val_loss=0.881]Epoch 34:   3%|▎         | 34/1000 [3:54:47<110:06:52, 410.36s/it, lr=0.0005, test_MAE=0.839, time=412, train_MAE=0.647, train_loss=0.723, val_MAE=0.805, val_loss=0.881]Epoch 34:   3%|▎         | 34/1000 [4:01:38<110:06:52, 410.36s/it, lr=0.0005, test_MAE=0.881, time=411, train_MAE=0.651, train_loss=0.727, val_MAE=0.836, val_loss=0.912]Epoch 34:   4%|▎         | 35/1000 [4:01:38<110:05:27, 410.70s/it, lr=0.0005, test_MAE=0.881, time=411, train_MAE=0.651, train_loss=0.727, val_MAE=0.836, val_loss=0.912]Epoch 35:   4%|▎         | 35/1000 [4:01:38<110:05:27, 410.70s/it, lr=0.0005, test_MAE=0.881, time=411, train_MAE=0.651, train_loss=0.727, val_MAE=0.836, val_loss=0.912]Epoch 35:   4%|▎         | 35/1000 [4:08:35<110:05:27, 410.70s/it, lr=0.0005, test_MAE=0.897, time=417, train_MAE=0.652, train_loss=0.729, val_MAE=0.833, val_loss=0.91] Epoch 35:   4%|▎         | 36/1000 [4:08:35<110:28:39, 412.57s/it, lr=0.0005, test_MAE=0.897, time=417, train_MAE=0.652, train_loss=0.729, val_MAE=0.833, val_loss=0.91]Epoch 36:   4%|▎         | 36/1000 [4:08:35<110:28:39, 412.57s/it, lr=0.0005, test_MAE=0.897, time=417, train_MAE=0.652, train_loss=0.729, val_MAE=0.833, val_loss=0.91]Epoch 36:   4%|▎         | 36/1000 [4:15:27<110:28:39, 412.57s/it, lr=0.0005, test_MAE=0.796, time=412, train_MAE=0.639, train_loss=0.716, val_MAE=0.748, val_loss=0.825]Epoch 36:   4%|▎         | 37/1000 [4:15:27<110:19:40, 412.44s/it, lr=0.0005, test_MAE=0.796, time=412, train_MAE=0.639, train_loss=0.716, val_MAE=0.748, val_loss=0.825]Epoch 37:   4%|▎         | 37/1000 [4:15:27<110:19:40, 412.44s/it, lr=0.0005, test_MAE=0.796, time=412, train_MAE=0.639, train_loss=0.716, val_MAE=0.748, val_loss=0.825]Epoch 37:   4%|▎         | 37/1000 [4:22:21<110:19:40, 412.44s/it, lr=0.0005, test_MAE=0.77, time=413, train_MAE=0.647, train_loss=0.724, val_MAE=0.72, val_loss=0.797]  Epoch 37:   4%|▍         | 38/1000 [4:22:21<110:17:46, 412.75s/it, lr=0.0005, test_MAE=0.77, time=413, train_MAE=0.647, train_loss=0.724, val_MAE=0.72, val_loss=0.797]Epoch 38:   4%|▍         | 38/1000 [4:22:21<110:17:46, 412.75s/it, lr=0.0005, test_MAE=0.77, time=413, train_MAE=0.647, train_loss=0.724, val_MAE=0.72, val_loss=0.797]Epoch 38:   4%|▍         | 38/1000 [4:29:05<110:17:46, 412.75s/it, lr=0.0005, test_MAE=0.739, time=404, train_MAE=0.639, train_loss=0.716, val_MAE=0.69, val_loss=0.767]Epoch 38:   4%|▍         | 39/1000 [4:29:05<109:30:37, 410.24s/it, lr=0.0005, test_MAE=0.739, time=404, train_MAE=0.639, train_loss=0.716, val_MAE=0.69, val_loss=0.767]Epoch 39:   4%|▍         | 39/1000 [4:29:05<109:30:37, 410.24s/it, lr=0.0005, test_MAE=0.739, time=404, train_MAE=0.639, train_loss=0.716, val_MAE=0.69, val_loss=0.767]Epoch 39:   4%|▍         | 39/1000 [4:35:51<109:30:37, 410.24s/it, lr=0.0005, test_MAE=0.86, time=406, train_MAE=0.64, train_loss=0.717, val_MAE=0.83, val_loss=0.907]  Epoch 39:   4%|▍         | 40/1000 [4:35:51<109:02:09, 408.88s/it, lr=0.0005, test_MAE=0.86, time=406, train_MAE=0.64, train_loss=0.717, val_MAE=0.83, val_loss=0.907]Epoch 40:   4%|▍         | 40/1000 [4:35:51<109:02:09, 408.88s/it, lr=0.0005, test_MAE=0.86, time=406, train_MAE=0.64, train_loss=0.717, val_MAE=0.83, val_loss=0.907]Epoch 40:   4%|▍         | 40/1000 [4:42:40<109:02:09, 408.88s/it, lr=0.0005, test_MAE=0.84, time=409, train_MAE=0.649, train_loss=0.726, val_MAE=0.806, val_loss=0.883]Epoch 40:   4%|▍         | 41/1000 [4:42:40<108:56:27, 408.95s/it, lr=0.0005, test_MAE=0.84, time=409, train_MAE=0.649, train_loss=0.726, val_MAE=0.806, val_loss=0.883]Epoch 41:   4%|▍         | 41/1000 [4:42:40<108:56:27, 408.95s/it, lr=0.0005, test_MAE=0.84, time=409, train_MAE=0.649, train_loss=0.726, val_MAE=0.806, val_loss=0.883]Epoch 41:   4%|▍         | 41/1000 [4:49:28<108:56:27, 408.95s/it, lr=0.0005, test_MAE=0.776, time=408, train_MAE=0.641, train_loss=0.719, val_MAE=0.715, val_loss=0.793]Epoch 41:   4%|▍         | 42/1000 [4:49:28<108:44:20, 408.62s/it, lr=0.0005, test_MAE=0.776, time=408, train_MAE=0.641, train_loss=0.719, val_MAE=0.715, val_loss=0.793]Epoch 42:   4%|▍         | 42/1000 [4:49:28<108:44:20, 408.62s/it, lr=0.0005, test_MAE=0.776, time=408, train_MAE=0.641, train_loss=0.719, val_MAE=0.715, val_loss=0.793]Epoch 42:   4%|▍         | 42/1000 [4:56:17<108:44:20, 408.62s/it, lr=0.0005, test_MAE=0.869, time=409, train_MAE=0.635, train_loss=0.713, val_MAE=0.823, val_loss=0.901]Epoch 42:   4%|▍         | 43/1000 [4:56:17<108:39:32, 408.75s/it, lr=0.0005, test_MAE=0.869, time=409, train_MAE=0.635, train_loss=0.713, val_MAE=0.823, val_loss=0.901]Epoch 43:   4%|▍         | 43/1000 [4:56:17<108:39:32, 408.75s/it, lr=0.0005, test_MAE=0.869, time=409, train_MAE=0.635, train_loss=0.713, val_MAE=0.823, val_loss=0.901]Epoch 43:   4%|▍         | 43/1000 [5:03:02<108:39:32, 408.75s/it, lr=0.0005, test_MAE=0.86, time=405, train_MAE=0.636, train_loss=0.714, val_MAE=0.827, val_loss=0.905] Epoch 43:   4%|▍         | 44/1000 [5:03:02<108:14:48, 407.62s/it, lr=0.0005, test_MAE=0.86, time=405, train_MAE=0.636, train_loss=0.714, val_MAE=0.827, val_loss=0.905]Epoch 44:   4%|▍         | 44/1000 [5:03:02<108:14:48, 407.62s/it, lr=0.0005, test_MAE=0.86, time=405, train_MAE=0.636, train_loss=0.714, val_MAE=0.827, val_loss=0.905]Epoch 44:   4%|▍         | 44/1000 [5:09:48<108:14:48, 407.62s/it, lr=0.0005, test_MAE=0.836, time=406, train_MAE=0.635, train_loss=0.712, val_MAE=0.802, val_loss=0.88]Epoch    45: reducing learning rate of group 0 to 2.5000e-04.
Epoch 44:   4%|▍         | 45/1000 [5:09:48<108:01:36, 407.22s/it, lr=0.0005, test_MAE=0.836, time=406, train_MAE=0.635, train_loss=0.712, val_MAE=0.802, val_loss=0.88]Epoch 45:   4%|▍         | 45/1000 [5:09:48<108:01:36, 407.22s/it, lr=0.0005, test_MAE=0.836, time=406, train_MAE=0.635, train_loss=0.712, val_MAE=0.802, val_loss=0.88]Epoch 45:   4%|▍         | 45/1000 [5:16:37<108:01:36, 407.22s/it, lr=0.00025, test_MAE=0.8, time=409, train_MAE=0.638, train_loss=0.715, val_MAE=0.763, val_loss=0.84] Epoch 45:   5%|▍         | 46/1000 [5:16:37<108:01:16, 407.63s/it, lr=0.00025, test_MAE=0.8, time=409, train_MAE=0.638, train_loss=0.715, val_MAE=0.763, val_loss=0.84]Epoch 46:   5%|▍         | 46/1000 [5:16:37<108:01:16, 407.63s/it, lr=0.00025, test_MAE=0.8, time=409, train_MAE=0.638, train_loss=0.715, val_MAE=0.763, val_loss=0.84]Epoch 46:   5%|▍         | 46/1000 [5:23:23<108:01:16, 407.63s/it, lr=0.00025, test_MAE=0.816, time=406, train_MAE=0.626, train_loss=0.704, val_MAE=0.843, val_loss=0.921]Epoch 46:   5%|▍         | 47/1000 [5:23:23<107:47:16, 407.17s/it, lr=0.00025, test_MAE=0.816, time=406, train_MAE=0.626, train_loss=0.704, val_MAE=0.843, val_loss=0.921]Epoch 47:   5%|▍         | 47/1000 [5:23:23<107:47:16, 407.17s/it, lr=0.00025, test_MAE=0.816, time=406, train_MAE=0.626, train_loss=0.704, val_MAE=0.843, val_loss=0.921]Epoch 47:   5%|▍         | 47/1000 [5:30:14<107:47:16, 407.17s/it, lr=0.00025, test_MAE=0.805, time=411, train_MAE=0.617, train_loss=0.695, val_MAE=0.777, val_loss=0.855]Epoch 47:   5%|▍         | 48/1000 [5:30:14<107:59:23, 408.37s/it, lr=0.00025, test_MAE=0.805, time=411, train_MAE=0.617, train_loss=0.695, val_MAE=0.777, val_loss=0.855]Epoch 48:   5%|▍         | 48/1000 [5:30:14<107:59:23, 408.37s/it, lr=0.00025, test_MAE=0.805, time=411, train_MAE=0.617, train_loss=0.695, val_MAE=0.777, val_loss=0.855]Epoch 48:   5%|▍         | 48/1000 [5:36:59<107:59:23, 408.37s/it, lr=0.00025, test_MAE=0.761, time=405, train_MAE=0.62, train_loss=0.698, val_MAE=0.737, val_loss=0.815] Epoch 48:   5%|▍         | 49/1000 [5:36:59<107:35:59, 407.32s/it, lr=0.00025, test_MAE=0.761, time=405, train_MAE=0.62, train_loss=0.698, val_MAE=0.737, val_loss=0.815]Epoch 49:   5%|▍         | 49/1000 [5:36:59<107:35:59, 407.32s/it, lr=0.00025, test_MAE=0.761, time=405, train_MAE=0.62, train_loss=0.698, val_MAE=0.737, val_loss=0.815]Epoch 49:   5%|▍         | 49/1000 [5:43:48<107:35:59, 407.32s/it, lr=0.00025, test_MAE=0.792, time=409, train_MAE=0.617, train_loss=0.695, val_MAE=0.754, val_loss=0.832]Epoch 49:   5%|▌         | 50/1000 [5:43:49<107:39:17, 407.96s/it, lr=0.00025, test_MAE=0.792, time=409, train_MAE=0.617, train_loss=0.695, val_MAE=0.754, val_loss=0.832]Epoch 50:   5%|▌         | 50/1000 [5:43:49<107:39:17, 407.96s/it, lr=0.00025, test_MAE=0.792, time=409, train_MAE=0.617, train_loss=0.695, val_MAE=0.754, val_loss=0.832]Epoch 50:   5%|▌         | 50/1000 [5:50:34<107:39:17, 407.96s/it, lr=0.00025, test_MAE=0.753, time=405, train_MAE=0.616, train_loss=0.694, val_MAE=0.709, val_loss=0.787]Epoch    51: reducing learning rate of group 0 to 1.2500e-04.
Epoch 50:   5%|▌         | 51/1000 [5:50:34<107:19:21, 407.12s/it, lr=0.00025, test_MAE=0.753, time=405, train_MAE=0.616, train_loss=0.694, val_MAE=0.709, val_loss=0.787]Epoch 51:   5%|▌         | 51/1000 [5:50:34<107:19:21, 407.12s/it, lr=0.00025, test_MAE=0.753, time=405, train_MAE=0.616, train_loss=0.694, val_MAE=0.709, val_loss=0.787]Epoch 51:   5%|▌         | 51/1000 [5:57:20<107:19:21, 407.12s/it, lr=0.000125, test_MAE=0.8, time=407, train_MAE=0.607, train_loss=0.685, val_MAE=0.761, val_loss=0.839] Epoch 51:   5%|▌         | 52/1000 [5:57:20<107:09:52, 406.95s/it, lr=0.000125, test_MAE=0.8, time=407, train_MAE=0.607, train_loss=0.685, val_MAE=0.761, val_loss=0.839]Epoch 52:   5%|▌         | 52/1000 [5:57:20<107:09:52, 406.95s/it, lr=0.000125, test_MAE=0.8, time=407, train_MAE=0.607, train_loss=0.685, val_MAE=0.761, val_loss=0.839]Epoch 52:   5%|▌         | 52/1000 [6:04:08<107:09:52, 406.95s/it, lr=0.000125, test_MAE=0.788, time=407, train_MAE=0.614, train_loss=0.692, val_MAE=0.753, val_loss=0.831]Epoch 52:   5%|▌         | 53/1000 [6:04:08<107:05:42, 407.12s/it, lr=0.000125, test_MAE=0.788, time=407, train_MAE=0.614, train_loss=0.692, val_MAE=0.753, val_loss=0.831]Epoch 53:   5%|▌         | 53/1000 [6:04:08<107:05:42, 407.12s/it, lr=0.000125, test_MAE=0.788, time=407, train_MAE=0.614, train_loss=0.692, val_MAE=0.753, val_loss=0.831]Epoch 53:   5%|▌         | 53/1000 [6:10:52<107:05:42, 407.12s/it, lr=0.000125, test_MAE=0.78, time=404, train_MAE=0.612, train_loss=0.69, val_MAE=0.721, val_loss=0.799]  Epoch 53:   5%|▌         | 54/1000 [6:10:52<106:44:52, 406.23s/it, lr=0.000125, test_MAE=0.78, time=404, train_MAE=0.612, train_loss=0.69, val_MAE=0.721, val_loss=0.799]Epoch 54:   5%|▌         | 54/1000 [6:10:52<106:44:52, 406.23s/it, lr=0.000125, test_MAE=0.78, time=404, train_MAE=0.612, train_loss=0.69, val_MAE=0.721, val_loss=0.799]Epoch 54:   5%|▌         | 54/1000 [6:17:41<106:44:52, 406.23s/it, lr=0.000125, test_MAE=0.77, time=409, train_MAE=0.611, train_loss=0.689, val_MAE=0.725, val_loss=0.803]Epoch 54:   6%|▌         | 55/1000 [6:17:41<106:52:37, 407.15s/it, lr=0.000125, test_MAE=0.77, time=409, train_MAE=0.611, train_loss=0.689, val_MAE=0.725, val_loss=0.803]Epoch 55:   6%|▌         | 55/1000 [6:17:41<106:52:37, 407.15s/it, lr=0.000125, test_MAE=0.77, time=409, train_MAE=0.611, train_loss=0.689, val_MAE=0.725, val_loss=0.803]Epoch 55:   6%|▌         | 55/1000 [6:24:27<106:52:37, 407.15s/it, lr=0.000125, test_MAE=0.787, time=405, train_MAE=0.621, train_loss=0.699, val_MAE=0.758, val_loss=0.836]Epoch 55:   6%|▌         | 56/1000 [6:24:27<106:37:47, 406.64s/it, lr=0.000125, test_MAE=0.787, time=405, train_MAE=0.621, train_loss=0.699, val_MAE=0.758, val_loss=0.836]Epoch 56:   6%|▌         | 56/1000 [6:24:27<106:37:47, 406.64s/it, lr=0.000125, test_MAE=0.787, time=405, train_MAE=0.621, train_loss=0.699, val_MAE=0.758, val_loss=0.836]Epoch 56:   6%|▌         | 56/1000 [6:31:10<106:37:47, 406.64s/it, lr=0.000125, test_MAE=0.738, time=403, train_MAE=0.61, train_loss=0.688, val_MAE=0.721, val_loss=0.799] Epoch    57: reducing learning rate of group 0 to 6.2500e-05.
Epoch 56:   6%|▌         | 57/1000 [6:31:10<106:16:08, 405.69s/it, lr=0.000125, test_MAE=0.738, time=403, train_MAE=0.61, train_loss=0.688, val_MAE=0.721, val_loss=0.799]Epoch 57:   6%|▌         | 57/1000 [6:31:10<106:16:08, 405.69s/it, lr=0.000125, test_MAE=0.738, time=403, train_MAE=0.61, train_loss=0.688, val_MAE=0.721, val_loss=0.799]Epoch 57:   6%|▌         | 57/1000 [6:37:58<106:16:08, 405.69s/it, lr=6.25e-5, test_MAE=0.72, time=408, train_MAE=0.605, train_loss=0.683, val_MAE=0.721, val_loss=0.799] Epoch 57:   6%|▌         | 58/1000 [6:37:58<106:19:29, 406.34s/it, lr=6.25e-5, test_MAE=0.72, time=408, train_MAE=0.605, train_loss=0.683, val_MAE=0.721, val_loss=0.799]Epoch 58:   6%|▌         | 58/1000 [6:37:58<106:19:29, 406.34s/it, lr=6.25e-5, test_MAE=0.72, time=408, train_MAE=0.605, train_loss=0.683, val_MAE=0.721, val_loss=0.799]Epoch 58:   6%|▌         | 58/1000 [6:44:43<106:19:29, 406.34s/it, lr=6.25e-5, test_MAE=0.742, time=406, train_MAE=0.603, train_loss=0.68, val_MAE=0.75, val_loss=0.827] Epoch 58:   6%|▌         | 59/1000 [6:44:44<106:08:56, 406.10s/it, lr=6.25e-5, test_MAE=0.742, time=406, train_MAE=0.603, train_loss=0.68, val_MAE=0.75, val_loss=0.827]Epoch 59:   6%|▌         | 59/1000 [6:44:44<106:08:56, 406.10s/it, lr=6.25e-5, test_MAE=0.742, time=406, train_MAE=0.603, train_loss=0.68, val_MAE=0.75, val_loss=0.827]Epoch 59:   6%|▌         | 59/1000 [6:51:33<106:08:56, 406.10s/it, lr=6.25e-5, test_MAE=0.747, time=409, train_MAE=0.603, train_loss=0.681, val_MAE=0.733, val_loss=0.811]Epoch 59:   6%|▌         | 60/1000 [6:51:33<106:16:38, 407.02s/it, lr=6.25e-5, test_MAE=0.747, time=409, train_MAE=0.603, train_loss=0.681, val_MAE=0.733, val_loss=0.811]Epoch 60:   6%|▌         | 60/1000 [6:51:33<106:16:38, 407.02s/it, lr=6.25e-5, test_MAE=0.747, time=409, train_MAE=0.603, train_loss=0.681, val_MAE=0.733, val_loss=0.811]Epoch 60:   6%|▌         | 60/1000 [6:58:15<106:16:38, 407.02s/it, lr=6.25e-5, test_MAE=0.751, time=402, train_MAE=0.609, train_loss=0.687, val_MAE=0.735, val_loss=0.812]Epoch 60:   6%|▌         | 61/1000 [6:58:15<105:47:11, 405.57s/it, lr=6.25e-5, test_MAE=0.751, time=402, train_MAE=0.609, train_loss=0.687, val_MAE=0.735, val_loss=0.812]Epoch 61:   6%|▌         | 61/1000 [6:58:15<105:47:11, 405.57s/it, lr=6.25e-5, test_MAE=0.751, time=402, train_MAE=0.609, train_loss=0.687, val_MAE=0.735, val_loss=0.812]Epoch 61:   6%|▌         | 61/1000 [7:05:01<105:47:11, 405.57s/it, lr=6.25e-5, test_MAE=1.38, time=406, train_MAE=0.603, train_loss=0.681, val_MAE=1.35, val_loss=1.42]   Epoch 61:   6%|▌         | 62/1000 [7:05:01<105:42:00, 405.67s/it, lr=6.25e-5, test_MAE=1.38, time=406, train_MAE=0.603, train_loss=0.681, val_MAE=1.35, val_loss=1.42]Epoch 62:   6%|▌         | 62/1000 [7:05:01<105:42:00, 405.67s/it, lr=6.25e-5, test_MAE=1.38, time=406, train_MAE=0.603, train_loss=0.681, val_MAE=1.35, val_loss=1.42]Epoch 62:   6%|▌         | 62/1000 [7:11:42<105:42:00, 405.67s/it, lr=6.25e-5, test_MAE=0.708, time=401, train_MAE=0.603, train_loss=0.681, val_MAE=0.727, val_loss=0.805]Epoch    63: reducing learning rate of group 0 to 3.1250e-05.
Epoch 62:   6%|▋         | 63/1000 [7:11:42<105:14:00, 404.31s/it, lr=6.25e-5, test_MAE=0.708, time=401, train_MAE=0.603, train_loss=0.681, val_MAE=0.727, val_loss=0.805]Epoch 63:   6%|▋         | 63/1000 [7:11:42<105:14:00, 404.31s/it, lr=6.25e-5, test_MAE=0.708, time=401, train_MAE=0.603, train_loss=0.681, val_MAE=0.727, val_loss=0.805]Epoch 63:   6%|▋         | 63/1000 [7:18:31<105:14:00, 404.31s/it, lr=3.13e-5, test_MAE=0.728, time=409, train_MAE=0.599, train_loss=0.677, val_MAE=0.691, val_loss=0.768]Epoch 63:   6%|▋         | 64/1000 [7:18:31<105:27:22, 405.60s/it, lr=3.13e-5, test_MAE=0.728, time=409, train_MAE=0.599, train_loss=0.677, val_MAE=0.691, val_loss=0.768]Epoch 64:   6%|▋         | 64/1000 [7:18:31<105:27:22, 405.60s/it, lr=3.13e-5, test_MAE=0.728, time=409, train_MAE=0.599, train_loss=0.677, val_MAE=0.691, val_loss=0.768]Epoch 64:   6%|▋         | 64/1000 [7:25:13<105:27:22, 405.60s/it, lr=3.13e-5, test_MAE=0.695, time=403, train_MAE=0.598, train_loss=0.676, val_MAE=1.12, val_loss=1.2]   Epoch 64:   6%|▋         | 65/1000 [7:25:13<105:06:59, 404.73s/it, lr=3.13e-5, test_MAE=0.695, time=403, train_MAE=0.598, train_loss=0.676, val_MAE=1.12, val_loss=1.2]Epoch 65:   6%|▋         | 65/1000 [7:25:13<105:06:59, 404.73s/it, lr=3.13e-5, test_MAE=0.695, time=403, train_MAE=0.598, train_loss=0.676, val_MAE=1.12, val_loss=1.2]Epoch 65:   6%|▋         | 65/1000 [7:32:00<105:06:59, 404.73s/it, lr=3.13e-5, test_MAE=0.695, time=407, train_MAE=0.591, train_loss=0.669, val_MAE=0.663, val_loss=0.741]Epoch 65:   7%|▋         | 66/1000 [7:32:00<105:08:59, 405.29s/it, lr=3.13e-5, test_MAE=0.695, time=407, train_MAE=0.591, train_loss=0.669, val_MAE=0.663, val_loss=0.741]Epoch 66:   7%|▋         | 66/1000 [7:32:00<105:08:59, 405.29s/it, lr=3.13e-5, test_MAE=0.695, time=407, train_MAE=0.591, train_loss=0.669, val_MAE=0.663, val_loss=0.741]Epoch 66:   7%|▋         | 66/1000 [7:38:42<105:08:59, 405.29s/it, lr=3.13e-5, test_MAE=0.704, time=402, train_MAE=0.598, train_loss=0.676, val_MAE=0.691, val_loss=0.769]Epoch 66:   7%|▋         | 67/1000 [7:38:42<104:47:37, 404.35s/it, lr=3.13e-5, test_MAE=0.704, time=402, train_MAE=0.598, train_loss=0.676, val_MAE=0.691, val_loss=0.769]Epoch 67:   7%|▋         | 67/1000 [7:38:42<104:47:37, 404.35s/it, lr=3.13e-5, test_MAE=0.704, time=402, train_MAE=0.598, train_loss=0.676, val_MAE=0.691, val_loss=0.769]Epoch 67:   7%|▋         | 67/1000 [7:45:30<104:47:37, 404.35s/it, lr=3.13e-5, test_MAE=0.692, time=408, train_MAE=0.613, train_loss=0.691, val_MAE=0.672, val_loss=0.749]Epoch 67:   7%|▋         | 68/1000 [7:45:30<104:56:41, 405.37s/it, lr=3.13e-5, test_MAE=0.692, time=408, train_MAE=0.613, train_loss=0.691, val_MAE=0.672, val_loss=0.749]Epoch 68:   7%|▋         | 68/1000 [7:45:30<104:56:41, 405.37s/it, lr=3.13e-5, test_MAE=0.692, time=408, train_MAE=0.613, train_loss=0.691, val_MAE=0.672, val_loss=0.749]Epoch 68:   7%|▋         | 68/1000 [7:52:16<104:56:41, 405.37s/it, lr=3.13e-5, test_MAE=0.739, time=407, train_MAE=0.595, train_loss=0.673, val_MAE=0.707, val_loss=0.785]Epoch 68:   7%|▋         | 69/1000 [7:52:16<104:56:01, 405.76s/it, lr=3.13e-5, test_MAE=0.739, time=407, train_MAE=0.595, train_loss=0.673, val_MAE=0.707, val_loss=0.785]Epoch 69:   7%|▋         | 69/1000 [7:52:16<104:56:01, 405.76s/it, lr=3.13e-5, test_MAE=0.739, time=407, train_MAE=0.595, train_loss=0.673, val_MAE=0.707, val_loss=0.785]Epoch 69:   7%|▋         | 69/1000 [7:59:02<104:56:01, 405.76s/it, lr=3.13e-5, test_MAE=0.7, time=406, train_MAE=0.602, train_loss=0.679, val_MAE=0.698, val_loss=0.776]  Epoch 69:   7%|▋         | 70/1000 [7:59:02<104:48:20, 405.70s/it, lr=3.13e-5, test_MAE=0.7, time=406, train_MAE=0.602, train_loss=0.679, val_MAE=0.698, val_loss=0.776]Epoch 70:   7%|▋         | 70/1000 [7:59:02<104:48:20, 405.70s/it, lr=3.13e-5, test_MAE=0.7, time=406, train_MAE=0.602, train_loss=0.679, val_MAE=0.698, val_loss=0.776]Epoch 70:   7%|▋         | 70/1000 [8:05:52<104:48:20, 405.70s/it, lr=3.13e-5, test_MAE=0.691, time=410, train_MAE=0.6, train_loss=0.678, val_MAE=0.659, val_loss=0.737]Epoch 70:   7%|▋         | 71/1000 [8:05:52<104:59:52, 406.88s/it, lr=3.13e-5, test_MAE=0.691, time=410, train_MAE=0.6, train_loss=0.678, val_MAE=0.659, val_loss=0.737]Epoch 71:   7%|▋         | 71/1000 [8:05:52<104:59:52, 406.88s/it, lr=3.13e-5, test_MAE=0.691, time=410, train_MAE=0.6, train_loss=0.678, val_MAE=0.659, val_loss=0.737]Epoch 71:   7%|▋         | 71/1000 [8:12:35<104:59:52, 406.88s/it, lr=3.13e-5, test_MAE=0.753, time=403, train_MAE=0.59, train_loss=0.668, val_MAE=0.714, val_loss=0.792]Epoch 71:   7%|▋         | 72/1000 [8:12:35<104:36:13, 405.79s/it, lr=3.13e-5, test_MAE=0.753, time=403, train_MAE=0.59, train_loss=0.668, val_MAE=0.714, val_loss=0.792]Epoch 72:   7%|▋         | 72/1000 [8:12:35<104:36:13, 405.79s/it, lr=3.13e-5, test_MAE=0.753, time=403, train_MAE=0.59, train_loss=0.668, val_MAE=0.714, val_loss=0.792]Epoch 72:   7%|▋         | 72/1000 [8:19:25<104:36:13, 405.79s/it, lr=3.13e-5, test_MAE=0.699, time=410, train_MAE=0.601, train_loss=0.679, val_MAE=0.671, val_loss=0.749]Epoch 72:   7%|▋         | 73/1000 [8:19:25<104:48:29, 407.02s/it, lr=3.13e-5, test_MAE=0.699, time=410, train_MAE=0.601, train_loss=0.679, val_MAE=0.671, val_loss=0.749]Epoch 73:   7%|▋         | 73/1000 [8:19:25<104:48:29, 407.02s/it, lr=3.13e-5, test_MAE=0.699, time=410, train_MAE=0.601, train_loss=0.679, val_MAE=0.671, val_loss=0.749]Epoch 73:   7%|▋         | 73/1000 [8:26:11<104:48:29, 407.02s/it, lr=3.13e-5, test_MAE=0.702, time=406, train_MAE=0.596, train_loss=0.674, val_MAE=0.674, val_loss=0.752]Epoch 73:   7%|▋         | 74/1000 [8:26:11<104:36:00, 406.65s/it, lr=3.13e-5, test_MAE=0.702, time=406, train_MAE=0.596, train_loss=0.674, val_MAE=0.674, val_loss=0.752]Epoch 74:   7%|▋         | 74/1000 [8:26:11<104:36:00, 406.65s/it, lr=3.13e-5, test_MAE=0.702, time=406, train_MAE=0.596, train_loss=0.674, val_MAE=0.674, val_loss=0.752]Epoch 74:   7%|▋         | 74/1000 [8:32:56<104:36:00, 406.65s/it, lr=3.13e-5, test_MAE=0.679, time=406, train_MAE=0.597, train_loss=0.675, val_MAE=0.653, val_loss=0.731]Epoch 74:   8%|▊         | 75/1000 [8:32:56<104:25:01, 406.38s/it, lr=3.13e-5, test_MAE=0.679, time=406, train_MAE=0.597, train_loss=0.675, val_MAE=0.653, val_loss=0.731]Epoch 75:   8%|▊         | 75/1000 [8:32:56<104:25:01, 406.38s/it, lr=3.13e-5, test_MAE=0.679, time=406, train_MAE=0.597, train_loss=0.675, val_MAE=0.653, val_loss=0.731]Epoch 75:   8%|▊         | 75/1000 [8:39:45<104:25:01, 406.38s/it, lr=3.13e-5, test_MAE=0.702, time=409, train_MAE=0.591, train_loss=0.668, val_MAE=0.669, val_loss=0.747]Epoch 75:   8%|▊         | 76/1000 [8:39:45<104:28:31, 407.05s/it, lr=3.13e-5, test_MAE=0.702, time=409, train_MAE=0.591, train_loss=0.668, val_MAE=0.669, val_loss=0.747]Epoch 76:   8%|▊         | 76/1000 [8:39:45<104:28:31, 407.05s/it, lr=3.13e-5, test_MAE=0.702, time=409, train_MAE=0.591, train_loss=0.668, val_MAE=0.669, val_loss=0.747]Epoch 76:   8%|▊         | 76/1000 [8:46:27<104:28:31, 407.05s/it, lr=3.13e-5, test_MAE=0.692, time=402, train_MAE=0.598, train_loss=0.676, val_MAE=0.666, val_loss=0.744]Epoch 76:   8%|▊         | 77/1000 [8:46:27<104:00:07, 405.64s/it, lr=3.13e-5, test_MAE=0.692, time=402, train_MAE=0.598, train_loss=0.676, val_MAE=0.666, val_loss=0.744]Epoch 77:   8%|▊         | 77/1000 [8:46:27<104:00:07, 405.64s/it, lr=3.13e-5, test_MAE=0.692, time=402, train_MAE=0.598, train_loss=0.676, val_MAE=0.666, val_loss=0.744]Epoch 77:   8%|▊         | 77/1000 [8:53:10<104:00:07, 405.64s/it, lr=3.13e-5, test_MAE=0.69, time=403, train_MAE=0.585, train_loss=0.663, val_MAE=0.652, val_loss=0.73]  Epoch 77:   8%|▊         | 78/1000 [8:53:10<103:41:37, 404.88s/it, lr=3.13e-5, test_MAE=0.69, time=403, train_MAE=0.585, train_loss=0.663, val_MAE=0.652, val_loss=0.73]Epoch 78:   8%|▊         | 78/1000 [8:53:10<103:41:37, 404.88s/it, lr=3.13e-5, test_MAE=0.69, time=403, train_MAE=0.585, train_loss=0.663, val_MAE=0.652, val_loss=0.73]Epoch 78:   8%|▊         | 78/1000 [8:59:53<103:41:37, 404.88s/it, lr=3.13e-5, test_MAE=0.694, time=403, train_MAE=0.6, train_loss=0.678, val_MAE=0.631, val_loss=0.708]Epoch 78:   8%|▊         | 79/1000 [8:59:53<103:26:38, 404.34s/it, lr=3.13e-5, test_MAE=0.694, time=403, train_MAE=0.6, train_loss=0.678, val_MAE=0.631, val_loss=0.708]Epoch 79:   8%|▊         | 79/1000 [8:59:53<103:26:38, 404.34s/it, lr=3.13e-5, test_MAE=0.694, time=403, train_MAE=0.6, train_loss=0.678, val_MAE=0.631, val_loss=0.708]Epoch 79:   8%|▊         | 79/1000 [9:06:37<103:26:38, 404.34s/it, lr=3.13e-5, test_MAE=0.709, time=403, train_MAE=0.599, train_loss=0.677, val_MAE=0.672, val_loss=0.749]Epoch 79:   8%|▊         | 80/1000 [9:06:37<103:14:18, 403.98s/it, lr=3.13e-5, test_MAE=0.709, time=403, train_MAE=0.599, train_loss=0.677, val_MAE=0.672, val_loss=0.749]Epoch 80:   8%|▊         | 80/1000 [9:06:37<103:14:18, 403.98s/it, lr=3.13e-5, test_MAE=0.709, time=403, train_MAE=0.599, train_loss=0.677, val_MAE=0.672, val_loss=0.749]Epoch 80:   8%|▊         | 80/1000 [9:13:19<103:14:18, 403.98s/it, lr=3.13e-5, test_MAE=0.696, time=403, train_MAE=0.598, train_loss=0.676, val_MAE=0.666, val_loss=0.743]Epoch 80:   8%|▊         | 81/1000 [9:13:19<103:01:12, 403.56s/it, lr=3.13e-5, test_MAE=0.696, time=403, train_MAE=0.598, train_loss=0.676, val_MAE=0.666, val_loss=0.743]Epoch 81:   8%|▊         | 81/1000 [9:13:19<103:01:12, 403.56s/it, lr=3.13e-5, test_MAE=0.696, time=403, train_MAE=0.598, train_loss=0.676, val_MAE=0.666, val_loss=0.743]Epoch 81:   8%|▊         | 81/1000 [9:20:02<103:01:12, 403.56s/it, lr=3.13e-5, test_MAE=0.692, time=403, train_MAE=0.595, train_loss=0.673, val_MAE=0.634, val_loss=0.712]Epoch 81:   8%|▊         | 82/1000 [9:20:02<102:50:54, 403.33s/it, lr=3.13e-5, test_MAE=0.692, time=403, train_MAE=0.595, train_loss=0.673, val_MAE=0.634, val_loss=0.712]Epoch 82:   8%|▊         | 82/1000 [9:20:02<102:50:54, 403.33s/it, lr=3.13e-5, test_MAE=0.692, time=403, train_MAE=0.595, train_loss=0.673, val_MAE=0.634, val_loss=0.712]Epoch 82:   8%|▊         | 82/1000 [9:26:45<102:50:54, 403.33s/it, lr=3.13e-5, test_MAE=0.684, time=404, train_MAE=0.595, train_loss=0.673, val_MAE=0.641, val_loss=0.719]Epoch 82:   8%|▊         | 83/1000 [9:26:45<102:45:10, 403.39s/it, lr=3.13e-5, test_MAE=0.684, time=404, train_MAE=0.595, train_loss=0.673, val_MAE=0.641, val_loss=0.719]Epoch 83:   8%|▊         | 83/1000 [9:26:45<102:45:10, 403.39s/it, lr=3.13e-5, test_MAE=0.684, time=404, train_MAE=0.595, train_loss=0.673, val_MAE=0.641, val_loss=0.719]Epoch 83:   8%|▊         | 83/1000 [9:33:29<102:45:10, 403.39s/it, lr=3.13e-5, test_MAE=0.685, time=404, train_MAE=0.592, train_loss=0.669, val_MAE=0.647, val_loss=0.725]Epoch 83:   8%|▊         | 84/1000 [9:33:29<102:40:06, 403.50s/it, lr=3.13e-5, test_MAE=0.685, time=404, train_MAE=0.592, train_loss=0.669, val_MAE=0.647, val_loss=0.725]Epoch 84:   8%|▊         | 84/1000 [9:33:29<102:40:06, 403.50s/it, lr=3.13e-5, test_MAE=0.685, time=404, train_MAE=0.592, train_loss=0.669, val_MAE=0.647, val_loss=0.725]Epoch 84:   8%|▊         | 84/1000 [9:40:12<102:40:06, 403.50s/it, lr=3.13e-5, test_MAE=0.687, time=403, train_MAE=0.595, train_loss=0.673, val_MAE=0.652, val_loss=0.73] Epoch    85: reducing learning rate of group 0 to 1.5625e-05.
Epoch 84:   8%|▊         | 85/1000 [9:40:12<102:30:29, 403.31s/it, lr=3.13e-5, test_MAE=0.687, time=403, train_MAE=0.595, train_loss=0.673, val_MAE=0.652, val_loss=0.73]Epoch 85:   8%|▊         | 85/1000 [9:40:12<102:30:29, 403.31s/it, lr=3.13e-5, test_MAE=0.687, time=403, train_MAE=0.595, train_loss=0.673, val_MAE=0.652, val_loss=0.73]Epoch 85:   8%|▊         | 85/1000 [9:46:55<102:30:29, 403.31s/it, lr=1.56e-5, test_MAE=0.712, time=403, train_MAE=0.595, train_loss=0.672, val_MAE=0.665, val_loss=0.743]Epoch 85:   9%|▊         | 86/1000 [9:46:55<102:23:36, 403.30s/it, lr=1.56e-5, test_MAE=0.712, time=403, train_MAE=0.595, train_loss=0.672, val_MAE=0.665, val_loss=0.743]Epoch 86:   9%|▊         | 86/1000 [9:46:55<102:23:36, 403.30s/it, lr=1.56e-5, test_MAE=0.712, time=403, train_MAE=0.595, train_loss=0.672, val_MAE=0.665, val_loss=0.743]Epoch 86:   9%|▊         | 86/1000 [9:53:38<102:23:36, 403.30s/it, lr=1.56e-5, test_MAE=0.68, time=403, train_MAE=0.59, train_loss=0.667, val_MAE=0.645, val_loss=0.723]  Epoch 86:   9%|▊         | 87/1000 [9:53:38<102:14:12, 403.12s/it, lr=1.56e-5, test_MAE=0.68, time=403, train_MAE=0.59, train_loss=0.667, val_MAE=0.645, val_loss=0.723]Epoch 87:   9%|▊         | 87/1000 [9:53:38<102:14:12, 403.12s/it, lr=1.56e-5, test_MAE=0.68, time=403, train_MAE=0.59, train_loss=0.667, val_MAE=0.645, val_loss=0.723]Epoch 87:   9%|▊         | 87/1000 [10:00:21<102:14:12, 403.12s/it, lr=1.56e-5, test_MAE=0.703, time=402, train_MAE=0.594, train_loss=0.672, val_MAE=0.66, val_loss=0.738]Epoch 87:   9%|▉         | 88/1000 [10:00:21<102:04:29, 402.93s/it, lr=1.56e-5, test_MAE=0.703, time=402, train_MAE=0.594, train_loss=0.672, val_MAE=0.66, val_loss=0.738]Epoch 88:   9%|▉         | 88/1000 [10:00:21<102:04:29, 402.93s/it, lr=1.56e-5, test_MAE=0.703, time=402, train_MAE=0.594, train_loss=0.672, val_MAE=0.66, val_loss=0.738]Epoch 88:   9%|▉         | 88/1000 [10:07:04<102:04:29, 402.93s/it, lr=1.56e-5, test_MAE=0.692, time=404, train_MAE=0.593, train_loss=0.671, val_MAE=0.641, val_loss=0.718]Epoch 88:   9%|▉         | 89/1000 [10:07:04<102:01:54, 403.20s/it, lr=1.56e-5, test_MAE=0.692, time=404, train_MAE=0.593, train_loss=0.671, val_MAE=0.641, val_loss=0.718]Epoch 89:   9%|▉         | 89/1000 [10:07:04<102:01:54, 403.20s/it, lr=1.56e-5, test_MAE=0.692, time=404, train_MAE=0.593, train_loss=0.671, val_MAE=0.641, val_loss=0.718]Epoch 89:   9%|▉         | 89/1000 [10:13:47<102:01:54, 403.20s/it, lr=1.56e-5, test_MAE=0.664, time=403, train_MAE=0.59, train_loss=0.667, val_MAE=0.616, val_loss=0.693] Epoch 89:   9%|▉         | 90/1000 [10:13:47<101:54:12, 403.13s/it, lr=1.56e-5, test_MAE=0.664, time=403, train_MAE=0.59, train_loss=0.667, val_MAE=0.616, val_loss=0.693]Epoch 90:   9%|▉         | 90/1000 [10:13:47<101:54:12, 403.13s/it, lr=1.56e-5, test_MAE=0.664, time=403, train_MAE=0.59, train_loss=0.667, val_MAE=0.616, val_loss=0.693]Epoch 90:   9%|▉         | 90/1000 [10:20:28<101:54:12, 403.13s/it, lr=1.56e-5, test_MAE=0.671, time=401, train_MAE=0.592, train_loss=0.669, val_MAE=0.631, val_loss=0.709]Epoch 90:   9%|▉         | 91/1000 [10:20:28<101:35:46, 402.36s/it, lr=1.56e-5, test_MAE=0.671, time=401, train_MAE=0.592, train_loss=0.669, val_MAE=0.631, val_loss=0.709]Epoch 91:   9%|▉         | 91/1000 [10:20:28<101:35:46, 402.36s/it, lr=1.56e-5, test_MAE=0.671, time=401, train_MAE=0.592, train_loss=0.669, val_MAE=0.631, val_loss=0.709]Epoch 91:   9%|▉         | 91/1000 [10:27:09<101:35:46, 402.36s/it, lr=1.56e-5, test_MAE=0.668, time=401, train_MAE=0.583, train_loss=0.661, val_MAE=0.629, val_loss=0.707]Epoch 91:   9%|▉         | 92/1000 [10:27:09<101:25:02, 402.10s/it, lr=1.56e-5, test_MAE=0.668, time=401, train_MAE=0.583, train_loss=0.661, val_MAE=0.629, val_loss=0.707]Epoch 92:   9%|▉         | 92/1000 [10:27:09<101:25:02, 402.10s/it, lr=1.56e-5, test_MAE=0.668, time=401, train_MAE=0.583, train_loss=0.661, val_MAE=0.629, val_loss=0.707]Epoch 92:   9%|▉         | 92/1000 [10:33:51<101:25:02, 402.10s/it, lr=1.56e-5, test_MAE=0.676, time=402, train_MAE=0.588, train_loss=0.665, val_MAE=0.639, val_loss=0.717]Epoch 92:   9%|▉         | 93/1000 [10:33:51<101:17:17, 402.03s/it, lr=1.56e-5, test_MAE=0.676, time=402, train_MAE=0.588, train_loss=0.665, val_MAE=0.639, val_loss=0.717]Epoch 93:   9%|▉         | 93/1000 [10:33:51<101:17:17, 402.03s/it, lr=1.56e-5, test_MAE=0.676, time=402, train_MAE=0.588, train_loss=0.665, val_MAE=0.639, val_loss=0.717]Epoch 93:   9%|▉         | 93/1000 [10:40:33<101:17:17, 402.03s/it, lr=1.56e-5, test_MAE=0.685, time=402, train_MAE=0.593, train_loss=0.671, val_MAE=0.641, val_loss=0.719]Epoch 93:   9%|▉         | 94/1000 [10:40:33<101:09:36, 401.96s/it, lr=1.56e-5, test_MAE=0.685, time=402, train_MAE=0.593, train_loss=0.671, val_MAE=0.641, val_loss=0.719]Epoch 94:   9%|▉         | 94/1000 [10:40:33<101:09:36, 401.96s/it, lr=1.56e-5, test_MAE=0.685, time=402, train_MAE=0.593, train_loss=0.671, val_MAE=0.641, val_loss=0.719]Epoch 94:   9%|▉         | 94/1000 [10:47:15<101:09:36, 401.96s/it, lr=1.56e-5, test_MAE=0.672, time=402, train_MAE=0.584, train_loss=0.661, val_MAE=0.648, val_loss=0.726]Epoch 94:  10%|▉         | 95/1000 [10:47:15<101:01:38, 401.88s/it, lr=1.56e-5, test_MAE=0.672, time=402, train_MAE=0.584, train_loss=0.661, val_MAE=0.648, val_loss=0.726]Epoch 95:  10%|▉         | 95/1000 [10:47:15<101:01:38, 401.88s/it, lr=1.56e-5, test_MAE=0.672, time=402, train_MAE=0.584, train_loss=0.661, val_MAE=0.648, val_loss=0.726]Epoch 95:  10%|▉         | 95/1000 [10:53:56<101:01:38, 401.88s/it, lr=1.56e-5, test_MAE=0.676, time=401, train_MAE=0.586, train_loss=0.664, val_MAE=0.627, val_loss=0.705]Epoch    96: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 95:  10%|▉         | 95/1000 [10:53:56<103:49:41, 413.02s/it, lr=1.56e-5, test_MAE=0.676, time=401, train_MAE=0.586, train_loss=0.664, val_MAE=0.627, val_loss=0.705]
Test MAE: 0.6764
Train MAE: 0.6011
Convergence Time (Epochs): 95.0000
TOTAL TIME TAKEN: 39404.1675s
AVG TIME PER EPOCH: 408.6983s
