I'm echoing to stdout
I'm echoing to stderr
My JobID is 56573437
I have 8 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.0340s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 4, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'rational_vec', 'normalized_laplacian': True, 'post_normalized': False, 'eigval_norm': '', 'num_eigs': 15, 'bias_mode': 'spatial', 'eigval_hidden_dim': 5, 'eigval_num_hidden_layer': 3, 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 1, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/zinc_train_rec_full.csv', 'test': 'supp_data/molecules/zinc_test_rec_full.csv', 'val': 'supp_data/molecules/zinc_val_rec_full.csv'}, 'fixMissingPhi1': False, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [02:09<?, ?it/s, lr=0.001, test_MAE=1.48, time=129, train_MAE=1.36, train_loss=1.39, val_MAE=1.42, val_loss=1.45]Epoch 0:   0%|          | 1/1000 [02:09<35:55:55, 129.48s/it, lr=0.001, test_MAE=1.48, time=129, train_MAE=1.36, train_loss=1.39, val_MAE=1.42, val_loss=1.45]Epoch 1:   0%|          | 1/1000 [02:09<35:55:55, 129.48s/it, lr=0.001, test_MAE=1.48, time=129, train_MAE=1.36, train_loss=1.39, val_MAE=1.42, val_loss=1.45]Epoch 1:   0%|          | 1/1000 [04:01<35:55:55, 129.48s/it, lr=0.001, test_MAE=1.51, time=112, train_MAE=1.15, train_loss=1.18, val_MAE=1.44, val_loss=1.47]Epoch 1:   0%|          | 2/1000 [04:01<34:28:37, 124.37s/it, lr=0.001, test_MAE=1.51, time=112, train_MAE=1.15, train_loss=1.18, val_MAE=1.44, val_loss=1.47]Epoch 2:   0%|          | 2/1000 [04:01<34:28:37, 124.37s/it, lr=0.001, test_MAE=1.51, time=112, train_MAE=1.15, train_loss=1.18, val_MAE=1.44, val_loss=1.47]Epoch 2:   0%|          | 2/1000 [05:55<34:28:37, 124.37s/it, lr=0.001, test_MAE=1.51, time=114, train_MAE=1, train_loss=1.04, val_MAE=1.44, val_loss=1.47]   Epoch 2:   0%|          | 3/1000 [05:55<33:33:40, 121.18s/it, lr=0.001, test_MAE=1.51, time=114, train_MAE=1, train_loss=1.04, val_MAE=1.44, val_loss=1.47]Epoch 3:   0%|          | 3/1000 [05:55<33:33:40, 121.18s/it, lr=0.001, test_MAE=1.51, time=114, train_MAE=1, train_loss=1.04, val_MAE=1.44, val_loss=1.47]Epoch 3:   0%|          | 3/1000 [07:49<33:33:40, 121.18s/it, lr=0.001, test_MAE=1.35, time=114, train_MAE=0.884, train_loss=0.921, val_MAE=1.19, val_loss=1.23]Epoch 3:   0%|          | 4/1000 [07:49<32:57:26, 119.12s/it, lr=0.001, test_MAE=1.35, time=114, train_MAE=0.884, train_loss=0.921, val_MAE=1.19, val_loss=1.23]Epoch 4:   0%|          | 4/1000 [07:49<32:57:26, 119.12s/it, lr=0.001, test_MAE=1.35, time=114, train_MAE=0.884, train_loss=0.921, val_MAE=1.19, val_loss=1.23]Epoch 4:   0%|          | 4/1000 [09:45<32:57:26, 119.12s/it, lr=0.001, test_MAE=1.24, time=115, train_MAE=0.82, train_loss=0.859, val_MAE=1.2, val_loss=1.24]  Epoch 4:   0%|          | 5/1000 [09:45<32:35:39, 117.93s/it, lr=0.001, test_MAE=1.24, time=115, train_MAE=0.82, train_loss=0.859, val_MAE=1.2, val_loss=1.24]Epoch 5:   0%|          | 5/1000 [09:45<32:35:39, 117.93s/it, lr=0.001, test_MAE=1.24, time=115, train_MAE=0.82, train_loss=0.859, val_MAE=1.2, val_loss=1.24]Epoch 5:   0%|          | 5/1000 [11:40<32:35:39, 117.93s/it, lr=0.001, test_MAE=1.14, time=115, train_MAE=0.789, train_loss=0.829, val_MAE=1.1, val_loss=1.14]Epoch 5:   1%|          | 6/1000 [11:40<32:20:46, 117.15s/it, lr=0.001, test_MAE=1.14, time=115, train_MAE=0.789, train_loss=0.829, val_MAE=1.1, val_loss=1.14]Epoch 6:   1%|          | 6/1000 [11:40<32:20:46, 117.15s/it, lr=0.001, test_MAE=1.14, time=115, train_MAE=0.789, train_loss=0.829, val_MAE=1.1, val_loss=1.14]Epoch 6:   1%|          | 6/1000 [13:35<32:20:46, 117.15s/it, lr=0.001, test_MAE=1.02, time=115, train_MAE=0.755, train_loss=0.796, val_MAE=0.956, val_loss=0.998]Epoch 6:   1%|          | 7/1000 [13:35<32:09:16, 116.57s/it, lr=0.001, test_MAE=1.02, time=115, train_MAE=0.755, train_loss=0.796, val_MAE=0.956, val_loss=0.998]Epoch 7:   1%|          | 7/1000 [13:35<32:09:16, 116.57s/it, lr=0.001, test_MAE=1.02, time=115, train_MAE=0.755, train_loss=0.796, val_MAE=0.956, val_loss=0.998]Epoch 7:   1%|          | 7/1000 [15:30<32:09:16, 116.57s/it, lr=0.001, test_MAE=0.922, time=115, train_MAE=0.725, train_loss=0.767, val_MAE=0.857, val_loss=0.9] Epoch 7:   1%|          | 8/1000 [15:30<31:57:34, 115.98s/it, lr=0.001, test_MAE=0.922, time=115, train_MAE=0.725, train_loss=0.767, val_MAE=0.857, val_loss=0.9]Epoch 8:   1%|          | 8/1000 [15:30<31:57:34, 115.98s/it, lr=0.001, test_MAE=0.922, time=115, train_MAE=0.725, train_loss=0.767, val_MAE=0.857, val_loss=0.9]Epoch 8:   1%|          | 8/1000 [17:25<31:57:34, 115.98s/it, lr=0.001, test_MAE=0.901, time=115, train_MAE=0.722, train_loss=0.765, val_MAE=0.824, val_loss=0.867]Epoch 8:   1%|          | 9/1000 [17:25<31:50:11, 115.65s/it, lr=0.001, test_MAE=0.901, time=115, train_MAE=0.722, train_loss=0.765, val_MAE=0.824, val_loss=0.867]Epoch 9:   1%|          | 9/1000 [17:25<31:50:11, 115.65s/it, lr=0.001, test_MAE=0.901, time=115, train_MAE=0.722, train_loss=0.765, val_MAE=0.824, val_loss=0.867]Epoch 9:   1%|          | 9/1000 [19:19<31:50:11, 115.65s/it, lr=0.001, test_MAE=0.931, time=114, train_MAE=0.709, train_loss=0.753, val_MAE=0.874, val_loss=0.918]Epoch 9:   1%|          | 10/1000 [19:19<31:42:17, 115.29s/it, lr=0.001, test_MAE=0.931, time=114, train_MAE=0.709, train_loss=0.753, val_MAE=0.874, val_loss=0.918]Epoch 10:   1%|          | 10/1000 [19:19<31:42:17, 115.29s/it, lr=0.001, test_MAE=0.931, time=114, train_MAE=0.709, train_loss=0.753, val_MAE=0.874, val_loss=0.918]Epoch 10:   1%|          | 10/1000 [21:14<31:42:17, 115.29s/it, lr=0.001, test_MAE=0.909, time=115, train_MAE=0.699, train_loss=0.743, val_MAE=0.867, val_loss=0.912]Epoch 10:   1%|          | 11/1000 [21:14<31:36:54, 115.08s/it, lr=0.001, test_MAE=0.909, time=115, train_MAE=0.699, train_loss=0.743, val_MAE=0.867, val_loss=0.912]Epoch 11:   1%|          | 11/1000 [21:14<31:36:54, 115.08s/it, lr=0.001, test_MAE=0.909, time=115, train_MAE=0.699, train_loss=0.743, val_MAE=0.867, val_loss=0.912]Epoch 11:   1%|          | 11/1000 [23:08<31:36:54, 115.08s/it, lr=0.001, test_MAE=0.8, time=115, train_MAE=0.694, train_loss=0.739, val_MAE=0.757, val_loss=0.802]  Epoch 11:   1%|          | 12/1000 [23:08<31:33:27, 114.99s/it, lr=0.001, test_MAE=0.8, time=115, train_MAE=0.694, train_loss=0.739, val_MAE=0.757, val_loss=0.802]Epoch 12:   1%|          | 12/1000 [23:08<31:33:27, 114.99s/it, lr=0.001, test_MAE=0.8, time=115, train_MAE=0.694, train_loss=0.739, val_MAE=0.757, val_loss=0.802]Epoch 12:   1%|          | 12/1000 [25:01<31:33:27, 114.99s/it, lr=0.001, test_MAE=0.903, time=113, train_MAE=0.688, train_loss=0.733, val_MAE=0.857, val_loss=0.902]Epoch 12:   1%|▏         | 13/1000 [25:01<31:19:44, 114.27s/it, lr=0.001, test_MAE=0.903, time=113, train_MAE=0.688, train_loss=0.733, val_MAE=0.857, val_loss=0.902]Epoch 13:   1%|▏         | 13/1000 [25:01<31:19:44, 114.27s/it, lr=0.001, test_MAE=0.903, time=113, train_MAE=0.688, train_loss=0.733, val_MAE=0.857, val_loss=0.902]Epoch 13:   1%|▏         | 13/1000 [26:55<31:19:44, 114.27s/it, lr=0.001, test_MAE=0.793, time=114, train_MAE=0.68, train_loss=0.726, val_MAE=0.738, val_loss=0.785] Epoch 13:   1%|▏         | 14/1000 [26:55<31:14:09, 114.05s/it, lr=0.001, test_MAE=0.793, time=114, train_MAE=0.68, train_loss=0.726, val_MAE=0.738, val_loss=0.785]Epoch 14:   1%|▏         | 14/1000 [26:55<31:14:09, 114.05s/it, lr=0.001, test_MAE=0.793, time=114, train_MAE=0.68, train_loss=0.726, val_MAE=0.738, val_loss=0.785]Epoch 14:   1%|▏         | 14/1000 [28:48<31:14:09, 114.05s/it, lr=0.001, test_MAE=0.84, time=113, train_MAE=0.686, train_loss=0.732, val_MAE=0.77, val_loss=0.816] Epoch 14:   2%|▏         | 15/1000 [28:48<31:09:00, 113.85s/it, lr=0.001, test_MAE=0.84, time=113, train_MAE=0.686, train_loss=0.732, val_MAE=0.77, val_loss=0.816]Epoch 15:   2%|▏         | 15/1000 [28:48<31:09:00, 113.85s/it, lr=0.001, test_MAE=0.84, time=113, train_MAE=0.686, train_loss=0.732, val_MAE=0.77, val_loss=0.816]Epoch 15:   2%|▏         | 15/1000 [30:42<31:09:00, 113.85s/it, lr=0.001, test_MAE=0.834, time=114, train_MAE=0.667, train_loss=0.713, val_MAE=0.77, val_loss=0.817]Epoch 15:   2%|▏         | 16/1000 [30:42<31:05:56, 113.78s/it, lr=0.001, test_MAE=0.834, time=114, train_MAE=0.667, train_loss=0.713, val_MAE=0.77, val_loss=0.817]Epoch 16:   2%|▏         | 16/1000 [30:42<31:05:56, 113.78s/it, lr=0.001, test_MAE=0.834, time=114, train_MAE=0.667, train_loss=0.713, val_MAE=0.77, val_loss=0.817]Epoch 16:   2%|▏         | 16/1000 [32:35<31:05:56, 113.78s/it, lr=0.001, test_MAE=0.893, time=114, train_MAE=0.669, train_loss=0.717, val_MAE=0.857, val_loss=0.905]Epoch 16:   2%|▏         | 17/1000 [32:35<31:02:53, 113.71s/it, lr=0.001, test_MAE=0.893, time=114, train_MAE=0.669, train_loss=0.717, val_MAE=0.857, val_loss=0.905]Epoch 17:   2%|▏         | 17/1000 [32:35<31:02:53, 113.71s/it, lr=0.001, test_MAE=0.893, time=114, train_MAE=0.669, train_loss=0.717, val_MAE=0.857, val_loss=0.905]Epoch 17:   2%|▏         | 17/1000 [34:28<31:02:53, 113.71s/it, lr=0.001, test_MAE=0.881, time=113, train_MAE=0.667, train_loss=0.714, val_MAE=0.835, val_loss=0.883]Epoch 17:   2%|▏         | 18/1000 [34:28<30:56:37, 113.44s/it, lr=0.001, test_MAE=0.881, time=113, train_MAE=0.667, train_loss=0.714, val_MAE=0.835, val_loss=0.883]Epoch 18:   2%|▏         | 18/1000 [34:28<30:56:37, 113.44s/it, lr=0.001, test_MAE=0.881, time=113, train_MAE=0.667, train_loss=0.714, val_MAE=0.835, val_loss=0.883]Epoch 18:   2%|▏         | 18/1000 [36:20<30:56:37, 113.44s/it, lr=0.001, test_MAE=0.831, time=112, train_MAE=0.658, train_loss=0.707, val_MAE=0.762, val_loss=0.811]Epoch 18:   2%|▏         | 19/1000 [36:20<30:48:22, 113.05s/it, lr=0.001, test_MAE=0.831, time=112, train_MAE=0.658, train_loss=0.707, val_MAE=0.762, val_loss=0.811]Epoch 19:   2%|▏         | 19/1000 [36:20<30:48:22, 113.05s/it, lr=0.001, test_MAE=0.831, time=112, train_MAE=0.658, train_loss=0.707, val_MAE=0.762, val_loss=0.811]Epoch 19:   2%|▏         | 19/1000 [38:13<30:48:22, 113.05s/it, lr=0.001, test_MAE=0.85, time=113, train_MAE=0.663, train_loss=0.711, val_MAE=0.718, val_loss=0.767] Epoch 19:   2%|▏         | 20/1000 [38:13<30:48:04, 113.15s/it, lr=0.001, test_MAE=0.85, time=113, train_MAE=0.663, train_loss=0.711, val_MAE=0.718, val_loss=0.767]Epoch 20:   2%|▏         | 20/1000 [38:13<30:48:04, 113.15s/it, lr=0.001, test_MAE=0.85, time=113, train_MAE=0.663, train_loss=0.711, val_MAE=0.718, val_loss=0.767]Epoch 20:   2%|▏         | 20/1000 [40:07<30:48:04, 113.15s/it, lr=0.001, test_MAE=0.843, time=114, train_MAE=0.681, train_loss=0.73, val_MAE=0.758, val_loss=0.807]Epoch 20:   2%|▏         | 21/1000 [40:07<30:49:17, 113.34s/it, lr=0.001, test_MAE=0.843, time=114, train_MAE=0.681, train_loss=0.73, val_MAE=0.758, val_loss=0.807]Epoch 21:   2%|▏         | 21/1000 [40:07<30:49:17, 113.34s/it, lr=0.001, test_MAE=0.843, time=114, train_MAE=0.681, train_loss=0.73, val_MAE=0.758, val_loss=0.807]Epoch 21:   2%|▏         | 21/1000 [42:00<30:49:17, 113.34s/it, lr=0.001, test_MAE=0.866, time=113, train_MAE=0.661, train_loss=0.711, val_MAE=0.808, val_loss=0.858]Epoch 21:   2%|▏         | 22/1000 [42:00<30:43:57, 113.13s/it, lr=0.001, test_MAE=0.866, time=113, train_MAE=0.661, train_loss=0.711, val_MAE=0.808, val_loss=0.858]Epoch 22:   2%|▏         | 22/1000 [42:00<30:43:57, 113.13s/it, lr=0.001, test_MAE=0.866, time=113, train_MAE=0.661, train_loss=0.711, val_MAE=0.808, val_loss=0.858]Epoch 22:   2%|▏         | 22/1000 [43:53<30:43:57, 113.13s/it, lr=0.001, test_MAE=0.765, time=113, train_MAE=0.652, train_loss=0.702, val_MAE=0.702, val_loss=0.752]Epoch 22:   2%|▏         | 23/1000 [43:53<30:41:55, 113.12s/it, lr=0.001, test_MAE=0.765, time=113, train_MAE=0.652, train_loss=0.702, val_MAE=0.702, val_loss=0.752]Epoch 23:   2%|▏         | 23/1000 [43:53<30:41:55, 113.12s/it, lr=0.001, test_MAE=0.765, time=113, train_MAE=0.652, train_loss=0.702, val_MAE=0.702, val_loss=0.752]Epoch 23:   2%|▏         | 23/1000 [45:47<30:41:55, 113.12s/it, lr=0.001, test_MAE=0.876, time=114, train_MAE=0.655, train_loss=0.705, val_MAE=0.839, val_loss=0.889]Epoch 23:   2%|▏         | 24/1000 [45:47<30:45:52, 113.48s/it, lr=0.001, test_MAE=0.876, time=114, train_MAE=0.655, train_loss=0.705, val_MAE=0.839, val_loss=0.889]Epoch 24:   2%|▏         | 24/1000 [45:47<30:45:52, 113.48s/it, lr=0.001, test_MAE=0.876, time=114, train_MAE=0.655, train_loss=0.705, val_MAE=0.839, val_loss=0.889]Epoch 24:   2%|▏         | 24/1000 [47:41<30:45:52, 113.48s/it, lr=0.001, test_MAE=0.789, time=113, train_MAE=0.654, train_loss=0.704, val_MAE=0.747, val_loss=0.797]Epoch 24:   2%|▎         | 25/1000 [47:41<30:44:06, 113.48s/it, lr=0.001, test_MAE=0.789, time=113, train_MAE=0.654, train_loss=0.704, val_MAE=0.747, val_loss=0.797]Epoch 25:   2%|▎         | 25/1000 [47:41<30:44:06, 113.48s/it, lr=0.001, test_MAE=0.789, time=113, train_MAE=0.654, train_loss=0.704, val_MAE=0.747, val_loss=0.797]Epoch 25:   2%|▎         | 25/1000 [49:35<30:44:06, 113.48s/it, lr=0.001, test_MAE=0.714, time=114, train_MAE=0.654, train_loss=0.704, val_MAE=0.654, val_loss=0.705]Epoch 25:   3%|▎         | 26/1000 [49:35<30:44:28, 113.62s/it, lr=0.001, test_MAE=0.714, time=114, train_MAE=0.654, train_loss=0.704, val_MAE=0.654, val_loss=0.705]Epoch 26:   3%|▎         | 26/1000 [49:35<30:44:28, 113.62s/it, lr=0.001, test_MAE=0.714, time=114, train_MAE=0.654, train_loss=0.704, val_MAE=0.654, val_loss=0.705]Epoch 26:   3%|▎         | 26/1000 [51:27<30:44:28, 113.62s/it, lr=0.001, test_MAE=0.792, time=113, train_MAE=0.65, train_loss=0.701, val_MAE=0.74, val_loss=0.792]  Epoch 26:   3%|▎         | 27/1000 [51:27<30:38:09, 113.35s/it, lr=0.001, test_MAE=0.792, time=113, train_MAE=0.65, train_loss=0.701, val_MAE=0.74, val_loss=0.792]Epoch 27:   3%|▎         | 27/1000 [51:27<30:38:09, 113.35s/it, lr=0.001, test_MAE=0.792, time=113, train_MAE=0.65, train_loss=0.701, val_MAE=0.74, val_loss=0.792]Epoch 27:   3%|▎         | 27/1000 [53:21<30:38:09, 113.35s/it, lr=0.001, test_MAE=0.751, time=114, train_MAE=0.648, train_loss=0.7, val_MAE=0.737, val_loss=0.789]Epoch 27:   3%|▎         | 28/1000 [53:21<30:37:23, 113.42s/it, lr=0.001, test_MAE=0.751, time=114, train_MAE=0.648, train_loss=0.7, val_MAE=0.737, val_loss=0.789]Epoch 28:   3%|▎         | 28/1000 [53:21<30:37:23, 113.42s/it, lr=0.001, test_MAE=0.751, time=114, train_MAE=0.648, train_loss=0.7, val_MAE=0.737, val_loss=0.789]Epoch 28:   3%|▎         | 28/1000 [55:14<30:37:23, 113.42s/it, lr=0.001, test_MAE=0.802, time=113, train_MAE=0.648, train_loss=0.701, val_MAE=0.763, val_loss=0.816]Epoch 28:   3%|▎         | 29/1000 [55:14<30:33:58, 113.33s/it, lr=0.001, test_MAE=0.802, time=113, train_MAE=0.648, train_loss=0.701, val_MAE=0.763, val_loss=0.816]Epoch 29:   3%|▎         | 29/1000 [55:14<30:33:58, 113.33s/it, lr=0.001, test_MAE=0.802, time=113, train_MAE=0.648, train_loss=0.701, val_MAE=0.763, val_loss=0.816]Epoch 29:   3%|▎         | 29/1000 [57:07<30:33:58, 113.33s/it, lr=0.001, test_MAE=0.75, time=113, train_MAE=0.657, train_loss=0.71, val_MAE=0.702, val_loss=0.755]  Epoch 29:   3%|▎         | 30/1000 [57:07<30:28:13, 113.09s/it, lr=0.001, test_MAE=0.75, time=113, train_MAE=0.657, train_loss=0.71, val_MAE=0.702, val_loss=0.755]Epoch 30:   3%|▎         | 30/1000 [57:07<30:28:13, 113.09s/it, lr=0.001, test_MAE=0.75, time=113, train_MAE=0.657, train_loss=0.71, val_MAE=0.702, val_loss=0.755]Epoch 30:   3%|▎         | 30/1000 [59:00<30:28:13, 113.09s/it, lr=0.001, test_MAE=0.816, time=113, train_MAE=0.645, train_loss=0.698, val_MAE=0.77, val_loss=0.824]Epoch 30:   3%|▎         | 31/1000 [59:00<30:27:02, 113.13s/it, lr=0.001, test_MAE=0.816, time=113, train_MAE=0.645, train_loss=0.698, val_MAE=0.77, val_loss=0.824]Epoch 31:   3%|▎         | 31/1000 [59:00<30:27:02, 113.13s/it, lr=0.001, test_MAE=0.816, time=113, train_MAE=0.645, train_loss=0.698, val_MAE=0.77, val_loss=0.824]Epoch 31:   3%|▎         | 31/1000 [1:00:55<30:27:02, 113.13s/it, lr=0.001, test_MAE=0.903, time=115, train_MAE=0.644, train_loss=0.698, val_MAE=0.871, val_loss=0.925]Epoch    32: reducing learning rate of group 0 to 5.0000e-04.
Epoch 31:   3%|▎         | 32/1000 [1:00:55<30:34:16, 113.69s/it, lr=0.001, test_MAE=0.903, time=115, train_MAE=0.644, train_loss=0.698, val_MAE=0.871, val_loss=0.925]Epoch 32:   3%|▎         | 32/1000 [1:00:55<30:34:16, 113.69s/it, lr=0.001, test_MAE=0.903, time=115, train_MAE=0.644, train_loss=0.698, val_MAE=0.871, val_loss=0.925]Epoch 32:   3%|▎         | 32/1000 [1:02:48<30:34:16, 113.69s/it, lr=0.0005, test_MAE=0.741, time=113, train_MAE=0.648, train_loss=0.701, val_MAE=0.688, val_loss=0.741]Epoch 32:   3%|▎         | 33/1000 [1:02:48<30:28:21, 113.45s/it, lr=0.0005, test_MAE=0.741, time=113, train_MAE=0.648, train_loss=0.701, val_MAE=0.688, val_loss=0.741]Epoch 33:   3%|▎         | 33/1000 [1:02:48<30:28:21, 113.45s/it, lr=0.0005, test_MAE=0.741, time=113, train_MAE=0.648, train_loss=0.701, val_MAE=0.688, val_loss=0.741]Epoch 33:   3%|▎         | 33/1000 [1:04:41<30:28:21, 113.45s/it, lr=0.0005, test_MAE=0.733, time=113, train_MAE=0.631, train_loss=0.685, val_MAE=0.694, val_loss=0.748]Epoch 33:   3%|▎         | 34/1000 [1:04:41<30:24:18, 113.31s/it, lr=0.0005, test_MAE=0.733, time=113, train_MAE=0.631, train_loss=0.685, val_MAE=0.694, val_loss=0.748]Epoch 34:   3%|▎         | 34/1000 [1:04:41<30:24:18, 113.31s/it, lr=0.0005, test_MAE=0.733, time=113, train_MAE=0.631, train_loss=0.685, val_MAE=0.694, val_loss=0.748]Epoch 34:   3%|▎         | 34/1000 [1:06:34<30:24:18, 113.31s/it, lr=0.0005, test_MAE=0.738, time=113, train_MAE=0.631, train_loss=0.685, val_MAE=0.704, val_loss=0.757]Epoch 34:   4%|▎         | 35/1000 [1:06:34<30:22:10, 113.30s/it, lr=0.0005, test_MAE=0.738, time=113, train_MAE=0.631, train_loss=0.685, val_MAE=0.704, val_loss=0.757]Epoch 35:   4%|▎         | 35/1000 [1:06:34<30:22:10, 113.30s/it, lr=0.0005, test_MAE=0.738, time=113, train_MAE=0.631, train_loss=0.685, val_MAE=0.704, val_loss=0.757]Epoch 35:   4%|▎         | 35/1000 [1:08:27<30:22:10, 113.30s/it, lr=0.0005, test_MAE=0.798, time=113, train_MAE=0.631, train_loss=0.684, val_MAE=0.744, val_loss=0.797]Epoch 35:   4%|▎         | 36/1000 [1:08:27<30:17:52, 113.15s/it, lr=0.0005, test_MAE=0.798, time=113, train_MAE=0.631, train_loss=0.684, val_MAE=0.744, val_loss=0.797]Epoch 36:   4%|▎         | 36/1000 [1:08:27<30:17:52, 113.15s/it, lr=0.0005, test_MAE=0.798, time=113, train_MAE=0.631, train_loss=0.684, val_MAE=0.744, val_loss=0.797]Epoch 36:   4%|▎         | 36/1000 [1:10:21<30:17:52, 113.15s/it, lr=0.0005, test_MAE=0.715, time=114, train_MAE=0.631, train_loss=0.685, val_MAE=0.677, val_loss=0.731]Epoch 36:   4%|▎         | 37/1000 [1:10:21<30:20:47, 113.44s/it, lr=0.0005, test_MAE=0.715, time=114, train_MAE=0.631, train_loss=0.685, val_MAE=0.677, val_loss=0.731]Epoch 37:   4%|▎         | 37/1000 [1:10:21<30:20:47, 113.44s/it, lr=0.0005, test_MAE=0.715, time=114, train_MAE=0.631, train_loss=0.685, val_MAE=0.677, val_loss=0.731]Epoch 37:   4%|▎         | 37/1000 [1:12:15<30:20:47, 113.44s/it, lr=0.0005, test_MAE=0.728, time=114, train_MAE=0.635, train_loss=0.688, val_MAE=0.674, val_loss=0.728]Epoch    38: reducing learning rate of group 0 to 2.5000e-04.
Epoch 37:   4%|▍         | 38/1000 [1:12:15<30:21:07, 113.58s/it, lr=0.0005, test_MAE=0.728, time=114, train_MAE=0.635, train_loss=0.688, val_MAE=0.674, val_loss=0.728]Epoch 38:   4%|▍         | 38/1000 [1:12:15<30:21:07, 113.58s/it, lr=0.0005, test_MAE=0.728, time=114, train_MAE=0.635, train_loss=0.688, val_MAE=0.674, val_loss=0.728]Epoch 38:   4%|▍         | 38/1000 [1:14:07<30:21:07, 113.58s/it, lr=0.00025, test_MAE=0.728, time=112, train_MAE=0.621, train_loss=0.675, val_MAE=0.678, val_loss=0.732]Epoch 38:   4%|▍         | 39/1000 [1:14:07<30:11:36, 113.11s/it, lr=0.00025, test_MAE=0.728, time=112, train_MAE=0.621, train_loss=0.675, val_MAE=0.678, val_loss=0.732]Epoch 39:   4%|▍         | 39/1000 [1:14:07<30:11:36, 113.11s/it, lr=0.00025, test_MAE=0.728, time=112, train_MAE=0.621, train_loss=0.675, val_MAE=0.678, val_loss=0.732]Epoch 39:   4%|▍         | 39/1000 [1:15:59<30:11:36, 113.11s/it, lr=0.00025, test_MAE=0.746, time=112, train_MAE=0.622, train_loss=0.675, val_MAE=0.704, val_loss=0.757]Epoch 39:   4%|▍         | 40/1000 [1:15:59<30:04:30, 112.78s/it, lr=0.00025, test_MAE=0.746, time=112, train_MAE=0.622, train_loss=0.675, val_MAE=0.704, val_loss=0.757]Epoch 40:   4%|▍         | 40/1000 [1:15:59<30:04:30, 112.78s/it, lr=0.00025, test_MAE=0.746, time=112, train_MAE=0.622, train_loss=0.675, val_MAE=0.704, val_loss=0.757]Epoch 40:   4%|▍         | 40/1000 [1:17:52<30:04:30, 112.78s/it, lr=0.00025, test_MAE=0.734, time=113, train_MAE=0.623, train_loss=0.677, val_MAE=0.673, val_loss=0.727]Epoch 40:   4%|▍         | 41/1000 [1:17:52<30:02:10, 112.75s/it, lr=0.00025, test_MAE=0.734, time=113, train_MAE=0.623, train_loss=0.677, val_MAE=0.673, val_loss=0.727]Epoch 41:   4%|▍         | 41/1000 [1:17:52<30:02:10, 112.75s/it, lr=0.00025, test_MAE=0.734, time=113, train_MAE=0.623, train_loss=0.677, val_MAE=0.673, val_loss=0.727]Epoch 41:   4%|▍         | 41/1000 [1:19:45<30:02:10, 112.75s/it, lr=0.00025, test_MAE=0.716, time=113, train_MAE=0.623, train_loss=0.677, val_MAE=0.687, val_loss=0.74] Epoch 41:   4%|▍         | 42/1000 [1:19:45<30:03:55, 112.98s/it, lr=0.00025, test_MAE=0.716, time=113, train_MAE=0.623, train_loss=0.677, val_MAE=0.687, val_loss=0.74]Epoch 42:   4%|▍         | 42/1000 [1:19:45<30:03:55, 112.98s/it, lr=0.00025, test_MAE=0.716, time=113, train_MAE=0.623, train_loss=0.677, val_MAE=0.687, val_loss=0.74]Epoch 42:   4%|▍         | 42/1000 [1:21:38<30:03:55, 112.98s/it, lr=0.00025, test_MAE=0.755, time=113, train_MAE=0.624, train_loss=0.678, val_MAE=0.707, val_loss=0.761]Epoch 42:   4%|▍         | 43/1000 [1:21:38<30:01:34, 112.95s/it, lr=0.00025, test_MAE=0.755, time=113, train_MAE=0.624, train_loss=0.678, val_MAE=0.707, val_loss=0.761]Epoch 43:   4%|▍         | 43/1000 [1:21:38<30:01:34, 112.95s/it, lr=0.00025, test_MAE=0.755, time=113, train_MAE=0.624, train_loss=0.678, val_MAE=0.707, val_loss=0.761]Epoch 43:   4%|▍         | 43/1000 [1:23:31<30:01:34, 112.95s/it, lr=0.00025, test_MAE=0.708, time=113, train_MAE=0.618, train_loss=0.672, val_MAE=0.665, val_loss=0.719]Epoch    44: reducing learning rate of group 0 to 1.2500e-04.
Epoch 43:   4%|▍         | 44/1000 [1:23:31<29:58:56, 112.90s/it, lr=0.00025, test_MAE=0.708, time=113, train_MAE=0.618, train_loss=0.672, val_MAE=0.665, val_loss=0.719]Epoch 44:   4%|▍         | 44/1000 [1:23:31<29:58:56, 112.90s/it, lr=0.00025, test_MAE=0.708, time=113, train_MAE=0.618, train_loss=0.672, val_MAE=0.665, val_loss=0.719]Epoch 44:   4%|▍         | 44/1000 [1:25:25<29:58:56, 112.90s/it, lr=0.000125, test_MAE=0.712, time=115, train_MAE=0.623, train_loss=0.676, val_MAE=0.672, val_loss=0.726]Epoch 44:   4%|▍         | 45/1000 [1:25:25<30:05:15, 113.42s/it, lr=0.000125, test_MAE=0.712, time=115, train_MAE=0.623, train_loss=0.676, val_MAE=0.672, val_loss=0.726]Epoch 45:   4%|▍         | 45/1000 [1:25:25<30:05:15, 113.42s/it, lr=0.000125, test_MAE=0.712, time=115, train_MAE=0.623, train_loss=0.676, val_MAE=0.672, val_loss=0.726]Epoch 45:   4%|▍         | 45/1000 [1:27:19<30:05:15, 113.42s/it, lr=0.000125, test_MAE=0.693, time=114, train_MAE=0.624, train_loss=0.678, val_MAE=0.646, val_loss=0.7]  Epoch 45:   5%|▍         | 46/1000 [1:27:19<30:05:12, 113.54s/it, lr=0.000125, test_MAE=0.693, time=114, train_MAE=0.624, train_loss=0.678, val_MAE=0.646, val_loss=0.7]Epoch 46:   5%|▍         | 46/1000 [1:27:19<30:05:12, 113.54s/it, lr=0.000125, test_MAE=0.693, time=114, train_MAE=0.624, train_loss=0.678, val_MAE=0.646, val_loss=0.7]Epoch 46:   5%|▍         | 46/1000 [1:29:12<30:05:12, 113.54s/it, lr=0.000125, test_MAE=0.787, time=113, train_MAE=0.614, train_loss=0.667, val_MAE=0.753, val_loss=0.806]Epoch 46:   5%|▍         | 47/1000 [1:29:12<29:59:05, 113.27s/it, lr=0.000125, test_MAE=0.787, time=113, train_MAE=0.614, train_loss=0.667, val_MAE=0.753, val_loss=0.806]Epoch 47:   5%|▍         | 47/1000 [1:29:12<29:59:05, 113.27s/it, lr=0.000125, test_MAE=0.787, time=113, train_MAE=0.614, train_loss=0.667, val_MAE=0.753, val_loss=0.806]Epoch 47:   5%|▍         | 47/1000 [1:31:04<29:59:05, 113.27s/it, lr=0.000125, test_MAE=0.712, time=113, train_MAE=0.612, train_loss=0.666, val_MAE=0.673, val_loss=0.727]Epoch 47:   5%|▍         | 48/1000 [1:31:04<29:54:01, 113.07s/it, lr=0.000125, test_MAE=0.712, time=113, train_MAE=0.612, train_loss=0.666, val_MAE=0.673, val_loss=0.727]Epoch 48:   5%|▍         | 48/1000 [1:31:04<29:54:01, 113.07s/it, lr=0.000125, test_MAE=0.712, time=113, train_MAE=0.612, train_loss=0.666, val_MAE=0.673, val_loss=0.727]Epoch 48:   5%|▍         | 48/1000 [1:32:57<29:54:01, 113.07s/it, lr=0.000125, test_MAE=0.717, time=113, train_MAE=0.615, train_loss=0.668, val_MAE=0.675, val_loss=0.728]Epoch 48:   5%|▍         | 49/1000 [1:32:57<29:51:20, 113.02s/it, lr=0.000125, test_MAE=0.717, time=113, train_MAE=0.615, train_loss=0.668, val_MAE=0.675, val_loss=0.728]Epoch 49:   5%|▍         | 49/1000 [1:32:57<29:51:20, 113.02s/it, lr=0.000125, test_MAE=0.717, time=113, train_MAE=0.615, train_loss=0.668, val_MAE=0.675, val_loss=0.728]Epoch 49:   5%|▍         | 49/1000 [1:34:50<29:51:20, 113.02s/it, lr=0.000125, test_MAE=0.711, time=113, train_MAE=0.611, train_loss=0.665, val_MAE=0.642, val_loss=0.696]Epoch 49:   5%|▌         | 50/1000 [1:34:50<29:47:11, 112.88s/it, lr=0.000125, test_MAE=0.711, time=113, train_MAE=0.611, train_loss=0.665, val_MAE=0.642, val_loss=0.696]Epoch 50:   5%|▌         | 50/1000 [1:34:50<29:47:11, 112.88s/it, lr=0.000125, test_MAE=0.711, time=113, train_MAE=0.611, train_loss=0.665, val_MAE=0.642, val_loss=0.696]Epoch 50:   5%|▌         | 50/1000 [1:36:42<29:47:11, 112.88s/it, lr=0.000125, test_MAE=0.699, time=113, train_MAE=0.616, train_loss=0.67, val_MAE=0.666, val_loss=0.72]  Epoch 50:   5%|▌         | 51/1000 [1:36:42<29:44:02, 112.80s/it, lr=0.000125, test_MAE=0.699, time=113, train_MAE=0.616, train_loss=0.67, val_MAE=0.666, val_loss=0.72]Epoch 51:   5%|▌         | 51/1000 [1:36:42<29:44:02, 112.80s/it, lr=0.000125, test_MAE=0.699, time=113, train_MAE=0.616, train_loss=0.67, val_MAE=0.666, val_loss=0.72]Epoch 51:   5%|▌         | 51/1000 [1:38:35<29:44:02, 112.80s/it, lr=0.000125, test_MAE=0.714, time=113, train_MAE=0.61, train_loss=0.664, val_MAE=0.652, val_loss=0.706]Epoch 51:   5%|▌         | 52/1000 [1:38:35<29:42:34, 112.82s/it, lr=0.000125, test_MAE=0.714, time=113, train_MAE=0.61, train_loss=0.664, val_MAE=0.652, val_loss=0.706]Epoch 52:   5%|▌         | 52/1000 [1:38:35<29:42:34, 112.82s/it, lr=0.000125, test_MAE=0.714, time=113, train_MAE=0.61, train_loss=0.664, val_MAE=0.652, val_loss=0.706]Epoch 52:   5%|▌         | 52/1000 [1:40:28<29:42:34, 112.82s/it, lr=0.000125, test_MAE=0.737, time=113, train_MAE=0.615, train_loss=0.668, val_MAE=0.688, val_loss=0.741]Epoch 52:   5%|▌         | 53/1000 [1:40:28<29:39:30, 112.75s/it, lr=0.000125, test_MAE=0.737, time=113, train_MAE=0.615, train_loss=0.668, val_MAE=0.688, val_loss=0.741]Epoch 53:   5%|▌         | 53/1000 [1:40:28<29:39:30, 112.75s/it, lr=0.000125, test_MAE=0.737, time=113, train_MAE=0.615, train_loss=0.668, val_MAE=0.688, val_loss=0.741]Epoch 53:   5%|▌         | 53/1000 [1:42:20<29:39:30, 112.75s/it, lr=0.000125, test_MAE=0.706, time=113, train_MAE=0.62, train_loss=0.673, val_MAE=0.676, val_loss=0.729] Epoch 53:   5%|▌         | 54/1000 [1:42:20<29:36:41, 112.69s/it, lr=0.000125, test_MAE=0.706, time=113, train_MAE=0.62, train_loss=0.673, val_MAE=0.676, val_loss=0.729]Epoch 54:   5%|▌         | 54/1000 [1:42:20<29:36:41, 112.69s/it, lr=0.000125, test_MAE=0.706, time=113, train_MAE=0.62, train_loss=0.673, val_MAE=0.676, val_loss=0.729]Epoch 54:   5%|▌         | 54/1000 [1:44:13<29:36:41, 112.69s/it, lr=0.000125, test_MAE=0.739, time=113, train_MAE=0.622, train_loss=0.675, val_MAE=0.682, val_loss=0.735]Epoch 54:   6%|▌         | 55/1000 [1:44:13<29:34:46, 112.68s/it, lr=0.000125, test_MAE=0.739, time=113, train_MAE=0.622, train_loss=0.675, val_MAE=0.682, val_loss=0.735]Epoch 55:   6%|▌         | 55/1000 [1:44:13<29:34:46, 112.68s/it, lr=0.000125, test_MAE=0.739, time=113, train_MAE=0.622, train_loss=0.675, val_MAE=0.682, val_loss=0.735]Epoch 55:   6%|▌         | 55/1000 [1:46:06<29:34:46, 112.68s/it, lr=0.000125, test_MAE=0.698, time=113, train_MAE=0.626, train_loss=0.68, val_MAE=0.649, val_loss=0.702] Epoch    56: reducing learning rate of group 0 to 6.2500e-05.
Epoch 55:   6%|▌         | 56/1000 [1:46:06<29:34:17, 112.77s/it, lr=0.000125, test_MAE=0.698, time=113, train_MAE=0.626, train_loss=0.68, val_MAE=0.649, val_loss=0.702]Epoch 56:   6%|▌         | 56/1000 [1:46:06<29:34:17, 112.77s/it, lr=0.000125, test_MAE=0.698, time=113, train_MAE=0.626, train_loss=0.68, val_MAE=0.649, val_loss=0.702]Epoch 56:   6%|▌         | 56/1000 [1:47:59<29:34:17, 112.77s/it, lr=6.25e-5, test_MAE=0.696, time=113, train_MAE=0.616, train_loss=0.669, val_MAE=0.648, val_loss=0.702]Epoch 56:   6%|▌         | 57/1000 [1:47:59<29:31:16, 112.70s/it, lr=6.25e-5, test_MAE=0.696, time=113, train_MAE=0.616, train_loss=0.669, val_MAE=0.648, val_loss=0.702]Epoch 57:   6%|▌         | 57/1000 [1:47:59<29:31:16, 112.70s/it, lr=6.25e-5, test_MAE=0.696, time=113, train_MAE=0.616, train_loss=0.669, val_MAE=0.648, val_loss=0.702]Epoch 57:   6%|▌         | 57/1000 [1:49:51<29:31:16, 112.70s/it, lr=6.25e-5, test_MAE=0.725, time=113, train_MAE=0.616, train_loss=0.669, val_MAE=0.687, val_loss=0.74] Epoch 57:   6%|▌         | 58/1000 [1:49:51<29:28:43, 112.66s/it, lr=6.25e-5, test_MAE=0.725, time=113, train_MAE=0.616, train_loss=0.669, val_MAE=0.687, val_loss=0.74]Epoch 58:   6%|▌         | 58/1000 [1:49:51<29:28:43, 112.66s/it, lr=6.25e-5, test_MAE=0.725, time=113, train_MAE=0.616, train_loss=0.669, val_MAE=0.687, val_loss=0.74]Epoch 58:   6%|▌         | 58/1000 [1:51:44<29:28:43, 112.66s/it, lr=6.25e-5, test_MAE=0.701, time=113, train_MAE=0.615, train_loss=0.669, val_MAE=0.65, val_loss=0.704]Epoch 58:   6%|▌         | 59/1000 [1:51:44<29:28:44, 112.78s/it, lr=6.25e-5, test_MAE=0.701, time=113, train_MAE=0.615, train_loss=0.669, val_MAE=0.65, val_loss=0.704]Epoch 59:   6%|▌         | 59/1000 [1:51:44<29:28:44, 112.78s/it, lr=6.25e-5, test_MAE=0.701, time=113, train_MAE=0.615, train_loss=0.669, val_MAE=0.65, val_loss=0.704]Epoch 59:   6%|▌         | 59/1000 [1:53:37<29:28:44, 112.78s/it, lr=6.25e-5, test_MAE=0.698, time=113, train_MAE=0.61, train_loss=0.663, val_MAE=0.655, val_loss=0.709]Epoch 59:   6%|▌         | 60/1000 [1:53:37<29:26:13, 112.74s/it, lr=6.25e-5, test_MAE=0.698, time=113, train_MAE=0.61, train_loss=0.663, val_MAE=0.655, val_loss=0.709]Epoch 60:   6%|▌         | 60/1000 [1:53:37<29:26:13, 112.74s/it, lr=6.25e-5, test_MAE=0.698, time=113, train_MAE=0.61, train_loss=0.663, val_MAE=0.655, val_loss=0.709]Epoch 60:   6%|▌         | 60/1000 [1:55:30<29:26:13, 112.74s/it, lr=6.25e-5, test_MAE=0.713, time=113, train_MAE=0.618, train_loss=0.671, val_MAE=0.675, val_loss=0.728]Epoch 60:   6%|▌         | 61/1000 [1:55:30<29:23:42, 112.70s/it, lr=6.25e-5, test_MAE=0.713, time=113, train_MAE=0.618, train_loss=0.671, val_MAE=0.675, val_loss=0.728]Epoch 61:   6%|▌         | 61/1000 [1:55:30<29:23:42, 112.70s/it, lr=6.25e-5, test_MAE=0.713, time=113, train_MAE=0.618, train_loss=0.671, val_MAE=0.675, val_loss=0.728]Epoch 61:   6%|▌         | 61/1000 [1:57:22<29:23:42, 112.70s/it, lr=6.25e-5, test_MAE=0.69, time=113, train_MAE=0.611, train_loss=0.664, val_MAE=0.656, val_loss=0.71]  Epoch    62: reducing learning rate of group 0 to 3.1250e-05.
Epoch 61:   6%|▌         | 62/1000 [1:57:22<29:21:27, 112.67s/it, lr=6.25e-5, test_MAE=0.69, time=113, train_MAE=0.611, train_loss=0.664, val_MAE=0.656, val_loss=0.71]Epoch 62:   6%|▌         | 62/1000 [1:57:22<29:21:27, 112.67s/it, lr=6.25e-5, test_MAE=0.69, time=113, train_MAE=0.611, train_loss=0.664, val_MAE=0.656, val_loss=0.71]Epoch 62:   6%|▌         | 62/1000 [1:59:15<29:21:27, 112.67s/it, lr=3.13e-5, test_MAE=0.694, time=113, train_MAE=0.617, train_loss=0.67, val_MAE=0.644, val_loss=0.697]Epoch 62:   6%|▋         | 63/1000 [1:59:15<29:20:47, 112.75s/it, lr=3.13e-5, test_MAE=0.694, time=113, train_MAE=0.617, train_loss=0.67, val_MAE=0.644, val_loss=0.697]Epoch 63:   6%|▋         | 63/1000 [1:59:15<29:20:47, 112.75s/it, lr=3.13e-5, test_MAE=0.694, time=113, train_MAE=0.617, train_loss=0.67, val_MAE=0.644, val_loss=0.697]Epoch 63:   6%|▋         | 63/1000 [2:01:08<29:20:47, 112.75s/it, lr=3.13e-5, test_MAE=0.712, time=113, train_MAE=0.61, train_loss=0.663, val_MAE=0.666, val_loss=0.719]Epoch 63:   6%|▋         | 64/1000 [2:01:08<29:18:25, 112.72s/it, lr=3.13e-5, test_MAE=0.712, time=113, train_MAE=0.61, train_loss=0.663, val_MAE=0.666, val_loss=0.719]Epoch 64:   6%|▋         | 64/1000 [2:01:08<29:18:25, 112.72s/it, lr=3.13e-5, test_MAE=0.712, time=113, train_MAE=0.61, train_loss=0.663, val_MAE=0.666, val_loss=0.719]Epoch 64:   6%|▋         | 64/1000 [2:03:00<29:18:25, 112.72s/it, lr=3.13e-5, test_MAE=0.69, time=113, train_MAE=0.612, train_loss=0.665, val_MAE=0.642, val_loss=0.695]Epoch 64:   6%|▋         | 65/1000 [2:03:00<29:15:43, 112.67s/it, lr=3.13e-5, test_MAE=0.69, time=113, train_MAE=0.612, train_loss=0.665, val_MAE=0.642, val_loss=0.695]Epoch 65:   6%|▋         | 65/1000 [2:03:00<29:15:43, 112.67s/it, lr=3.13e-5, test_MAE=0.69, time=113, train_MAE=0.612, train_loss=0.665, val_MAE=0.642, val_loss=0.695]Epoch 65:   6%|▋         | 65/1000 [2:04:53<29:15:43, 112.67s/it, lr=3.13e-5, test_MAE=0.702, time=113, train_MAE=0.611, train_loss=0.664, val_MAE=0.657, val_loss=0.711]Epoch 65:   7%|▋         | 66/1000 [2:04:53<29:14:50, 112.73s/it, lr=3.13e-5, test_MAE=0.702, time=113, train_MAE=0.611, train_loss=0.664, val_MAE=0.657, val_loss=0.711]Epoch 66:   7%|▋         | 66/1000 [2:04:53<29:14:50, 112.73s/it, lr=3.13e-5, test_MAE=0.702, time=113, train_MAE=0.611, train_loss=0.664, val_MAE=0.657, val_loss=0.711]Epoch 66:   7%|▋         | 66/1000 [2:06:46<29:14:50, 112.73s/it, lr=3.13e-5, test_MAE=0.703, time=113, train_MAE=0.61, train_loss=0.663, val_MAE=0.662, val_loss=0.715] Epoch 66:   7%|▋         | 67/1000 [2:06:46<29:12:33, 112.70s/it, lr=3.13e-5, test_MAE=0.703, time=113, train_MAE=0.61, train_loss=0.663, val_MAE=0.662, val_loss=0.715]Epoch 67:   7%|▋         | 67/1000 [2:06:46<29:12:33, 112.70s/it, lr=3.13e-5, test_MAE=0.703, time=113, train_MAE=0.61, train_loss=0.663, val_MAE=0.662, val_loss=0.715]Epoch 67:   7%|▋         | 67/1000 [2:08:38<29:12:33, 112.70s/it, lr=3.13e-5, test_MAE=0.703, time=113, train_MAE=0.627, train_loss=0.68, val_MAE=0.657, val_loss=0.71] Epoch 67:   7%|▋         | 68/1000 [2:08:38<29:10:02, 112.66s/it, lr=3.13e-5, test_MAE=0.703, time=113, train_MAE=0.627, train_loss=0.68, val_MAE=0.657, val_loss=0.71]Epoch 68:   7%|▋         | 68/1000 [2:08:38<29:10:02, 112.66s/it, lr=3.13e-5, test_MAE=0.703, time=113, train_MAE=0.627, train_loss=0.68, val_MAE=0.657, val_loss=0.71]Epoch 68:   7%|▋         | 68/1000 [2:10:31<29:10:02, 112.66s/it, lr=3.13e-5, test_MAE=0.699, time=113, train_MAE=0.609, train_loss=0.662, val_MAE=0.667, val_loss=0.72]Epoch 68:   7%|▋         | 69/1000 [2:10:31<29:08:17, 112.67s/it, lr=3.13e-5, test_MAE=0.699, time=113, train_MAE=0.609, train_loss=0.662, val_MAE=0.667, val_loss=0.72]Epoch 69:   7%|▋         | 69/1000 [2:10:31<29:08:17, 112.67s/it, lr=3.13e-5, test_MAE=0.699, time=113, train_MAE=0.609, train_loss=0.662, val_MAE=0.667, val_loss=0.72]Epoch 69:   7%|▋         | 69/1000 [2:12:24<29:08:17, 112.67s/it, lr=3.13e-5, test_MAE=0.694, time=113, train_MAE=0.613, train_loss=0.666, val_MAE=0.656, val_loss=0.709]Epoch 69:   7%|▋         | 70/1000 [2:12:24<29:07:55, 112.77s/it, lr=3.13e-5, test_MAE=0.694, time=113, train_MAE=0.613, train_loss=0.666, val_MAE=0.656, val_loss=0.709]Epoch 70:   7%|▋         | 70/1000 [2:12:24<29:07:55, 112.77s/it, lr=3.13e-5, test_MAE=0.694, time=113, train_MAE=0.613, train_loss=0.666, val_MAE=0.656, val_loss=0.709]Epoch 70:   7%|▋         | 70/1000 [2:14:17<29:07:55, 112.77s/it, lr=3.13e-5, test_MAE=0.708, time=113, train_MAE=0.611, train_loss=0.664, val_MAE=0.649, val_loss=0.702]Epoch    71: reducing learning rate of group 0 to 1.5625e-05.
Epoch 70:   7%|▋         | 71/1000 [2:14:17<29:05:05, 112.71s/it, lr=3.13e-5, test_MAE=0.708, time=113, train_MAE=0.611, train_loss=0.664, val_MAE=0.649, val_loss=0.702]Epoch 71:   7%|▋         | 71/1000 [2:14:17<29:05:05, 112.71s/it, lr=3.13e-5, test_MAE=0.708, time=113, train_MAE=0.611, train_loss=0.664, val_MAE=0.649, val_loss=0.702]Epoch 71:   7%|▋         | 71/1000 [2:16:09<29:05:05, 112.71s/it, lr=1.56e-5, test_MAE=0.698, time=113, train_MAE=0.606, train_loss=0.659, val_MAE=0.648, val_loss=0.701]Epoch 71:   7%|▋         | 72/1000 [2:16:09<29:02:59, 112.69s/it, lr=1.56e-5, test_MAE=0.698, time=113, train_MAE=0.606, train_loss=0.659, val_MAE=0.648, val_loss=0.701]Epoch 72:   7%|▋         | 72/1000 [2:16:09<29:02:59, 112.69s/it, lr=1.56e-5, test_MAE=0.698, time=113, train_MAE=0.606, train_loss=0.659, val_MAE=0.648, val_loss=0.701]Epoch 72:   7%|▋         | 72/1000 [2:18:02<29:02:59, 112.69s/it, lr=1.56e-5, test_MAE=0.684, time=113, train_MAE=0.611, train_loss=0.664, val_MAE=0.652, val_loss=0.705]Epoch 72:   7%|▋         | 73/1000 [2:18:02<29:02:00, 112.75s/it, lr=1.56e-5, test_MAE=0.684, time=113, train_MAE=0.611, train_loss=0.664, val_MAE=0.652, val_loss=0.705]Epoch 73:   7%|▋         | 73/1000 [2:18:02<29:02:00, 112.75s/it, lr=1.56e-5, test_MAE=0.684, time=113, train_MAE=0.611, train_loss=0.664, val_MAE=0.652, val_loss=0.705]Epoch 73:   7%|▋         | 73/1000 [2:19:55<29:02:00, 112.75s/it, lr=1.56e-5, test_MAE=0.698, time=113, train_MAE=0.608, train_loss=0.661, val_MAE=0.652, val_loss=0.705]Epoch 73:   7%|▋         | 74/1000 [2:19:55<28:59:49, 112.73s/it, lr=1.56e-5, test_MAE=0.698, time=113, train_MAE=0.608, train_loss=0.661, val_MAE=0.652, val_loss=0.705]Epoch 74:   7%|▋         | 74/1000 [2:19:55<28:59:49, 112.73s/it, lr=1.56e-5, test_MAE=0.698, time=113, train_MAE=0.608, train_loss=0.661, val_MAE=0.652, val_loss=0.705]Epoch 74:   7%|▋         | 74/1000 [2:21:47<28:59:49, 112.73s/it, lr=1.56e-5, test_MAE=0.716, time=112, train_MAE=0.609, train_loss=0.662, val_MAE=0.698, val_loss=0.751]Epoch 74:   8%|▊         | 75/1000 [2:21:47<28:55:13, 112.56s/it, lr=1.56e-5, test_MAE=0.716, time=112, train_MAE=0.609, train_loss=0.662, val_MAE=0.698, val_loss=0.751]Epoch 75:   8%|▊         | 75/1000 [2:21:47<28:55:13, 112.56s/it, lr=1.56e-5, test_MAE=0.716, time=112, train_MAE=0.609, train_loss=0.662, val_MAE=0.698, val_loss=0.751]Epoch 75:   8%|▊         | 75/1000 [2:23:39<28:55:13, 112.56s/it, lr=1.56e-5, test_MAE=0.695, time=112, train_MAE=0.603, train_loss=0.656, val_MAE=0.665, val_loss=0.718]Epoch 75:   8%|▊         | 76/1000 [2:23:39<28:52:07, 112.48s/it, lr=1.56e-5, test_MAE=0.695, time=112, train_MAE=0.603, train_loss=0.656, val_MAE=0.665, val_loss=0.718]Epoch 76:   8%|▊         | 76/1000 [2:23:39<28:52:07, 112.48s/it, lr=1.56e-5, test_MAE=0.695, time=112, train_MAE=0.603, train_loss=0.656, val_MAE=0.665, val_loss=0.718]Epoch 76:   8%|▊         | 76/1000 [2:25:30<28:52:07, 112.48s/it, lr=1.56e-5, test_MAE=0.694, time=111, train_MAE=0.607, train_loss=0.66, val_MAE=0.654, val_loss=0.707] Epoch    77: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 76:   8%|▊         | 76/1000 [2:25:30<29:29:03, 114.87s/it, lr=1.56e-5, test_MAE=0.694, time=111, train_MAE=0.607, train_loss=0.66, val_MAE=0.654, val_loss=0.707]
Test MAE: 0.6942
Train MAE: 0.6272
Convergence Time (Epochs): 76.0000
TOTAL TIME TAKEN: 8780.2156s
AVG TIME PER EPOCH: 113.3648s
