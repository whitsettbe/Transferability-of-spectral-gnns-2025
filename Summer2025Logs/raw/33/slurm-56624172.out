I'm echoing to stdout
I'm echoing to stderr
My JobID is 56624172
I have 8 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.1120s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 4, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'rational_vec', 'normalized_laplacian': True, 'post_normalized': False, 'eigval_norm': '', 'num_eigs': 15, 'bias_mode': 'spatial', 'eigval_hidden_dim': 5, 'eigval_num_hidden_layer': 3, 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 1, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/zinc_train_kway.csv', 'test': 'supp_data/molecules/zinc_test_part_kway.csv', 'val': 'supp_data/molecules/zinc_val_kway.csv'}, 'fixMissingPhi1': True, 'extraOrtho': False, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [02:05<?, ?it/s, lr=0.001, test_MAE=1.57, time=125, train_MAE=1.22, train_loss=1.24, val_MAE=1.53, val_loss=1.55]Epoch 0:   0%|          | 1/1000 [02:05<34:41:59, 125.04s/it, lr=0.001, test_MAE=1.57, time=125, train_MAE=1.22, train_loss=1.24, val_MAE=1.53, val_loss=1.55]Epoch 1:   0%|          | 1/1000 [02:05<34:41:59, 125.04s/it, lr=0.001, test_MAE=1.57, time=125, train_MAE=1.22, train_loss=1.24, val_MAE=1.53, val_loss=1.55]Epoch 1:   0%|          | 1/1000 [03:58<34:41:59, 125.04s/it, lr=0.001, test_MAE=1.27, time=113, train_MAE=0.868, train_loss=0.899, val_MAE=1.17, val_loss=1.2]Epoch 1:   0%|          | 2/1000 [03:58<33:42:16, 121.58s/it, lr=0.001, test_MAE=1.27, time=113, train_MAE=0.868, train_loss=0.899, val_MAE=1.17, val_loss=1.2]Epoch 2:   0%|          | 2/1000 [03:58<33:42:16, 121.58s/it, lr=0.001, test_MAE=1.27, time=113, train_MAE=0.868, train_loss=0.899, val_MAE=1.17, val_loss=1.2]Epoch 2:   0%|          | 2/1000 [05:52<33:42:16, 121.58s/it, lr=0.001, test_MAE=1.19, time=114, train_MAE=0.781, train_loss=0.815, val_MAE=1.11, val_loss=1.14]Epoch 2:   0%|          | 3/1000 [05:52<33:02:47, 119.33s/it, lr=0.001, test_MAE=1.19, time=114, train_MAE=0.781, train_loss=0.815, val_MAE=1.11, val_loss=1.14]Epoch 3:   0%|          | 3/1000 [05:52<33:02:47, 119.33s/it, lr=0.001, test_MAE=1.19, time=114, train_MAE=0.781, train_loss=0.815, val_MAE=1.11, val_loss=1.14]Epoch 3:   0%|          | 3/1000 [07:46<33:02:47, 119.33s/it, lr=0.001, test_MAE=1.24, time=114, train_MAE=0.724, train_loss=0.759, val_MAE=1.16, val_loss=1.2] Epoch 3:   0%|          | 4/1000 [07:46<32:35:00, 117.77s/it, lr=0.001, test_MAE=1.24, time=114, train_MAE=0.724, train_loss=0.759, val_MAE=1.16, val_loss=1.2]Epoch 4:   0%|          | 4/1000 [07:46<32:35:00, 117.77s/it, lr=0.001, test_MAE=1.24, time=114, train_MAE=0.724, train_loss=0.759, val_MAE=1.16, val_loss=1.2]Epoch 4:   0%|          | 4/1000 [09:40<32:35:00, 117.77s/it, lr=0.001, test_MAE=0.885, time=114, train_MAE=0.695, train_loss=0.73, val_MAE=0.83, val_loss=0.866]Epoch 4:   0%|          | 5/1000 [09:40<32:13:12, 116.58s/it, lr=0.001, test_MAE=0.885, time=114, train_MAE=0.695, train_loss=0.73, val_MAE=0.83, val_loss=0.866]Epoch 5:   0%|          | 5/1000 [09:40<32:13:12, 116.58s/it, lr=0.001, test_MAE=0.885, time=114, train_MAE=0.695, train_loss=0.73, val_MAE=0.83, val_loss=0.866]Epoch 5:   0%|          | 5/1000 [11:34<32:13:12, 116.58s/it, lr=0.001, test_MAE=0.97, time=113, train_MAE=0.692, train_loss=0.728, val_MAE=0.909, val_loss=0.946]Epoch 5:   1%|          | 6/1000 [11:34<31:56:00, 115.65s/it, lr=0.001, test_MAE=0.97, time=113, train_MAE=0.692, train_loss=0.728, val_MAE=0.909, val_loss=0.946]Epoch 6:   1%|          | 6/1000 [11:34<31:56:00, 115.65s/it, lr=0.001, test_MAE=0.97, time=113, train_MAE=0.692, train_loss=0.728, val_MAE=0.909, val_loss=0.946]Epoch 6:   1%|          | 6/1000 [13:28<31:56:00, 115.65s/it, lr=0.001, test_MAE=0.82, time=114, train_MAE=0.669, train_loss=0.706, val_MAE=0.698, val_loss=0.735]Epoch 6:   1%|          | 7/1000 [13:28<31:48:25, 115.31s/it, lr=0.001, test_MAE=0.82, time=114, train_MAE=0.669, train_loss=0.706, val_MAE=0.698, val_loss=0.735]Epoch 7:   1%|          | 7/1000 [13:28<31:48:25, 115.31s/it, lr=0.001, test_MAE=0.82, time=114, train_MAE=0.669, train_loss=0.706, val_MAE=0.698, val_loss=0.735]Epoch 7:   1%|          | 7/1000 [15:22<31:48:25, 115.31s/it, lr=0.001, test_MAE=0.769, time=114, train_MAE=0.673, train_loss=0.71, val_MAE=0.713, val_loss=0.75] Epoch 7:   1%|          | 8/1000 [15:22<31:38:34, 114.83s/it, lr=0.001, test_MAE=0.769, time=114, train_MAE=0.673, train_loss=0.71, val_MAE=0.713, val_loss=0.75]Epoch 8:   1%|          | 8/1000 [15:22<31:38:34, 114.83s/it, lr=0.001, test_MAE=0.769, time=114, train_MAE=0.673, train_loss=0.71, val_MAE=0.713, val_loss=0.75]Epoch 8:   1%|          | 8/1000 [17:16<31:38:34, 114.83s/it, lr=0.001, test_MAE=0.833, time=114, train_MAE=0.663, train_loss=0.701, val_MAE=0.788, val_loss=0.825]Epoch 8:   1%|          | 9/1000 [17:16<31:31:43, 114.53s/it, lr=0.001, test_MAE=0.833, time=114, train_MAE=0.663, train_loss=0.701, val_MAE=0.788, val_loss=0.825]Epoch 9:   1%|          | 9/1000 [17:16<31:31:43, 114.53s/it, lr=0.001, test_MAE=0.833, time=114, train_MAE=0.663, train_loss=0.701, val_MAE=0.788, val_loss=0.825]Epoch 9:   1%|          | 9/1000 [19:09<31:31:43, 114.53s/it, lr=0.001, test_MAE=0.777, time=114, train_MAE=0.669, train_loss=0.707, val_MAE=0.723, val_loss=0.761]Epoch 9:   1%|          | 10/1000 [19:09<31:25:33, 114.28s/it, lr=0.001, test_MAE=0.777, time=114, train_MAE=0.669, train_loss=0.707, val_MAE=0.723, val_loss=0.761]Epoch 10:   1%|          | 10/1000 [19:09<31:25:33, 114.28s/it, lr=0.001, test_MAE=0.777, time=114, train_MAE=0.669, train_loss=0.707, val_MAE=0.723, val_loss=0.761]Epoch 10:   1%|          | 10/1000 [21:04<31:25:33, 114.28s/it, lr=0.001, test_MAE=0.78, time=114, train_MAE=0.659, train_loss=0.697, val_MAE=0.719, val_loss=0.758] Epoch 10:   1%|          | 11/1000 [21:04<31:24:25, 114.32s/it, lr=0.001, test_MAE=0.78, time=114, train_MAE=0.659, train_loss=0.697, val_MAE=0.719, val_loss=0.758]Epoch 11:   1%|          | 11/1000 [21:04<31:24:25, 114.32s/it, lr=0.001, test_MAE=0.78, time=114, train_MAE=0.659, train_loss=0.697, val_MAE=0.719, val_loss=0.758]Epoch 11:   1%|          | 11/1000 [22:57<31:24:25, 114.32s/it, lr=0.001, test_MAE=0.73, time=114, train_MAE=0.654, train_loss=0.693, val_MAE=0.666, val_loss=0.705]Epoch 11:   1%|          | 12/1000 [22:57<31:19:09, 114.12s/it, lr=0.001, test_MAE=0.73, time=114, train_MAE=0.654, train_loss=0.693, val_MAE=0.666, val_loss=0.705]Epoch 12:   1%|          | 12/1000 [22:57<31:19:09, 114.12s/it, lr=0.001, test_MAE=0.73, time=114, train_MAE=0.654, train_loss=0.693, val_MAE=0.666, val_loss=0.705]Epoch 12:   1%|          | 12/1000 [24:51<31:19:09, 114.12s/it, lr=0.001, test_MAE=0.719, time=113, train_MAE=0.65, train_loss=0.69, val_MAE=0.662, val_loss=0.702] Epoch 12:   1%|▏         | 13/1000 [24:51<31:13:04, 113.86s/it, lr=0.001, test_MAE=0.719, time=113, train_MAE=0.65, train_loss=0.69, val_MAE=0.662, val_loss=0.702]Epoch 13:   1%|▏         | 13/1000 [24:51<31:13:04, 113.86s/it, lr=0.001, test_MAE=0.719, time=113, train_MAE=0.65, train_loss=0.69, val_MAE=0.662, val_loss=0.702]Epoch 13:   1%|▏         | 13/1000 [26:45<31:13:04, 113.86s/it, lr=0.001, test_MAE=0.71, time=114, train_MAE=0.645, train_loss=0.684, val_MAE=0.662, val_loss=0.701]Epoch 13:   1%|▏         | 14/1000 [26:45<31:12:28, 113.94s/it, lr=0.001, test_MAE=0.71, time=114, train_MAE=0.645, train_loss=0.684, val_MAE=0.662, val_loss=0.701]Epoch 14:   1%|▏         | 14/1000 [26:45<31:12:28, 113.94s/it, lr=0.001, test_MAE=0.71, time=114, train_MAE=0.645, train_loss=0.684, val_MAE=0.662, val_loss=0.701]Epoch 14:   1%|▏         | 14/1000 [28:39<31:12:28, 113.94s/it, lr=0.001, test_MAE=0.739, time=114, train_MAE=0.657, train_loss=0.697, val_MAE=0.673, val_loss=0.713]Epoch 14:   2%|▏         | 15/1000 [28:39<31:09:52, 113.90s/it, lr=0.001, test_MAE=0.739, time=114, train_MAE=0.657, train_loss=0.697, val_MAE=0.673, val_loss=0.713]Epoch 15:   2%|▏         | 15/1000 [28:39<31:09:52, 113.90s/it, lr=0.001, test_MAE=0.739, time=114, train_MAE=0.657, train_loss=0.697, val_MAE=0.673, val_loss=0.713]Epoch 15:   2%|▏         | 15/1000 [30:32<31:09:52, 113.90s/it, lr=0.001, test_MAE=0.707, time=114, train_MAE=0.638, train_loss=0.678, val_MAE=0.663, val_loss=0.704]Epoch 15:   2%|▏         | 16/1000 [30:32<31:06:33, 113.81s/it, lr=0.001, test_MAE=0.707, time=114, train_MAE=0.638, train_loss=0.678, val_MAE=0.663, val_loss=0.704]Epoch 16:   2%|▏         | 16/1000 [30:32<31:06:33, 113.81s/it, lr=0.001, test_MAE=0.707, time=114, train_MAE=0.638, train_loss=0.678, val_MAE=0.663, val_loss=0.704]Epoch 16:   2%|▏         | 16/1000 [32:26<31:06:33, 113.81s/it, lr=0.001, test_MAE=0.724, time=114, train_MAE=0.644, train_loss=0.685, val_MAE=0.686, val_loss=0.727]Epoch 16:   2%|▏         | 17/1000 [32:26<31:04:00, 113.78s/it, lr=0.001, test_MAE=0.724, time=114, train_MAE=0.644, train_loss=0.685, val_MAE=0.686, val_loss=0.727]Epoch 17:   2%|▏         | 17/1000 [32:26<31:04:00, 113.78s/it, lr=0.001, test_MAE=0.724, time=114, train_MAE=0.644, train_loss=0.685, val_MAE=0.686, val_loss=0.727]Epoch 17:   2%|▏         | 17/1000 [34:20<31:04:00, 113.78s/it, lr=0.001, test_MAE=0.851, time=114, train_MAE=0.636, train_loss=0.677, val_MAE=0.822, val_loss=0.863]Epoch 17:   2%|▏         | 18/1000 [34:20<31:04:05, 113.90s/it, lr=0.001, test_MAE=0.851, time=114, train_MAE=0.636, train_loss=0.677, val_MAE=0.822, val_loss=0.863]Epoch 18:   2%|▏         | 18/1000 [34:20<31:04:05, 113.90s/it, lr=0.001, test_MAE=0.851, time=114, train_MAE=0.636, train_loss=0.677, val_MAE=0.822, val_loss=0.863]Epoch 18:   2%|▏         | 18/1000 [36:13<31:04:05, 113.90s/it, lr=0.001, test_MAE=0.723, time=113, train_MAE=0.637, train_loss=0.678, val_MAE=0.674, val_loss=0.715]Epoch 18:   2%|▏         | 19/1000 [36:13<30:59:17, 113.72s/it, lr=0.001, test_MAE=0.723, time=113, train_MAE=0.637, train_loss=0.678, val_MAE=0.674, val_loss=0.715]Epoch 19:   2%|▏         | 19/1000 [36:13<30:59:17, 113.72s/it, lr=0.001, test_MAE=0.723, time=113, train_MAE=0.637, train_loss=0.678, val_MAE=0.674, val_loss=0.715]Epoch 19:   2%|▏         | 19/1000 [38:07<30:59:17, 113.72s/it, lr=0.001, test_MAE=0.84, time=114, train_MAE=0.64, train_loss=0.682, val_MAE=0.784, val_loss=0.825]  Epoch    20: reducing learning rate of group 0 to 5.0000e-04.
Epoch 19:   2%|▏         | 20/1000 [38:07<30:58:36, 113.79s/it, lr=0.001, test_MAE=0.84, time=114, train_MAE=0.64, train_loss=0.682, val_MAE=0.784, val_loss=0.825]Epoch 20:   2%|▏         | 20/1000 [38:07<30:58:36, 113.79s/it, lr=0.001, test_MAE=0.84, time=114, train_MAE=0.64, train_loss=0.682, val_MAE=0.784, val_loss=0.825]Epoch 20:   2%|▏         | 20/1000 [40:01<30:58:36, 113.79s/it, lr=0.0005, test_MAE=0.724, time=114, train_MAE=0.647, train_loss=0.689, val_MAE=0.67, val_loss=0.712]Epoch 20:   2%|▏         | 21/1000 [40:01<30:58:18, 113.89s/it, lr=0.0005, test_MAE=0.724, time=114, train_MAE=0.647, train_loss=0.689, val_MAE=0.67, val_loss=0.712]Epoch 21:   2%|▏         | 21/1000 [40:01<30:58:18, 113.89s/it, lr=0.0005, test_MAE=0.724, time=114, train_MAE=0.647, train_loss=0.689, val_MAE=0.67, val_loss=0.712]Epoch 21:   2%|▏         | 21/1000 [41:55<30:58:18, 113.89s/it, lr=0.0005, test_MAE=0.711, time=114, train_MAE=0.624, train_loss=0.665, val_MAE=0.665, val_loss=0.707]Epoch 21:   2%|▏         | 22/1000 [41:55<30:55:46, 113.85s/it, lr=0.0005, test_MAE=0.711, time=114, train_MAE=0.624, train_loss=0.665, val_MAE=0.665, val_loss=0.707]Epoch 22:   2%|▏         | 22/1000 [41:55<30:55:46, 113.85s/it, lr=0.0005, test_MAE=0.711, time=114, train_MAE=0.624, train_loss=0.665, val_MAE=0.665, val_loss=0.707]Epoch 22:   2%|▏         | 22/1000 [43:49<30:55:46, 113.85s/it, lr=0.0005, test_MAE=0.691, time=113, train_MAE=0.621, train_loss=0.662, val_MAE=0.641, val_loss=0.682]Epoch 22:   2%|▏         | 23/1000 [43:49<30:51:24, 113.70s/it, lr=0.0005, test_MAE=0.691, time=113, train_MAE=0.621, train_loss=0.662, val_MAE=0.641, val_loss=0.682]Epoch 23:   2%|▏         | 23/1000 [43:49<30:51:24, 113.70s/it, lr=0.0005, test_MAE=0.691, time=113, train_MAE=0.621, train_loss=0.662, val_MAE=0.641, val_loss=0.682]Epoch 23:   2%|▏         | 23/1000 [45:43<30:51:24, 113.70s/it, lr=0.0005, test_MAE=0.716, time=114, train_MAE=0.621, train_loss=0.662, val_MAE=0.675, val_loss=0.717]Epoch 23:   2%|▏         | 24/1000 [45:43<30:51:37, 113.83s/it, lr=0.0005, test_MAE=0.716, time=114, train_MAE=0.621, train_loss=0.662, val_MAE=0.675, val_loss=0.717]Epoch 24:   2%|▏         | 24/1000 [45:43<30:51:37, 113.83s/it, lr=0.0005, test_MAE=0.716, time=114, train_MAE=0.621, train_loss=0.662, val_MAE=0.675, val_loss=0.717]Epoch 24:   2%|▏         | 24/1000 [47:35<30:51:37, 113.83s/it, lr=0.0005, test_MAE=0.712, time=112, train_MAE=0.624, train_loss=0.666, val_MAE=0.672, val_loss=0.713]Epoch 24:   2%|▎         | 25/1000 [47:35<30:41:33, 113.33s/it, lr=0.0005, test_MAE=0.712, time=112, train_MAE=0.624, train_loss=0.666, val_MAE=0.672, val_loss=0.713]Epoch 25:   2%|▎         | 25/1000 [47:35<30:41:33, 113.33s/it, lr=0.0005, test_MAE=0.712, time=112, train_MAE=0.624, train_loss=0.666, val_MAE=0.672, val_loss=0.713]Epoch 25:   2%|▎         | 25/1000 [49:27<30:41:33, 113.33s/it, lr=0.0005, test_MAE=0.693, time=112, train_MAE=0.617, train_loss=0.659, val_MAE=0.652, val_loss=0.694]Epoch 25:   3%|▎         | 26/1000 [49:27<30:31:58, 112.85s/it, lr=0.0005, test_MAE=0.693, time=112, train_MAE=0.617, train_loss=0.659, val_MAE=0.652, val_loss=0.694]Epoch 26:   3%|▎         | 26/1000 [49:27<30:31:58, 112.85s/it, lr=0.0005, test_MAE=0.693, time=112, train_MAE=0.617, train_loss=0.659, val_MAE=0.652, val_loss=0.694]Epoch 26:   3%|▎         | 26/1000 [51:18<30:31:58, 112.85s/it, lr=0.0005, test_MAE=0.682, time=112, train_MAE=0.619, train_loss=0.66, val_MAE=0.639, val_loss=0.68]  Epoch 26:   3%|▎         | 27/1000 [51:18<30:24:32, 112.51s/it, lr=0.0005, test_MAE=0.682, time=112, train_MAE=0.619, train_loss=0.66, val_MAE=0.639, val_loss=0.68]Epoch 27:   3%|▎         | 27/1000 [51:18<30:24:32, 112.51s/it, lr=0.0005, test_MAE=0.682, time=112, train_MAE=0.619, train_loss=0.66, val_MAE=0.639, val_loss=0.68]Epoch 27:   3%|▎         | 27/1000 [53:10<30:24:32, 112.51s/it, lr=0.0005, test_MAE=0.749, time=112, train_MAE=0.616, train_loss=0.658, val_MAE=0.681, val_loss=0.722]Epoch 27:   3%|▎         | 28/1000 [53:10<30:20:21, 112.37s/it, lr=0.0005, test_MAE=0.749, time=112, train_MAE=0.616, train_loss=0.658, val_MAE=0.681, val_loss=0.722]Epoch 28:   3%|▎         | 28/1000 [53:10<30:20:21, 112.37s/it, lr=0.0005, test_MAE=0.749, time=112, train_MAE=0.616, train_loss=0.658, val_MAE=0.681, val_loss=0.722]Epoch 28:   3%|▎         | 28/1000 [55:02<30:20:21, 112.37s/it, lr=0.0005, test_MAE=0.726, time=112, train_MAE=0.617, train_loss=0.658, val_MAE=0.67, val_loss=0.712] Epoch 28:   3%|▎         | 29/1000 [55:02<30:15:13, 112.17s/it, lr=0.0005, test_MAE=0.726, time=112, train_MAE=0.617, train_loss=0.658, val_MAE=0.67, val_loss=0.712]Epoch 29:   3%|▎         | 29/1000 [55:02<30:15:13, 112.17s/it, lr=0.0005, test_MAE=0.726, time=112, train_MAE=0.617, train_loss=0.658, val_MAE=0.67, val_loss=0.712]Epoch 29:   3%|▎         | 29/1000 [56:54<30:15:13, 112.17s/it, lr=0.0005, test_MAE=0.684, time=112, train_MAE=0.627, train_loss=0.668, val_MAE=0.644, val_loss=0.686]Epoch 29:   3%|▎         | 30/1000 [56:54<30:11:25, 112.05s/it, lr=0.0005, test_MAE=0.684, time=112, train_MAE=0.627, train_loss=0.668, val_MAE=0.644, val_loss=0.686]Epoch 30:   3%|▎         | 30/1000 [56:54<30:11:25, 112.05s/it, lr=0.0005, test_MAE=0.684, time=112, train_MAE=0.627, train_loss=0.668, val_MAE=0.644, val_loss=0.686]Epoch 30:   3%|▎         | 30/1000 [58:46<30:11:25, 112.05s/it, lr=0.0005, test_MAE=0.692, time=112, train_MAE=0.613, train_loss=0.654, val_MAE=0.64, val_loss=0.682] Epoch 30:   3%|▎         | 31/1000 [58:46<30:09:35, 112.05s/it, lr=0.0005, test_MAE=0.692, time=112, train_MAE=0.613, train_loss=0.654, val_MAE=0.64, val_loss=0.682]Epoch 31:   3%|▎         | 31/1000 [58:46<30:09:35, 112.05s/it, lr=0.0005, test_MAE=0.692, time=112, train_MAE=0.613, train_loss=0.654, val_MAE=0.64, val_loss=0.682]Epoch 31:   3%|▎         | 31/1000 [1:00:38<30:09:35, 112.05s/it, lr=0.0005, test_MAE=0.71, time=112, train_MAE=0.614, train_loss=0.656, val_MAE=0.68, val_loss=0.721]Epoch 31:   3%|▎         | 32/1000 [1:00:38<30:06:39, 111.98s/it, lr=0.0005, test_MAE=0.71, time=112, train_MAE=0.614, train_loss=0.656, val_MAE=0.68, val_loss=0.721]Epoch 32:   3%|▎         | 32/1000 [1:00:38<30:06:39, 111.98s/it, lr=0.0005, test_MAE=0.71, time=112, train_MAE=0.614, train_loss=0.656, val_MAE=0.68, val_loss=0.721]Epoch 32:   3%|▎         | 32/1000 [1:02:30<30:06:39, 111.98s/it, lr=0.0005, test_MAE=0.7, time=112, train_MAE=0.626, train_loss=0.668, val_MAE=0.662, val_loss=0.703]Epoch    33: reducing learning rate of group 0 to 2.5000e-04.
Epoch 32:   3%|▎         | 33/1000 [1:02:30<30:04:24, 111.96s/it, lr=0.0005, test_MAE=0.7, time=112, train_MAE=0.626, train_loss=0.668, val_MAE=0.662, val_loss=0.703]Epoch 33:   3%|▎         | 33/1000 [1:02:30<30:04:24, 111.96s/it, lr=0.0005, test_MAE=0.7, time=112, train_MAE=0.626, train_loss=0.668, val_MAE=0.662, val_loss=0.703]Epoch 33:   3%|▎         | 33/1000 [1:04:21<30:04:24, 111.96s/it, lr=0.00025, test_MAE=0.714, time=112, train_MAE=0.601, train_loss=0.643, val_MAE=0.68, val_loss=0.722]Epoch 33:   3%|▎         | 34/1000 [1:04:21<30:01:14, 111.88s/it, lr=0.00025, test_MAE=0.714, time=112, train_MAE=0.601, train_loss=0.643, val_MAE=0.68, val_loss=0.722]Epoch 34:   3%|▎         | 34/1000 [1:04:21<30:01:14, 111.88s/it, lr=0.00025, test_MAE=0.714, time=112, train_MAE=0.601, train_loss=0.643, val_MAE=0.68, val_loss=0.722]Epoch 34:   3%|▎         | 34/1000 [1:06:13<30:01:14, 111.88s/it, lr=0.00025, test_MAE=0.688, time=112, train_MAE=0.604, train_loss=0.645, val_MAE=0.664, val_loss=0.706]Epoch 34:   4%|▎         | 35/1000 [1:06:13<29:59:51, 111.91s/it, lr=0.00025, test_MAE=0.688, time=112, train_MAE=0.604, train_loss=0.645, val_MAE=0.664, val_loss=0.706]Epoch 35:   4%|▎         | 35/1000 [1:06:13<29:59:51, 111.91s/it, lr=0.00025, test_MAE=0.688, time=112, train_MAE=0.604, train_loss=0.645, val_MAE=0.664, val_loss=0.706]Epoch 35:   4%|▎         | 35/1000 [1:08:05<29:59:51, 111.91s/it, lr=0.00025, test_MAE=0.763, time=112, train_MAE=0.603, train_loss=0.645, val_MAE=0.641, val_loss=0.683]Epoch 35:   4%|▎         | 36/1000 [1:08:05<29:57:00, 111.85s/it, lr=0.00025, test_MAE=0.763, time=112, train_MAE=0.603, train_loss=0.645, val_MAE=0.641, val_loss=0.683]Epoch 36:   4%|▎         | 36/1000 [1:08:05<29:57:00, 111.85s/it, lr=0.00025, test_MAE=0.763, time=112, train_MAE=0.603, train_loss=0.645, val_MAE=0.641, val_loss=0.683]Epoch 36:   4%|▎         | 36/1000 [1:09:56<29:57:00, 111.85s/it, lr=0.00025, test_MAE=0.704, time=112, train_MAE=0.597, train_loss=0.638, val_MAE=0.657, val_loss=0.698]Epoch 36:   4%|▎         | 37/1000 [1:09:56<29:53:43, 111.76s/it, lr=0.00025, test_MAE=0.704, time=112, train_MAE=0.597, train_loss=0.638, val_MAE=0.657, val_loss=0.698]Epoch 37:   4%|▎         | 37/1000 [1:09:56<29:53:43, 111.76s/it, lr=0.00025, test_MAE=0.704, time=112, train_MAE=0.597, train_loss=0.638, val_MAE=0.657, val_loss=0.698]Epoch 37:   4%|▎         | 37/1000 [1:11:48<29:53:43, 111.76s/it, lr=0.00025, test_MAE=0.696, time=112, train_MAE=0.604, train_loss=0.646, val_MAE=0.649, val_loss=0.69] Epoch 37:   4%|▍         | 38/1000 [1:11:49<29:53:14, 111.84s/it, lr=0.00025, test_MAE=0.696, time=112, train_MAE=0.604, train_loss=0.646, val_MAE=0.649, val_loss=0.69]Epoch 38:   4%|▍         | 38/1000 [1:11:49<29:53:14, 111.84s/it, lr=0.00025, test_MAE=0.696, time=112, train_MAE=0.604, train_loss=0.646, val_MAE=0.649, val_loss=0.69]Epoch 38:   4%|▍         | 38/1000 [1:13:40<29:53:14, 111.84s/it, lr=0.00025, test_MAE=0.709, time=112, train_MAE=0.596, train_loss=0.637, val_MAE=0.666, val_loss=0.707]Epoch    39: reducing learning rate of group 0 to 1.2500e-04.
Epoch 38:   4%|▍         | 39/1000 [1:13:40<29:50:25, 111.79s/it, lr=0.00025, test_MAE=0.709, time=112, train_MAE=0.596, train_loss=0.637, val_MAE=0.666, val_loss=0.707]Epoch 39:   4%|▍         | 39/1000 [1:13:40<29:50:25, 111.79s/it, lr=0.00025, test_MAE=0.709, time=112, train_MAE=0.596, train_loss=0.637, val_MAE=0.666, val_loss=0.707]Epoch 39:   4%|▍         | 39/1000 [1:15:32<29:50:25, 111.79s/it, lr=0.000125, test_MAE=0.684, time=112, train_MAE=0.589, train_loss=0.631, val_MAE=0.643, val_loss=0.684]Epoch 39:   4%|▍         | 40/1000 [1:15:32<29:48:06, 111.76s/it, lr=0.000125, test_MAE=0.684, time=112, train_MAE=0.589, train_loss=0.631, val_MAE=0.643, val_loss=0.684]Epoch 40:   4%|▍         | 40/1000 [1:15:32<29:48:06, 111.76s/it, lr=0.000125, test_MAE=0.684, time=112, train_MAE=0.589, train_loss=0.631, val_MAE=0.643, val_loss=0.684]Epoch 40:   4%|▍         | 40/1000 [1:17:23<29:48:06, 111.76s/it, lr=0.000125, test_MAE=0.693, time=112, train_MAE=0.592, train_loss=0.633, val_MAE=0.65, val_loss=0.691] Epoch 40:   4%|▍         | 41/1000 [1:17:24<29:45:43, 111.72s/it, lr=0.000125, test_MAE=0.693, time=112, train_MAE=0.592, train_loss=0.633, val_MAE=0.65, val_loss=0.691]Epoch 41:   4%|▍         | 41/1000 [1:17:24<29:45:43, 111.72s/it, lr=0.000125, test_MAE=0.693, time=112, train_MAE=0.592, train_loss=0.633, val_MAE=0.65, val_loss=0.691]Epoch 41:   4%|▍         | 41/1000 [1:19:15<29:45:43, 111.72s/it, lr=0.000125, test_MAE=0.689, time=112, train_MAE=0.592, train_loss=0.633, val_MAE=0.643, val_loss=0.684]Epoch 41:   4%|▍         | 42/1000 [1:19:15<29:45:07, 111.80s/it, lr=0.000125, test_MAE=0.689, time=112, train_MAE=0.592, train_loss=0.633, val_MAE=0.643, val_loss=0.684]Epoch 42:   4%|▍         | 42/1000 [1:19:15<29:45:07, 111.80s/it, lr=0.000125, test_MAE=0.689, time=112, train_MAE=0.592, train_loss=0.633, val_MAE=0.643, val_loss=0.684]Epoch 42:   4%|▍         | 42/1000 [1:21:07<29:45:07, 111.80s/it, lr=0.000125, test_MAE=0.69, time=112, train_MAE=0.591, train_loss=0.633, val_MAE=0.648, val_loss=0.689] Epoch 42:   4%|▍         | 43/1000 [1:21:07<29:42:43, 111.77s/it, lr=0.000125, test_MAE=0.69, time=112, train_MAE=0.591, train_loss=0.633, val_MAE=0.648, val_loss=0.689]Epoch 43:   4%|▍         | 43/1000 [1:21:07<29:42:43, 111.77s/it, lr=0.000125, test_MAE=0.69, time=112, train_MAE=0.591, train_loss=0.633, val_MAE=0.648, val_loss=0.689]Epoch 43:   4%|▍         | 43/1000 [1:22:59<29:42:43, 111.77s/it, lr=0.000125, test_MAE=0.688, time=112, train_MAE=0.589, train_loss=0.63, val_MAE=0.639, val_loss=0.68] Epoch 43:   4%|▍         | 44/1000 [1:22:59<29:40:23, 111.74s/it, lr=0.000125, test_MAE=0.688, time=112, train_MAE=0.589, train_loss=0.63, val_MAE=0.639, val_loss=0.68]Epoch 44:   4%|▍         | 44/1000 [1:22:59<29:40:23, 111.74s/it, lr=0.000125, test_MAE=0.688, time=112, train_MAE=0.589, train_loss=0.63, val_MAE=0.639, val_loss=0.68]Epoch 44:   4%|▍         | 44/1000 [1:24:51<29:40:23, 111.74s/it, lr=0.000125, test_MAE=0.692, time=112, train_MAE=0.595, train_loss=0.636, val_MAE=0.651, val_loss=0.692]Epoch    45: reducing learning rate of group 0 to 6.2500e-05.
Epoch 44:   4%|▍         | 45/1000 [1:24:51<29:39:38, 111.81s/it, lr=0.000125, test_MAE=0.692, time=112, train_MAE=0.595, train_loss=0.636, val_MAE=0.651, val_loss=0.692]Epoch 45:   4%|▍         | 45/1000 [1:24:51<29:39:38, 111.81s/it, lr=0.000125, test_MAE=0.692, time=112, train_MAE=0.595, train_loss=0.636, val_MAE=0.651, val_loss=0.692]Epoch 45:   4%|▍         | 45/1000 [1:26:43<29:39:38, 111.81s/it, lr=6.25e-5, test_MAE=0.698, time=112, train_MAE=0.59, train_loss=0.631, val_MAE=0.649, val_loss=0.69]   Epoch 45:   5%|▍         | 46/1000 [1:26:43<29:37:15, 111.78s/it, lr=6.25e-5, test_MAE=0.698, time=112, train_MAE=0.59, train_loss=0.631, val_MAE=0.649, val_loss=0.69]Epoch 46:   5%|▍         | 46/1000 [1:26:43<29:37:15, 111.78s/it, lr=6.25e-5, test_MAE=0.698, time=112, train_MAE=0.59, train_loss=0.631, val_MAE=0.649, val_loss=0.69]Epoch 46:   5%|▍         | 46/1000 [1:28:34<29:37:15, 111.78s/it, lr=6.25e-5, test_MAE=0.686, time=112, train_MAE=0.579, train_loss=0.62, val_MAE=0.642, val_loss=0.683]Epoch 46:   5%|▍         | 47/1000 [1:28:34<29:35:01, 111.75s/it, lr=6.25e-5, test_MAE=0.686, time=112, train_MAE=0.579, train_loss=0.62, val_MAE=0.642, val_loss=0.683]Epoch 47:   5%|▍         | 47/1000 [1:28:34<29:35:01, 111.75s/it, lr=6.25e-5, test_MAE=0.686, time=112, train_MAE=0.579, train_loss=0.62, val_MAE=0.642, val_loss=0.683]Epoch 47:   5%|▍         | 47/1000 [1:30:26<29:35:01, 111.75s/it, lr=6.25e-5, test_MAE=0.684, time=112, train_MAE=0.578, train_loss=0.619, val_MAE=0.642, val_loss=0.683]Epoch 47:   5%|▍         | 48/1000 [1:30:26<29:32:27, 111.71s/it, lr=6.25e-5, test_MAE=0.684, time=112, train_MAE=0.578, train_loss=0.619, val_MAE=0.642, val_loss=0.683]Epoch 48:   5%|▍         | 48/1000 [1:30:26<29:32:27, 111.71s/it, lr=6.25e-5, test_MAE=0.684, time=112, train_MAE=0.578, train_loss=0.619, val_MAE=0.642, val_loss=0.683]Epoch 48:   5%|▍         | 48/1000 [1:32:18<29:32:27, 111.71s/it, lr=6.25e-5, test_MAE=0.689, time=112, train_MAE=0.58, train_loss=0.621, val_MAE=0.648, val_loss=0.689] Epoch 48:   5%|▍         | 49/1000 [1:32:18<29:32:07, 111.81s/it, lr=6.25e-5, test_MAE=0.689, time=112, train_MAE=0.58, train_loss=0.621, val_MAE=0.648, val_loss=0.689]Epoch 49:   5%|▍         | 49/1000 [1:32:18<29:32:07, 111.81s/it, lr=6.25e-5, test_MAE=0.689, time=112, train_MAE=0.58, train_loss=0.621, val_MAE=0.648, val_loss=0.689]Epoch 49:   5%|▍         | 49/1000 [1:34:10<29:32:07, 111.81s/it, lr=6.25e-5, test_MAE=0.704, time=112, train_MAE=0.575, train_loss=0.616, val_MAE=0.658, val_loss=0.699]Epoch 49:   5%|▌         | 50/1000 [1:34:10<29:29:48, 111.78s/it, lr=6.25e-5, test_MAE=0.704, time=112, train_MAE=0.575, train_loss=0.616, val_MAE=0.658, val_loss=0.699]Epoch 50:   5%|▌         | 50/1000 [1:34:10<29:29:48, 111.78s/it, lr=6.25e-5, test_MAE=0.704, time=112, train_MAE=0.575, train_loss=0.616, val_MAE=0.658, val_loss=0.699]Epoch 50:   5%|▌         | 50/1000 [1:36:01<29:29:48, 111.78s/it, lr=6.25e-5, test_MAE=0.686, time=112, train_MAE=0.581, train_loss=0.622, val_MAE=0.642, val_loss=0.683]Epoch    51: reducing learning rate of group 0 to 3.1250e-05.
Epoch 50:   5%|▌         | 51/1000 [1:36:01<29:27:38, 111.76s/it, lr=6.25e-5, test_MAE=0.686, time=112, train_MAE=0.581, train_loss=0.622, val_MAE=0.642, val_loss=0.683]Epoch 51:   5%|▌         | 51/1000 [1:36:01<29:27:38, 111.76s/it, lr=6.25e-5, test_MAE=0.686, time=112, train_MAE=0.581, train_loss=0.622, val_MAE=0.642, val_loss=0.683]Epoch 51:   5%|▌         | 51/1000 [1:37:53<29:27:38, 111.76s/it, lr=3.13e-5, test_MAE=0.696, time=112, train_MAE=0.571, train_loss=0.612, val_MAE=0.653, val_loss=0.693]Epoch 51:   5%|▌         | 52/1000 [1:37:53<29:26:43, 111.82s/it, lr=3.13e-5, test_MAE=0.696, time=112, train_MAE=0.571, train_loss=0.612, val_MAE=0.653, val_loss=0.693]Epoch 52:   5%|▌         | 52/1000 [1:37:53<29:26:43, 111.82s/it, lr=3.13e-5, test_MAE=0.696, time=112, train_MAE=0.571, train_loss=0.612, val_MAE=0.653, val_loss=0.693]Epoch 52:   5%|▌         | 52/1000 [1:39:45<29:26:43, 111.82s/it, lr=3.13e-5, test_MAE=0.689, time=112, train_MAE=0.573, train_loss=0.614, val_MAE=0.644, val_loss=0.685]Epoch 52:   5%|▌         | 53/1000 [1:39:45<29:24:13, 111.78s/it, lr=3.13e-5, test_MAE=0.689, time=112, train_MAE=0.573, train_loss=0.614, val_MAE=0.644, val_loss=0.685]Epoch 53:   5%|▌         | 53/1000 [1:39:45<29:24:13, 111.78s/it, lr=3.13e-5, test_MAE=0.689, time=112, train_MAE=0.573, train_loss=0.614, val_MAE=0.644, val_loss=0.685]Epoch 53:   5%|▌         | 53/1000 [1:41:36<29:24:13, 111.78s/it, lr=3.13e-5, test_MAE=0.715, time=111, train_MAE=0.576, train_loss=0.617, val_MAE=0.654, val_loss=0.695]Epoch 53:   5%|▌         | 54/1000 [1:41:36<29:20:30, 111.66s/it, lr=3.13e-5, test_MAE=0.715, time=111, train_MAE=0.576, train_loss=0.617, val_MAE=0.654, val_loss=0.695]Epoch 54:   5%|▌         | 54/1000 [1:41:36<29:20:30, 111.66s/it, lr=3.13e-5, test_MAE=0.715, time=111, train_MAE=0.576, train_loss=0.617, val_MAE=0.654, val_loss=0.695]Epoch 54:   5%|▌         | 54/1000 [1:43:28<29:20:30, 111.66s/it, lr=3.13e-5, test_MAE=0.702, time=111, train_MAE=0.574, train_loss=0.615, val_MAE=0.643, val_loss=0.684]Epoch 54:   6%|▌         | 55/1000 [1:43:28<29:17:23, 111.58s/it, lr=3.13e-5, test_MAE=0.702, time=111, train_MAE=0.574, train_loss=0.615, val_MAE=0.643, val_loss=0.684]Epoch 55:   6%|▌         | 55/1000 [1:43:28<29:17:23, 111.58s/it, lr=3.13e-5, test_MAE=0.702, time=111, train_MAE=0.574, train_loss=0.615, val_MAE=0.643, val_loss=0.684]Epoch 55:   6%|▌         | 55/1000 [1:45:18<29:17:23, 111.58s/it, lr=3.13e-5, test_MAE=0.692, time=111, train_MAE=0.581, train_loss=0.622, val_MAE=0.648, val_loss=0.689]Epoch 55:   6%|▌         | 56/1000 [1:45:18<29:11:31, 111.33s/it, lr=3.13e-5, test_MAE=0.692, time=111, train_MAE=0.581, train_loss=0.622, val_MAE=0.648, val_loss=0.689]Epoch 56:   6%|▌         | 56/1000 [1:45:18<29:11:31, 111.33s/it, lr=3.13e-5, test_MAE=0.692, time=111, train_MAE=0.581, train_loss=0.622, val_MAE=0.648, val_loss=0.689]Epoch 56:   6%|▌         | 56/1000 [1:47:07<29:11:31, 111.33s/it, lr=3.13e-5, test_MAE=0.688, time=108, train_MAE=0.571, train_loss=0.612, val_MAE=0.645, val_loss=0.686]Epoch    57: reducing learning rate of group 0 to 1.5625e-05.
Epoch 56:   6%|▌         | 57/1000 [1:47:07<28:54:46, 110.38s/it, lr=3.13e-5, test_MAE=0.688, time=108, train_MAE=0.571, train_loss=0.612, val_MAE=0.645, val_loss=0.686]Epoch 57:   6%|▌         | 57/1000 [1:47:07<28:54:46, 110.38s/it, lr=3.13e-5, test_MAE=0.688, time=108, train_MAE=0.571, train_loss=0.612, val_MAE=0.645, val_loss=0.686]Epoch 57:   6%|▌         | 57/1000 [1:48:53<28:54:46, 110.38s/it, lr=1.56e-5, test_MAE=0.68, time=106, train_MAE=0.571, train_loss=0.611, val_MAE=0.641, val_loss=0.682] Epoch 57:   6%|▌         | 58/1000 [1:48:53<28:33:17, 109.13s/it, lr=1.56e-5, test_MAE=0.68, time=106, train_MAE=0.571, train_loss=0.611, val_MAE=0.641, val_loss=0.682]Epoch 58:   6%|▌         | 58/1000 [1:48:53<28:33:17, 109.13s/it, lr=1.56e-5, test_MAE=0.68, time=106, train_MAE=0.571, train_loss=0.611, val_MAE=0.641, val_loss=0.682]Epoch 58:   6%|▌         | 58/1000 [1:50:39<28:33:17, 109.13s/it, lr=1.56e-5, test_MAE=0.688, time=106, train_MAE=0.568, train_loss=0.609, val_MAE=0.644, val_loss=0.685]Epoch 58:   6%|▌         | 59/1000 [1:50:39<28:18:33, 108.30s/it, lr=1.56e-5, test_MAE=0.688, time=106, train_MAE=0.568, train_loss=0.609, val_MAE=0.644, val_loss=0.685]Epoch 59:   6%|▌         | 59/1000 [1:50:39<28:18:33, 108.30s/it, lr=1.56e-5, test_MAE=0.688, time=106, train_MAE=0.568, train_loss=0.609, val_MAE=0.644, val_loss=0.685]Epoch 59:   6%|▌         | 59/1000 [1:52:25<28:18:33, 108.30s/it, lr=1.56e-5, test_MAE=0.695, time=106, train_MAE=0.57, train_loss=0.61, val_MAE=0.644, val_loss=0.684]  Epoch 59:   6%|▌         | 60/1000 [1:52:25<28:04:38, 107.53s/it, lr=1.56e-5, test_MAE=0.695, time=106, train_MAE=0.57, train_loss=0.61, val_MAE=0.644, val_loss=0.684]Epoch 60:   6%|▌         | 60/1000 [1:52:25<28:04:38, 107.53s/it, lr=1.56e-5, test_MAE=0.695, time=106, train_MAE=0.57, train_loss=0.61, val_MAE=0.644, val_loss=0.684]Epoch 60:   6%|▌         | 60/1000 [1:54:10<28:04:38, 107.53s/it, lr=1.56e-5, test_MAE=0.706, time=105, train_MAE=0.576, train_loss=0.617, val_MAE=0.647, val_loss=0.688]Epoch 60:   6%|▌         | 61/1000 [1:54:10<27:51:29, 106.81s/it, lr=1.56e-5, test_MAE=0.706, time=105, train_MAE=0.576, train_loss=0.617, val_MAE=0.647, val_loss=0.688]Epoch 61:   6%|▌         | 61/1000 [1:54:10<27:51:29, 106.81s/it, lr=1.56e-5, test_MAE=0.706, time=105, train_MAE=0.576, train_loss=0.617, val_MAE=0.647, val_loss=0.688]Epoch 61:   6%|▌         | 61/1000 [1:55:55<27:51:29, 106.81s/it, lr=1.56e-5, test_MAE=0.687, time=105, train_MAE=0.57, train_loss=0.61, val_MAE=0.641, val_loss=0.681]  Epoch 61:   6%|▌         | 62/1000 [1:55:55<27:40:27, 106.21s/it, lr=1.56e-5, test_MAE=0.687, time=105, train_MAE=0.57, train_loss=0.61, val_MAE=0.641, val_loss=0.681]Epoch 62:   6%|▌         | 62/1000 [1:55:55<27:40:27, 106.21s/it, lr=1.56e-5, test_MAE=0.687, time=105, train_MAE=0.57, train_loss=0.61, val_MAE=0.641, val_loss=0.681]Epoch 62:   6%|▌         | 62/1000 [1:57:40<27:40:27, 106.21s/it, lr=1.56e-5, test_MAE=0.685, time=105, train_MAE=0.574, train_loss=0.615, val_MAE=0.642, val_loss=0.682]Epoch    63: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 62:   6%|▌         | 62/1000 [1:57:40<29:40:21, 113.88s/it, lr=1.56e-5, test_MAE=0.685, time=105, train_MAE=0.574, train_loss=0.615, val_MAE=0.642, val_loss=0.682]
Test MAE: 0.6848
Train MAE: 0.5586
Convergence Time (Epochs): 62.0000
TOTAL TIME TAKEN: 7109.6858s
AVG TIME PER EPOCH: 112.0583s
