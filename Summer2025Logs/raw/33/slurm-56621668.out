I'm echoing to stdout
I'm echoing to stderr
My JobID is 56621668
I have 8 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.0897s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 4, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'rational_vec', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_sub', 'num_eigs': 15, 'bias_mode': 'spatial', 'eigval_hidden_dim': 5, 'eigval_num_hidden_layer': 3, 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 1, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/zinc_train_kway.csv', 'test': 'supp_data/molecules/zinc_test_part_kway.csv', 'val': 'supp_data/molecules/zinc_val_kway.csv'}, 'fixMissingPhi1': True, 'extraOrtho': False, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [02:16<?, ?it/s, lr=0.001, test_MAE=2.17, time=137, train_MAE=1.08, train_loss=1.1, val_MAE=2.12, val_loss=2.15]Epoch 0:   0%|          | 1/1000 [02:16<37:57:50, 136.81s/it, lr=0.001, test_MAE=2.17, time=137, train_MAE=1.08, train_loss=1.1, val_MAE=2.12, val_loss=2.15]Epoch 1:   0%|          | 1/1000 [02:16<37:57:50, 136.81s/it, lr=0.001, test_MAE=2.17, time=137, train_MAE=1.08, train_loss=1.1, val_MAE=2.12, val_loss=2.15]Epoch 1:   0%|          | 1/1000 [04:21<37:57:50, 136.81s/it, lr=0.001, test_MAE=1.29, time=125, train_MAE=0.768, train_loss=0.801, val_MAE=1.2, val_loss=1.23]Epoch 1:   0%|          | 2/1000 [04:21<36:56:38, 133.27s/it, lr=0.001, test_MAE=1.29, time=125, train_MAE=0.768, train_loss=0.801, val_MAE=1.2, val_loss=1.23]Epoch 2:   0%|          | 2/1000 [04:21<36:56:38, 133.27s/it, lr=0.001, test_MAE=1.29, time=125, train_MAE=0.768, train_loss=0.801, val_MAE=1.2, val_loss=1.23]Epoch 2:   0%|          | 2/1000 [06:26<36:56:38, 133.27s/it, lr=0.001, test_MAE=2.81, time=125, train_MAE=0.707, train_loss=0.743, val_MAE=2.62, val_loss=2.66]Epoch 2:   0%|          | 3/1000 [06:26<36:12:36, 130.75s/it, lr=0.001, test_MAE=2.81, time=125, train_MAE=0.707, train_loss=0.743, val_MAE=2.62, val_loss=2.66]Epoch 3:   0%|          | 3/1000 [06:26<36:12:36, 130.75s/it, lr=0.001, test_MAE=2.81, time=125, train_MAE=0.707, train_loss=0.743, val_MAE=2.62, val_loss=2.66]Epoch 3:   0%|          | 3/1000 [08:31<36:12:36, 130.75s/it, lr=0.001, test_MAE=1.67, time=125, train_MAE=0.681, train_loss=0.718, val_MAE=1.65, val_loss=1.68]Epoch 3:   0%|          | 4/1000 [08:31<35:40:45, 128.96s/it, lr=0.001, test_MAE=1.67, time=125, train_MAE=0.681, train_loss=0.718, val_MAE=1.65, val_loss=1.68]Epoch 4:   0%|          | 4/1000 [08:31<35:40:45, 128.96s/it, lr=0.001, test_MAE=1.67, time=125, train_MAE=0.681, train_loss=0.718, val_MAE=1.65, val_loss=1.68]Epoch 4:   0%|          | 4/1000 [10:36<35:40:45, 128.96s/it, lr=0.001, test_MAE=0.995, time=125, train_MAE=0.676, train_loss=0.714, val_MAE=0.939, val_loss=0.977]Epoch 4:   0%|          | 5/1000 [10:36<35:18:16, 127.74s/it, lr=0.001, test_MAE=0.995, time=125, train_MAE=0.676, train_loss=0.714, val_MAE=0.939, val_loss=0.977]Epoch 5:   0%|          | 5/1000 [10:36<35:18:16, 127.74s/it, lr=0.001, test_MAE=0.995, time=125, train_MAE=0.676, train_loss=0.714, val_MAE=0.939, val_loss=0.977]Epoch 5:   0%|          | 5/1000 [12:41<35:18:16, 127.74s/it, lr=0.001, test_MAE=0.88, time=125, train_MAE=0.669, train_loss=0.707, val_MAE=0.809, val_loss=0.848] Epoch 5:   1%|          | 6/1000 [12:41<35:01:40, 126.86s/it, lr=0.001, test_MAE=0.88, time=125, train_MAE=0.669, train_loss=0.707, val_MAE=0.809, val_loss=0.848]Epoch 6:   1%|          | 6/1000 [12:41<35:01:40, 126.86s/it, lr=0.001, test_MAE=0.88, time=125, train_MAE=0.669, train_loss=0.707, val_MAE=0.809, val_loss=0.848]Epoch 6:   1%|          | 6/1000 [14:46<35:01:40, 126.86s/it, lr=0.001, test_MAE=0.773, time=125, train_MAE=0.662, train_loss=0.701, val_MAE=0.715, val_loss=0.755]Epoch 6:   1%|          | 7/1000 [14:46<34:51:33, 126.38s/it, lr=0.001, test_MAE=0.773, time=125, train_MAE=0.662, train_loss=0.701, val_MAE=0.715, val_loss=0.755]Epoch 7:   1%|          | 7/1000 [14:46<34:51:33, 126.38s/it, lr=0.001, test_MAE=0.773, time=125, train_MAE=0.662, train_loss=0.701, val_MAE=0.715, val_loss=0.755]Epoch 7:   1%|          | 7/1000 [16:51<34:51:33, 126.38s/it, lr=0.001, test_MAE=1.14, time=125, train_MAE=0.661, train_loss=0.701, val_MAE=1.07, val_loss=1.11]   Epoch 7:   1%|          | 8/1000 [16:51<34:42:00, 125.93s/it, lr=0.001, test_MAE=1.14, time=125, train_MAE=0.661, train_loss=0.701, val_MAE=1.07, val_loss=1.11]Epoch 8:   1%|          | 8/1000 [16:51<34:42:00, 125.93s/it, lr=0.001, test_MAE=1.14, time=125, train_MAE=0.661, train_loss=0.701, val_MAE=1.07, val_loss=1.11]Epoch 8:   1%|          | 8/1000 [18:56<34:42:00, 125.93s/it, lr=0.001, test_MAE=0.844, time=125, train_MAE=0.659, train_loss=0.699, val_MAE=0.783, val_loss=0.823]Epoch 8:   1%|          | 9/1000 [18:56<34:34:51, 125.62s/it, lr=0.001, test_MAE=0.844, time=125, train_MAE=0.659, train_loss=0.699, val_MAE=0.783, val_loss=0.823]Epoch 9:   1%|          | 9/1000 [18:56<34:34:51, 125.62s/it, lr=0.001, test_MAE=0.844, time=125, train_MAE=0.659, train_loss=0.699, val_MAE=0.783, val_loss=0.823]Epoch 9:   1%|          | 9/1000 [21:01<34:34:51, 125.62s/it, lr=0.001, test_MAE=0.756, time=125, train_MAE=0.658, train_loss=0.698, val_MAE=0.712, val_loss=0.752]Epoch 9:   1%|          | 10/1000 [21:01<34:30:28, 125.48s/it, lr=0.001, test_MAE=0.756, time=125, train_MAE=0.658, train_loss=0.698, val_MAE=0.712, val_loss=0.752]Epoch 10:   1%|          | 10/1000 [21:01<34:30:28, 125.48s/it, lr=0.001, test_MAE=0.756, time=125, train_MAE=0.658, train_loss=0.698, val_MAE=0.712, val_loss=0.752]Epoch 10:   1%|          | 10/1000 [23:06<34:30:28, 125.48s/it, lr=0.001, test_MAE=0.782, time=125, train_MAE=0.654, train_loss=0.695, val_MAE=0.687, val_loss=0.728]Epoch 10:   1%|          | 11/1000 [23:06<34:25:38, 125.32s/it, lr=0.001, test_MAE=0.782, time=125, train_MAE=0.654, train_loss=0.695, val_MAE=0.687, val_loss=0.728]Epoch 11:   1%|          | 11/1000 [23:06<34:25:38, 125.32s/it, lr=0.001, test_MAE=0.782, time=125, train_MAE=0.654, train_loss=0.695, val_MAE=0.687, val_loss=0.728]Epoch 11:   1%|          | 11/1000 [25:10<34:25:38, 125.32s/it, lr=0.001, test_MAE=0.734, time=125, train_MAE=0.652, train_loss=0.694, val_MAE=0.684, val_loss=0.726]Epoch 11:   1%|          | 12/1000 [25:10<34:19:49, 125.09s/it, lr=0.001, test_MAE=0.734, time=125, train_MAE=0.652, train_loss=0.694, val_MAE=0.684, val_loss=0.726]Epoch 12:   1%|          | 12/1000 [25:10<34:19:49, 125.09s/it, lr=0.001, test_MAE=0.734, time=125, train_MAE=0.652, train_loss=0.694, val_MAE=0.684, val_loss=0.726]Epoch 12:   1%|          | 12/1000 [27:16<34:19:49, 125.09s/it, lr=0.001, test_MAE=1.17, time=126, train_MAE=0.649, train_loss=0.691, val_MAE=1.12, val_loss=1.16]   Epoch 12:   1%|▏         | 13/1000 [27:16<34:20:47, 125.28s/it, lr=0.001, test_MAE=1.17, time=126, train_MAE=0.649, train_loss=0.691, val_MAE=1.12, val_loss=1.16]Epoch 13:   1%|▏         | 13/1000 [27:16<34:20:47, 125.28s/it, lr=0.001, test_MAE=1.17, time=126, train_MAE=0.649, train_loss=0.691, val_MAE=1.12, val_loss=1.16]Epoch 13:   1%|▏         | 13/1000 [29:21<34:20:47, 125.28s/it, lr=0.001, test_MAE=0.756, time=125, train_MAE=0.643, train_loss=0.686, val_MAE=0.692, val_loss=0.735]Epoch 13:   1%|▏         | 14/1000 [29:21<34:18:03, 125.24s/it, lr=0.001, test_MAE=0.756, time=125, train_MAE=0.643, train_loss=0.686, val_MAE=0.692, val_loss=0.735]Epoch 14:   1%|▏         | 14/1000 [29:21<34:18:03, 125.24s/it, lr=0.001, test_MAE=0.756, time=125, train_MAE=0.643, train_loss=0.686, val_MAE=0.692, val_loss=0.735]Epoch 14:   1%|▏         | 14/1000 [31:24<34:18:03, 125.24s/it, lr=0.001, test_MAE=0.826, time=123, train_MAE=0.649, train_loss=0.692, val_MAE=0.713, val_loss=0.756]Epoch 14:   2%|▏         | 15/1000 [31:24<34:06:21, 124.65s/it, lr=0.001, test_MAE=0.826, time=123, train_MAE=0.649, train_loss=0.692, val_MAE=0.713, val_loss=0.756]Epoch 15:   2%|▏         | 15/1000 [31:24<34:06:21, 124.65s/it, lr=0.001, test_MAE=0.826, time=123, train_MAE=0.649, train_loss=0.692, val_MAE=0.713, val_loss=0.756]Epoch 15:   2%|▏         | 15/1000 [33:25<34:06:21, 124.65s/it, lr=0.001, test_MAE=0.814, time=120, train_MAE=0.635, train_loss=0.679, val_MAE=0.736, val_loss=0.78] Epoch 15:   2%|▏         | 16/1000 [33:25<33:42:59, 123.35s/it, lr=0.001, test_MAE=0.814, time=120, train_MAE=0.635, train_loss=0.679, val_MAE=0.736, val_loss=0.78]Epoch 16:   2%|▏         | 16/1000 [33:25<33:42:59, 123.35s/it, lr=0.001, test_MAE=0.814, time=120, train_MAE=0.635, train_loss=0.679, val_MAE=0.736, val_loss=0.78]Epoch 16:   2%|▏         | 16/1000 [35:24<33:42:59, 123.35s/it, lr=0.001, test_MAE=1.01, time=119, train_MAE=0.64, train_loss=0.684, val_MAE=0.938, val_loss=0.982] Epoch 16:   2%|▏         | 17/1000 [35:24<33:19:11, 122.03s/it, lr=0.001, test_MAE=1.01, time=119, train_MAE=0.64, train_loss=0.684, val_MAE=0.938, val_loss=0.982]Epoch 17:   2%|▏         | 17/1000 [35:24<33:19:11, 122.03s/it, lr=0.001, test_MAE=1.01, time=119, train_MAE=0.64, train_loss=0.684, val_MAE=0.938, val_loss=0.982]Epoch 17:   2%|▏         | 17/1000 [37:22<33:19:11, 122.03s/it, lr=0.001, test_MAE=0.989, time=118, train_MAE=0.633, train_loss=0.678, val_MAE=0.934, val_loss=0.978]Epoch    18: reducing learning rate of group 0 to 5.0000e-04.
Epoch 17:   2%|▏         | 18/1000 [37:22<32:59:01, 120.92s/it, lr=0.001, test_MAE=0.989, time=118, train_MAE=0.633, train_loss=0.678, val_MAE=0.934, val_loss=0.978]Epoch 18:   2%|▏         | 18/1000 [37:22<32:59:01, 120.92s/it, lr=0.001, test_MAE=0.989, time=118, train_MAE=0.633, train_loss=0.678, val_MAE=0.934, val_loss=0.978]Epoch 18:   2%|▏         | 18/1000 [39:20<32:59:01, 120.92s/it, lr=0.0005, test_MAE=0.725, time=118, train_MAE=0.62, train_loss=0.664, val_MAE=0.668, val_loss=0.712]Epoch 18:   2%|▏         | 19/1000 [39:20<32:44:22, 120.14s/it, lr=0.0005, test_MAE=0.725, time=118, train_MAE=0.62, train_loss=0.664, val_MAE=0.668, val_loss=0.712]Epoch 19:   2%|▏         | 19/1000 [39:20<32:44:22, 120.14s/it, lr=0.0005, test_MAE=0.725, time=118, train_MAE=0.62, train_loss=0.664, val_MAE=0.668, val_loss=0.712]Epoch 19:   2%|▏         | 19/1000 [41:18<32:44:22, 120.14s/it, lr=0.0005, test_MAE=0.716, time=118, train_MAE=0.62, train_loss=0.664, val_MAE=0.658, val_loss=0.703]Epoch 19:   2%|▏         | 20/1000 [41:18<32:30:56, 119.45s/it, lr=0.0005, test_MAE=0.716, time=118, train_MAE=0.62, train_loss=0.664, val_MAE=0.658, val_loss=0.703]Epoch 20:   2%|▏         | 20/1000 [41:18<32:30:56, 119.45s/it, lr=0.0005, test_MAE=0.716, time=118, train_MAE=0.62, train_loss=0.664, val_MAE=0.658, val_loss=0.703]Epoch 20:   2%|▏         | 20/1000 [43:15<32:30:56, 119.45s/it, lr=0.0005, test_MAE=0.745, time=117, train_MAE=0.64, train_loss=0.684, val_MAE=0.664, val_loss=0.708]Epoch 20:   2%|▏         | 21/1000 [43:15<32:18:00, 118.78s/it, lr=0.0005, test_MAE=0.745, time=117, train_MAE=0.64, train_loss=0.684, val_MAE=0.664, val_loss=0.708]Epoch 21:   2%|▏         | 21/1000 [43:15<32:18:00, 118.78s/it, lr=0.0005, test_MAE=0.745, time=117, train_MAE=0.64, train_loss=0.684, val_MAE=0.664, val_loss=0.708]Epoch 21:   2%|▏         | 21/1000 [45:13<32:18:00, 118.78s/it, lr=0.0005, test_MAE=0.7, time=117, train_MAE=0.616, train_loss=0.661, val_MAE=0.632, val_loss=0.676] Epoch 21:   2%|▏         | 22/1000 [45:13<32:08:14, 118.30s/it, lr=0.0005, test_MAE=0.7, time=117, train_MAE=0.616, train_loss=0.661, val_MAE=0.632, val_loss=0.676]Epoch 22:   2%|▏         | 22/1000 [45:13<32:08:14, 118.30s/it, lr=0.0005, test_MAE=0.7, time=117, train_MAE=0.616, train_loss=0.661, val_MAE=0.632, val_loss=0.676]Epoch 22:   2%|▏         | 22/1000 [47:09<32:08:14, 118.30s/it, lr=0.0005, test_MAE=0.7, time=116, train_MAE=0.611, train_loss=0.655, val_MAE=0.638, val_loss=0.682]Epoch 22:   2%|▏         | 23/1000 [47:09<31:56:30, 117.70s/it, lr=0.0005, test_MAE=0.7, time=116, train_MAE=0.611, train_loss=0.655, val_MAE=0.638, val_loss=0.682]Epoch 23:   2%|▏         | 23/1000 [47:09<31:56:30, 117.70s/it, lr=0.0005, test_MAE=0.7, time=116, train_MAE=0.611, train_loss=0.655, val_MAE=0.638, val_loss=0.682]Epoch 23:   2%|▏         | 23/1000 [49:05<31:56:30, 117.70s/it, lr=0.0005, test_MAE=0.707, time=116, train_MAE=0.614, train_loss=0.658, val_MAE=0.66, val_loss=0.704]Epoch 23:   2%|▏         | 24/1000 [49:05<31:48:18, 117.31s/it, lr=0.0005, test_MAE=0.707, time=116, train_MAE=0.614, train_loss=0.658, val_MAE=0.66, val_loss=0.704]Epoch 24:   2%|▏         | 24/1000 [49:05<31:48:18, 117.31s/it, lr=0.0005, test_MAE=0.707, time=116, train_MAE=0.614, train_loss=0.658, val_MAE=0.66, val_loss=0.704]Epoch 24:   2%|▏         | 24/1000 [51:01<31:48:18, 117.31s/it, lr=0.0005, test_MAE=0.702, time=116, train_MAE=0.615, train_loss=0.659, val_MAE=0.631, val_loss=0.676]Epoch 24:   2%|▎         | 25/1000 [51:01<31:38:54, 116.86s/it, lr=0.0005, test_MAE=0.702, time=116, train_MAE=0.615, train_loss=0.659, val_MAE=0.631, val_loss=0.676]Epoch 25:   2%|▎         | 25/1000 [51:01<31:38:54, 116.86s/it, lr=0.0005, test_MAE=0.702, time=116, train_MAE=0.615, train_loss=0.659, val_MAE=0.631, val_loss=0.676]Epoch 25:   2%|▎         | 25/1000 [52:57<31:38:54, 116.86s/it, lr=0.0005, test_MAE=0.709, time=116, train_MAE=0.609, train_loss=0.653, val_MAE=0.644, val_loss=0.688]Epoch 25:   3%|▎         | 26/1000 [52:57<31:31:14, 116.50s/it, lr=0.0005, test_MAE=0.709, time=116, train_MAE=0.609, train_loss=0.653, val_MAE=0.644, val_loss=0.688]Epoch 26:   3%|▎         | 26/1000 [52:57<31:31:14, 116.50s/it, lr=0.0005, test_MAE=0.709, time=116, train_MAE=0.609, train_loss=0.653, val_MAE=0.644, val_loss=0.688]Epoch 26:   3%|▎         | 26/1000 [54:53<31:31:14, 116.50s/it, lr=0.0005, test_MAE=0.771, time=116, train_MAE=0.616, train_loss=0.66, val_MAE=0.729, val_loss=0.774] Epoch 26:   3%|▎         | 27/1000 [54:53<31:26:16, 116.32s/it, lr=0.0005, test_MAE=0.771, time=116, train_MAE=0.616, train_loss=0.66, val_MAE=0.729, val_loss=0.774]Epoch 27:   3%|▎         | 27/1000 [54:53<31:26:16, 116.32s/it, lr=0.0005, test_MAE=0.771, time=116, train_MAE=0.616, train_loss=0.66, val_MAE=0.729, val_loss=0.774]Epoch 27:   3%|▎         | 27/1000 [56:48<31:26:16, 116.32s/it, lr=0.0005, test_MAE=0.86, time=116, train_MAE=0.608, train_loss=0.653, val_MAE=0.826, val_loss=0.871]Epoch 27:   3%|▎         | 28/1000 [56:48<31:21:32, 116.14s/it, lr=0.0005, test_MAE=0.86, time=116, train_MAE=0.608, train_loss=0.653, val_MAE=0.826, val_loss=0.871]Epoch 28:   3%|▎         | 28/1000 [56:48<31:21:32, 116.14s/it, lr=0.0005, test_MAE=0.86, time=116, train_MAE=0.608, train_loss=0.653, val_MAE=0.826, val_loss=0.871]Epoch 28:   3%|▎         | 28/1000 [58:44<31:21:32, 116.14s/it, lr=0.0005, test_MAE=0.827, time=115, train_MAE=0.606, train_loss=0.65, val_MAE=0.742, val_loss=0.787]Epoch 28:   3%|▎         | 29/1000 [58:44<31:15:50, 115.91s/it, lr=0.0005, test_MAE=0.827, time=115, train_MAE=0.606, train_loss=0.65, val_MAE=0.742, val_loss=0.787]Epoch 29:   3%|▎         | 29/1000 [58:44<31:15:50, 115.91s/it, lr=0.0005, test_MAE=0.827, time=115, train_MAE=0.606, train_loss=0.65, val_MAE=0.742, val_loss=0.787]Epoch 29:   3%|▎         | 29/1000 [1:00:40<31:15:50, 115.91s/it, lr=0.0005, test_MAE=0.717, time=116, train_MAE=0.619, train_loss=0.664, val_MAE=0.661, val_loss=0.706]Epoch 29:   3%|▎         | 30/1000 [1:00:40<31:15:56, 116.04s/it, lr=0.0005, test_MAE=0.717, time=116, train_MAE=0.619, train_loss=0.664, val_MAE=0.661, val_loss=0.706]Epoch 30:   3%|▎         | 30/1000 [1:00:40<31:15:56, 116.04s/it, lr=0.0005, test_MAE=0.717, time=116, train_MAE=0.619, train_loss=0.664, val_MAE=0.661, val_loss=0.706]Epoch 30:   3%|▎         | 30/1000 [1:02:37<31:15:56, 116.04s/it, lr=0.0005, test_MAE=0.708, time=116, train_MAE=0.605, train_loss=0.65, val_MAE=0.642, val_loss=0.687] Epoch    31: reducing learning rate of group 0 to 2.5000e-04.
Epoch 30:   3%|▎         | 31/1000 [1:02:37<31:16:01, 116.16s/it, lr=0.0005, test_MAE=0.708, time=116, train_MAE=0.605, train_loss=0.65, val_MAE=0.642, val_loss=0.687]Epoch 31:   3%|▎         | 31/1000 [1:02:37<31:16:01, 116.16s/it, lr=0.0005, test_MAE=0.708, time=116, train_MAE=0.605, train_loss=0.65, val_MAE=0.642, val_loss=0.687]Epoch 31:   3%|▎         | 31/1000 [1:04:32<31:16:01, 116.16s/it, lr=0.00025, test_MAE=0.694, time=116, train_MAE=0.593, train_loss=0.638, val_MAE=0.646, val_loss=0.691]Epoch 31:   3%|▎         | 32/1000 [1:04:32<31:11:29, 116.00s/it, lr=0.00025, test_MAE=0.694, time=116, train_MAE=0.593, train_loss=0.638, val_MAE=0.646, val_loss=0.691]Epoch 32:   3%|▎         | 32/1000 [1:04:32<31:11:29, 116.00s/it, lr=0.00025, test_MAE=0.694, time=116, train_MAE=0.593, train_loss=0.638, val_MAE=0.646, val_loss=0.691]Epoch 32:   3%|▎         | 32/1000 [1:06:28<31:11:29, 116.00s/it, lr=0.00025, test_MAE=0.696, time=116, train_MAE=0.592, train_loss=0.637, val_MAE=0.632, val_loss=0.677]Epoch 32:   3%|▎         | 33/1000 [1:06:28<31:09:32, 116.00s/it, lr=0.00025, test_MAE=0.696, time=116, train_MAE=0.592, train_loss=0.637, val_MAE=0.632, val_loss=0.677]Epoch 33:   3%|▎         | 33/1000 [1:06:28<31:09:32, 116.00s/it, lr=0.00025, test_MAE=0.696, time=116, train_MAE=0.592, train_loss=0.637, val_MAE=0.632, val_loss=0.677]Epoch 33:   3%|▎         | 33/1000 [1:08:24<31:09:32, 116.00s/it, lr=0.00025, test_MAE=0.707, time=116, train_MAE=0.583, train_loss=0.628, val_MAE=0.651, val_loss=0.695]Epoch 33:   3%|▎         | 34/1000 [1:08:24<31:05:43, 115.88s/it, lr=0.00025, test_MAE=0.707, time=116, train_MAE=0.583, train_loss=0.628, val_MAE=0.651, val_loss=0.695]Epoch 34:   3%|▎         | 34/1000 [1:08:24<31:05:43, 115.88s/it, lr=0.00025, test_MAE=0.707, time=116, train_MAE=0.583, train_loss=0.628, val_MAE=0.651, val_loss=0.695]Epoch 34:   3%|▎         | 34/1000 [1:10:19<31:05:43, 115.88s/it, lr=0.00025, test_MAE=0.69, time=115, train_MAE=0.587, train_loss=0.632, val_MAE=0.628, val_loss=0.672] Epoch 34:   4%|▎         | 35/1000 [1:10:19<31:01:25, 115.74s/it, lr=0.00025, test_MAE=0.69, time=115, train_MAE=0.587, train_loss=0.632, val_MAE=0.628, val_loss=0.672]Epoch 35:   4%|▎         | 35/1000 [1:10:19<31:01:25, 115.74s/it, lr=0.00025, test_MAE=0.69, time=115, train_MAE=0.587, train_loss=0.632, val_MAE=0.628, val_loss=0.672]Epoch 35:   4%|▎         | 35/1000 [1:12:15<31:01:25, 115.74s/it, lr=0.00025, test_MAE=0.717, time=116, train_MAE=0.584, train_loss=0.628, val_MAE=0.656, val_loss=0.7] Epoch 35:   4%|▎         | 36/1000 [1:12:15<31:00:27, 115.80s/it, lr=0.00025, test_MAE=0.717, time=116, train_MAE=0.584, train_loss=0.628, val_MAE=0.656, val_loss=0.7]Epoch 36:   4%|▎         | 36/1000 [1:12:15<31:00:27, 115.80s/it, lr=0.00025, test_MAE=0.717, time=116, train_MAE=0.584, train_loss=0.628, val_MAE=0.656, val_loss=0.7]Epoch 36:   4%|▎         | 36/1000 [1:14:11<31:00:27, 115.80s/it, lr=0.00025, test_MAE=0.697, time=116, train_MAE=0.577, train_loss=0.621, val_MAE=0.636, val_loss=0.68]Epoch 36:   4%|▎         | 37/1000 [1:14:11<30:57:35, 115.74s/it, lr=0.00025, test_MAE=0.697, time=116, train_MAE=0.577, train_loss=0.621, val_MAE=0.636, val_loss=0.68]Epoch 37:   4%|▎         | 37/1000 [1:14:11<30:57:35, 115.74s/it, lr=0.00025, test_MAE=0.697, time=116, train_MAE=0.577, train_loss=0.621, val_MAE=0.636, val_loss=0.68]Epoch 37:   4%|▎         | 37/1000 [1:16:06<30:57:35, 115.74s/it, lr=0.00025, test_MAE=0.713, time=115, train_MAE=0.582, train_loss=0.626, val_MAE=0.649, val_loss=0.694]Epoch 37:   4%|▍         | 38/1000 [1:16:06<30:54:03, 115.64s/it, lr=0.00025, test_MAE=0.713, time=115, train_MAE=0.582, train_loss=0.626, val_MAE=0.649, val_loss=0.694]Epoch 38:   4%|▍         | 38/1000 [1:16:06<30:54:03, 115.64s/it, lr=0.00025, test_MAE=0.713, time=115, train_MAE=0.582, train_loss=0.626, val_MAE=0.649, val_loss=0.694]Epoch 38:   4%|▍         | 38/1000 [1:18:02<30:54:03, 115.64s/it, lr=0.00025, test_MAE=0.694, time=116, train_MAE=0.578, train_loss=0.622, val_MAE=0.633, val_loss=0.677]Epoch 38:   4%|▍         | 39/1000 [1:18:02<30:53:14, 115.71s/it, lr=0.00025, test_MAE=0.694, time=116, train_MAE=0.578, train_loss=0.622, val_MAE=0.633, val_loss=0.677]Epoch 39:   4%|▍         | 39/1000 [1:18:02<30:53:14, 115.71s/it, lr=0.00025, test_MAE=0.694, time=116, train_MAE=0.578, train_loss=0.622, val_MAE=0.633, val_loss=0.677]Epoch 39:   4%|▍         | 39/1000 [1:19:58<30:53:14, 115.71s/it, lr=0.00025, test_MAE=0.751, time=116, train_MAE=0.573, train_loss=0.617, val_MAE=0.703, val_loss=0.747]Epoch 39:   4%|▍         | 40/1000 [1:19:58<30:51:12, 115.70s/it, lr=0.00025, test_MAE=0.751, time=116, train_MAE=0.573, train_loss=0.617, val_MAE=0.703, val_loss=0.747]Epoch 40:   4%|▍         | 40/1000 [1:19:58<30:51:12, 115.70s/it, lr=0.00025, test_MAE=0.751, time=116, train_MAE=0.573, train_loss=0.617, val_MAE=0.703, val_loss=0.747]Epoch 40:   4%|▍         | 40/1000 [1:21:53<30:51:12, 115.70s/it, lr=0.00025, test_MAE=0.73, time=115, train_MAE=0.58, train_loss=0.624, val_MAE=0.689, val_loss=0.733]  Epoch    41: reducing learning rate of group 0 to 1.2500e-04.
Epoch 40:   4%|▍         | 41/1000 [1:21:53<30:47:55, 115.62s/it, lr=0.00025, test_MAE=0.73, time=115, train_MAE=0.58, train_loss=0.624, val_MAE=0.689, val_loss=0.733]Epoch 41:   4%|▍         | 41/1000 [1:21:53<30:47:55, 115.62s/it, lr=0.00025, test_MAE=0.73, time=115, train_MAE=0.58, train_loss=0.624, val_MAE=0.689, val_loss=0.733]Epoch 41:   4%|▍         | 41/1000 [1:23:49<30:47:55, 115.62s/it, lr=0.000125, test_MAE=0.733, time=116, train_MAE=0.562, train_loss=0.606, val_MAE=0.677, val_loss=0.721]Epoch 41:   4%|▍         | 42/1000 [1:23:49<30:48:20, 115.76s/it, lr=0.000125, test_MAE=0.733, time=116, train_MAE=0.562, train_loss=0.606, val_MAE=0.677, val_loss=0.721]Epoch 42:   4%|▍         | 42/1000 [1:23:49<30:48:20, 115.76s/it, lr=0.000125, test_MAE=0.733, time=116, train_MAE=0.562, train_loss=0.606, val_MAE=0.677, val_loss=0.721]Epoch 42:   4%|▍         | 42/1000 [1:25:45<30:48:20, 115.76s/it, lr=0.000125, test_MAE=0.697, time=116, train_MAE=0.558, train_loss=0.602, val_MAE=0.638, val_loss=0.682]Epoch 42:   4%|▍         | 43/1000 [1:25:45<30:48:05, 115.87s/it, lr=0.000125, test_MAE=0.697, time=116, train_MAE=0.558, train_loss=0.602, val_MAE=0.638, val_loss=0.682]Epoch 43:   4%|▍         | 43/1000 [1:25:45<30:48:05, 115.87s/it, lr=0.000125, test_MAE=0.697, time=116, train_MAE=0.558, train_loss=0.602, val_MAE=0.638, val_loss=0.682]Epoch 43:   4%|▍         | 43/1000 [1:27:42<30:48:05, 115.87s/it, lr=0.000125, test_MAE=0.685, time=117, train_MAE=0.554, train_loss=0.598, val_MAE=0.63, val_loss=0.674] Epoch 43:   4%|▍         | 44/1000 [1:27:42<30:50:21, 116.13s/it, lr=0.000125, test_MAE=0.685, time=117, train_MAE=0.554, train_loss=0.598, val_MAE=0.63, val_loss=0.674]Epoch 44:   4%|▍         | 44/1000 [1:27:42<30:50:21, 116.13s/it, lr=0.000125, test_MAE=0.685, time=117, train_MAE=0.554, train_loss=0.598, val_MAE=0.63, val_loss=0.674]Epoch 44:   4%|▍         | 44/1000 [1:29:38<30:50:21, 116.13s/it, lr=0.000125, test_MAE=0.698, time=116, train_MAE=0.559, train_loss=0.603, val_MAE=0.641, val_loss=0.685]Epoch 44:   4%|▍         | 45/1000 [1:29:38<30:49:29, 116.20s/it, lr=0.000125, test_MAE=0.698, time=116, train_MAE=0.559, train_loss=0.603, val_MAE=0.641, val_loss=0.685]Epoch 45:   4%|▍         | 45/1000 [1:29:38<30:49:29, 116.20s/it, lr=0.000125, test_MAE=0.698, time=116, train_MAE=0.559, train_loss=0.603, val_MAE=0.641, val_loss=0.685]Epoch 45:   4%|▍         | 45/1000 [1:31:35<30:49:29, 116.20s/it, lr=0.000125, test_MAE=0.696, time=116, train_MAE=0.555, train_loss=0.598, val_MAE=0.637, val_loss=0.68] Epoch 45:   5%|▍         | 46/1000 [1:31:35<30:48:26, 116.25s/it, lr=0.000125, test_MAE=0.696, time=116, train_MAE=0.555, train_loss=0.598, val_MAE=0.637, val_loss=0.68]Epoch 46:   5%|▍         | 46/1000 [1:31:35<30:48:26, 116.25s/it, lr=0.000125, test_MAE=0.696, time=116, train_MAE=0.555, train_loss=0.598, val_MAE=0.637, val_loss=0.68]Epoch 46:   5%|▍         | 46/1000 [1:33:32<30:48:26, 116.25s/it, lr=0.000125, test_MAE=0.697, time=117, train_MAE=0.548, train_loss=0.592, val_MAE=0.636, val_loss=0.679]Epoch    47: reducing learning rate of group 0 to 6.2500e-05.
Epoch 46:   5%|▍         | 47/1000 [1:33:32<30:48:55, 116.41s/it, lr=0.000125, test_MAE=0.697, time=117, train_MAE=0.548, train_loss=0.592, val_MAE=0.636, val_loss=0.679]Epoch 47:   5%|▍         | 47/1000 [1:33:32<30:48:55, 116.41s/it, lr=0.000125, test_MAE=0.697, time=117, train_MAE=0.548, train_loss=0.592, val_MAE=0.636, val_loss=0.679]Epoch 47:   5%|▍         | 47/1000 [1:35:28<30:48:55, 116.41s/it, lr=6.25e-5, test_MAE=0.762, time=116, train_MAE=0.533, train_loss=0.577, val_MAE=0.701, val_loss=0.744] Epoch 47:   5%|▍         | 48/1000 [1:35:28<30:47:21, 116.43s/it, lr=6.25e-5, test_MAE=0.762, time=116, train_MAE=0.533, train_loss=0.577, val_MAE=0.701, val_loss=0.744]Epoch 48:   5%|▍         | 48/1000 [1:35:28<30:47:21, 116.43s/it, lr=6.25e-5, test_MAE=0.762, time=116, train_MAE=0.533, train_loss=0.577, val_MAE=0.701, val_loss=0.744]Epoch 48:   5%|▍         | 48/1000 [1:37:24<30:47:21, 116.43s/it, lr=6.25e-5, test_MAE=0.713, time=116, train_MAE=0.534, train_loss=0.577, val_MAE=0.653, val_loss=0.696]Epoch 48:   5%|▍         | 49/1000 [1:37:24<30:44:43, 116.39s/it, lr=6.25e-5, test_MAE=0.713, time=116, train_MAE=0.534, train_loss=0.577, val_MAE=0.653, val_loss=0.696]Epoch 49:   5%|▍         | 49/1000 [1:37:24<30:44:43, 116.39s/it, lr=6.25e-5, test_MAE=0.713, time=116, train_MAE=0.534, train_loss=0.577, val_MAE=0.653, val_loss=0.696]Epoch 49:   5%|▍         | 49/1000 [1:39:21<30:44:43, 116.39s/it, lr=6.25e-5, test_MAE=0.702, time=117, train_MAE=0.527, train_loss=0.571, val_MAE=0.638, val_loss=0.682]Epoch 49:   5%|▌         | 50/1000 [1:39:21<30:45:38, 116.57s/it, lr=6.25e-5, test_MAE=0.702, time=117, train_MAE=0.527, train_loss=0.571, val_MAE=0.638, val_loss=0.682]Epoch 50:   5%|▌         | 50/1000 [1:39:21<30:45:38, 116.57s/it, lr=6.25e-5, test_MAE=0.702, time=117, train_MAE=0.527, train_loss=0.571, val_MAE=0.638, val_loss=0.682]Epoch 50:   5%|▌         | 50/1000 [1:41:18<30:45:38, 116.57s/it, lr=6.25e-5, test_MAE=0.69, time=116, train_MAE=0.525, train_loss=0.568, val_MAE=0.63, val_loss=0.673]  Epoch 50:   5%|▌         | 51/1000 [1:41:18<30:42:46, 116.51s/it, lr=6.25e-5, test_MAE=0.69, time=116, train_MAE=0.525, train_loss=0.568, val_MAE=0.63, val_loss=0.673]Epoch 51:   5%|▌         | 51/1000 [1:41:18<30:42:46, 116.51s/it, lr=6.25e-5, test_MAE=0.69, time=116, train_MAE=0.525, train_loss=0.568, val_MAE=0.63, val_loss=0.673]Epoch 51:   5%|▌         | 51/1000 [1:43:14<30:42:46, 116.51s/it, lr=6.25e-5, test_MAE=0.698, time=116, train_MAE=0.522, train_loss=0.565, val_MAE=0.64, val_loss=0.683]Epoch 51:   5%|▌         | 52/1000 [1:43:14<30:38:48, 116.38s/it, lr=6.25e-5, test_MAE=0.698, time=116, train_MAE=0.522, train_loss=0.565, val_MAE=0.64, val_loss=0.683]Epoch 52:   5%|▌         | 52/1000 [1:43:14<30:38:48, 116.38s/it, lr=6.25e-5, test_MAE=0.698, time=116, train_MAE=0.522, train_loss=0.565, val_MAE=0.64, val_loss=0.683]Epoch 52:   5%|▌         | 52/1000 [1:45:10<30:38:48, 116.38s/it, lr=6.25e-5, test_MAE=0.712, time=117, train_MAE=0.524, train_loss=0.567, val_MAE=0.646, val_loss=0.689]Epoch    53: reducing learning rate of group 0 to 3.1250e-05.
Epoch 52:   5%|▌         | 53/1000 [1:45:10<30:38:13, 116.47s/it, lr=6.25e-5, test_MAE=0.712, time=117, train_MAE=0.524, train_loss=0.567, val_MAE=0.646, val_loss=0.689]Epoch 53:   5%|▌         | 53/1000 [1:45:10<30:38:13, 116.47s/it, lr=6.25e-5, test_MAE=0.712, time=117, train_MAE=0.524, train_loss=0.567, val_MAE=0.646, val_loss=0.689]Epoch 53:   5%|▌         | 53/1000 [1:47:07<30:38:13, 116.47s/it, lr=3.13e-5, test_MAE=0.694, time=117, train_MAE=0.517, train_loss=0.56, val_MAE=0.635, val_loss=0.678] Epoch 53:   5%|▌         | 54/1000 [1:47:07<30:38:03, 116.58s/it, lr=3.13e-5, test_MAE=0.694, time=117, train_MAE=0.517, train_loss=0.56, val_MAE=0.635, val_loss=0.678]Epoch 54:   5%|▌         | 54/1000 [1:47:07<30:38:03, 116.58s/it, lr=3.13e-5, test_MAE=0.694, time=117, train_MAE=0.517, train_loss=0.56, val_MAE=0.635, val_loss=0.678]Epoch 54:   5%|▌         | 54/1000 [1:49:04<30:38:03, 116.58s/it, lr=3.13e-5, test_MAE=0.697, time=116, train_MAE=0.51, train_loss=0.554, val_MAE=0.634, val_loss=0.678]Epoch 54:   6%|▌         | 55/1000 [1:49:04<30:35:04, 116.51s/it, lr=3.13e-5, test_MAE=0.697, time=116, train_MAE=0.51, train_loss=0.554, val_MAE=0.634, val_loss=0.678]Epoch 55:   6%|▌         | 55/1000 [1:49:04<30:35:04, 116.51s/it, lr=3.13e-5, test_MAE=0.697, time=116, train_MAE=0.51, train_loss=0.554, val_MAE=0.634, val_loss=0.678]Epoch 55:   6%|▌         | 55/1000 [1:51:00<30:35:04, 116.51s/it, lr=3.13e-5, test_MAE=0.695, time=117, train_MAE=0.52, train_loss=0.563, val_MAE=0.634, val_loss=0.677]Epoch 55:   6%|▌         | 56/1000 [1:51:00<30:34:19, 116.59s/it, lr=3.13e-5, test_MAE=0.695, time=117, train_MAE=0.52, train_loss=0.563, val_MAE=0.634, val_loss=0.677]Epoch 56:   6%|▌         | 56/1000 [1:51:00<30:34:19, 116.59s/it, lr=3.13e-5, test_MAE=0.695, time=117, train_MAE=0.52, train_loss=0.563, val_MAE=0.634, val_loss=0.677]Epoch 56:   6%|▌         | 56/1000 [1:52:57<30:34:19, 116.59s/it, lr=3.13e-5, test_MAE=0.704, time=116, train_MAE=0.508, train_loss=0.552, val_MAE=0.639, val_loss=0.682]Epoch 56:   6%|▌         | 57/1000 [1:52:57<30:31:42, 116.55s/it, lr=3.13e-5, test_MAE=0.704, time=116, train_MAE=0.508, train_loss=0.552, val_MAE=0.639, val_loss=0.682]Epoch 57:   6%|▌         | 57/1000 [1:52:57<30:31:42, 116.55s/it, lr=3.13e-5, test_MAE=0.704, time=116, train_MAE=0.508, train_loss=0.552, val_MAE=0.639, val_loss=0.682]Epoch 57:   6%|▌         | 57/1000 [1:54:53<30:31:42, 116.55s/it, lr=3.13e-5, test_MAE=0.702, time=116, train_MAE=0.508, train_loss=0.551, val_MAE=0.637, val_loss=0.68] Epoch 57:   6%|▌         | 58/1000 [1:54:53<30:27:43, 116.42s/it, lr=3.13e-5, test_MAE=0.702, time=116, train_MAE=0.508, train_loss=0.551, val_MAE=0.637, val_loss=0.68]Epoch 58:   6%|▌         | 58/1000 [1:54:53<30:27:43, 116.42s/it, lr=3.13e-5, test_MAE=0.702, time=116, train_MAE=0.508, train_loss=0.551, val_MAE=0.637, val_loss=0.68]Epoch 58:   6%|▌         | 58/1000 [1:56:50<30:27:43, 116.42s/it, lr=3.13e-5, test_MAE=0.695, time=117, train_MAE=0.505, train_loss=0.548, val_MAE=0.632, val_loss=0.675]Epoch    59: reducing learning rate of group 0 to 1.5625e-05.
Epoch 58:   6%|▌         | 59/1000 [1:56:50<30:27:19, 116.51s/it, lr=3.13e-5, test_MAE=0.695, time=117, train_MAE=0.505, train_loss=0.548, val_MAE=0.632, val_loss=0.675]Epoch 59:   6%|▌         | 59/1000 [1:56:50<30:27:19, 116.51s/it, lr=3.13e-5, test_MAE=0.695, time=117, train_MAE=0.505, train_loss=0.548, val_MAE=0.632, val_loss=0.675]Epoch 59:   6%|▌         | 59/1000 [1:58:46<30:27:19, 116.51s/it, lr=1.56e-5, test_MAE=0.699, time=116, train_MAE=0.5, train_loss=0.543, val_MAE=0.632, val_loss=0.675]  Epoch 59:   6%|▌         | 60/1000 [1:58:46<30:24:49, 116.48s/it, lr=1.56e-5, test_MAE=0.699, time=116, train_MAE=0.5, train_loss=0.543, val_MAE=0.632, val_loss=0.675]Epoch 60:   6%|▌         | 60/1000 [1:58:46<30:24:49, 116.48s/it, lr=1.56e-5, test_MAE=0.699, time=116, train_MAE=0.5, train_loss=0.543, val_MAE=0.632, val_loss=0.675]Epoch 60:   6%|▌         | 60/1000 [2:00:43<30:24:49, 116.48s/it, lr=1.56e-5, test_MAE=0.707, time=116, train_MAE=0.506, train_loss=0.549, val_MAE=0.638, val_loss=0.681]Epoch 60:   6%|▌         | 61/1000 [2:00:43<30:22:53, 116.48s/it, lr=1.56e-5, test_MAE=0.707, time=116, train_MAE=0.506, train_loss=0.549, val_MAE=0.638, val_loss=0.681]Epoch 61:   6%|▌         | 61/1000 [2:00:43<30:22:53, 116.48s/it, lr=1.56e-5, test_MAE=0.707, time=116, train_MAE=0.506, train_loss=0.549, val_MAE=0.638, val_loss=0.681]Epoch 61:   6%|▌         | 61/1000 [2:02:39<30:22:53, 116.48s/it, lr=1.56e-5, test_MAE=0.693, time=117, train_MAE=0.497, train_loss=0.54, val_MAE=0.634, val_loss=0.677] Epoch 61:   6%|▌         | 62/1000 [2:02:39<30:22:14, 116.56s/it, lr=1.56e-5, test_MAE=0.693, time=117, train_MAE=0.497, train_loss=0.54, val_MAE=0.634, val_loss=0.677]Epoch 62:   6%|▌         | 62/1000 [2:02:39<30:22:14, 116.56s/it, lr=1.56e-5, test_MAE=0.693, time=117, train_MAE=0.497, train_loss=0.54, val_MAE=0.634, val_loss=0.677]Epoch 62:   6%|▌         | 62/1000 [2:04:36<30:22:14, 116.56s/it, lr=1.56e-5, test_MAE=0.701, time=116, train_MAE=0.502, train_loss=0.545, val_MAE=0.635, val_loss=0.678]Epoch 62:   6%|▋         | 63/1000 [2:04:36<30:18:55, 116.47s/it, lr=1.56e-5, test_MAE=0.701, time=116, train_MAE=0.502, train_loss=0.545, val_MAE=0.635, val_loss=0.678]Epoch 63:   6%|▋         | 63/1000 [2:04:36<30:18:55, 116.47s/it, lr=1.56e-5, test_MAE=0.701, time=116, train_MAE=0.502, train_loss=0.545, val_MAE=0.635, val_loss=0.678]Epoch 63:   6%|▋         | 63/1000 [2:06:32<30:18:55, 116.47s/it, lr=1.56e-5, test_MAE=0.703, time=117, train_MAE=0.498, train_loss=0.541, val_MAE=0.634, val_loss=0.677]Epoch 63:   6%|▋         | 64/1000 [2:06:32<30:18:22, 116.56s/it, lr=1.56e-5, test_MAE=0.703, time=117, train_MAE=0.498, train_loss=0.541, val_MAE=0.634, val_loss=0.677]Epoch 64:   6%|▋         | 64/1000 [2:06:32<30:18:22, 116.56s/it, lr=1.56e-5, test_MAE=0.703, time=117, train_MAE=0.498, train_loss=0.541, val_MAE=0.634, val_loss=0.677]Epoch 64:   6%|▋         | 64/1000 [2:08:29<30:18:22, 116.56s/it, lr=1.56e-5, test_MAE=0.705, time=116, train_MAE=0.493, train_loss=0.536, val_MAE=0.639, val_loss=0.682]Epoch    65: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 64:   6%|▋         | 64/1000 [2:08:29<31:19:09, 120.46s/it, lr=1.56e-5, test_MAE=0.705, time=116, train_MAE=0.493, train_loss=0.536, val_MAE=0.639, val_loss=0.682]
Test MAE: 0.7046
Train MAE: 0.4891
Convergence Time (Epochs): 64.0000
TOTAL TIME TAKEN: 7767.2677s
AVG TIME PER EPOCH: 118.5874s
