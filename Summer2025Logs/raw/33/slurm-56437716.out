I'm echoing to stdout
I'm echoing to stderr
My JobID is 56437716
I have 8 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.1553s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 10, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'sparse_vec', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_all', 'num_eigs': 15, 'bias_mode': 'spatial', 'eigval_hidden_dim': 5, 'eigval_num_hidden_layer': 3, 'l1_reg': 1e-06, 'l2_reg': 0.0001, 'gen_reg': 0.0, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/zinc_train_kway.csv', 'test': 'supp_data/molecules/zinc_test_part_kway.csv', 'val': 'supp_data/molecules/zinc_val_kway.csv'}, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [02:24<?, ?it/s, lr=0.001, test_MAE=0.869, time=145, train_MAE=0.975, train_loss=1.01, val_MAE=0.848, val_loss=0.887]Epoch 0:   0%|          | 1/1000 [02:24<40:13:17, 144.94s/it, lr=0.001, test_MAE=0.869, time=145, train_MAE=0.975, train_loss=1.01, val_MAE=0.848, val_loss=0.887]Epoch 1:   0%|          | 1/1000 [02:24<40:13:17, 144.94s/it, lr=0.001, test_MAE=0.869, time=145, train_MAE=0.975, train_loss=1.01, val_MAE=0.848, val_loss=0.887]Epoch 1:   0%|          | 1/1000 [04:38<40:13:17, 144.94s/it, lr=0.001, test_MAE=0.763, time=133, train_MAE=0.777, train_loss=0.816, val_MAE=0.727, val_loss=0.767]Epoch 1:   0%|          | 2/1000 [04:38<39:12:23, 141.43s/it, lr=0.001, test_MAE=0.763, time=133, train_MAE=0.777, train_loss=0.816, val_MAE=0.727, val_loss=0.767]Epoch 2:   0%|          | 2/1000 [04:38<39:12:23, 141.43s/it, lr=0.001, test_MAE=0.763, time=133, train_MAE=0.777, train_loss=0.816, val_MAE=0.727, val_loss=0.767]Epoch 2:   0%|          | 2/1000 [06:51<39:12:23, 141.43s/it, lr=0.001, test_MAE=0.801, time=133, train_MAE=0.723, train_loss=0.763, val_MAE=0.749, val_loss=0.789]Epoch 2:   0%|          | 3/1000 [06:51<38:29:25, 138.98s/it, lr=0.001, test_MAE=0.801, time=133, train_MAE=0.723, train_loss=0.763, val_MAE=0.749, val_loss=0.789]Epoch 3:   0%|          | 3/1000 [06:51<38:29:25, 138.98s/it, lr=0.001, test_MAE=0.801, time=133, train_MAE=0.723, train_loss=0.763, val_MAE=0.749, val_loss=0.789]Epoch 3:   0%|          | 3/1000 [09:03<38:29:25, 138.98s/it, lr=0.001, test_MAE=0.768, time=132, train_MAE=0.723, train_loss=0.762, val_MAE=0.71, val_loss=0.75]  Epoch 3:   0%|          | 4/1000 [09:03<37:54:46, 137.03s/it, lr=0.001, test_MAE=0.768, time=132, train_MAE=0.723, train_loss=0.762, val_MAE=0.71, val_loss=0.75]Epoch 4:   0%|          | 4/1000 [09:03<37:54:46, 137.03s/it, lr=0.001, test_MAE=0.768, time=132, train_MAE=0.723, train_loss=0.762, val_MAE=0.71, val_loss=0.75]Epoch 4:   0%|          | 4/1000 [11:16<37:54:46, 137.03s/it, lr=0.001, test_MAE=0.754, time=133, train_MAE=0.688, train_loss=0.727, val_MAE=0.697, val_loss=0.736]Epoch 4:   0%|          | 5/1000 [11:16<37:30:27, 135.71s/it, lr=0.001, test_MAE=0.754, time=133, train_MAE=0.688, train_loss=0.727, val_MAE=0.697, val_loss=0.736]Epoch 5:   0%|          | 5/1000 [11:16<37:30:27, 135.71s/it, lr=0.001, test_MAE=0.754, time=133, train_MAE=0.688, train_loss=0.727, val_MAE=0.697, val_loss=0.736]Epoch 5:   0%|          | 5/1000 [13:29<37:30:27, 135.71s/it, lr=0.001, test_MAE=0.759, time=133, train_MAE=0.695, train_loss=0.734, val_MAE=0.715, val_loss=0.754]Epoch 5:   1%|          | 6/1000 [13:29<37:15:32, 134.94s/it, lr=0.001, test_MAE=0.759, time=133, train_MAE=0.695, train_loss=0.734, val_MAE=0.715, val_loss=0.754]Epoch 6:   1%|          | 6/1000 [13:29<37:15:32, 134.94s/it, lr=0.001, test_MAE=0.759, time=133, train_MAE=0.695, train_loss=0.734, val_MAE=0.715, val_loss=0.754]Epoch 6:   1%|          | 6/1000 [15:43<37:15:32, 134.94s/it, lr=0.001, test_MAE=0.726, time=133, train_MAE=0.688, train_loss=0.727, val_MAE=0.671, val_loss=0.71] Epoch 6:   1%|          | 7/1000 [15:43<37:05:13, 134.45s/it, lr=0.001, test_MAE=0.726, time=133, train_MAE=0.688, train_loss=0.727, val_MAE=0.671, val_loss=0.71]Epoch 7:   1%|          | 7/1000 [15:43<37:05:13, 134.45s/it, lr=0.001, test_MAE=0.726, time=133, train_MAE=0.688, train_loss=0.727, val_MAE=0.671, val_loss=0.71]Epoch 7:   1%|          | 7/1000 [17:56<37:05:13, 134.45s/it, lr=0.001, test_MAE=0.72, time=133, train_MAE=0.664, train_loss=0.703, val_MAE=0.675, val_loss=0.714]Epoch 7:   1%|          | 8/1000 [17:56<36:56:57, 134.09s/it, lr=0.001, test_MAE=0.72, time=133, train_MAE=0.664, train_loss=0.703, val_MAE=0.675, val_loss=0.714]Epoch 8:   1%|          | 8/1000 [17:56<36:56:57, 134.09s/it, lr=0.001, test_MAE=0.72, time=133, train_MAE=0.664, train_loss=0.703, val_MAE=0.675, val_loss=0.714]Epoch 8:   1%|          | 8/1000 [20:09<36:56:57, 134.09s/it, lr=0.001, test_MAE=0.731, time=133, train_MAE=0.67, train_loss=0.709, val_MAE=0.689, val_loss=0.729]Epoch 8:   1%|          | 9/1000 [20:09<36:51:10, 133.88s/it, lr=0.001, test_MAE=0.731, time=133, train_MAE=0.67, train_loss=0.709, val_MAE=0.689, val_loss=0.729]Epoch 9:   1%|          | 9/1000 [20:09<36:51:10, 133.88s/it, lr=0.001, test_MAE=0.731, time=133, train_MAE=0.67, train_loss=0.709, val_MAE=0.689, val_loss=0.729]Epoch 9:   1%|          | 9/1000 [22:23<36:51:10, 133.88s/it, lr=0.001, test_MAE=0.737, time=134, train_MAE=0.656, train_loss=0.696, val_MAE=0.675, val_loss=0.714]Epoch 9:   1%|          | 10/1000 [22:23<36:47:30, 133.79s/it, lr=0.001, test_MAE=0.737, time=134, train_MAE=0.656, train_loss=0.696, val_MAE=0.675, val_loss=0.714]Epoch 10:   1%|          | 10/1000 [22:23<36:47:30, 133.79s/it, lr=0.001, test_MAE=0.737, time=134, train_MAE=0.656, train_loss=0.696, val_MAE=0.675, val_loss=0.714]Epoch 10:   1%|          | 10/1000 [24:36<36:47:30, 133.79s/it, lr=0.001, test_MAE=0.748, time=133, train_MAE=0.652, train_loss=0.692, val_MAE=0.687, val_loss=0.727]Epoch 10:   1%|          | 11/1000 [24:36<36:43:13, 133.66s/it, lr=0.001, test_MAE=0.748, time=133, train_MAE=0.652, train_loss=0.692, val_MAE=0.687, val_loss=0.727]Epoch 11:   1%|          | 11/1000 [24:36<36:43:13, 133.66s/it, lr=0.001, test_MAE=0.748, time=133, train_MAE=0.652, train_loss=0.692, val_MAE=0.687, val_loss=0.727]Epoch 11:   1%|          | 11/1000 [26:49<36:43:13, 133.66s/it, lr=0.001, test_MAE=0.76, time=133, train_MAE=0.668, train_loss=0.708, val_MAE=0.7, val_loss=0.74]    Epoch 11:   1%|          | 12/1000 [26:49<36:36:12, 133.37s/it, lr=0.001, test_MAE=0.76, time=133, train_MAE=0.668, train_loss=0.708, val_MAE=0.7, val_loss=0.74]Epoch 12:   1%|          | 12/1000 [26:49<36:36:12, 133.37s/it, lr=0.001, test_MAE=0.76, time=133, train_MAE=0.668, train_loss=0.708, val_MAE=0.7, val_loss=0.74]Epoch 12:   1%|          | 12/1000 [29:03<36:36:12, 133.37s/it, lr=0.001, test_MAE=0.779, time=134, train_MAE=0.651, train_loss=0.691, val_MAE=0.711, val_loss=0.751]Epoch    13: reducing learning rate of group 0 to 5.0000e-04.
Epoch 12:   1%|▏         | 13/1000 [29:03<36:35:54, 133.49s/it, lr=0.001, test_MAE=0.779, time=134, train_MAE=0.651, train_loss=0.691, val_MAE=0.711, val_loss=0.751]Epoch 13:   1%|▏         | 13/1000 [29:03<36:35:54, 133.49s/it, lr=0.001, test_MAE=0.779, time=134, train_MAE=0.651, train_loss=0.691, val_MAE=0.711, val_loss=0.751]Epoch 13:   1%|▏         | 13/1000 [31:16<36:35:54, 133.49s/it, lr=0.0005, test_MAE=0.712, time=133, train_MAE=0.634, train_loss=0.674, val_MAE=0.657, val_loss=0.697]Epoch 13:   1%|▏         | 14/1000 [31:16<36:32:25, 133.41s/it, lr=0.0005, test_MAE=0.712, time=133, train_MAE=0.634, train_loss=0.674, val_MAE=0.657, val_loss=0.697]Epoch 14:   1%|▏         | 14/1000 [31:16<36:32:25, 133.41s/it, lr=0.0005, test_MAE=0.712, time=133, train_MAE=0.634, train_loss=0.674, val_MAE=0.657, val_loss=0.697]Epoch 14:   1%|▏         | 14/1000 [33:29<36:32:25, 133.41s/it, lr=0.0005, test_MAE=0.718, time=133, train_MAE=0.624, train_loss=0.663, val_MAE=0.658, val_loss=0.698]Epoch 14:   2%|▏         | 15/1000 [33:29<36:27:41, 133.26s/it, lr=0.0005, test_MAE=0.718, time=133, train_MAE=0.624, train_loss=0.663, val_MAE=0.658, val_loss=0.698]Epoch 15:   2%|▏         | 15/1000 [33:29<36:27:41, 133.26s/it, lr=0.0005, test_MAE=0.718, time=133, train_MAE=0.624, train_loss=0.663, val_MAE=0.658, val_loss=0.698]Epoch 15:   2%|▏         | 15/1000 [35:43<36:27:41, 133.26s/it, lr=0.0005, test_MAE=0.742, time=134, train_MAE=0.628, train_loss=0.668, val_MAE=0.682, val_loss=0.722]Epoch 15:   2%|▏         | 16/1000 [35:43<36:28:59, 133.48s/it, lr=0.0005, test_MAE=0.742, time=134, train_MAE=0.628, train_loss=0.668, val_MAE=0.682, val_loss=0.722]Epoch 16:   2%|▏         | 16/1000 [35:43<36:28:59, 133.48s/it, lr=0.0005, test_MAE=0.742, time=134, train_MAE=0.628, train_loss=0.668, val_MAE=0.682, val_loss=0.722]Epoch 16:   2%|▏         | 16/1000 [37:56<36:28:59, 133.48s/it, lr=0.0005, test_MAE=0.699, time=133, train_MAE=0.616, train_loss=0.656, val_MAE=0.645, val_loss=0.685]Epoch 16:   2%|▏         | 17/1000 [37:56<36:26:03, 133.43s/it, lr=0.0005, test_MAE=0.699, time=133, train_MAE=0.616, train_loss=0.656, val_MAE=0.645, val_loss=0.685]Epoch 17:   2%|▏         | 17/1000 [37:56<36:26:03, 133.43s/it, lr=0.0005, test_MAE=0.699, time=133, train_MAE=0.616, train_loss=0.656, val_MAE=0.645, val_loss=0.685]Epoch 17:   2%|▏         | 17/1000 [40:09<36:26:03, 133.43s/it, lr=0.0005, test_MAE=0.749, time=133, train_MAE=0.618, train_loss=0.658, val_MAE=0.691, val_loss=0.731]Epoch 17:   2%|▏         | 18/1000 [40:09<36:21:03, 133.26s/it, lr=0.0005, test_MAE=0.749, time=133, train_MAE=0.618, train_loss=0.658, val_MAE=0.691, val_loss=0.731]Epoch 18:   2%|▏         | 18/1000 [40:09<36:21:03, 133.26s/it, lr=0.0005, test_MAE=0.749, time=133, train_MAE=0.618, train_loss=0.658, val_MAE=0.691, val_loss=0.731]Epoch 18:   2%|▏         | 18/1000 [42:23<36:21:03, 133.26s/it, lr=0.0005, test_MAE=0.714, time=134, train_MAE=0.617, train_loss=0.657, val_MAE=0.663, val_loss=0.703]Epoch 18:   2%|▏         | 19/1000 [42:23<36:20:57, 133.39s/it, lr=0.0005, test_MAE=0.714, time=134, train_MAE=0.617, train_loss=0.657, val_MAE=0.663, val_loss=0.703]Epoch 19:   2%|▏         | 19/1000 [42:23<36:20:57, 133.39s/it, lr=0.0005, test_MAE=0.714, time=134, train_MAE=0.617, train_loss=0.657, val_MAE=0.663, val_loss=0.703]Epoch 19:   2%|▏         | 19/1000 [44:36<36:20:57, 133.39s/it, lr=0.0005, test_MAE=0.722, time=133, train_MAE=0.609, train_loss=0.648, val_MAE=0.656, val_loss=0.696]Epoch 19:   2%|▏         | 20/1000 [44:36<36:17:43, 133.33s/it, lr=0.0005, test_MAE=0.722, time=133, train_MAE=0.609, train_loss=0.648, val_MAE=0.656, val_loss=0.696]Epoch 20:   2%|▏         | 20/1000 [44:36<36:17:43, 133.33s/it, lr=0.0005, test_MAE=0.722, time=133, train_MAE=0.609, train_loss=0.648, val_MAE=0.656, val_loss=0.696]Epoch 20:   2%|▏         | 20/1000 [46:49<36:17:43, 133.33s/it, lr=0.0005, test_MAE=0.706, time=133, train_MAE=0.613, train_loss=0.653, val_MAE=0.653, val_loss=0.693]Epoch 20:   2%|▏         | 21/1000 [46:49<36:14:49, 133.29s/it, lr=0.0005, test_MAE=0.706, time=133, train_MAE=0.613, train_loss=0.653, val_MAE=0.653, val_loss=0.693]Epoch 21:   2%|▏         | 21/1000 [46:49<36:14:49, 133.29s/it, lr=0.0005, test_MAE=0.706, time=133, train_MAE=0.613, train_loss=0.653, val_MAE=0.653, val_loss=0.693]Epoch 21:   2%|▏         | 21/1000 [49:03<36:14:49, 133.29s/it, lr=0.0005, test_MAE=0.705, time=134, train_MAE=0.613, train_loss=0.653, val_MAE=0.652, val_loss=0.692]Epoch 21:   2%|▏         | 22/1000 [49:03<36:14:11, 133.39s/it, lr=0.0005, test_MAE=0.705, time=134, train_MAE=0.613, train_loss=0.653, val_MAE=0.652, val_loss=0.692]Epoch 22:   2%|▏         | 22/1000 [49:03<36:14:11, 133.39s/it, lr=0.0005, test_MAE=0.705, time=134, train_MAE=0.613, train_loss=0.653, val_MAE=0.652, val_loss=0.692]Epoch 22:   2%|▏         | 22/1000 [51:15<36:14:11, 133.39s/it, lr=0.0005, test_MAE=0.705, time=133, train_MAE=0.608, train_loss=0.648, val_MAE=0.648, val_loss=0.688]Epoch    23: reducing learning rate of group 0 to 2.5000e-04.
Epoch 22:   2%|▏         | 23/1000 [51:15<36:09:29, 133.23s/it, lr=0.0005, test_MAE=0.705, time=133, train_MAE=0.608, train_loss=0.648, val_MAE=0.648, val_loss=0.688]Epoch 23:   2%|▏         | 23/1000 [51:15<36:09:29, 133.23s/it, lr=0.0005, test_MAE=0.705, time=133, train_MAE=0.608, train_loss=0.648, val_MAE=0.648, val_loss=0.688]Epoch 23:   2%|▏         | 23/1000 [53:29<36:09:29, 133.23s/it, lr=0.00025, test_MAE=0.706, time=134, train_MAE=0.601, train_loss=0.641, val_MAE=0.657, val_loss=0.696]Epoch 23:   2%|▏         | 24/1000 [53:29<36:09:50, 133.39s/it, lr=0.00025, test_MAE=0.706, time=134, train_MAE=0.601, train_loss=0.641, val_MAE=0.657, val_loss=0.696]Epoch 24:   2%|▏         | 24/1000 [53:29<36:09:50, 133.39s/it, lr=0.00025, test_MAE=0.706, time=134, train_MAE=0.601, train_loss=0.641, val_MAE=0.657, val_loss=0.696]Epoch 24:   2%|▏         | 24/1000 [55:43<36:09:50, 133.39s/it, lr=0.00025, test_MAE=0.7, time=133, train_MAE=0.602, train_loss=0.642, val_MAE=0.648, val_loss=0.688]  Epoch 24:   2%|▎         | 25/1000 [55:43<36:07:50, 133.41s/it, lr=0.00025, test_MAE=0.7, time=133, train_MAE=0.602, train_loss=0.642, val_MAE=0.648, val_loss=0.688]Epoch 25:   2%|▎         | 25/1000 [55:43<36:07:50, 133.41s/it, lr=0.00025, test_MAE=0.7, time=133, train_MAE=0.602, train_loss=0.642, val_MAE=0.648, val_loss=0.688]Epoch 25:   2%|▎         | 25/1000 [57:56<36:07:50, 133.41s/it, lr=0.00025, test_MAE=0.701, time=133, train_MAE=0.593, train_loss=0.633, val_MAE=0.643, val_loss=0.683]Epoch 25:   3%|▎         | 26/1000 [57:56<36:04:17, 133.32s/it, lr=0.00025, test_MAE=0.701, time=133, train_MAE=0.593, train_loss=0.633, val_MAE=0.643, val_loss=0.683]Epoch 26:   3%|▎         | 26/1000 [57:56<36:04:17, 133.32s/it, lr=0.00025, test_MAE=0.701, time=133, train_MAE=0.593, train_loss=0.633, val_MAE=0.643, val_loss=0.683]Epoch 26:   3%|▎         | 26/1000 [1:00:09<36:04:17, 133.32s/it, lr=0.00025, test_MAE=0.697, time=134, train_MAE=0.589, train_loss=0.629, val_MAE=0.648, val_loss=0.687]Epoch 26:   3%|▎         | 27/1000 [1:00:09<36:03:35, 133.42s/it, lr=0.00025, test_MAE=0.697, time=134, train_MAE=0.589, train_loss=0.629, val_MAE=0.648, val_loss=0.687]Epoch 27:   3%|▎         | 27/1000 [1:00:09<36:03:35, 133.42s/it, lr=0.00025, test_MAE=0.697, time=134, train_MAE=0.589, train_loss=0.629, val_MAE=0.648, val_loss=0.687]Epoch 27:   3%|▎         | 27/1000 [1:02:23<36:03:35, 133.42s/it, lr=0.00025, test_MAE=0.708, time=133, train_MAE=0.589, train_loss=0.629, val_MAE=0.65, val_loss=0.69]  Epoch 27:   3%|▎         | 28/1000 [1:02:23<36:00:23, 133.36s/it, lr=0.00025, test_MAE=0.708, time=133, train_MAE=0.589, train_loss=0.629, val_MAE=0.65, val_loss=0.69]Epoch 28:   3%|▎         | 28/1000 [1:02:23<36:00:23, 133.36s/it, lr=0.00025, test_MAE=0.708, time=133, train_MAE=0.589, train_loss=0.629, val_MAE=0.65, val_loss=0.69]Epoch 28:   3%|▎         | 28/1000 [1:04:35<36:00:23, 133.36s/it, lr=0.00025, test_MAE=0.714, time=133, train_MAE=0.588, train_loss=0.627, val_MAE=0.653, val_loss=0.692]Epoch 28:   3%|▎         | 29/1000 [1:04:35<35:55:22, 133.19s/it, lr=0.00025, test_MAE=0.714, time=133, train_MAE=0.588, train_loss=0.627, val_MAE=0.653, val_loss=0.692]Epoch 29:   3%|▎         | 29/1000 [1:04:35<35:55:22, 133.19s/it, lr=0.00025, test_MAE=0.714, time=133, train_MAE=0.588, train_loss=0.627, val_MAE=0.653, val_loss=0.692]Epoch 29:   3%|▎         | 29/1000 [1:06:49<35:55:22, 133.19s/it, lr=0.00025, test_MAE=0.703, time=134, train_MAE=0.585, train_loss=0.625, val_MAE=0.645, val_loss=0.685]Epoch 29:   3%|▎         | 30/1000 [1:06:49<35:56:48, 133.41s/it, lr=0.00025, test_MAE=0.703, time=134, train_MAE=0.585, train_loss=0.625, val_MAE=0.645, val_loss=0.685]Epoch 30:   3%|▎         | 30/1000 [1:06:49<35:56:48, 133.41s/it, lr=0.00025, test_MAE=0.703, time=134, train_MAE=0.585, train_loss=0.625, val_MAE=0.645, val_loss=0.685]Epoch 30:   3%|▎         | 30/1000 [1:09:03<35:56:48, 133.41s/it, lr=0.00025, test_MAE=0.705, time=133, train_MAE=0.592, train_loss=0.632, val_MAE=0.653, val_loss=0.693]Epoch 30:   3%|▎         | 31/1000 [1:09:03<35:53:54, 133.37s/it, lr=0.00025, test_MAE=0.705, time=133, train_MAE=0.592, train_loss=0.632, val_MAE=0.653, val_loss=0.693]Epoch 31:   3%|▎         | 31/1000 [1:09:03<35:53:54, 133.37s/it, lr=0.00025, test_MAE=0.705, time=133, train_MAE=0.592, train_loss=0.632, val_MAE=0.653, val_loss=0.693]Epoch 31:   3%|▎         | 31/1000 [1:11:15<35:53:54, 133.37s/it, lr=0.00025, test_MAE=0.7, time=133, train_MAE=0.579, train_loss=0.619, val_MAE=0.649, val_loss=0.689]  Epoch    32: reducing learning rate of group 0 to 1.2500e-04.
Epoch 31:   3%|▎         | 32/1000 [1:11:15<35:48:34, 133.18s/it, lr=0.00025, test_MAE=0.7, time=133, train_MAE=0.579, train_loss=0.619, val_MAE=0.649, val_loss=0.689]Epoch 32:   3%|▎         | 32/1000 [1:11:15<35:48:34, 133.18s/it, lr=0.00025, test_MAE=0.7, time=133, train_MAE=0.579, train_loss=0.619, val_MAE=0.649, val_loss=0.689]Epoch 32:   3%|▎         | 32/1000 [1:13:29<35:48:34, 133.18s/it, lr=0.000125, test_MAE=0.707, time=134, train_MAE=0.579, train_loss=0.619, val_MAE=0.651, val_loss=0.691]Epoch 32:   3%|▎         | 33/1000 [1:13:29<35:48:09, 133.29s/it, lr=0.000125, test_MAE=0.707, time=134, train_MAE=0.579, train_loss=0.619, val_MAE=0.651, val_loss=0.691]Epoch 33:   3%|▎         | 33/1000 [1:13:29<35:48:09, 133.29s/it, lr=0.000125, test_MAE=0.707, time=134, train_MAE=0.579, train_loss=0.619, val_MAE=0.651, val_loss=0.691]Epoch 33:   3%|▎         | 33/1000 [1:15:42<35:48:09, 133.29s/it, lr=0.000125, test_MAE=0.701, time=133, train_MAE=0.572, train_loss=0.612, val_MAE=0.65, val_loss=0.69]  Epoch 33:   3%|▎         | 34/1000 [1:15:42<35:45:27, 133.26s/it, lr=0.000125, test_MAE=0.701, time=133, train_MAE=0.572, train_loss=0.612, val_MAE=0.65, val_loss=0.69]Epoch 34:   3%|▎         | 34/1000 [1:15:42<35:45:27, 133.26s/it, lr=0.000125, test_MAE=0.701, time=133, train_MAE=0.572, train_loss=0.612, val_MAE=0.65, val_loss=0.69]Epoch 34:   3%|▎         | 34/1000 [1:17:55<35:45:27, 133.26s/it, lr=0.000125, test_MAE=0.704, time=133, train_MAE=0.573, train_loss=0.613, val_MAE=0.652, val_loss=0.692]Epoch 34:   4%|▎         | 35/1000 [1:17:55<35:41:56, 133.18s/it, lr=0.000125, test_MAE=0.704, time=133, train_MAE=0.573, train_loss=0.613, val_MAE=0.652, val_loss=0.692]Epoch 35:   4%|▎         | 35/1000 [1:17:55<35:41:56, 133.18s/it, lr=0.000125, test_MAE=0.704, time=133, train_MAE=0.573, train_loss=0.613, val_MAE=0.652, val_loss=0.692]Epoch 35:   4%|▎         | 35/1000 [1:20:09<35:41:56, 133.18s/it, lr=0.000125, test_MAE=0.703, time=134, train_MAE=0.567, train_loss=0.607, val_MAE=0.644, val_loss=0.684]Epoch 35:   4%|▎         | 36/1000 [1:20:09<35:41:21, 133.28s/it, lr=0.000125, test_MAE=0.703, time=134, train_MAE=0.567, train_loss=0.607, val_MAE=0.644, val_loss=0.684]Epoch 36:   4%|▎         | 36/1000 [1:20:09<35:41:21, 133.28s/it, lr=0.000125, test_MAE=0.703, time=134, train_MAE=0.567, train_loss=0.607, val_MAE=0.644, val_loss=0.684]Epoch 36:   4%|▎         | 36/1000 [1:22:22<35:41:21, 133.28s/it, lr=0.000125, test_MAE=0.699, time=133, train_MAE=0.571, train_loss=0.611, val_MAE=0.643, val_loss=0.683]Epoch 36:   4%|▎         | 37/1000 [1:22:22<35:38:49, 133.26s/it, lr=0.000125, test_MAE=0.699, time=133, train_MAE=0.571, train_loss=0.611, val_MAE=0.643, val_loss=0.683]Epoch 37:   4%|▎         | 37/1000 [1:22:22<35:38:49, 133.26s/it, lr=0.000125, test_MAE=0.699, time=133, train_MAE=0.571, train_loss=0.611, val_MAE=0.643, val_loss=0.683]Epoch 37:   4%|▎         | 37/1000 [1:24:34<35:38:49, 133.26s/it, lr=0.000125, test_MAE=0.704, time=132, train_MAE=0.57, train_loss=0.61, val_MAE=0.653, val_loss=0.692]  Epoch    38: reducing learning rate of group 0 to 6.2500e-05.
Epoch 37:   4%|▍         | 38/1000 [1:24:34<35:32:28, 133.00s/it, lr=0.000125, test_MAE=0.704, time=132, train_MAE=0.57, train_loss=0.61, val_MAE=0.653, val_loss=0.692]Epoch 38:   4%|▍         | 38/1000 [1:24:34<35:32:28, 133.00s/it, lr=0.000125, test_MAE=0.704, time=132, train_MAE=0.57, train_loss=0.61, val_MAE=0.653, val_loss=0.692]Epoch 38:   4%|▍         | 38/1000 [1:26:47<35:32:28, 133.00s/it, lr=6.25e-5, test_MAE=0.705, time=133, train_MAE=0.566, train_loss=0.606, val_MAE=0.65, val_loss=0.69] Epoch 38:   4%|▍         | 39/1000 [1:26:47<35:30:30, 133.02s/it, lr=6.25e-5, test_MAE=0.705, time=133, train_MAE=0.566, train_loss=0.606, val_MAE=0.65, val_loss=0.69]Epoch 39:   4%|▍         | 39/1000 [1:26:47<35:30:30, 133.02s/it, lr=6.25e-5, test_MAE=0.705, time=133, train_MAE=0.566, train_loss=0.606, val_MAE=0.65, val_loss=0.69]Epoch 39:   4%|▍         | 39/1000 [1:29:00<35:30:30, 133.02s/it, lr=6.25e-5, test_MAE=0.7, time=133, train_MAE=0.561, train_loss=0.601, val_MAE=0.647, val_loss=0.686]Epoch 39:   4%|▍         | 40/1000 [1:29:00<35:29:11, 133.07s/it, lr=6.25e-5, test_MAE=0.7, time=133, train_MAE=0.561, train_loss=0.601, val_MAE=0.647, val_loss=0.686]Epoch 40:   4%|▍         | 40/1000 [1:29:00<35:29:11, 133.07s/it, lr=6.25e-5, test_MAE=0.7, time=133, train_MAE=0.561, train_loss=0.601, val_MAE=0.647, val_loss=0.686]Epoch 40:   4%|▍         | 40/1000 [1:31:14<35:29:11, 133.07s/it, lr=6.25e-5, test_MAE=0.702, time=133, train_MAE=0.561, train_loss=0.6, val_MAE=0.644, val_loss=0.684]Epoch 40:   4%|▍         | 41/1000 [1:31:14<35:27:13, 133.09s/it, lr=6.25e-5, test_MAE=0.702, time=133, train_MAE=0.561, train_loss=0.6, val_MAE=0.644, val_loss=0.684]Epoch 41:   4%|▍         | 41/1000 [1:31:14<35:27:13, 133.09s/it, lr=6.25e-5, test_MAE=0.702, time=133, train_MAE=0.561, train_loss=0.6, val_MAE=0.644, val_loss=0.684]Epoch 41:   4%|▍         | 41/1000 [1:33:27<35:27:13, 133.09s/it, lr=6.25e-5, test_MAE=0.702, time=134, train_MAE=0.565, train_loss=0.604, val_MAE=0.644, val_loss=0.683]Epoch 41:   4%|▍         | 42/1000 [1:33:27<35:28:30, 133.31s/it, lr=6.25e-5, test_MAE=0.702, time=134, train_MAE=0.565, train_loss=0.604, val_MAE=0.644, val_loss=0.683]Epoch 42:   4%|▍         | 42/1000 [1:33:27<35:28:30, 133.31s/it, lr=6.25e-5, test_MAE=0.702, time=134, train_MAE=0.565, train_loss=0.604, val_MAE=0.644, val_loss=0.683]Epoch 42:   4%|▍         | 42/1000 [1:35:40<35:28:30, 133.31s/it, lr=6.25e-5, test_MAE=0.704, time=133, train_MAE=0.561, train_loss=0.601, val_MAE=0.648, val_loss=0.687]Epoch 42:   4%|▍         | 43/1000 [1:35:41<35:25:25, 133.26s/it, lr=6.25e-5, test_MAE=0.704, time=133, train_MAE=0.561, train_loss=0.601, val_MAE=0.648, val_loss=0.687]Epoch 43:   4%|▍         | 43/1000 [1:35:41<35:25:25, 133.26s/it, lr=6.25e-5, test_MAE=0.704, time=133, train_MAE=0.561, train_loss=0.601, val_MAE=0.648, val_loss=0.687]Epoch 43:   4%|▍         | 43/1000 [1:37:54<35:25:25, 133.26s/it, lr=6.25e-5, test_MAE=0.701, time=134, train_MAE=0.564, train_loss=0.604, val_MAE=0.647, val_loss=0.687]Epoch    44: reducing learning rate of group 0 to 3.1250e-05.
Epoch 43:   4%|▍         | 44/1000 [1:37:54<35:25:10, 133.38s/it, lr=6.25e-5, test_MAE=0.701, time=134, train_MAE=0.564, train_loss=0.604, val_MAE=0.647, val_loss=0.687]Epoch 44:   4%|▍         | 44/1000 [1:37:54<35:25:10, 133.38s/it, lr=6.25e-5, test_MAE=0.701, time=134, train_MAE=0.564, train_loss=0.604, val_MAE=0.647, val_loss=0.687]Epoch 44:   4%|▍         | 44/1000 [1:40:08<35:25:10, 133.38s/it, lr=3.13e-5, test_MAE=0.702, time=134, train_MAE=0.557, train_loss=0.597, val_MAE=0.647, val_loss=0.686]Epoch 44:   4%|▍         | 45/1000 [1:40:08<35:24:47, 133.50s/it, lr=3.13e-5, test_MAE=0.702, time=134, train_MAE=0.557, train_loss=0.597, val_MAE=0.647, val_loss=0.686]Epoch 45:   4%|▍         | 45/1000 [1:40:08<35:24:47, 133.50s/it, lr=3.13e-5, test_MAE=0.702, time=134, train_MAE=0.557, train_loss=0.597, val_MAE=0.647, val_loss=0.686]Epoch 45:   4%|▍         | 45/1000 [1:42:23<35:24:47, 133.50s/it, lr=3.13e-5, test_MAE=0.708, time=135, train_MAE=0.555, train_loss=0.595, val_MAE=0.652, val_loss=0.691]Epoch 45:   5%|▍         | 46/1000 [1:42:23<35:30:22, 133.99s/it, lr=3.13e-5, test_MAE=0.708, time=135, train_MAE=0.555, train_loss=0.595, val_MAE=0.652, val_loss=0.691]Epoch 46:   5%|▍         | 46/1000 [1:42:23<35:30:22, 133.99s/it, lr=3.13e-5, test_MAE=0.708, time=135, train_MAE=0.555, train_loss=0.595, val_MAE=0.652, val_loss=0.691]Epoch 46:   5%|▍         | 46/1000 [1:44:38<35:30:22, 133.99s/it, lr=3.13e-5, test_MAE=0.702, time=135, train_MAE=0.559, train_loss=0.599, val_MAE=0.647, val_loss=0.687]Epoch 46:   5%|▍         | 47/1000 [1:44:38<35:34:06, 134.36s/it, lr=3.13e-5, test_MAE=0.702, time=135, train_MAE=0.559, train_loss=0.599, val_MAE=0.647, val_loss=0.687]Epoch 47:   5%|▍         | 47/1000 [1:44:38<35:34:06, 134.36s/it, lr=3.13e-5, test_MAE=0.702, time=135, train_MAE=0.559, train_loss=0.599, val_MAE=0.647, val_loss=0.687]Epoch 47:   5%|▍         | 47/1000 [1:46:54<35:34:06, 134.36s/it, lr=3.13e-5, test_MAE=0.703, time=135, train_MAE=0.558, train_loss=0.598, val_MAE=0.649, val_loss=0.689]Epoch 47:   5%|▍         | 48/1000 [1:46:54<35:37:06, 134.69s/it, lr=3.13e-5, test_MAE=0.703, time=135, train_MAE=0.558, train_loss=0.598, val_MAE=0.649, val_loss=0.689]Epoch 48:   5%|▍         | 48/1000 [1:46:54<35:37:06, 134.69s/it, lr=3.13e-5, test_MAE=0.703, time=135, train_MAE=0.558, train_loss=0.598, val_MAE=0.649, val_loss=0.689]Epoch 48:   5%|▍         | 48/1000 [1:49:09<35:37:06, 134.69s/it, lr=3.13e-5, test_MAE=0.702, time=135, train_MAE=0.559, train_loss=0.599, val_MAE=0.644, val_loss=0.684]Epoch 48:   5%|▍         | 49/1000 [1:49:09<35:38:32, 134.92s/it, lr=3.13e-5, test_MAE=0.702, time=135, train_MAE=0.559, train_loss=0.599, val_MAE=0.644, val_loss=0.684]Epoch 49:   5%|▍         | 49/1000 [1:49:09<35:38:32, 134.92s/it, lr=3.13e-5, test_MAE=0.702, time=135, train_MAE=0.559, train_loss=0.599, val_MAE=0.644, val_loss=0.684]Epoch 49:   5%|▍         | 49/1000 [1:51:26<35:38:32, 134.92s/it, lr=3.13e-5, test_MAE=0.703, time=137, train_MAE=0.559, train_loss=0.599, val_MAE=0.647, val_loss=0.687]Epoch    50: reducing learning rate of group 0 to 1.5625e-05.
Epoch 49:   5%|▌         | 50/1000 [1:51:26<35:45:53, 135.53s/it, lr=3.13e-5, test_MAE=0.703, time=137, train_MAE=0.559, train_loss=0.599, val_MAE=0.647, val_loss=0.687]Epoch 50:   5%|▌         | 50/1000 [1:51:26<35:45:53, 135.53s/it, lr=3.13e-5, test_MAE=0.703, time=137, train_MAE=0.559, train_loss=0.599, val_MAE=0.647, val_loss=0.687]Epoch 50:   5%|▌         | 50/1000 [1:53:41<35:45:53, 135.53s/it, lr=1.56e-5, test_MAE=0.701, time=134, train_MAE=0.56, train_loss=0.6, val_MAE=0.645, val_loss=0.685]   Epoch 50:   5%|▌         | 51/1000 [1:53:41<35:37:58, 135.17s/it, lr=1.56e-5, test_MAE=0.701, time=134, train_MAE=0.56, train_loss=0.6, val_MAE=0.645, val_loss=0.685]Epoch 51:   5%|▌         | 51/1000 [1:53:41<35:37:58, 135.17s/it, lr=1.56e-5, test_MAE=0.701, time=134, train_MAE=0.56, train_loss=0.6, val_MAE=0.645, val_loss=0.685]Epoch 51:   5%|▌         | 51/1000 [1:55:54<35:37:58, 135.17s/it, lr=1.56e-5, test_MAE=0.702, time=134, train_MAE=0.555, train_loss=0.595, val_MAE=0.646, val_loss=0.686]Epoch 51:   5%|▌         | 52/1000 [1:55:54<35:29:19, 134.77s/it, lr=1.56e-5, test_MAE=0.702, time=134, train_MAE=0.555, train_loss=0.595, val_MAE=0.646, val_loss=0.686]Epoch 52:   5%|▌         | 52/1000 [1:55:54<35:29:19, 134.77s/it, lr=1.56e-5, test_MAE=0.702, time=134, train_MAE=0.555, train_loss=0.595, val_MAE=0.646, val_loss=0.686]Epoch 52:   5%|▌         | 52/1000 [1:58:09<35:29:19, 134.77s/it, lr=1.56e-5, test_MAE=0.7, time=135, train_MAE=0.558, train_loss=0.598, val_MAE=0.647, val_loss=0.687]  Epoch 52:   5%|▌         | 53/1000 [1:58:09<35:27:38, 134.80s/it, lr=1.56e-5, test_MAE=0.7, time=135, train_MAE=0.558, train_loss=0.598, val_MAE=0.647, val_loss=0.687]Epoch 53:   5%|▌         | 53/1000 [1:58:09<35:27:38, 134.80s/it, lr=1.56e-5, test_MAE=0.7, time=135, train_MAE=0.558, train_loss=0.598, val_MAE=0.647, val_loss=0.687]Epoch 53:   5%|▌         | 53/1000 [2:00:23<35:27:38, 134.80s/it, lr=1.56e-5, test_MAE=0.702, time=134, train_MAE=0.554, train_loss=0.594, val_MAE=0.645, val_loss=0.685]Epoch 53:   5%|▌         | 54/1000 [2:00:24<35:22:48, 134.64s/it, lr=1.56e-5, test_MAE=0.702, time=134, train_MAE=0.554, train_loss=0.594, val_MAE=0.645, val_loss=0.685]Epoch 54:   5%|▌         | 54/1000 [2:00:24<35:22:48, 134.64s/it, lr=1.56e-5, test_MAE=0.702, time=134, train_MAE=0.554, train_loss=0.594, val_MAE=0.645, val_loss=0.685]Epoch 54:   5%|▌         | 54/1000 [2:02:37<35:22:48, 134.64s/it, lr=1.56e-5, test_MAE=0.703, time=134, train_MAE=0.553, train_loss=0.593, val_MAE=0.649, val_loss=0.688]Epoch 54:   6%|▌         | 55/1000 [2:02:37<35:17:04, 134.42s/it, lr=1.56e-5, test_MAE=0.703, time=134, train_MAE=0.553, train_loss=0.593, val_MAE=0.649, val_loss=0.688]Epoch 55:   6%|▌         | 55/1000 [2:02:37<35:17:04, 134.42s/it, lr=1.56e-5, test_MAE=0.703, time=134, train_MAE=0.553, train_loss=0.593, val_MAE=0.649, val_loss=0.688]Epoch 55:   6%|▌         | 55/1000 [2:04:52<35:17:04, 134.42s/it, lr=1.56e-5, test_MAE=0.702, time=135, train_MAE=0.552, train_loss=0.591, val_MAE=0.645, val_loss=0.685]Epoch    56: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 55:   6%|▌         | 55/1000 [2:04:52<35:45:35, 136.23s/it, lr=1.56e-5, test_MAE=0.702, time=135, train_MAE=0.552, train_loss=0.591, val_MAE=0.645, val_loss=0.685]
Test MAE: 0.7016
Train MAE: 0.5422
Convergence Time (Epochs): 55.0000
TOTAL TIME TAKEN: 7555.2915s
AVG TIME PER EPOCH: 133.7740s
