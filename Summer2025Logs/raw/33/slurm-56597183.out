I'm echoing to stdout
I'm echoing to stderr
My JobID is 56597183
I have 8 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.0325s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 4, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'rational_vec', 'normalized_laplacian': True, 'post_normalized': False, 'eigval_norm': '', 'num_eigs': 15, 'bias_mode': 'spatial', 'eigval_hidden_dim': 5, 'eigval_num_hidden_layer': 3, 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 1, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/zinc_train_rec_full.csv', 'test': 'supp_data/molecules/zinc_test_rec_full.csv', 'val': 'supp_data/molecules/zinc_val_rec_full.csv'}, 'fixMissingPhi1': False, 'extraOrtho': True, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [04:19<?, ?it/s, lr=0.001, test_MAE=1.53, time=260, train_MAE=1.33, train_loss=1.36, val_MAE=1.45, val_loss=1.48]Epoch 0:   0%|          | 1/1000 [04:19<72:03:48, 259.69s/it, lr=0.001, test_MAE=1.53, time=260, train_MAE=1.33, train_loss=1.36, val_MAE=1.45, val_loss=1.48]Epoch 1:   0%|          | 1/1000 [04:19<72:03:48, 259.69s/it, lr=0.001, test_MAE=1.53, time=260, train_MAE=1.33, train_loss=1.36, val_MAE=1.45, val_loss=1.48]Epoch 1:   0%|          | 1/1000 [06:12<72:03:48, 259.69s/it, lr=0.001, test_MAE=1.48, time=113, train_MAE=1.16, train_loss=1.19, val_MAE=1.4, val_loss=1.44] Epoch 1:   0%|          | 2/1000 [06:12<59:47:44, 215.70s/it, lr=0.001, test_MAE=1.48, time=113, train_MAE=1.16, train_loss=1.19, val_MAE=1.4, val_loss=1.44]Epoch 2:   0%|          | 2/1000 [06:12<59:47:44, 215.70s/it, lr=0.001, test_MAE=1.48, time=113, train_MAE=1.16, train_loss=1.19, val_MAE=1.4, val_loss=1.44]Epoch 2:   0%|          | 2/1000 [08:06<59:47:44, 215.70s/it, lr=0.001, test_MAE=1.47, time=114, train_MAE=0.997, train_loss=1.03, val_MAE=1.46, val_loss=1.5]Epoch 2:   0%|          | 3/1000 [08:06<51:17:01, 185.18s/it, lr=0.001, test_MAE=1.47, time=114, train_MAE=0.997, train_loss=1.03, val_MAE=1.46, val_loss=1.5]Epoch 3:   0%|          | 3/1000 [08:06<51:17:01, 185.18s/it, lr=0.001, test_MAE=1.47, time=114, train_MAE=0.997, train_loss=1.03, val_MAE=1.46, val_loss=1.5]Epoch 3:   0%|          | 3/1000 [10:00<51:17:01, 185.18s/it, lr=0.001, test_MAE=1.35, time=114, train_MAE=0.881, train_loss=0.918, val_MAE=1.35, val_loss=1.39]Epoch 3:   0%|          | 4/1000 [10:00<45:19:02, 163.80s/it, lr=0.001, test_MAE=1.35, time=114, train_MAE=0.881, train_loss=0.918, val_MAE=1.35, val_loss=1.39]Epoch 4:   0%|          | 4/1000 [10:00<45:19:02, 163.80s/it, lr=0.001, test_MAE=1.35, time=114, train_MAE=0.881, train_loss=0.918, val_MAE=1.35, val_loss=1.39]Epoch 4:   0%|          | 4/1000 [11:54<45:19:02, 163.80s/it, lr=0.001, test_MAE=1.24, time=114, train_MAE=0.818, train_loss=0.857, val_MAE=1.17, val_loss=1.21]Epoch 4:   0%|          | 5/1000 [11:54<41:06:58, 148.76s/it, lr=0.001, test_MAE=1.24, time=114, train_MAE=0.818, train_loss=0.857, val_MAE=1.17, val_loss=1.21]Epoch 5:   0%|          | 5/1000 [11:54<41:06:58, 148.76s/it, lr=0.001, test_MAE=1.24, time=114, train_MAE=0.818, train_loss=0.857, val_MAE=1.17, val_loss=1.21]Epoch 5:   0%|          | 5/1000 [13:47<41:06:58, 148.76s/it, lr=0.001, test_MAE=1.15, time=113, train_MAE=0.778, train_loss=0.818, val_MAE=1.08, val_loss=1.12]Epoch 5:   1%|          | 6/1000 [13:47<38:07:27, 138.08s/it, lr=0.001, test_MAE=1.15, time=113, train_MAE=0.778, train_loss=0.818, val_MAE=1.08, val_loss=1.12]Epoch 6:   1%|          | 6/1000 [13:47<38:07:27, 138.08s/it, lr=0.001, test_MAE=1.15, time=113, train_MAE=0.778, train_loss=0.818, val_MAE=1.08, val_loss=1.12]Epoch 6:   1%|          | 6/1000 [15:41<38:07:27, 138.08s/it, lr=0.001, test_MAE=1.11, time=114, train_MAE=0.743, train_loss=0.784, val_MAE=1.07, val_loss=1.11]Epoch 6:   1%|          | 7/1000 [15:41<36:05:36, 130.85s/it, lr=0.001, test_MAE=1.11, time=114, train_MAE=0.743, train_loss=0.784, val_MAE=1.07, val_loss=1.11]Epoch 7:   1%|          | 7/1000 [15:41<36:05:36, 130.85s/it, lr=0.001, test_MAE=1.11, time=114, train_MAE=0.743, train_loss=0.784, val_MAE=1.07, val_loss=1.11]Epoch 7:   1%|          | 7/1000 [17:34<36:05:36, 130.85s/it, lr=0.001, test_MAE=1.03, time=113, train_MAE=0.729, train_loss=0.771, val_MAE=0.997, val_loss=1.04]Epoch 7:   1%|          | 8/1000 [17:34<34:37:07, 125.63s/it, lr=0.001, test_MAE=1.03, time=113, train_MAE=0.729, train_loss=0.771, val_MAE=0.997, val_loss=1.04]Epoch 8:   1%|          | 8/1000 [17:34<34:37:07, 125.63s/it, lr=0.001, test_MAE=1.03, time=113, train_MAE=0.729, train_loss=0.771, val_MAE=0.997, val_loss=1.04]Epoch 8:   1%|          | 8/1000 [19:28<34:37:07, 125.63s/it, lr=0.001, test_MAE=1.02, time=113, train_MAE=0.721, train_loss=0.763, val_MAE=1.01, val_loss=1.05] Epoch 8:   1%|          | 9/1000 [19:28<33:34:07, 121.94s/it, lr=0.001, test_MAE=1.02, time=113, train_MAE=0.721, train_loss=0.763, val_MAE=1.01, val_loss=1.05]Epoch 9:   1%|          | 9/1000 [19:28<33:34:07, 121.94s/it, lr=0.001, test_MAE=1.02, time=113, train_MAE=0.721, train_loss=0.763, val_MAE=1.01, val_loss=1.05]Epoch 9:   1%|          | 9/1000 [21:21<33:34:07, 121.94s/it, lr=0.001, test_MAE=0.882, time=113, train_MAE=0.705, train_loss=0.749, val_MAE=0.836, val_loss=0.88]Epoch 9:   1%|          | 10/1000 [21:21<32:49:38, 119.37s/it, lr=0.001, test_MAE=0.882, time=113, train_MAE=0.705, train_loss=0.749, val_MAE=0.836, val_loss=0.88]Epoch 10:   1%|          | 10/1000 [21:21<32:49:38, 119.37s/it, lr=0.001, test_MAE=0.882, time=113, train_MAE=0.705, train_loss=0.749, val_MAE=0.836, val_loss=0.88]Epoch 10:   1%|          | 10/1000 [23:14<32:49:38, 119.37s/it, lr=0.001, test_MAE=0.951, time=113, train_MAE=0.699, train_loss=0.743, val_MAE=0.923, val_loss=0.968]Epoch 10:   1%|          | 11/1000 [23:14<32:17:15, 117.53s/it, lr=0.001, test_MAE=0.951, time=113, train_MAE=0.699, train_loss=0.743, val_MAE=0.923, val_loss=0.968]Epoch 11:   1%|          | 11/1000 [23:14<32:17:15, 117.53s/it, lr=0.001, test_MAE=0.951, time=113, train_MAE=0.699, train_loss=0.743, val_MAE=0.923, val_loss=0.968]Epoch 11:   1%|          | 11/1000 [25:05<32:17:15, 117.53s/it, lr=0.001, test_MAE=0.859, time=110, train_MAE=0.699, train_loss=0.743, val_MAE=0.812, val_loss=0.857]Epoch 11:   1%|          | 12/1000 [25:05<31:39:25, 115.35s/it, lr=0.001, test_MAE=0.859, time=110, train_MAE=0.699, train_loss=0.743, val_MAE=0.812, val_loss=0.857]Epoch 12:   1%|          | 12/1000 [25:05<31:39:25, 115.35s/it, lr=0.001, test_MAE=0.859, time=110, train_MAE=0.699, train_loss=0.743, val_MAE=0.812, val_loss=0.857]Epoch 12:   1%|          | 12/1000 [26:53<31:39:25, 115.35s/it, lr=0.001, test_MAE=0.804, time=109, train_MAE=0.684, train_loss=0.729, val_MAE=0.768, val_loss=0.813]Epoch 12:   1%|▏         | 13/1000 [26:53<31:04:49, 113.36s/it, lr=0.001, test_MAE=0.804, time=109, train_MAE=0.684, train_loss=0.729, val_MAE=0.768, val_loss=0.813]Epoch 13:   1%|▏         | 13/1000 [26:53<31:04:49, 113.36s/it, lr=0.001, test_MAE=0.804, time=109, train_MAE=0.684, train_loss=0.729, val_MAE=0.768, val_loss=0.813]Epoch 13:   1%|▏         | 13/1000 [28:42<31:04:49, 113.36s/it, lr=0.001, test_MAE=0.845, time=109, train_MAE=0.686, train_loss=0.731, val_MAE=0.794, val_loss=0.84] Epoch 13:   1%|▏         | 14/1000 [28:42<30:40:21, 111.99s/it, lr=0.001, test_MAE=0.845, time=109, train_MAE=0.686, train_loss=0.731, val_MAE=0.794, val_loss=0.84]Epoch 14:   1%|▏         | 14/1000 [28:42<30:40:21, 111.99s/it, lr=0.001, test_MAE=0.845, time=109, train_MAE=0.686, train_loss=0.731, val_MAE=0.794, val_loss=0.84]Epoch 14:   1%|▏         | 14/1000 [30:30<30:40:21, 111.99s/it, lr=0.001, test_MAE=0.771, time=108, train_MAE=0.69, train_loss=0.736, val_MAE=0.729, val_loss=0.775]Epoch 14:   2%|▏         | 15/1000 [30:30<30:20:15, 110.88s/it, lr=0.001, test_MAE=0.771, time=108, train_MAE=0.69, train_loss=0.736, val_MAE=0.729, val_loss=0.775]Epoch 15:   2%|▏         | 15/1000 [30:30<30:20:15, 110.88s/it, lr=0.001, test_MAE=0.771, time=108, train_MAE=0.69, train_loss=0.736, val_MAE=0.729, val_loss=0.775]Epoch 15:   2%|▏         | 15/1000 [32:19<30:20:15, 110.88s/it, lr=0.001, test_MAE=0.799, time=109, train_MAE=0.672, train_loss=0.719, val_MAE=0.753, val_loss=0.8] Epoch 15:   2%|▏         | 16/1000 [32:19<30:07:06, 110.19s/it, lr=0.001, test_MAE=0.799, time=109, train_MAE=0.672, train_loss=0.719, val_MAE=0.753, val_loss=0.8]Epoch 16:   2%|▏         | 16/1000 [32:19<30:07:06, 110.19s/it, lr=0.001, test_MAE=0.799, time=109, train_MAE=0.672, train_loss=0.719, val_MAE=0.753, val_loss=0.8]Epoch 16:   2%|▏         | 16/1000 [34:07<30:07:06, 110.19s/it, lr=0.001, test_MAE=0.891, time=108, train_MAE=0.679, train_loss=0.726, val_MAE=0.857, val_loss=0.904]Epoch 16:   2%|▏         | 17/1000 [34:07<29:56:07, 109.63s/it, lr=0.001, test_MAE=0.891, time=108, train_MAE=0.679, train_loss=0.726, val_MAE=0.857, val_loss=0.904]Epoch 17:   2%|▏         | 17/1000 [34:07<29:56:07, 109.63s/it, lr=0.001, test_MAE=0.891, time=108, train_MAE=0.679, train_loss=0.726, val_MAE=0.857, val_loss=0.904]Epoch 17:   2%|▏         | 17/1000 [35:54<29:56:07, 109.63s/it, lr=0.001, test_MAE=0.802, time=107, train_MAE=0.669, train_loss=0.716, val_MAE=0.759, val_loss=0.807]Epoch 17:   2%|▏         | 18/1000 [35:54<29:40:50, 108.81s/it, lr=0.001, test_MAE=0.802, time=107, train_MAE=0.669, train_loss=0.716, val_MAE=0.759, val_loss=0.807]Epoch 18:   2%|▏         | 18/1000 [35:54<29:40:50, 108.81s/it, lr=0.001, test_MAE=0.802, time=107, train_MAE=0.669, train_loss=0.716, val_MAE=0.759, val_loss=0.807]Epoch 18:   2%|▏         | 18/1000 [37:40<29:40:50, 108.81s/it, lr=0.001, test_MAE=0.804, time=106, train_MAE=0.668, train_loss=0.716, val_MAE=0.764, val_loss=0.812]Epoch 18:   2%|▏         | 19/1000 [37:40<29:24:27, 107.92s/it, lr=0.001, test_MAE=0.804, time=106, train_MAE=0.668, train_loss=0.716, val_MAE=0.764, val_loss=0.812]Epoch 19:   2%|▏         | 19/1000 [37:40<29:24:27, 107.92s/it, lr=0.001, test_MAE=0.804, time=106, train_MAE=0.668, train_loss=0.716, val_MAE=0.764, val_loss=0.812]Epoch 19:   2%|▏         | 19/1000 [39:26<29:24:27, 107.92s/it, lr=0.001, test_MAE=0.73, time=106, train_MAE=0.668, train_loss=0.716, val_MAE=0.674, val_loss=0.723] Epoch 19:   2%|▏         | 20/1000 [39:26<29:12:55, 107.32s/it, lr=0.001, test_MAE=0.73, time=106, train_MAE=0.668, train_loss=0.716, val_MAE=0.674, val_loss=0.723]Epoch 20:   2%|▏         | 20/1000 [39:26<29:12:55, 107.32s/it, lr=0.001, test_MAE=0.73, time=106, train_MAE=0.668, train_loss=0.716, val_MAE=0.674, val_loss=0.723]Epoch 20:   2%|▏         | 20/1000 [41:12<29:12:55, 107.32s/it, lr=0.001, test_MAE=0.732, time=106, train_MAE=0.683, train_loss=0.732, val_MAE=0.682, val_loss=0.731]Epoch 20:   2%|▏         | 21/1000 [41:12<29:02:39, 106.80s/it, lr=0.001, test_MAE=0.732, time=106, train_MAE=0.683, train_loss=0.732, val_MAE=0.682, val_loss=0.731]Epoch 21:   2%|▏         | 21/1000 [41:12<29:02:39, 106.80s/it, lr=0.001, test_MAE=0.732, time=106, train_MAE=0.683, train_loss=0.732, val_MAE=0.682, val_loss=0.731]Epoch 21:   2%|▏         | 21/1000 [42:57<29:02:39, 106.80s/it, lr=0.001, test_MAE=0.8, time=106, train_MAE=0.661, train_loss=0.71, val_MAE=0.757, val_loss=0.806]   Epoch 21:   2%|▏         | 22/1000 [42:58<28:56:45, 106.55s/it, lr=0.001, test_MAE=0.8, time=106, train_MAE=0.661, train_loss=0.71, val_MAE=0.757, val_loss=0.806]Epoch 22:   2%|▏         | 22/1000 [42:58<28:56:45, 106.55s/it, lr=0.001, test_MAE=0.8, time=106, train_MAE=0.661, train_loss=0.71, val_MAE=0.757, val_loss=0.806]Epoch 22:   2%|▏         | 22/1000 [44:42<28:56:45, 106.55s/it, lr=0.001, test_MAE=0.748, time=105, train_MAE=0.656, train_loss=0.706, val_MAE=0.698, val_loss=0.748]Epoch 22:   2%|▏         | 23/1000 [44:42<28:45:36, 105.97s/it, lr=0.001, test_MAE=0.748, time=105, train_MAE=0.656, train_loss=0.706, val_MAE=0.698, val_loss=0.748]Epoch 23:   2%|▏         | 23/1000 [44:42<28:45:36, 105.97s/it, lr=0.001, test_MAE=0.748, time=105, train_MAE=0.656, train_loss=0.706, val_MAE=0.698, val_loss=0.748]Epoch 23:   2%|▏         | 23/1000 [46:28<28:45:36, 105.97s/it, lr=0.001, test_MAE=0.924, time=105, train_MAE=0.657, train_loss=0.707, val_MAE=0.892, val_loss=0.942]Epoch 23:   2%|▏         | 24/1000 [46:28<28:41:36, 105.84s/it, lr=0.001, test_MAE=0.924, time=105, train_MAE=0.657, train_loss=0.707, val_MAE=0.892, val_loss=0.942]Epoch 24:   2%|▏         | 24/1000 [46:28<28:41:36, 105.84s/it, lr=0.001, test_MAE=0.924, time=105, train_MAE=0.657, train_loss=0.707, val_MAE=0.892, val_loss=0.942]Epoch 24:   2%|▏         | 24/1000 [48:13<28:41:36, 105.84s/it, lr=0.001, test_MAE=0.823, time=105, train_MAE=0.659, train_loss=0.71, val_MAE=0.791, val_loss=0.842] Epoch 24:   2%|▎         | 25/1000 [48:13<28:35:17, 105.56s/it, lr=0.001, test_MAE=0.823, time=105, train_MAE=0.659, train_loss=0.71, val_MAE=0.791, val_loss=0.842]Epoch 25:   2%|▎         | 25/1000 [48:13<28:35:17, 105.56s/it, lr=0.001, test_MAE=0.823, time=105, train_MAE=0.659, train_loss=0.71, val_MAE=0.791, val_loss=0.842]Epoch 25:   2%|▎         | 25/1000 [49:57<28:35:17, 105.56s/it, lr=0.001, test_MAE=0.768, time=105, train_MAE=0.654, train_loss=0.705, val_MAE=0.713, val_loss=0.763]Epoch    26: reducing learning rate of group 0 to 5.0000e-04.
Epoch 25:   3%|▎         | 26/1000 [49:58<28:30:32, 105.37s/it, lr=0.001, test_MAE=0.768, time=105, train_MAE=0.654, train_loss=0.705, val_MAE=0.713, val_loss=0.763]Epoch 26:   3%|▎         | 26/1000 [49:58<28:30:32, 105.37s/it, lr=0.001, test_MAE=0.768, time=105, train_MAE=0.654, train_loss=0.705, val_MAE=0.713, val_loss=0.763]Epoch 26:   3%|▎         | 26/1000 [51:43<28:30:32, 105.37s/it, lr=0.0005, test_MAE=0.728, time=105, train_MAE=0.646, train_loss=0.697, val_MAE=0.679, val_loss=0.729]Epoch 26:   3%|▎         | 27/1000 [51:43<28:27:43, 105.31s/it, lr=0.0005, test_MAE=0.728, time=105, train_MAE=0.646, train_loss=0.697, val_MAE=0.679, val_loss=0.729]Epoch 27:   3%|▎         | 27/1000 [51:43<28:27:43, 105.31s/it, lr=0.0005, test_MAE=0.728, time=105, train_MAE=0.646, train_loss=0.697, val_MAE=0.679, val_loss=0.729]Epoch 27:   3%|▎         | 27/1000 [53:28<28:27:43, 105.31s/it, lr=0.0005, test_MAE=0.733, time=106, train_MAE=0.642, train_loss=0.692, val_MAE=0.688, val_loss=0.739]Epoch 27:   3%|▎         | 28/1000 [53:28<28:27:16, 105.39s/it, lr=0.0005, test_MAE=0.733, time=106, train_MAE=0.642, train_loss=0.692, val_MAE=0.688, val_loss=0.739]Epoch 28:   3%|▎         | 28/1000 [53:28<28:27:16, 105.39s/it, lr=0.0005, test_MAE=0.733, time=106, train_MAE=0.642, train_loss=0.692, val_MAE=0.688, val_loss=0.739]Epoch 28:   3%|▎         | 28/1000 [55:14<28:27:16, 105.39s/it, lr=0.0005, test_MAE=0.782, time=105, train_MAE=0.642, train_loss=0.692, val_MAE=0.744, val_loss=0.794]Epoch 28:   3%|▎         | 29/1000 [55:14<28:25:49, 105.41s/it, lr=0.0005, test_MAE=0.782, time=105, train_MAE=0.642, train_loss=0.692, val_MAE=0.744, val_loss=0.794]Epoch 29:   3%|▎         | 29/1000 [55:14<28:25:49, 105.41s/it, lr=0.0005, test_MAE=0.782, time=105, train_MAE=0.642, train_loss=0.692, val_MAE=0.744, val_loss=0.794]Epoch 29:   3%|▎         | 29/1000 [56:59<28:25:49, 105.41s/it, lr=0.0005, test_MAE=0.775, time=105, train_MAE=0.65, train_loss=0.7, val_MAE=0.743, val_loss=0.794]   Epoch 29:   3%|▎         | 30/1000 [56:59<28:23:46, 105.39s/it, lr=0.0005, test_MAE=0.775, time=105, train_MAE=0.65, train_loss=0.7, val_MAE=0.743, val_loss=0.794]Epoch 30:   3%|▎         | 30/1000 [56:59<28:23:46, 105.39s/it, lr=0.0005, test_MAE=0.775, time=105, train_MAE=0.65, train_loss=0.7, val_MAE=0.743, val_loss=0.794]Epoch 30:   3%|▎         | 30/1000 [58:45<28:23:46, 105.39s/it, lr=0.0005, test_MAE=0.736, time=106, train_MAE=0.638, train_loss=0.689, val_MAE=0.695, val_loss=0.746]Epoch 30:   3%|▎         | 31/1000 [58:45<28:23:53, 105.50s/it, lr=0.0005, test_MAE=0.736, time=106, train_MAE=0.638, train_loss=0.689, val_MAE=0.695, val_loss=0.746]Epoch 31:   3%|▎         | 31/1000 [58:45<28:23:53, 105.50s/it, lr=0.0005, test_MAE=0.736, time=106, train_MAE=0.638, train_loss=0.689, val_MAE=0.695, val_loss=0.746]Epoch 31:   3%|▎         | 31/1000 [1:00:30<28:23:53, 105.50s/it, lr=0.0005, test_MAE=0.736, time=106, train_MAE=0.639, train_loss=0.689, val_MAE=0.704, val_loss=0.754]Epoch    32: reducing learning rate of group 0 to 2.5000e-04.
Epoch 31:   3%|▎         | 32/1000 [1:00:30<28:22:29, 105.53s/it, lr=0.0005, test_MAE=0.736, time=106, train_MAE=0.639, train_loss=0.689, val_MAE=0.704, val_loss=0.754]Epoch 32:   3%|▎         | 32/1000 [1:00:30<28:22:29, 105.53s/it, lr=0.0005, test_MAE=0.736, time=106, train_MAE=0.639, train_loss=0.689, val_MAE=0.704, val_loss=0.754]Epoch 32:   3%|▎         | 32/1000 [1:02:16<28:22:29, 105.53s/it, lr=0.00025, test_MAE=0.701, time=106, train_MAE=0.643, train_loss=0.694, val_MAE=0.656, val_loss=0.707]Epoch 32:   3%|▎         | 33/1000 [1:02:16<28:21:15, 105.56s/it, lr=0.00025, test_MAE=0.701, time=106, train_MAE=0.643, train_loss=0.694, val_MAE=0.656, val_loss=0.707]Epoch 33:   3%|▎         | 33/1000 [1:02:16<28:21:15, 105.56s/it, lr=0.00025, test_MAE=0.701, time=106, train_MAE=0.643, train_loss=0.694, val_MAE=0.656, val_loss=0.707]Epoch 33:   3%|▎         | 33/1000 [1:04:03<28:21:15, 105.56s/it, lr=0.00025, test_MAE=0.705, time=107, train_MAE=0.632, train_loss=0.683, val_MAE=0.661, val_loss=0.712]Epoch 33:   3%|▎         | 34/1000 [1:04:03<28:25:38, 105.94s/it, lr=0.00025, test_MAE=0.705, time=107, train_MAE=0.632, train_loss=0.683, val_MAE=0.661, val_loss=0.712]Epoch 34:   3%|▎         | 34/1000 [1:04:03<28:25:38, 105.94s/it, lr=0.00025, test_MAE=0.705, time=107, train_MAE=0.632, train_loss=0.683, val_MAE=0.661, val_loss=0.712]Epoch 34:   3%|▎         | 34/1000 [1:05:50<28:25:38, 105.94s/it, lr=0.00025, test_MAE=0.715, time=107, train_MAE=0.633, train_loss=0.683, val_MAE=0.669, val_loss=0.719]Epoch 34:   4%|▎         | 35/1000 [1:05:50<28:29:24, 106.28s/it, lr=0.00025, test_MAE=0.715, time=107, train_MAE=0.633, train_loss=0.683, val_MAE=0.669, val_loss=0.719]Epoch 35:   4%|▎         | 35/1000 [1:05:50<28:29:24, 106.28s/it, lr=0.00025, test_MAE=0.715, time=107, train_MAE=0.633, train_loss=0.683, val_MAE=0.669, val_loss=0.719]Epoch 35:   4%|▎         | 35/1000 [1:07:35<28:29:24, 106.28s/it, lr=0.00025, test_MAE=0.717, time=105, train_MAE=0.634, train_loss=0.684, val_MAE=0.672, val_loss=0.722]Epoch 35:   4%|▎         | 36/1000 [1:07:35<28:23:37, 106.04s/it, lr=0.00025, test_MAE=0.717, time=105, train_MAE=0.634, train_loss=0.684, val_MAE=0.672, val_loss=0.722]Epoch 36:   4%|▎         | 36/1000 [1:07:35<28:23:37, 106.04s/it, lr=0.00025, test_MAE=0.717, time=105, train_MAE=0.634, train_loss=0.684, val_MAE=0.672, val_loss=0.722]Epoch 36:   4%|▎         | 36/1000 [1:09:21<28:23:37, 106.04s/it, lr=0.00025, test_MAE=0.739, time=106, train_MAE=0.629, train_loss=0.679, val_MAE=0.704, val_loss=0.755]Epoch 36:   4%|▎         | 37/1000 [1:09:21<28:21:11, 105.99s/it, lr=0.00025, test_MAE=0.739, time=106, train_MAE=0.629, train_loss=0.679, val_MAE=0.704, val_loss=0.755]Epoch 37:   4%|▎         | 37/1000 [1:09:21<28:21:11, 105.99s/it, lr=0.00025, test_MAE=0.739, time=106, train_MAE=0.629, train_loss=0.679, val_MAE=0.704, val_loss=0.755]Epoch 37:   4%|▎         | 37/1000 [1:11:07<28:21:11, 105.99s/it, lr=0.00025, test_MAE=0.702, time=106, train_MAE=0.637, train_loss=0.688, val_MAE=0.658, val_loss=0.708]Epoch 37:   4%|▍         | 38/1000 [1:11:07<28:20:13, 106.04s/it, lr=0.00025, test_MAE=0.702, time=106, train_MAE=0.637, train_loss=0.688, val_MAE=0.658, val_loss=0.708]Epoch 38:   4%|▍         | 38/1000 [1:11:07<28:20:13, 106.04s/it, lr=0.00025, test_MAE=0.702, time=106, train_MAE=0.637, train_loss=0.688, val_MAE=0.658, val_loss=0.708]Epoch 38:   4%|▍         | 38/1000 [1:12:53<28:20:13, 106.04s/it, lr=0.00025, test_MAE=0.721, time=106, train_MAE=0.627, train_loss=0.677, val_MAE=0.668, val_loss=0.718]Epoch    39: reducing learning rate of group 0 to 1.2500e-04.
Epoch 38:   4%|▍         | 39/1000 [1:12:53<28:16:11, 105.90s/it, lr=0.00025, test_MAE=0.721, time=106, train_MAE=0.627, train_loss=0.677, val_MAE=0.668, val_loss=0.718]Epoch 39:   4%|▍         | 39/1000 [1:12:53<28:16:11, 105.90s/it, lr=0.00025, test_MAE=0.721, time=106, train_MAE=0.627, train_loss=0.677, val_MAE=0.668, val_loss=0.718]Epoch 39:   4%|▍         | 39/1000 [1:14:39<28:16:11, 105.90s/it, lr=0.000125, test_MAE=0.71, time=106, train_MAE=0.629, train_loss=0.68, val_MAE=0.668, val_loss=0.719] Epoch 39:   4%|▍         | 40/1000 [1:14:39<28:14:17, 105.89s/it, lr=0.000125, test_MAE=0.71, time=106, train_MAE=0.629, train_loss=0.68, val_MAE=0.668, val_loss=0.719]Epoch 40:   4%|▍         | 40/1000 [1:14:39<28:14:17, 105.89s/it, lr=0.000125, test_MAE=0.71, time=106, train_MAE=0.629, train_loss=0.68, val_MAE=0.668, val_loss=0.719]Epoch 40:   4%|▍         | 40/1000 [1:16:25<28:14:17, 105.89s/it, lr=0.000125, test_MAE=0.699, time=106, train_MAE=0.63, train_loss=0.68, val_MAE=0.657, val_loss=0.708]Epoch 40:   4%|▍         | 41/1000 [1:16:25<28:12:35, 105.90s/it, lr=0.000125, test_MAE=0.699, time=106, train_MAE=0.63, train_loss=0.68, val_MAE=0.657, val_loss=0.708]Epoch 41:   4%|▍         | 41/1000 [1:16:25<28:12:35, 105.90s/it, lr=0.000125, test_MAE=0.699, time=106, train_MAE=0.63, train_loss=0.68, val_MAE=0.657, val_loss=0.708]Epoch 41:   4%|▍         | 41/1000 [1:18:11<28:12:35, 105.90s/it, lr=0.000125, test_MAE=0.713, time=107, train_MAE=0.632, train_loss=0.683, val_MAE=0.682, val_loss=0.733]Epoch 41:   4%|▍         | 42/1000 [1:18:11<28:14:20, 106.12s/it, lr=0.000125, test_MAE=0.713, time=107, train_MAE=0.632, train_loss=0.683, val_MAE=0.682, val_loss=0.733]Epoch 42:   4%|▍         | 42/1000 [1:18:11<28:14:20, 106.12s/it, lr=0.000125, test_MAE=0.713, time=107, train_MAE=0.632, train_loss=0.683, val_MAE=0.682, val_loss=0.733]Epoch 42:   4%|▍         | 42/1000 [1:19:58<28:14:20, 106.12s/it, lr=0.000125, test_MAE=0.696, time=106, train_MAE=0.628, train_loss=0.679, val_MAE=0.659, val_loss=0.709]Epoch 42:   4%|▍         | 43/1000 [1:19:58<28:13:33, 106.18s/it, lr=0.000125, test_MAE=0.696, time=106, train_MAE=0.628, train_loss=0.679, val_MAE=0.659, val_loss=0.709]Epoch 43:   4%|▍         | 43/1000 [1:19:58<28:13:33, 106.18s/it, lr=0.000125, test_MAE=0.696, time=106, train_MAE=0.628, train_loss=0.679, val_MAE=0.659, val_loss=0.709]Epoch 43:   4%|▍         | 43/1000 [1:21:43<28:13:33, 106.18s/it, lr=0.000125, test_MAE=0.7, time=105, train_MAE=0.625, train_loss=0.676, val_MAE=0.666, val_loss=0.717]  Epoch 43:   4%|▍         | 44/1000 [1:21:43<28:07:33, 105.91s/it, lr=0.000125, test_MAE=0.7, time=105, train_MAE=0.625, train_loss=0.676, val_MAE=0.666, val_loss=0.717]Epoch 44:   4%|▍         | 44/1000 [1:21:43<28:07:33, 105.91s/it, lr=0.000125, test_MAE=0.7, time=105, train_MAE=0.625, train_loss=0.676, val_MAE=0.666, val_loss=0.717]Epoch 44:   4%|▍         | 44/1000 [1:23:29<28:07:33, 105.91s/it, lr=0.000125, test_MAE=0.687, time=106, train_MAE=0.631, train_loss=0.681, val_MAE=0.642, val_loss=0.693]Epoch 44:   4%|▍         | 45/1000 [1:23:29<28:05:57, 105.92s/it, lr=0.000125, test_MAE=0.687, time=106, train_MAE=0.631, train_loss=0.681, val_MAE=0.642, val_loss=0.693]Epoch 45:   4%|▍         | 45/1000 [1:23:29<28:05:57, 105.92s/it, lr=0.000125, test_MAE=0.687, time=106, train_MAE=0.631, train_loss=0.681, val_MAE=0.642, val_loss=0.693]Epoch 45:   4%|▍         | 45/1000 [1:25:14<28:05:57, 105.92s/it, lr=0.000125, test_MAE=0.689, time=105, train_MAE=0.634, train_loss=0.685, val_MAE=0.644, val_loss=0.694]Epoch 45:   5%|▍         | 46/1000 [1:25:14<28:01:32, 105.76s/it, lr=0.000125, test_MAE=0.689, time=105, train_MAE=0.634, train_loss=0.685, val_MAE=0.644, val_loss=0.694]Epoch 46:   5%|▍         | 46/1000 [1:25:14<28:01:32, 105.76s/it, lr=0.000125, test_MAE=0.689, time=105, train_MAE=0.634, train_loss=0.685, val_MAE=0.644, val_loss=0.694]Epoch 46:   5%|▍         | 46/1000 [1:27:00<28:01:32, 105.76s/it, lr=0.000125, test_MAE=0.753, time=105, train_MAE=0.621, train_loss=0.672, val_MAE=0.723, val_loss=0.773]Epoch 46:   5%|▍         | 47/1000 [1:27:00<27:57:57, 105.64s/it, lr=0.000125, test_MAE=0.753, time=105, train_MAE=0.621, train_loss=0.672, val_MAE=0.723, val_loss=0.773]Epoch 47:   5%|▍         | 47/1000 [1:27:00<27:57:57, 105.64s/it, lr=0.000125, test_MAE=0.753, time=105, train_MAE=0.621, train_loss=0.672, val_MAE=0.723, val_loss=0.773]Epoch 47:   5%|▍         | 47/1000 [1:28:45<27:57:57, 105.64s/it, lr=0.000125, test_MAE=0.727, time=106, train_MAE=0.622, train_loss=0.672, val_MAE=0.674, val_loss=0.725]Epoch 47:   5%|▍         | 48/1000 [1:28:45<27:56:08, 105.64s/it, lr=0.000125, test_MAE=0.727, time=106, train_MAE=0.622, train_loss=0.672, val_MAE=0.674, val_loss=0.725]Epoch 48:   5%|▍         | 48/1000 [1:28:45<27:56:08, 105.64s/it, lr=0.000125, test_MAE=0.727, time=106, train_MAE=0.622, train_loss=0.672, val_MAE=0.674, val_loss=0.725]Epoch 48:   5%|▍         | 48/1000 [1:30:31<27:56:08, 105.64s/it, lr=0.000125, test_MAE=0.705, time=106, train_MAE=0.625, train_loss=0.675, val_MAE=0.66, val_loss=0.711] Epoch 48:   5%|▍         | 49/1000 [1:30:31<27:54:33, 105.65s/it, lr=0.000125, test_MAE=0.705, time=106, train_MAE=0.625, train_loss=0.675, val_MAE=0.66, val_loss=0.711]Epoch 49:   5%|▍         | 49/1000 [1:30:31<27:54:33, 105.65s/it, lr=0.000125, test_MAE=0.705, time=106, train_MAE=0.625, train_loss=0.675, val_MAE=0.66, val_loss=0.711]Epoch 49:   5%|▍         | 49/1000 [1:32:17<27:54:33, 105.65s/it, lr=0.000125, test_MAE=0.697, time=106, train_MAE=0.621, train_loss=0.672, val_MAE=0.656, val_loss=0.707]Epoch 49:   5%|▌         | 50/1000 [1:32:17<27:53:12, 105.68s/it, lr=0.000125, test_MAE=0.697, time=106, train_MAE=0.621, train_loss=0.672, val_MAE=0.656, val_loss=0.707]Epoch 50:   5%|▌         | 50/1000 [1:32:17<27:53:12, 105.68s/it, lr=0.000125, test_MAE=0.697, time=106, train_MAE=0.621, train_loss=0.672, val_MAE=0.656, val_loss=0.707]Epoch 50:   5%|▌         | 50/1000 [1:34:02<27:53:12, 105.68s/it, lr=0.000125, test_MAE=0.73, time=106, train_MAE=0.628, train_loss=0.678, val_MAE=0.667, val_loss=0.718] Epoch    51: reducing learning rate of group 0 to 6.2500e-05.
Epoch 50:   5%|▌         | 51/1000 [1:34:02<27:51:28, 105.68s/it, lr=0.000125, test_MAE=0.73, time=106, train_MAE=0.628, train_loss=0.678, val_MAE=0.667, val_loss=0.718]Epoch 51:   5%|▌         | 51/1000 [1:34:02<27:51:28, 105.68s/it, lr=0.000125, test_MAE=0.73, time=106, train_MAE=0.628, train_loss=0.678, val_MAE=0.667, val_loss=0.718]Epoch 51:   5%|▌         | 51/1000 [1:35:49<27:51:28, 105.68s/it, lr=6.25e-5, test_MAE=0.683, time=106, train_MAE=0.614, train_loss=0.664, val_MAE=0.653, val_loss=0.704]Epoch 51:   5%|▌         | 52/1000 [1:35:49<27:51:57, 105.82s/it, lr=6.25e-5, test_MAE=0.683, time=106, train_MAE=0.614, train_loss=0.664, val_MAE=0.653, val_loss=0.704]Epoch 52:   5%|▌         | 52/1000 [1:35:49<27:51:57, 105.82s/it, lr=6.25e-5, test_MAE=0.683, time=106, train_MAE=0.614, train_loss=0.664, val_MAE=0.653, val_loss=0.704]Epoch 52:   5%|▌         | 52/1000 [1:37:34<27:51:57, 105.82s/it, lr=6.25e-5, test_MAE=0.689, time=105, train_MAE=0.62, train_loss=0.67, val_MAE=0.653, val_loss=0.704]  Epoch 52:   5%|▌         | 53/1000 [1:37:34<27:47:16, 105.64s/it, lr=6.25e-5, test_MAE=0.689, time=105, train_MAE=0.62, train_loss=0.67, val_MAE=0.653, val_loss=0.704]Epoch 53:   5%|▌         | 53/1000 [1:37:34<27:47:16, 105.64s/it, lr=6.25e-5, test_MAE=0.689, time=105, train_MAE=0.62, train_loss=0.67, val_MAE=0.653, val_loss=0.704]Epoch 53:   5%|▌         | 53/1000 [1:39:19<27:47:16, 105.64s/it, lr=6.25e-5, test_MAE=0.677, time=105, train_MAE=0.621, train_loss=0.671, val_MAE=0.641, val_loss=0.691]Epoch 53:   5%|▌         | 54/1000 [1:39:19<27:42:57, 105.47s/it, lr=6.25e-5, test_MAE=0.677, time=105, train_MAE=0.621, train_loss=0.671, val_MAE=0.641, val_loss=0.691]Epoch 54:   5%|▌         | 54/1000 [1:39:19<27:42:57, 105.47s/it, lr=6.25e-5, test_MAE=0.677, time=105, train_MAE=0.621, train_loss=0.671, val_MAE=0.641, val_loss=0.691]Epoch 54:   5%|▌         | 54/1000 [1:41:05<27:42:57, 105.47s/it, lr=6.25e-5, test_MAE=0.691, time=106, train_MAE=0.622, train_loss=0.672, val_MAE=0.649, val_loss=0.7]  Epoch 54:   6%|▌         | 55/1000 [1:41:05<27:42:02, 105.53s/it, lr=6.25e-5, test_MAE=0.691, time=106, train_MAE=0.622, train_loss=0.672, val_MAE=0.649, val_loss=0.7]Epoch 55:   6%|▌         | 55/1000 [1:41:05<27:42:02, 105.53s/it, lr=6.25e-5, test_MAE=0.691, time=106, train_MAE=0.622, train_loss=0.672, val_MAE=0.649, val_loss=0.7]Epoch 55:   6%|▌         | 55/1000 [1:42:51<27:42:02, 105.53s/it, lr=6.25e-5, test_MAE=0.7, time=107, train_MAE=0.63, train_loss=0.681, val_MAE=0.662, val_loss=0.713] Epoch 55:   6%|▌         | 56/1000 [1:42:51<27:45:22, 105.85s/it, lr=6.25e-5, test_MAE=0.7, time=107, train_MAE=0.63, train_loss=0.681, val_MAE=0.662, val_loss=0.713]Epoch 56:   6%|▌         | 56/1000 [1:42:51<27:45:22, 105.85s/it, lr=6.25e-5, test_MAE=0.7, time=107, train_MAE=0.63, train_loss=0.681, val_MAE=0.662, val_loss=0.713]Epoch 56:   6%|▌         | 56/1000 [1:44:37<27:45:22, 105.85s/it, lr=6.25e-5, test_MAE=0.69, time=106, train_MAE=0.618, train_loss=0.668, val_MAE=0.653, val_loss=0.703]Epoch 56:   6%|▌         | 57/1000 [1:44:37<27:42:21, 105.77s/it, lr=6.25e-5, test_MAE=0.69, time=106, train_MAE=0.618, train_loss=0.668, val_MAE=0.653, val_loss=0.703]Epoch 57:   6%|▌         | 57/1000 [1:44:37<27:42:21, 105.77s/it, lr=6.25e-5, test_MAE=0.69, time=106, train_MAE=0.618, train_loss=0.668, val_MAE=0.653, val_loss=0.703]Epoch 57:   6%|▌         | 57/1000 [1:46:22<27:42:21, 105.77s/it, lr=6.25e-5, test_MAE=0.706, time=105, train_MAE=0.617, train_loss=0.667, val_MAE=0.676, val_loss=0.726]Epoch 57:   6%|▌         | 58/1000 [1:46:22<27:38:36, 105.64s/it, lr=6.25e-5, test_MAE=0.706, time=105, train_MAE=0.617, train_loss=0.667, val_MAE=0.676, val_loss=0.726]Epoch 58:   6%|▌         | 58/1000 [1:46:22<27:38:36, 105.64s/it, lr=6.25e-5, test_MAE=0.706, time=105, train_MAE=0.617, train_loss=0.667, val_MAE=0.676, val_loss=0.726]Epoch 58:   6%|▌         | 58/1000 [1:48:08<27:38:36, 105.64s/it, lr=6.25e-5, test_MAE=0.679, time=106, train_MAE=0.618, train_loss=0.668, val_MAE=0.638, val_loss=0.688]Epoch 58:   6%|▌         | 59/1000 [1:48:08<27:36:43, 105.64s/it, lr=6.25e-5, test_MAE=0.679, time=106, train_MAE=0.618, train_loss=0.668, val_MAE=0.638, val_loss=0.688]Epoch 59:   6%|▌         | 59/1000 [1:48:08<27:36:43, 105.64s/it, lr=6.25e-5, test_MAE=0.679, time=106, train_MAE=0.618, train_loss=0.668, val_MAE=0.638, val_loss=0.688]Epoch 59:   6%|▌         | 59/1000 [1:49:53<27:36:43, 105.64s/it, lr=6.25e-5, test_MAE=0.686, time=105, train_MAE=0.617, train_loss=0.667, val_MAE=0.652, val_loss=0.703]Epoch 59:   6%|▌         | 60/1000 [1:49:53<27:33:56, 105.57s/it, lr=6.25e-5, test_MAE=0.686, time=105, train_MAE=0.617, train_loss=0.667, val_MAE=0.652, val_loss=0.703]Epoch 60:   6%|▌         | 60/1000 [1:49:53<27:33:56, 105.57s/it, lr=6.25e-5, test_MAE=0.686, time=105, train_MAE=0.617, train_loss=0.667, val_MAE=0.652, val_loss=0.703]Epoch 60:   6%|▌         | 60/1000 [1:51:38<27:33:56, 105.57s/it, lr=6.25e-5, test_MAE=0.741, time=105, train_MAE=0.621, train_loss=0.671, val_MAE=0.718, val_loss=0.768]Epoch 60:   6%|▌         | 61/1000 [1:51:38<27:31:04, 105.50s/it, lr=6.25e-5, test_MAE=0.741, time=105, train_MAE=0.621, train_loss=0.671, val_MAE=0.718, val_loss=0.768]Epoch 61:   6%|▌         | 61/1000 [1:51:38<27:31:04, 105.50s/it, lr=6.25e-5, test_MAE=0.741, time=105, train_MAE=0.621, train_loss=0.671, val_MAE=0.718, val_loss=0.768]Epoch 61:   6%|▌         | 61/1000 [1:53:24<27:31:04, 105.50s/it, lr=6.25e-5, test_MAE=0.687, time=105, train_MAE=0.621, train_loss=0.671, val_MAE=0.651, val_loss=0.701]Epoch 61:   6%|▌         | 62/1000 [1:53:24<27:29:10, 105.49s/it, lr=6.25e-5, test_MAE=0.687, time=105, train_MAE=0.621, train_loss=0.671, val_MAE=0.651, val_loss=0.701]Epoch 62:   6%|▌         | 62/1000 [1:53:24<27:29:10, 105.49s/it, lr=6.25e-5, test_MAE=0.687, time=105, train_MAE=0.621, train_loss=0.671, val_MAE=0.651, val_loss=0.701]Epoch 62:   6%|▌         | 62/1000 [1:55:10<27:29:10, 105.49s/it, lr=6.25e-5, test_MAE=0.69, time=106, train_MAE=0.624, train_loss=0.674, val_MAE=0.655, val_loss=0.705] Epoch 62:   6%|▋         | 63/1000 [1:55:10<27:28:15, 105.54s/it, lr=6.25e-5, test_MAE=0.69, time=106, train_MAE=0.624, train_loss=0.674, val_MAE=0.655, val_loss=0.705]Epoch 63:   6%|▋         | 63/1000 [1:55:10<27:28:15, 105.54s/it, lr=6.25e-5, test_MAE=0.69, time=106, train_MAE=0.624, train_loss=0.674, val_MAE=0.655, val_loss=0.705]Epoch 63:   6%|▋         | 63/1000 [1:56:55<27:28:15, 105.54s/it, lr=6.25e-5, test_MAE=0.713, time=105, train_MAE=0.619, train_loss=0.669, val_MAE=0.67, val_loss=0.72] Epoch 63:   6%|▋         | 64/1000 [1:56:55<27:26:02, 105.52s/it, lr=6.25e-5, test_MAE=0.713, time=105, train_MAE=0.619, train_loss=0.669, val_MAE=0.67, val_loss=0.72]Epoch 64:   6%|▋         | 64/1000 [1:56:55<27:26:02, 105.52s/it, lr=6.25e-5, test_MAE=0.713, time=105, train_MAE=0.619, train_loss=0.669, val_MAE=0.67, val_loss=0.72]Epoch 64:   6%|▋         | 64/1000 [1:58:40<27:26:02, 105.52s/it, lr=6.25e-5, test_MAE=0.682, time=105, train_MAE=0.619, train_loss=0.67, val_MAE=0.636, val_loss=0.686]Epoch 64:   6%|▋         | 65/1000 [1:58:40<27:23:54, 105.49s/it, lr=6.25e-5, test_MAE=0.682, time=105, train_MAE=0.619, train_loss=0.67, val_MAE=0.636, val_loss=0.686]Epoch 65:   6%|▋         | 65/1000 [1:58:40<27:23:54, 105.49s/it, lr=6.25e-5, test_MAE=0.682, time=105, train_MAE=0.619, train_loss=0.67, val_MAE=0.636, val_loss=0.686]Epoch 65:   6%|▋         | 65/1000 [2:00:26<27:23:54, 105.49s/it, lr=6.25e-5, test_MAE=0.678, time=106, train_MAE=0.618, train_loss=0.668, val_MAE=0.639, val_loss=0.69]Epoch 65:   7%|▋         | 66/1000 [2:00:26<27:22:54, 105.54s/it, lr=6.25e-5, test_MAE=0.678, time=106, train_MAE=0.618, train_loss=0.668, val_MAE=0.639, val_loss=0.69]Epoch 66:   7%|▋         | 66/1000 [2:00:26<27:22:54, 105.54s/it, lr=6.25e-5, test_MAE=0.678, time=106, train_MAE=0.618, train_loss=0.668, val_MAE=0.639, val_loss=0.69]Epoch 66:   7%|▋         | 66/1000 [2:02:11<27:22:54, 105.54s/it, lr=6.25e-5, test_MAE=0.712, time=105, train_MAE=0.618, train_loss=0.669, val_MAE=0.686, val_loss=0.736]Epoch 66:   7%|▋         | 67/1000 [2:02:11<27:19:02, 105.40s/it, lr=6.25e-5, test_MAE=0.712, time=105, train_MAE=0.618, train_loss=0.669, val_MAE=0.686, val_loss=0.736]Epoch 67:   7%|▋         | 67/1000 [2:02:11<27:19:02, 105.40s/it, lr=6.25e-5, test_MAE=0.712, time=105, train_MAE=0.618, train_loss=0.669, val_MAE=0.686, val_loss=0.736]Epoch 67:   7%|▋         | 67/1000 [2:03:56<27:19:02, 105.40s/it, lr=6.25e-5, test_MAE=0.687, time=105, train_MAE=0.636, train_loss=0.686, val_MAE=0.649, val_loss=0.699]Epoch 67:   7%|▋         | 68/1000 [2:03:56<27:15:13, 105.27s/it, lr=6.25e-5, test_MAE=0.687, time=105, train_MAE=0.636, train_loss=0.686, val_MAE=0.649, val_loss=0.699]Epoch 68:   7%|▋         | 68/1000 [2:03:56<27:15:13, 105.27s/it, lr=6.25e-5, test_MAE=0.687, time=105, train_MAE=0.636, train_loss=0.686, val_MAE=0.649, val_loss=0.699]Epoch 68:   7%|▋         | 68/1000 [2:05:41<27:15:13, 105.27s/it, lr=6.25e-5, test_MAE=0.683, time=105, train_MAE=0.615, train_loss=0.665, val_MAE=0.643, val_loss=0.693]Epoch 68:   7%|▋         | 69/1000 [2:05:41<27:12:05, 105.18s/it, lr=6.25e-5, test_MAE=0.683, time=105, train_MAE=0.615, train_loss=0.665, val_MAE=0.643, val_loss=0.693]Epoch 69:   7%|▋         | 69/1000 [2:05:41<27:12:05, 105.18s/it, lr=6.25e-5, test_MAE=0.683, time=105, train_MAE=0.615, train_loss=0.665, val_MAE=0.643, val_loss=0.693]Epoch 69:   7%|▋         | 69/1000 [2:07:27<27:12:05, 105.18s/it, lr=6.25e-5, test_MAE=0.682, time=105, train_MAE=0.62, train_loss=0.67, val_MAE=0.644, val_loss=0.694]  Epoch 69:   7%|▋         | 70/1000 [2:07:27<27:11:33, 105.26s/it, lr=6.25e-5, test_MAE=0.682, time=105, train_MAE=0.62, train_loss=0.67, val_MAE=0.644, val_loss=0.694]Epoch 70:   7%|▋         | 70/1000 [2:07:27<27:11:33, 105.26s/it, lr=6.25e-5, test_MAE=0.682, time=105, train_MAE=0.62, train_loss=0.67, val_MAE=0.644, val_loss=0.694]Epoch 70:   7%|▋         | 70/1000 [2:09:12<27:11:33, 105.26s/it, lr=6.25e-5, test_MAE=0.683, time=105, train_MAE=0.62, train_loss=0.671, val_MAE=0.649, val_loss=0.699]Epoch    71: reducing learning rate of group 0 to 3.1250e-05.
Epoch 70:   7%|▋         | 71/1000 [2:09:12<27:08:27, 105.17s/it, lr=6.25e-5, test_MAE=0.683, time=105, train_MAE=0.62, train_loss=0.671, val_MAE=0.649, val_loss=0.699]Epoch 71:   7%|▋         | 71/1000 [2:09:12<27:08:27, 105.17s/it, lr=6.25e-5, test_MAE=0.683, time=105, train_MAE=0.62, train_loss=0.671, val_MAE=0.649, val_loss=0.699]Epoch 71:   7%|▋         | 71/1000 [2:10:57<27:08:27, 105.17s/it, lr=3.13e-5, test_MAE=0.697, time=105, train_MAE=0.616, train_loss=0.666, val_MAE=0.673, val_loss=0.723]Epoch 71:   7%|▋         | 72/1000 [2:10:57<27:06:04, 105.13s/it, lr=3.13e-5, test_MAE=0.697, time=105, train_MAE=0.616, train_loss=0.666, val_MAE=0.673, val_loss=0.723]Epoch 72:   7%|▋         | 72/1000 [2:10:57<27:06:04, 105.13s/it, lr=3.13e-5, test_MAE=0.697, time=105, train_MAE=0.616, train_loss=0.666, val_MAE=0.673, val_loss=0.723]Epoch 72:   7%|▋         | 72/1000 [2:12:42<27:06:04, 105.13s/it, lr=3.13e-5, test_MAE=0.674, time=105, train_MAE=0.624, train_loss=0.674, val_MAE=0.635, val_loss=0.685]Epoch 72:   7%|▋         | 73/1000 [2:12:42<27:05:27, 105.21s/it, lr=3.13e-5, test_MAE=0.674, time=105, train_MAE=0.624, train_loss=0.674, val_MAE=0.635, val_loss=0.685]Epoch 73:   7%|▋         | 73/1000 [2:12:42<27:05:27, 105.21s/it, lr=3.13e-5, test_MAE=0.674, time=105, train_MAE=0.624, train_loss=0.674, val_MAE=0.635, val_loss=0.685]Epoch 73:   7%|▋         | 73/1000 [2:14:27<27:05:27, 105.21s/it, lr=3.13e-5, test_MAE=0.678, time=105, train_MAE=0.619, train_loss=0.669, val_MAE=0.648, val_loss=0.698]Epoch 73:   7%|▋         | 74/1000 [2:14:27<27:03:04, 105.17s/it, lr=3.13e-5, test_MAE=0.678, time=105, train_MAE=0.619, train_loss=0.669, val_MAE=0.648, val_loss=0.698]Epoch 74:   7%|▋         | 74/1000 [2:14:27<27:03:04, 105.17s/it, lr=3.13e-5, test_MAE=0.678, time=105, train_MAE=0.619, train_loss=0.669, val_MAE=0.648, val_loss=0.698]Epoch 74:   7%|▋         | 74/1000 [2:16:12<27:03:04, 105.17s/it, lr=3.13e-5, test_MAE=0.675, time=105, train_MAE=0.62, train_loss=0.67, val_MAE=0.638, val_loss=0.688]  Epoch 74:   8%|▊         | 75/1000 [2:16:12<27:00:03, 105.08s/it, lr=3.13e-5, test_MAE=0.675, time=105, train_MAE=0.62, train_loss=0.67, val_MAE=0.638, val_loss=0.688]Epoch 75:   8%|▊         | 75/1000 [2:16:12<27:00:03, 105.08s/it, lr=3.13e-5, test_MAE=0.675, time=105, train_MAE=0.62, train_loss=0.67, val_MAE=0.638, val_loss=0.688]Epoch 75:   8%|▊         | 75/1000 [2:17:57<27:00:03, 105.08s/it, lr=3.13e-5, test_MAE=0.709, time=105, train_MAE=0.613, train_loss=0.663, val_MAE=0.671, val_loss=0.721]Epoch 75:   8%|▊         | 76/1000 [2:17:57<26:57:47, 105.05s/it, lr=3.13e-5, test_MAE=0.709, time=105, train_MAE=0.613, train_loss=0.663, val_MAE=0.671, val_loss=0.721]Epoch 76:   8%|▊         | 76/1000 [2:17:57<26:57:47, 105.05s/it, lr=3.13e-5, test_MAE=0.709, time=105, train_MAE=0.613, train_loss=0.663, val_MAE=0.671, val_loss=0.721]Epoch 76:   8%|▊         | 76/1000 [2:19:42<26:57:47, 105.05s/it, lr=3.13e-5, test_MAE=0.71, time=105, train_MAE=0.619, train_loss=0.669, val_MAE=0.672, val_loss=0.722] Epoch 76:   8%|▊         | 77/1000 [2:19:42<26:57:08, 105.12s/it, lr=3.13e-5, test_MAE=0.71, time=105, train_MAE=0.619, train_loss=0.669, val_MAE=0.672, val_loss=0.722]Epoch 77:   8%|▊         | 77/1000 [2:19:42<26:57:08, 105.12s/it, lr=3.13e-5, test_MAE=0.71, time=105, train_MAE=0.619, train_loss=0.669, val_MAE=0.672, val_loss=0.722]Epoch 77:   8%|▊         | 77/1000 [2:21:27<26:57:08, 105.12s/it, lr=3.13e-5, test_MAE=0.683, time=105, train_MAE=0.611, train_loss=0.661, val_MAE=0.65, val_loss=0.7]  Epoch 77:   8%|▊         | 78/1000 [2:21:27<26:54:37, 105.07s/it, lr=3.13e-5, test_MAE=0.683, time=105, train_MAE=0.611, train_loss=0.661, val_MAE=0.65, val_loss=0.7]Epoch 78:   8%|▊         | 78/1000 [2:21:27<26:54:37, 105.07s/it, lr=3.13e-5, test_MAE=0.683, time=105, train_MAE=0.611, train_loss=0.661, val_MAE=0.65, val_loss=0.7]Epoch 78:   8%|▊         | 78/1000 [2:23:12<26:54:37, 105.07s/it, lr=3.13e-5, test_MAE=0.685, time=105, train_MAE=0.628, train_loss=0.678, val_MAE=0.641, val_loss=0.691]Epoch    79: reducing learning rate of group 0 to 1.5625e-05.
Epoch 78:   8%|▊         | 79/1000 [2:23:12<26:52:53, 105.07s/it, lr=3.13e-5, test_MAE=0.685, time=105, train_MAE=0.628, train_loss=0.678, val_MAE=0.641, val_loss=0.691]Epoch 79:   8%|▊         | 79/1000 [2:23:12<26:52:53, 105.07s/it, lr=3.13e-5, test_MAE=0.685, time=105, train_MAE=0.628, train_loss=0.678, val_MAE=0.641, val_loss=0.691]Epoch 79:   8%|▊         | 79/1000 [2:24:57<26:52:53, 105.07s/it, lr=1.56e-5, test_MAE=0.685, time=105, train_MAE=0.621, train_loss=0.671, val_MAE=0.65, val_loss=0.7]   Epoch 79:   8%|▊         | 80/1000 [2:24:57<26:51:49, 105.12s/it, lr=1.56e-5, test_MAE=0.685, time=105, train_MAE=0.621, train_loss=0.671, val_MAE=0.65, val_loss=0.7]Epoch 80:   8%|▊         | 80/1000 [2:24:57<26:51:49, 105.12s/it, lr=1.56e-5, test_MAE=0.685, time=105, train_MAE=0.621, train_loss=0.671, val_MAE=0.65, val_loss=0.7]Epoch 80:   8%|▊         | 80/1000 [2:26:43<26:51:49, 105.12s/it, lr=1.56e-5, test_MAE=0.682, time=105, train_MAE=0.619, train_loss=0.669, val_MAE=0.642, val_loss=0.692]Epoch 80:   8%|▊         | 81/1000 [2:26:43<26:49:46, 105.10s/it, lr=1.56e-5, test_MAE=0.682, time=105, train_MAE=0.619, train_loss=0.669, val_MAE=0.642, val_loss=0.692]Epoch 81:   8%|▊         | 81/1000 [2:26:43<26:49:46, 105.10s/it, lr=1.56e-5, test_MAE=0.682, time=105, train_MAE=0.619, train_loss=0.669, val_MAE=0.642, val_loss=0.692]Epoch 81:   8%|▊         | 81/1000 [2:28:28<26:49:46, 105.10s/it, lr=1.56e-5, test_MAE=0.69, time=105, train_MAE=0.617, train_loss=0.667, val_MAE=0.648, val_loss=0.698] Epoch 81:   8%|▊         | 82/1000 [2:28:28<26:47:34, 105.07s/it, lr=1.56e-5, test_MAE=0.69, time=105, train_MAE=0.617, train_loss=0.667, val_MAE=0.648, val_loss=0.698]Epoch 82:   8%|▊         | 82/1000 [2:28:28<26:47:34, 105.07s/it, lr=1.56e-5, test_MAE=0.69, time=105, train_MAE=0.617, train_loss=0.667, val_MAE=0.648, val_loss=0.698]Epoch 82:   8%|▊         | 82/1000 [2:30:13<26:47:34, 105.07s/it, lr=1.56e-5, test_MAE=0.677, time=105, train_MAE=0.619, train_loss=0.669, val_MAE=0.649, val_loss=0.699]Epoch 82:   8%|▊         | 83/1000 [2:30:13<26:45:32, 105.05s/it, lr=1.56e-5, test_MAE=0.677, time=105, train_MAE=0.619, train_loss=0.669, val_MAE=0.649, val_loss=0.699]Epoch 83:   8%|▊         | 83/1000 [2:30:13<26:45:32, 105.05s/it, lr=1.56e-5, test_MAE=0.677, time=105, train_MAE=0.619, train_loss=0.669, val_MAE=0.649, val_loss=0.699]Epoch 83:   8%|▊         | 83/1000 [2:31:58<26:45:32, 105.05s/it, lr=1.56e-5, test_MAE=0.674, time=105, train_MAE=0.614, train_loss=0.664, val_MAE=0.644, val_loss=0.693]Epoch 83:   8%|▊         | 84/1000 [2:31:58<26:45:07, 105.14s/it, lr=1.56e-5, test_MAE=0.674, time=105, train_MAE=0.614, train_loss=0.664, val_MAE=0.644, val_loss=0.693]Epoch 84:   8%|▊         | 84/1000 [2:31:58<26:45:07, 105.14s/it, lr=1.56e-5, test_MAE=0.674, time=105, train_MAE=0.614, train_loss=0.664, val_MAE=0.644, val_loss=0.693]Epoch 84:   8%|▊         | 84/1000 [2:33:43<26:45:07, 105.14s/it, lr=1.56e-5, test_MAE=0.664, time=105, train_MAE=0.618, train_loss=0.668, val_MAE=0.634, val_loss=0.684]Epoch 84:   8%|▊         | 85/1000 [2:33:43<26:42:41, 105.09s/it, lr=1.56e-5, test_MAE=0.664, time=105, train_MAE=0.618, train_loss=0.668, val_MAE=0.634, val_loss=0.684]Epoch 85:   8%|▊         | 85/1000 [2:33:43<26:42:41, 105.09s/it, lr=1.56e-5, test_MAE=0.664, time=105, train_MAE=0.618, train_loss=0.668, val_MAE=0.634, val_loss=0.684]Epoch 85:   8%|▊         | 85/1000 [2:35:28<26:42:41, 105.09s/it, lr=1.56e-5, test_MAE=0.676, time=105, train_MAE=0.622, train_loss=0.672, val_MAE=0.644, val_loss=0.694]Epoch 85:   9%|▊         | 86/1000 [2:35:28<26:40:36, 105.07s/it, lr=1.56e-5, test_MAE=0.676, time=105, train_MAE=0.622, train_loss=0.672, val_MAE=0.644, val_loss=0.694]Epoch 86:   9%|▊         | 86/1000 [2:35:28<26:40:36, 105.07s/it, lr=1.56e-5, test_MAE=0.676, time=105, train_MAE=0.622, train_loss=0.672, val_MAE=0.644, val_loss=0.694]Epoch 86:   9%|▊         | 86/1000 [2:37:13<26:40:36, 105.07s/it, lr=1.56e-5, test_MAE=0.71, time=105, train_MAE=0.614, train_loss=0.664, val_MAE=0.643, val_loss=0.692] Epoch 86:   9%|▊         | 87/1000 [2:37:13<26:39:46, 105.13s/it, lr=1.56e-5, test_MAE=0.71, time=105, train_MAE=0.614, train_loss=0.664, val_MAE=0.643, val_loss=0.692]Epoch 87:   9%|▊         | 87/1000 [2:37:13<26:39:46, 105.13s/it, lr=1.56e-5, test_MAE=0.71, time=105, train_MAE=0.614, train_loss=0.664, val_MAE=0.643, val_loss=0.692]Epoch 87:   9%|▊         | 87/1000 [2:38:58<26:39:46, 105.13s/it, lr=1.56e-5, test_MAE=0.689, time=105, train_MAE=0.616, train_loss=0.666, val_MAE=0.652, val_loss=0.702]Epoch 87:   9%|▉         | 88/1000 [2:38:58<26:36:50, 105.06s/it, lr=1.56e-5, test_MAE=0.689, time=105, train_MAE=0.616, train_loss=0.666, val_MAE=0.652, val_loss=0.702]Epoch 88:   9%|▉         | 88/1000 [2:38:58<26:36:50, 105.06s/it, lr=1.56e-5, test_MAE=0.689, time=105, train_MAE=0.616, train_loss=0.666, val_MAE=0.652, val_loss=0.702]Epoch 88:   9%|▉         | 88/1000 [2:40:43<26:36:50, 105.06s/it, lr=1.56e-5, test_MAE=0.69, time=105, train_MAE=0.619, train_loss=0.669, val_MAE=0.653, val_loss=0.703] Epoch 88:   9%|▉         | 89/1000 [2:40:43<26:34:24, 105.01s/it, lr=1.56e-5, test_MAE=0.69, time=105, train_MAE=0.619, train_loss=0.669, val_MAE=0.653, val_loss=0.703]Epoch 89:   9%|▉         | 89/1000 [2:40:43<26:34:24, 105.01s/it, lr=1.56e-5, test_MAE=0.69, time=105, train_MAE=0.619, train_loss=0.669, val_MAE=0.653, val_loss=0.703]Epoch 89:   9%|▉         | 89/1000 [2:42:28<26:34:24, 105.01s/it, lr=1.56e-5, test_MAE=0.694, time=105, train_MAE=0.619, train_loss=0.669, val_MAE=0.653, val_loss=0.703]Epoch 89:   9%|▉         | 90/1000 [2:42:28<26:32:36, 105.01s/it, lr=1.56e-5, test_MAE=0.694, time=105, train_MAE=0.619, train_loss=0.669, val_MAE=0.653, val_loss=0.703]Epoch 90:   9%|▉         | 90/1000 [2:42:28<26:32:36, 105.01s/it, lr=1.56e-5, test_MAE=0.694, time=105, train_MAE=0.619, train_loss=0.669, val_MAE=0.653, val_loss=0.703]Epoch 90:   9%|▉         | 90/1000 [2:44:13<26:32:36, 105.01s/it, lr=1.56e-5, test_MAE=0.68, time=105, train_MAE=0.616, train_loss=0.666, val_MAE=0.643, val_loss=0.693] Epoch    91: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 90:   9%|▉         | 90/1000 [2:44:13<27:40:31, 109.49s/it, lr=1.56e-5, test_MAE=0.68, time=105, train_MAE=0.616, train_loss=0.666, val_MAE=0.643, val_loss=0.693]
Test MAE: 0.6797
Train MAE: 0.6224
Convergence Time (Epochs): 90.0000
TOTAL TIME TAKEN: 9903.8630s
AVG TIME PER EPOCH: 108.2651s
