I'm echoing to stdout
I'm echoing to stderr
My JobID is 56621679
I have 8 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.4037s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 4, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'rational_vec', 'normalized_laplacian': True, 'post_normalized': False, 'eigval_norm': '', 'num_eigs': 15, 'bias_mode': 'spatial', 'eigval_hidden_dim': 5, 'eigval_num_hidden_layer': 3, 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 1, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/zinc_train_kway.csv', 'test': 'supp_data/molecules/zinc_test_part_kway.csv', 'val': 'supp_data/molecules/zinc_val_kway.csv'}, 'fixMissingPhi1': True, 'extraOrtho': False, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [02:16<?, ?it/s, lr=0.001, test_MAE=1.57, time=137, train_MAE=1.22, train_loss=1.24, val_MAE=1.53, val_loss=1.55]Epoch 0:   0%|          | 1/1000 [02:16<38:00:17, 136.95s/it, lr=0.001, test_MAE=1.57, time=137, train_MAE=1.22, train_loss=1.24, val_MAE=1.53, val_loss=1.55]Epoch 1:   0%|          | 1/1000 [02:16<38:00:17, 136.95s/it, lr=0.001, test_MAE=1.57, time=137, train_MAE=1.22, train_loss=1.24, val_MAE=1.53, val_loss=1.55]Epoch 1:   0%|          | 1/1000 [04:16<38:00:17, 136.95s/it, lr=0.001, test_MAE=1.27, time=120, train_MAE=0.868, train_loss=0.899, val_MAE=1.17, val_loss=1.2]Epoch 1:   0%|          | 2/1000 [04:17<36:33:39, 131.88s/it, lr=0.001, test_MAE=1.27, time=120, train_MAE=0.868, train_loss=0.899, val_MAE=1.17, val_loss=1.2]Epoch 2:   0%|          | 2/1000 [04:17<36:33:39, 131.88s/it, lr=0.001, test_MAE=1.27, time=120, train_MAE=0.868, train_loss=0.899, val_MAE=1.17, val_loss=1.2]Epoch 2:   0%|          | 2/1000 [06:17<36:33:39, 131.88s/it, lr=0.001, test_MAE=1.19, time=121, train_MAE=0.781, train_loss=0.815, val_MAE=1.11, val_loss=1.14]Epoch 2:   0%|          | 3/1000 [06:17<35:35:56, 128.54s/it, lr=0.001, test_MAE=1.19, time=121, train_MAE=0.781, train_loss=0.815, val_MAE=1.11, val_loss=1.14]Epoch 3:   0%|          | 3/1000 [06:17<35:35:56, 128.54s/it, lr=0.001, test_MAE=1.19, time=121, train_MAE=0.781, train_loss=0.815, val_MAE=1.11, val_loss=1.14]Epoch 3:   0%|          | 3/1000 [08:17<35:35:56, 128.54s/it, lr=0.001, test_MAE=1.24, time=120, train_MAE=0.724, train_loss=0.759, val_MAE=1.16, val_loss=1.2] Epoch 3:   0%|          | 4/1000 [08:17<34:51:20, 125.98s/it, lr=0.001, test_MAE=1.24, time=120, train_MAE=0.724, train_loss=0.759, val_MAE=1.16, val_loss=1.2]Epoch 4:   0%|          | 4/1000 [08:17<34:51:20, 125.98s/it, lr=0.001, test_MAE=1.24, time=120, train_MAE=0.724, train_loss=0.759, val_MAE=1.16, val_loss=1.2]Epoch 4:   0%|          | 4/1000 [10:16<34:51:20, 125.98s/it, lr=0.001, test_MAE=0.885, time=119, train_MAE=0.695, train_loss=0.73, val_MAE=0.83, val_loss=0.866]Epoch 4:   0%|          | 5/1000 [10:16<34:13:42, 123.84s/it, lr=0.001, test_MAE=0.885, time=119, train_MAE=0.695, train_loss=0.73, val_MAE=0.83, val_loss=0.866]Epoch 5:   0%|          | 5/1000 [10:16<34:13:42, 123.84s/it, lr=0.001, test_MAE=0.885, time=119, train_MAE=0.695, train_loss=0.73, val_MAE=0.83, val_loss=0.866]Epoch 5:   0%|          | 5/1000 [12:15<34:13:42, 123.84s/it, lr=0.001, test_MAE=0.97, time=119, train_MAE=0.692, train_loss=0.728, val_MAE=0.909, val_loss=0.946]Epoch 5:   1%|          | 6/1000 [12:15<33:45:48, 122.28s/it, lr=0.001, test_MAE=0.97, time=119, train_MAE=0.692, train_loss=0.728, val_MAE=0.909, val_loss=0.946]Epoch 6:   1%|          | 6/1000 [12:15<33:45:48, 122.28s/it, lr=0.001, test_MAE=0.97, time=119, train_MAE=0.692, train_loss=0.728, val_MAE=0.909, val_loss=0.946]Epoch 6:   1%|          | 6/1000 [14:15<33:45:48, 122.28s/it, lr=0.001, test_MAE=0.82, time=120, train_MAE=0.669, train_loss=0.706, val_MAE=0.698, val_loss=0.735]Epoch 6:   1%|          | 7/1000 [14:15<33:31:33, 121.54s/it, lr=0.001, test_MAE=0.82, time=120, train_MAE=0.669, train_loss=0.706, val_MAE=0.698, val_loss=0.735]Epoch 7:   1%|          | 7/1000 [14:15<33:31:33, 121.54s/it, lr=0.001, test_MAE=0.82, time=120, train_MAE=0.669, train_loss=0.706, val_MAE=0.698, val_loss=0.735]Epoch 7:   1%|          | 7/1000 [16:13<33:31:33, 121.54s/it, lr=0.001, test_MAE=0.769, time=119, train_MAE=0.673, train_loss=0.71, val_MAE=0.713, val_loss=0.75] Epoch 7:   1%|          | 8/1000 [16:13<33:16:19, 120.75s/it, lr=0.001, test_MAE=0.769, time=119, train_MAE=0.673, train_loss=0.71, val_MAE=0.713, val_loss=0.75]Epoch 8:   1%|          | 8/1000 [16:13<33:16:19, 120.75s/it, lr=0.001, test_MAE=0.769, time=119, train_MAE=0.673, train_loss=0.71, val_MAE=0.713, val_loss=0.75]Epoch 8:   1%|          | 8/1000 [18:13<33:16:19, 120.75s/it, lr=0.001, test_MAE=0.833, time=119, train_MAE=0.663, train_loss=0.701, val_MAE=0.788, val_loss=0.825]Epoch 8:   1%|          | 9/1000 [18:13<33:07:01, 120.30s/it, lr=0.001, test_MAE=0.833, time=119, train_MAE=0.663, train_loss=0.701, val_MAE=0.788, val_loss=0.825]Epoch 9:   1%|          | 9/1000 [18:13<33:07:01, 120.30s/it, lr=0.001, test_MAE=0.833, time=119, train_MAE=0.663, train_loss=0.701, val_MAE=0.788, val_loss=0.825]Epoch 9:   1%|          | 9/1000 [20:11<33:07:01, 120.30s/it, lr=0.001, test_MAE=0.777, time=119, train_MAE=0.669, train_loss=0.707, val_MAE=0.723, val_loss=0.761]Epoch 9:   1%|          | 10/1000 [20:11<32:57:06, 119.82s/it, lr=0.001, test_MAE=0.777, time=119, train_MAE=0.669, train_loss=0.707, val_MAE=0.723, val_loss=0.761]Epoch 10:   1%|          | 10/1000 [20:11<32:57:06, 119.82s/it, lr=0.001, test_MAE=0.777, time=119, train_MAE=0.669, train_loss=0.707, val_MAE=0.723, val_loss=0.761]Epoch 10:   1%|          | 10/1000 [22:11<32:57:06, 119.82s/it, lr=0.001, test_MAE=0.78, time=120, train_MAE=0.659, train_loss=0.697, val_MAE=0.719, val_loss=0.758] Epoch 10:   1%|          | 11/1000 [22:11<32:54:14, 119.77s/it, lr=0.001, test_MAE=0.78, time=120, train_MAE=0.659, train_loss=0.697, val_MAE=0.719, val_loss=0.758]Epoch 11:   1%|          | 11/1000 [22:11<32:54:14, 119.77s/it, lr=0.001, test_MAE=0.78, time=120, train_MAE=0.659, train_loss=0.697, val_MAE=0.719, val_loss=0.758]Epoch 11:   1%|          | 11/1000 [24:10<32:54:14, 119.77s/it, lr=0.001, test_MAE=0.73, time=119, train_MAE=0.654, train_loss=0.693, val_MAE=0.666, val_loss=0.705]Epoch 11:   1%|          | 12/1000 [24:10<32:49:21, 119.60s/it, lr=0.001, test_MAE=0.73, time=119, train_MAE=0.654, train_loss=0.693, val_MAE=0.666, val_loss=0.705]Epoch 12:   1%|          | 12/1000 [24:10<32:49:21, 119.60s/it, lr=0.001, test_MAE=0.73, time=119, train_MAE=0.654, train_loss=0.693, val_MAE=0.666, val_loss=0.705]Epoch 12:   1%|          | 12/1000 [26:09<32:49:21, 119.60s/it, lr=0.001, test_MAE=0.719, time=119, train_MAE=0.65, train_loss=0.69, val_MAE=0.662, val_loss=0.702] Epoch 12:   1%|▏         | 13/1000 [26:09<32:45:25, 119.48s/it, lr=0.001, test_MAE=0.719, time=119, train_MAE=0.65, train_loss=0.69, val_MAE=0.662, val_loss=0.702]Epoch 13:   1%|▏         | 13/1000 [26:09<32:45:25, 119.48s/it, lr=0.001, test_MAE=0.719, time=119, train_MAE=0.65, train_loss=0.69, val_MAE=0.662, val_loss=0.702]Epoch 13:   1%|▏         | 13/1000 [28:09<32:45:25, 119.48s/it, lr=0.001, test_MAE=0.71, time=120, train_MAE=0.645, train_loss=0.684, val_MAE=0.662, val_loss=0.701]Epoch 13:   1%|▏         | 14/1000 [28:09<32:44:22, 119.54s/it, lr=0.001, test_MAE=0.71, time=120, train_MAE=0.645, train_loss=0.684, val_MAE=0.662, val_loss=0.701]Epoch 14:   1%|▏         | 14/1000 [28:09<32:44:22, 119.54s/it, lr=0.001, test_MAE=0.71, time=120, train_MAE=0.645, train_loss=0.684, val_MAE=0.662, val_loss=0.701]Epoch 14:   1%|▏         | 14/1000 [30:08<32:44:22, 119.54s/it, lr=0.001, test_MAE=0.739, time=119, train_MAE=0.657, train_loss=0.697, val_MAE=0.673, val_loss=0.713]Epoch 14:   2%|▏         | 15/1000 [30:08<32:38:33, 119.30s/it, lr=0.001, test_MAE=0.739, time=119, train_MAE=0.657, train_loss=0.697, val_MAE=0.673, val_loss=0.713]Epoch 15:   2%|▏         | 15/1000 [30:08<32:38:33, 119.30s/it, lr=0.001, test_MAE=0.739, time=119, train_MAE=0.657, train_loss=0.697, val_MAE=0.673, val_loss=0.713]Epoch 15:   2%|▏         | 15/1000 [32:06<32:38:33, 119.30s/it, lr=0.001, test_MAE=0.707, time=118, train_MAE=0.638, train_loss=0.678, val_MAE=0.663, val_loss=0.704]Epoch 15:   2%|▏         | 16/1000 [32:06<32:31:58, 119.02s/it, lr=0.001, test_MAE=0.707, time=118, train_MAE=0.638, train_loss=0.678, val_MAE=0.663, val_loss=0.704]Epoch 16:   2%|▏         | 16/1000 [32:06<32:31:58, 119.02s/it, lr=0.001, test_MAE=0.707, time=118, train_MAE=0.638, train_loss=0.678, val_MAE=0.663, val_loss=0.704]Epoch 16:   2%|▏         | 16/1000 [34:05<32:31:58, 119.02s/it, lr=0.001, test_MAE=0.724, time=118, train_MAE=0.644, train_loss=0.685, val_MAE=0.686, val_loss=0.727]Epoch 16:   2%|▏         | 17/1000 [34:05<32:26:20, 118.80s/it, lr=0.001, test_MAE=0.724, time=118, train_MAE=0.644, train_loss=0.685, val_MAE=0.686, val_loss=0.727]Epoch 17:   2%|▏         | 17/1000 [34:05<32:26:20, 118.80s/it, lr=0.001, test_MAE=0.724, time=118, train_MAE=0.644, train_loss=0.685, val_MAE=0.686, val_loss=0.727]Epoch 17:   2%|▏         | 17/1000 [36:04<32:26:20, 118.80s/it, lr=0.001, test_MAE=0.851, time=119, train_MAE=0.636, train_loss=0.677, val_MAE=0.822, val_loss=0.863]Epoch 17:   2%|▏         | 18/1000 [36:04<32:25:24, 118.86s/it, lr=0.001, test_MAE=0.851, time=119, train_MAE=0.636, train_loss=0.677, val_MAE=0.822, val_loss=0.863]Epoch 18:   2%|▏         | 18/1000 [36:04<32:25:24, 118.86s/it, lr=0.001, test_MAE=0.851, time=119, train_MAE=0.636, train_loss=0.677, val_MAE=0.822, val_loss=0.863]Epoch 18:   2%|▏         | 18/1000 [38:02<32:25:24, 118.86s/it, lr=0.001, test_MAE=0.723, time=118, train_MAE=0.637, train_loss=0.678, val_MAE=0.674, val_loss=0.715]Epoch 18:   2%|▏         | 19/1000 [38:02<32:20:52, 118.71s/it, lr=0.001, test_MAE=0.723, time=118, train_MAE=0.637, train_loss=0.678, val_MAE=0.674, val_loss=0.715]Epoch 19:   2%|▏         | 19/1000 [38:02<32:20:52, 118.71s/it, lr=0.001, test_MAE=0.723, time=118, train_MAE=0.637, train_loss=0.678, val_MAE=0.674, val_loss=0.715]Epoch 19:   2%|▏         | 19/1000 [40:01<32:20:52, 118.71s/it, lr=0.001, test_MAE=0.84, time=119, train_MAE=0.64, train_loss=0.682, val_MAE=0.784, val_loss=0.825]  Epoch    20: reducing learning rate of group 0 to 5.0000e-04.
Epoch 19:   2%|▏         | 20/1000 [40:01<32:19:07, 118.72s/it, lr=0.001, test_MAE=0.84, time=119, train_MAE=0.64, train_loss=0.682, val_MAE=0.784, val_loss=0.825]Epoch 20:   2%|▏         | 20/1000 [40:01<32:19:07, 118.72s/it, lr=0.001, test_MAE=0.84, time=119, train_MAE=0.64, train_loss=0.682, val_MAE=0.784, val_loss=0.825]Epoch 20:   2%|▏         | 20/1000 [42:00<32:19:07, 118.72s/it, lr=0.0005, test_MAE=0.724, time=119, train_MAE=0.647, train_loss=0.689, val_MAE=0.67, val_loss=0.712]Epoch 20:   2%|▏         | 21/1000 [42:00<32:20:18, 118.92s/it, lr=0.0005, test_MAE=0.724, time=119, train_MAE=0.647, train_loss=0.689, val_MAE=0.67, val_loss=0.712]Epoch 21:   2%|▏         | 21/1000 [42:00<32:20:18, 118.92s/it, lr=0.0005, test_MAE=0.724, time=119, train_MAE=0.647, train_loss=0.689, val_MAE=0.67, val_loss=0.712]Epoch 21:   2%|▏         | 21/1000 [44:00<32:20:18, 118.92s/it, lr=0.0005, test_MAE=0.711, time=120, train_MAE=0.624, train_loss=0.665, val_MAE=0.665, val_loss=0.707]Epoch 21:   2%|▏         | 22/1000 [44:00<32:23:21, 119.22s/it, lr=0.0005, test_MAE=0.711, time=120, train_MAE=0.624, train_loss=0.665, val_MAE=0.665, val_loss=0.707]Epoch 22:   2%|▏         | 22/1000 [44:00<32:23:21, 119.22s/it, lr=0.0005, test_MAE=0.711, time=120, train_MAE=0.624, train_loss=0.665, val_MAE=0.665, val_loss=0.707]Epoch 22:   2%|▏         | 22/1000 [45:58<32:23:21, 119.22s/it, lr=0.0005, test_MAE=0.691, time=118, train_MAE=0.621, train_loss=0.662, val_MAE=0.641, val_loss=0.682]Epoch 22:   2%|▏         | 23/1000 [45:58<32:15:32, 118.87s/it, lr=0.0005, test_MAE=0.691, time=118, train_MAE=0.621, train_loss=0.662, val_MAE=0.641, val_loss=0.682]Epoch 23:   2%|▏         | 23/1000 [45:58<32:15:32, 118.87s/it, lr=0.0005, test_MAE=0.691, time=118, train_MAE=0.621, train_loss=0.662, val_MAE=0.641, val_loss=0.682]Epoch 23:   2%|▏         | 23/1000 [47:55<32:15:32, 118.87s/it, lr=0.0005, test_MAE=0.716, time=117, train_MAE=0.621, train_loss=0.662, val_MAE=0.675, val_loss=0.717]Epoch 23:   2%|▏         | 24/1000 [47:55<32:02:18, 118.17s/it, lr=0.0005, test_MAE=0.716, time=117, train_MAE=0.621, train_loss=0.662, val_MAE=0.675, val_loss=0.717]Epoch 24:   2%|▏         | 24/1000 [47:55<32:02:18, 118.17s/it, lr=0.0005, test_MAE=0.716, time=117, train_MAE=0.621, train_loss=0.662, val_MAE=0.675, val_loss=0.717]Epoch 24:   2%|▏         | 24/1000 [49:50<32:02:18, 118.17s/it, lr=0.0005, test_MAE=0.712, time=115, train_MAE=0.624, train_loss=0.666, val_MAE=0.672, val_loss=0.713]Epoch 24:   2%|▎         | 25/1000 [49:50<31:45:38, 117.27s/it, lr=0.0005, test_MAE=0.712, time=115, train_MAE=0.624, train_loss=0.666, val_MAE=0.672, val_loss=0.713]Epoch 25:   2%|▎         | 25/1000 [49:50<31:45:38, 117.27s/it, lr=0.0005, test_MAE=0.712, time=115, train_MAE=0.624, train_loss=0.666, val_MAE=0.672, val_loss=0.713]Epoch 25:   2%|▎         | 25/1000 [51:46<31:45:38, 117.27s/it, lr=0.0005, test_MAE=0.693, time=116, train_MAE=0.617, train_loss=0.659, val_MAE=0.652, val_loss=0.694]Epoch 25:   3%|▎         | 26/1000 [51:46<31:37:01, 116.86s/it, lr=0.0005, test_MAE=0.693, time=116, train_MAE=0.617, train_loss=0.659, val_MAE=0.652, val_loss=0.694]Epoch 26:   3%|▎         | 26/1000 [51:46<31:37:01, 116.86s/it, lr=0.0005, test_MAE=0.693, time=116, train_MAE=0.617, train_loss=0.659, val_MAE=0.652, val_loss=0.694]Epoch 26:   3%|▎         | 26/1000 [53:41<31:37:01, 116.86s/it, lr=0.0005, test_MAE=0.682, time=115, train_MAE=0.619, train_loss=0.66, val_MAE=0.639, val_loss=0.68]  Epoch 26:   3%|▎         | 27/1000 [53:41<31:27:49, 116.41s/it, lr=0.0005, test_MAE=0.682, time=115, train_MAE=0.619, train_loss=0.66, val_MAE=0.639, val_loss=0.68]Epoch 27:   3%|▎         | 27/1000 [53:41<31:27:49, 116.41s/it, lr=0.0005, test_MAE=0.682, time=115, train_MAE=0.619, train_loss=0.66, val_MAE=0.639, val_loss=0.68]Epoch 27:   3%|▎         | 27/1000 [55:37<31:27:49, 116.41s/it, lr=0.0005, test_MAE=0.749, time=116, train_MAE=0.616, train_loss=0.658, val_MAE=0.681, val_loss=0.722]Epoch 27:   3%|▎         | 28/1000 [55:37<31:22:28, 116.20s/it, lr=0.0005, test_MAE=0.749, time=116, train_MAE=0.616, train_loss=0.658, val_MAE=0.681, val_loss=0.722]Epoch 28:   3%|▎         | 28/1000 [55:37<31:22:28, 116.20s/it, lr=0.0005, test_MAE=0.749, time=116, train_MAE=0.616, train_loss=0.658, val_MAE=0.681, val_loss=0.722]Epoch 28:   3%|▎         | 28/1000 [57:32<31:22:28, 116.20s/it, lr=0.0005, test_MAE=0.726, time=115, train_MAE=0.617, train_loss=0.658, val_MAE=0.67, val_loss=0.712] Epoch 28:   3%|▎         | 29/1000 [57:32<31:15:40, 115.90s/it, lr=0.0005, test_MAE=0.726, time=115, train_MAE=0.617, train_loss=0.658, val_MAE=0.67, val_loss=0.712]Epoch 29:   3%|▎         | 29/1000 [57:32<31:15:40, 115.90s/it, lr=0.0005, test_MAE=0.726, time=115, train_MAE=0.617, train_loss=0.658, val_MAE=0.67, val_loss=0.712]Epoch 29:   3%|▎         | 29/1000 [59:27<31:15:40, 115.90s/it, lr=0.0005, test_MAE=0.684, time=115, train_MAE=0.627, train_loss=0.668, val_MAE=0.644, val_loss=0.686]Epoch 29:   3%|▎         | 30/1000 [59:27<31:10:35, 115.71s/it, lr=0.0005, test_MAE=0.684, time=115, train_MAE=0.627, train_loss=0.668, val_MAE=0.644, val_loss=0.686]Epoch 30:   3%|▎         | 30/1000 [59:27<31:10:35, 115.71s/it, lr=0.0005, test_MAE=0.684, time=115, train_MAE=0.627, train_loss=0.668, val_MAE=0.644, val_loss=0.686]Epoch 30:   3%|▎         | 30/1000 [1:01:23<31:10:35, 115.71s/it, lr=0.0005, test_MAE=0.692, time=116, train_MAE=0.613, train_loss=0.654, val_MAE=0.64, val_loss=0.682]Epoch 30:   3%|▎         | 31/1000 [1:01:23<31:07:48, 115.65s/it, lr=0.0005, test_MAE=0.692, time=116, train_MAE=0.613, train_loss=0.654, val_MAE=0.64, val_loss=0.682]Epoch 31:   3%|▎         | 31/1000 [1:01:23<31:07:48, 115.65s/it, lr=0.0005, test_MAE=0.692, time=116, train_MAE=0.613, train_loss=0.654, val_MAE=0.64, val_loss=0.682]Epoch 31:   3%|▎         | 31/1000 [1:03:18<31:07:48, 115.65s/it, lr=0.0005, test_MAE=0.71, time=116, train_MAE=0.614, train_loss=0.656, val_MAE=0.68, val_loss=0.721] Epoch 31:   3%|▎         | 32/1000 [1:03:18<31:05:28, 115.63s/it, lr=0.0005, test_MAE=0.71, time=116, train_MAE=0.614, train_loss=0.656, val_MAE=0.68, val_loss=0.721]Epoch 32:   3%|▎         | 32/1000 [1:03:18<31:05:28, 115.63s/it, lr=0.0005, test_MAE=0.71, time=116, train_MAE=0.614, train_loss=0.656, val_MAE=0.68, val_loss=0.721]Epoch 32:   3%|▎         | 32/1000 [1:05:14<31:05:28, 115.63s/it, lr=0.0005, test_MAE=0.7, time=116, train_MAE=0.626, train_loss=0.668, val_MAE=0.662, val_loss=0.703]Epoch    33: reducing learning rate of group 0 to 2.5000e-04.
Epoch 32:   3%|▎         | 33/1000 [1:05:14<31:03:02, 115.60s/it, lr=0.0005, test_MAE=0.7, time=116, train_MAE=0.626, train_loss=0.668, val_MAE=0.662, val_loss=0.703]Epoch 33:   3%|▎         | 33/1000 [1:05:14<31:03:02, 115.60s/it, lr=0.0005, test_MAE=0.7, time=116, train_MAE=0.626, train_loss=0.668, val_MAE=0.662, val_loss=0.703]Epoch 33:   3%|▎         | 33/1000 [1:07:09<31:03:02, 115.60s/it, lr=0.00025, test_MAE=0.714, time=115, train_MAE=0.601, train_loss=0.643, val_MAE=0.68, val_loss=0.722]Epoch 33:   3%|▎         | 34/1000 [1:07:09<30:59:38, 115.51s/it, lr=0.00025, test_MAE=0.714, time=115, train_MAE=0.601, train_loss=0.643, val_MAE=0.68, val_loss=0.722]Epoch 34:   3%|▎         | 34/1000 [1:07:09<30:59:38, 115.51s/it, lr=0.00025, test_MAE=0.714, time=115, train_MAE=0.601, train_loss=0.643, val_MAE=0.68, val_loss=0.722]Epoch 34:   3%|▎         | 34/1000 [1:09:05<30:59:38, 115.51s/it, lr=0.00025, test_MAE=0.688, time=116, train_MAE=0.604, train_loss=0.645, val_MAE=0.664, val_loss=0.706]Epoch 34:   4%|▎         | 35/1000 [1:09:05<30:57:52, 115.52s/it, lr=0.00025, test_MAE=0.688, time=116, train_MAE=0.604, train_loss=0.645, val_MAE=0.664, val_loss=0.706]Epoch 35:   4%|▎         | 35/1000 [1:09:05<30:57:52, 115.52s/it, lr=0.00025, test_MAE=0.688, time=116, train_MAE=0.604, train_loss=0.645, val_MAE=0.664, val_loss=0.706]Epoch 35:   4%|▎         | 35/1000 [1:11:00<30:57:52, 115.52s/it, lr=0.00025, test_MAE=0.763, time=115, train_MAE=0.603, train_loss=0.645, val_MAE=0.641, val_loss=0.683]Epoch 35:   4%|▎         | 36/1000 [1:11:00<30:54:32, 115.43s/it, lr=0.00025, test_MAE=0.763, time=115, train_MAE=0.603, train_loss=0.645, val_MAE=0.641, val_loss=0.683]Epoch 36:   4%|▎         | 36/1000 [1:11:00<30:54:32, 115.43s/it, lr=0.00025, test_MAE=0.763, time=115, train_MAE=0.603, train_loss=0.645, val_MAE=0.641, val_loss=0.683]Epoch 36:   4%|▎         | 36/1000 [1:12:55<30:54:32, 115.43s/it, lr=0.00025, test_MAE=0.704, time=115, train_MAE=0.597, train_loss=0.638, val_MAE=0.657, val_loss=0.698]Epoch 36:   4%|▎         | 37/1000 [1:12:55<30:52:00, 115.39s/it, lr=0.00025, test_MAE=0.704, time=115, train_MAE=0.597, train_loss=0.638, val_MAE=0.657, val_loss=0.698]Epoch 37:   4%|▎         | 37/1000 [1:12:55<30:52:00, 115.39s/it, lr=0.00025, test_MAE=0.704, time=115, train_MAE=0.597, train_loss=0.638, val_MAE=0.657, val_loss=0.698]Epoch 37:   4%|▎         | 37/1000 [1:14:51<30:52:00, 115.39s/it, lr=0.00025, test_MAE=0.696, time=116, train_MAE=0.604, train_loss=0.646, val_MAE=0.649, val_loss=0.69] Epoch 37:   4%|▍         | 38/1000 [1:14:51<30:50:53, 115.44s/it, lr=0.00025, test_MAE=0.696, time=116, train_MAE=0.604, train_loss=0.646, val_MAE=0.649, val_loss=0.69]Epoch 38:   4%|▍         | 38/1000 [1:14:51<30:50:53, 115.44s/it, lr=0.00025, test_MAE=0.696, time=116, train_MAE=0.604, train_loss=0.646, val_MAE=0.649, val_loss=0.69]Epoch 38:   4%|▍         | 38/1000 [1:16:46<30:50:53, 115.44s/it, lr=0.00025, test_MAE=0.709, time=115, train_MAE=0.596, train_loss=0.637, val_MAE=0.666, val_loss=0.707]Epoch    39: reducing learning rate of group 0 to 1.2500e-04.
Epoch 38:   4%|▍         | 39/1000 [1:16:46<30:47:53, 115.37s/it, lr=0.00025, test_MAE=0.709, time=115, train_MAE=0.596, train_loss=0.637, val_MAE=0.666, val_loss=0.707]Epoch 39:   4%|▍         | 39/1000 [1:16:46<30:47:53, 115.37s/it, lr=0.00025, test_MAE=0.709, time=115, train_MAE=0.596, train_loss=0.637, val_MAE=0.666, val_loss=0.707]Epoch 39:   4%|▍         | 39/1000 [1:18:41<30:47:53, 115.37s/it, lr=0.000125, test_MAE=0.684, time=115, train_MAE=0.589, train_loss=0.631, val_MAE=0.643, val_loss=0.684]Epoch 39:   4%|▍         | 40/1000 [1:18:41<30:45:42, 115.36s/it, lr=0.000125, test_MAE=0.684, time=115, train_MAE=0.589, train_loss=0.631, val_MAE=0.643, val_loss=0.684]Epoch 40:   4%|▍         | 40/1000 [1:18:41<30:45:42, 115.36s/it, lr=0.000125, test_MAE=0.684, time=115, train_MAE=0.589, train_loss=0.631, val_MAE=0.643, val_loss=0.684]Epoch 40:   4%|▍         | 40/1000 [1:20:37<30:45:42, 115.36s/it, lr=0.000125, test_MAE=0.693, time=115, train_MAE=0.592, train_loss=0.633, val_MAE=0.65, val_loss=0.691] Epoch 40:   4%|▍         | 41/1000 [1:20:37<30:43:56, 115.37s/it, lr=0.000125, test_MAE=0.693, time=115, train_MAE=0.592, train_loss=0.633, val_MAE=0.65, val_loss=0.691]Epoch 41:   4%|▍         | 41/1000 [1:20:37<30:43:56, 115.37s/it, lr=0.000125, test_MAE=0.693, time=115, train_MAE=0.592, train_loss=0.633, val_MAE=0.65, val_loss=0.691]Epoch 41:   4%|▍         | 41/1000 [1:22:32<30:43:56, 115.37s/it, lr=0.000125, test_MAE=0.689, time=116, train_MAE=0.592, train_loss=0.633, val_MAE=0.643, val_loss=0.684]Epoch 41:   4%|▍         | 42/1000 [1:22:32<30:43:37, 115.47s/it, lr=0.000125, test_MAE=0.689, time=116, train_MAE=0.592, train_loss=0.633, val_MAE=0.643, val_loss=0.684]Epoch 42:   4%|▍         | 42/1000 [1:22:32<30:43:37, 115.47s/it, lr=0.000125, test_MAE=0.689, time=116, train_MAE=0.592, train_loss=0.633, val_MAE=0.643, val_loss=0.684]Epoch 42:   4%|▍         | 42/1000 [1:24:28<30:43:37, 115.47s/it, lr=0.000125, test_MAE=0.69, time=115, train_MAE=0.591, train_loss=0.633, val_MAE=0.648, val_loss=0.689] Epoch 42:   4%|▍         | 43/1000 [1:24:28<30:41:03, 115.43s/it, lr=0.000125, test_MAE=0.69, time=115, train_MAE=0.591, train_loss=0.633, val_MAE=0.648, val_loss=0.689]Epoch 43:   4%|▍         | 43/1000 [1:24:28<30:41:03, 115.43s/it, lr=0.000125, test_MAE=0.69, time=115, train_MAE=0.591, train_loss=0.633, val_MAE=0.648, val_loss=0.689]Epoch 43:   4%|▍         | 43/1000 [1:26:25<30:41:03, 115.43s/it, lr=0.000125, test_MAE=0.688, time=117, train_MAE=0.589, train_loss=0.63, val_MAE=0.639, val_loss=0.68] Epoch 43:   4%|▍         | 44/1000 [1:26:25<30:47:34, 115.96s/it, lr=0.000125, test_MAE=0.688, time=117, train_MAE=0.589, train_loss=0.63, val_MAE=0.639, val_loss=0.68]Epoch 44:   4%|▍         | 44/1000 [1:26:25<30:47:34, 115.96s/it, lr=0.000125, test_MAE=0.688, time=117, train_MAE=0.589, train_loss=0.63, val_MAE=0.639, val_loss=0.68]Epoch 44:   4%|▍         | 44/1000 [1:28:23<30:47:34, 115.96s/it, lr=0.000125, test_MAE=0.692, time=119, train_MAE=0.595, train_loss=0.636, val_MAE=0.651, val_loss=0.692]Epoch    45: reducing learning rate of group 0 to 6.2500e-05.
Epoch 44:   4%|▍         | 45/1000 [1:28:23<30:58:11, 116.74s/it, lr=0.000125, test_MAE=0.692, time=119, train_MAE=0.595, train_loss=0.636, val_MAE=0.651, val_loss=0.692]Epoch 45:   4%|▍         | 45/1000 [1:28:23<30:58:11, 116.74s/it, lr=0.000125, test_MAE=0.692, time=119, train_MAE=0.595, train_loss=0.636, val_MAE=0.651, val_loss=0.692]Epoch 45:   4%|▍         | 45/1000 [1:30:22<30:58:11, 116.74s/it, lr=6.25e-5, test_MAE=0.698, time=118, train_MAE=0.59, train_loss=0.631, val_MAE=0.649, val_loss=0.69]   Epoch 45:   5%|▍         | 46/1000 [1:30:22<31:03:54, 117.23s/it, lr=6.25e-5, test_MAE=0.698, time=118, train_MAE=0.59, train_loss=0.631, val_MAE=0.649, val_loss=0.69]Epoch 46:   5%|▍         | 46/1000 [1:30:22<31:03:54, 117.23s/it, lr=6.25e-5, test_MAE=0.698, time=118, train_MAE=0.59, train_loss=0.631, val_MAE=0.649, val_loss=0.69]Epoch 46:   5%|▍         | 46/1000 [1:32:20<31:03:54, 117.23s/it, lr=6.25e-5, test_MAE=0.686, time=118, train_MAE=0.579, train_loss=0.62, val_MAE=0.642, val_loss=0.683]Epoch 46:   5%|▍         | 47/1000 [1:32:20<31:07:44, 117.59s/it, lr=6.25e-5, test_MAE=0.686, time=118, train_MAE=0.579, train_loss=0.62, val_MAE=0.642, val_loss=0.683]Epoch 47:   5%|▍         | 47/1000 [1:32:20<31:07:44, 117.59s/it, lr=6.25e-5, test_MAE=0.686, time=118, train_MAE=0.579, train_loss=0.62, val_MAE=0.642, val_loss=0.683]Epoch 47:   5%|▍         | 47/1000 [1:34:20<31:07:44, 117.59s/it, lr=6.25e-5, test_MAE=0.684, time=119, train_MAE=0.578, train_loss=0.619, val_MAE=0.642, val_loss=0.683]Epoch 47:   5%|▍         | 48/1000 [1:34:20<31:14:17, 118.13s/it, lr=6.25e-5, test_MAE=0.684, time=119, train_MAE=0.578, train_loss=0.619, val_MAE=0.642, val_loss=0.683]Epoch 48:   5%|▍         | 48/1000 [1:34:20<31:14:17, 118.13s/it, lr=6.25e-5, test_MAE=0.684, time=119, train_MAE=0.578, train_loss=0.619, val_MAE=0.642, val_loss=0.683]Epoch 48:   5%|▍         | 48/1000 [1:36:19<31:14:17, 118.13s/it, lr=6.25e-5, test_MAE=0.689, time=120, train_MAE=0.58, train_loss=0.621, val_MAE=0.648, val_loss=0.689] Epoch 48:   5%|▍         | 49/1000 [1:36:19<31:19:23, 118.57s/it, lr=6.25e-5, test_MAE=0.689, time=120, train_MAE=0.58, train_loss=0.621, val_MAE=0.648, val_loss=0.689]Epoch 49:   5%|▍         | 49/1000 [1:36:19<31:19:23, 118.57s/it, lr=6.25e-5, test_MAE=0.689, time=120, train_MAE=0.58, train_loss=0.621, val_MAE=0.648, val_loss=0.689]Epoch 49:   5%|▍         | 49/1000 [1:38:18<31:19:23, 118.57s/it, lr=6.25e-5, test_MAE=0.704, time=119, train_MAE=0.575, train_loss=0.616, val_MAE=0.658, val_loss=0.699]Epoch 49:   5%|▌         | 50/1000 [1:38:18<31:20:27, 118.77s/it, lr=6.25e-5, test_MAE=0.704, time=119, train_MAE=0.575, train_loss=0.616, val_MAE=0.658, val_loss=0.699]Epoch 50:   5%|▌         | 50/1000 [1:38:18<31:20:27, 118.77s/it, lr=6.25e-5, test_MAE=0.704, time=119, train_MAE=0.575, train_loss=0.616, val_MAE=0.658, val_loss=0.699]Epoch 50:   5%|▌         | 50/1000 [1:40:17<31:20:27, 118.77s/it, lr=6.25e-5, test_MAE=0.686, time=119, train_MAE=0.581, train_loss=0.622, val_MAE=0.642, val_loss=0.683]Epoch    51: reducing learning rate of group 0 to 3.1250e-05.
Epoch 50:   5%|▌         | 51/1000 [1:40:17<31:17:40, 118.72s/it, lr=6.25e-5, test_MAE=0.686, time=119, train_MAE=0.581, train_loss=0.622, val_MAE=0.642, val_loss=0.683]Epoch 51:   5%|▌         | 51/1000 [1:40:17<31:17:40, 118.72s/it, lr=6.25e-5, test_MAE=0.686, time=119, train_MAE=0.581, train_loss=0.622, val_MAE=0.642, val_loss=0.683]Epoch 51:   5%|▌         | 51/1000 [1:42:16<31:17:40, 118.72s/it, lr=3.13e-5, test_MAE=0.696, time=119, train_MAE=0.571, train_loss=0.612, val_MAE=0.653, val_loss=0.693]Epoch 51:   5%|▌         | 52/1000 [1:42:16<31:17:07, 118.81s/it, lr=3.13e-5, test_MAE=0.696, time=119, train_MAE=0.571, train_loss=0.612, val_MAE=0.653, val_loss=0.693]Epoch 52:   5%|▌         | 52/1000 [1:42:16<31:17:07, 118.81s/it, lr=3.13e-5, test_MAE=0.696, time=119, train_MAE=0.571, train_loss=0.612, val_MAE=0.653, val_loss=0.693]Epoch 52:   5%|▌         | 52/1000 [1:44:15<31:17:07, 118.81s/it, lr=3.13e-5, test_MAE=0.689, time=119, train_MAE=0.573, train_loss=0.614, val_MAE=0.644, val_loss=0.685]Epoch 52:   5%|▌         | 53/1000 [1:44:15<31:16:15, 118.88s/it, lr=3.13e-5, test_MAE=0.689, time=119, train_MAE=0.573, train_loss=0.614, val_MAE=0.644, val_loss=0.685]Epoch 53:   5%|▌         | 53/1000 [1:44:15<31:16:15, 118.88s/it, lr=3.13e-5, test_MAE=0.689, time=119, train_MAE=0.573, train_loss=0.614, val_MAE=0.644, val_loss=0.685]Epoch 53:   5%|▌         | 53/1000 [1:46:42<31:16:15, 118.88s/it, lr=3.13e-5, test_MAE=0.715, time=147, train_MAE=0.576, train_loss=0.617, val_MAE=0.654, val_loss=0.695]Epoch 53:   5%|▌         | 54/1000 [1:46:42<33:25:01, 127.17s/it, lr=3.13e-5, test_MAE=0.715, time=147, train_MAE=0.576, train_loss=0.617, val_MAE=0.654, val_loss=0.695]Epoch 54:   5%|▌         | 54/1000 [1:46:42<33:25:01, 127.17s/it, lr=3.13e-5, test_MAE=0.715, time=147, train_MAE=0.576, train_loss=0.617, val_MAE=0.654, val_loss=0.695]Epoch 54:   5%|▌         | 54/1000 [1:49:23<33:25:01, 127.17s/it, lr=3.13e-5, test_MAE=0.702, time=161, train_MAE=0.574, train_loss=0.615, val_MAE=0.643, val_loss=0.684]Epoch 54:   6%|▌         | 55/1000 [1:49:23<36:03:52, 137.39s/it, lr=3.13e-5, test_MAE=0.702, time=161, train_MAE=0.574, train_loss=0.615, val_MAE=0.643, val_loss=0.684]Epoch 55:   6%|▌         | 55/1000 [1:49:23<36:03:52, 137.39s/it, lr=3.13e-5, test_MAE=0.702, time=161, train_MAE=0.574, train_loss=0.615, val_MAE=0.643, val_loss=0.684]Epoch 55:   6%|▌         | 55/1000 [1:52:04<36:03:52, 137.39s/it, lr=3.13e-5, test_MAE=0.692, time=161, train_MAE=0.581, train_loss=0.622, val_MAE=0.648, val_loss=0.689]Epoch 55:   6%|▌         | 56/1000 [1:52:04<37:54:49, 144.59s/it, lr=3.13e-5, test_MAE=0.692, time=161, train_MAE=0.581, train_loss=0.622, val_MAE=0.648, val_loss=0.689]Epoch 56:   6%|▌         | 56/1000 [1:52:04<37:54:49, 144.59s/it, lr=3.13e-5, test_MAE=0.692, time=161, train_MAE=0.581, train_loss=0.622, val_MAE=0.648, val_loss=0.689]Epoch 56:   6%|▌         | 56/1000 [1:54:45<37:54:49, 144.59s/it, lr=3.13e-5, test_MAE=0.688, time=160, train_MAE=0.571, train_loss=0.612, val_MAE=0.645, val_loss=0.686]Epoch    57: reducing learning rate of group 0 to 1.5625e-05.
Epoch 56:   6%|▌         | 57/1000 [1:54:45<39:06:31, 149.30s/it, lr=3.13e-5, test_MAE=0.688, time=160, train_MAE=0.571, train_loss=0.612, val_MAE=0.645, val_loss=0.686]Epoch 57:   6%|▌         | 57/1000 [1:54:45<39:06:31, 149.30s/it, lr=3.13e-5, test_MAE=0.688, time=160, train_MAE=0.571, train_loss=0.612, val_MAE=0.645, val_loss=0.686]Epoch 57:   6%|▌         | 57/1000 [1:57:25<39:06:31, 149.30s/it, lr=1.56e-5, test_MAE=0.68, time=160, train_MAE=0.571, train_loss=0.611, val_MAE=0.641, val_loss=0.682] Epoch 57:   6%|▌         | 58/1000 [1:57:25<39:56:29, 152.64s/it, lr=1.56e-5, test_MAE=0.68, time=160, train_MAE=0.571, train_loss=0.611, val_MAE=0.641, val_loss=0.682]Epoch 58:   6%|▌         | 58/1000 [1:57:25<39:56:29, 152.64s/it, lr=1.56e-5, test_MAE=0.68, time=160, train_MAE=0.571, train_loss=0.611, val_MAE=0.641, val_loss=0.682]Epoch 58:   6%|▌         | 58/1000 [2:00:07<39:56:29, 152.64s/it, lr=1.56e-5, test_MAE=0.688, time=162, train_MAE=0.568, train_loss=0.609, val_MAE=0.644, val_loss=0.685]Epoch 58:   6%|▌         | 59/1000 [2:00:07<40:36:43, 155.37s/it, lr=1.56e-5, test_MAE=0.688, time=162, train_MAE=0.568, train_loss=0.609, val_MAE=0.644, val_loss=0.685]Epoch 59:   6%|▌         | 59/1000 [2:00:07<40:36:43, 155.37s/it, lr=1.56e-5, test_MAE=0.688, time=162, train_MAE=0.568, train_loss=0.609, val_MAE=0.644, val_loss=0.685]Epoch 59:   6%|▌         | 59/1000 [2:02:47<40:36:43, 155.37s/it, lr=1.56e-5, test_MAE=0.695, time=160, train_MAE=0.57, train_loss=0.61, val_MAE=0.644, val_loss=0.684]  Epoch 59:   6%|▌         | 60/1000 [2:02:47<40:56:33, 156.80s/it, lr=1.56e-5, test_MAE=0.695, time=160, train_MAE=0.57, train_loss=0.61, val_MAE=0.644, val_loss=0.684]Epoch 60:   6%|▌         | 60/1000 [2:02:47<40:56:33, 156.80s/it, lr=1.56e-5, test_MAE=0.695, time=160, train_MAE=0.57, train_loss=0.61, val_MAE=0.644, val_loss=0.684]Epoch 60:   6%|▌         | 60/1000 [2:05:27<40:56:33, 156.80s/it, lr=1.56e-5, test_MAE=0.706, time=161, train_MAE=0.576, train_loss=0.617, val_MAE=0.647, val_loss=0.688]Epoch 60:   6%|▌         | 61/1000 [2:05:27<41:11:28, 157.92s/it, lr=1.56e-5, test_MAE=0.706, time=161, train_MAE=0.576, train_loss=0.617, val_MAE=0.647, val_loss=0.688]Epoch 61:   6%|▌         | 61/1000 [2:05:27<41:11:28, 157.92s/it, lr=1.56e-5, test_MAE=0.706, time=161, train_MAE=0.576, train_loss=0.617, val_MAE=0.647, val_loss=0.688]Epoch 61:   6%|▌         | 61/1000 [2:08:08<41:11:28, 157.92s/it, lr=1.56e-5, test_MAE=0.687, time=161, train_MAE=0.57, train_loss=0.61, val_MAE=0.641, val_loss=0.681]  Epoch 61:   6%|▌         | 62/1000 [2:08:08<41:21:39, 158.74s/it, lr=1.56e-5, test_MAE=0.687, time=161, train_MAE=0.57, train_loss=0.61, val_MAE=0.641, val_loss=0.681]Epoch 62:   6%|▌         | 62/1000 [2:08:08<41:21:39, 158.74s/it, lr=1.56e-5, test_MAE=0.687, time=161, train_MAE=0.57, train_loss=0.61, val_MAE=0.641, val_loss=0.681]Epoch 62:   6%|▌         | 62/1000 [2:10:50<41:21:39, 158.74s/it, lr=1.56e-5, test_MAE=0.685, time=162, train_MAE=0.574, train_loss=0.615, val_MAE=0.642, val_loss=0.682]Epoch    63: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 62:   6%|▌         | 62/1000 [2:10:50<32:59:36, 126.63s/it, lr=1.56e-5, test_MAE=0.685, time=162, train_MAE=0.574, train_loss=0.615, val_MAE=0.642, val_loss=0.682]
Test MAE: 0.6848
Train MAE: 0.5586
Convergence Time (Epochs): 62.0000
TOTAL TIME TAKEN: 7921.3717s
AVG TIME PER EPOCH: 124.6000s
