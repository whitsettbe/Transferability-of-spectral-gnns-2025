I'm echoing to stdout
I'm echoing to stderr
My JobID is 57931988
I have 8 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.0305s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 6, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'poly_mlp', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_all', 'num_eigs': 16, 'bias_mode': 'spatial', 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 0.0, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/aug07/zinc_train_rec.csv', 'test': 'supp_data/molecules/aug07/zinc_test_rec.csv', 'val': 'supp_data/molecules/aug07/zinc_val_rec.csv'}, 'fixMissingPhi1': False, 'extraOrtho': False, 'doublePrecision': True, 'eigval_hidden_dim': 100, 'eigval_num_hidden_layer': 3, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [01:46<?, ?it/s, lr=0.001, test_MAE=0.949, time=107, train_MAE=1.06, train_loss=1.06, val_MAE=0.898, val_loss=0.898]Epoch 0:   0%|          | 1/1000 [01:46<29:36:52, 106.72s/it, lr=0.001, test_MAE=0.949, time=107, train_MAE=1.06, train_loss=1.06, val_MAE=0.898, val_loss=0.898]Epoch 1:   0%|          | 1/1000 [01:46<29:36:52, 106.72s/it, lr=0.001, test_MAE=0.949, time=107, train_MAE=1.06, train_loss=1.06, val_MAE=0.898, val_loss=0.898]Epoch 1:   0%|          | 1/1000 [03:15<29:36:52, 106.72s/it, lr=0.001, test_MAE=0.723, time=88.3, train_MAE=0.696, train_loss=0.696, val_MAE=0.679, val_loss=0.679]Epoch 1:   0%|          | 2/1000 [03:15<28:03:28, 101.21s/it, lr=0.001, test_MAE=0.723, time=88.3, train_MAE=0.696, train_loss=0.696, val_MAE=0.679, val_loss=0.679]Epoch 2:   0%|          | 2/1000 [03:15<28:03:28, 101.21s/it, lr=0.001, test_MAE=0.723, time=88.3, train_MAE=0.696, train_loss=0.696, val_MAE=0.679, val_loss=0.679]Epoch 2:   0%|          | 2/1000 [04:43<28:03:28, 101.21s/it, lr=0.001, test_MAE=0.7, time=88.4, train_MAE=0.652, train_loss=0.652, val_MAE=0.65, val_loss=0.65]    Epoch 2:   0%|          | 3/1000 [04:43<26:58:12, 97.38s/it, lr=0.001, test_MAE=0.7, time=88.4, train_MAE=0.652, train_loss=0.652, val_MAE=0.65, val_loss=0.65] Epoch 3:   0%|          | 3/1000 [04:43<26:58:12, 97.38s/it, lr=0.001, test_MAE=0.7, time=88.4, train_MAE=0.652, train_loss=0.652, val_MAE=0.65, val_loss=0.65]Epoch 3:   0%|          | 3/1000 [06:12<26:58:12, 97.38s/it, lr=0.001, test_MAE=0.66, time=88.6, train_MAE=0.639, train_loss=0.639, val_MAE=0.621, val_loss=0.621]Epoch 3:   0%|          | 4/1000 [06:12<26:13:04, 94.76s/it, lr=0.001, test_MAE=0.66, time=88.6, train_MAE=0.639, train_loss=0.639, val_MAE=0.621, val_loss=0.621]Epoch 4:   0%|          | 4/1000 [06:12<26:13:04, 94.76s/it, lr=0.001, test_MAE=0.66, time=88.6, train_MAE=0.639, train_loss=0.639, val_MAE=0.621, val_loss=0.621]Epoch 4:   0%|          | 4/1000 [07:40<26:13:04, 94.76s/it, lr=0.001, test_MAE=0.844, time=88.2, train_MAE=0.623, train_loss=0.623, val_MAE=0.811, val_loss=0.811]Epoch 4:   0%|          | 5/1000 [07:40<25:39:11, 92.82s/it, lr=0.001, test_MAE=0.844, time=88.2, train_MAE=0.623, train_loss=0.623, val_MAE=0.811, val_loss=0.811]Epoch 5:   0%|          | 5/1000 [07:40<25:39:11, 92.82s/it, lr=0.001, test_MAE=0.844, time=88.2, train_MAE=0.623, train_loss=0.623, val_MAE=0.811, val_loss=0.811]Epoch 5:   0%|          | 5/1000 [09:09<25:39:11, 92.82s/it, lr=0.001, test_MAE=0.673, time=88.7, train_MAE=0.63, train_loss=0.63, val_MAE=0.625, val_loss=0.625]  Epoch 5:   1%|          | 6/1000 [09:09<25:17:40, 91.61s/it, lr=0.001, test_MAE=0.673, time=88.7, train_MAE=0.63, train_loss=0.63, val_MAE=0.625, val_loss=0.625]Epoch 6:   1%|          | 6/1000 [09:09<25:17:40, 91.61s/it, lr=0.001, test_MAE=0.673, time=88.7, train_MAE=0.63, train_loss=0.63, val_MAE=0.625, val_loss=0.625]Epoch 6:   1%|          | 6/1000 [10:38<25:17:40, 91.61s/it, lr=0.001, test_MAE=0.799, time=89, train_MAE=0.611, train_loss=0.611, val_MAE=0.764, val_loss=0.764]Epoch 6:   1%|          | 7/1000 [10:38<25:03:17, 90.83s/it, lr=0.001, test_MAE=0.799, time=89, train_MAE=0.611, train_loss=0.611, val_MAE=0.764, val_loss=0.764]Epoch 7:   1%|          | 7/1000 [10:38<25:03:17, 90.83s/it, lr=0.001, test_MAE=0.799, time=89, train_MAE=0.611, train_loss=0.611, val_MAE=0.764, val_loss=0.764]Epoch 7:   1%|          | 7/1000 [12:06<25:03:17, 90.83s/it, lr=0.001, test_MAE=0.791, time=88.7, train_MAE=0.617, train_loss=0.617, val_MAE=0.758, val_loss=0.758]Epoch 7:   1%|          | 8/1000 [12:07<24:51:22, 90.20s/it, lr=0.001, test_MAE=0.791, time=88.7, train_MAE=0.617, train_loss=0.617, val_MAE=0.758, val_loss=0.758]Epoch 8:   1%|          | 8/1000 [12:07<24:51:22, 90.20s/it, lr=0.001, test_MAE=0.791, time=88.7, train_MAE=0.617, train_loss=0.617, val_MAE=0.758, val_loss=0.758]Epoch 8:   1%|          | 8/1000 [13:35<24:51:22, 90.20s/it, lr=0.001, test_MAE=0.729, time=89, train_MAE=0.615, train_loss=0.615, val_MAE=0.699, val_loss=0.699]  Epoch 8:   1%|          | 9/1000 [13:36<24:43:55, 89.84s/it, lr=0.001, test_MAE=0.729, time=89, train_MAE=0.615, train_loss=0.615, val_MAE=0.699, val_loss=0.699]Epoch 9:   1%|          | 9/1000 [13:36<24:43:55, 89.84s/it, lr=0.001, test_MAE=0.729, time=89, train_MAE=0.615, train_loss=0.615, val_MAE=0.699, val_loss=0.699]Epoch 9:   1%|          | 9/1000 [15:04<24:43:55, 89.84s/it, lr=0.001, test_MAE=0.638, time=88.9, train_MAE=0.601, train_loss=0.601, val_MAE=0.604, val_loss=0.604]Epoch 9:   1%|          | 10/1000 [15:04<24:37:54, 89.57s/it, lr=0.001, test_MAE=0.638, time=88.9, train_MAE=0.601, train_loss=0.601, val_MAE=0.604, val_loss=0.604]Epoch 10:   1%|          | 10/1000 [15:04<24:37:54, 89.57s/it, lr=0.001, test_MAE=0.638, time=88.9, train_MAE=0.601, train_loss=0.601, val_MAE=0.604, val_loss=0.604]Epoch 10:   1%|          | 10/1000 [16:33<24:37:54, 89.57s/it, lr=0.001, test_MAE=0.872, time=88.6, train_MAE=0.59, train_loss=0.59, val_MAE=0.836, val_loss=0.836]  Epoch 10:   1%|          | 11/1000 [16:33<24:32:00, 89.30s/it, lr=0.001, test_MAE=0.872, time=88.6, train_MAE=0.59, train_loss=0.59, val_MAE=0.836, val_loss=0.836]Epoch 11:   1%|          | 11/1000 [16:33<24:32:00, 89.30s/it, lr=0.001, test_MAE=0.872, time=88.6, train_MAE=0.59, train_loss=0.59, val_MAE=0.836, val_loss=0.836]Epoch 11:   1%|          | 11/1000 [18:01<24:32:00, 89.30s/it, lr=0.001, test_MAE=0.649, time=88.2, train_MAE=0.607, train_loss=0.607, val_MAE=0.616, val_loss=0.616]Epoch 11:   1%|          | 12/1000 [18:01<24:25:06, 88.97s/it, lr=0.001, test_MAE=0.649, time=88.2, train_MAE=0.607, train_loss=0.607, val_MAE=0.616, val_loss=0.616]Epoch 12:   1%|          | 12/1000 [18:01<24:25:06, 88.97s/it, lr=0.001, test_MAE=0.649, time=88.2, train_MAE=0.607, train_loss=0.607, val_MAE=0.616, val_loss=0.616]Epoch 12:   1%|          | 12/1000 [19:30<24:25:06, 88.97s/it, lr=0.001, test_MAE=0.678, time=88.9, train_MAE=0.589, train_loss=0.589, val_MAE=0.658, val_loss=0.658]Epoch 12:   1%|▏         | 13/1000 [19:30<24:23:13, 88.95s/it, lr=0.001, test_MAE=0.678, time=88.9, train_MAE=0.589, train_loss=0.589, val_MAE=0.658, val_loss=0.658]Epoch 13:   1%|▏         | 13/1000 [19:30<24:23:13, 88.95s/it, lr=0.001, test_MAE=0.678, time=88.9, train_MAE=0.589, train_loss=0.589, val_MAE=0.658, val_loss=0.658]Epoch 13:   1%|▏         | 13/1000 [20:59<24:23:13, 88.95s/it, lr=0.001, test_MAE=0.722, time=88.3, train_MAE=0.593, train_loss=0.593, val_MAE=0.661, val_loss=0.661]Epoch 13:   1%|▏         | 14/1000 [20:59<24:18:47, 88.77s/it, lr=0.001, test_MAE=0.722, time=88.3, train_MAE=0.593, train_loss=0.593, val_MAE=0.661, val_loss=0.661]Epoch 14:   1%|▏         | 14/1000 [20:59<24:18:47, 88.77s/it, lr=0.001, test_MAE=0.722, time=88.3, train_MAE=0.593, train_loss=0.593, val_MAE=0.661, val_loss=0.661]Epoch 14:   1%|▏         | 14/1000 [22:27<24:18:47, 88.77s/it, lr=0.001, test_MAE=0.642, time=88.1, train_MAE=0.586, train_loss=0.586, val_MAE=0.605, val_loss=0.605]Epoch 14:   2%|▏         | 15/1000 [22:27<24:14:19, 88.59s/it, lr=0.001, test_MAE=0.642, time=88.1, train_MAE=0.586, train_loss=0.586, val_MAE=0.605, val_loss=0.605]Epoch 15:   2%|▏         | 15/1000 [22:27<24:14:19, 88.59s/it, lr=0.001, test_MAE=0.642, time=88.1, train_MAE=0.586, train_loss=0.586, val_MAE=0.605, val_loss=0.605]Epoch 15:   2%|▏         | 15/1000 [23:56<24:14:19, 88.59s/it, lr=0.001, test_MAE=0.715, time=89, train_MAE=0.584, train_loss=0.584, val_MAE=0.684, val_loss=0.684]  Epoch    16: reducing learning rate of group 0 to 5.0000e-04.
Epoch 15:   2%|▏         | 16/1000 [23:56<24:14:56, 88.72s/it, lr=0.001, test_MAE=0.715, time=89, train_MAE=0.584, train_loss=0.584, val_MAE=0.684, val_loss=0.684]Epoch 16:   2%|▏         | 16/1000 [23:56<24:14:56, 88.72s/it, lr=0.001, test_MAE=0.715, time=89, train_MAE=0.584, train_loss=0.584, val_MAE=0.684, val_loss=0.684]Epoch 16:   2%|▏         | 16/1000 [25:24<24:14:56, 88.72s/it, lr=0.0005, test_MAE=0.679, time=88.6, train_MAE=0.559, train_loss=0.559, val_MAE=0.657, val_loss=0.657]Epoch 16:   2%|▏         | 17/1000 [25:24<24:13:18, 88.71s/it, lr=0.0005, test_MAE=0.679, time=88.6, train_MAE=0.559, train_loss=0.559, val_MAE=0.657, val_loss=0.657]Epoch 17:   2%|▏         | 17/1000 [25:24<24:13:18, 88.71s/it, lr=0.0005, test_MAE=0.679, time=88.6, train_MAE=0.559, train_loss=0.559, val_MAE=0.657, val_loss=0.657]Epoch 17:   2%|▏         | 17/1000 [26:53<24:13:18, 88.71s/it, lr=0.0005, test_MAE=0.628, time=88.3, train_MAE=0.56, train_loss=0.56, val_MAE=0.6, val_loss=0.6]      Epoch 17:   2%|▏         | 18/1000 [26:53<24:09:58, 88.59s/it, lr=0.0005, test_MAE=0.628, time=88.3, train_MAE=0.56, train_loss=0.56, val_MAE=0.6, val_loss=0.6]Epoch 18:   2%|▏         | 18/1000 [26:53<24:09:58, 88.59s/it, lr=0.0005, test_MAE=0.628, time=88.3, train_MAE=0.56, train_loss=0.56, val_MAE=0.6, val_loss=0.6]Epoch 18:   2%|▏         | 18/1000 [28:21<24:09:58, 88.59s/it, lr=0.0005, test_MAE=0.63, time=88.6, train_MAE=0.549, train_loss=0.549, val_MAE=0.598, val_loss=0.598]Epoch 18:   2%|▏         | 19/1000 [28:21<24:08:40, 88.60s/it, lr=0.0005, test_MAE=0.63, time=88.6, train_MAE=0.549, train_loss=0.549, val_MAE=0.598, val_loss=0.598]Epoch 19:   2%|▏         | 19/1000 [28:21<24:08:40, 88.60s/it, lr=0.0005, test_MAE=0.63, time=88.6, train_MAE=0.549, train_loss=0.549, val_MAE=0.598, val_loss=0.598]Epoch 19:   2%|▏         | 19/1000 [29:50<24:08:40, 88.60s/it, lr=0.0005, test_MAE=0.646, time=89, train_MAE=0.555, train_loss=0.555, val_MAE=0.614, val_loss=0.614] Epoch 19:   2%|▏         | 20/1000 [29:50<24:09:03, 88.72s/it, lr=0.0005, test_MAE=0.646, time=89, train_MAE=0.555, train_loss=0.555, val_MAE=0.614, val_loss=0.614]Epoch 20:   2%|▏         | 20/1000 [29:50<24:09:03, 88.72s/it, lr=0.0005, test_MAE=0.646, time=89, train_MAE=0.555, train_loss=0.555, val_MAE=0.614, val_loss=0.614]Epoch 20:   2%|▏         | 20/1000 [31:19<24:09:03, 88.72s/it, lr=0.0005, test_MAE=0.634, time=88.5, train_MAE=0.547, train_loss=0.547, val_MAE=0.604, val_loss=0.604]Epoch 20:   2%|▏         | 21/1000 [31:19<24:06:51, 88.67s/it, lr=0.0005, test_MAE=0.634, time=88.5, train_MAE=0.547, train_loss=0.547, val_MAE=0.604, val_loss=0.604]Epoch 21:   2%|▏         | 21/1000 [31:19<24:06:51, 88.67s/it, lr=0.0005, test_MAE=0.634, time=88.5, train_MAE=0.547, train_loss=0.547, val_MAE=0.604, val_loss=0.604]Epoch 21:   2%|▏         | 21/1000 [32:48<24:06:51, 88.67s/it, lr=0.0005, test_MAE=0.648, time=88.9, train_MAE=0.554, train_loss=0.554, val_MAE=0.611, val_loss=0.611]Epoch 21:   2%|▏         | 22/1000 [32:48<24:06:33, 88.75s/it, lr=0.0005, test_MAE=0.648, time=88.9, train_MAE=0.554, train_loss=0.554, val_MAE=0.611, val_loss=0.611]Epoch 22:   2%|▏         | 22/1000 [32:48<24:06:33, 88.75s/it, lr=0.0005, test_MAE=0.648, time=88.9, train_MAE=0.554, train_loss=0.554, val_MAE=0.611, val_loss=0.611]Epoch 22:   2%|▏         | 22/1000 [34:16<24:06:33, 88.75s/it, lr=0.0005, test_MAE=0.637, time=88.3, train_MAE=0.542, train_loss=0.542, val_MAE=0.595, val_loss=0.595]Epoch 22:   2%|▏         | 23/1000 [34:16<24:03:06, 88.62s/it, lr=0.0005, test_MAE=0.637, time=88.3, train_MAE=0.542, train_loss=0.542, val_MAE=0.595, val_loss=0.595]Epoch 23:   2%|▏         | 23/1000 [34:16<24:03:06, 88.62s/it, lr=0.0005, test_MAE=0.637, time=88.3, train_MAE=0.542, train_loss=0.542, val_MAE=0.595, val_loss=0.595]Epoch 23:   2%|▏         | 23/1000 [35:45<24:03:06, 88.62s/it, lr=0.0005, test_MAE=0.625, time=88.9, train_MAE=0.538, train_loss=0.538, val_MAE=0.603, val_loss=0.603]Epoch 23:   2%|▏         | 24/1000 [35:45<24:03:14, 88.72s/it, lr=0.0005, test_MAE=0.625, time=88.9, train_MAE=0.538, train_loss=0.538, val_MAE=0.603, val_loss=0.603]Epoch 24:   2%|▏         | 24/1000 [35:45<24:03:14, 88.72s/it, lr=0.0005, test_MAE=0.625, time=88.9, train_MAE=0.538, train_loss=0.538, val_MAE=0.603, val_loss=0.603]Epoch 24:   2%|▏         | 24/1000 [37:14<24:03:14, 88.72s/it, lr=0.0005, test_MAE=0.751, time=88.6, train_MAE=0.54, train_loss=0.54, val_MAE=0.715, val_loss=0.715]  Epoch 24:   2%|▎         | 25/1000 [37:14<24:01:21, 88.70s/it, lr=0.0005, test_MAE=0.751, time=88.6, train_MAE=0.54, train_loss=0.54, val_MAE=0.715, val_loss=0.715]Epoch 25:   2%|▎         | 25/1000 [37:14<24:01:21, 88.70s/it, lr=0.0005, test_MAE=0.751, time=88.6, train_MAE=0.54, train_loss=0.54, val_MAE=0.715, val_loss=0.715]Epoch 25:   2%|▎         | 25/1000 [38:42<24:01:21, 88.70s/it, lr=0.0005, test_MAE=0.605, time=88.4, train_MAE=0.539, train_loss=0.539, val_MAE=0.578, val_loss=0.578]Epoch 25:   3%|▎         | 26/1000 [38:42<23:58:20, 88.60s/it, lr=0.0005, test_MAE=0.605, time=88.4, train_MAE=0.539, train_loss=0.539, val_MAE=0.578, val_loss=0.578]Epoch 26:   3%|▎         | 26/1000 [38:42<23:58:20, 88.60s/it, lr=0.0005, test_MAE=0.605, time=88.4, train_MAE=0.539, train_loss=0.539, val_MAE=0.578, val_loss=0.578]Epoch 26:   3%|▎         | 26/1000 [40:11<23:58:20, 88.60s/it, lr=0.0005, test_MAE=0.637, time=88.8, train_MAE=0.535, train_loss=0.535, val_MAE=0.609, val_loss=0.609]Epoch 26:   3%|▎         | 27/1000 [40:11<23:58:01, 88.68s/it, lr=0.0005, test_MAE=0.637, time=88.8, train_MAE=0.535, train_loss=0.535, val_MAE=0.609, val_loss=0.609]Epoch 27:   3%|▎         | 27/1000 [40:11<23:58:01, 88.68s/it, lr=0.0005, test_MAE=0.637, time=88.8, train_MAE=0.535, train_loss=0.535, val_MAE=0.609, val_loss=0.609]Epoch 27:   3%|▎         | 27/1000 [41:40<23:58:01, 88.68s/it, lr=0.0005, test_MAE=0.7, time=88.6, train_MAE=0.537, train_loss=0.537, val_MAE=0.669, val_loss=0.669]  Epoch 27:   3%|▎         | 28/1000 [41:40<23:56:05, 88.65s/it, lr=0.0005, test_MAE=0.7, time=88.6, train_MAE=0.537, train_loss=0.537, val_MAE=0.669, val_loss=0.669]Epoch 28:   3%|▎         | 28/1000 [41:40<23:56:05, 88.65s/it, lr=0.0005, test_MAE=0.7, time=88.6, train_MAE=0.537, train_loss=0.537, val_MAE=0.669, val_loss=0.669]Epoch 28:   3%|▎         | 28/1000 [43:08<23:56:05, 88.65s/it, lr=0.0005, test_MAE=0.668, time=88, train_MAE=0.532, train_loss=0.532, val_MAE=0.636, val_loss=0.636]Epoch 28:   3%|▎         | 29/1000 [43:08<23:51:38, 88.46s/it, lr=0.0005, test_MAE=0.668, time=88, train_MAE=0.532, train_loss=0.532, val_MAE=0.636, val_loss=0.636]Epoch 29:   3%|▎         | 29/1000 [43:08<23:51:38, 88.46s/it, lr=0.0005, test_MAE=0.668, time=88, train_MAE=0.532, train_loss=0.532, val_MAE=0.636, val_loss=0.636]Epoch 29:   3%|▎         | 29/1000 [44:37<23:51:38, 88.46s/it, lr=0.0005, test_MAE=0.639, time=89.1, train_MAE=0.523, train_loss=0.523, val_MAE=0.62, val_loss=0.62]Epoch 29:   3%|▎         | 30/1000 [44:37<23:53:34, 88.67s/it, lr=0.0005, test_MAE=0.639, time=89.1, train_MAE=0.523, train_loss=0.523, val_MAE=0.62, val_loss=0.62]Epoch 30:   3%|▎         | 30/1000 [44:37<23:53:34, 88.67s/it, lr=0.0005, test_MAE=0.639, time=89.1, train_MAE=0.523, train_loss=0.523, val_MAE=0.62, val_loss=0.62]Epoch 30:   3%|▎         | 30/1000 [46:06<23:53:34, 88.67s/it, lr=0.0005, test_MAE=0.626, time=88.7, train_MAE=0.531, train_loss=0.531, val_MAE=0.588, val_loss=0.588]Epoch 30:   3%|▎         | 31/1000 [46:06<23:52:26, 88.70s/it, lr=0.0005, test_MAE=0.626, time=88.7, train_MAE=0.531, train_loss=0.531, val_MAE=0.588, val_loss=0.588]Epoch 31:   3%|▎         | 31/1000 [46:06<23:52:26, 88.70s/it, lr=0.0005, test_MAE=0.626, time=88.7, train_MAE=0.531, train_loss=0.531, val_MAE=0.588, val_loss=0.588]Epoch 31:   3%|▎         | 31/1000 [47:34<23:52:26, 88.70s/it, lr=0.0005, test_MAE=0.623, time=88.5, train_MAE=0.525, train_loss=0.525, val_MAE=0.601, val_loss=0.601]Epoch    32: reducing learning rate of group 0 to 2.5000e-04.
Epoch 31:   3%|▎         | 32/1000 [47:34<23:50:16, 88.65s/it, lr=0.0005, test_MAE=0.623, time=88.5, train_MAE=0.525, train_loss=0.525, val_MAE=0.601, val_loss=0.601]Epoch 32:   3%|▎         | 32/1000 [47:34<23:50:16, 88.65s/it, lr=0.0005, test_MAE=0.623, time=88.5, train_MAE=0.525, train_loss=0.525, val_MAE=0.601, val_loss=0.601]Epoch 32:   3%|▎         | 32/1000 [49:03<23:50:16, 88.65s/it, lr=0.00025, test_MAE=0.649, time=88.8, train_MAE=0.513, train_loss=0.513, val_MAE=0.618, val_loss=0.618]Epoch 32:   3%|▎         | 33/1000 [49:03<23:49:38, 88.71s/it, lr=0.00025, test_MAE=0.649, time=88.8, train_MAE=0.513, train_loss=0.513, val_MAE=0.618, val_loss=0.618]Epoch 33:   3%|▎         | 33/1000 [49:03<23:49:38, 88.71s/it, lr=0.00025, test_MAE=0.649, time=88.8, train_MAE=0.513, train_loss=0.513, val_MAE=0.618, val_loss=0.618]Epoch 33:   3%|▎         | 33/1000 [50:31<23:49:38, 88.71s/it, lr=0.00025, test_MAE=0.622, time=88.2, train_MAE=0.511, train_loss=0.511, val_MAE=0.591, val_loss=0.591]Epoch 33:   3%|▎         | 34/1000 [50:31<23:45:51, 88.56s/it, lr=0.00025, test_MAE=0.622, time=88.2, train_MAE=0.511, train_loss=0.511, val_MAE=0.591, val_loss=0.591]Epoch 34:   3%|▎         | 34/1000 [50:31<23:45:51, 88.56s/it, lr=0.00025, test_MAE=0.622, time=88.2, train_MAE=0.511, train_loss=0.511, val_MAE=0.591, val_loss=0.591]Epoch 34:   3%|▎         | 34/1000 [51:59<23:45:51, 88.56s/it, lr=0.00025, test_MAE=0.65, time=87.7, train_MAE=0.507, train_loss=0.507, val_MAE=0.617, val_loss=0.617] Epoch 34:   4%|▎         | 35/1000 [51:59<23:40:22, 88.31s/it, lr=0.00025, test_MAE=0.65, time=87.7, train_MAE=0.507, train_loss=0.507, val_MAE=0.617, val_loss=0.617]Epoch 35:   4%|▎         | 35/1000 [51:59<23:40:22, 88.31s/it, lr=0.00025, test_MAE=0.65, time=87.7, train_MAE=0.507, train_loss=0.507, val_MAE=0.617, val_loss=0.617]Epoch 35:   4%|▎         | 35/1000 [53:27<23:40:22, 88.31s/it, lr=0.00025, test_MAE=0.603, time=88.3, train_MAE=0.506, train_loss=0.506, val_MAE=0.574, val_loss=0.574]Epoch 35:   4%|▎         | 36/1000 [53:27<23:39:02, 88.32s/it, lr=0.00025, test_MAE=0.603, time=88.3, train_MAE=0.506, train_loss=0.506, val_MAE=0.574, val_loss=0.574]Epoch 36:   4%|▎         | 36/1000 [53:27<23:39:02, 88.32s/it, lr=0.00025, test_MAE=0.603, time=88.3, train_MAE=0.506, train_loss=0.506, val_MAE=0.574, val_loss=0.574]Epoch 36:   4%|▎         | 36/1000 [54:55<23:39:02, 88.32s/it, lr=0.00025, test_MAE=0.606, time=88, train_MAE=0.5, train_loss=0.5, val_MAE=0.582, val_loss=0.582]      Epoch 36:   4%|▎         | 37/1000 [54:55<23:36:14, 88.24s/it, lr=0.00025, test_MAE=0.606, time=88, train_MAE=0.5, train_loss=0.5, val_MAE=0.582, val_loss=0.582]Epoch 37:   4%|▎         | 37/1000 [54:55<23:36:14, 88.24s/it, lr=0.00025, test_MAE=0.606, time=88, train_MAE=0.5, train_loss=0.5, val_MAE=0.582, val_loss=0.582]Epoch 37:   4%|▎         | 37/1000 [56:23<23:36:14, 88.24s/it, lr=0.00025, test_MAE=0.619, time=87.7, train_MAE=0.5, train_loss=0.5, val_MAE=0.588, val_loss=0.588]Epoch 37:   4%|▍         | 38/1000 [56:23<23:32:16, 88.08s/it, lr=0.00025, test_MAE=0.619, time=87.7, train_MAE=0.5, train_loss=0.5, val_MAE=0.588, val_loss=0.588]Epoch 38:   4%|▍         | 38/1000 [56:23<23:32:16, 88.08s/it, lr=0.00025, test_MAE=0.619, time=87.7, train_MAE=0.5, train_loss=0.5, val_MAE=0.588, val_loss=0.588]Epoch 38:   4%|▍         | 38/1000 [57:51<23:32:16, 88.08s/it, lr=0.00025, test_MAE=0.713, time=88.3, train_MAE=0.505, train_loss=0.505, val_MAE=0.677, val_loss=0.677]Epoch 38:   4%|▍         | 39/1000 [57:51<23:31:56, 88.15s/it, lr=0.00025, test_MAE=0.713, time=88.3, train_MAE=0.505, train_loss=0.505, val_MAE=0.677, val_loss=0.677]Epoch 39:   4%|▍         | 39/1000 [57:51<23:31:56, 88.15s/it, lr=0.00025, test_MAE=0.713, time=88.3, train_MAE=0.505, train_loss=0.505, val_MAE=0.677, val_loss=0.677]Epoch 39:   4%|▍         | 39/1000 [59:20<23:31:56, 88.15s/it, lr=0.00025, test_MAE=0.613, time=88.3, train_MAE=0.495, train_loss=0.495, val_MAE=0.576, val_loss=0.576]Epoch 39:   4%|▍         | 40/1000 [59:20<23:31:20, 88.21s/it, lr=0.00025, test_MAE=0.613, time=88.3, train_MAE=0.495, train_loss=0.495, val_MAE=0.576, val_loss=0.576]Epoch 40:   4%|▍         | 40/1000 [59:20<23:31:20, 88.21s/it, lr=0.00025, test_MAE=0.613, time=88.3, train_MAE=0.495, train_loss=0.495, val_MAE=0.576, val_loss=0.576]Epoch 40:   4%|▍         | 40/1000 [1:00:48<23:31:20, 88.21s/it, lr=0.00025, test_MAE=0.634, time=88.1, train_MAE=0.496, train_loss=0.496, val_MAE=0.605, val_loss=0.605]Epoch 40:   4%|▍         | 41/1000 [1:00:48<23:29:23, 88.18s/it, lr=0.00025, test_MAE=0.634, time=88.1, train_MAE=0.496, train_loss=0.496, val_MAE=0.605, val_loss=0.605]Epoch 41:   4%|▍         | 41/1000 [1:00:48<23:29:23, 88.18s/it, lr=0.00025, test_MAE=0.634, time=88.1, train_MAE=0.496, train_loss=0.496, val_MAE=0.605, val_loss=0.605]Epoch 41:   4%|▍         | 41/1000 [1:02:16<23:29:23, 88.18s/it, lr=0.00025, test_MAE=0.612, time=87.9, train_MAE=0.492, train_loss=0.492, val_MAE=0.576, val_loss=0.576]Epoch    42: reducing learning rate of group 0 to 1.2500e-04.
Epoch 41:   4%|▍         | 42/1000 [1:02:16<23:26:48, 88.11s/it, lr=0.00025, test_MAE=0.612, time=87.9, train_MAE=0.492, train_loss=0.492, val_MAE=0.576, val_loss=0.576]Epoch 42:   4%|▍         | 42/1000 [1:02:16<23:26:48, 88.11s/it, lr=0.00025, test_MAE=0.612, time=87.9, train_MAE=0.492, train_loss=0.492, val_MAE=0.576, val_loss=0.576]Epoch 42:   4%|▍         | 42/1000 [1:03:44<23:26:48, 88.11s/it, lr=0.000125, test_MAE=0.599, time=88.6, train_MAE=0.491, train_loss=0.491, val_MAE=0.578, val_loss=0.578]Epoch 42:   4%|▍         | 43/1000 [1:03:44<23:27:41, 88.26s/it, lr=0.000125, test_MAE=0.599, time=88.6, train_MAE=0.491, train_loss=0.491, val_MAE=0.578, val_loss=0.578]Epoch 43:   4%|▍         | 43/1000 [1:03:44<23:27:41, 88.26s/it, lr=0.000125, test_MAE=0.599, time=88.6, train_MAE=0.491, train_loss=0.491, val_MAE=0.578, val_loss=0.578]Epoch 43:   4%|▍         | 43/1000 [1:05:12<23:27:41, 88.26s/it, lr=0.000125, test_MAE=0.611, time=87.7, train_MAE=0.486, train_loss=0.486, val_MAE=0.579, val_loss=0.579]Epoch 43:   4%|▍         | 44/1000 [1:05:12<23:23:58, 88.12s/it, lr=0.000125, test_MAE=0.611, time=87.7, train_MAE=0.486, train_loss=0.486, val_MAE=0.579, val_loss=0.579]Epoch 44:   4%|▍         | 44/1000 [1:05:12<23:23:58, 88.12s/it, lr=0.000125, test_MAE=0.611, time=87.7, train_MAE=0.486, train_loss=0.486, val_MAE=0.579, val_loss=0.579]Epoch 44:   4%|▍         | 44/1000 [1:06:40<23:23:58, 88.12s/it, lr=0.000125, test_MAE=0.664, time=88.4, train_MAE=0.498, train_loss=0.498, val_MAE=0.636, val_loss=0.636]Epoch 44:   4%|▍         | 45/1000 [1:06:40<23:23:50, 88.20s/it, lr=0.000125, test_MAE=0.664, time=88.4, train_MAE=0.498, train_loss=0.498, val_MAE=0.636, val_loss=0.636]Epoch 45:   4%|▍         | 45/1000 [1:06:40<23:23:50, 88.20s/it, lr=0.000125, test_MAE=0.664, time=88.4, train_MAE=0.498, train_loss=0.498, val_MAE=0.636, val_loss=0.636]Epoch 45:   4%|▍         | 45/1000 [1:08:09<23:23:50, 88.20s/it, lr=0.000125, test_MAE=0.647, time=88.2, train_MAE=0.485, train_loss=0.485, val_MAE=0.613, val_loss=0.613]Epoch 45:   5%|▍         | 46/1000 [1:08:09<23:22:41, 88.22s/it, lr=0.000125, test_MAE=0.647, time=88.2, train_MAE=0.485, train_loss=0.485, val_MAE=0.613, val_loss=0.613]Epoch 46:   5%|▍         | 46/1000 [1:08:09<23:22:41, 88.22s/it, lr=0.000125, test_MAE=0.647, time=88.2, train_MAE=0.485, train_loss=0.485, val_MAE=0.613, val_loss=0.613]Epoch 46:   5%|▍         | 46/1000 [1:09:37<23:22:41, 88.22s/it, lr=0.000125, test_MAE=0.604, time=88, train_MAE=0.481, train_loss=0.481, val_MAE=0.572, val_loss=0.572]  Epoch 46:   5%|▍         | 47/1000 [1:09:37<23:20:13, 88.16s/it, lr=0.000125, test_MAE=0.604, time=88, train_MAE=0.481, train_loss=0.481, val_MAE=0.572, val_loss=0.572]Epoch 47:   5%|▍         | 47/1000 [1:09:37<23:20:13, 88.16s/it, lr=0.000125, test_MAE=0.604, time=88, train_MAE=0.481, train_loss=0.481, val_MAE=0.572, val_loss=0.572]Epoch 47:   5%|▍         | 47/1000 [1:11:04<23:20:13, 88.16s/it, lr=0.000125, test_MAE=0.606, time=87.7, train_MAE=0.483, train_loss=0.483, val_MAE=0.574, val_loss=0.574]Epoch 47:   5%|▍         | 48/1000 [1:11:04<23:16:29, 88.01s/it, lr=0.000125, test_MAE=0.606, time=87.7, train_MAE=0.483, train_loss=0.483, val_MAE=0.574, val_loss=0.574]Epoch 48:   5%|▍         | 48/1000 [1:11:04<23:16:29, 88.01s/it, lr=0.000125, test_MAE=0.606, time=87.7, train_MAE=0.483, train_loss=0.483, val_MAE=0.574, val_loss=0.574]Epoch 48:   5%|▍         | 48/1000 [1:12:33<23:16:29, 88.01s/it, lr=0.000125, test_MAE=0.607, time=88.5, train_MAE=0.479, train_loss=0.479, val_MAE=0.579, val_loss=0.579]Epoch 48:   5%|▍         | 49/1000 [1:12:33<23:17:16, 88.16s/it, lr=0.000125, test_MAE=0.607, time=88.5, train_MAE=0.479, train_loss=0.479, val_MAE=0.579, val_loss=0.579]Epoch 49:   5%|▍         | 49/1000 [1:12:33<23:17:16, 88.16s/it, lr=0.000125, test_MAE=0.607, time=88.5, train_MAE=0.479, train_loss=0.479, val_MAE=0.579, val_loss=0.579]Epoch 49:   5%|▍         | 49/1000 [1:14:01<23:17:16, 88.16s/it, lr=0.000125, test_MAE=0.606, time=88.2, train_MAE=0.481, train_loss=0.481, val_MAE=0.578, val_loss=0.578]Epoch 49:   5%|▌         | 50/1000 [1:14:01<23:16:20, 88.19s/it, lr=0.000125, test_MAE=0.606, time=88.2, train_MAE=0.481, train_loss=0.481, val_MAE=0.578, val_loss=0.578]Epoch 50:   5%|▌         | 50/1000 [1:14:01<23:16:20, 88.19s/it, lr=0.000125, test_MAE=0.606, time=88.2, train_MAE=0.481, train_loss=0.481, val_MAE=0.578, val_loss=0.578]Epoch 50:   5%|▌         | 50/1000 [1:15:30<23:16:20, 88.19s/it, lr=0.000125, test_MAE=0.606, time=88.3, train_MAE=0.479, train_loss=0.479, val_MAE=0.57, val_loss=0.57]  Epoch 50:   5%|▌         | 51/1000 [1:15:30<23:15:30, 88.23s/it, lr=0.000125, test_MAE=0.606, time=88.3, train_MAE=0.479, train_loss=0.479, val_MAE=0.57, val_loss=0.57]Epoch 51:   5%|▌         | 51/1000 [1:15:30<23:15:30, 88.23s/it, lr=0.000125, test_MAE=0.606, time=88.3, train_MAE=0.479, train_loss=0.479, val_MAE=0.57, val_loss=0.57]Epoch 51:   5%|▌         | 51/1000 [1:16:58<23:15:30, 88.23s/it, lr=0.000125, test_MAE=0.611, time=88.3, train_MAE=0.471, train_loss=0.471, val_MAE=0.582, val_loss=0.582]Epoch 51:   5%|▌         | 52/1000 [1:16:58<23:14:20, 88.25s/it, lr=0.000125, test_MAE=0.611, time=88.3, train_MAE=0.471, train_loss=0.471, val_MAE=0.582, val_loss=0.582]Epoch 52:   5%|▌         | 52/1000 [1:16:58<23:14:20, 88.25s/it, lr=0.000125, test_MAE=0.611, time=88.3, train_MAE=0.471, train_loss=0.471, val_MAE=0.582, val_loss=0.582]Epoch 52:   5%|▌         | 52/1000 [1:18:24<23:14:20, 88.25s/it, lr=0.000125, test_MAE=0.603, time=86.5, train_MAE=0.471, train_loss=0.471, val_MAE=0.572, val_loss=0.572]Epoch 52:   5%|▌         | 53/1000 [1:18:24<23:04:55, 87.75s/it, lr=0.000125, test_MAE=0.603, time=86.5, train_MAE=0.471, train_loss=0.471, val_MAE=0.572, val_loss=0.572]Epoch 53:   5%|▌         | 53/1000 [1:18:24<23:04:55, 87.75s/it, lr=0.000125, test_MAE=0.603, time=86.5, train_MAE=0.471, train_loss=0.471, val_MAE=0.572, val_loss=0.572]Epoch 53:   5%|▌         | 53/1000 [1:19:49<23:04:55, 87.75s/it, lr=0.000125, test_MAE=0.617, time=85.1, train_MAE=0.472, train_loss=0.472, val_MAE=0.587, val_loss=0.587]Epoch 53:   5%|▌         | 54/1000 [1:19:50<22:51:05, 86.96s/it, lr=0.000125, test_MAE=0.617, time=85.1, train_MAE=0.472, train_loss=0.472, val_MAE=0.587, val_loss=0.587]Epoch 54:   5%|▌         | 54/1000 [1:19:50<22:51:05, 86.96s/it, lr=0.000125, test_MAE=0.617, time=85.1, train_MAE=0.472, train_loss=0.472, val_MAE=0.587, val_loss=0.587]Epoch 54:   5%|▌         | 54/1000 [1:21:14<22:51:05, 86.96s/it, lr=0.000125, test_MAE=0.616, time=84.1, train_MAE=0.471, train_loss=0.471, val_MAE=0.584, val_loss=0.584]Epoch 54:   6%|▌         | 55/1000 [1:21:14<22:36:17, 86.11s/it, lr=0.000125, test_MAE=0.616, time=84.1, train_MAE=0.471, train_loss=0.471, val_MAE=0.584, val_loss=0.584]Epoch 55:   6%|▌         | 55/1000 [1:21:14<22:36:17, 86.11s/it, lr=0.000125, test_MAE=0.616, time=84.1, train_MAE=0.471, train_loss=0.471, val_MAE=0.584, val_loss=0.584]Epoch 55:   6%|▌         | 55/1000 [1:22:36<22:36:17, 86.11s/it, lr=0.000125, test_MAE=0.62, time=82.8, train_MAE=0.47, train_loss=0.47, val_MAE=0.588, val_loss=0.588]   Epoch 55:   6%|▌         | 56/1000 [1:22:36<22:19:10, 85.12s/it, lr=0.000125, test_MAE=0.62, time=82.8, train_MAE=0.47, train_loss=0.47, val_MAE=0.588, val_loss=0.588]Epoch 56:   6%|▌         | 56/1000 [1:22:36<22:19:10, 85.12s/it, lr=0.000125, test_MAE=0.62, time=82.8, train_MAE=0.47, train_loss=0.47, val_MAE=0.588, val_loss=0.588]Epoch 56:   6%|▌         | 56/1000 [1:24:00<22:19:10, 85.12s/it, lr=0.000125, test_MAE=0.614, time=83.1, train_MAE=0.479, train_loss=0.479, val_MAE=0.578, val_loss=0.578]Epoch    57: reducing learning rate of group 0 to 6.2500e-05.
Epoch 56:   6%|▌         | 57/1000 [1:24:00<22:08:33, 84.53s/it, lr=0.000125, test_MAE=0.614, time=83.1, train_MAE=0.479, train_loss=0.479, val_MAE=0.578, val_loss=0.578]Epoch 57:   6%|▌         | 57/1000 [1:24:00<22:08:33, 84.53s/it, lr=0.000125, test_MAE=0.614, time=83.1, train_MAE=0.479, train_loss=0.479, val_MAE=0.578, val_loss=0.578]Epoch 57:   6%|▌         | 57/1000 [1:25:22<22:08:33, 84.53s/it, lr=6.25e-5, test_MAE=0.615, time=82.6, train_MAE=0.47, train_loss=0.47, val_MAE=0.581, val_loss=0.581]   Epoch 57:   6%|▌         | 58/1000 [1:25:22<21:58:19, 83.97s/it, lr=6.25e-5, test_MAE=0.615, time=82.6, train_MAE=0.47, train_loss=0.47, val_MAE=0.581, val_loss=0.581]Epoch 58:   6%|▌         | 58/1000 [1:25:22<21:58:19, 83.97s/it, lr=6.25e-5, test_MAE=0.615, time=82.6, train_MAE=0.47, train_loss=0.47, val_MAE=0.581, val_loss=0.581]Epoch 58:   6%|▌         | 58/1000 [1:26:45<21:58:19, 83.97s/it, lr=6.25e-5, test_MAE=0.609, time=82.7, train_MAE=0.467, train_loss=0.467, val_MAE=0.577, val_loss=0.577]Epoch 58:   6%|▌         | 59/1000 [1:26:45<21:51:03, 83.60s/it, lr=6.25e-5, test_MAE=0.609, time=82.7, train_MAE=0.467, train_loss=0.467, val_MAE=0.577, val_loss=0.577]Epoch 59:   6%|▌         | 59/1000 [1:26:45<21:51:03, 83.60s/it, lr=6.25e-5, test_MAE=0.609, time=82.7, train_MAE=0.467, train_loss=0.467, val_MAE=0.577, val_loss=0.577]Epoch 59:   6%|▌         | 59/1000 [1:28:08<21:51:03, 83.60s/it, lr=6.25e-5, test_MAE=0.606, time=82.6, train_MAE=0.474, train_loss=0.474, val_MAE=0.578, val_loss=0.578]Epoch 59:   6%|▌         | 60/1000 [1:28:08<21:45:21, 83.32s/it, lr=6.25e-5, test_MAE=0.606, time=82.6, train_MAE=0.474, train_loss=0.474, val_MAE=0.578, val_loss=0.578]Epoch 60:   6%|▌         | 60/1000 [1:28:08<21:45:21, 83.32s/it, lr=6.25e-5, test_MAE=0.606, time=82.6, train_MAE=0.474, train_loss=0.474, val_MAE=0.578, val_loss=0.578]Epoch 60:   6%|▌         | 60/1000 [1:29:30<21:45:21, 83.32s/it, lr=6.25e-5, test_MAE=0.625, time=82.8, train_MAE=0.462, train_loss=0.462, val_MAE=0.595, val_loss=0.595]Epoch 60:   6%|▌         | 61/1000 [1:29:31<21:41:40, 83.17s/it, lr=6.25e-5, test_MAE=0.625, time=82.8, train_MAE=0.462, train_loss=0.462, val_MAE=0.595, val_loss=0.595]Epoch 61:   6%|▌         | 61/1000 [1:29:31<21:41:40, 83.17s/it, lr=6.25e-5, test_MAE=0.625, time=82.8, train_MAE=0.462, train_loss=0.462, val_MAE=0.595, val_loss=0.595]Epoch 61:   6%|▌         | 61/1000 [1:30:53<21:41:40, 83.17s/it, lr=6.25e-5, test_MAE=0.604, time=83, train_MAE=0.47, train_loss=0.47, val_MAE=0.575, val_loss=0.575]    Epoch 61:   6%|▌         | 62/1000 [1:30:54<21:39:29, 83.12s/it, lr=6.25e-5, test_MAE=0.604, time=83, train_MAE=0.47, train_loss=0.47, val_MAE=0.575, val_loss=0.575]Epoch 62:   6%|▌         | 62/1000 [1:30:54<21:39:29, 83.12s/it, lr=6.25e-5, test_MAE=0.604, time=83, train_MAE=0.47, train_loss=0.47, val_MAE=0.575, val_loss=0.575]Epoch 62:   6%|▌         | 62/1000 [1:32:17<21:39:29, 83.12s/it, lr=6.25e-5, test_MAE=0.604, time=83.2, train_MAE=0.462, train_loss=0.462, val_MAE=0.575, val_loss=0.575]Epoch    63: reducing learning rate of group 0 to 3.1250e-05.
Epoch 62:   6%|▋         | 63/1000 [1:32:17<21:38:38, 83.16s/it, lr=6.25e-5, test_MAE=0.604, time=83.2, train_MAE=0.462, train_loss=0.462, val_MAE=0.575, val_loss=0.575]Epoch 63:   6%|▋         | 63/1000 [1:32:17<21:38:38, 83.16s/it, lr=6.25e-5, test_MAE=0.604, time=83.2, train_MAE=0.462, train_loss=0.462, val_MAE=0.575, val_loss=0.575]Epoch 63:   6%|▋         | 63/1000 [1:33:40<21:38:38, 83.16s/it, lr=3.13e-5, test_MAE=0.606, time=83, train_MAE=0.46, train_loss=0.46, val_MAE=0.579, val_loss=0.579]    Epoch 63:   6%|▋         | 64/1000 [1:33:40<21:36:45, 83.13s/it, lr=3.13e-5, test_MAE=0.606, time=83, train_MAE=0.46, train_loss=0.46, val_MAE=0.579, val_loss=0.579]Epoch 64:   6%|▋         | 64/1000 [1:33:40<21:36:45, 83.13s/it, lr=3.13e-5, test_MAE=0.606, time=83, train_MAE=0.46, train_loss=0.46, val_MAE=0.579, val_loss=0.579]Epoch 64:   6%|▋         | 64/1000 [1:35:03<21:36:45, 83.13s/it, lr=3.13e-5, test_MAE=0.606, time=83.1, train_MAE=0.455, train_loss=0.455, val_MAE=0.574, val_loss=0.574]Epoch 64:   6%|▋         | 65/1000 [1:35:03<21:35:09, 83.11s/it, lr=3.13e-5, test_MAE=0.606, time=83.1, train_MAE=0.455, train_loss=0.455, val_MAE=0.574, val_loss=0.574]Epoch 65:   6%|▋         | 65/1000 [1:35:03<21:35:09, 83.11s/it, lr=3.13e-5, test_MAE=0.606, time=83.1, train_MAE=0.455, train_loss=0.455, val_MAE=0.574, val_loss=0.574]Epoch 65:   6%|▋         | 65/1000 [1:36:26<21:35:09, 83.11s/it, lr=3.13e-5, test_MAE=0.616, time=83.3, train_MAE=0.468, train_loss=0.468, val_MAE=0.58, val_loss=0.58]  Epoch 65:   7%|▋         | 66/1000 [1:36:26<21:34:57, 83.19s/it, lr=3.13e-5, test_MAE=0.616, time=83.3, train_MAE=0.468, train_loss=0.468, val_MAE=0.58, val_loss=0.58]Epoch 66:   7%|▋         | 66/1000 [1:36:26<21:34:57, 83.19s/it, lr=3.13e-5, test_MAE=0.616, time=83.3, train_MAE=0.468, train_loss=0.468, val_MAE=0.58, val_loss=0.58]Epoch 66:   7%|▋         | 66/1000 [1:37:50<21:34:57, 83.19s/it, lr=3.13e-5, test_MAE=0.605, time=83.3, train_MAE=0.459, train_loss=0.459, val_MAE=0.576, val_loss=0.576]Epoch 66:   7%|▋         | 67/1000 [1:37:50<21:34:20, 83.24s/it, lr=3.13e-5, test_MAE=0.605, time=83.3, train_MAE=0.459, train_loss=0.459, val_MAE=0.576, val_loss=0.576]Epoch 67:   7%|▋         | 67/1000 [1:37:50<21:34:20, 83.24s/it, lr=3.13e-5, test_MAE=0.605, time=83.3, train_MAE=0.459, train_loss=0.459, val_MAE=0.576, val_loss=0.576]Epoch 67:   7%|▋         | 67/1000 [1:39:12<21:34:20, 83.24s/it, lr=3.13e-5, test_MAE=0.602, time=82.6, train_MAE=0.465, train_loss=0.465, val_MAE=0.575, val_loss=0.575]Epoch 67:   7%|▋         | 68/1000 [1:39:12<21:30:02, 83.05s/it, lr=3.13e-5, test_MAE=0.602, time=82.6, train_MAE=0.465, train_loss=0.465, val_MAE=0.575, val_loss=0.575]Epoch 68:   7%|▋         | 68/1000 [1:39:12<21:30:02, 83.05s/it, lr=3.13e-5, test_MAE=0.602, time=82.6, train_MAE=0.465, train_loss=0.465, val_MAE=0.575, val_loss=0.575]Epoch 68:   7%|▋         | 68/1000 [1:40:35<21:30:02, 83.05s/it, lr=3.13e-5, test_MAE=0.603, time=83.3, train_MAE=0.464, train_loss=0.464, val_MAE=0.575, val_loss=0.575]Epoch    69: reducing learning rate of group 0 to 1.5625e-05.
Epoch 68:   7%|▋         | 69/1000 [1:40:36<21:29:48, 83.12s/it, lr=3.13e-5, test_MAE=0.603, time=83.3, train_MAE=0.464, train_loss=0.464, val_MAE=0.575, val_loss=0.575]Epoch 69:   7%|▋         | 69/1000 [1:40:36<21:29:48, 83.12s/it, lr=3.13e-5, test_MAE=0.603, time=83.3, train_MAE=0.464, train_loss=0.464, val_MAE=0.575, val_loss=0.575]Epoch 69:   7%|▋         | 69/1000 [1:41:58<21:29:48, 83.12s/it, lr=1.56e-5, test_MAE=0.605, time=82.9, train_MAE=0.457, train_loss=0.457, val_MAE=0.575, val_loss=0.575]Epoch 69:   7%|▋         | 70/1000 [1:41:58<21:27:40, 83.08s/it, lr=1.56e-5, test_MAE=0.605, time=82.9, train_MAE=0.457, train_loss=0.457, val_MAE=0.575, val_loss=0.575]Epoch 70:   7%|▋         | 70/1000 [1:41:58<21:27:40, 83.08s/it, lr=1.56e-5, test_MAE=0.605, time=82.9, train_MAE=0.457, train_loss=0.457, val_MAE=0.575, val_loss=0.575]Epoch 70:   7%|▋         | 70/1000 [1:43:21<21:27:40, 83.08s/it, lr=1.56e-5, test_MAE=0.604, time=82.8, train_MAE=0.454, train_loss=0.454, val_MAE=0.574, val_loss=0.574]Epoch 70:   7%|▋         | 71/1000 [1:43:21<21:25:12, 83.01s/it, lr=1.56e-5, test_MAE=0.604, time=82.8, train_MAE=0.454, train_loss=0.454, val_MAE=0.574, val_loss=0.574]Epoch 71:   7%|▋         | 71/1000 [1:43:21<21:25:12, 83.01s/it, lr=1.56e-5, test_MAE=0.604, time=82.8, train_MAE=0.454, train_loss=0.454, val_MAE=0.574, val_loss=0.574]Epoch 71:   7%|▋         | 71/1000 [1:44:45<21:25:12, 83.01s/it, lr=1.56e-5, test_MAE=0.605, time=83.2, train_MAE=0.456, train_loss=0.456, val_MAE=0.573, val_loss=0.573]Epoch 71:   7%|▋         | 72/1000 [1:44:45<21:24:48, 83.07s/it, lr=1.56e-5, test_MAE=0.605, time=83.2, train_MAE=0.456, train_loss=0.456, val_MAE=0.573, val_loss=0.573]Epoch 72:   7%|▋         | 72/1000 [1:44:45<21:24:48, 83.07s/it, lr=1.56e-5, test_MAE=0.605, time=83.2, train_MAE=0.456, train_loss=0.456, val_MAE=0.573, val_loss=0.573]Epoch 72:   7%|▋         | 72/1000 [1:46:07<21:24:48, 83.07s/it, lr=1.56e-5, test_MAE=0.605, time=82.8, train_MAE=0.458, train_loss=0.458, val_MAE=0.577, val_loss=0.577]Epoch 72:   7%|▋         | 73/1000 [1:46:07<21:22:22, 83.00s/it, lr=1.56e-5, test_MAE=0.605, time=82.8, train_MAE=0.458, train_loss=0.458, val_MAE=0.577, val_loss=0.577]Epoch 73:   7%|▋         | 73/1000 [1:46:07<21:22:22, 83.00s/it, lr=1.56e-5, test_MAE=0.605, time=82.8, train_MAE=0.458, train_loss=0.458, val_MAE=0.577, val_loss=0.577]Epoch 73:   7%|▋         | 73/1000 [1:47:30<21:22:22, 83.00s/it, lr=1.56e-5, test_MAE=0.608, time=82.5, train_MAE=0.462, train_loss=0.462, val_MAE=0.576, val_loss=0.576]Epoch 73:   7%|▋         | 74/1000 [1:47:30<21:18:55, 82.87s/it, lr=1.56e-5, test_MAE=0.608, time=82.5, train_MAE=0.462, train_loss=0.462, val_MAE=0.576, val_loss=0.576]Epoch 74:   7%|▋         | 74/1000 [1:47:30<21:18:55, 82.87s/it, lr=1.56e-5, test_MAE=0.608, time=82.5, train_MAE=0.462, train_loss=0.462, val_MAE=0.576, val_loss=0.576]Epoch 74:   7%|▋         | 74/1000 [1:48:53<21:18:55, 82.87s/it, lr=1.56e-5, test_MAE=0.605, time=83.4, train_MAE=0.46, train_loss=0.46, val_MAE=0.576, val_loss=0.576]  Epoch    75: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 74:   7%|▋         | 74/1000 [1:48:53<22:42:41, 88.30s/it, lr=1.56e-5, test_MAE=0.605, time=83.4, train_MAE=0.46, train_loss=0.46, val_MAE=0.576, val_loss=0.576]
Test MAE: 0.6047
Train MAE: 0.4407
Convergence Time (Epochs): 74.0000
TOTAL TIME TAKEN: 6579.5533s
AVG TIME PER EPOCH: 87.0892s
