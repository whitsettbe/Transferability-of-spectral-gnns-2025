I'm echoing to stdout
I'm echoing to stderr
My JobID is 58322346
I have 4 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 4.9490s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 16, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 4, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'cheb02_vec', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_sub', 'num_eigs': 16, 'bias_mode': 'spatial', 'l1_reg': 1e-05, 'l2_reg': 0.0, 'gen_reg': 0.0, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/aug07/zinc_train_rec.csv', 'test': 'supp_data/molecules/aug07/zinc_test_rec.csv', 'val': 'supp_data/molecules/aug07/zinc_val_rec.csv'}, 'fixMissingPhi1': False, 'extraOrtho': False, 'doublePrecision': True, 'eigval_hidden_dim': 100, 'eigval_num_hidden_layer': 3, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [04:40<?, ?it/s, lr=0.001, test_MAE=1.51, time=281, train_MAE=0.838, train_loss=0.926, val_MAE=1.47, val_loss=1.55]Epoch 0:   0%|          | 1/1000 [04:40<77:55:45, 280.83s/it, lr=0.001, test_MAE=1.51, time=281, train_MAE=0.838, train_loss=0.926, val_MAE=1.47, val_loss=1.55]Epoch 1:   0%|          | 1/1000 [04:40<77:55:45, 280.83s/it, lr=0.001, test_MAE=1.51, time=281, train_MAE=0.838, train_loss=0.926, val_MAE=1.47, val_loss=1.55]Epoch 1:   0%|          | 1/1000 [09:08<77:55:45, 280.83s/it, lr=0.001, test_MAE=0.755, time=268, train_MAE=0.699, train_loss=0.784, val_MAE=0.683, val_loss=0.766]Epoch 1:   0%|          | 2/1000 [09:08<76:47:55, 277.03s/it, lr=0.001, test_MAE=0.755, time=268, train_MAE=0.699, train_loss=0.784, val_MAE=0.683, val_loss=0.766]Epoch 2:   0%|          | 2/1000 [09:08<76:47:55, 277.03s/it, lr=0.001, test_MAE=0.755, time=268, train_MAE=0.699, train_loss=0.784, val_MAE=0.683, val_loss=0.766]Epoch 2:   0%|          | 2/1000 [13:35<76:47:55, 277.03s/it, lr=0.001, test_MAE=0.774, time=267, train_MAE=0.674, train_loss=0.756, val_MAE=0.735, val_loss=0.817]Epoch 2:   0%|          | 3/1000 [13:35<75:51:04, 273.89s/it, lr=0.001, test_MAE=0.774, time=267, train_MAE=0.674, train_loss=0.756, val_MAE=0.735, val_loss=0.817]Epoch 3:   0%|          | 3/1000 [13:35<75:51:04, 273.89s/it, lr=0.001, test_MAE=0.774, time=267, train_MAE=0.674, train_loss=0.756, val_MAE=0.735, val_loss=0.817]Epoch 3:   0%|          | 3/1000 [18:02<75:51:04, 273.89s/it, lr=0.001, test_MAE=0.883, time=267, train_MAE=0.652, train_loss=0.733, val_MAE=0.845, val_loss=0.924]Epoch 3:   0%|          | 4/1000 [18:02<75:13:07, 271.88s/it, lr=0.001, test_MAE=0.883, time=267, train_MAE=0.652, train_loss=0.733, val_MAE=0.845, val_loss=0.924]Epoch 4:   0%|          | 4/1000 [18:02<75:13:07, 271.88s/it, lr=0.001, test_MAE=0.883, time=267, train_MAE=0.652, train_loss=0.733, val_MAE=0.845, val_loss=0.924]Epoch 4:   0%|          | 4/1000 [22:30<75:13:07, 271.88s/it, lr=0.001, test_MAE=0.736, time=268, train_MAE=0.632, train_loss=0.709, val_MAE=0.715, val_loss=0.791]Epoch 4:   0%|          | 5/1000 [22:30<74:47:57, 270.63s/it, lr=0.001, test_MAE=0.736, time=268, train_MAE=0.632, train_loss=0.709, val_MAE=0.715, val_loss=0.791]Epoch 5:   0%|          | 5/1000 [22:30<74:47:57, 270.63s/it, lr=0.001, test_MAE=0.736, time=268, train_MAE=0.632, train_loss=0.709, val_MAE=0.715, val_loss=0.791]Epoch 5:   0%|          | 5/1000 [26:56<74:47:57, 270.63s/it, lr=0.001, test_MAE=0.662, time=266, train_MAE=0.652, train_loss=0.729, val_MAE=0.624, val_loss=0.701]Epoch 5:   1%|          | 6/1000 [26:56<74:19:14, 269.17s/it, lr=0.001, test_MAE=0.662, time=266, train_MAE=0.652, train_loss=0.729, val_MAE=0.624, val_loss=0.701]Epoch 6:   1%|          | 6/1000 [26:56<74:19:14, 269.17s/it, lr=0.001, test_MAE=0.662, time=266, train_MAE=0.652, train_loss=0.729, val_MAE=0.624, val_loss=0.701]Epoch 6:   1%|          | 6/1000 [31:22<74:19:14, 269.17s/it, lr=0.001, test_MAE=0.733, time=266, train_MAE=0.627, train_loss=0.703, val_MAE=0.707, val_loss=0.783]Epoch 6:   1%|          | 7/1000 [31:22<74:00:55, 268.33s/it, lr=0.001, test_MAE=0.733, time=266, train_MAE=0.627, train_loss=0.703, val_MAE=0.707, val_loss=0.783]Epoch 7:   1%|          | 7/1000 [31:22<74:00:55, 268.33s/it, lr=0.001, test_MAE=0.733, time=266, train_MAE=0.627, train_loss=0.703, val_MAE=0.707, val_loss=0.783]Epoch 7:   1%|          | 7/1000 [35:49<74:00:55, 268.33s/it, lr=0.001, test_MAE=0.7, time=267, train_MAE=0.619, train_loss=0.693, val_MAE=0.682, val_loss=0.756]  Epoch 7:   1%|          | 8/1000 [35:49<73:50:29, 267.97s/it, lr=0.001, test_MAE=0.7, time=267, train_MAE=0.619, train_loss=0.693, val_MAE=0.682, val_loss=0.756]Epoch 8:   1%|          | 8/1000 [35:49<73:50:29, 267.97s/it, lr=0.001, test_MAE=0.7, time=267, train_MAE=0.619, train_loss=0.693, val_MAE=0.682, val_loss=0.756]Epoch 8:   1%|          | 8/1000 [40:15<73:50:29, 267.97s/it, lr=0.001, test_MAE=0.976, time=266, train_MAE=0.629, train_loss=0.704, val_MAE=0.949, val_loss=1.02]Epoch 8:   1%|          | 9/1000 [40:15<73:34:36, 267.28s/it, lr=0.001, test_MAE=0.976, time=266, train_MAE=0.629, train_loss=0.704, val_MAE=0.949, val_loss=1.02]Epoch 9:   1%|          | 9/1000 [40:15<73:34:36, 267.28s/it, lr=0.001, test_MAE=0.976, time=266, train_MAE=0.629, train_loss=0.704, val_MAE=0.949, val_loss=1.02]Epoch 9:   1%|          | 9/1000 [44:41<73:34:36, 267.28s/it, lr=0.001, test_MAE=0.74, time=266, train_MAE=0.616, train_loss=0.691, val_MAE=0.705, val_loss=0.78] Epoch 9:   1%|          | 10/1000 [44:41<73:24:57, 266.97s/it, lr=0.001, test_MAE=0.74, time=266, train_MAE=0.616, train_loss=0.691, val_MAE=0.705, val_loss=0.78]Epoch 10:   1%|          | 10/1000 [44:41<73:24:57, 266.97s/it, lr=0.001, test_MAE=0.74, time=266, train_MAE=0.616, train_loss=0.691, val_MAE=0.705, val_loss=0.78]Epoch 10:   1%|          | 10/1000 [49:08<73:24:57, 266.97s/it, lr=0.001, test_MAE=0.676, time=267, train_MAE=0.613, train_loss=0.688, val_MAE=0.636, val_loss=0.709]Epoch 10:   1%|          | 11/1000 [49:08<73:21:12, 267.01s/it, lr=0.001, test_MAE=0.676, time=267, train_MAE=0.613, train_loss=0.688, val_MAE=0.636, val_loss=0.709]Epoch 11:   1%|          | 11/1000 [49:08<73:21:12, 267.01s/it, lr=0.001, test_MAE=0.676, time=267, train_MAE=0.613, train_loss=0.688, val_MAE=0.636, val_loss=0.709]Epoch 11:   1%|          | 11/1000 [53:34<73:21:12, 267.01s/it, lr=0.001, test_MAE=0.817, time=266, train_MAE=0.602, train_loss=0.677, val_MAE=0.787, val_loss=0.861]Epoch    12: reducing learning rate of group 0 to 5.0000e-04.
Epoch 11:   1%|          | 12/1000 [53:34<73:09:41, 266.58s/it, lr=0.001, test_MAE=0.817, time=266, train_MAE=0.602, train_loss=0.677, val_MAE=0.787, val_loss=0.861]Epoch 12:   1%|          | 12/1000 [53:34<73:09:41, 266.58s/it, lr=0.001, test_MAE=0.817, time=266, train_MAE=0.602, train_loss=0.677, val_MAE=0.787, val_loss=0.861]Epoch 12:   1%|          | 12/1000 [58:00<73:09:41, 266.58s/it, lr=0.0005, test_MAE=0.641, time=266, train_MAE=0.577, train_loss=0.65, val_MAE=0.593, val_loss=0.664]Epoch 12:   1%|▏         | 13/1000 [58:00<73:03:50, 266.50s/it, lr=0.0005, test_MAE=0.641, time=266, train_MAE=0.577, train_loss=0.65, val_MAE=0.593, val_loss=0.664]Epoch 13:   1%|▏         | 13/1000 [58:00<73:03:50, 266.50s/it, lr=0.0005, test_MAE=0.641, time=266, train_MAE=0.577, train_loss=0.65, val_MAE=0.593, val_loss=0.664]Epoch 13:   1%|▏         | 13/1000 [1:02:27<73:03:50, 266.50s/it, lr=0.0005, test_MAE=0.716, time=267, train_MAE=0.571, train_loss=0.643, val_MAE=0.681, val_loss=0.752]Epoch 13:   1%|▏         | 14/1000 [1:02:27<73:03:23, 266.74s/it, lr=0.0005, test_MAE=0.716, time=267, train_MAE=0.571, train_loss=0.643, val_MAE=0.681, val_loss=0.752]Epoch 14:   1%|▏         | 14/1000 [1:02:27<73:03:23, 266.74s/it, lr=0.0005, test_MAE=0.716, time=267, train_MAE=0.571, train_loss=0.643, val_MAE=0.681, val_loss=0.752]Epoch 14:   1%|▏         | 14/1000 [1:06:53<73:03:23, 266.74s/it, lr=0.0005, test_MAE=0.684, time=266, train_MAE=0.571, train_loss=0.642, val_MAE=0.629, val_loss=0.699]Epoch 14:   2%|▏         | 15/1000 [1:06:53<72:53:34, 266.41s/it, lr=0.0005, test_MAE=0.684, time=266, train_MAE=0.571, train_loss=0.642, val_MAE=0.629, val_loss=0.699]Epoch 15:   2%|▏         | 15/1000 [1:06:53<72:53:34, 266.41s/it, lr=0.0005, test_MAE=0.684, time=266, train_MAE=0.571, train_loss=0.642, val_MAE=0.629, val_loss=0.699]Epoch 15:   2%|▏         | 15/1000 [1:11:19<72:53:34, 266.41s/it, lr=0.0005, test_MAE=0.805, time=266, train_MAE=0.568, train_loss=0.64, val_MAE=0.757, val_loss=0.827] Epoch 15:   2%|▏         | 16/1000 [1:11:19<72:48:28, 266.37s/it, lr=0.0005, test_MAE=0.805, time=266, train_MAE=0.568, train_loss=0.64, val_MAE=0.757, val_loss=0.827]Epoch 16:   2%|▏         | 16/1000 [1:11:19<72:48:28, 266.37s/it, lr=0.0005, test_MAE=0.805, time=266, train_MAE=0.568, train_loss=0.64, val_MAE=0.757, val_loss=0.827]Epoch 16:   2%|▏         | 16/1000 [1:15:47<72:48:28, 266.37s/it, lr=0.0005, test_MAE=0.819, time=267, train_MAE=0.562, train_loss=0.634, val_MAE=0.808, val_loss=0.88]Epoch 16:   2%|▏         | 17/1000 [1:15:47<72:49:24, 266.70s/it, lr=0.0005, test_MAE=0.819, time=267, train_MAE=0.562, train_loss=0.634, val_MAE=0.808, val_loss=0.88]Epoch 17:   2%|▏         | 17/1000 [1:15:47<72:49:24, 266.70s/it, lr=0.0005, test_MAE=0.819, time=267, train_MAE=0.562, train_loss=0.634, val_MAE=0.808, val_loss=0.88]Epoch 17:   2%|▏         | 17/1000 [1:20:13<72:49:24, 266.70s/it, lr=0.0005, test_MAE=0.649, time=267, train_MAE=0.553, train_loss=0.624, val_MAE=0.618, val_loss=0.689]Epoch 17:   2%|▏         | 18/1000 [1:20:13<72:44:37, 266.68s/it, lr=0.0005, test_MAE=0.649, time=267, train_MAE=0.553, train_loss=0.624, val_MAE=0.618, val_loss=0.689]Epoch 18:   2%|▏         | 18/1000 [1:20:13<72:44:37, 266.68s/it, lr=0.0005, test_MAE=0.649, time=267, train_MAE=0.553, train_loss=0.624, val_MAE=0.618, val_loss=0.689]Epoch 18:   2%|▏         | 18/1000 [1:24:41<72:44:37, 266.68s/it, lr=0.0005, test_MAE=0.685, time=268, train_MAE=0.549, train_loss=0.621, val_MAE=0.634, val_loss=0.705]Epoch    19: reducing learning rate of group 0 to 2.5000e-04.
Epoch 18:   2%|▏         | 19/1000 [1:24:41<72:45:00, 266.97s/it, lr=0.0005, test_MAE=0.685, time=268, train_MAE=0.549, train_loss=0.621, val_MAE=0.634, val_loss=0.705]Epoch 19:   2%|▏         | 19/1000 [1:24:41<72:45:00, 266.97s/it, lr=0.0005, test_MAE=0.685, time=268, train_MAE=0.549, train_loss=0.621, val_MAE=0.634, val_loss=0.705]Epoch 19:   2%|▏         | 19/1000 [1:29:09<72:45:00, 266.97s/it, lr=0.00025, test_MAE=0.635, time=267, train_MAE=0.53, train_loss=0.6, val_MAE=0.595, val_loss=0.664]  Epoch 19:   2%|▏         | 20/1000 [1:29:09<72:42:57, 267.12s/it, lr=0.00025, test_MAE=0.635, time=267, train_MAE=0.53, train_loss=0.6, val_MAE=0.595, val_loss=0.664]Epoch 20:   2%|▏         | 20/1000 [1:29:09<72:42:57, 267.12s/it, lr=0.00025, test_MAE=0.635, time=267, train_MAE=0.53, train_loss=0.6, val_MAE=0.595, val_loss=0.664]Epoch 20:   2%|▏         | 20/1000 [1:33:34<72:42:57, 267.12s/it, lr=0.00025, test_MAE=0.68, time=266, train_MAE=0.526, train_loss=0.596, val_MAE=0.642, val_loss=0.711]Epoch 20:   2%|▏         | 21/1000 [1:33:34<72:32:25, 266.75s/it, lr=0.00025, test_MAE=0.68, time=266, train_MAE=0.526, train_loss=0.596, val_MAE=0.642, val_loss=0.711]Epoch 21:   2%|▏         | 21/1000 [1:33:34<72:32:25, 266.75s/it, lr=0.00025, test_MAE=0.68, time=266, train_MAE=0.526, train_loss=0.596, val_MAE=0.642, val_loss=0.711]Epoch 21:   2%|▏         | 21/1000 [1:38:01<72:32:25, 266.75s/it, lr=0.00025, test_MAE=0.703, time=266, train_MAE=0.528, train_loss=0.597, val_MAE=0.659, val_loss=0.728]Epoch 21:   2%|▏         | 22/1000 [1:38:01<72:26:01, 266.63s/it, lr=0.00025, test_MAE=0.703, time=266, train_MAE=0.528, train_loss=0.597, val_MAE=0.659, val_loss=0.728]Epoch 22:   2%|▏         | 22/1000 [1:38:01<72:26:01, 266.63s/it, lr=0.00025, test_MAE=0.703, time=266, train_MAE=0.528, train_loss=0.597, val_MAE=0.659, val_loss=0.728]Epoch 22:   2%|▏         | 22/1000 [1:42:28<72:26:01, 266.63s/it, lr=0.00025, test_MAE=0.651, time=267, train_MAE=0.513, train_loss=0.582, val_MAE=0.621, val_loss=0.689]Epoch 22:   2%|▏         | 23/1000 [1:42:28<72:24:18, 266.80s/it, lr=0.00025, test_MAE=0.651, time=267, train_MAE=0.513, train_loss=0.582, val_MAE=0.621, val_loss=0.689]Epoch 23:   2%|▏         | 23/1000 [1:42:28<72:24:18, 266.80s/it, lr=0.00025, test_MAE=0.651, time=267, train_MAE=0.513, train_loss=0.582, val_MAE=0.621, val_loss=0.689]Epoch 23:   2%|▏         | 23/1000 [1:46:54<72:24:18, 266.80s/it, lr=0.00025, test_MAE=0.657, time=266, train_MAE=0.533, train_loss=0.602, val_MAE=0.615, val_loss=0.684]Epoch 23:   2%|▏         | 24/1000 [1:46:54<72:14:32, 266.47s/it, lr=0.00025, test_MAE=0.657, time=266, train_MAE=0.533, train_loss=0.602, val_MAE=0.615, val_loss=0.684]Epoch 24:   2%|▏         | 24/1000 [1:46:54<72:14:32, 266.47s/it, lr=0.00025, test_MAE=0.657, time=266, train_MAE=0.533, train_loss=0.602, val_MAE=0.615, val_loss=0.684]Epoch 24:   2%|▏         | 24/1000 [1:51:20<72:14:32, 266.47s/it, lr=0.00025, test_MAE=0.744, time=266, train_MAE=0.517, train_loss=0.586, val_MAE=0.69, val_loss=0.759] Epoch    25: reducing learning rate of group 0 to 1.2500e-04.
Epoch 24:   2%|▎         | 25/1000 [1:51:20<72:09:50, 266.45s/it, lr=0.00025, test_MAE=0.744, time=266, train_MAE=0.517, train_loss=0.586, val_MAE=0.69, val_loss=0.759]Epoch 25:   2%|▎         | 25/1000 [1:51:20<72:09:50, 266.45s/it, lr=0.00025, test_MAE=0.744, time=266, train_MAE=0.517, train_loss=0.586, val_MAE=0.69, val_loss=0.759]Epoch 25:   2%|▎         | 25/1000 [1:55:47<72:09:50, 266.45s/it, lr=0.000125, test_MAE=0.63, time=267, train_MAE=0.489, train_loss=0.557, val_MAE=0.587, val_loss=0.655]Epoch 25:   3%|▎         | 26/1000 [1:55:47<72:07:59, 266.61s/it, lr=0.000125, test_MAE=0.63, time=267, train_MAE=0.489, train_loss=0.557, val_MAE=0.587, val_loss=0.655]Epoch 26:   3%|▎         | 26/1000 [1:55:47<72:07:59, 266.61s/it, lr=0.000125, test_MAE=0.63, time=267, train_MAE=0.489, train_loss=0.557, val_MAE=0.587, val_loss=0.655]Epoch 26:   3%|▎         | 26/1000 [2:00:13<72:07:59, 266.61s/it, lr=0.000125, test_MAE=0.618, time=266, train_MAE=0.488, train_loss=0.555, val_MAE=0.589, val_loss=0.656]Epoch 26:   3%|▎         | 27/1000 [2:00:13<72:00:26, 266.42s/it, lr=0.000125, test_MAE=0.618, time=266, train_MAE=0.488, train_loss=0.555, val_MAE=0.589, val_loss=0.656]Epoch 27:   3%|▎         | 27/1000 [2:00:13<72:00:26, 266.42s/it, lr=0.000125, test_MAE=0.618, time=266, train_MAE=0.488, train_loss=0.555, val_MAE=0.589, val_loss=0.656]Epoch 27:   3%|▎         | 27/1000 [2:04:40<72:00:26, 266.42s/it, lr=0.000125, test_MAE=0.619, time=267, train_MAE=0.49, train_loss=0.557, val_MAE=0.583, val_loss=0.651] Epoch 27:   3%|▎         | 28/1000 [2:04:40<71:58:15, 266.56s/it, lr=0.000125, test_MAE=0.619, time=267, train_MAE=0.49, train_loss=0.557, val_MAE=0.583, val_loss=0.651]Epoch 28:   3%|▎         | 28/1000 [2:04:40<71:58:15, 266.56s/it, lr=0.000125, test_MAE=0.619, time=267, train_MAE=0.49, train_loss=0.557, val_MAE=0.583, val_loss=0.651]Epoch 28:   3%|▎         | 28/1000 [2:09:11<71:58:15, 266.56s/it, lr=0.000125, test_MAE=0.641, time=271, train_MAE=0.488, train_loss=0.555, val_MAE=0.597, val_loss=0.665]Epoch 28:   3%|▎         | 29/1000 [2:09:11<72:13:52, 267.80s/it, lr=0.000125, test_MAE=0.641, time=271, train_MAE=0.488, train_loss=0.555, val_MAE=0.597, val_loss=0.665]Epoch 29:   3%|▎         | 29/1000 [2:09:11<72:13:52, 267.80s/it, lr=0.000125, test_MAE=0.641, time=271, train_MAE=0.488, train_loss=0.555, val_MAE=0.597, val_loss=0.665]Epoch 29:   3%|▎         | 29/1000 [2:13:39<72:13:52, 267.80s/it, lr=0.000125, test_MAE=0.641, time=269, train_MAE=0.481, train_loss=0.548, val_MAE=0.607, val_loss=0.674]Epoch 29:   3%|▎         | 30/1000 [2:13:39<72:14:07, 268.09s/it, lr=0.000125, test_MAE=0.641, time=269, train_MAE=0.481, train_loss=0.548, val_MAE=0.607, val_loss=0.674]Epoch 30:   3%|▎         | 30/1000 [2:13:39<72:14:07, 268.09s/it, lr=0.000125, test_MAE=0.641, time=269, train_MAE=0.481, train_loss=0.548, val_MAE=0.607, val_loss=0.674]Epoch 30:   3%|▎         | 30/1000 [2:18:09<72:14:07, 268.09s/it, lr=0.000125, test_MAE=0.624, time=270, train_MAE=0.483, train_loss=0.551, val_MAE=0.585, val_loss=0.653]Epoch 30:   3%|▎         | 31/1000 [2:18:09<72:17:23, 268.57s/it, lr=0.000125, test_MAE=0.624, time=270, train_MAE=0.483, train_loss=0.551, val_MAE=0.585, val_loss=0.653]Epoch 31:   3%|▎         | 31/1000 [2:18:09<72:17:23, 268.57s/it, lr=0.000125, test_MAE=0.624, time=270, train_MAE=0.483, train_loss=0.551, val_MAE=0.585, val_loss=0.653]Epoch 31:   3%|▎         | 31/1000 [2:22:40<72:17:23, 268.57s/it, lr=0.000125, test_MAE=0.615, time=270, train_MAE=0.471, train_loss=0.538, val_MAE=0.588, val_loss=0.656]Epoch 31:   3%|▎         | 32/1000 [2:22:40<72:22:02, 269.14s/it, lr=0.000125, test_MAE=0.615, time=270, train_MAE=0.471, train_loss=0.538, val_MAE=0.588, val_loss=0.656]Epoch 32:   3%|▎         | 32/1000 [2:22:40<72:22:02, 269.14s/it, lr=0.000125, test_MAE=0.615, time=270, train_MAE=0.471, train_loss=0.538, val_MAE=0.588, val_loss=0.656]Epoch 32:   3%|▎         | 32/1000 [2:27:11<72:22:02, 269.14s/it, lr=0.000125, test_MAE=0.634, time=272, train_MAE=0.474, train_loss=0.541, val_MAE=0.594, val_loss=0.662]Epoch 32:   3%|▎         | 33/1000 [2:27:11<72:30:23, 269.93s/it, lr=0.000125, test_MAE=0.634, time=272, train_MAE=0.474, train_loss=0.541, val_MAE=0.594, val_loss=0.662]Epoch 33:   3%|▎         | 33/1000 [2:27:11<72:30:23, 269.93s/it, lr=0.000125, test_MAE=0.634, time=272, train_MAE=0.474, train_loss=0.541, val_MAE=0.594, val_loss=0.662]Epoch 33:   3%|▎         | 33/1000 [2:31:44<72:30:23, 269.93s/it, lr=0.000125, test_MAE=0.688, time=273, train_MAE=0.463, train_loss=0.53, val_MAE=0.639, val_loss=0.706] Epoch    34: reducing learning rate of group 0 to 6.2500e-05.
Epoch 33:   3%|▎         | 34/1000 [2:31:44<72:38:29, 270.71s/it, lr=0.000125, test_MAE=0.688, time=273, train_MAE=0.463, train_loss=0.53, val_MAE=0.639, val_loss=0.706]Epoch 34:   3%|▎         | 34/1000 [2:31:44<72:38:29, 270.71s/it, lr=0.000125, test_MAE=0.688, time=273, train_MAE=0.463, train_loss=0.53, val_MAE=0.639, val_loss=0.706]Epoch 34:   3%|▎         | 34/1000 [2:36:18<72:38:29, 270.71s/it, lr=6.25e-5, test_MAE=0.623, time=274, train_MAE=0.451, train_loss=0.518, val_MAE=0.585, val_loss=0.653]Epoch 34:   4%|▎         | 35/1000 [2:36:18<72:48:57, 271.65s/it, lr=6.25e-5, test_MAE=0.623, time=274, train_MAE=0.451, train_loss=0.518, val_MAE=0.585, val_loss=0.653]Epoch 35:   4%|▎         | 35/1000 [2:36:18<72:48:57, 271.65s/it, lr=6.25e-5, test_MAE=0.623, time=274, train_MAE=0.451, train_loss=0.518, val_MAE=0.585, val_loss=0.653]Epoch 35:   4%|▎         | 35/1000 [2:40:50<72:48:57, 271.65s/it, lr=6.25e-5, test_MAE=0.651, time=272, train_MAE=0.449, train_loss=0.516, val_MAE=0.619, val_loss=0.686]Epoch 35:   4%|▎         | 36/1000 [2:40:50<72:47:24, 271.83s/it, lr=6.25e-5, test_MAE=0.651, time=272, train_MAE=0.449, train_loss=0.516, val_MAE=0.619, val_loss=0.686]Epoch 36:   4%|▎         | 36/1000 [2:40:50<72:47:24, 271.83s/it, lr=6.25e-5, test_MAE=0.651, time=272, train_MAE=0.449, train_loss=0.516, val_MAE=0.619, val_loss=0.686]Epoch 36:   4%|▎         | 36/1000 [2:45:24<72:47:24, 271.83s/it, lr=6.25e-5, test_MAE=0.639, time=274, train_MAE=0.45, train_loss=0.517, val_MAE=0.61, val_loss=0.677]  Epoch 36:   4%|▎         | 37/1000 [2:45:24<72:54:16, 272.54s/it, lr=6.25e-5, test_MAE=0.639, time=274, train_MAE=0.45, train_loss=0.517, val_MAE=0.61, val_loss=0.677]Epoch 37:   4%|▎         | 37/1000 [2:45:24<72:54:16, 272.54s/it, lr=6.25e-5, test_MAE=0.639, time=274, train_MAE=0.45, train_loss=0.517, val_MAE=0.61, val_loss=0.677]Epoch 37:   4%|▎         | 37/1000 [2:50:03<72:54:16, 272.54s/it, lr=6.25e-5, test_MAE=0.64, time=279, train_MAE=0.433, train_loss=0.5, val_MAE=0.592, val_loss=0.659] Epoch 37:   4%|▍         | 38/1000 [2:50:03<73:20:31, 274.46s/it, lr=6.25e-5, test_MAE=0.64, time=279, train_MAE=0.433, train_loss=0.5, val_MAE=0.592, val_loss=0.659]Epoch 38:   4%|▍         | 38/1000 [2:50:03<73:20:31, 274.46s/it, lr=6.25e-5, test_MAE=0.64, time=279, train_MAE=0.433, train_loss=0.5, val_MAE=0.592, val_loss=0.659]Epoch 38:   4%|▍         | 38/1000 [2:54:37<73:20:31, 274.46s/it, lr=6.25e-5, test_MAE=0.627, time=274, train_MAE=0.436, train_loss=0.503, val_MAE=0.584, val_loss=0.651]Epoch 38:   4%|▍         | 39/1000 [2:54:37<73:14:04, 274.34s/it, lr=6.25e-5, test_MAE=0.627, time=274, train_MAE=0.436, train_loss=0.503, val_MAE=0.584, val_loss=0.651]Epoch 39:   4%|▍         | 39/1000 [2:54:37<73:14:04, 274.34s/it, lr=6.25e-5, test_MAE=0.627, time=274, train_MAE=0.436, train_loss=0.503, val_MAE=0.584, val_loss=0.651]Epoch 39:   4%|▍         | 39/1000 [2:59:06<73:14:04, 274.34s/it, lr=6.25e-5, test_MAE=0.644, time=269, train_MAE=0.422, train_loss=0.489, val_MAE=0.601, val_loss=0.668]Epoch    40: reducing learning rate of group 0 to 3.1250e-05.
Epoch 39:   4%|▍         | 40/1000 [2:59:06<72:45:14, 272.83s/it, lr=6.25e-5, test_MAE=0.644, time=269, train_MAE=0.422, train_loss=0.489, val_MAE=0.601, val_loss=0.668]Epoch 40:   4%|▍         | 40/1000 [2:59:06<72:45:14, 272.83s/it, lr=6.25e-5, test_MAE=0.644, time=269, train_MAE=0.422, train_loss=0.489, val_MAE=0.601, val_loss=0.668]Epoch 40:   4%|▍         | 40/1000 [3:03:37<72:45:14, 272.83s/it, lr=3.13e-5, test_MAE=0.621, time=270, train_MAE=0.419, train_loss=0.486, val_MAE=0.582, val_loss=0.649]Epoch 40:   4%|▍         | 41/1000 [3:03:37<72:28:20, 272.05s/it, lr=3.13e-5, test_MAE=0.621, time=270, train_MAE=0.419, train_loss=0.486, val_MAE=0.582, val_loss=0.649]Epoch 41:   4%|▍         | 41/1000 [3:03:37<72:28:20, 272.05s/it, lr=3.13e-5, test_MAE=0.621, time=270, train_MAE=0.419, train_loss=0.486, val_MAE=0.582, val_loss=0.649]Epoch 41:   4%|▍         | 41/1000 [3:08:06<72:28:20, 272.05s/it, lr=3.13e-5, test_MAE=0.637, time=269, train_MAE=0.413, train_loss=0.48, val_MAE=0.594, val_loss=0.661] Epoch 41:   4%|▍         | 42/1000 [3:08:06<72:08:51, 271.12s/it, lr=3.13e-5, test_MAE=0.637, time=269, train_MAE=0.413, train_loss=0.48, val_MAE=0.594, val_loss=0.661]Epoch 42:   4%|▍         | 42/1000 [3:08:06<72:08:51, 271.12s/it, lr=3.13e-5, test_MAE=0.637, time=269, train_MAE=0.413, train_loss=0.48, val_MAE=0.594, val_loss=0.661]Epoch 42:   4%|▍         | 42/1000 [3:12:33<72:08:51, 271.12s/it, lr=3.13e-5, test_MAE=0.626, time=267, train_MAE=0.423, train_loss=0.489, val_MAE=0.585, val_loss=0.652]Epoch 42:   4%|▍         | 43/1000 [3:12:33<71:45:54, 269.96s/it, lr=3.13e-5, test_MAE=0.626, time=267, train_MAE=0.423, train_loss=0.489, val_MAE=0.585, val_loss=0.652]Epoch 43:   4%|▍         | 43/1000 [3:12:33<71:45:54, 269.96s/it, lr=3.13e-5, test_MAE=0.626, time=267, train_MAE=0.423, train_loss=0.489, val_MAE=0.585, val_loss=0.652]Epoch 43:   4%|▍         | 43/1000 [3:16:50<71:45:54, 269.96s/it, lr=3.13e-5, test_MAE=0.633, time=257, train_MAE=0.41, train_loss=0.477, val_MAE=0.591, val_loss=0.658] Epoch 43:   4%|▍         | 44/1000 [3:16:50<70:40:34, 266.14s/it, lr=3.13e-5, test_MAE=0.633, time=257, train_MAE=0.41, train_loss=0.477, val_MAE=0.591, val_loss=0.658]Epoch 44:   4%|▍         | 44/1000 [3:16:50<70:40:34, 266.14s/it, lr=3.13e-5, test_MAE=0.633, time=257, train_MAE=0.41, train_loss=0.477, val_MAE=0.591, val_loss=0.658]Epoch 44:   4%|▍         | 44/1000 [3:21:01<70:40:34, 266.14s/it, lr=3.13e-5, test_MAE=0.624, time=251, train_MAE=0.406, train_loss=0.473, val_MAE=0.583, val_loss=0.65]Epoch 44:   4%|▍         | 45/1000 [3:21:01<69:22:06, 261.49s/it, lr=3.13e-5, test_MAE=0.624, time=251, train_MAE=0.406, train_loss=0.473, val_MAE=0.583, val_loss=0.65]Epoch 45:   4%|▍         | 45/1000 [3:21:01<69:22:06, 261.49s/it, lr=3.13e-5, test_MAE=0.624, time=251, train_MAE=0.406, train_loss=0.473, val_MAE=0.583, val_loss=0.65]Epoch 45:   4%|▍         | 45/1000 [3:25:12<69:22:06, 261.49s/it, lr=3.13e-5, test_MAE=0.628, time=251, train_MAE=0.409, train_loss=0.476, val_MAE=0.584, val_loss=0.651]Epoch 45:   5%|▍         | 46/1000 [3:25:12<68:27:12, 258.31s/it, lr=3.13e-5, test_MAE=0.628, time=251, train_MAE=0.409, train_loss=0.476, val_MAE=0.584, val_loss=0.651]Epoch 46:   5%|▍         | 46/1000 [3:25:12<68:27:12, 258.31s/it, lr=3.13e-5, test_MAE=0.628, time=251, train_MAE=0.409, train_loss=0.476, val_MAE=0.584, val_loss=0.651]Epoch 46:   5%|▍         | 46/1000 [3:29:23<68:27:12, 258.31s/it, lr=3.13e-5, test_MAE=0.629, time=252, train_MAE=0.408, train_loss=0.475, val_MAE=0.591, val_loss=0.658]Epoch    47: reducing learning rate of group 0 to 1.5625e-05.
Epoch 46:   5%|▍         | 47/1000 [3:29:23<67:51:35, 256.34s/it, lr=3.13e-5, test_MAE=0.629, time=252, train_MAE=0.408, train_loss=0.475, val_MAE=0.591, val_loss=0.658]Epoch 47:   5%|▍         | 47/1000 [3:29:23<67:51:35, 256.34s/it, lr=3.13e-5, test_MAE=0.629, time=252, train_MAE=0.408, train_loss=0.475, val_MAE=0.591, val_loss=0.658]Epoch 47:   5%|▍         | 47/1000 [3:33:34<67:51:35, 256.34s/it, lr=1.56e-5, test_MAE=0.635, time=250, train_MAE=0.405, train_loss=0.471, val_MAE=0.593, val_loss=0.66] Epoch 47:   5%|▍         | 48/1000 [3:33:34<67:18:57, 254.56s/it, lr=1.56e-5, test_MAE=0.635, time=250, train_MAE=0.405, train_loss=0.471, val_MAE=0.593, val_loss=0.66]Epoch 48:   5%|▍         | 48/1000 [3:33:34<67:18:57, 254.56s/it, lr=1.56e-5, test_MAE=0.635, time=250, train_MAE=0.405, train_loss=0.471, val_MAE=0.593, val_loss=0.66]Epoch 48:   5%|▍         | 48/1000 [3:37:45<67:18:57, 254.56s/it, lr=1.56e-5, test_MAE=0.631, time=251, train_MAE=0.398, train_loss=0.465, val_MAE=0.589, val_loss=0.656]Epoch 48:   5%|▍         | 49/1000 [3:37:45<66:58:03, 253.50s/it, lr=1.56e-5, test_MAE=0.631, time=251, train_MAE=0.398, train_loss=0.465, val_MAE=0.589, val_loss=0.656]Epoch 49:   5%|▍         | 49/1000 [3:37:45<66:58:03, 253.50s/it, lr=1.56e-5, test_MAE=0.631, time=251, train_MAE=0.398, train_loss=0.465, val_MAE=0.589, val_loss=0.656]Epoch 49:   5%|▍         | 49/1000 [3:41:57<66:58:03, 253.50s/it, lr=1.56e-5, test_MAE=0.64, time=252, train_MAE=0.397, train_loss=0.464, val_MAE=0.592, val_loss=0.659] Epoch 49:   5%|▌         | 50/1000 [3:41:57<66:45:28, 252.98s/it, lr=1.56e-5, test_MAE=0.64, time=252, train_MAE=0.397, train_loss=0.464, val_MAE=0.592, val_loss=0.659]Epoch 50:   5%|▌         | 50/1000 [3:41:57<66:45:28, 252.98s/it, lr=1.56e-5, test_MAE=0.64, time=252, train_MAE=0.397, train_loss=0.464, val_MAE=0.592, val_loss=0.659]Epoch 50:   5%|▌         | 50/1000 [3:46:07<66:45:28, 252.98s/it, lr=1.56e-5, test_MAE=0.641, time=250, train_MAE=0.399, train_loss=0.466, val_MAE=0.593, val_loss=0.66]Epoch 50:   5%|▌         | 51/1000 [3:46:07<66:28:36, 252.18s/it, lr=1.56e-5, test_MAE=0.641, time=250, train_MAE=0.399, train_loss=0.466, val_MAE=0.593, val_loss=0.66]Epoch 51:   5%|▌         | 51/1000 [3:46:07<66:28:36, 252.18s/it, lr=1.56e-5, test_MAE=0.641, time=250, train_MAE=0.399, train_loss=0.466, val_MAE=0.593, val_loss=0.66]Epoch 51:   5%|▌         | 51/1000 [3:50:18<66:28:36, 252.18s/it, lr=1.56e-5, test_MAE=0.643, time=251, train_MAE=0.389, train_loss=0.456, val_MAE=0.596, val_loss=0.663]Epoch 51:   5%|▌         | 52/1000 [3:50:18<66:18:05, 251.78s/it, lr=1.56e-5, test_MAE=0.643, time=251, train_MAE=0.389, train_loss=0.456, val_MAE=0.596, val_loss=0.663]Epoch 52:   5%|▌         | 52/1000 [3:50:18<66:18:05, 251.78s/it, lr=1.56e-5, test_MAE=0.643, time=251, train_MAE=0.389, train_loss=0.456, val_MAE=0.596, val_loss=0.663]Epoch 52:   5%|▌         | 52/1000 [3:54:30<66:18:05, 251.78s/it, lr=1.56e-5, test_MAE=0.63, time=252, train_MAE=0.388, train_loss=0.455, val_MAE=0.587, val_loss=0.654] Epoch    53: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 52:   5%|▌         | 52/1000 [3:54:30<71:15:07, 270.58s/it, lr=1.56e-5, test_MAE=0.63, time=252, train_MAE=0.388, train_loss=0.455, val_MAE=0.587, val_loss=0.654]
Test MAE: 0.6302
Train MAE: 0.3589
Convergence Time (Epochs): 52.0000
TOTAL TIME TAKEN: 14228.1471s
AVG TIME PER EPOCH: 265.4407s
