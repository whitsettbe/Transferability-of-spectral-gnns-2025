I'm echoing to stdout
I'm echoing to stderr
My JobID is 57722082
I have 8 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 4.9902s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 2, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'cheb02_vec', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_all', 'num_eigs': 16, 'bias_mode': 'spatial', 'eigval_hidden_dim': 5, 'eigval_num_hidden_layer': 3, 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 0.0, 'eigmod': 'rand_basis', 'eigInFiles': {'train': 'supp_data/molecules/aug07/zinc_train_rec.csv', 'test': 'supp_data/molecules/aug07/zinc_test_rec.csv', 'val': 'supp_data/molecules/aug07/zinc_val_rec.csv'}, 'fixMissingPhi1': False, 'extraOrtho': False, 'doublePrecision': True, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [01:09<?, ?it/s, lr=0.001, test_MAE=0.985, time=70, train_MAE=1.2, train_loss=1.2, val_MAE=0.936, val_loss=0.936]Epoch 0:   0%|          | 1/1000 [01:10<19:25:56, 70.03s/it, lr=0.001, test_MAE=0.985, time=70, train_MAE=1.2, train_loss=1.2, val_MAE=0.936, val_loss=0.936]Epoch 1:   0%|          | 1/1000 [01:10<19:25:56, 70.03s/it, lr=0.001, test_MAE=0.985, time=70, train_MAE=1.2, train_loss=1.2, val_MAE=0.936, val_loss=0.936]Epoch 1:   0%|          | 1/1000 [02:10<19:25:56, 70.03s/it, lr=0.001, test_MAE=0.906, time=60.5, train_MAE=0.941, train_loss=0.941, val_MAE=0.852, val_loss=0.852]Epoch 1:   0%|          | 2/1000 [02:10<18:37:28, 67.18s/it, lr=0.001, test_MAE=0.906, time=60.5, train_MAE=0.941, train_loss=0.941, val_MAE=0.852, val_loss=0.852]Epoch 2:   0%|          | 2/1000 [02:10<18:37:28, 67.18s/it, lr=0.001, test_MAE=0.906, time=60.5, train_MAE=0.941, train_loss=0.941, val_MAE=0.852, val_loss=0.852]Epoch 2:   0%|          | 2/1000 [03:11<18:37:28, 67.18s/it, lr=0.001, test_MAE=0.914, time=60.5, train_MAE=0.906, train_loss=0.906, val_MAE=0.831, val_loss=0.831]Epoch 2:   0%|          | 3/1000 [03:11<18:02:52, 65.17s/it, lr=0.001, test_MAE=0.914, time=60.5, train_MAE=0.906, train_loss=0.906, val_MAE=0.831, val_loss=0.831]Epoch 3:   0%|          | 3/1000 [03:11<18:02:52, 65.17s/it, lr=0.001, test_MAE=0.914, time=60.5, train_MAE=0.906, train_loss=0.906, val_MAE=0.831, val_loss=0.831]Epoch 3:   0%|          | 3/1000 [04:11<18:02:52, 65.17s/it, lr=0.001, test_MAE=0.829, time=60.8, train_MAE=0.841, train_loss=0.841, val_MAE=0.788, val_loss=0.788]Epoch 3:   0%|          | 4/1000 [04:11<17:40:02, 63.86s/it, lr=0.001, test_MAE=0.829, time=60.8, train_MAE=0.841, train_loss=0.841, val_MAE=0.788, val_loss=0.788]Epoch 4:   0%|          | 4/1000 [04:11<17:40:02, 63.86s/it, lr=0.001, test_MAE=0.829, time=60.8, train_MAE=0.841, train_loss=0.841, val_MAE=0.788, val_loss=0.788]Epoch 4:   0%|          | 4/1000 [05:11<17:40:02, 63.86s/it, lr=0.001, test_MAE=0.837, time=60, train_MAE=0.816, train_loss=0.816, val_MAE=0.786, val_loss=0.786]  Epoch 4:   0%|          | 5/1000 [05:11<17:20:06, 62.72s/it, lr=0.001, test_MAE=0.837, time=60, train_MAE=0.816, train_loss=0.816, val_MAE=0.786, val_loss=0.786]Epoch 5:   0%|          | 5/1000 [05:11<17:20:06, 62.72s/it, lr=0.001, test_MAE=0.837, time=60, train_MAE=0.816, train_loss=0.816, val_MAE=0.786, val_loss=0.786]Epoch 5:   0%|          | 5/1000 [06:12<17:20:06, 62.72s/it, lr=0.001, test_MAE=0.809, time=60.7, train_MAE=0.812, train_loss=0.812, val_MAE=0.765, val_loss=0.765]Epoch 5:   1%|          | 6/1000 [06:12<17:09:04, 62.12s/it, lr=0.001, test_MAE=0.809, time=60.7, train_MAE=0.812, train_loss=0.812, val_MAE=0.765, val_loss=0.765]Epoch 6:   1%|          | 6/1000 [06:12<17:09:04, 62.12s/it, lr=0.001, test_MAE=0.809, time=60.7, train_MAE=0.812, train_loss=0.812, val_MAE=0.765, val_loss=0.765]Epoch 6:   1%|          | 6/1000 [07:13<17:09:04, 62.12s/it, lr=0.001, test_MAE=0.797, time=60.4, train_MAE=0.782, train_loss=0.782, val_MAE=0.754, val_loss=0.754]Epoch 6:   1%|          | 7/1000 [07:13<16:59:36, 61.61s/it, lr=0.001, test_MAE=0.797, time=60.4, train_MAE=0.782, train_loss=0.782, val_MAE=0.754, val_loss=0.754]Epoch 7:   1%|          | 7/1000 [07:13<16:59:36, 61.61s/it, lr=0.001, test_MAE=0.797, time=60.4, train_MAE=0.782, train_loss=0.782, val_MAE=0.754, val_loss=0.754]Epoch 7:   1%|          | 7/1000 [08:13<16:59:36, 61.61s/it, lr=0.001, test_MAE=0.801, time=60.4, train_MAE=0.792, train_loss=0.792, val_MAE=0.768, val_loss=0.768]Epoch 7:   1%|          | 8/1000 [08:13<16:52:50, 61.26s/it, lr=0.001, test_MAE=0.801, time=60.4, train_MAE=0.792, train_loss=0.792, val_MAE=0.768, val_loss=0.768]Epoch 8:   1%|          | 8/1000 [08:13<16:52:50, 61.26s/it, lr=0.001, test_MAE=0.801, time=60.4, train_MAE=0.792, train_loss=0.792, val_MAE=0.768, val_loss=0.768]Epoch 8:   1%|          | 8/1000 [09:14<16:52:50, 61.26s/it, lr=0.001, test_MAE=0.797, time=60.6, train_MAE=0.751, train_loss=0.751, val_MAE=0.747, val_loss=0.747]Epoch 8:   1%|          | 9/1000 [09:14<16:48:47, 61.08s/it, lr=0.001, test_MAE=0.797, time=60.6, train_MAE=0.751, train_loss=0.751, val_MAE=0.747, val_loss=0.747]Epoch 9:   1%|          | 9/1000 [09:14<16:48:47, 61.08s/it, lr=0.001, test_MAE=0.797, time=60.6, train_MAE=0.751, train_loss=0.751, val_MAE=0.747, val_loss=0.747]Epoch 9:   1%|          | 9/1000 [10:15<16:48:47, 61.08s/it, lr=0.001, test_MAE=0.789, time=61, train_MAE=0.749, train_loss=0.749, val_MAE=0.747, val_loss=0.747]  Epoch 9:   1%|          | 10/1000 [10:15<16:47:36, 61.07s/it, lr=0.001, test_MAE=0.789, time=61, train_MAE=0.749, train_loss=0.749, val_MAE=0.747, val_loss=0.747]Epoch 10:   1%|          | 10/1000 [10:15<16:47:36, 61.07s/it, lr=0.001, test_MAE=0.789, time=61, train_MAE=0.749, train_loss=0.749, val_MAE=0.747, val_loss=0.747]Epoch 10:   1%|          | 10/1000 [11:15<16:47:36, 61.07s/it, lr=0.001, test_MAE=0.8, time=60.7, train_MAE=0.74, train_loss=0.74, val_MAE=0.754, val_loss=0.754]  Epoch 10:   1%|          | 11/1000 [11:15<16:45:00, 60.97s/it, lr=0.001, test_MAE=0.8, time=60.7, train_MAE=0.74, train_loss=0.74, val_MAE=0.754, val_loss=0.754]Epoch 11:   1%|          | 11/1000 [11:15<16:45:00, 60.97s/it, lr=0.001, test_MAE=0.8, time=60.7, train_MAE=0.74, train_loss=0.74, val_MAE=0.754, val_loss=0.754]Epoch 11:   1%|          | 11/1000 [12:18<16:45:00, 60.97s/it, lr=0.001, test_MAE=0.922, time=62.3, train_MAE=0.75, train_loss=0.75, val_MAE=0.855, val_loss=0.855]Epoch 11:   1%|          | 12/1000 [12:18<16:50:38, 61.38s/it, lr=0.001, test_MAE=0.922, time=62.3, train_MAE=0.75, train_loss=0.75, val_MAE=0.855, val_loss=0.855]Epoch 12:   1%|          | 12/1000 [12:18<16:50:38, 61.38s/it, lr=0.001, test_MAE=0.922, time=62.3, train_MAE=0.75, train_loss=0.75, val_MAE=0.855, val_loss=0.855]Epoch 12:   1%|          | 12/1000 [13:20<16:50:38, 61.38s/it, lr=0.001, test_MAE=0.865, time=62.1, train_MAE=0.757, train_loss=0.757, val_MAE=0.826, val_loss=0.826]Epoch 12:   1%|▏         | 13/1000 [13:20<16:53:09, 61.59s/it, lr=0.001, test_MAE=0.865, time=62.1, train_MAE=0.757, train_loss=0.757, val_MAE=0.826, val_loss=0.826]Epoch 13:   1%|▏         | 13/1000 [13:20<16:53:09, 61.59s/it, lr=0.001, test_MAE=0.865, time=62.1, train_MAE=0.757, train_loss=0.757, val_MAE=0.826, val_loss=0.826]Epoch 13:   1%|▏         | 13/1000 [14:21<16:53:09, 61.59s/it, lr=0.001, test_MAE=0.794, time=61.5, train_MAE=0.731, train_loss=0.731, val_MAE=0.747, val_loss=0.747]Epoch 13:   1%|▏         | 14/1000 [14:21<16:51:33, 61.55s/it, lr=0.001, test_MAE=0.794, time=61.5, train_MAE=0.731, train_loss=0.731, val_MAE=0.747, val_loss=0.747]Epoch 14:   1%|▏         | 14/1000 [14:21<16:51:33, 61.55s/it, lr=0.001, test_MAE=0.794, time=61.5, train_MAE=0.731, train_loss=0.731, val_MAE=0.747, val_loss=0.747]Epoch 14:   1%|▏         | 14/1000 [15:24<16:51:33, 61.55s/it, lr=0.001, test_MAE=0.759, time=62.2, train_MAE=0.706, train_loss=0.706, val_MAE=0.71, val_loss=0.71]  Epoch 14:   2%|▏         | 15/1000 [15:24<16:53:49, 61.76s/it, lr=0.001, test_MAE=0.759, time=62.2, train_MAE=0.706, train_loss=0.706, val_MAE=0.71, val_loss=0.71]Epoch 15:   2%|▏         | 15/1000 [15:24<16:53:49, 61.76s/it, lr=0.001, test_MAE=0.759, time=62.2, train_MAE=0.706, train_loss=0.706, val_MAE=0.71, val_loss=0.71]Epoch 15:   2%|▏         | 15/1000 [16:25<16:53:49, 61.76s/it, lr=0.001, test_MAE=0.79, time=61.8, train_MAE=0.726, train_loss=0.726, val_MAE=0.755, val_loss=0.755]Epoch 15:   2%|▏         | 16/1000 [16:25<16:53:18, 61.79s/it, lr=0.001, test_MAE=0.79, time=61.8, train_MAE=0.726, train_loss=0.726, val_MAE=0.755, val_loss=0.755]Epoch 16:   2%|▏         | 16/1000 [16:25<16:53:18, 61.79s/it, lr=0.001, test_MAE=0.79, time=61.8, train_MAE=0.726, train_loss=0.726, val_MAE=0.755, val_loss=0.755]Epoch 16:   2%|▏         | 16/1000 [17:27<16:53:18, 61.79s/it, lr=0.001, test_MAE=0.8, time=61.5, train_MAE=0.736, train_loss=0.736, val_MAE=0.758, val_loss=0.758] Epoch 16:   2%|▏         | 17/1000 [17:27<16:50:52, 61.70s/it, lr=0.001, test_MAE=0.8, time=61.5, train_MAE=0.736, train_loss=0.736, val_MAE=0.758, val_loss=0.758]Epoch 17:   2%|▏         | 17/1000 [17:27<16:50:52, 61.70s/it, lr=0.001, test_MAE=0.8, time=61.5, train_MAE=0.736, train_loss=0.736, val_MAE=0.758, val_loss=0.758]Epoch 17:   2%|▏         | 17/1000 [18:29<16:50:52, 61.70s/it, lr=0.001, test_MAE=0.751, time=62.1, train_MAE=0.719, train_loss=0.719, val_MAE=0.707, val_loss=0.707]Epoch 17:   2%|▏         | 18/1000 [18:29<16:52:02, 61.84s/it, lr=0.001, test_MAE=0.751, time=62.1, train_MAE=0.719, train_loss=0.719, val_MAE=0.707, val_loss=0.707]Epoch 18:   2%|▏         | 18/1000 [18:29<16:52:02, 61.84s/it, lr=0.001, test_MAE=0.751, time=62.1, train_MAE=0.719, train_loss=0.719, val_MAE=0.707, val_loss=0.707]Epoch 18:   2%|▏         | 18/1000 [19:31<16:52:02, 61.84s/it, lr=0.001, test_MAE=0.779, time=61.7, train_MAE=0.703, train_loss=0.703, val_MAE=0.726, val_loss=0.726]Epoch 18:   2%|▏         | 19/1000 [19:31<16:50:23, 61.80s/it, lr=0.001, test_MAE=0.779, time=61.7, train_MAE=0.703, train_loss=0.703, val_MAE=0.726, val_loss=0.726]Epoch 19:   2%|▏         | 19/1000 [19:31<16:50:23, 61.80s/it, lr=0.001, test_MAE=0.779, time=61.7, train_MAE=0.703, train_loss=0.703, val_MAE=0.726, val_loss=0.726]Epoch 19:   2%|▏         | 19/1000 [20:32<16:50:23, 61.80s/it, lr=0.001, test_MAE=0.742, time=61.4, train_MAE=0.695, train_loss=0.695, val_MAE=0.71, val_loss=0.71]  Epoch 19:   2%|▏         | 20/1000 [20:32<16:47:26, 61.68s/it, lr=0.001, test_MAE=0.742, time=61.4, train_MAE=0.695, train_loss=0.695, val_MAE=0.71, val_loss=0.71]Epoch 20:   2%|▏         | 20/1000 [20:32<16:47:26, 61.68s/it, lr=0.001, test_MAE=0.742, time=61.4, train_MAE=0.695, train_loss=0.695, val_MAE=0.71, val_loss=0.71]Epoch 20:   2%|▏         | 20/1000 [21:34<16:47:26, 61.68s/it, lr=0.001, test_MAE=0.752, time=62, train_MAE=0.695, train_loss=0.695, val_MAE=0.71, val_loss=0.71]  Epoch 20:   2%|▏         | 21/1000 [21:34<16:48:10, 61.79s/it, lr=0.001, test_MAE=0.752, time=62, train_MAE=0.695, train_loss=0.695, val_MAE=0.71, val_loss=0.71]Epoch 21:   2%|▏         | 21/1000 [21:34<16:48:10, 61.79s/it, lr=0.001, test_MAE=0.752, time=62, train_MAE=0.695, train_loss=0.695, val_MAE=0.71, val_loss=0.71]Epoch 21:   2%|▏         | 21/1000 [22:36<16:48:10, 61.79s/it, lr=0.001, test_MAE=0.752, time=61.7, train_MAE=0.685, train_loss=0.685, val_MAE=0.701, val_loss=0.701]Epoch 21:   2%|▏         | 22/1000 [22:36<16:46:57, 61.78s/it, lr=0.001, test_MAE=0.752, time=61.7, train_MAE=0.685, train_loss=0.685, val_MAE=0.701, val_loss=0.701]Epoch 22:   2%|▏         | 22/1000 [22:36<16:46:57, 61.78s/it, lr=0.001, test_MAE=0.752, time=61.7, train_MAE=0.685, train_loss=0.685, val_MAE=0.701, val_loss=0.701]Epoch 22:   2%|▏         | 22/1000 [23:38<16:46:57, 61.78s/it, lr=0.001, test_MAE=0.758, time=61.8, train_MAE=0.68, train_loss=0.68, val_MAE=0.714, val_loss=0.714]  Epoch 22:   2%|▏         | 23/1000 [23:38<16:46:02, 61.78s/it, lr=0.001, test_MAE=0.758, time=61.8, train_MAE=0.68, train_loss=0.68, val_MAE=0.714, val_loss=0.714]Epoch 23:   2%|▏         | 23/1000 [23:38<16:46:02, 61.78s/it, lr=0.001, test_MAE=0.758, time=61.8, train_MAE=0.68, train_loss=0.68, val_MAE=0.714, val_loss=0.714]Epoch 23:   2%|▏         | 23/1000 [24:40<16:46:02, 61.78s/it, lr=0.001, test_MAE=0.74, time=62, train_MAE=0.676, train_loss=0.676, val_MAE=0.713, val_loss=0.713] Epoch 23:   2%|▏         | 24/1000 [24:40<16:46:21, 61.87s/it, lr=0.001, test_MAE=0.74, time=62, train_MAE=0.676, train_loss=0.676, val_MAE=0.713, val_loss=0.713]Epoch 24:   2%|▏         | 24/1000 [24:40<16:46:21, 61.87s/it, lr=0.001, test_MAE=0.74, time=62, train_MAE=0.676, train_loss=0.676, val_MAE=0.713, val_loss=0.713]Epoch 24:   2%|▏         | 24/1000 [25:41<16:46:21, 61.87s/it, lr=0.001, test_MAE=0.74, time=61.7, train_MAE=0.686, train_loss=0.686, val_MAE=0.71, val_loss=0.71]Epoch 24:   2%|▎         | 25/1000 [25:41<16:44:24, 61.81s/it, lr=0.001, test_MAE=0.74, time=61.7, train_MAE=0.686, train_loss=0.686, val_MAE=0.71, val_loss=0.71]Epoch 25:   2%|▎         | 25/1000 [25:41<16:44:24, 61.81s/it, lr=0.001, test_MAE=0.74, time=61.7, train_MAE=0.686, train_loss=0.686, val_MAE=0.71, val_loss=0.71]Epoch 25:   2%|▎         | 25/1000 [26:44<16:44:24, 61.81s/it, lr=0.001, test_MAE=0.757, time=62.1, train_MAE=0.699, train_loss=0.699, val_MAE=0.719, val_loss=0.719]Epoch 25:   3%|▎         | 26/1000 [26:44<16:44:47, 61.90s/it, lr=0.001, test_MAE=0.757, time=62.1, train_MAE=0.699, train_loss=0.699, val_MAE=0.719, val_loss=0.719]Epoch 26:   3%|▎         | 26/1000 [26:44<16:44:47, 61.90s/it, lr=0.001, test_MAE=0.757, time=62.1, train_MAE=0.699, train_loss=0.699, val_MAE=0.719, val_loss=0.719]Epoch 26:   3%|▎         | 26/1000 [27:45<16:44:47, 61.90s/it, lr=0.001, test_MAE=0.752, time=61.8, train_MAE=0.664, train_loss=0.664, val_MAE=0.718, val_loss=0.718]Epoch 26:   3%|▎         | 27/1000 [27:45<16:43:09, 61.86s/it, lr=0.001, test_MAE=0.752, time=61.8, train_MAE=0.664, train_loss=0.664, val_MAE=0.718, val_loss=0.718]Epoch 27:   3%|▎         | 27/1000 [27:45<16:43:09, 61.86s/it, lr=0.001, test_MAE=0.752, time=61.8, train_MAE=0.664, train_loss=0.664, val_MAE=0.718, val_loss=0.718]Epoch 27:   3%|▎         | 27/1000 [28:47<16:43:09, 61.86s/it, lr=0.001, test_MAE=0.746, time=62.1, train_MAE=0.681, train_loss=0.681, val_MAE=0.697, val_loss=0.697]Epoch 27:   3%|▎         | 28/1000 [28:47<16:43:23, 61.94s/it, lr=0.001, test_MAE=0.746, time=62.1, train_MAE=0.681, train_loss=0.681, val_MAE=0.697, val_loss=0.697]Epoch 28:   3%|▎         | 28/1000 [28:47<16:43:23, 61.94s/it, lr=0.001, test_MAE=0.746, time=62.1, train_MAE=0.681, train_loss=0.681, val_MAE=0.697, val_loss=0.697]Epoch 28:   3%|▎         | 28/1000 [29:49<16:43:23, 61.94s/it, lr=0.001, test_MAE=0.771, time=61.4, train_MAE=0.668, train_loss=0.668, val_MAE=0.72, val_loss=0.72]  Epoch 28:   3%|▎         | 29/1000 [29:49<16:39:43, 61.77s/it, lr=0.001, test_MAE=0.771, time=61.4, train_MAE=0.668, train_loss=0.668, val_MAE=0.72, val_loss=0.72]Epoch 29:   3%|▎         | 29/1000 [29:49<16:39:43, 61.77s/it, lr=0.001, test_MAE=0.771, time=61.4, train_MAE=0.668, train_loss=0.668, val_MAE=0.72, val_loss=0.72]Epoch 29:   3%|▎         | 29/1000 [30:51<16:39:43, 61.77s/it, lr=0.001, test_MAE=0.739, time=62, train_MAE=0.664, train_loss=0.664, val_MAE=0.704, val_loss=0.704]Epoch 29:   3%|▎         | 30/1000 [30:51<16:39:53, 61.85s/it, lr=0.001, test_MAE=0.739, time=62, train_MAE=0.664, train_loss=0.664, val_MAE=0.704, val_loss=0.704]Epoch 30:   3%|▎         | 30/1000 [30:51<16:39:53, 61.85s/it, lr=0.001, test_MAE=0.739, time=62, train_MAE=0.664, train_loss=0.664, val_MAE=0.704, val_loss=0.704]Epoch 30:   3%|▎         | 30/1000 [31:53<16:39:53, 61.85s/it, lr=0.001, test_MAE=0.78, time=62, train_MAE=0.654, train_loss=0.654, val_MAE=0.751, val_loss=0.751] Epoch 30:   3%|▎         | 31/1000 [31:53<16:39:34, 61.89s/it, lr=0.001, test_MAE=0.78, time=62, train_MAE=0.654, train_loss=0.654, val_MAE=0.751, val_loss=0.751]Epoch 31:   3%|▎         | 31/1000 [31:53<16:39:34, 61.89s/it, lr=0.001, test_MAE=0.78, time=62, train_MAE=0.654, train_loss=0.654, val_MAE=0.751, val_loss=0.751]Epoch 31:   3%|▎         | 31/1000 [32:54<16:39:34, 61.89s/it, lr=0.001, test_MAE=0.74, time=61.4, train_MAE=0.659, train_loss=0.659, val_MAE=0.7, val_loss=0.7]  Epoch 31:   3%|▎         | 32/1000 [32:54<16:36:05, 61.74s/it, lr=0.001, test_MAE=0.74, time=61.4, train_MAE=0.659, train_loss=0.659, val_MAE=0.7, val_loss=0.7]Epoch 32:   3%|▎         | 32/1000 [32:54<16:36:05, 61.74s/it, lr=0.001, test_MAE=0.74, time=61.4, train_MAE=0.659, train_loss=0.659, val_MAE=0.7, val_loss=0.7]Epoch 32:   3%|▎         | 32/1000 [33:56<16:36:05, 61.74s/it, lr=0.001, test_MAE=0.729, time=61.9, train_MAE=0.653, train_loss=0.653, val_MAE=0.698, val_loss=0.698]Epoch 32:   3%|▎         | 33/1000 [33:56<16:35:59, 61.80s/it, lr=0.001, test_MAE=0.729, time=61.9, train_MAE=0.653, train_loss=0.653, val_MAE=0.698, val_loss=0.698]Epoch 33:   3%|▎         | 33/1000 [33:56<16:35:59, 61.80s/it, lr=0.001, test_MAE=0.729, time=61.9, train_MAE=0.653, train_loss=0.653, val_MAE=0.698, val_loss=0.698]Epoch 33:   3%|▎         | 33/1000 [34:58<16:35:59, 61.80s/it, lr=0.001, test_MAE=0.764, time=61.7, train_MAE=0.659, train_loss=0.659, val_MAE=0.739, val_loss=0.739]Epoch    34: reducing learning rate of group 0 to 5.0000e-04.
Epoch 33:   3%|▎         | 34/1000 [34:58<16:34:45, 61.79s/it, lr=0.001, test_MAE=0.764, time=61.7, train_MAE=0.659, train_loss=0.659, val_MAE=0.739, val_loss=0.739]Epoch 34:   3%|▎         | 34/1000 [34:58<16:34:45, 61.79s/it, lr=0.001, test_MAE=0.764, time=61.7, train_MAE=0.659, train_loss=0.659, val_MAE=0.739, val_loss=0.739]Epoch 34:   3%|▎         | 34/1000 [36:00<16:34:45, 61.79s/it, lr=0.0005, test_MAE=0.723, time=61.7, train_MAE=0.642, train_loss=0.642, val_MAE=0.691, val_loss=0.691]Epoch 34:   4%|▎         | 35/1000 [36:00<16:33:27, 61.77s/it, lr=0.0005, test_MAE=0.723, time=61.7, train_MAE=0.642, train_loss=0.642, val_MAE=0.691, val_loss=0.691]Epoch 35:   4%|▎         | 35/1000 [36:00<16:33:27, 61.77s/it, lr=0.0005, test_MAE=0.723, time=61.7, train_MAE=0.642, train_loss=0.642, val_MAE=0.691, val_loss=0.691]Epoch 35:   4%|▎         | 35/1000 [37:02<16:33:27, 61.77s/it, lr=0.0005, test_MAE=0.731, time=62, train_MAE=0.633, train_loss=0.633, val_MAE=0.692, val_loss=0.692]  Epoch 35:   4%|▎         | 36/1000 [37:02<16:33:45, 61.85s/it, lr=0.0005, test_MAE=0.731, time=62, train_MAE=0.633, train_loss=0.633, val_MAE=0.692, val_loss=0.692]Epoch 36:   4%|▎         | 36/1000 [37:02<16:33:45, 61.85s/it, lr=0.0005, test_MAE=0.731, time=62, train_MAE=0.633, train_loss=0.633, val_MAE=0.692, val_loss=0.692]Epoch 36:   4%|▎         | 36/1000 [38:04<16:33:45, 61.85s/it, lr=0.0005, test_MAE=0.719, time=61.8, train_MAE=0.63, train_loss=0.63, val_MAE=0.688, val_loss=0.688]Epoch 36:   4%|▎         | 37/1000 [38:04<16:32:29, 61.84s/it, lr=0.0005, test_MAE=0.719, time=61.8, train_MAE=0.63, train_loss=0.63, val_MAE=0.688, val_loss=0.688]Epoch 37:   4%|▎         | 37/1000 [38:04<16:32:29, 61.84s/it, lr=0.0005, test_MAE=0.719, time=61.8, train_MAE=0.63, train_loss=0.63, val_MAE=0.688, val_loss=0.688]Epoch 37:   4%|▎         | 37/1000 [39:05<16:32:29, 61.84s/it, lr=0.0005, test_MAE=0.726, time=61.7, train_MAE=0.628, train_loss=0.628, val_MAE=0.694, val_loss=0.694]Epoch 37:   4%|▍         | 38/1000 [39:05<16:30:47, 61.80s/it, lr=0.0005, test_MAE=0.726, time=61.7, train_MAE=0.628, train_loss=0.628, val_MAE=0.694, val_loss=0.694]Epoch 38:   4%|▍         | 38/1000 [39:05<16:30:47, 61.80s/it, lr=0.0005, test_MAE=0.726, time=61.7, train_MAE=0.628, train_loss=0.628, val_MAE=0.694, val_loss=0.694]Epoch 38:   4%|▍         | 38/1000 [40:07<16:30:47, 61.80s/it, lr=0.0005, test_MAE=0.718, time=62, train_MAE=0.622, train_loss=0.622, val_MAE=0.688, val_loss=0.688]  Epoch 38:   4%|▍         | 39/1000 [40:07<16:30:47, 61.86s/it, lr=0.0005, test_MAE=0.718, time=62, train_MAE=0.622, train_loss=0.622, val_MAE=0.688, val_loss=0.688]Epoch 39:   4%|▍         | 39/1000 [40:07<16:30:47, 61.86s/it, lr=0.0005, test_MAE=0.718, time=62, train_MAE=0.622, train_loss=0.622, val_MAE=0.688, val_loss=0.688]Epoch 39:   4%|▍         | 39/1000 [41:09<16:30:47, 61.86s/it, lr=0.0005, test_MAE=0.736, time=61.7, train_MAE=0.622, train_loss=0.622, val_MAE=0.697, val_loss=0.697]Epoch 39:   4%|▍         | 40/1000 [41:09<16:29:01, 61.81s/it, lr=0.0005, test_MAE=0.736, time=61.7, train_MAE=0.622, train_loss=0.622, val_MAE=0.697, val_loss=0.697]Epoch 40:   4%|▍         | 40/1000 [41:09<16:29:01, 61.81s/it, lr=0.0005, test_MAE=0.736, time=61.7, train_MAE=0.622, train_loss=0.622, val_MAE=0.697, val_loss=0.697]Epoch 40:   4%|▍         | 40/1000 [42:10<16:29:01, 61.81s/it, lr=0.0005, test_MAE=0.722, time=61.3, train_MAE=0.631, train_loss=0.631, val_MAE=0.695, val_loss=0.695]Epoch 40:   4%|▍         | 41/1000 [42:10<16:25:33, 61.66s/it, lr=0.0005, test_MAE=0.722, time=61.3, train_MAE=0.631, train_loss=0.631, val_MAE=0.695, val_loss=0.695]Epoch 41:   4%|▍         | 41/1000 [42:10<16:25:33, 61.66s/it, lr=0.0005, test_MAE=0.722, time=61.3, train_MAE=0.631, train_loss=0.631, val_MAE=0.695, val_loss=0.695]Epoch 41:   4%|▍         | 41/1000 [43:12<16:25:33, 61.66s/it, lr=0.0005, test_MAE=0.731, time=62.2, train_MAE=0.618, train_loss=0.618, val_MAE=0.696, val_loss=0.696]Epoch 41:   4%|▍         | 42/1000 [43:12<16:26:57, 61.81s/it, lr=0.0005, test_MAE=0.731, time=62.2, train_MAE=0.618, train_loss=0.618, val_MAE=0.696, val_loss=0.696]Epoch 42:   4%|▍         | 42/1000 [43:12<16:26:57, 61.81s/it, lr=0.0005, test_MAE=0.731, time=62.2, train_MAE=0.618, train_loss=0.618, val_MAE=0.696, val_loss=0.696]Epoch 42:   4%|▍         | 42/1000 [44:14<16:26:57, 61.81s/it, lr=0.0005, test_MAE=0.723, time=62, train_MAE=0.627, train_loss=0.627, val_MAE=0.695, val_loss=0.695]  Epoch    43: reducing learning rate of group 0 to 2.5000e-04.
Epoch 42:   4%|▍         | 43/1000 [44:14<16:26:53, 61.87s/it, lr=0.0005, test_MAE=0.723, time=62, train_MAE=0.627, train_loss=0.627, val_MAE=0.695, val_loss=0.695]Epoch 43:   4%|▍         | 43/1000 [44:14<16:26:53, 61.87s/it, lr=0.0005, test_MAE=0.723, time=62, train_MAE=0.627, train_loss=0.627, val_MAE=0.695, val_loss=0.695]Epoch 43:   4%|▍         | 43/1000 [45:16<16:26:53, 61.87s/it, lr=0.00025, test_MAE=0.722, time=61.3, train_MAE=0.605, train_loss=0.605, val_MAE=0.697, val_loss=0.697]Epoch 43:   4%|▍         | 44/1000 [45:16<16:23:04, 61.70s/it, lr=0.00025, test_MAE=0.722, time=61.3, train_MAE=0.605, train_loss=0.605, val_MAE=0.697, val_loss=0.697]Epoch 44:   4%|▍         | 44/1000 [45:16<16:23:04, 61.70s/it, lr=0.00025, test_MAE=0.722, time=61.3, train_MAE=0.605, train_loss=0.605, val_MAE=0.697, val_loss=0.697]Epoch 44:   4%|▍         | 44/1000 [46:17<16:23:04, 61.70s/it, lr=0.00025, test_MAE=0.716, time=61.3, train_MAE=0.603, train_loss=0.603, val_MAE=0.692, val_loss=0.692]Epoch 44:   4%|▍         | 45/1000 [46:17<16:19:58, 61.57s/it, lr=0.00025, test_MAE=0.716, time=61.3, train_MAE=0.603, train_loss=0.603, val_MAE=0.692, val_loss=0.692]Epoch 45:   4%|▍         | 45/1000 [46:17<16:19:58, 61.57s/it, lr=0.00025, test_MAE=0.716, time=61.3, train_MAE=0.603, train_loss=0.603, val_MAE=0.692, val_loss=0.692]Epoch 45:   4%|▍         | 45/1000 [47:19<16:19:58, 61.57s/it, lr=0.00025, test_MAE=0.719, time=61.9, train_MAE=0.6, train_loss=0.6, val_MAE=0.69, val_loss=0.69]      Epoch 45:   5%|▍         | 46/1000 [47:19<16:20:38, 61.68s/it, lr=0.00025, test_MAE=0.719, time=61.9, train_MAE=0.6, train_loss=0.6, val_MAE=0.69, val_loss=0.69]Epoch 46:   5%|▍         | 46/1000 [47:19<16:20:38, 61.68s/it, lr=0.00025, test_MAE=0.719, time=61.9, train_MAE=0.6, train_loss=0.6, val_MAE=0.69, val_loss=0.69]Epoch 46:   5%|▍         | 46/1000 [48:21<16:20:38, 61.68s/it, lr=0.00025, test_MAE=0.729, time=62, train_MAE=0.597, train_loss=0.597, val_MAE=0.697, val_loss=0.697]Epoch 46:   5%|▍         | 47/1000 [48:21<16:21:12, 61.78s/it, lr=0.00025, test_MAE=0.729, time=62, train_MAE=0.597, train_loss=0.597, val_MAE=0.697, val_loss=0.697]Epoch 47:   5%|▍         | 47/1000 [48:21<16:21:12, 61.78s/it, lr=0.00025, test_MAE=0.729, time=62, train_MAE=0.597, train_loss=0.597, val_MAE=0.697, val_loss=0.697]Epoch 47:   5%|▍         | 47/1000 [49:22<16:21:12, 61.78s/it, lr=0.00025, test_MAE=0.719, time=61.3, train_MAE=0.599, train_loss=0.599, val_MAE=0.692, val_loss=0.692]Epoch 47:   5%|▍         | 48/1000 [49:22<16:17:52, 61.63s/it, lr=0.00025, test_MAE=0.719, time=61.3, train_MAE=0.599, train_loss=0.599, val_MAE=0.692, val_loss=0.692]Epoch 48:   5%|▍         | 48/1000 [49:22<16:17:52, 61.63s/it, lr=0.00025, test_MAE=0.719, time=61.3, train_MAE=0.599, train_loss=0.599, val_MAE=0.692, val_loss=0.692]Epoch 48:   5%|▍         | 48/1000 [50:24<16:17:52, 61.63s/it, lr=0.00025, test_MAE=0.718, time=62, train_MAE=0.596, train_loss=0.596, val_MAE=0.685, val_loss=0.685]  Epoch 48:   5%|▍         | 49/1000 [50:24<16:18:27, 61.73s/it, lr=0.00025, test_MAE=0.718, time=62, train_MAE=0.596, train_loss=0.596, val_MAE=0.685, val_loss=0.685]Epoch 49:   5%|▍         | 49/1000 [50:24<16:18:27, 61.73s/it, lr=0.00025, test_MAE=0.718, time=62, train_MAE=0.596, train_loss=0.596, val_MAE=0.685, val_loss=0.685]Epoch 49:   5%|▍         | 49/1000 [51:26<16:18:27, 61.73s/it, lr=0.00025, test_MAE=0.727, time=61.8, train_MAE=0.599, train_loss=0.599, val_MAE=0.702, val_loss=0.702]Epoch 49:   5%|▌         | 50/1000 [51:26<16:17:37, 61.74s/it, lr=0.00025, test_MAE=0.727, time=61.8, train_MAE=0.599, train_loss=0.599, val_MAE=0.702, val_loss=0.702]Epoch 50:   5%|▌         | 50/1000 [51:26<16:17:37, 61.74s/it, lr=0.00025, test_MAE=0.727, time=61.8, train_MAE=0.599, train_loss=0.599, val_MAE=0.702, val_loss=0.702]Epoch 50:   5%|▌         | 50/1000 [52:28<16:17:37, 61.74s/it, lr=0.00025, test_MAE=0.724, time=61.7, train_MAE=0.596, train_loss=0.596, val_MAE=0.69, val_loss=0.69]  Epoch 50:   5%|▌         | 51/1000 [52:28<16:16:34, 61.74s/it, lr=0.00025, test_MAE=0.724, time=61.7, train_MAE=0.596, train_loss=0.596, val_MAE=0.69, val_loss=0.69]Epoch 51:   5%|▌         | 51/1000 [52:28<16:16:34, 61.74s/it, lr=0.00025, test_MAE=0.724, time=61.7, train_MAE=0.596, train_loss=0.596, val_MAE=0.69, val_loss=0.69]Epoch 51:   5%|▌         | 51/1000 [53:30<16:16:34, 61.74s/it, lr=0.00025, test_MAE=0.718, time=61.9, train_MAE=0.593, train_loss=0.593, val_MAE=0.689, val_loss=0.689]Epoch 51:   5%|▌         | 52/1000 [53:30<16:16:21, 61.79s/it, lr=0.00025, test_MAE=0.718, time=61.9, train_MAE=0.593, train_loss=0.593, val_MAE=0.689, val_loss=0.689]Epoch 52:   5%|▌         | 52/1000 [53:30<16:16:21, 61.79s/it, lr=0.00025, test_MAE=0.718, time=61.9, train_MAE=0.593, train_loss=0.593, val_MAE=0.689, val_loss=0.689]Epoch 52:   5%|▌         | 52/1000 [54:31<16:16:21, 61.79s/it, lr=0.00025, test_MAE=0.718, time=61.7, train_MAE=0.59, train_loss=0.59, val_MAE=0.688, val_loss=0.688]  Epoch 52:   5%|▌         | 53/1000 [54:31<16:15:00, 61.77s/it, lr=0.00025, test_MAE=0.718, time=61.7, train_MAE=0.59, train_loss=0.59, val_MAE=0.688, val_loss=0.688]Epoch 53:   5%|▌         | 53/1000 [54:31<16:15:00, 61.77s/it, lr=0.00025, test_MAE=0.718, time=61.7, train_MAE=0.59, train_loss=0.59, val_MAE=0.688, val_loss=0.688]Epoch 53:   5%|▌         | 53/1000 [55:33<16:15:00, 61.77s/it, lr=0.00025, test_MAE=0.722, time=61.8, train_MAE=0.593, train_loss=0.593, val_MAE=0.686, val_loss=0.686]Epoch 53:   5%|▌         | 54/1000 [55:33<16:13:57, 61.77s/it, lr=0.00025, test_MAE=0.722, time=61.8, train_MAE=0.593, train_loss=0.593, val_MAE=0.686, val_loss=0.686]Epoch 54:   5%|▌         | 54/1000 [55:33<16:13:57, 61.77s/it, lr=0.00025, test_MAE=0.722, time=61.8, train_MAE=0.593, train_loss=0.593, val_MAE=0.686, val_loss=0.686]Epoch 54:   5%|▌         | 54/1000 [56:35<16:13:57, 61.77s/it, lr=0.00025, test_MAE=0.727, time=61.9, train_MAE=0.597, train_loss=0.597, val_MAE=0.694, val_loss=0.694]Epoch    55: reducing learning rate of group 0 to 1.2500e-04.
Epoch 54:   6%|▌         | 55/1000 [56:35<16:13:47, 61.83s/it, lr=0.00025, test_MAE=0.727, time=61.9, train_MAE=0.597, train_loss=0.597, val_MAE=0.694, val_loss=0.694]Epoch 55:   6%|▌         | 55/1000 [56:35<16:13:47, 61.83s/it, lr=0.00025, test_MAE=0.727, time=61.9, train_MAE=0.597, train_loss=0.597, val_MAE=0.694, val_loss=0.694]Epoch 55:   6%|▌         | 55/1000 [57:37<16:13:47, 61.83s/it, lr=0.000125, test_MAE=0.721, time=61.9, train_MAE=0.583, train_loss=0.583, val_MAE=0.684, val_loss=0.684]Epoch 55:   6%|▌         | 56/1000 [57:37<16:13:08, 61.85s/it, lr=0.000125, test_MAE=0.721, time=61.9, train_MAE=0.583, train_loss=0.583, val_MAE=0.684, val_loss=0.684]Epoch 56:   6%|▌         | 56/1000 [57:37<16:13:08, 61.85s/it, lr=0.000125, test_MAE=0.721, time=61.9, train_MAE=0.583, train_loss=0.583, val_MAE=0.684, val_loss=0.684]Epoch 56:   6%|▌         | 56/1000 [58:38<16:13:08, 61.85s/it, lr=0.000125, test_MAE=0.722, time=61.3, train_MAE=0.581, train_loss=0.581, val_MAE=0.689, val_loss=0.689]Epoch 56:   6%|▌         | 57/1000 [58:38<16:09:43, 61.70s/it, lr=0.000125, test_MAE=0.722, time=61.3, train_MAE=0.581, train_loss=0.581, val_MAE=0.689, val_loss=0.689]Epoch 57:   6%|▌         | 57/1000 [58:38<16:09:43, 61.70s/it, lr=0.000125, test_MAE=0.722, time=61.3, train_MAE=0.581, train_loss=0.581, val_MAE=0.689, val_loss=0.689]Epoch 57:   6%|▌         | 57/1000 [59:41<16:09:43, 61.70s/it, lr=0.000125, test_MAE=0.717, time=62.3, train_MAE=0.581, train_loss=0.581, val_MAE=0.687, val_loss=0.687]Epoch 57:   6%|▌         | 58/1000 [59:41<16:11:24, 61.87s/it, lr=0.000125, test_MAE=0.717, time=62.3, train_MAE=0.581, train_loss=0.581, val_MAE=0.687, val_loss=0.687]Epoch 58:   6%|▌         | 58/1000 [59:41<16:11:24, 61.87s/it, lr=0.000125, test_MAE=0.717, time=62.3, train_MAE=0.581, train_loss=0.581, val_MAE=0.687, val_loss=0.687]Epoch 58:   6%|▌         | 58/1000 [1:00:42<16:11:24, 61.87s/it, lr=0.000125, test_MAE=0.718, time=61.7, train_MAE=0.58, train_loss=0.58, val_MAE=0.688, val_loss=0.688]Epoch 58:   6%|▌         | 59/1000 [1:00:42<16:09:39, 61.83s/it, lr=0.000125, test_MAE=0.718, time=61.7, train_MAE=0.58, train_loss=0.58, val_MAE=0.688, val_loss=0.688]Epoch 59:   6%|▌         | 59/1000 [1:00:42<16:09:39, 61.83s/it, lr=0.000125, test_MAE=0.718, time=61.7, train_MAE=0.58, train_loss=0.58, val_MAE=0.688, val_loss=0.688]Epoch 59:   6%|▌         | 59/1000 [1:01:44<16:09:39, 61.83s/it, lr=0.000125, test_MAE=0.727, time=61.3, train_MAE=0.58, train_loss=0.58, val_MAE=0.7, val_loss=0.7]    Epoch 59:   6%|▌         | 60/1000 [1:01:44<16:06:13, 61.67s/it, lr=0.000125, test_MAE=0.727, time=61.3, train_MAE=0.58, train_loss=0.58, val_MAE=0.7, val_loss=0.7]Epoch 60:   6%|▌         | 60/1000 [1:01:44<16:06:13, 61.67s/it, lr=0.000125, test_MAE=0.727, time=61.3, train_MAE=0.58, train_loss=0.58, val_MAE=0.7, val_loss=0.7]Epoch 60:   6%|▌         | 60/1000 [1:02:46<16:06:13, 61.67s/it, lr=0.000125, test_MAE=0.728, time=62, train_MAE=0.578, train_loss=0.578, val_MAE=0.696, val_loss=0.696]Epoch 60:   6%|▌         | 61/1000 [1:02:46<16:06:54, 61.78s/it, lr=0.000125, test_MAE=0.728, time=62, train_MAE=0.578, train_loss=0.578, val_MAE=0.696, val_loss=0.696]Epoch 61:   6%|▌         | 61/1000 [1:02:46<16:06:54, 61.78s/it, lr=0.000125, test_MAE=0.728, time=62, train_MAE=0.578, train_loss=0.578, val_MAE=0.696, val_loss=0.696]Epoch 61:   6%|▌         | 61/1000 [1:03:48<16:06:54, 61.78s/it, lr=0.000125, test_MAE=0.718, time=61.9, train_MAE=0.573, train_loss=0.573, val_MAE=0.692, val_loss=0.692]Epoch    62: reducing learning rate of group 0 to 6.2500e-05.
Epoch 61:   6%|▌         | 62/1000 [1:03:48<16:06:17, 61.81s/it, lr=0.000125, test_MAE=0.718, time=61.9, train_MAE=0.573, train_loss=0.573, val_MAE=0.692, val_loss=0.692]Epoch 62:   6%|▌         | 62/1000 [1:03:48<16:06:17, 61.81s/it, lr=0.000125, test_MAE=0.718, time=61.9, train_MAE=0.573, train_loss=0.573, val_MAE=0.692, val_loss=0.692]Epoch 62:   6%|▌         | 62/1000 [1:04:49<16:06:17, 61.81s/it, lr=6.25e-5, test_MAE=0.72, time=61.4, train_MAE=0.573, train_loss=0.573, val_MAE=0.691, val_loss=0.691]  Epoch 62:   6%|▋         | 63/1000 [1:04:49<16:03:16, 61.68s/it, lr=6.25e-5, test_MAE=0.72, time=61.4, train_MAE=0.573, train_loss=0.573, val_MAE=0.691, val_loss=0.691]Epoch 63:   6%|▋         | 63/1000 [1:04:49<16:03:16, 61.68s/it, lr=6.25e-5, test_MAE=0.72, time=61.4, train_MAE=0.573, train_loss=0.573, val_MAE=0.691, val_loss=0.691]Epoch 63:   6%|▋         | 63/1000 [1:05:51<16:03:16, 61.68s/it, lr=6.25e-5, test_MAE=0.72, time=62, train_MAE=0.576, train_loss=0.576, val_MAE=0.689, val_loss=0.689]  Epoch 63:   6%|▋         | 64/1000 [1:05:51<16:03:48, 61.78s/it, lr=6.25e-5, test_MAE=0.72, time=62, train_MAE=0.576, train_loss=0.576, val_MAE=0.689, val_loss=0.689]Epoch 64:   6%|▋         | 64/1000 [1:05:51<16:03:48, 61.78s/it, lr=6.25e-5, test_MAE=0.72, time=62, train_MAE=0.576, train_loss=0.576, val_MAE=0.689, val_loss=0.689]Epoch 64:   6%|▋         | 64/1000 [1:06:53<16:03:48, 61.78s/it, lr=6.25e-5, test_MAE=0.721, time=61.7, train_MAE=0.569, train_loss=0.569, val_MAE=0.689, val_loss=0.689]Epoch 64:   6%|▋         | 65/1000 [1:06:53<16:02:19, 61.75s/it, lr=6.25e-5, test_MAE=0.721, time=61.7, train_MAE=0.569, train_loss=0.569, val_MAE=0.689, val_loss=0.689]Epoch 65:   6%|▋         | 65/1000 [1:06:53<16:02:19, 61.75s/it, lr=6.25e-5, test_MAE=0.721, time=61.7, train_MAE=0.569, train_loss=0.569, val_MAE=0.689, val_loss=0.689]Epoch 65:   6%|▋         | 65/1000 [1:07:54<16:02:19, 61.75s/it, lr=6.25e-5, test_MAE=0.716, time=61.6, train_MAE=0.57, train_loss=0.57, val_MAE=0.688, val_loss=0.688]  Epoch 65:   7%|▋         | 66/1000 [1:07:54<16:00:40, 61.71s/it, lr=6.25e-5, test_MAE=0.716, time=61.6, train_MAE=0.57, train_loss=0.57, val_MAE=0.688, val_loss=0.688]Epoch 66:   7%|▋         | 66/1000 [1:07:54<16:00:40, 61.71s/it, lr=6.25e-5, test_MAE=0.716, time=61.6, train_MAE=0.57, train_loss=0.57, val_MAE=0.688, val_loss=0.688]Epoch 66:   7%|▋         | 66/1000 [1:08:56<16:00:40, 61.71s/it, lr=6.25e-5, test_MAE=0.72, time=61.8, train_MAE=0.567, train_loss=0.567, val_MAE=0.691, val_loss=0.691]Epoch 66:   7%|▋         | 67/1000 [1:08:56<16:00:16, 61.75s/it, lr=6.25e-5, test_MAE=0.72, time=61.8, train_MAE=0.567, train_loss=0.567, val_MAE=0.691, val_loss=0.691]Epoch 67:   7%|▋         | 67/1000 [1:08:56<16:00:16, 61.75s/it, lr=6.25e-5, test_MAE=0.72, time=61.8, train_MAE=0.567, train_loss=0.567, val_MAE=0.691, val_loss=0.691]Epoch 67:   7%|▋         | 67/1000 [1:09:58<16:00:16, 61.75s/it, lr=6.25e-5, test_MAE=0.727, time=61.6, train_MAE=0.573, train_loss=0.573, val_MAE=0.692, val_loss=0.692]Epoch    68: reducing learning rate of group 0 to 3.1250e-05.
Epoch 67:   7%|▋         | 68/1000 [1:09:58<15:58:42, 61.72s/it, lr=6.25e-5, test_MAE=0.727, time=61.6, train_MAE=0.573, train_loss=0.573, val_MAE=0.692, val_loss=0.692]Epoch 68:   7%|▋         | 68/1000 [1:09:58<15:58:42, 61.72s/it, lr=6.25e-5, test_MAE=0.727, time=61.6, train_MAE=0.573, train_loss=0.573, val_MAE=0.692, val_loss=0.692]Epoch 68:   7%|▋         | 68/1000 [1:10:59<15:58:42, 61.72s/it, lr=3.13e-5, test_MAE=0.721, time=61.6, train_MAE=0.563, train_loss=0.563, val_MAE=0.691, val_loss=0.691]Epoch 68:   7%|▋         | 69/1000 [1:10:59<15:57:20, 61.70s/it, lr=3.13e-5, test_MAE=0.721, time=61.6, train_MAE=0.563, train_loss=0.563, val_MAE=0.691, val_loss=0.691]Epoch 69:   7%|▋         | 69/1000 [1:10:59<15:57:20, 61.70s/it, lr=3.13e-5, test_MAE=0.721, time=61.6, train_MAE=0.563, train_loss=0.563, val_MAE=0.691, val_loss=0.691]Epoch 69:   7%|▋         | 69/1000 [1:12:01<15:57:20, 61.70s/it, lr=3.13e-5, test_MAE=0.717, time=62, train_MAE=0.565, train_loss=0.565, val_MAE=0.688, val_loss=0.688]  Epoch 69:   7%|▋         | 70/1000 [1:12:01<15:57:52, 61.80s/it, lr=3.13e-5, test_MAE=0.717, time=62, train_MAE=0.565, train_loss=0.565, val_MAE=0.688, val_loss=0.688]Epoch 70:   7%|▋         | 70/1000 [1:12:01<15:57:52, 61.80s/it, lr=3.13e-5, test_MAE=0.717, time=62, train_MAE=0.565, train_loss=0.565, val_MAE=0.688, val_loss=0.688]Epoch 70:   7%|▋         | 70/1000 [1:13:03<15:57:52, 61.80s/it, lr=3.13e-5, test_MAE=0.719, time=61.9, train_MAE=0.569, train_loss=0.569, val_MAE=0.689, val_loss=0.689]Epoch 70:   7%|▋         | 71/1000 [1:13:03<15:57:28, 61.84s/it, lr=3.13e-5, test_MAE=0.719, time=61.9, train_MAE=0.569, train_loss=0.569, val_MAE=0.689, val_loss=0.689]Epoch 71:   7%|▋         | 71/1000 [1:13:03<15:57:28, 61.84s/it, lr=3.13e-5, test_MAE=0.719, time=61.9, train_MAE=0.569, train_loss=0.569, val_MAE=0.689, val_loss=0.689]Epoch 71:   7%|▋         | 71/1000 [1:14:05<15:57:28, 61.84s/it, lr=3.13e-5, test_MAE=0.724, time=61.4, train_MAE=0.571, train_loss=0.571, val_MAE=0.691, val_loss=0.691]Epoch 71:   7%|▋         | 72/1000 [1:14:05<15:54:23, 61.71s/it, lr=3.13e-5, test_MAE=0.724, time=61.4, train_MAE=0.571, train_loss=0.571, val_MAE=0.691, val_loss=0.691]Epoch 72:   7%|▋         | 72/1000 [1:14:05<15:54:23, 61.71s/it, lr=3.13e-5, test_MAE=0.724, time=61.4, train_MAE=0.571, train_loss=0.571, val_MAE=0.691, val_loss=0.691]Epoch 72:   7%|▋         | 72/1000 [1:15:07<15:54:23, 61.71s/it, lr=3.13e-5, test_MAE=0.72, time=62.3, train_MAE=0.565, train_loss=0.565, val_MAE=0.691, val_loss=0.691] Epoch 72:   7%|▋         | 73/1000 [1:15:07<15:56:25, 61.90s/it, lr=3.13e-5, test_MAE=0.72, time=62.3, train_MAE=0.565, train_loss=0.565, val_MAE=0.691, val_loss=0.691]Epoch 73:   7%|▋         | 73/1000 [1:15:07<15:56:25, 61.90s/it, lr=3.13e-5, test_MAE=0.72, time=62.3, train_MAE=0.565, train_loss=0.565, val_MAE=0.691, val_loss=0.691]Epoch 73:   7%|▋         | 73/1000 [1:16:09<15:56:25, 61.90s/it, lr=3.13e-5, test_MAE=0.717, time=61.7, train_MAE=0.564, train_loss=0.564, val_MAE=0.687, val_loss=0.687]Epoch    74: reducing learning rate of group 0 to 1.5625e-05.
Epoch 73:   7%|▋         | 74/1000 [1:16:09<15:54:39, 61.86s/it, lr=3.13e-5, test_MAE=0.717, time=61.7, train_MAE=0.564, train_loss=0.564, val_MAE=0.687, val_loss=0.687]Epoch 74:   7%|▋         | 74/1000 [1:16:09<15:54:39, 61.86s/it, lr=3.13e-5, test_MAE=0.717, time=61.7, train_MAE=0.564, train_loss=0.564, val_MAE=0.687, val_loss=0.687]Epoch 74:   7%|▋         | 74/1000 [1:17:10<15:54:39, 61.86s/it, lr=1.56e-5, test_MAE=0.722, time=61.3, train_MAE=0.561, train_loss=0.561, val_MAE=0.697, val_loss=0.697]Epoch 74:   8%|▊         | 75/1000 [1:17:10<15:51:17, 61.71s/it, lr=1.56e-5, test_MAE=0.722, time=61.3, train_MAE=0.561, train_loss=0.561, val_MAE=0.697, val_loss=0.697]Epoch 75:   8%|▊         | 75/1000 [1:17:10<15:51:17, 61.71s/it, lr=1.56e-5, test_MAE=0.722, time=61.3, train_MAE=0.561, train_loss=0.561, val_MAE=0.697, val_loss=0.697]Epoch 75:   8%|▊         | 75/1000 [1:18:12<15:51:17, 61.71s/it, lr=1.56e-5, test_MAE=0.719, time=62.2, train_MAE=0.563, train_loss=0.563, val_MAE=0.689, val_loss=0.689]Epoch 75:   8%|▊         | 76/1000 [1:18:12<15:52:32, 61.85s/it, lr=1.56e-5, test_MAE=0.719, time=62.2, train_MAE=0.563, train_loss=0.563, val_MAE=0.689, val_loss=0.689]Epoch 76:   8%|▊         | 76/1000 [1:18:12<15:52:32, 61.85s/it, lr=1.56e-5, test_MAE=0.719, time=62.2, train_MAE=0.563, train_loss=0.563, val_MAE=0.689, val_loss=0.689]Epoch 76:   8%|▊         | 76/1000 [1:19:14<15:52:32, 61.85s/it, lr=1.56e-5, test_MAE=0.72, time=61.7, train_MAE=0.562, train_loss=0.562, val_MAE=0.69, val_loss=0.69]   Epoch 76:   8%|▊         | 77/1000 [1:19:14<15:51:04, 61.82s/it, lr=1.56e-5, test_MAE=0.72, time=61.7, train_MAE=0.562, train_loss=0.562, val_MAE=0.69, val_loss=0.69]Epoch 77:   8%|▊         | 77/1000 [1:19:14<15:51:04, 61.82s/it, lr=1.56e-5, test_MAE=0.72, time=61.7, train_MAE=0.562, train_loss=0.562, val_MAE=0.69, val_loss=0.69]Epoch 77:   8%|▊         | 77/1000 [1:20:16<15:51:04, 61.82s/it, lr=1.56e-5, test_MAE=0.721, time=61.4, train_MAE=0.565, train_loss=0.565, val_MAE=0.692, val_loss=0.692]Epoch 77:   8%|▊         | 78/1000 [1:20:16<15:48:08, 61.70s/it, lr=1.56e-5, test_MAE=0.721, time=61.4, train_MAE=0.565, train_loss=0.565, val_MAE=0.692, val_loss=0.692]Epoch 78:   8%|▊         | 78/1000 [1:20:16<15:48:08, 61.70s/it, lr=1.56e-5, test_MAE=0.721, time=61.4, train_MAE=0.565, train_loss=0.565, val_MAE=0.692, val_loss=0.692]Epoch 78:   8%|▊         | 78/1000 [1:21:18<15:48:08, 61.70s/it, lr=1.56e-5, test_MAE=0.717, time=62, train_MAE=0.569, train_loss=0.569, val_MAE=0.687, val_loss=0.687]  Epoch 78:   8%|▊         | 79/1000 [1:21:18<15:48:31, 61.79s/it, lr=1.56e-5, test_MAE=0.717, time=62, train_MAE=0.569, train_loss=0.569, val_MAE=0.687, val_loss=0.687]Epoch 79:   8%|▊         | 79/1000 [1:21:18<15:48:31, 61.79s/it, lr=1.56e-5, test_MAE=0.717, time=62, train_MAE=0.569, train_loss=0.569, val_MAE=0.687, val_loss=0.687]Epoch 79:   8%|▊         | 79/1000 [1:22:19<15:48:31, 61.79s/it, lr=1.56e-5, test_MAE=0.719, time=61.7, train_MAE=0.565, train_loss=0.565, val_MAE=0.691, val_loss=0.691]Epoch    80: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 79:   8%|▊         | 79/1000 [1:22:19<15:59:49, 62.53s/it, lr=1.56e-5, test_MAE=0.719, time=61.7, train_MAE=0.565, train_loss=0.565, val_MAE=0.691, val_loss=0.691]
Test MAE: 0.7195
Train MAE: 0.5633
Convergence Time (Epochs): 79.0000
TOTAL TIME TAKEN: 4978.8473s
AVG TIME PER EPOCH: 61.7334s
