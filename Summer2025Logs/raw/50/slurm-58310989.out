I'm echoing to stdout
I'm echoing to stderr
My JobID is 58310989
I have 4 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.0495s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 16, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 4, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'cheb02_vec', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_sub', 'num_eigs': 16, 'bias_mode': 'spatial', 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 0.0, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/aug07/zinc_train_rec.csv', 'test': 'supp_data/molecules/aug07/zinc_test_rec.csv', 'val': 'supp_data/molecules/aug07/zinc_val_rec.csv'}, 'fixMissingPhi1': False, 'extraOrtho': False, 'doublePrecision': True, 'eigval_hidden_dim': 100, 'eigval_num_hidden_layer': 3, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [04:40<?, ?it/s, lr=0.001, test_MAE=2.54, time=280, train_MAE=0.84, train_loss=0.84, val_MAE=2.51, val_loss=2.51]Epoch 0:   0%|          | 1/1000 [04:40<77:43:30, 280.09s/it, lr=0.001, test_MAE=2.54, time=280, train_MAE=0.84, train_loss=0.84, val_MAE=2.51, val_loss=2.51]Epoch 1:   0%|          | 1/1000 [04:40<77:43:30, 280.09s/it, lr=0.001, test_MAE=2.54, time=280, train_MAE=0.84, train_loss=0.84, val_MAE=2.51, val_loss=2.51]Epoch 1:   0%|          | 1/1000 [09:06<77:43:30, 280.09s/it, lr=0.001, test_MAE=0.739, time=266, train_MAE=0.692, train_loss=0.692, val_MAE=0.683, val_loss=0.683]Epoch 1:   0%|          | 2/1000 [09:06<76:31:01, 276.01s/it, lr=0.001, test_MAE=0.739, time=266, train_MAE=0.692, train_loss=0.692, val_MAE=0.683, val_loss=0.683]Epoch 2:   0%|          | 2/1000 [09:06<76:31:01, 276.01s/it, lr=0.001, test_MAE=0.739, time=266, train_MAE=0.692, train_loss=0.692, val_MAE=0.683, val_loss=0.683]Epoch 2:   0%|          | 2/1000 [13:23<76:31:01, 276.01s/it, lr=0.001, test_MAE=0.729, time=256, train_MAE=0.666, train_loss=0.666, val_MAE=0.691, val_loss=0.691]Epoch 2:   0%|          | 3/1000 [13:23<74:49:12, 270.16s/it, lr=0.001, test_MAE=0.729, time=256, train_MAE=0.666, train_loss=0.666, val_MAE=0.691, val_loss=0.691]Epoch 3:   0%|          | 3/1000 [13:23<74:49:12, 270.16s/it, lr=0.001, test_MAE=0.729, time=256, train_MAE=0.666, train_loss=0.666, val_MAE=0.691, val_loss=0.691]Epoch 3:   0%|          | 3/1000 [17:32<74:49:12, 270.16s/it, lr=0.001, test_MAE=0.671, time=250, train_MAE=0.647, train_loss=0.647, val_MAE=0.649, val_loss=0.649]Epoch 3:   0%|          | 4/1000 [17:32<73:03:18, 264.05s/it, lr=0.001, test_MAE=0.671, time=250, train_MAE=0.647, train_loss=0.647, val_MAE=0.649, val_loss=0.649]Epoch 4:   0%|          | 4/1000 [17:32<73:03:18, 264.05s/it, lr=0.001, test_MAE=0.671, time=250, train_MAE=0.647, train_loss=0.647, val_MAE=0.649, val_loss=0.649]Epoch 4:   0%|          | 4/1000 [21:42<73:03:18, 264.05s/it, lr=0.001, test_MAE=0.773, time=250, train_MAE=0.628, train_loss=0.628, val_MAE=0.722, val_loss=0.722]Epoch 4:   0%|          | 5/1000 [21:42<71:49:05, 259.85s/it, lr=0.001, test_MAE=0.773, time=250, train_MAE=0.628, train_loss=0.628, val_MAE=0.722, val_loss=0.722]Epoch 5:   0%|          | 5/1000 [21:42<71:49:05, 259.85s/it, lr=0.001, test_MAE=0.773, time=250, train_MAE=0.628, train_loss=0.628, val_MAE=0.722, val_loss=0.722]Epoch 5:   0%|          | 5/1000 [25:51<71:49:05, 259.85s/it, lr=0.001, test_MAE=0.699, time=248, train_MAE=0.644, train_loss=0.644, val_MAE=0.638, val_loss=0.638]Epoch 5:   1%|          | 6/1000 [25:51<70:48:18, 256.44s/it, lr=0.001, test_MAE=0.699, time=248, train_MAE=0.644, train_loss=0.644, val_MAE=0.638, val_loss=0.638]Epoch 6:   1%|          | 6/1000 [25:51<70:48:18, 256.44s/it, lr=0.001, test_MAE=0.699, time=248, train_MAE=0.644, train_loss=0.644, val_MAE=0.638, val_loss=0.638]Epoch 6:   1%|          | 6/1000 [30:00<70:48:18, 256.44s/it, lr=0.001, test_MAE=0.676, time=249, train_MAE=0.626, train_loss=0.626, val_MAE=0.638, val_loss=0.638]Epoch 6:   1%|          | 7/1000 [30:00<70:06:28, 254.17s/it, lr=0.001, test_MAE=0.676, time=249, train_MAE=0.626, train_loss=0.626, val_MAE=0.638, val_loss=0.638]Epoch 7:   1%|          | 7/1000 [30:00<70:06:28, 254.17s/it, lr=0.001, test_MAE=0.676, time=249, train_MAE=0.626, train_loss=0.626, val_MAE=0.638, val_loss=0.638]Epoch 7:   1%|          | 7/1000 [34:10<70:06:28, 254.17s/it, lr=0.001, test_MAE=0.705, time=250, train_MAE=0.615, train_loss=0.615, val_MAE=0.674, val_loss=0.674]Epoch 7:   1%|          | 8/1000 [34:10<69:41:00, 252.88s/it, lr=0.001, test_MAE=0.705, time=250, train_MAE=0.615, train_loss=0.615, val_MAE=0.674, val_loss=0.674]Epoch 8:   1%|          | 8/1000 [34:10<69:41:00, 252.88s/it, lr=0.001, test_MAE=0.705, time=250, train_MAE=0.615, train_loss=0.615, val_MAE=0.674, val_loss=0.674]Epoch 8:   1%|          | 8/1000 [38:18<69:41:00, 252.88s/it, lr=0.001, test_MAE=0.822, time=248, train_MAE=0.619, train_loss=0.619, val_MAE=0.79, val_loss=0.79]  Epoch 8:   1%|          | 9/1000 [38:18<69:15:08, 251.57s/it, lr=0.001, test_MAE=0.822, time=248, train_MAE=0.619, train_loss=0.619, val_MAE=0.79, val_loss=0.79]Epoch 9:   1%|          | 9/1000 [38:18<69:15:08, 251.57s/it, lr=0.001, test_MAE=0.822, time=248, train_MAE=0.619, train_loss=0.619, val_MAE=0.79, val_loss=0.79]Epoch 9:   1%|          | 9/1000 [42:27<69:15:08, 251.57s/it, lr=0.001, test_MAE=0.667, time=249, train_MAE=0.606, train_loss=0.606, val_MAE=0.624, val_loss=0.624]Epoch 9:   1%|          | 10/1000 [42:27<68:58:34, 250.82s/it, lr=0.001, test_MAE=0.667, time=249, train_MAE=0.606, train_loss=0.606, val_MAE=0.624, val_loss=0.624]Epoch 10:   1%|          | 10/1000 [42:27<68:58:34, 250.82s/it, lr=0.001, test_MAE=0.667, time=249, train_MAE=0.606, train_loss=0.606, val_MAE=0.624, val_loss=0.624]Epoch 10:   1%|          | 10/1000 [46:37<68:58:34, 250.82s/it, lr=0.001, test_MAE=0.654, time=250, train_MAE=0.602, train_loss=0.602, val_MAE=0.622, val_loss=0.622]Epoch 10:   1%|          | 11/1000 [46:37<68:49:02, 250.50s/it, lr=0.001, test_MAE=0.654, time=250, train_MAE=0.602, train_loss=0.602, val_MAE=0.622, val_loss=0.622]Epoch 11:   1%|          | 11/1000 [46:37<68:49:02, 250.50s/it, lr=0.001, test_MAE=0.654, time=250, train_MAE=0.602, train_loss=0.602, val_MAE=0.622, val_loss=0.622]Epoch 11:   1%|          | 11/1000 [50:45<68:49:02, 250.50s/it, lr=0.001, test_MAE=0.776, time=248, train_MAE=0.596, train_loss=0.596, val_MAE=0.749, val_loss=0.749]Epoch 11:   1%|          | 12/1000 [50:45<68:34:15, 249.85s/it, lr=0.001, test_MAE=0.776, time=248, train_MAE=0.596, train_loss=0.596, val_MAE=0.749, val_loss=0.749]Epoch 12:   1%|          | 12/1000 [50:45<68:34:15, 249.85s/it, lr=0.001, test_MAE=0.776, time=248, train_MAE=0.596, train_loss=0.596, val_MAE=0.749, val_loss=0.749]Epoch 12:   1%|          | 12/1000 [54:55<68:34:15, 249.85s/it, lr=0.001, test_MAE=0.67, time=249, train_MAE=0.585, train_loss=0.585, val_MAE=0.632, val_loss=0.632] Epoch 12:   1%|▏         | 13/1000 [54:55<68:27:18, 249.68s/it, lr=0.001, test_MAE=0.67, time=249, train_MAE=0.585, train_loss=0.585, val_MAE=0.632, val_loss=0.632]Epoch 13:   1%|▏         | 13/1000 [54:55<68:27:18, 249.68s/it, lr=0.001, test_MAE=0.67, time=249, train_MAE=0.585, train_loss=0.585, val_MAE=0.632, val_loss=0.632]Epoch 13:   1%|▏         | 13/1000 [59:04<68:27:18, 249.68s/it, lr=0.001, test_MAE=0.746, time=250, train_MAE=0.574, train_loss=0.574, val_MAE=0.707, val_loss=0.707]Epoch 13:   1%|▏         | 14/1000 [59:04<68:23:57, 249.73s/it, lr=0.001, test_MAE=0.746, time=250, train_MAE=0.574, train_loss=0.574, val_MAE=0.707, val_loss=0.707]Epoch 14:   1%|▏         | 14/1000 [59:04<68:23:57, 249.73s/it, lr=0.001, test_MAE=0.746, time=250, train_MAE=0.574, train_loss=0.574, val_MAE=0.707, val_loss=0.707]Epoch 14:   1%|▏         | 14/1000 [1:03:13<68:23:57, 249.73s/it, lr=0.001, test_MAE=0.832, time=248, train_MAE=0.58, train_loss=0.58, val_MAE=0.748, val_loss=0.748]Epoch 14:   2%|▏         | 15/1000 [1:03:13<68:13:07, 249.33s/it, lr=0.001, test_MAE=0.832, time=248, train_MAE=0.58, train_loss=0.58, val_MAE=0.748, val_loss=0.748]Epoch 15:   2%|▏         | 15/1000 [1:03:13<68:13:07, 249.33s/it, lr=0.001, test_MAE=0.832, time=248, train_MAE=0.58, train_loss=0.58, val_MAE=0.748, val_loss=0.748]Epoch 15:   2%|▏         | 15/1000 [1:07:22<68:13:07, 249.33s/it, lr=0.001, test_MAE=0.797, time=249, train_MAE=0.579, train_loss=0.579, val_MAE=0.745, val_loss=0.745]Epoch 15:   2%|▏         | 16/1000 [1:07:22<68:06:29, 249.18s/it, lr=0.001, test_MAE=0.797, time=249, train_MAE=0.579, train_loss=0.579, val_MAE=0.745, val_loss=0.745]Epoch 16:   2%|▏         | 16/1000 [1:07:22<68:06:29, 249.18s/it, lr=0.001, test_MAE=0.797, time=249, train_MAE=0.579, train_loss=0.579, val_MAE=0.745, val_loss=0.745]Epoch 16:   2%|▏         | 16/1000 [1:11:31<68:06:29, 249.18s/it, lr=0.001, test_MAE=0.719, time=250, train_MAE=0.563, train_loss=0.563, val_MAE=0.672, val_loss=0.672]Epoch    17: reducing learning rate of group 0 to 5.0000e-04.
Epoch 16:   2%|▏         | 17/1000 [1:11:31<68:05:23, 249.36s/it, lr=0.001, test_MAE=0.719, time=250, train_MAE=0.563, train_loss=0.563, val_MAE=0.672, val_loss=0.672]Epoch 17:   2%|▏         | 17/1000 [1:11:31<68:05:23, 249.36s/it, lr=0.001, test_MAE=0.719, time=250, train_MAE=0.563, train_loss=0.563, val_MAE=0.672, val_loss=0.672]Epoch 17:   2%|▏         | 17/1000 [1:15:40<68:05:23, 249.36s/it, lr=0.0005, test_MAE=0.678, time=249, train_MAE=0.536, train_loss=0.536, val_MAE=0.634, val_loss=0.634]Epoch 17:   2%|▏         | 18/1000 [1:15:40<67:57:07, 249.11s/it, lr=0.0005, test_MAE=0.678, time=249, train_MAE=0.536, train_loss=0.536, val_MAE=0.634, val_loss=0.634]Epoch 18:   2%|▏         | 18/1000 [1:15:40<67:57:07, 249.11s/it, lr=0.0005, test_MAE=0.678, time=249, train_MAE=0.536, train_loss=0.536, val_MAE=0.634, val_loss=0.634]Epoch 18:   2%|▏         | 18/1000 [1:19:49<67:57:07, 249.11s/it, lr=0.0005, test_MAE=0.631, time=249, train_MAE=0.525, train_loss=0.525, val_MAE=0.594, val_loss=0.594]Epoch 18:   2%|▏         | 19/1000 [1:19:49<67:52:43, 249.10s/it, lr=0.0005, test_MAE=0.631, time=249, train_MAE=0.525, train_loss=0.525, val_MAE=0.594, val_loss=0.594]Epoch 19:   2%|▏         | 19/1000 [1:19:49<67:52:43, 249.10s/it, lr=0.0005, test_MAE=0.631, time=249, train_MAE=0.525, train_loss=0.525, val_MAE=0.594, val_loss=0.594]Epoch 19:   2%|▏         | 19/1000 [1:23:59<67:52:43, 249.10s/it, lr=0.0005, test_MAE=0.642, time=250, train_MAE=0.523, train_loss=0.523, val_MAE=0.593, val_loss=0.593]Epoch 19:   2%|▏         | 20/1000 [1:23:59<67:52:01, 249.31s/it, lr=0.0005, test_MAE=0.642, time=250, train_MAE=0.523, train_loss=0.523, val_MAE=0.593, val_loss=0.593]Epoch 20:   2%|▏         | 20/1000 [1:23:59<67:52:01, 249.31s/it, lr=0.0005, test_MAE=0.642, time=250, train_MAE=0.523, train_loss=0.523, val_MAE=0.593, val_loss=0.593]Epoch 20:   2%|▏         | 20/1000 [1:28:07<67:52:01, 249.31s/it, lr=0.0005, test_MAE=0.648, time=248, train_MAE=0.524, train_loss=0.524, val_MAE=0.608, val_loss=0.608]Epoch 20:   2%|▏         | 21/1000 [1:28:07<67:43:43, 249.05s/it, lr=0.0005, test_MAE=0.648, time=248, train_MAE=0.524, train_loss=0.524, val_MAE=0.608, val_loss=0.608]Epoch 21:   2%|▏         | 21/1000 [1:28:07<67:43:43, 249.05s/it, lr=0.0005, test_MAE=0.648, time=248, train_MAE=0.524, train_loss=0.524, val_MAE=0.608, val_loss=0.608]Epoch 21:   2%|▏         | 21/1000 [1:32:16<67:43:43, 249.05s/it, lr=0.0005, test_MAE=0.63, time=249, train_MAE=0.522, train_loss=0.522, val_MAE=0.583, val_loss=0.583] Epoch 21:   2%|▏         | 22/1000 [1:32:16<67:39:27, 249.05s/it, lr=0.0005, test_MAE=0.63, time=249, train_MAE=0.522, train_loss=0.522, val_MAE=0.583, val_loss=0.583]Epoch 22:   2%|▏         | 22/1000 [1:32:16<67:39:27, 249.05s/it, lr=0.0005, test_MAE=0.63, time=249, train_MAE=0.522, train_loss=0.522, val_MAE=0.583, val_loss=0.583]Epoch 22:   2%|▏         | 22/1000 [1:36:26<67:39:27, 249.05s/it, lr=0.0005, test_MAE=0.689, time=250, train_MAE=0.507, train_loss=0.507, val_MAE=0.641, val_loss=0.641]Epoch 22:   2%|▏         | 23/1000 [1:36:26<67:38:42, 249.26s/it, lr=0.0005, test_MAE=0.689, time=250, train_MAE=0.507, train_loss=0.507, val_MAE=0.641, val_loss=0.641]Epoch 23:   2%|▏         | 23/1000 [1:36:26<67:38:42, 249.26s/it, lr=0.0005, test_MAE=0.689, time=250, train_MAE=0.507, train_loss=0.507, val_MAE=0.641, val_loss=0.641]Epoch 23:   2%|▏         | 23/1000 [1:40:34<67:38:42, 249.26s/it, lr=0.0005, test_MAE=0.803, time=248, train_MAE=0.53, train_loss=0.53, val_MAE=0.767, val_loss=0.767]  Epoch 23:   2%|▏         | 24/1000 [1:40:34<67:30:09, 248.99s/it, lr=0.0005, test_MAE=0.803, time=248, train_MAE=0.53, train_loss=0.53, val_MAE=0.767, val_loss=0.767]Epoch 24:   2%|▏         | 24/1000 [1:40:34<67:30:09, 248.99s/it, lr=0.0005, test_MAE=0.803, time=248, train_MAE=0.53, train_loss=0.53, val_MAE=0.767, val_loss=0.767]Epoch 24:   2%|▏         | 24/1000 [1:44:43<67:30:09, 248.99s/it, lr=0.0005, test_MAE=0.663, time=249, train_MAE=0.509, train_loss=0.509, val_MAE=0.608, val_loss=0.608]Epoch 24:   2%|▎         | 25/1000 [1:44:43<67:25:43, 248.97s/it, lr=0.0005, test_MAE=0.663, time=249, train_MAE=0.509, train_loss=0.509, val_MAE=0.608, val_loss=0.608]Epoch 25:   2%|▎         | 25/1000 [1:44:43<67:25:43, 248.97s/it, lr=0.0005, test_MAE=0.663, time=249, train_MAE=0.509, train_loss=0.509, val_MAE=0.608, val_loss=0.608]Epoch 25:   2%|▎         | 25/1000 [1:48:53<67:25:43, 248.97s/it, lr=0.0005, test_MAE=0.685, time=250, train_MAE=0.496, train_loss=0.496, val_MAE=0.623, val_loss=0.623]Epoch 25:   3%|▎         | 26/1000 [1:48:53<67:25:28, 249.21s/it, lr=0.0005, test_MAE=0.685, time=250, train_MAE=0.496, train_loss=0.496, val_MAE=0.623, val_loss=0.623]Epoch 26:   3%|▎         | 26/1000 [1:48:53<67:25:28, 249.21s/it, lr=0.0005, test_MAE=0.685, time=250, train_MAE=0.496, train_loss=0.496, val_MAE=0.623, val_loss=0.623]Epoch 26:   3%|▎         | 26/1000 [1:53:02<67:25:28, 249.21s/it, lr=0.0005, test_MAE=0.711, time=249, train_MAE=0.494, train_loss=0.494, val_MAE=0.642, val_loss=0.642]Epoch 26:   3%|▎         | 27/1000 [1:53:02<67:18:22, 249.03s/it, lr=0.0005, test_MAE=0.711, time=249, train_MAE=0.494, train_loss=0.494, val_MAE=0.642, val_loss=0.642]Epoch 27:   3%|▎         | 27/1000 [1:53:02<67:18:22, 249.03s/it, lr=0.0005, test_MAE=0.711, time=249, train_MAE=0.494, train_loss=0.494, val_MAE=0.642, val_loss=0.642]Epoch 27:   3%|▎         | 27/1000 [1:57:11<67:18:22, 249.03s/it, lr=0.0005, test_MAE=0.671, time=249, train_MAE=0.495, train_loss=0.495, val_MAE=0.636, val_loss=0.636]Epoch    28: reducing learning rate of group 0 to 2.5000e-04.
Epoch 27:   3%|▎         | 28/1000 [1:57:11<67:14:26, 249.04s/it, lr=0.0005, test_MAE=0.671, time=249, train_MAE=0.495, train_loss=0.495, val_MAE=0.636, val_loss=0.636]Epoch 28:   3%|▎         | 28/1000 [1:57:11<67:14:26, 249.04s/it, lr=0.0005, test_MAE=0.671, time=249, train_MAE=0.495, train_loss=0.495, val_MAE=0.636, val_loss=0.636]Epoch 28:   3%|▎         | 28/1000 [2:01:21<67:14:26, 249.04s/it, lr=0.00025, test_MAE=0.644, time=250, train_MAE=0.47, train_loss=0.47, val_MAE=0.594, val_loss=0.594] Epoch 28:   3%|▎         | 29/1000 [2:01:21<67:14:10, 249.28s/it, lr=0.00025, test_MAE=0.644, time=250, train_MAE=0.47, train_loss=0.47, val_MAE=0.594, val_loss=0.594]Epoch 29:   3%|▎         | 29/1000 [2:01:21<67:14:10, 249.28s/it, lr=0.00025, test_MAE=0.644, time=250, train_MAE=0.47, train_loss=0.47, val_MAE=0.594, val_loss=0.594]Epoch 29:   3%|▎         | 29/1000 [2:05:29<67:14:10, 249.28s/it, lr=0.00025, test_MAE=0.653, time=248, train_MAE=0.464, train_loss=0.464, val_MAE=0.598, val_loss=0.598]Epoch 29:   3%|▎         | 30/1000 [2:05:29<67:05:52, 249.02s/it, lr=0.00025, test_MAE=0.653, time=248, train_MAE=0.464, train_loss=0.464, val_MAE=0.598, val_loss=0.598]Epoch 30:   3%|▎         | 30/1000 [2:05:29<67:05:52, 249.02s/it, lr=0.00025, test_MAE=0.653, time=248, train_MAE=0.464, train_loss=0.464, val_MAE=0.598, val_loss=0.598]Epoch 30:   3%|▎         | 30/1000 [2:09:38<67:05:52, 249.02s/it, lr=0.00025, test_MAE=0.633, time=249, train_MAE=0.459, train_loss=0.459, val_MAE=0.594, val_loss=0.594]Epoch 30:   3%|▎         | 31/1000 [2:09:38<67:01:41, 249.02s/it, lr=0.00025, test_MAE=0.633, time=249, train_MAE=0.459, train_loss=0.459, val_MAE=0.594, val_loss=0.594]Epoch 31:   3%|▎         | 31/1000 [2:09:38<67:01:41, 249.02s/it, lr=0.00025, test_MAE=0.633, time=249, train_MAE=0.459, train_loss=0.459, val_MAE=0.594, val_loss=0.594]Epoch 31:   3%|▎         | 31/1000 [2:13:48<67:01:41, 249.02s/it, lr=0.00025, test_MAE=0.667, time=250, train_MAE=0.452, train_loss=0.452, val_MAE=0.625, val_loss=0.625]Epoch 31:   3%|▎         | 32/1000 [2:13:48<67:01:40, 249.28s/it, lr=0.00025, test_MAE=0.667, time=250, train_MAE=0.452, train_loss=0.452, val_MAE=0.625, val_loss=0.625]Epoch 32:   3%|▎         | 32/1000 [2:13:48<67:01:40, 249.28s/it, lr=0.00025, test_MAE=0.667, time=250, train_MAE=0.452, train_loss=0.452, val_MAE=0.625, val_loss=0.625]Epoch 32:   3%|▎         | 32/1000 [2:17:56<67:01:40, 249.28s/it, lr=0.00025, test_MAE=0.651, time=248, train_MAE=0.45, train_loss=0.45, val_MAE=0.61, val_loss=0.61]    Epoch 32:   3%|▎         | 33/1000 [2:17:56<66:53:47, 249.05s/it, lr=0.00025, test_MAE=0.651, time=248, train_MAE=0.45, train_loss=0.45, val_MAE=0.61, val_loss=0.61]Epoch 33:   3%|▎         | 33/1000 [2:17:56<66:53:47, 249.05s/it, lr=0.00025, test_MAE=0.651, time=248, train_MAE=0.45, train_loss=0.45, val_MAE=0.61, val_loss=0.61]Epoch 33:   3%|▎         | 33/1000 [2:22:05<66:53:47, 249.05s/it, lr=0.00025, test_MAE=0.666, time=249, train_MAE=0.44, train_loss=0.44, val_MAE=0.626, val_loss=0.626]Epoch    34: reducing learning rate of group 0 to 1.2500e-04.
Epoch 33:   3%|▎         | 34/1000 [2:22:05<66:49:09, 249.02s/it, lr=0.00025, test_MAE=0.666, time=249, train_MAE=0.44, train_loss=0.44, val_MAE=0.626, val_loss=0.626]Epoch 34:   3%|▎         | 34/1000 [2:22:05<66:49:09, 249.02s/it, lr=0.00025, test_MAE=0.666, time=249, train_MAE=0.44, train_loss=0.44, val_MAE=0.626, val_loss=0.626]Epoch 34:   3%|▎         | 34/1000 [2:26:15<66:49:09, 249.02s/it, lr=0.000125, test_MAE=0.638, time=250, train_MAE=0.43, train_loss=0.43, val_MAE=0.592, val_loss=0.592]Epoch 34:   4%|▎         | 35/1000 [2:26:15<66:49:08, 249.27s/it, lr=0.000125, test_MAE=0.638, time=250, train_MAE=0.43, train_loss=0.43, val_MAE=0.592, val_loss=0.592]Epoch 35:   4%|▎         | 35/1000 [2:26:15<66:49:08, 249.27s/it, lr=0.000125, test_MAE=0.638, time=250, train_MAE=0.43, train_loss=0.43, val_MAE=0.592, val_loss=0.592]Epoch 35:   4%|▎         | 35/1000 [2:30:24<66:49:08, 249.27s/it, lr=0.000125, test_MAE=0.672, time=249, train_MAE=0.423, train_loss=0.423, val_MAE=0.62, val_loss=0.62]Epoch 35:   4%|▎         | 36/1000 [2:30:24<66:42:09, 249.10s/it, lr=0.000125, test_MAE=0.672, time=249, train_MAE=0.423, train_loss=0.423, val_MAE=0.62, val_loss=0.62]Epoch 36:   4%|▎         | 36/1000 [2:30:24<66:42:09, 249.10s/it, lr=0.000125, test_MAE=0.672, time=249, train_MAE=0.423, train_loss=0.423, val_MAE=0.62, val_loss=0.62]Epoch 36:   4%|▎         | 36/1000 [2:34:33<66:42:09, 249.10s/it, lr=0.000125, test_MAE=0.632, time=249, train_MAE=0.422, train_loss=0.422, val_MAE=0.585, val_loss=0.585]Epoch 36:   4%|▎         | 37/1000 [2:34:33<66:37:22, 249.06s/it, lr=0.000125, test_MAE=0.632, time=249, train_MAE=0.422, train_loss=0.422, val_MAE=0.585, val_loss=0.585]Epoch 37:   4%|▎         | 37/1000 [2:34:33<66:37:22, 249.06s/it, lr=0.000125, test_MAE=0.632, time=249, train_MAE=0.422, train_loss=0.422, val_MAE=0.585, val_loss=0.585]Epoch 37:   4%|▎         | 37/1000 [2:38:43<66:37:22, 249.06s/it, lr=0.000125, test_MAE=0.641, time=250, train_MAE=0.409, train_loss=0.409, val_MAE=0.592, val_loss=0.592]Epoch 37:   4%|▍         | 38/1000 [2:38:43<66:36:40, 249.27s/it, lr=0.000125, test_MAE=0.641, time=250, train_MAE=0.409, train_loss=0.409, val_MAE=0.592, val_loss=0.592]Epoch 38:   4%|▍         | 38/1000 [2:38:43<66:36:40, 249.27s/it, lr=0.000125, test_MAE=0.641, time=250, train_MAE=0.409, train_loss=0.409, val_MAE=0.592, val_loss=0.592]Epoch 38:   4%|▍         | 38/1000 [2:42:51<66:36:40, 249.27s/it, lr=0.000125, test_MAE=0.638, time=248, train_MAE=0.408, train_loss=0.408, val_MAE=0.587, val_loss=0.587]Epoch 38:   4%|▍         | 39/1000 [2:42:51<66:28:05, 249.00s/it, lr=0.000125, test_MAE=0.638, time=248, train_MAE=0.408, train_loss=0.408, val_MAE=0.587, val_loss=0.587]Epoch 39:   4%|▍         | 39/1000 [2:42:51<66:28:05, 249.00s/it, lr=0.000125, test_MAE=0.638, time=248, train_MAE=0.408, train_loss=0.408, val_MAE=0.587, val_loss=0.587]Epoch 39:   4%|▍         | 39/1000 [2:47:00<66:28:05, 249.00s/it, lr=0.000125, test_MAE=0.662, time=249, train_MAE=0.395, train_loss=0.395, val_MAE=0.616, val_loss=0.616]Epoch    40: reducing learning rate of group 0 to 6.2500e-05.
Epoch 39:   4%|▍         | 40/1000 [2:47:00<66:23:23, 248.96s/it, lr=0.000125, test_MAE=0.662, time=249, train_MAE=0.395, train_loss=0.395, val_MAE=0.616, val_loss=0.616]Epoch 40:   4%|▍         | 40/1000 [2:47:00<66:23:23, 248.96s/it, lr=0.000125, test_MAE=0.662, time=249, train_MAE=0.395, train_loss=0.395, val_MAE=0.616, val_loss=0.616]Epoch 40:   4%|▍         | 40/1000 [2:51:10<66:23:23, 248.96s/it, lr=6.25e-5, test_MAE=0.639, time=250, train_MAE=0.394, train_loss=0.394, val_MAE=0.587, val_loss=0.587] Epoch 40:   4%|▍         | 41/1000 [2:51:10<66:23:13, 249.21s/it, lr=6.25e-5, test_MAE=0.639, time=250, train_MAE=0.394, train_loss=0.394, val_MAE=0.587, val_loss=0.587]Epoch 41:   4%|▍         | 41/1000 [2:51:10<66:23:13, 249.21s/it, lr=6.25e-5, test_MAE=0.639, time=250, train_MAE=0.394, train_loss=0.394, val_MAE=0.587, val_loss=0.587]Epoch 41:   4%|▍         | 41/1000 [2:55:18<66:23:13, 249.21s/it, lr=6.25e-5, test_MAE=0.649, time=248, train_MAE=0.389, train_loss=0.389, val_MAE=0.6, val_loss=0.6]    Epoch 41:   4%|▍         | 42/1000 [2:55:18<66:15:03, 248.96s/it, lr=6.25e-5, test_MAE=0.649, time=248, train_MAE=0.389, train_loss=0.389, val_MAE=0.6, val_loss=0.6]Epoch 42:   4%|▍         | 42/1000 [2:55:18<66:15:03, 248.96s/it, lr=6.25e-5, test_MAE=0.649, time=248, train_MAE=0.389, train_loss=0.389, val_MAE=0.6, val_loss=0.6]Epoch 42:   4%|▍         | 42/1000 [2:59:27<66:15:03, 248.96s/it, lr=6.25e-5, test_MAE=0.649, time=249, train_MAE=0.393, train_loss=0.393, val_MAE=0.604, val_loss=0.604]Epoch 42:   4%|▍         | 43/1000 [2:59:27<66:10:37, 248.94s/it, lr=6.25e-5, test_MAE=0.649, time=249, train_MAE=0.393, train_loss=0.393, val_MAE=0.604, val_loss=0.604]Epoch 43:   4%|▍         | 43/1000 [2:59:27<66:10:37, 248.94s/it, lr=6.25e-5, test_MAE=0.649, time=249, train_MAE=0.393, train_loss=0.393, val_MAE=0.604, val_loss=0.604]Epoch 43:   4%|▍         | 43/1000 [3:03:37<66:10:37, 248.94s/it, lr=6.25e-5, test_MAE=0.643, time=250, train_MAE=0.384, train_loss=0.384, val_MAE=0.59, val_loss=0.59]  Epoch 43:   4%|▍         | 44/1000 [3:03:37<66:10:35, 249.20s/it, lr=6.25e-5, test_MAE=0.643, time=250, train_MAE=0.384, train_loss=0.384, val_MAE=0.59, val_loss=0.59]Epoch 44:   4%|▍         | 44/1000 [3:03:37<66:10:35, 249.20s/it, lr=6.25e-5, test_MAE=0.643, time=250, train_MAE=0.384, train_loss=0.384, val_MAE=0.59, val_loss=0.59]Epoch 44:   4%|▍         | 44/1000 [3:07:45<66:10:35, 249.20s/it, lr=6.25e-5, test_MAE=0.638, time=248, train_MAE=0.38, train_loss=0.38, val_MAE=0.584, val_loss=0.584]Epoch 44:   4%|▍         | 45/1000 [3:07:45<66:02:36, 248.96s/it, lr=6.25e-5, test_MAE=0.638, time=248, train_MAE=0.38, train_loss=0.38, val_MAE=0.584, val_loss=0.584]Epoch 45:   4%|▍         | 45/1000 [3:07:45<66:02:36, 248.96s/it, lr=6.25e-5, test_MAE=0.638, time=248, train_MAE=0.38, train_loss=0.38, val_MAE=0.584, val_loss=0.584]Epoch 45:   4%|▍         | 45/1000 [3:11:55<66:02:36, 248.96s/it, lr=6.25e-5, test_MAE=0.643, time=249, train_MAE=0.386, train_loss=0.386, val_MAE=0.589, val_loss=0.589]Epoch    46: reducing learning rate of group 0 to 3.1250e-05.
Epoch 45:   5%|▍         | 46/1000 [3:11:55<66:00:01, 249.06s/it, lr=6.25e-5, test_MAE=0.643, time=249, train_MAE=0.386, train_loss=0.386, val_MAE=0.589, val_loss=0.589]Epoch 46:   5%|▍         | 46/1000 [3:11:55<66:00:01, 249.06s/it, lr=6.25e-5, test_MAE=0.643, time=249, train_MAE=0.386, train_loss=0.386, val_MAE=0.589, val_loss=0.589]Epoch 46:   5%|▍         | 46/1000 [3:16:04<66:00:01, 249.06s/it, lr=3.13e-5, test_MAE=0.641, time=250, train_MAE=0.379, train_loss=0.379, val_MAE=0.586, val_loss=0.586]Epoch 46:   5%|▍         | 47/1000 [3:16:04<65:58:38, 249.23s/it, lr=3.13e-5, test_MAE=0.641, time=250, train_MAE=0.379, train_loss=0.379, val_MAE=0.586, val_loss=0.586]Epoch 47:   5%|▍         | 47/1000 [3:16:04<65:58:38, 249.23s/it, lr=3.13e-5, test_MAE=0.641, time=250, train_MAE=0.379, train_loss=0.379, val_MAE=0.586, val_loss=0.586]Epoch 47:   5%|▍         | 47/1000 [3:20:12<65:58:38, 249.23s/it, lr=3.13e-5, test_MAE=0.645, time=248, train_MAE=0.379, train_loss=0.379, val_MAE=0.589, val_loss=0.589]Epoch 47:   5%|▍         | 48/1000 [3:20:12<65:50:07, 248.96s/it, lr=3.13e-5, test_MAE=0.645, time=248, train_MAE=0.379, train_loss=0.379, val_MAE=0.589, val_loss=0.589]Epoch 48:   5%|▍         | 48/1000 [3:20:12<65:50:07, 248.96s/it, lr=3.13e-5, test_MAE=0.645, time=248, train_MAE=0.379, train_loss=0.379, val_MAE=0.589, val_loss=0.589]Epoch 48:   5%|▍         | 48/1000 [3:24:21<65:50:07, 248.96s/it, lr=3.13e-5, test_MAE=0.64, time=249, train_MAE=0.373, train_loss=0.373, val_MAE=0.591, val_loss=0.591] Epoch 48:   5%|▍         | 49/1000 [3:24:21<65:45:53, 248.95s/it, lr=3.13e-5, test_MAE=0.64, time=249, train_MAE=0.373, train_loss=0.373, val_MAE=0.591, val_loss=0.591]Epoch 49:   5%|▍         | 49/1000 [3:24:21<65:45:53, 248.95s/it, lr=3.13e-5, test_MAE=0.64, time=249, train_MAE=0.373, train_loss=0.373, val_MAE=0.591, val_loss=0.591]Epoch 49:   5%|▍         | 49/1000 [3:28:31<65:45:53, 248.95s/it, lr=3.13e-5, test_MAE=0.64, time=250, train_MAE=0.372, train_loss=0.372, val_MAE=0.585, val_loss=0.585]Epoch 49:   5%|▌         | 50/1000 [3:28:31<65:46:18, 249.24s/it, lr=3.13e-5, test_MAE=0.64, time=250, train_MAE=0.372, train_loss=0.372, val_MAE=0.585, val_loss=0.585]Epoch 50:   5%|▌         | 50/1000 [3:28:31<65:46:18, 249.24s/it, lr=3.13e-5, test_MAE=0.64, time=250, train_MAE=0.372, train_loss=0.372, val_MAE=0.585, val_loss=0.585]Epoch 50:   5%|▌         | 50/1000 [3:32:40<65:46:18, 249.24s/it, lr=3.13e-5, test_MAE=0.646, time=248, train_MAE=0.378, train_loss=0.378, val_MAE=0.591, val_loss=0.591]Epoch 50:   5%|▌         | 51/1000 [3:32:40<65:37:51, 248.97s/it, lr=3.13e-5, test_MAE=0.646, time=248, train_MAE=0.378, train_loss=0.378, val_MAE=0.591, val_loss=0.591]Epoch 51:   5%|▌         | 51/1000 [3:32:40<65:37:51, 248.97s/it, lr=3.13e-5, test_MAE=0.646, time=248, train_MAE=0.378, train_loss=0.378, val_MAE=0.591, val_loss=0.591]Epoch 51:   5%|▌         | 51/1000 [3:36:48<65:37:51, 248.97s/it, lr=3.13e-5, test_MAE=0.641, time=249, train_MAE=0.366, train_loss=0.366, val_MAE=0.588, val_loss=0.588]Epoch    52: reducing learning rate of group 0 to 1.5625e-05.
Epoch 51:   5%|▌         | 52/1000 [3:36:48<65:31:53, 248.85s/it, lr=3.13e-5, test_MAE=0.641, time=249, train_MAE=0.366, train_loss=0.366, val_MAE=0.588, val_loss=0.588]Epoch 52:   5%|▌         | 52/1000 [3:36:48<65:31:53, 248.85s/it, lr=3.13e-5, test_MAE=0.641, time=249, train_MAE=0.366, train_loss=0.366, val_MAE=0.588, val_loss=0.588]Epoch 52:   5%|▌         | 52/1000 [3:40:58<65:31:53, 248.85s/it, lr=1.56e-5, test_MAE=0.639, time=250, train_MAE=0.365, train_loss=0.365, val_MAE=0.587, val_loss=0.587]Epoch 52:   5%|▌         | 53/1000 [3:40:58<65:31:35, 249.10s/it, lr=1.56e-5, test_MAE=0.639, time=250, train_MAE=0.365, train_loss=0.365, val_MAE=0.587, val_loss=0.587]Epoch 53:   5%|▌         | 53/1000 [3:40:58<65:31:35, 249.10s/it, lr=1.56e-5, test_MAE=0.639, time=250, train_MAE=0.365, train_loss=0.365, val_MAE=0.587, val_loss=0.587]Epoch 53:   5%|▌         | 53/1000 [3:45:06<65:31:35, 249.10s/it, lr=1.56e-5, test_MAE=0.643, time=248, train_MAE=0.364, train_loss=0.364, val_MAE=0.593, val_loss=0.593]Epoch 53:   5%|▌         | 54/1000 [3:45:06<65:23:04, 248.82s/it, lr=1.56e-5, test_MAE=0.643, time=248, train_MAE=0.364, train_loss=0.364, val_MAE=0.593, val_loss=0.593]Epoch 54:   5%|▌         | 54/1000 [3:45:06<65:23:04, 248.82s/it, lr=1.56e-5, test_MAE=0.643, time=248, train_MAE=0.364, train_loss=0.364, val_MAE=0.593, val_loss=0.593]Epoch 54:   5%|▌         | 54/1000 [3:49:15<65:23:04, 248.82s/it, lr=1.56e-5, test_MAE=0.64, time=249, train_MAE=0.36, train_loss=0.36, val_MAE=0.588, val_loss=0.588]   Epoch 54:   6%|▌         | 55/1000 [3:49:15<65:18:51, 248.82s/it, lr=1.56e-5, test_MAE=0.64, time=249, train_MAE=0.36, train_loss=0.36, val_MAE=0.588, val_loss=0.588]Epoch 55:   6%|▌         | 55/1000 [3:49:15<65:18:51, 248.82s/it, lr=1.56e-5, test_MAE=0.64, time=249, train_MAE=0.36, train_loss=0.36, val_MAE=0.588, val_loss=0.588]Epoch 55:   6%|▌         | 55/1000 [3:53:25<65:18:51, 248.82s/it, lr=1.56e-5, test_MAE=0.641, time=250, train_MAE=0.37, train_loss=0.37, val_MAE=0.591, val_loss=0.591]Epoch 55:   6%|▌         | 56/1000 [3:53:25<65:18:42, 249.07s/it, lr=1.56e-5, test_MAE=0.641, time=250, train_MAE=0.37, train_loss=0.37, val_MAE=0.591, val_loss=0.591]Epoch 56:   6%|▌         | 56/1000 [3:53:25<65:18:42, 249.07s/it, lr=1.56e-5, test_MAE=0.641, time=250, train_MAE=0.37, train_loss=0.37, val_MAE=0.591, val_loss=0.591]Epoch 56:   6%|▌         | 56/1000 [3:57:33<65:18:42, 249.07s/it, lr=1.56e-5, test_MAE=0.639, time=248, train_MAE=0.364, train_loss=0.364, val_MAE=0.586, val_loss=0.586]Epoch 56:   6%|▌         | 57/1000 [3:57:33<65:10:09, 248.79s/it, lr=1.56e-5, test_MAE=0.639, time=248, train_MAE=0.364, train_loss=0.364, val_MAE=0.586, val_loss=0.586]Epoch 57:   6%|▌         | 57/1000 [3:57:33<65:10:09, 248.79s/it, lr=1.56e-5, test_MAE=0.639, time=248, train_MAE=0.364, train_loss=0.364, val_MAE=0.586, val_loss=0.586]Epoch 57:   6%|▌         | 57/1000 [4:01:41<65:10:09, 248.79s/it, lr=1.56e-5, test_MAE=0.642, time=249, train_MAE=0.359, train_loss=0.359, val_MAE=0.593, val_loss=0.593]Epoch    58: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 57:   6%|▌         | 57/1000 [4:01:41<66:38:37, 254.42s/it, lr=1.56e-5, test_MAE=0.642, time=249, train_MAE=0.359, train_loss=0.359, val_MAE=0.593, val_loss=0.593]
Test MAE: 0.6423
Train MAE: 0.3335
Convergence Time (Epochs): 57.0000
TOTAL TIME TAKEN: 14660.3499s
AVG TIME PER EPOCH: 250.0030s
