I'm echoing to stdout
I'm echoing to stderr
My JobID is 57955708
I have 8 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.1997s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 2, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'poly_mlp', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_all', 'num_eigs': 16, 'bias_mode': 'spatial', 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 0.0, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/aug07/zinc_train_rec.csv', 'test': 'supp_data/molecules/aug07/zinc_test_rec.csv', 'val': 'supp_data/molecules/aug07/zinc_val_rec.csv'}, 'fixMissingPhi1': False, 'extraOrtho': False, 'doublePrecision': True, 'eigval_hidden_dim': 2, 'eigval_num_hidden_layer': 0, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [01:28<?, ?it/s, lr=0.001, test_MAE=0.758, time=88.6, train_MAE=0.897, train_loss=0.897, val_MAE=0.704, val_loss=0.704]Epoch 0:   0%|          | 1/1000 [01:28<24:35:21, 88.61s/it, lr=0.001, test_MAE=0.758, time=88.6, train_MAE=0.897, train_loss=0.897, val_MAE=0.704, val_loss=0.704]Epoch 1:   0%|          | 1/1000 [01:28<24:35:21, 88.61s/it, lr=0.001, test_MAE=0.758, time=88.6, train_MAE=0.897, train_loss=0.897, val_MAE=0.704, val_loss=0.704]Epoch 1:   0%|          | 1/1000 [02:37<24:35:21, 88.61s/it, lr=0.001, test_MAE=1.21, time=68.7, train_MAE=0.688, train_loss=0.688, val_MAE=1.18, val_loss=1.18]   Epoch 1:   0%|          | 2/1000 [02:37<22:54:36, 82.64s/it, lr=0.001, test_MAE=1.21, time=68.7, train_MAE=0.688, train_loss=0.688, val_MAE=1.18, val_loss=1.18]Epoch 2:   0%|          | 2/1000 [02:37<22:54:36, 82.64s/it, lr=0.001, test_MAE=1.21, time=68.7, train_MAE=0.688, train_loss=0.688, val_MAE=1.18, val_loss=1.18]Epoch 2:   0%|          | 2/1000 [03:45<22:54:36, 82.64s/it, lr=0.001, test_MAE=0.74, time=68.7, train_MAE=0.666, train_loss=0.666, val_MAE=0.697, val_loss=0.697]Epoch 2:   0%|          | 3/1000 [03:46<21:43:41, 78.46s/it, lr=0.001, test_MAE=0.74, time=68.7, train_MAE=0.666, train_loss=0.666, val_MAE=0.697, val_loss=0.697]Epoch 3:   0%|          | 3/1000 [03:46<21:43:41, 78.46s/it, lr=0.001, test_MAE=0.74, time=68.7, train_MAE=0.666, train_loss=0.666, val_MAE=0.697, val_loss=0.697]Epoch 3:   0%|          | 3/1000 [04:54<21:43:41, 78.46s/it, lr=0.001, test_MAE=0.8, time=68.3, train_MAE=0.653, train_loss=0.653, val_MAE=0.757, val_loss=0.757] Epoch 3:   0%|          | 4/1000 [04:54<20:52:05, 75.43s/it, lr=0.001, test_MAE=0.8, time=68.3, train_MAE=0.653, train_loss=0.653, val_MAE=0.757, val_loss=0.757]Epoch 4:   0%|          | 4/1000 [04:54<20:52:05, 75.43s/it, lr=0.001, test_MAE=0.8, time=68.3, train_MAE=0.653, train_loss=0.653, val_MAE=0.757, val_loss=0.757]Epoch 4:   0%|          | 4/1000 [06:02<20:52:05, 75.43s/it, lr=0.001, test_MAE=0.926, time=68, train_MAE=0.656, train_loss=0.656, val_MAE=0.887, val_loss=0.887]Epoch 4:   0%|          | 5/1000 [06:02<20:14:01, 73.21s/it, lr=0.001, test_MAE=0.926, time=68, train_MAE=0.656, train_loss=0.656, val_MAE=0.887, val_loss=0.887]Epoch 5:   0%|          | 5/1000 [06:02<20:14:01, 73.21s/it, lr=0.001, test_MAE=0.926, time=68, train_MAE=0.656, train_loss=0.656, val_MAE=0.887, val_loss=0.887]Epoch 5:   0%|          | 5/1000 [07:09<20:14:01, 73.21s/it, lr=0.001, test_MAE=0.655, time=67.5, train_MAE=0.64, train_loss=0.64, val_MAE=0.616, val_loss=0.616]Epoch 5:   1%|          | 6/1000 [07:09<19:44:42, 71.51s/it, lr=0.001, test_MAE=0.655, time=67.5, train_MAE=0.64, train_loss=0.64, val_MAE=0.616, val_loss=0.616]Epoch 6:   1%|          | 6/1000 [07:09<19:44:42, 71.51s/it, lr=0.001, test_MAE=0.655, time=67.5, train_MAE=0.64, train_loss=0.64, val_MAE=0.616, val_loss=0.616]Epoch 6:   1%|          | 6/1000 [08:16<19:44:42, 71.51s/it, lr=0.001, test_MAE=0.77, time=66.9, train_MAE=0.619, train_loss=0.619, val_MAE=0.721, val_loss=0.721]Epoch 6:   1%|          | 7/1000 [08:16<19:20:28, 70.12s/it, lr=0.001, test_MAE=0.77, time=66.9, train_MAE=0.619, train_loss=0.619, val_MAE=0.721, val_loss=0.721]Epoch 7:   1%|          | 7/1000 [08:16<19:20:28, 70.12s/it, lr=0.001, test_MAE=0.77, time=66.9, train_MAE=0.619, train_loss=0.619, val_MAE=0.721, val_loss=0.721]Epoch 7:   1%|          | 7/1000 [09:21<19:20:28, 70.12s/it, lr=0.001, test_MAE=0.702, time=64.4, train_MAE=0.621, train_loss=0.621, val_MAE=0.677, val_loss=0.677]Epoch 7:   1%|          | 8/1000 [09:21<18:51:17, 68.43s/it, lr=0.001, test_MAE=0.702, time=64.4, train_MAE=0.621, train_loss=0.621, val_MAE=0.677, val_loss=0.677]Epoch 8:   1%|          | 8/1000 [09:21<18:51:17, 68.43s/it, lr=0.001, test_MAE=0.702, time=64.4, train_MAE=0.621, train_loss=0.621, val_MAE=0.677, val_loss=0.677]Epoch 8:   1%|          | 8/1000 [10:24<18:51:17, 68.43s/it, lr=0.001, test_MAE=0.778, time=63, train_MAE=0.612, train_loss=0.612, val_MAE=0.735, val_loss=0.735]  Epoch 8:   1%|          | 9/1000 [10:24<18:23:41, 66.82s/it, lr=0.001, test_MAE=0.778, time=63, train_MAE=0.612, train_loss=0.612, val_MAE=0.735, val_loss=0.735]Epoch 9:   1%|          | 9/1000 [10:24<18:23:41, 66.82s/it, lr=0.001, test_MAE=0.778, time=63, train_MAE=0.612, train_loss=0.612, val_MAE=0.735, val_loss=0.735]Epoch 9:   1%|          | 9/1000 [11:27<18:23:41, 66.82s/it, lr=0.001, test_MAE=0.652, time=63.1, train_MAE=0.605, train_loss=0.605, val_MAE=0.611, val_loss=0.611]Epoch 9:   1%|          | 10/1000 [11:27<18:04:23, 65.72s/it, lr=0.001, test_MAE=0.652, time=63.1, train_MAE=0.605, train_loss=0.605, val_MAE=0.611, val_loss=0.611]Epoch 10:   1%|          | 10/1000 [11:27<18:04:23, 65.72s/it, lr=0.001, test_MAE=0.652, time=63.1, train_MAE=0.605, train_loss=0.605, val_MAE=0.611, val_loss=0.611]Epoch 10:   1%|          | 10/1000 [12:30<18:04:23, 65.72s/it, lr=0.001, test_MAE=0.647, time=63.2, train_MAE=0.603, train_loss=0.603, val_MAE=0.627, val_loss=0.627]Epoch 10:   1%|          | 11/1000 [12:30<17:51:09, 64.98s/it, lr=0.001, test_MAE=0.647, time=63.2, train_MAE=0.603, train_loss=0.603, val_MAE=0.627, val_loss=0.627]Epoch 11:   1%|          | 11/1000 [12:30<17:51:09, 64.98s/it, lr=0.001, test_MAE=0.647, time=63.2, train_MAE=0.603, train_loss=0.603, val_MAE=0.627, val_loss=0.627]Epoch 11:   1%|          | 11/1000 [13:33<17:51:09, 64.98s/it, lr=0.001, test_MAE=0.663, time=62.9, train_MAE=0.596, train_loss=0.596, val_MAE=0.624, val_loss=0.624]Epoch 11:   1%|          | 12/1000 [13:33<17:39:46, 64.36s/it, lr=0.001, test_MAE=0.663, time=62.9, train_MAE=0.596, train_loss=0.596, val_MAE=0.624, val_loss=0.624]Epoch 12:   1%|          | 12/1000 [13:33<17:39:46, 64.36s/it, lr=0.001, test_MAE=0.663, time=62.9, train_MAE=0.596, train_loss=0.596, val_MAE=0.624, val_loss=0.624]Epoch 12:   1%|          | 12/1000 [14:36<17:39:46, 64.36s/it, lr=0.001, test_MAE=0.633, time=63.1, train_MAE=0.598, train_loss=0.598, val_MAE=0.608, val_loss=0.608]Epoch 12:   1%|▏         | 13/1000 [14:36<17:32:31, 63.98s/it, lr=0.001, test_MAE=0.633, time=63.1, train_MAE=0.598, train_loss=0.598, val_MAE=0.608, val_loss=0.608]Epoch 13:   1%|▏         | 13/1000 [14:36<17:32:31, 63.98s/it, lr=0.001, test_MAE=0.633, time=63.1, train_MAE=0.598, train_loss=0.598, val_MAE=0.608, val_loss=0.608]Epoch 13:   1%|▏         | 13/1000 [15:39<17:32:31, 63.98s/it, lr=0.001, test_MAE=1.02, time=62.9, train_MAE=0.601, train_loss=0.601, val_MAE=0.988, val_loss=0.988] Epoch 13:   1%|▏         | 14/1000 [15:39<17:26:12, 63.66s/it, lr=0.001, test_MAE=1.02, time=62.9, train_MAE=0.601, train_loss=0.601, val_MAE=0.988, val_loss=0.988]Epoch 14:   1%|▏         | 14/1000 [15:39<17:26:12, 63.66s/it, lr=0.001, test_MAE=1.02, time=62.9, train_MAE=0.601, train_loss=0.601, val_MAE=0.988, val_loss=0.988]Epoch 14:   1%|▏         | 14/1000 [16:42<17:26:12, 63.66s/it, lr=0.001, test_MAE=0.663, time=62.6, train_MAE=0.602, train_loss=0.602, val_MAE=0.62, val_loss=0.62] Epoch 14:   2%|▏         | 15/1000 [16:42<17:19:54, 63.34s/it, lr=0.001, test_MAE=0.663, time=62.6, train_MAE=0.602, train_loss=0.602, val_MAE=0.62, val_loss=0.62]Epoch 15:   2%|▏         | 15/1000 [16:42<17:19:54, 63.34s/it, lr=0.001, test_MAE=0.663, time=62.6, train_MAE=0.602, train_loss=0.602, val_MAE=0.62, val_loss=0.62]Epoch 15:   2%|▏         | 15/1000 [17:45<17:19:54, 63.34s/it, lr=0.001, test_MAE=0.637, time=63.4, train_MAE=0.599, train_loss=0.599, val_MAE=0.605, val_loss=0.605]Epoch 15:   2%|▏         | 16/1000 [17:45<17:19:16, 63.37s/it, lr=0.001, test_MAE=0.637, time=63.4, train_MAE=0.599, train_loss=0.599, val_MAE=0.605, val_loss=0.605]Epoch 16:   2%|▏         | 16/1000 [17:45<17:19:16, 63.37s/it, lr=0.001, test_MAE=0.637, time=63.4, train_MAE=0.599, train_loss=0.599, val_MAE=0.605, val_loss=0.605]Epoch 16:   2%|▏         | 16/1000 [18:49<17:19:16, 63.37s/it, lr=0.001, test_MAE=0.634, time=63.3, train_MAE=0.591, train_loss=0.591, val_MAE=0.598, val_loss=0.598]Epoch 16:   2%|▏         | 17/1000 [18:49<17:18:04, 63.36s/it, lr=0.001, test_MAE=0.634, time=63.3, train_MAE=0.591, train_loss=0.591, val_MAE=0.598, val_loss=0.598]Epoch 17:   2%|▏         | 17/1000 [18:49<17:18:04, 63.36s/it, lr=0.001, test_MAE=0.634, time=63.3, train_MAE=0.591, train_loss=0.591, val_MAE=0.598, val_loss=0.598]Epoch 17:   2%|▏         | 17/1000 [19:51<17:18:04, 63.36s/it, lr=0.001, test_MAE=0.646, time=62.7, train_MAE=0.586, train_loss=0.586, val_MAE=0.598, val_loss=0.598]Epoch 17:   2%|▏         | 18/1000 [19:51<17:14:01, 63.18s/it, lr=0.001, test_MAE=0.646, time=62.7, train_MAE=0.586, train_loss=0.586, val_MAE=0.598, val_loss=0.598]Epoch 18:   2%|▏         | 18/1000 [19:51<17:14:01, 63.18s/it, lr=0.001, test_MAE=0.646, time=62.7, train_MAE=0.586, train_loss=0.586, val_MAE=0.598, val_loss=0.598]Epoch 18:   2%|▏         | 18/1000 [20:55<17:14:01, 63.18s/it, lr=0.001, test_MAE=0.755, time=63.3, train_MAE=0.573, train_loss=0.573, val_MAE=0.708, val_loss=0.708]Epoch 18:   2%|▏         | 19/1000 [20:55<17:13:27, 63.21s/it, lr=0.001, test_MAE=0.755, time=63.3, train_MAE=0.573, train_loss=0.573, val_MAE=0.708, val_loss=0.708]Epoch 19:   2%|▏         | 19/1000 [20:55<17:13:27, 63.21s/it, lr=0.001, test_MAE=0.755, time=63.3, train_MAE=0.573, train_loss=0.573, val_MAE=0.708, val_loss=0.708]Epoch 19:   2%|▏         | 19/1000 [21:58<17:13:27, 63.21s/it, lr=0.001, test_MAE=0.634, time=63, train_MAE=0.583, train_loss=0.583, val_MAE=0.593, val_loss=0.593]  Epoch 19:   2%|▏         | 20/1000 [21:58<17:11:34, 63.16s/it, lr=0.001, test_MAE=0.634, time=63, train_MAE=0.583, train_loss=0.583, val_MAE=0.593, val_loss=0.593]Epoch 20:   2%|▏         | 20/1000 [21:58<17:11:34, 63.16s/it, lr=0.001, test_MAE=0.634, time=63, train_MAE=0.583, train_loss=0.583, val_MAE=0.593, val_loss=0.593]Epoch 20:   2%|▏         | 20/1000 [23:01<17:11:34, 63.16s/it, lr=0.001, test_MAE=0.657, time=63.3, train_MAE=0.579, train_loss=0.579, val_MAE=0.615, val_loss=0.615]Epoch 20:   2%|▏         | 21/1000 [23:01<17:11:11, 63.20s/it, lr=0.001, test_MAE=0.657, time=63.3, train_MAE=0.579, train_loss=0.579, val_MAE=0.615, val_loss=0.615]Epoch 21:   2%|▏         | 21/1000 [23:01<17:11:11, 63.20s/it, lr=0.001, test_MAE=0.657, time=63.3, train_MAE=0.579, train_loss=0.579, val_MAE=0.615, val_loss=0.615]Epoch 21:   2%|▏         | 21/1000 [24:04<17:11:11, 63.20s/it, lr=0.001, test_MAE=0.656, time=63.4, train_MAE=0.577, train_loss=0.577, val_MAE=0.618, val_loss=0.618]Epoch 21:   2%|▏         | 22/1000 [24:04<17:11:27, 63.28s/it, lr=0.001, test_MAE=0.656, time=63.4, train_MAE=0.577, train_loss=0.577, val_MAE=0.618, val_loss=0.618]Epoch 22:   2%|▏         | 22/1000 [24:04<17:11:27, 63.28s/it, lr=0.001, test_MAE=0.656, time=63.4, train_MAE=0.577, train_loss=0.577, val_MAE=0.618, val_loss=0.618]Epoch 22:   2%|▏         | 22/1000 [25:07<17:11:27, 63.28s/it, lr=0.001, test_MAE=0.637, time=62.7, train_MAE=0.57, train_loss=0.57, val_MAE=0.608, val_loss=0.608]  Epoch 22:   2%|▏         | 23/1000 [25:07<17:07:49, 63.12s/it, lr=0.001, test_MAE=0.637, time=62.7, train_MAE=0.57, train_loss=0.57, val_MAE=0.608, val_loss=0.608]Epoch 23:   2%|▏         | 23/1000 [25:07<17:07:49, 63.12s/it, lr=0.001, test_MAE=0.637, time=62.7, train_MAE=0.57, train_loss=0.57, val_MAE=0.608, val_loss=0.608]Epoch 23:   2%|▏         | 23/1000 [26:11<17:07:49, 63.12s/it, lr=0.001, test_MAE=0.637, time=63.3, train_MAE=0.569, train_loss=0.569, val_MAE=0.586, val_loss=0.586]Epoch 23:   2%|▏         | 24/1000 [26:11<17:07:58, 63.20s/it, lr=0.001, test_MAE=0.637, time=63.3, train_MAE=0.569, train_loss=0.569, val_MAE=0.586, val_loss=0.586]Epoch 24:   2%|▏         | 24/1000 [26:11<17:07:58, 63.20s/it, lr=0.001, test_MAE=0.637, time=63.3, train_MAE=0.569, train_loss=0.569, val_MAE=0.586, val_loss=0.586]Epoch 24:   2%|▏         | 24/1000 [27:14<17:07:58, 63.20s/it, lr=0.001, test_MAE=0.655, time=63, train_MAE=0.567, train_loss=0.567, val_MAE=0.625, val_loss=0.625]  Epoch 24:   2%|▎         | 25/1000 [27:14<17:06:04, 63.14s/it, lr=0.001, test_MAE=0.655, time=63, train_MAE=0.567, train_loss=0.567, val_MAE=0.625, val_loss=0.625]Epoch 25:   2%|▎         | 25/1000 [27:14<17:06:04, 63.14s/it, lr=0.001, test_MAE=0.655, time=63, train_MAE=0.567, train_loss=0.567, val_MAE=0.625, val_loss=0.625]Epoch 25:   2%|▎         | 25/1000 [28:17<17:06:04, 63.14s/it, lr=0.001, test_MAE=0.618, time=63.2, train_MAE=0.567, train_loss=0.567, val_MAE=0.589, val_loss=0.589]Epoch 25:   3%|▎         | 26/1000 [28:17<17:05:26, 63.17s/it, lr=0.001, test_MAE=0.618, time=63.2, train_MAE=0.567, train_loss=0.567, val_MAE=0.589, val_loss=0.589]Epoch 26:   3%|▎         | 26/1000 [28:17<17:05:26, 63.17s/it, lr=0.001, test_MAE=0.618, time=63.2, train_MAE=0.567, train_loss=0.567, val_MAE=0.589, val_loss=0.589]Epoch 26:   3%|▎         | 26/1000 [29:20<17:05:26, 63.17s/it, lr=0.001, test_MAE=0.659, time=63.5, train_MAE=0.569, train_loss=0.569, val_MAE=0.626, val_loss=0.626]Epoch 26:   3%|▎         | 27/1000 [29:20<17:05:52, 63.26s/it, lr=0.001, test_MAE=0.659, time=63.5, train_MAE=0.569, train_loss=0.569, val_MAE=0.626, val_loss=0.626]Epoch 27:   3%|▎         | 27/1000 [29:20<17:05:52, 63.26s/it, lr=0.001, test_MAE=0.659, time=63.5, train_MAE=0.569, train_loss=0.569, val_MAE=0.626, val_loss=0.626]Epoch 27:   3%|▎         | 27/1000 [30:23<17:05:52, 63.26s/it, lr=0.001, test_MAE=0.675, time=62.9, train_MAE=0.569, train_loss=0.569, val_MAE=0.632, val_loss=0.632]Epoch 27:   3%|▎         | 28/1000 [30:23<17:03:08, 63.16s/it, lr=0.001, test_MAE=0.675, time=62.9, train_MAE=0.569, train_loss=0.569, val_MAE=0.632, val_loss=0.632]Epoch 28:   3%|▎         | 28/1000 [30:23<17:03:08, 63.16s/it, lr=0.001, test_MAE=0.675, time=62.9, train_MAE=0.569, train_loss=0.569, val_MAE=0.632, val_loss=0.632]Epoch 28:   3%|▎         | 28/1000 [31:26<17:03:08, 63.16s/it, lr=0.001, test_MAE=0.685, time=62.7, train_MAE=0.57, train_loss=0.57, val_MAE=0.644, val_loss=0.644]  Epoch 28:   3%|▎         | 29/1000 [31:26<16:59:49, 63.02s/it, lr=0.001, test_MAE=0.685, time=62.7, train_MAE=0.57, train_loss=0.57, val_MAE=0.644, val_loss=0.644]Epoch 29:   3%|▎         | 29/1000 [31:26<16:59:49, 63.02s/it, lr=0.001, test_MAE=0.685, time=62.7, train_MAE=0.57, train_loss=0.57, val_MAE=0.644, val_loss=0.644]Epoch 29:   3%|▎         | 29/1000 [32:29<16:59:49, 63.02s/it, lr=0.001, test_MAE=0.638, time=63.4, train_MAE=0.559, train_loss=0.559, val_MAE=0.593, val_loss=0.593]Epoch    30: reducing learning rate of group 0 to 5.0000e-04.
Epoch 29:   3%|▎         | 30/1000 [32:29<17:00:43, 63.14s/it, lr=0.001, test_MAE=0.638, time=63.4, train_MAE=0.559, train_loss=0.559, val_MAE=0.593, val_loss=0.593]Epoch 30:   3%|▎         | 30/1000 [32:29<17:00:43, 63.14s/it, lr=0.001, test_MAE=0.638, time=63.4, train_MAE=0.559, train_loss=0.559, val_MAE=0.593, val_loss=0.593]Epoch 30:   3%|▎         | 30/1000 [33:32<17:00:43, 63.14s/it, lr=0.0005, test_MAE=0.61, time=63, train_MAE=0.538, train_loss=0.538, val_MAE=0.579, val_loss=0.579]  Epoch 30:   3%|▎         | 31/1000 [33:32<16:58:55, 63.09s/it, lr=0.0005, test_MAE=0.61, time=63, train_MAE=0.538, train_loss=0.538, val_MAE=0.579, val_loss=0.579]Epoch 31:   3%|▎         | 31/1000 [33:32<16:58:55, 63.09s/it, lr=0.0005, test_MAE=0.61, time=63, train_MAE=0.538, train_loss=0.538, val_MAE=0.579, val_loss=0.579]Epoch 31:   3%|▎         | 31/1000 [34:35<16:58:55, 63.09s/it, lr=0.0005, test_MAE=0.621, time=62.8, train_MAE=0.537, train_loss=0.537, val_MAE=0.588, val_loss=0.588]Epoch 31:   3%|▎         | 32/1000 [34:35<16:56:33, 63.01s/it, lr=0.0005, test_MAE=0.621, time=62.8, train_MAE=0.537, train_loss=0.537, val_MAE=0.588, val_loss=0.588]Epoch 32:   3%|▎         | 32/1000 [34:35<16:56:33, 63.01s/it, lr=0.0005, test_MAE=0.621, time=62.8, train_MAE=0.537, train_loss=0.537, val_MAE=0.588, val_loss=0.588]Epoch 32:   3%|▎         | 32/1000 [35:38<16:56:33, 63.01s/it, lr=0.0005, test_MAE=0.609, time=63.2, train_MAE=0.528, train_loss=0.528, val_MAE=0.567, val_loss=0.567]Epoch 32:   3%|▎         | 33/1000 [35:38<16:56:41, 63.08s/it, lr=0.0005, test_MAE=0.609, time=63.2, train_MAE=0.528, train_loss=0.528, val_MAE=0.567, val_loss=0.567]Epoch 33:   3%|▎         | 33/1000 [35:38<16:56:41, 63.08s/it, lr=0.0005, test_MAE=0.609, time=63.2, train_MAE=0.528, train_loss=0.528, val_MAE=0.567, val_loss=0.567]Epoch 33:   3%|▎         | 33/1000 [36:41<16:56:41, 63.08s/it, lr=0.0005, test_MAE=0.616, time=62.9, train_MAE=0.527, train_loss=0.527, val_MAE=0.581, val_loss=0.581]Epoch 33:   3%|▎         | 34/1000 [36:41<16:54:44, 63.03s/it, lr=0.0005, test_MAE=0.616, time=62.9, train_MAE=0.527, train_loss=0.527, val_MAE=0.581, val_loss=0.581]Epoch 34:   3%|▎         | 34/1000 [36:41<16:54:44, 63.03s/it, lr=0.0005, test_MAE=0.616, time=62.9, train_MAE=0.527, train_loss=0.527, val_MAE=0.581, val_loss=0.581]Epoch 34:   3%|▎         | 34/1000 [37:44<16:54:44, 63.03s/it, lr=0.0005, test_MAE=0.637, time=62.8, train_MAE=0.526, train_loss=0.526, val_MAE=0.606, val_loss=0.606]Epoch 34:   4%|▎         | 35/1000 [37:44<16:52:41, 62.97s/it, lr=0.0005, test_MAE=0.637, time=62.8, train_MAE=0.526, train_loss=0.526, val_MAE=0.606, val_loss=0.606]Epoch 35:   4%|▎         | 35/1000 [37:44<16:52:41, 62.97s/it, lr=0.0005, test_MAE=0.637, time=62.8, train_MAE=0.526, train_loss=0.526, val_MAE=0.606, val_loss=0.606]Epoch 35:   4%|▎         | 35/1000 [38:47<16:52:41, 62.97s/it, lr=0.0005, test_MAE=0.605, time=63.3, train_MAE=0.526, train_loss=0.526, val_MAE=0.579, val_loss=0.579]Epoch 35:   4%|▎         | 36/1000 [38:47<16:53:23, 63.07s/it, lr=0.0005, test_MAE=0.605, time=63.3, train_MAE=0.526, train_loss=0.526, val_MAE=0.579, val_loss=0.579]Epoch 36:   4%|▎         | 36/1000 [38:47<16:53:23, 63.07s/it, lr=0.0005, test_MAE=0.605, time=63.3, train_MAE=0.526, train_loss=0.526, val_MAE=0.579, val_loss=0.579]Epoch 36:   4%|▎         | 36/1000 [39:50<16:53:23, 63.07s/it, lr=0.0005, test_MAE=0.675, time=62.6, train_MAE=0.533, train_loss=0.533, val_MAE=0.646, val_loss=0.646]Epoch 36:   4%|▎         | 37/1000 [39:50<16:50:20, 62.95s/it, lr=0.0005, test_MAE=0.675, time=62.6, train_MAE=0.533, train_loss=0.533, val_MAE=0.646, val_loss=0.646]Epoch 37:   4%|▎         | 37/1000 [39:50<16:50:20, 62.95s/it, lr=0.0005, test_MAE=0.675, time=62.6, train_MAE=0.533, train_loss=0.533, val_MAE=0.646, val_loss=0.646]Epoch 37:   4%|▎         | 37/1000 [40:52<16:50:20, 62.95s/it, lr=0.0005, test_MAE=0.599, time=62.3, train_MAE=0.522, train_loss=0.522, val_MAE=0.567, val_loss=0.567]Epoch 37:   4%|▍         | 38/1000 [40:52<16:46:35, 62.78s/it, lr=0.0005, test_MAE=0.599, time=62.3, train_MAE=0.522, train_loss=0.522, val_MAE=0.567, val_loss=0.567]Epoch 38:   4%|▍         | 38/1000 [40:52<16:46:35, 62.78s/it, lr=0.0005, test_MAE=0.599, time=62.3, train_MAE=0.522, train_loss=0.522, val_MAE=0.567, val_loss=0.567]Epoch 38:   4%|▍         | 38/1000 [41:55<16:46:35, 62.78s/it, lr=0.0005, test_MAE=0.724, time=62.9, train_MAE=0.528, train_loss=0.528, val_MAE=0.684, val_loss=0.684]Epoch 38:   4%|▍         | 39/1000 [41:55<16:46:15, 62.83s/it, lr=0.0005, test_MAE=0.724, time=62.9, train_MAE=0.528, train_loss=0.528, val_MAE=0.684, val_loss=0.684]Epoch 39:   4%|▍         | 39/1000 [41:55<16:46:15, 62.83s/it, lr=0.0005, test_MAE=0.724, time=62.9, train_MAE=0.528, train_loss=0.528, val_MAE=0.684, val_loss=0.684]Epoch 39:   4%|▍         | 39/1000 [42:58<16:46:15, 62.83s/it, lr=0.0005, test_MAE=0.714, time=62.8, train_MAE=0.522, train_loss=0.522, val_MAE=0.684, val_loss=0.684]Epoch 39:   4%|▍         | 40/1000 [42:58<16:45:26, 62.84s/it, lr=0.0005, test_MAE=0.714, time=62.8, train_MAE=0.522, train_loss=0.522, val_MAE=0.684, val_loss=0.684]Epoch 40:   4%|▍         | 40/1000 [42:58<16:45:26, 62.84s/it, lr=0.0005, test_MAE=0.714, time=62.8, train_MAE=0.522, train_loss=0.522, val_MAE=0.684, val_loss=0.684]Epoch 40:   4%|▍         | 40/1000 [44:01<16:45:26, 62.84s/it, lr=0.0005, test_MAE=0.643, time=62.8, train_MAE=0.518, train_loss=0.518, val_MAE=0.603, val_loss=0.603]Epoch 40:   4%|▍         | 41/1000 [44:01<16:44:25, 62.84s/it, lr=0.0005, test_MAE=0.643, time=62.8, train_MAE=0.518, train_loss=0.518, val_MAE=0.603, val_loss=0.603]Epoch 41:   4%|▍         | 41/1000 [44:01<16:44:25, 62.84s/it, lr=0.0005, test_MAE=0.643, time=62.8, train_MAE=0.518, train_loss=0.518, val_MAE=0.603, val_loss=0.603]Epoch 41:   4%|▍         | 41/1000 [45:04<16:44:25, 62.84s/it, lr=0.0005, test_MAE=0.632, time=62.9, train_MAE=0.522, train_loss=0.522, val_MAE=0.595, val_loss=0.595]Epoch 41:   4%|▍         | 42/1000 [45:04<16:43:40, 62.86s/it, lr=0.0005, test_MAE=0.632, time=62.9, train_MAE=0.522, train_loss=0.522, val_MAE=0.595, val_loss=0.595]Epoch 42:   4%|▍         | 42/1000 [45:04<16:43:40, 62.86s/it, lr=0.0005, test_MAE=0.632, time=62.9, train_MAE=0.522, train_loss=0.522, val_MAE=0.595, val_loss=0.595]Epoch 42:   4%|▍         | 42/1000 [46:06<16:43:40, 62.86s/it, lr=0.0005, test_MAE=0.614, time=62.2, train_MAE=0.518, train_loss=0.518, val_MAE=0.577, val_loss=0.577]Epoch 42:   4%|▍         | 43/1000 [46:06<16:39:39, 62.67s/it, lr=0.0005, test_MAE=0.614, time=62.2, train_MAE=0.518, train_loss=0.518, val_MAE=0.577, val_loss=0.577]Epoch 43:   4%|▍         | 43/1000 [46:06<16:39:39, 62.67s/it, lr=0.0005, test_MAE=0.614, time=62.2, train_MAE=0.518, train_loss=0.518, val_MAE=0.577, val_loss=0.577]Epoch 43:   4%|▍         | 43/1000 [47:09<16:39:39, 62.67s/it, lr=0.0005, test_MAE=0.686, time=62.9, train_MAE=0.51, train_loss=0.51, val_MAE=0.651, val_loss=0.651]  Epoch    44: reducing learning rate of group 0 to 2.5000e-04.
Epoch 43:   4%|▍         | 44/1000 [47:09<16:39:49, 62.75s/it, lr=0.0005, test_MAE=0.686, time=62.9, train_MAE=0.51, train_loss=0.51, val_MAE=0.651, val_loss=0.651]Epoch 44:   4%|▍         | 44/1000 [47:09<16:39:49, 62.75s/it, lr=0.0005, test_MAE=0.686, time=62.9, train_MAE=0.51, train_loss=0.51, val_MAE=0.651, val_loss=0.651]Epoch 44:   4%|▍         | 44/1000 [48:12<16:39:49, 62.75s/it, lr=0.00025, test_MAE=0.609, time=62.9, train_MAE=0.506, train_loss=0.506, val_MAE=0.571, val_loss=0.571]Epoch 44:   4%|▍         | 45/1000 [48:12<16:39:44, 62.81s/it, lr=0.00025, test_MAE=0.609, time=62.9, train_MAE=0.506, train_loss=0.506, val_MAE=0.571, val_loss=0.571]Epoch 45:   4%|▍         | 45/1000 [48:12<16:39:44, 62.81s/it, lr=0.00025, test_MAE=0.609, time=62.9, train_MAE=0.506, train_loss=0.506, val_MAE=0.571, val_loss=0.571]Epoch 45:   4%|▍         | 45/1000 [49:15<16:39:44, 62.81s/it, lr=0.00025, test_MAE=0.615, time=62.6, train_MAE=0.496, train_loss=0.496, val_MAE=0.578, val_loss=0.578]Epoch 45:   5%|▍         | 46/1000 [49:15<16:37:55, 62.76s/it, lr=0.00025, test_MAE=0.615, time=62.6, train_MAE=0.496, train_loss=0.496, val_MAE=0.578, val_loss=0.578]Epoch 46:   5%|▍         | 46/1000 [49:15<16:37:55, 62.76s/it, lr=0.00025, test_MAE=0.615, time=62.6, train_MAE=0.496, train_loss=0.496, val_MAE=0.578, val_loss=0.578]Epoch 46:   5%|▍         | 46/1000 [50:18<16:37:55, 62.76s/it, lr=0.00025, test_MAE=0.6, time=62.8, train_MAE=0.5, train_loss=0.5, val_MAE=0.577, val_loss=0.577]      Epoch 46:   5%|▍         | 47/1000 [50:18<16:37:13, 62.78s/it, lr=0.00025, test_MAE=0.6, time=62.8, train_MAE=0.5, train_loss=0.5, val_MAE=0.577, val_loss=0.577]Epoch 47:   5%|▍         | 47/1000 [50:18<16:37:13, 62.78s/it, lr=0.00025, test_MAE=0.6, time=62.8, train_MAE=0.5, train_loss=0.5, val_MAE=0.577, val_loss=0.577]Epoch 47:   5%|▍         | 47/1000 [51:20<16:37:13, 62.78s/it, lr=0.00025, test_MAE=0.619, time=62.2, train_MAE=0.498, train_loss=0.498, val_MAE=0.594, val_loss=0.594]Epoch 47:   5%|▍         | 48/1000 [51:20<16:33:33, 62.62s/it, lr=0.00025, test_MAE=0.619, time=62.2, train_MAE=0.498, train_loss=0.498, val_MAE=0.594, val_loss=0.594]Epoch 48:   5%|▍         | 48/1000 [51:20<16:33:33, 62.62s/it, lr=0.00025, test_MAE=0.619, time=62.2, train_MAE=0.498, train_loss=0.498, val_MAE=0.594, val_loss=0.594]Epoch 48:   5%|▍         | 48/1000 [52:22<16:33:33, 62.62s/it, lr=0.00025, test_MAE=0.599, time=62.3, train_MAE=0.488, train_loss=0.488, val_MAE=0.574, val_loss=0.574]Epoch 48:   5%|▍         | 49/1000 [52:22<16:31:18, 62.54s/it, lr=0.00025, test_MAE=0.599, time=62.3, train_MAE=0.488, train_loss=0.488, val_MAE=0.574, val_loss=0.574]Epoch 49:   5%|▍         | 49/1000 [52:22<16:31:18, 62.54s/it, lr=0.00025, test_MAE=0.599, time=62.3, train_MAE=0.488, train_loss=0.488, val_MAE=0.574, val_loss=0.574]Epoch 49:   5%|▍         | 49/1000 [53:26<16:31:18, 62.54s/it, lr=0.00025, test_MAE=0.608, time=63.4, train_MAE=0.489, train_loss=0.489, val_MAE=0.581, val_loss=0.581]Epoch    50: reducing learning rate of group 0 to 1.2500e-04.
Epoch 49:   5%|▌         | 50/1000 [53:26<16:34:13, 62.79s/it, lr=0.00025, test_MAE=0.608, time=63.4, train_MAE=0.489, train_loss=0.489, val_MAE=0.581, val_loss=0.581]Epoch 50:   5%|▌         | 50/1000 [53:26<16:34:13, 62.79s/it, lr=0.00025, test_MAE=0.608, time=63.4, train_MAE=0.489, train_loss=0.489, val_MAE=0.581, val_loss=0.581]Epoch 50:   5%|▌         | 50/1000 [54:28<16:34:13, 62.79s/it, lr=0.000125, test_MAE=0.594, time=62.7, train_MAE=0.479, train_loss=0.479, val_MAE=0.57, val_loss=0.57] Epoch 50:   5%|▌         | 51/1000 [54:28<16:32:43, 62.76s/it, lr=0.000125, test_MAE=0.594, time=62.7, train_MAE=0.479, train_loss=0.479, val_MAE=0.57, val_loss=0.57]Epoch 51:   5%|▌         | 51/1000 [54:28<16:32:43, 62.76s/it, lr=0.000125, test_MAE=0.594, time=62.7, train_MAE=0.479, train_loss=0.479, val_MAE=0.57, val_loss=0.57]Epoch 51:   5%|▌         | 51/1000 [55:31<16:32:43, 62.76s/it, lr=0.000125, test_MAE=0.598, time=62.4, train_MAE=0.476, train_loss=0.476, val_MAE=0.572, val_loss=0.572]Epoch 51:   5%|▌         | 52/1000 [55:31<16:29:59, 62.66s/it, lr=0.000125, test_MAE=0.598, time=62.4, train_MAE=0.476, train_loss=0.476, val_MAE=0.572, val_loss=0.572]Epoch 52:   5%|▌         | 52/1000 [55:31<16:29:59, 62.66s/it, lr=0.000125, test_MAE=0.598, time=62.4, train_MAE=0.476, train_loss=0.476, val_MAE=0.572, val_loss=0.572]Epoch 52:   5%|▌         | 52/1000 [56:33<16:29:59, 62.66s/it, lr=0.000125, test_MAE=0.598, time=62.8, train_MAE=0.475, train_loss=0.475, val_MAE=0.566, val_loss=0.566]Epoch 52:   5%|▌         | 53/1000 [56:34<16:29:44, 62.71s/it, lr=0.000125, test_MAE=0.598, time=62.8, train_MAE=0.475, train_loss=0.475, val_MAE=0.566, val_loss=0.566]Epoch 53:   5%|▌         | 53/1000 [56:34<16:29:44, 62.71s/it, lr=0.000125, test_MAE=0.598, time=62.8, train_MAE=0.475, train_loss=0.475, val_MAE=0.566, val_loss=0.566]Epoch 53:   5%|▌         | 53/1000 [57:36<16:29:44, 62.71s/it, lr=0.000125, test_MAE=0.598, time=62.6, train_MAE=0.482, train_loss=0.482, val_MAE=0.569, val_loss=0.569]Epoch 53:   5%|▌         | 54/1000 [57:36<16:28:28, 62.69s/it, lr=0.000125, test_MAE=0.598, time=62.6, train_MAE=0.482, train_loss=0.482, val_MAE=0.569, val_loss=0.569]Epoch 54:   5%|▌         | 54/1000 [57:36<16:28:28, 62.69s/it, lr=0.000125, test_MAE=0.598, time=62.6, train_MAE=0.482, train_loss=0.482, val_MAE=0.569, val_loss=0.569]Epoch 54:   5%|▌         | 54/1000 [58:39<16:28:28, 62.69s/it, lr=0.000125, test_MAE=0.596, time=62.6, train_MAE=0.478, train_loss=0.478, val_MAE=0.572, val_loss=0.572]Epoch 54:   6%|▌         | 55/1000 [58:39<16:27:22, 62.69s/it, lr=0.000125, test_MAE=0.596, time=62.6, train_MAE=0.478, train_loss=0.478, val_MAE=0.572, val_loss=0.572]Epoch 55:   6%|▌         | 55/1000 [58:39<16:27:22, 62.69s/it, lr=0.000125, test_MAE=0.596, time=62.6, train_MAE=0.478, train_loss=0.478, val_MAE=0.572, val_loss=0.572]Epoch 55:   6%|▌         | 55/1000 [59:42<16:27:22, 62.69s/it, lr=0.000125, test_MAE=0.608, time=63, train_MAE=0.475, train_loss=0.475, val_MAE=0.577, val_loss=0.577]  Epoch 55:   6%|▌         | 56/1000 [59:42<16:27:41, 62.78s/it, lr=0.000125, test_MAE=0.608, time=63, train_MAE=0.475, train_loss=0.475, val_MAE=0.577, val_loss=0.577]Epoch 56:   6%|▌         | 56/1000 [59:42<16:27:41, 62.78s/it, lr=0.000125, test_MAE=0.608, time=63, train_MAE=0.475, train_loss=0.475, val_MAE=0.577, val_loss=0.577]Epoch 56:   6%|▌         | 56/1000 [1:00:44<16:27:41, 62.78s/it, lr=0.000125, test_MAE=0.605, time=62.5, train_MAE=0.48, train_loss=0.48, val_MAE=0.579, val_loss=0.579]Epoch 56:   6%|▌         | 57/1000 [1:00:44<16:25:20, 62.69s/it, lr=0.000125, test_MAE=0.605, time=62.5, train_MAE=0.48, train_loss=0.48, val_MAE=0.579, val_loss=0.579]Epoch 57:   6%|▌         | 57/1000 [1:00:44<16:25:20, 62.69s/it, lr=0.000125, test_MAE=0.605, time=62.5, train_MAE=0.48, train_loss=0.48, val_MAE=0.579, val_loss=0.579]Epoch 57:   6%|▌         | 57/1000 [1:01:47<16:25:20, 62.69s/it, lr=0.000125, test_MAE=0.602, time=62.3, train_MAE=0.471, train_loss=0.471, val_MAE=0.57, val_loss=0.57]Epoch 57:   6%|▌         | 58/1000 [1:01:47<16:22:36, 62.59s/it, lr=0.000125, test_MAE=0.602, time=62.3, train_MAE=0.471, train_loss=0.471, val_MAE=0.57, val_loss=0.57]Epoch 58:   6%|▌         | 58/1000 [1:01:47<16:22:36, 62.59s/it, lr=0.000125, test_MAE=0.602, time=62.3, train_MAE=0.471, train_loss=0.471, val_MAE=0.57, val_loss=0.57]Epoch 58:   6%|▌         | 58/1000 [1:02:50<16:22:36, 62.59s/it, lr=0.000125, test_MAE=0.594, time=63.1, train_MAE=0.471, train_loss=0.471, val_MAE=0.568, val_loss=0.568]Epoch    59: reducing learning rate of group 0 to 6.2500e-05.
Epoch 58:   6%|▌         | 59/1000 [1:02:50<16:24:02, 62.74s/it, lr=0.000125, test_MAE=0.594, time=63.1, train_MAE=0.471, train_loss=0.471, val_MAE=0.568, val_loss=0.568]Epoch 59:   6%|▌         | 59/1000 [1:02:50<16:24:02, 62.74s/it, lr=0.000125, test_MAE=0.594, time=63.1, train_MAE=0.471, train_loss=0.471, val_MAE=0.568, val_loss=0.568]Epoch 59:   6%|▌         | 59/1000 [1:03:53<16:24:02, 62.74s/it, lr=6.25e-5, test_MAE=0.599, time=62.8, train_MAE=0.473, train_loss=0.473, val_MAE=0.572, val_loss=0.572] Epoch 59:   6%|▌         | 60/1000 [1:03:53<16:23:37, 62.78s/it, lr=6.25e-5, test_MAE=0.599, time=62.8, train_MAE=0.473, train_loss=0.473, val_MAE=0.572, val_loss=0.572]Epoch 60:   6%|▌         | 60/1000 [1:03:53<16:23:37, 62.78s/it, lr=6.25e-5, test_MAE=0.599, time=62.8, train_MAE=0.473, train_loss=0.473, val_MAE=0.572, val_loss=0.572]Epoch 60:   6%|▌         | 60/1000 [1:04:55<16:23:37, 62.78s/it, lr=6.25e-5, test_MAE=0.6, time=62.7, train_MAE=0.474, train_loss=0.474, val_MAE=0.569, val_loss=0.569]  Epoch 60:   6%|▌         | 61/1000 [1:04:55<16:22:07, 62.76s/it, lr=6.25e-5, test_MAE=0.6, time=62.7, train_MAE=0.474, train_loss=0.474, val_MAE=0.569, val_loss=0.569]Epoch 61:   6%|▌         | 61/1000 [1:04:55<16:22:07, 62.76s/it, lr=6.25e-5, test_MAE=0.6, time=62.7, train_MAE=0.474, train_loss=0.474, val_MAE=0.569, val_loss=0.569]Epoch 61:   6%|▌         | 61/1000 [1:05:58<16:22:07, 62.76s/it, lr=6.25e-5, test_MAE=0.6, time=62.9, train_MAE=0.463, train_loss=0.463, val_MAE=0.573, val_loss=0.573]Epoch 61:   6%|▌         | 62/1000 [1:05:58<16:21:46, 62.80s/it, lr=6.25e-5, test_MAE=0.6, time=62.9, train_MAE=0.463, train_loss=0.463, val_MAE=0.573, val_loss=0.573]Epoch 62:   6%|▌         | 62/1000 [1:05:58<16:21:46, 62.80s/it, lr=6.25e-5, test_MAE=0.6, time=62.9, train_MAE=0.463, train_loss=0.463, val_MAE=0.573, val_loss=0.573]Epoch 62:   6%|▌         | 62/1000 [1:07:00<16:21:46, 62.80s/it, lr=6.25e-5, test_MAE=0.606, time=62.2, train_MAE=0.47, train_loss=0.47, val_MAE=0.577, val_loss=0.577]Epoch 62:   6%|▋         | 63/1000 [1:07:00<16:18:01, 62.63s/it, lr=6.25e-5, test_MAE=0.606, time=62.2, train_MAE=0.47, train_loss=0.47, val_MAE=0.577, val_loss=0.577]Epoch 63:   6%|▋         | 63/1000 [1:07:00<16:18:01, 62.63s/it, lr=6.25e-5, test_MAE=0.606, time=62.2, train_MAE=0.47, train_loss=0.47, val_MAE=0.577, val_loss=0.577]Epoch 63:   6%|▋         | 63/1000 [1:08:04<16:18:01, 62.63s/it, lr=6.25e-5, test_MAE=0.595, time=63.1, train_MAE=0.471, train_loss=0.471, val_MAE=0.569, val_loss=0.569]Epoch 63:   6%|▋         | 64/1000 [1:08:04<16:19:22, 62.78s/it, lr=6.25e-5, test_MAE=0.595, time=63.1, train_MAE=0.471, train_loss=0.471, val_MAE=0.569, val_loss=0.569]Epoch 64:   6%|▋         | 64/1000 [1:08:04<16:19:22, 62.78s/it, lr=6.25e-5, test_MAE=0.595, time=63.1, train_MAE=0.471, train_loss=0.471, val_MAE=0.569, val_loss=0.569]Epoch 64:   6%|▋         | 64/1000 [1:09:06<16:19:22, 62.78s/it, lr=6.25e-5, test_MAE=0.597, time=62.6, train_MAE=0.465, train_loss=0.465, val_MAE=0.568, val_loss=0.568]Epoch    65: reducing learning rate of group 0 to 3.1250e-05.
Epoch 64:   6%|▋         | 65/1000 [1:09:06<16:17:44, 62.74s/it, lr=6.25e-5, test_MAE=0.597, time=62.6, train_MAE=0.465, train_loss=0.465, val_MAE=0.568, val_loss=0.568]Epoch 65:   6%|▋         | 65/1000 [1:09:06<16:17:44, 62.74s/it, lr=6.25e-5, test_MAE=0.597, time=62.6, train_MAE=0.465, train_loss=0.465, val_MAE=0.568, val_loss=0.568]Epoch 65:   6%|▋         | 65/1000 [1:10:09<16:17:44, 62.74s/it, lr=3.13e-5, test_MAE=0.595, time=62.5, train_MAE=0.463, train_loss=0.463, val_MAE=0.568, val_loss=0.568]Epoch 65:   7%|▋         | 66/1000 [1:10:09<16:15:57, 62.70s/it, lr=3.13e-5, test_MAE=0.595, time=62.5, train_MAE=0.463, train_loss=0.463, val_MAE=0.568, val_loss=0.568]Epoch 66:   7%|▋         | 66/1000 [1:10:09<16:15:57, 62.70s/it, lr=3.13e-5, test_MAE=0.595, time=62.5, train_MAE=0.463, train_loss=0.463, val_MAE=0.568, val_loss=0.568]Epoch 66:   7%|▋         | 66/1000 [1:11:12<16:15:57, 62.70s/it, lr=3.13e-5, test_MAE=0.596, time=62.9, train_MAE=0.469, train_loss=0.469, val_MAE=0.57, val_loss=0.57]  Epoch 66:   7%|▋         | 67/1000 [1:11:12<16:15:58, 62.76s/it, lr=3.13e-5, test_MAE=0.596, time=62.9, train_MAE=0.469, train_loss=0.469, val_MAE=0.57, val_loss=0.57]Epoch 67:   7%|▋         | 67/1000 [1:11:12<16:15:58, 62.76s/it, lr=3.13e-5, test_MAE=0.596, time=62.9, train_MAE=0.469, train_loss=0.469, val_MAE=0.57, val_loss=0.57]Epoch 67:   7%|▋         | 67/1000 [1:12:14<16:15:58, 62.76s/it, lr=3.13e-5, test_MAE=0.594, time=62.5, train_MAE=0.464, train_loss=0.464, val_MAE=0.568, val_loss=0.568]Epoch 67:   7%|▋         | 68/1000 [1:12:14<16:13:43, 62.69s/it, lr=3.13e-5, test_MAE=0.594, time=62.5, train_MAE=0.464, train_loss=0.464, val_MAE=0.568, val_loss=0.568]Epoch 68:   7%|▋         | 68/1000 [1:12:14<16:13:43, 62.69s/it, lr=3.13e-5, test_MAE=0.594, time=62.5, train_MAE=0.464, train_loss=0.464, val_MAE=0.568, val_loss=0.568]Epoch 68:   7%|▋         | 68/1000 [1:13:17<16:13:43, 62.69s/it, lr=3.13e-5, test_MAE=0.594, time=62.5, train_MAE=0.465, train_loss=0.465, val_MAE=0.568, val_loss=0.568]Epoch 68:   7%|▋         | 69/1000 [1:13:17<16:11:57, 62.64s/it, lr=3.13e-5, test_MAE=0.594, time=62.5, train_MAE=0.465, train_loss=0.465, val_MAE=0.568, val_loss=0.568]Epoch 69:   7%|▋         | 69/1000 [1:13:17<16:11:57, 62.64s/it, lr=3.13e-5, test_MAE=0.594, time=62.5, train_MAE=0.465, train_loss=0.465, val_MAE=0.568, val_loss=0.568]Epoch 69:   7%|▋         | 69/1000 [1:14:20<16:11:57, 62.64s/it, lr=3.13e-5, test_MAE=0.601, time=63.5, train_MAE=0.463, train_loss=0.463, val_MAE=0.574, val_loss=0.574]Epoch 69:   7%|▋         | 70/1000 [1:14:20<16:15:06, 62.91s/it, lr=3.13e-5, test_MAE=0.601, time=63.5, train_MAE=0.463, train_loss=0.463, val_MAE=0.574, val_loss=0.574]Epoch 70:   7%|▋         | 70/1000 [1:14:20<16:15:06, 62.91s/it, lr=3.13e-5, test_MAE=0.601, time=63.5, train_MAE=0.463, train_loss=0.463, val_MAE=0.574, val_loss=0.574]Epoch 70:   7%|▋         | 70/1000 [1:15:23<16:15:06, 62.91s/it, lr=3.13e-5, test_MAE=0.594, time=62.5, train_MAE=0.46, train_loss=0.46, val_MAE=0.569, val_loss=0.569]  Epoch    71: reducing learning rate of group 0 to 1.5625e-05.
Epoch 70:   7%|▋         | 71/1000 [1:15:23<16:12:10, 62.79s/it, lr=3.13e-5, test_MAE=0.594, time=62.5, train_MAE=0.46, train_loss=0.46, val_MAE=0.569, val_loss=0.569]Epoch 71:   7%|▋         | 71/1000 [1:15:23<16:12:10, 62.79s/it, lr=3.13e-5, test_MAE=0.594, time=62.5, train_MAE=0.46, train_loss=0.46, val_MAE=0.569, val_loss=0.569]Epoch 71:   7%|▋         | 71/1000 [1:16:25<16:12:10, 62.79s/it, lr=1.56e-5, test_MAE=0.594, time=62.2, train_MAE=0.46, train_loss=0.46, val_MAE=0.567, val_loss=0.567]Epoch 71:   7%|▋         | 72/1000 [1:16:25<16:08:22, 62.61s/it, lr=1.56e-5, test_MAE=0.594, time=62.2, train_MAE=0.46, train_loss=0.46, val_MAE=0.567, val_loss=0.567]Epoch 72:   7%|▋         | 72/1000 [1:16:25<16:08:22, 62.61s/it, lr=1.56e-5, test_MAE=0.594, time=62.2, train_MAE=0.46, train_loss=0.46, val_MAE=0.567, val_loss=0.567]Epoch 72:   7%|▋         | 72/1000 [1:17:28<16:08:22, 62.61s/it, lr=1.56e-5, test_MAE=0.594, time=63, train_MAE=0.459, train_loss=0.459, val_MAE=0.566, val_loss=0.566]Epoch 72:   7%|▋         | 73/1000 [1:17:28<16:09:09, 62.73s/it, lr=1.56e-5, test_MAE=0.594, time=63, train_MAE=0.459, train_loss=0.459, val_MAE=0.566, val_loss=0.566]Epoch 73:   7%|▋         | 73/1000 [1:17:28<16:09:09, 62.73s/it, lr=1.56e-5, test_MAE=0.594, time=63, train_MAE=0.459, train_loss=0.459, val_MAE=0.566, val_loss=0.566]Epoch 73:   7%|▋         | 73/1000 [1:18:31<16:09:09, 62.73s/it, lr=1.56e-5, test_MAE=0.594, time=62.8, train_MAE=0.462, train_loss=0.462, val_MAE=0.567, val_loss=0.567]Epoch 73:   7%|▋         | 74/1000 [1:18:31<16:08:45, 62.77s/it, lr=1.56e-5, test_MAE=0.594, time=62.8, train_MAE=0.462, train_loss=0.462, val_MAE=0.567, val_loss=0.567]Epoch 74:   7%|▋         | 74/1000 [1:18:31<16:08:45, 62.77s/it, lr=1.56e-5, test_MAE=0.594, time=62.8, train_MAE=0.462, train_loss=0.462, val_MAE=0.567, val_loss=0.567]Epoch 74:   7%|▋         | 74/1000 [1:19:33<16:08:45, 62.77s/it, lr=1.56e-5, test_MAE=0.595, time=62.4, train_MAE=0.458, train_loss=0.458, val_MAE=0.569, val_loss=0.569]Epoch 74:   8%|▊         | 75/1000 [1:19:33<16:06:16, 62.68s/it, lr=1.56e-5, test_MAE=0.595, time=62.4, train_MAE=0.458, train_loss=0.458, val_MAE=0.569, val_loss=0.569]Epoch 75:   8%|▊         | 75/1000 [1:19:33<16:06:16, 62.68s/it, lr=1.56e-5, test_MAE=0.595, time=62.4, train_MAE=0.458, train_loss=0.458, val_MAE=0.569, val_loss=0.569]Epoch 75:   8%|▊         | 75/1000 [1:20:36<16:06:16, 62.68s/it, lr=1.56e-5, test_MAE=0.594, time=62.9, train_MAE=0.47, train_loss=0.47, val_MAE=0.566, val_loss=0.566]  Epoch 75:   8%|▊         | 76/1000 [1:20:36<16:06:37, 62.77s/it, lr=1.56e-5, test_MAE=0.594, time=62.9, train_MAE=0.47, train_loss=0.47, val_MAE=0.566, val_loss=0.566]Epoch 76:   8%|▊         | 76/1000 [1:20:36<16:06:37, 62.77s/it, lr=1.56e-5, test_MAE=0.594, time=62.9, train_MAE=0.47, train_loss=0.47, val_MAE=0.566, val_loss=0.566]Epoch 76:   8%|▊         | 76/1000 [1:21:39<16:06:37, 62.77s/it, lr=1.56e-5, test_MAE=0.595, time=62.5, train_MAE=0.465, train_loss=0.465, val_MAE=0.57, val_loss=0.57]Epoch 76:   8%|▊         | 77/1000 [1:21:39<16:04:34, 62.70s/it, lr=1.56e-5, test_MAE=0.595, time=62.5, train_MAE=0.465, train_loss=0.465, val_MAE=0.57, val_loss=0.57]Epoch 77:   8%|▊         | 77/1000 [1:21:39<16:04:34, 62.70s/it, lr=1.56e-5, test_MAE=0.595, time=62.5, train_MAE=0.465, train_loss=0.465, val_MAE=0.57, val_loss=0.57]Epoch 77:   8%|▊         | 77/1000 [1:22:41<16:04:34, 62.70s/it, lr=1.56e-5, test_MAE=0.594, time=62.3, train_MAE=0.459, train_loss=0.459, val_MAE=0.568, val_loss=0.568]Epoch 77:   8%|▊         | 78/1000 [1:22:41<16:02:01, 62.60s/it, lr=1.56e-5, test_MAE=0.594, time=62.3, train_MAE=0.459, train_loss=0.459, val_MAE=0.568, val_loss=0.568]Epoch 78:   8%|▊         | 78/1000 [1:22:41<16:02:01, 62.60s/it, lr=1.56e-5, test_MAE=0.594, time=62.3, train_MAE=0.459, train_loss=0.459, val_MAE=0.568, val_loss=0.568]Epoch 78:   8%|▊         | 78/1000 [1:23:45<16:02:01, 62.60s/it, lr=1.56e-5, test_MAE=0.595, time=63.3, train_MAE=0.458, train_loss=0.458, val_MAE=0.567, val_loss=0.567]Epoch 78:   8%|▊         | 79/1000 [1:23:45<16:04:14, 62.82s/it, lr=1.56e-5, test_MAE=0.595, time=63.3, train_MAE=0.458, train_loss=0.458, val_MAE=0.567, val_loss=0.567]Epoch 79:   8%|▊         | 79/1000 [1:23:45<16:04:14, 62.82s/it, lr=1.56e-5, test_MAE=0.595, time=63.3, train_MAE=0.458, train_loss=0.458, val_MAE=0.567, val_loss=0.567]Epoch 79:   8%|▊         | 79/1000 [1:24:47<16:04:14, 62.82s/it, lr=1.56e-5, test_MAE=0.597, time=62.8, train_MAE=0.461, train_loss=0.461, val_MAE=0.571, val_loss=0.571]Epoch 79:   8%|▊         | 80/1000 [1:24:47<16:03:24, 62.83s/it, lr=1.56e-5, test_MAE=0.597, time=62.8, train_MAE=0.461, train_loss=0.461, val_MAE=0.571, val_loss=0.571]Epoch 80:   8%|▊         | 80/1000 [1:24:47<16:03:24, 62.83s/it, lr=1.56e-5, test_MAE=0.597, time=62.8, train_MAE=0.461, train_loss=0.461, val_MAE=0.571, val_loss=0.571]Epoch 80:   8%|▊         | 80/1000 [1:25:50<16:03:24, 62.83s/it, lr=1.56e-5, test_MAE=0.596, time=62.4, train_MAE=0.459, train_loss=0.459, val_MAE=0.57, val_loss=0.57]  Epoch 80:   8%|▊         | 81/1000 [1:25:50<16:00:31, 62.71s/it, lr=1.56e-5, test_MAE=0.596, time=62.4, train_MAE=0.459, train_loss=0.459, val_MAE=0.57, val_loss=0.57]Epoch 81:   8%|▊         | 81/1000 [1:25:50<16:00:31, 62.71s/it, lr=1.56e-5, test_MAE=0.596, time=62.4, train_MAE=0.459, train_loss=0.459, val_MAE=0.57, val_loss=0.57]Epoch 81:   8%|▊         | 81/1000 [1:26:52<16:00:31, 62.71s/it, lr=1.56e-5, test_MAE=0.595, time=62.5, train_MAE=0.458, train_loss=0.458, val_MAE=0.569, val_loss=0.569]Epoch    82: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 81:   8%|▊         | 81/1000 [1:26:52<16:25:44, 64.36s/it, lr=1.56e-5, test_MAE=0.595, time=62.5, train_MAE=0.458, train_loss=0.458, val_MAE=0.569, val_loss=0.569]
Test MAE: 0.5954
Train MAE: 0.4467
Convergence Time (Epochs): 81.0000
TOTAL TIME TAKEN: 5251.4187s
AVG TIME PER EPOCH: 63.5464s
