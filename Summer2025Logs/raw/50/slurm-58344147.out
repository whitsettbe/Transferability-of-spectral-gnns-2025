I'm echoing to stdout
I'm echoing to stderr
My JobID is 58344147
I have 4 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.1603s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 16, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 4, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'cheb02_vec', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_sub', 'num_eigs': 16, 'bias_mode': 'spatial', 'l1_reg': 0.0001, 'l2_reg': 0.0, 'gen_reg': 0.0, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/aug07/zinc_train_rec.csv', 'test': 'supp_data/molecules/aug07/zinc_test_rec.csv', 'val': 'supp_data/molecules/aug07/zinc_val_rec.csv'}, 'fixMissingPhi1': False, 'extraOrtho': False, 'doublePrecision': True, 'eigval_hidden_dim': 100, 'eigval_num_hidden_layer': 3, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [04:49<?, ?it/s, lr=0.001, test_MAE=1.35, time=289, train_MAE=0.844, train_loss=1.58, val_MAE=1.31, val_loss=1.94]Epoch 0:   0%|          | 1/1000 [04:49<80:20:20, 289.51s/it, lr=0.001, test_MAE=1.35, time=289, train_MAE=0.844, train_loss=1.58, val_MAE=1.31, val_loss=1.94]Epoch 1:   0%|          | 1/1000 [04:49<80:20:20, 289.51s/it, lr=0.001, test_MAE=1.35, time=289, train_MAE=0.844, train_loss=1.58, val_MAE=1.31, val_loss=1.94]Epoch 1:   0%|          | 1/1000 [09:22<80:20:20, 289.51s/it, lr=0.001, test_MAE=0.786, time=273, train_MAE=0.705, train_loss=1.29, val_MAE=0.727, val_loss=1.3]Epoch 1:   0%|          | 2/1000 [09:22<78:51:57, 284.49s/it, lr=0.001, test_MAE=0.786, time=273, train_MAE=0.705, train_loss=1.29, val_MAE=0.727, val_loss=1.3]Epoch 2:   0%|          | 2/1000 [09:22<78:51:57, 284.49s/it, lr=0.001, test_MAE=0.786, time=273, train_MAE=0.705, train_loss=1.29, val_MAE=0.727, val_loss=1.3]Epoch 2:   0%|          | 2/1000 [13:53<78:51:57, 284.49s/it, lr=0.001, test_MAE=0.964, time=272, train_MAE=0.684, train_loss=1.24, val_MAE=0.846, val_loss=1.4]Epoch 2:   0%|          | 3/1000 [13:54<77:43:43, 280.67s/it, lr=0.001, test_MAE=0.964, time=272, train_MAE=0.684, train_loss=1.24, val_MAE=0.846, val_loss=1.4]Epoch 3:   0%|          | 3/1000 [13:54<77:43:43, 280.67s/it, lr=0.001, test_MAE=0.964, time=272, train_MAE=0.684, train_loss=1.24, val_MAE=0.846, val_loss=1.4]Epoch 3:   0%|          | 3/1000 [18:26<77:43:43, 280.67s/it, lr=0.001, test_MAE=0.951, time=272, train_MAE=0.662, train_loss=1.19, val_MAE=0.903, val_loss=1.42]Epoch 3:   0%|          | 4/1000 [18:26<76:56:30, 278.10s/it, lr=0.001, test_MAE=0.951, time=272, train_MAE=0.662, train_loss=1.19, val_MAE=0.903, val_loss=1.42]Epoch 4:   0%|          | 4/1000 [18:26<76:56:30, 278.10s/it, lr=0.001, test_MAE=0.951, time=272, train_MAE=0.662, train_loss=1.19, val_MAE=0.903, val_loss=1.42]Epoch 4:   0%|          | 4/1000 [22:58<76:56:30, 278.10s/it, lr=0.001, test_MAE=0.882, time=273, train_MAE=0.655, train_loss=1.17, val_MAE=0.835, val_loss=1.33]Epoch 4:   0%|          | 5/1000 [22:59<76:25:45, 276.53s/it, lr=0.001, test_MAE=0.882, time=273, train_MAE=0.655, train_loss=1.17, val_MAE=0.835, val_loss=1.33]Epoch 5:   0%|          | 5/1000 [22:59<76:25:45, 276.53s/it, lr=0.001, test_MAE=0.882, time=273, train_MAE=0.655, train_loss=1.17, val_MAE=0.835, val_loss=1.33]Epoch 5:   0%|          | 5/1000 [27:30<76:25:45, 276.53s/it, lr=0.001, test_MAE=0.724, time=271, train_MAE=0.67, train_loss=1.17, val_MAE=0.684, val_loss=1.17] Epoch 5:   1%|          | 6/1000 [27:30<75:54:18, 274.91s/it, lr=0.001, test_MAE=0.724, time=271, train_MAE=0.67, train_loss=1.17, val_MAE=0.684, val_loss=1.17]Epoch 6:   1%|          | 6/1000 [27:30<75:54:18, 274.91s/it, lr=0.001, test_MAE=0.724, time=271, train_MAE=0.67, train_loss=1.17, val_MAE=0.684, val_loss=1.17]Epoch 6:   1%|          | 6/1000 [32:01<75:54:18, 274.91s/it, lr=0.001, test_MAE=0.714, time=271, train_MAE=0.646, train_loss=1.12, val_MAE=0.665, val_loss=1.15]Epoch 6:   1%|          | 7/1000 [32:01<75:32:24, 273.86s/it, lr=0.001, test_MAE=0.714, time=271, train_MAE=0.646, train_loss=1.12, val_MAE=0.665, val_loss=1.15]Epoch 7:   1%|          | 7/1000 [32:01<75:32:24, 273.86s/it, lr=0.001, test_MAE=0.714, time=271, train_MAE=0.646, train_loss=1.12, val_MAE=0.665, val_loss=1.15]Epoch 7:   1%|          | 7/1000 [36:34<75:32:24, 273.86s/it, lr=0.001, test_MAE=0.767, time=273, train_MAE=0.642, train_loss=1.12, val_MAE=0.741, val_loss=1.2] Epoch 7:   1%|          | 8/1000 [36:34<75:21:39, 273.49s/it, lr=0.001, test_MAE=0.767, time=273, train_MAE=0.642, train_loss=1.12, val_MAE=0.741, val_loss=1.2]Epoch 8:   1%|          | 8/1000 [36:34<75:21:39, 273.49s/it, lr=0.001, test_MAE=0.767, time=273, train_MAE=0.642, train_loss=1.12, val_MAE=0.741, val_loss=1.2]Epoch 8:   1%|          | 8/1000 [41:05<75:21:39, 273.49s/it, lr=0.001, test_MAE=1.14, time=271, train_MAE=0.658, train_loss=1.12, val_MAE=1.1, val_loss=1.55]  Epoch 8:   1%|          | 9/1000 [41:05<75:05:30, 272.79s/it, lr=0.001, test_MAE=1.14, time=271, train_MAE=0.658, train_loss=1.12, val_MAE=1.1, val_loss=1.55]Epoch 9:   1%|          | 9/1000 [41:05<75:05:30, 272.79s/it, lr=0.001, test_MAE=1.14, time=271, train_MAE=0.658, train_loss=1.12, val_MAE=1.1, val_loss=1.55]Epoch 9:   1%|          | 9/1000 [45:37<75:05:30, 272.79s/it, lr=0.001, test_MAE=0.792, time=272, train_MAE=0.646, train_loss=1.09, val_MAE=0.706, val_loss=1.14]Epoch 9:   1%|          | 10/1000 [45:37<74:55:44, 272.47s/it, lr=0.001, test_MAE=0.792, time=272, train_MAE=0.646, train_loss=1.09, val_MAE=0.706, val_loss=1.14]Epoch 10:   1%|          | 10/1000 [45:37<74:55:44, 272.47s/it, lr=0.001, test_MAE=0.792, time=272, train_MAE=0.646, train_loss=1.09, val_MAE=0.706, val_loss=1.14]Epoch 10:   1%|          | 10/1000 [50:09<74:55:44, 272.47s/it, lr=0.001, test_MAE=0.791, time=273, train_MAE=0.638, train_loss=1.06, val_MAE=0.758, val_loss=1.17]Epoch 10:   1%|          | 11/1000 [50:09<74:52:04, 272.52s/it, lr=0.001, test_MAE=0.791, time=273, train_MAE=0.638, train_loss=1.06, val_MAE=0.758, val_loss=1.17]Epoch 11:   1%|          | 11/1000 [50:09<74:52:04, 272.52s/it, lr=0.001, test_MAE=0.791, time=273, train_MAE=0.638, train_loss=1.06, val_MAE=0.758, val_loss=1.17]Epoch 11:   1%|          | 11/1000 [54:40<74:52:04, 272.52s/it, lr=0.001, test_MAE=0.972, time=271, train_MAE=0.628, train_loss=1.05, val_MAE=0.907, val_loss=1.3] Epoch 11:   1%|          | 12/1000 [54:40<74:39:08, 272.01s/it, lr=0.001, test_MAE=0.972, time=271, train_MAE=0.628, train_loss=1.05, val_MAE=0.907, val_loss=1.3]Epoch 12:   1%|          | 12/1000 [54:40<74:39:08, 272.01s/it, lr=0.001, test_MAE=0.972, time=271, train_MAE=0.628, train_loss=1.05, val_MAE=0.907, val_loss=1.3]Epoch 12:   1%|          | 12/1000 [59:12<74:39:08, 272.01s/it, lr=0.001, test_MAE=0.707, time=272, train_MAE=0.622, train_loss=1.02, val_MAE=0.663, val_loss=1.06]Epoch 12:   1%|▏         | 13/1000 [59:12<74:33:23, 271.94s/it, lr=0.001, test_MAE=0.707, time=272, train_MAE=0.622, train_loss=1.02, val_MAE=0.663, val_loss=1.06]Epoch 13:   1%|▏         | 13/1000 [59:12<74:33:23, 271.94s/it, lr=0.001, test_MAE=0.707, time=272, train_MAE=0.622, train_loss=1.02, val_MAE=0.663, val_loss=1.06]Epoch 13:   1%|▏         | 13/1000 [1:03:44<74:33:23, 271.94s/it, lr=0.001, test_MAE=0.819, time=273, train_MAE=0.621, train_loss=1.01, val_MAE=0.783, val_loss=1.17]Epoch 13:   1%|▏         | 14/1000 [1:03:44<74:32:19, 272.15s/it, lr=0.001, test_MAE=0.819, time=273, train_MAE=0.621, train_loss=1.01, val_MAE=0.783, val_loss=1.17]Epoch 14:   1%|▏         | 14/1000 [1:03:44<74:32:19, 272.15s/it, lr=0.001, test_MAE=0.819, time=273, train_MAE=0.621, train_loss=1.01, val_MAE=0.783, val_loss=1.17]Epoch 14:   1%|▏         | 14/1000 [1:08:16<74:32:19, 272.15s/it, lr=0.001, test_MAE=0.793, time=271, train_MAE=0.629, train_loss=1.01, val_MAE=0.763, val_loss=1.14]Epoch 14:   2%|▏         | 15/1000 [1:08:16<74:22:53, 271.85s/it, lr=0.001, test_MAE=0.793, time=271, train_MAE=0.629, train_loss=1.01, val_MAE=0.763, val_loss=1.14]Epoch 15:   2%|▏         | 15/1000 [1:08:16<74:22:53, 271.85s/it, lr=0.001, test_MAE=0.793, time=271, train_MAE=0.629, train_loss=1.01, val_MAE=0.763, val_loss=1.14]Epoch 15:   2%|▏         | 15/1000 [1:12:47<74:22:53, 271.85s/it, lr=0.001, test_MAE=0.792, time=271, train_MAE=0.634, train_loss=1.01, val_MAE=0.749, val_loss=1.11]Epoch 15:   2%|▏         | 16/1000 [1:12:47<74:16:44, 271.75s/it, lr=0.001, test_MAE=0.792, time=271, train_MAE=0.634, train_loss=1.01, val_MAE=0.749, val_loss=1.11]Epoch 16:   2%|▏         | 16/1000 [1:12:47<74:16:44, 271.75s/it, lr=0.001, test_MAE=0.792, time=271, train_MAE=0.634, train_loss=1.01, val_MAE=0.749, val_loss=1.11]Epoch 16:   2%|▏         | 16/1000 [1:17:20<74:16:44, 271.75s/it, lr=0.001, test_MAE=1.03, time=273, train_MAE=0.616, train_loss=0.974, val_MAE=1.01, val_loss=1.35] Epoch 16:   2%|▏         | 17/1000 [1:17:20<74:16:28, 272.01s/it, lr=0.001, test_MAE=1.03, time=273, train_MAE=0.616, train_loss=0.974, val_MAE=1.01, val_loss=1.35]Epoch 17:   2%|▏         | 17/1000 [1:17:20<74:16:28, 272.01s/it, lr=0.001, test_MAE=1.03, time=273, train_MAE=0.616, train_loss=0.974, val_MAE=1.01, val_loss=1.35]Epoch 17:   2%|▏         | 17/1000 [1:21:50<74:16:28, 272.01s/it, lr=0.001, test_MAE=0.78, time=271, train_MAE=0.611, train_loss=0.957, val_MAE=0.738, val_loss=1.08]Epoch 17:   2%|▏         | 18/1000 [1:21:51<74:05:57, 271.65s/it, lr=0.001, test_MAE=0.78, time=271, train_MAE=0.611, train_loss=0.957, val_MAE=0.738, val_loss=1.08]Epoch 18:   2%|▏         | 18/1000 [1:21:51<74:05:57, 271.65s/it, lr=0.001, test_MAE=0.78, time=271, train_MAE=0.611, train_loss=0.957, val_MAE=0.738, val_loss=1.08]Epoch 18:   2%|▏         | 18/1000 [1:26:22<74:05:57, 271.65s/it, lr=0.001, test_MAE=0.651, time=272, train_MAE=0.61, train_loss=0.945, val_MAE=0.627, val_loss=0.944]Epoch 18:   2%|▏         | 19/1000 [1:26:22<74:02:14, 271.70s/it, lr=0.001, test_MAE=0.651, time=272, train_MAE=0.61, train_loss=0.945, val_MAE=0.627, val_loss=0.944]Epoch 19:   2%|▏         | 19/1000 [1:26:22<74:02:14, 271.70s/it, lr=0.001, test_MAE=0.651, time=272, train_MAE=0.61, train_loss=0.945, val_MAE=0.627, val_loss=0.944]Epoch 19:   2%|▏         | 19/1000 [1:30:55<74:02:14, 271.70s/it, lr=0.001, test_MAE=0.792, time=273, train_MAE=0.607, train_loss=0.929, val_MAE=0.736, val_loss=1.05]Epoch 19:   2%|▏         | 20/1000 [1:30:55<74:02:36, 272.00s/it, lr=0.001, test_MAE=0.792, time=273, train_MAE=0.607, train_loss=0.929, val_MAE=0.736, val_loss=1.05]Epoch 20:   2%|▏         | 20/1000 [1:30:55<74:02:36, 272.00s/it, lr=0.001, test_MAE=0.792, time=273, train_MAE=0.607, train_loss=0.929, val_MAE=0.736, val_loss=1.05]Epoch 20:   2%|▏         | 20/1000 [1:35:26<74:02:36, 272.00s/it, lr=0.001, test_MAE=0.826, time=271, train_MAE=0.612, train_loss=0.939, val_MAE=0.766, val_loss=1.08]Epoch 20:   2%|▏         | 21/1000 [1:35:26<73:53:03, 271.69s/it, lr=0.001, test_MAE=0.826, time=271, train_MAE=0.612, train_loss=0.939, val_MAE=0.766, val_loss=1.08]Epoch 21:   2%|▏         | 21/1000 [1:35:26<73:53:03, 271.69s/it, lr=0.001, test_MAE=0.826, time=271, train_MAE=0.612, train_loss=0.939, val_MAE=0.766, val_loss=1.08]Epoch 21:   2%|▏         | 21/1000 [1:39:58<73:53:03, 271.69s/it, lr=0.001, test_MAE=0.781, time=272, train_MAE=0.607, train_loss=0.919, val_MAE=0.74, val_loss=1.04] Epoch 21:   2%|▏         | 22/1000 [1:39:58<73:47:50, 271.65s/it, lr=0.001, test_MAE=0.781, time=272, train_MAE=0.607, train_loss=0.919, val_MAE=0.74, val_loss=1.04]Epoch 22:   2%|▏         | 22/1000 [1:39:58<73:47:50, 271.65s/it, lr=0.001, test_MAE=0.781, time=272, train_MAE=0.607, train_loss=0.919, val_MAE=0.74, val_loss=1.04]Epoch 22:   2%|▏         | 22/1000 [1:44:30<73:47:50, 271.65s/it, lr=0.001, test_MAE=0.692, time=272, train_MAE=0.599, train_loss=0.894, val_MAE=0.657, val_loss=0.949]Epoch 22:   2%|▏         | 23/1000 [1:44:30<73:47:13, 271.89s/it, lr=0.001, test_MAE=0.692, time=272, train_MAE=0.599, train_loss=0.894, val_MAE=0.657, val_loss=0.949]Epoch 23:   2%|▏         | 23/1000 [1:44:30<73:47:13, 271.89s/it, lr=0.001, test_MAE=0.692, time=272, train_MAE=0.599, train_loss=0.894, val_MAE=0.657, val_loss=0.949]Epoch 23:   2%|▏         | 23/1000 [1:49:01<73:47:13, 271.89s/it, lr=0.001, test_MAE=0.693, time=271, train_MAE=0.621, train_loss=0.916, val_MAE=0.663, val_loss=0.951]Epoch 23:   2%|▏         | 24/1000 [1:49:01<73:37:14, 271.55s/it, lr=0.001, test_MAE=0.693, time=271, train_MAE=0.621, train_loss=0.916, val_MAE=0.663, val_loss=0.951]Epoch 24:   2%|▏         | 24/1000 [1:49:01<73:37:14, 271.55s/it, lr=0.001, test_MAE=0.693, time=271, train_MAE=0.621, train_loss=0.916, val_MAE=0.663, val_loss=0.951]Epoch 24:   2%|▏         | 24/1000 [1:53:32<73:37:14, 271.55s/it, lr=0.001, test_MAE=1.06, time=272, train_MAE=0.609, train_loss=0.893, val_MAE=1, val_loss=1.27]      Epoch    25: reducing learning rate of group 0 to 5.0000e-04.
Epoch 24:   2%|▎         | 25/1000 [1:53:32<73:32:47, 271.56s/it, lr=0.001, test_MAE=1.06, time=272, train_MAE=0.609, train_loss=0.893, val_MAE=1, val_loss=1.27]Epoch 25:   2%|▎         | 25/1000 [1:53:32<73:32:47, 271.56s/it, lr=0.001, test_MAE=1.06, time=272, train_MAE=0.609, train_loss=0.893, val_MAE=1, val_loss=1.27]Epoch 25:   2%|▎         | 25/1000 [1:58:05<73:32:47, 271.56s/it, lr=0.0005, test_MAE=0.659, time=272, train_MAE=0.575, train_loss=0.837, val_MAE=0.624, val_loss=0.873]Epoch 25:   3%|▎         | 26/1000 [1:58:05<73:32:38, 271.83s/it, lr=0.0005, test_MAE=0.659, time=272, train_MAE=0.575, train_loss=0.837, val_MAE=0.624, val_loss=0.873]Epoch 26:   3%|▎         | 26/1000 [1:58:05<73:32:38, 271.83s/it, lr=0.0005, test_MAE=0.659, time=272, train_MAE=0.575, train_loss=0.837, val_MAE=0.624, val_loss=0.873]Epoch 26:   3%|▎         | 26/1000 [2:02:36<73:32:38, 271.83s/it, lr=0.0005, test_MAE=0.721, time=271, train_MAE=0.574, train_loss=0.825, val_MAE=0.676, val_loss=0.925]Epoch 26:   3%|▎         | 27/1000 [2:02:36<73:24:06, 271.58s/it, lr=0.0005, test_MAE=0.721, time=271, train_MAE=0.574, train_loss=0.825, val_MAE=0.676, val_loss=0.925]Epoch 27:   3%|▎         | 27/1000 [2:02:36<73:24:06, 271.58s/it, lr=0.0005, test_MAE=0.721, time=271, train_MAE=0.574, train_loss=0.825, val_MAE=0.676, val_loss=0.925]Epoch 27:   3%|▎         | 27/1000 [2:07:07<73:24:06, 271.58s/it, lr=0.0005, test_MAE=0.696, time=271, train_MAE=0.582, train_loss=0.833, val_MAE=0.636, val_loss=0.881]Epoch 27:   3%|▎         | 28/1000 [2:07:07<73:19:17, 271.56s/it, lr=0.0005, test_MAE=0.696, time=271, train_MAE=0.582, train_loss=0.833, val_MAE=0.636, val_loss=0.881]Epoch 28:   3%|▎         | 28/1000 [2:07:07<73:19:17, 271.56s/it, lr=0.0005, test_MAE=0.696, time=271, train_MAE=0.582, train_loss=0.833, val_MAE=0.636, val_loss=0.881]Epoch 28:   3%|▎         | 28/1000 [2:11:40<73:19:17, 271.56s/it, lr=0.0005, test_MAE=0.762, time=273, train_MAE=0.583, train_loss=0.828, val_MAE=0.74, val_loss=0.99]  Epoch 28:   3%|▎         | 29/1000 [2:11:40<73:20:07, 271.89s/it, lr=0.0005, test_MAE=0.762, time=273, train_MAE=0.583, train_loss=0.828, val_MAE=0.74, val_loss=0.99]Epoch 29:   3%|▎         | 29/1000 [2:11:40<73:20:07, 271.89s/it, lr=0.0005, test_MAE=0.762, time=273, train_MAE=0.583, train_loss=0.828, val_MAE=0.74, val_loss=0.99]Epoch 29:   3%|▎         | 29/1000 [2:16:11<73:20:07, 271.89s/it, lr=0.0005, test_MAE=0.684, time=271, train_MAE=0.579, train_loss=0.823, val_MAE=0.642, val_loss=0.884]Epoch 29:   3%|▎         | 30/1000 [2:16:11<73:10:07, 271.55s/it, lr=0.0005, test_MAE=0.684, time=271, train_MAE=0.579, train_loss=0.823, val_MAE=0.642, val_loss=0.884]Epoch 30:   3%|▎         | 30/1000 [2:16:11<73:10:07, 271.55s/it, lr=0.0005, test_MAE=0.684, time=271, train_MAE=0.579, train_loss=0.823, val_MAE=0.642, val_loss=0.884]Epoch 30:   3%|▎         | 30/1000 [2:20:42<73:10:07, 271.55s/it, lr=0.0005, test_MAE=0.871, time=272, train_MAE=0.578, train_loss=0.818, val_MAE=0.845, val_loss=1.08] Epoch 30:   3%|▎         | 31/1000 [2:20:42<73:05:32, 271.55s/it, lr=0.0005, test_MAE=0.871, time=272, train_MAE=0.578, train_loss=0.818, val_MAE=0.845, val_loss=1.08]Epoch 31:   3%|▎         | 31/1000 [2:20:42<73:05:32, 271.55s/it, lr=0.0005, test_MAE=0.871, time=272, train_MAE=0.578, train_loss=0.818, val_MAE=0.845, val_loss=1.08]Epoch 31:   3%|▎         | 31/1000 [2:25:14<73:05:32, 271.55s/it, lr=0.0005, test_MAE=0.769, time=272, train_MAE=0.573, train_loss=0.811, val_MAE=0.74, val_loss=0.975]Epoch    32: reducing learning rate of group 0 to 2.5000e-04.
Epoch 31:   3%|▎         | 32/1000 [2:25:14<73:04:14, 271.75s/it, lr=0.0005, test_MAE=0.769, time=272, train_MAE=0.573, train_loss=0.811, val_MAE=0.74, val_loss=0.975]Epoch 32:   3%|▎         | 32/1000 [2:25:14<73:04:14, 271.75s/it, lr=0.0005, test_MAE=0.769, time=272, train_MAE=0.573, train_loss=0.811, val_MAE=0.74, val_loss=0.975]Epoch 32:   3%|▎         | 32/1000 [2:29:46<73:04:14, 271.75s/it, lr=0.00025, test_MAE=0.646, time=271, train_MAE=0.564, train_loss=0.79, val_MAE=0.609, val_loss=0.831]Epoch 32:   3%|▎         | 33/1000 [2:29:46<72:56:17, 271.54s/it, lr=0.00025, test_MAE=0.646, time=271, train_MAE=0.564, train_loss=0.79, val_MAE=0.609, val_loss=0.831]Epoch 33:   3%|▎         | 33/1000 [2:29:46<72:56:17, 271.54s/it, lr=0.00025, test_MAE=0.646, time=271, train_MAE=0.564, train_loss=0.79, val_MAE=0.609, val_loss=0.831]Epoch 33:   3%|▎         | 33/1000 [2:34:17<72:56:17, 271.54s/it, lr=0.00025, test_MAE=0.638, time=272, train_MAE=0.552, train_loss=0.775, val_MAE=0.601, val_loss=0.823]Epoch 33:   3%|▎         | 34/1000 [2:34:17<72:52:19, 271.57s/it, lr=0.00025, test_MAE=0.638, time=272, train_MAE=0.552, train_loss=0.775, val_MAE=0.601, val_loss=0.823]Epoch 34:   3%|▎         | 34/1000 [2:34:17<72:52:19, 271.57s/it, lr=0.00025, test_MAE=0.638, time=272, train_MAE=0.552, train_loss=0.775, val_MAE=0.601, val_loss=0.823]Epoch 34:   3%|▎         | 34/1000 [2:38:49<72:52:19, 271.57s/it, lr=0.00025, test_MAE=0.625, time=272, train_MAE=0.547, train_loss=0.768, val_MAE=0.591, val_loss=0.81] Epoch 34:   4%|▎         | 35/1000 [2:38:49<72:50:45, 271.76s/it, lr=0.00025, test_MAE=0.625, time=272, train_MAE=0.547, train_loss=0.768, val_MAE=0.591, val_loss=0.81]Epoch 35:   4%|▎         | 35/1000 [2:38:49<72:50:45, 271.76s/it, lr=0.00025, test_MAE=0.625, time=272, train_MAE=0.547, train_loss=0.768, val_MAE=0.591, val_loss=0.81]Epoch 35:   4%|▎         | 35/1000 [2:43:10<72:50:45, 271.76s/it, lr=0.00025, test_MAE=0.783, time=260, train_MAE=0.554, train_loss=0.773, val_MAE=0.751, val_loss=0.971]Epoch 35:   4%|▎         | 36/1000 [2:43:10<71:51:21, 268.34s/it, lr=0.00025, test_MAE=0.783, time=260, train_MAE=0.554, train_loss=0.773, val_MAE=0.751, val_loss=0.971]Epoch 36:   4%|▎         | 36/1000 [2:43:10<71:51:21, 268.34s/it, lr=0.00025, test_MAE=0.783, time=260, train_MAE=0.554, train_loss=0.773, val_MAE=0.751, val_loss=0.971]Epoch 36:   4%|▎         | 36/1000 [2:47:24<71:51:21, 268.34s/it, lr=0.00025, test_MAE=0.66, time=254, train_MAE=0.559, train_loss=0.781, val_MAE=0.636, val_loss=0.854] Epoch 36:   4%|▎         | 37/1000 [2:47:24<70:37:46, 264.04s/it, lr=0.00025, test_MAE=0.66, time=254, train_MAE=0.559, train_loss=0.781, val_MAE=0.636, val_loss=0.854]Epoch 37:   4%|▎         | 37/1000 [2:47:24<70:37:46, 264.04s/it, lr=0.00025, test_MAE=0.66, time=254, train_MAE=0.559, train_loss=0.781, val_MAE=0.636, val_loss=0.854]Epoch 37:   4%|▎         | 37/1000 [2:51:38<70:37:46, 264.04s/it, lr=0.00025, test_MAE=0.758, time=254, train_MAE=0.544, train_loss=0.761, val_MAE=0.708, val_loss=0.926]Epoch 37:   4%|▍         | 38/1000 [2:51:38<69:45:38, 261.06s/it, lr=0.00025, test_MAE=0.758, time=254, train_MAE=0.544, train_loss=0.761, val_MAE=0.708, val_loss=0.926]Epoch 38:   4%|▍         | 38/1000 [2:51:38<69:45:38, 261.06s/it, lr=0.00025, test_MAE=0.758, time=254, train_MAE=0.544, train_loss=0.761, val_MAE=0.708, val_loss=0.926]Epoch 38:   4%|▍         | 38/1000 [2:55:51<69:45:38, 261.06s/it, lr=0.00025, test_MAE=0.632, time=253, train_MAE=0.546, train_loss=0.762, val_MAE=0.605, val_loss=0.82] Epoch 38:   4%|▍         | 39/1000 [2:55:51<69:01:23, 258.57s/it, lr=0.00025, test_MAE=0.632, time=253, train_MAE=0.546, train_loss=0.762, val_MAE=0.605, val_loss=0.82]Epoch 39:   4%|▍         | 39/1000 [2:55:51<69:01:23, 258.57s/it, lr=0.00025, test_MAE=0.632, time=253, train_MAE=0.546, train_loss=0.762, val_MAE=0.605, val_loss=0.82]Epoch 39:   4%|▍         | 39/1000 [3:00:04<69:01:23, 258.57s/it, lr=0.00025, test_MAE=0.653, time=253, train_MAE=0.532, train_loss=0.746, val_MAE=0.614, val_loss=0.826]Epoch 39:   4%|▍         | 40/1000 [3:00:04<68:32:00, 257.00s/it, lr=0.00025, test_MAE=0.653, time=253, train_MAE=0.532, train_loss=0.746, val_MAE=0.614, val_loss=0.826]Epoch 40:   4%|▍         | 40/1000 [3:00:04<68:32:00, 257.00s/it, lr=0.00025, test_MAE=0.653, time=253, train_MAE=0.532, train_loss=0.746, val_MAE=0.614, val_loss=0.826]Epoch 40:   4%|▍         | 40/1000 [3:04:18<68:32:00, 257.00s/it, lr=0.00025, test_MAE=0.756, time=254, train_MAE=0.538, train_loss=0.752, val_MAE=0.722, val_loss=0.935]Epoch    41: reducing learning rate of group 0 to 1.2500e-04.
Epoch 40:   4%|▍         | 41/1000 [3:04:18<68:14:09, 256.15s/it, lr=0.00025, test_MAE=0.756, time=254, train_MAE=0.538, train_loss=0.752, val_MAE=0.722, val_loss=0.935]Epoch 41:   4%|▍         | 41/1000 [3:04:18<68:14:09, 256.15s/it, lr=0.00025, test_MAE=0.756, time=254, train_MAE=0.538, train_loss=0.752, val_MAE=0.722, val_loss=0.935]Epoch 41:   4%|▍         | 41/1000 [3:08:31<68:14:09, 256.15s/it, lr=0.000125, test_MAE=0.629, time=253, train_MAE=0.527, train_loss=0.736, val_MAE=0.594, val_loss=0.799]Epoch 41:   4%|▍         | 42/1000 [3:08:31<67:54:05, 255.16s/it, lr=0.000125, test_MAE=0.629, time=253, train_MAE=0.527, train_loss=0.736, val_MAE=0.594, val_loss=0.799]Epoch 42:   4%|▍         | 42/1000 [3:08:31<67:54:05, 255.16s/it, lr=0.000125, test_MAE=0.629, time=253, train_MAE=0.527, train_loss=0.736, val_MAE=0.594, val_loss=0.799]Epoch 42:   4%|▍         | 42/1000 [3:12:44<67:54:05, 255.16s/it, lr=0.000125, test_MAE=0.741, time=253, train_MAE=0.531, train_loss=0.737, val_MAE=0.704, val_loss=0.909]Epoch 42:   4%|▍         | 43/1000 [3:12:44<67:41:35, 254.65s/it, lr=0.000125, test_MAE=0.741, time=253, train_MAE=0.531, train_loss=0.737, val_MAE=0.704, val_loss=0.909]Epoch 43:   4%|▍         | 43/1000 [3:12:44<67:41:35, 254.65s/it, lr=0.000125, test_MAE=0.741, time=253, train_MAE=0.531, train_loss=0.737, val_MAE=0.704, val_loss=0.909]Epoch 43:   4%|▍         | 43/1000 [3:16:58<67:41:35, 254.65s/it, lr=0.000125, test_MAE=0.622, time=254, train_MAE=0.523, train_loss=0.728, val_MAE=0.578, val_loss=0.783]Epoch 43:   4%|▍         | 44/1000 [3:16:59<67:34:47, 254.48s/it, lr=0.000125, test_MAE=0.622, time=254, train_MAE=0.523, train_loss=0.728, val_MAE=0.578, val_loss=0.783]Epoch 44:   4%|▍         | 44/1000 [3:16:59<67:34:47, 254.48s/it, lr=0.000125, test_MAE=0.622, time=254, train_MAE=0.523, train_loss=0.728, val_MAE=0.578, val_loss=0.783]Epoch 44:   4%|▍         | 44/1000 [3:21:11<67:34:47, 254.48s/it, lr=0.000125, test_MAE=0.651, time=253, train_MAE=0.518, train_loss=0.723, val_MAE=0.61, val_loss=0.814] Epoch 44:   4%|▍         | 45/1000 [3:21:11<67:22:15, 253.96s/it, lr=0.000125, test_MAE=0.651, time=253, train_MAE=0.518, train_loss=0.723, val_MAE=0.61, val_loss=0.814]Epoch 45:   4%|▍         | 45/1000 [3:21:11<67:22:15, 253.96s/it, lr=0.000125, test_MAE=0.651, time=253, train_MAE=0.518, train_loss=0.723, val_MAE=0.61, val_loss=0.814]Epoch 45:   4%|▍         | 45/1000 [3:25:37<67:22:15, 253.96s/it, lr=0.000125, test_MAE=0.618, time=266, train_MAE=0.523, train_loss=0.728, val_MAE=0.582, val_loss=0.787]Epoch 45:   5%|▍         | 46/1000 [3:25:37<68:15:49, 257.60s/it, lr=0.000125, test_MAE=0.618, time=266, train_MAE=0.523, train_loss=0.728, val_MAE=0.582, val_loss=0.787]Epoch 46:   5%|▍         | 46/1000 [3:25:37<68:15:49, 257.60s/it, lr=0.000125, test_MAE=0.618, time=266, train_MAE=0.523, train_loss=0.728, val_MAE=0.582, val_loss=0.787]Epoch 46:   5%|▍         | 46/1000 [3:30:04<68:15:49, 257.60s/it, lr=0.000125, test_MAE=0.651, time=266, train_MAE=0.517, train_loss=0.72, val_MAE=0.6, val_loss=0.803]   Epoch 46:   5%|▍         | 47/1000 [3:30:04<68:53:20, 260.23s/it, lr=0.000125, test_MAE=0.651, time=266, train_MAE=0.517, train_loss=0.72, val_MAE=0.6, val_loss=0.803]Epoch 47:   5%|▍         | 47/1000 [3:30:04<68:53:20, 260.23s/it, lr=0.000125, test_MAE=0.651, time=266, train_MAE=0.517, train_loss=0.72, val_MAE=0.6, val_loss=0.803]Epoch 47:   5%|▍         | 47/1000 [3:34:20<68:53:20, 260.23s/it, lr=0.000125, test_MAE=0.644, time=256, train_MAE=0.522, train_loss=0.727, val_MAE=0.589, val_loss=0.794]Epoch 47:   5%|▍         | 48/1000 [3:34:20<68:31:02, 259.10s/it, lr=0.000125, test_MAE=0.644, time=256, train_MAE=0.522, train_loss=0.727, val_MAE=0.589, val_loss=0.794]Epoch 48:   5%|▍         | 48/1000 [3:34:20<68:31:02, 259.10s/it, lr=0.000125, test_MAE=0.644, time=256, train_MAE=0.522, train_loss=0.727, val_MAE=0.589, val_loss=0.794]Epoch 48:   5%|▍         | 48/1000 [3:38:40<68:31:02, 259.10s/it, lr=0.000125, test_MAE=0.667, time=260, train_MAE=0.517, train_loss=0.719, val_MAE=0.623, val_loss=0.825]Epoch 48:   5%|▍         | 49/1000 [3:38:40<68:31:16, 259.39s/it, lr=0.000125, test_MAE=0.667, time=260, train_MAE=0.517, train_loss=0.719, val_MAE=0.623, val_loss=0.825]Epoch 49:   5%|▍         | 49/1000 [3:38:40<68:31:16, 259.39s/it, lr=0.000125, test_MAE=0.667, time=260, train_MAE=0.517, train_loss=0.719, val_MAE=0.623, val_loss=0.825]Epoch 49:   5%|▍         | 49/1000 [3:42:58<68:31:16, 259.39s/it, lr=0.000125, test_MAE=0.639, time=258, train_MAE=0.516, train_loss=0.719, val_MAE=0.587, val_loss=0.79] Epoch    50: reducing learning rate of group 0 to 6.2500e-05.
Epoch 49:   5%|▌         | 50/1000 [3:42:58<68:19:02, 258.89s/it, lr=0.000125, test_MAE=0.639, time=258, train_MAE=0.516, train_loss=0.719, val_MAE=0.587, val_loss=0.79]Epoch 50:   5%|▌         | 50/1000 [3:42:58<68:19:02, 258.89s/it, lr=0.000125, test_MAE=0.639, time=258, train_MAE=0.516, train_loss=0.719, val_MAE=0.587, val_loss=0.79]Epoch 50:   5%|▌         | 50/1000 [3:47:13<68:19:02, 258.89s/it, lr=6.25e-5, test_MAE=0.667, time=255, train_MAE=0.515, train_loss=0.714, val_MAE=0.622, val_loss=0.82] Epoch 50:   5%|▌         | 51/1000 [3:47:13<67:56:21, 257.73s/it, lr=6.25e-5, test_MAE=0.667, time=255, train_MAE=0.515, train_loss=0.714, val_MAE=0.622, val_loss=0.82]Epoch 51:   5%|▌         | 51/1000 [3:47:13<67:56:21, 257.73s/it, lr=6.25e-5, test_MAE=0.667, time=255, train_MAE=0.515, train_loss=0.714, val_MAE=0.622, val_loss=0.82]Epoch 51:   5%|▌         | 51/1000 [3:51:29<67:56:21, 257.73s/it, lr=6.25e-5, test_MAE=0.617, time=256, train_MAE=0.498, train_loss=0.697, val_MAE=0.575, val_loss=0.773]Epoch 51:   5%|▌         | 52/1000 [3:51:29<67:42:04, 257.09s/it, lr=6.25e-5, test_MAE=0.617, time=256, train_MAE=0.498, train_loss=0.697, val_MAE=0.575, val_loss=0.773]Epoch 52:   5%|▌         | 52/1000 [3:51:29<67:42:04, 257.09s/it, lr=6.25e-5, test_MAE=0.617, time=256, train_MAE=0.498, train_loss=0.697, val_MAE=0.575, val_loss=0.773]Epoch 52:   5%|▌         | 52/1000 [3:55:45<67:42:04, 257.09s/it, lr=6.25e-5, test_MAE=0.637, time=256, train_MAE=0.495, train_loss=0.693, val_MAE=0.584, val_loss=0.782]Epoch 52:   5%|▌         | 53/1000 [3:55:45<67:34:36, 256.89s/it, lr=6.25e-5, test_MAE=0.637, time=256, train_MAE=0.495, train_loss=0.693, val_MAE=0.584, val_loss=0.782]Epoch 53:   5%|▌         | 53/1000 [3:55:45<67:34:36, 256.89s/it, lr=6.25e-5, test_MAE=0.637, time=256, train_MAE=0.495, train_loss=0.693, val_MAE=0.584, val_loss=0.782]Epoch 53:   5%|▌         | 53/1000 [4:00:00<67:34:36, 256.89s/it, lr=6.25e-5, test_MAE=0.622, time=255, train_MAE=0.5, train_loss=0.697, val_MAE=0.589, val_loss=0.787]  Epoch 53:   5%|▌         | 54/1000 [4:00:00<67:21:47, 256.35s/it, lr=6.25e-5, test_MAE=0.622, time=255, train_MAE=0.5, train_loss=0.697, val_MAE=0.589, val_loss=0.787]Epoch 54:   5%|▌         | 54/1000 [4:00:00<67:21:47, 256.35s/it, lr=6.25e-5, test_MAE=0.622, time=255, train_MAE=0.5, train_loss=0.697, val_MAE=0.589, val_loss=0.787]Epoch 54:   5%|▌         | 54/1000 [4:04:16<67:21:47, 256.35s/it, lr=6.25e-5, test_MAE=0.644, time=256, train_MAE=0.497, train_loss=0.695, val_MAE=0.596, val_loss=0.794]Epoch 54:   6%|▌         | 55/1000 [4:04:16<67:14:20, 256.15s/it, lr=6.25e-5, test_MAE=0.644, time=256, train_MAE=0.497, train_loss=0.695, val_MAE=0.596, val_loss=0.794]Epoch 55:   6%|▌         | 55/1000 [4:04:16<67:14:20, 256.15s/it, lr=6.25e-5, test_MAE=0.644, time=256, train_MAE=0.497, train_loss=0.695, val_MAE=0.596, val_loss=0.794]Epoch 55:   6%|▌         | 55/1000 [4:08:32<67:14:20, 256.15s/it, lr=6.25e-5, test_MAE=0.627, time=256, train_MAE=0.505, train_loss=0.703, val_MAE=0.582, val_loss=0.78] Epoch 55:   6%|▌         | 56/1000 [4:08:32<67:11:04, 256.21s/it, lr=6.25e-5, test_MAE=0.627, time=256, train_MAE=0.505, train_loss=0.703, val_MAE=0.582, val_loss=0.78]Epoch 56:   6%|▌         | 56/1000 [4:08:32<67:11:04, 256.21s/it, lr=6.25e-5, test_MAE=0.627, time=256, train_MAE=0.505, train_loss=0.703, val_MAE=0.582, val_loss=0.78]Epoch 56:   6%|▌         | 56/1000 [4:12:47<67:11:04, 256.21s/it, lr=6.25e-5, test_MAE=0.626, time=255, train_MAE=0.498, train_loss=0.695, val_MAE=0.581, val_loss=0.779]Epoch 56:   6%|▌         | 57/1000 [4:12:47<67:00:59, 255.84s/it, lr=6.25e-5, test_MAE=0.626, time=255, train_MAE=0.498, train_loss=0.695, val_MAE=0.581, val_loss=0.779]Epoch 57:   6%|▌         | 57/1000 [4:12:47<67:00:59, 255.84s/it, lr=6.25e-5, test_MAE=0.626, time=255, train_MAE=0.498, train_loss=0.695, val_MAE=0.581, val_loss=0.779]Epoch 57:   6%|▌         | 57/1000 [4:17:03<67:00:59, 255.84s/it, lr=6.25e-5, test_MAE=0.707, time=256, train_MAE=0.488, train_loss=0.685, val_MAE=0.672, val_loss=0.869]Epoch    58: reducing learning rate of group 0 to 3.1250e-05.
Epoch 57:   6%|▌         | 58/1000 [4:17:03<66:55:48, 255.78s/it, lr=6.25e-5, test_MAE=0.707, time=256, train_MAE=0.488, train_loss=0.685, val_MAE=0.672, val_loss=0.869]Epoch 58:   6%|▌         | 58/1000 [4:17:03<66:55:48, 255.78s/it, lr=6.25e-5, test_MAE=0.707, time=256, train_MAE=0.488, train_loss=0.685, val_MAE=0.672, val_loss=0.869]Epoch 58:   6%|▌         | 58/1000 [4:21:19<66:55:48, 255.78s/it, lr=3.13e-5, test_MAE=0.63, time=256, train_MAE=0.493, train_loss=0.689, val_MAE=0.581, val_loss=0.777] Epoch 58:   6%|▌         | 59/1000 [4:21:19<66:54:43, 255.99s/it, lr=3.13e-5, test_MAE=0.63, time=256, train_MAE=0.493, train_loss=0.689, val_MAE=0.581, val_loss=0.777]Epoch 59:   6%|▌         | 59/1000 [4:21:19<66:54:43, 255.99s/it, lr=3.13e-5, test_MAE=0.63, time=256, train_MAE=0.493, train_loss=0.689, val_MAE=0.581, val_loss=0.777]Epoch 59:   6%|▌         | 59/1000 [4:25:34<66:54:43, 255.99s/it, lr=3.13e-5, test_MAE=0.626, time=255, train_MAE=0.495, train_loss=0.691, val_MAE=0.574, val_loss=0.77]Epoch 59:   6%|▌         | 60/1000 [4:25:34<66:46:11, 255.71s/it, lr=3.13e-5, test_MAE=0.626, time=255, train_MAE=0.495, train_loss=0.691, val_MAE=0.574, val_loss=0.77]Epoch 60:   6%|▌         | 60/1000 [4:25:34<66:46:11, 255.71s/it, lr=3.13e-5, test_MAE=0.626, time=255, train_MAE=0.495, train_loss=0.691, val_MAE=0.574, val_loss=0.77]Epoch 60:   6%|▌         | 60/1000 [4:29:50<66:46:11, 255.71s/it, lr=3.13e-5, test_MAE=0.621, time=255, train_MAE=0.48, train_loss=0.675, val_MAE=0.58, val_loss=0.775] Epoch 60:   6%|▌         | 61/1000 [4:29:50<66:40:48, 255.64s/it, lr=3.13e-5, test_MAE=0.621, time=255, train_MAE=0.48, train_loss=0.675, val_MAE=0.58, val_loss=0.775]Epoch 61:   6%|▌         | 61/1000 [4:29:50<66:40:48, 255.64s/it, lr=3.13e-5, test_MAE=0.621, time=255, train_MAE=0.48, train_loss=0.675, val_MAE=0.58, val_loss=0.775]Epoch 61:   6%|▌         | 61/1000 [4:34:06<66:40:48, 255.64s/it, lr=3.13e-5, test_MAE=0.627, time=256, train_MAE=0.486, train_loss=0.681, val_MAE=0.582, val_loss=0.777]Epoch 61:   6%|▌         | 62/1000 [4:34:06<66:39:39, 255.84s/it, lr=3.13e-5, test_MAE=0.627, time=256, train_MAE=0.486, train_loss=0.681, val_MAE=0.582, val_loss=0.777]Epoch 62:   6%|▌         | 62/1000 [4:34:06<66:39:39, 255.84s/it, lr=3.13e-5, test_MAE=0.627, time=256, train_MAE=0.486, train_loss=0.681, val_MAE=0.582, val_loss=0.777]Epoch 62:   6%|▌         | 62/1000 [4:38:21<66:39:39, 255.84s/it, lr=3.13e-5, test_MAE=0.634, time=255, train_MAE=0.487, train_loss=0.682, val_MAE=0.587, val_loss=0.782]Epoch 62:   6%|▋         | 63/1000 [4:38:21<66:31:44, 255.61s/it, lr=3.13e-5, test_MAE=0.634, time=255, train_MAE=0.487, train_loss=0.682, val_MAE=0.587, val_loss=0.782]Epoch 63:   6%|▋         | 63/1000 [4:38:21<66:31:44, 255.61s/it, lr=3.13e-5, test_MAE=0.634, time=255, train_MAE=0.487, train_loss=0.682, val_MAE=0.587, val_loss=0.782]Epoch 63:   6%|▋         | 63/1000 [4:42:37<66:31:44, 255.61s/it, lr=3.13e-5, test_MAE=0.655, time=256, train_MAE=0.485, train_loss=0.68, val_MAE=0.613, val_loss=0.808] Epoch 63:   6%|▋         | 64/1000 [4:42:37<66:27:25, 255.60s/it, lr=3.13e-5, test_MAE=0.655, time=256, train_MAE=0.485, train_loss=0.68, val_MAE=0.613, val_loss=0.808]Epoch 64:   6%|▋         | 64/1000 [4:42:37<66:27:25, 255.60s/it, lr=3.13e-5, test_MAE=0.655, time=256, train_MAE=0.485, train_loss=0.68, val_MAE=0.613, val_loss=0.808]Epoch 64:   6%|▋         | 64/1000 [4:46:53<66:27:25, 255.60s/it, lr=3.13e-5, test_MAE=0.641, time=256, train_MAE=0.492, train_loss=0.687, val_MAE=0.594, val_loss=0.789]Epoch 64:   6%|▋         | 65/1000 [4:46:53<66:26:55, 255.85s/it, lr=3.13e-5, test_MAE=0.641, time=256, train_MAE=0.492, train_loss=0.687, val_MAE=0.594, val_loss=0.789]Epoch 65:   6%|▋         | 65/1000 [4:46:53<66:26:55, 255.85s/it, lr=3.13e-5, test_MAE=0.641, time=256, train_MAE=0.492, train_loss=0.687, val_MAE=0.594, val_loss=0.789]Epoch 65:   6%|▋         | 65/1000 [4:51:08<66:26:55, 255.85s/it, lr=3.13e-5, test_MAE=0.638, time=255, train_MAE=0.477, train_loss=0.671, val_MAE=0.588, val_loss=0.783]Epoch    66: reducing learning rate of group 0 to 1.5625e-05.
Epoch 65:   7%|▋         | 66/1000 [4:51:08<66:18:02, 255.55s/it, lr=3.13e-5, test_MAE=0.638, time=255, train_MAE=0.477, train_loss=0.671, val_MAE=0.588, val_loss=0.783]Epoch 66:   7%|▋         | 66/1000 [4:51:08<66:18:02, 255.55s/it, lr=3.13e-5, test_MAE=0.638, time=255, train_MAE=0.477, train_loss=0.671, val_MAE=0.588, val_loss=0.783]Epoch 66:   7%|▋         | 66/1000 [4:55:24<66:18:02, 255.55s/it, lr=1.56e-5, test_MAE=0.635, time=256, train_MAE=0.475, train_loss=0.67, val_MAE=0.582, val_loss=0.776] Epoch 66:   7%|▋         | 67/1000 [4:55:24<66:14:27, 255.59s/it, lr=1.56e-5, test_MAE=0.635, time=256, train_MAE=0.475, train_loss=0.67, val_MAE=0.582, val_loss=0.776]Epoch 67:   7%|▋         | 67/1000 [4:55:24<66:14:27, 255.59s/it, lr=1.56e-5, test_MAE=0.635, time=256, train_MAE=0.475, train_loss=0.67, val_MAE=0.582, val_loss=0.776]Epoch 67:   7%|▋         | 67/1000 [4:59:40<66:14:27, 255.59s/it, lr=1.56e-5, test_MAE=0.636, time=256, train_MAE=0.472, train_loss=0.666, val_MAE=0.599, val_loss=0.793]Epoch 67:   7%|▋         | 68/1000 [4:59:40<66:14:02, 255.84s/it, lr=1.56e-5, test_MAE=0.636, time=256, train_MAE=0.472, train_loss=0.666, val_MAE=0.599, val_loss=0.793]Epoch 68:   7%|▋         | 68/1000 [4:59:40<66:14:02, 255.84s/it, lr=1.56e-5, test_MAE=0.636, time=256, train_MAE=0.472, train_loss=0.666, val_MAE=0.599, val_loss=0.793]Epoch 68:   7%|▋         | 68/1000 [5:03:55<66:14:02, 255.84s/it, lr=1.56e-5, test_MAE=0.628, time=255, train_MAE=0.472, train_loss=0.666, val_MAE=0.586, val_loss=0.78] Epoch 68:   7%|▋         | 69/1000 [5:03:55<66:05:49, 255.59s/it, lr=1.56e-5, test_MAE=0.628, time=255, train_MAE=0.472, train_loss=0.666, val_MAE=0.586, val_loss=0.78]Epoch 69:   7%|▋         | 69/1000 [5:03:55<66:05:49, 255.59s/it, lr=1.56e-5, test_MAE=0.628, time=255, train_MAE=0.472, train_loss=0.666, val_MAE=0.586, val_loss=0.78]Epoch 69:   7%|▋         | 69/1000 [5:08:11<66:05:49, 255.59s/it, lr=1.56e-5, test_MAE=0.623, time=255, train_MAE=0.467, train_loss=0.661, val_MAE=0.579, val_loss=0.773]Epoch 69:   7%|▋         | 70/1000 [5:08:11<66:01:18, 255.57s/it, lr=1.56e-5, test_MAE=0.623, time=255, train_MAE=0.467, train_loss=0.661, val_MAE=0.579, val_loss=0.773]Epoch 70:   7%|▋         | 70/1000 [5:08:11<66:01:18, 255.57s/it, lr=1.56e-5, test_MAE=0.623, time=255, train_MAE=0.467, train_loss=0.661, val_MAE=0.579, val_loss=0.773]Epoch 70:   7%|▋         | 70/1000 [5:12:27<66:01:18, 255.57s/it, lr=1.56e-5, test_MAE=0.643, time=257, train_MAE=0.478, train_loss=0.672, val_MAE=0.598, val_loss=0.791]Epoch 70:   7%|▋         | 71/1000 [5:12:27<66:02:00, 255.89s/it, lr=1.56e-5, test_MAE=0.643, time=257, train_MAE=0.478, train_loss=0.672, val_MAE=0.598, val_loss=0.791]Epoch 71:   7%|▋         | 71/1000 [5:12:27<66:02:00, 255.89s/it, lr=1.56e-5, test_MAE=0.643, time=257, train_MAE=0.478, train_loss=0.672, val_MAE=0.598, val_loss=0.791]Epoch 71:   7%|▋         | 71/1000 [5:16:42<66:02:00, 255.89s/it, lr=1.56e-5, test_MAE=0.634, time=255, train_MAE=0.48, train_loss=0.674, val_MAE=0.585, val_loss=0.779] Epoch    72: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 71:   7%|▋         | 71/1000 [5:16:42<69:04:01, 267.64s/it, lr=1.56e-5, test_MAE=0.634, time=255, train_MAE=0.48, train_loss=0.674, val_MAE=0.585, val_loss=0.779]
Test MAE: 0.6336
Train MAE: 0.4484
Convergence Time (Epochs): 71.0000
TOTAL TIME TAKEN: 19164.6128s
AVG TIME PER EPOCH: 263.8864s
