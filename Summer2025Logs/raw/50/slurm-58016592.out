I'm echoing to stdout
I'm echoing to stderr
My JobID is 58016592
I have 4 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.2184s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': False, 'readout': 'mean', 'k': 2, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'poly_mlp', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_all', 'num_eigs': 16, 'bias_mode': 'spatial', 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 0.0, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/aug07/zinc_train_rec.csv', 'test': 'supp_data/molecules/aug07/zinc_test_rec.csv', 'val': 'supp_data/molecules/aug07/zinc_val_rec.csv'}, 'fixMissingPhi1': False, 'extraOrtho': False, 'doublePrecision': True, 'eigval_hidden_dim': 100, 'eigval_num_hidden_layer': 0, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [01:23<?, ?it/s, lr=0.001, test_MAE=0.928, time=83.8, train_MAE=0.975, train_loss=0.975, val_MAE=0.84, val_loss=0.84]Epoch 0:   0%|          | 1/1000 [01:23<23:15:47, 83.83s/it, lr=0.001, test_MAE=0.928, time=83.8, train_MAE=0.975, train_loss=0.975, val_MAE=0.84, val_loss=0.84]Epoch 1:   0%|          | 1/1000 [01:23<23:15:47, 83.83s/it, lr=0.001, test_MAE=0.928, time=83.8, train_MAE=0.975, train_loss=0.975, val_MAE=0.84, val_loss=0.84]Epoch 1:   0%|          | 1/1000 [02:29<23:15:47, 83.83s/it, lr=0.001, test_MAE=0.84, time=65.8, train_MAE=0.697, train_loss=0.697, val_MAE=0.773, val_loss=0.773]Epoch 1:   0%|          | 2/1000 [02:29<21:44:43, 78.44s/it, lr=0.001, test_MAE=0.84, time=65.8, train_MAE=0.697, train_loss=0.697, val_MAE=0.773, val_loss=0.773]Epoch 2:   0%|          | 2/1000 [02:29<21:44:43, 78.44s/it, lr=0.001, test_MAE=0.84, time=65.8, train_MAE=0.697, train_loss=0.697, val_MAE=0.773, val_loss=0.773]Epoch 2:   0%|          | 2/1000 [03:35<21:44:43, 78.44s/it, lr=0.001, test_MAE=0.76, time=65.9, train_MAE=0.687, train_loss=0.687, val_MAE=0.711, val_loss=0.711]Epoch 2:   0%|          | 3/1000 [03:35<20:41:08, 74.69s/it, lr=0.001, test_MAE=0.76, time=65.9, train_MAE=0.687, train_loss=0.687, val_MAE=0.711, val_loss=0.711]Epoch 3:   0%|          | 3/1000 [03:35<20:41:08, 74.69s/it, lr=0.001, test_MAE=0.76, time=65.9, train_MAE=0.687, train_loss=0.687, val_MAE=0.711, val_loss=0.711]Epoch 3:   0%|          | 3/1000 [04:41<20:41:08, 74.69s/it, lr=0.001, test_MAE=0.72, time=65.8, train_MAE=0.672, train_loss=0.672, val_MAE=0.669, val_loss=0.669]Epoch 3:   0%|          | 4/1000 [04:41<19:56:02, 72.05s/it, lr=0.001, test_MAE=0.72, time=65.8, train_MAE=0.672, train_loss=0.672, val_MAE=0.669, val_loss=0.669]Epoch 4:   0%|          | 4/1000 [04:41<19:56:02, 72.05s/it, lr=0.001, test_MAE=0.72, time=65.8, train_MAE=0.672, train_loss=0.672, val_MAE=0.669, val_loss=0.669]Epoch 4:   0%|          | 4/1000 [05:47<19:56:02, 72.05s/it, lr=0.001, test_MAE=0.698, time=66, train_MAE=0.655, train_loss=0.655, val_MAE=0.657, val_loss=0.657] Epoch 4:   0%|          | 5/1000 [05:47<19:25:09, 70.26s/it, lr=0.001, test_MAE=0.698, time=66, train_MAE=0.655, train_loss=0.655, val_MAE=0.657, val_loss=0.657]Epoch 5:   0%|          | 5/1000 [05:47<19:25:09, 70.26s/it, lr=0.001, test_MAE=0.698, time=66, train_MAE=0.655, train_loss=0.655, val_MAE=0.657, val_loss=0.657]Epoch 5:   0%|          | 5/1000 [06:53<19:25:09, 70.26s/it, lr=0.001, test_MAE=0.901, time=66, train_MAE=0.658, train_loss=0.658, val_MAE=0.834, val_loss=0.834]Epoch 5:   1%|          | 6/1000 [06:53<19:02:44, 68.98s/it, lr=0.001, test_MAE=0.901, time=66, train_MAE=0.658, train_loss=0.658, val_MAE=0.834, val_loss=0.834]Epoch 6:   1%|          | 6/1000 [06:53<19:02:44, 68.98s/it, lr=0.001, test_MAE=0.901, time=66, train_MAE=0.658, train_loss=0.658, val_MAE=0.834, val_loss=0.834]Epoch 6:   1%|          | 6/1000 [07:59<19:02:44, 68.98s/it, lr=0.001, test_MAE=0.779, time=66.3, train_MAE=0.646, train_loss=0.646, val_MAE=0.719, val_loss=0.719]Epoch 6:   1%|          | 7/1000 [07:59<18:48:31, 68.19s/it, lr=0.001, test_MAE=0.779, time=66.3, train_MAE=0.646, train_loss=0.646, val_MAE=0.719, val_loss=0.719]Epoch 7:   1%|          | 7/1000 [07:59<18:48:31, 68.19s/it, lr=0.001, test_MAE=0.779, time=66.3, train_MAE=0.646, train_loss=0.646, val_MAE=0.719, val_loss=0.719]Epoch 7:   1%|          | 7/1000 [09:06<18:48:31, 68.19s/it, lr=0.001, test_MAE=0.771, time=66.1, train_MAE=0.643, train_loss=0.643, val_MAE=0.727, val_loss=0.727]Epoch 7:   1%|          | 8/1000 [09:06<18:37:13, 67.57s/it, lr=0.001, test_MAE=0.771, time=66.1, train_MAE=0.643, train_loss=0.643, val_MAE=0.727, val_loss=0.727]Epoch 8:   1%|          | 8/1000 [09:06<18:37:13, 67.57s/it, lr=0.001, test_MAE=0.771, time=66.1, train_MAE=0.643, train_loss=0.643, val_MAE=0.727, val_loss=0.727]Epoch 8:   1%|          | 8/1000 [10:12<18:37:13, 67.57s/it, lr=0.001, test_MAE=0.691, time=66.2, train_MAE=0.643, train_loss=0.643, val_MAE=0.659, val_loss=0.659]Epoch 8:   1%|          | 9/1000 [10:12<18:29:21, 67.17s/it, lr=0.001, test_MAE=0.691, time=66.2, train_MAE=0.643, train_loss=0.643, val_MAE=0.659, val_loss=0.659]Epoch 9:   1%|          | 9/1000 [10:12<18:29:21, 67.17s/it, lr=0.001, test_MAE=0.691, time=66.2, train_MAE=0.643, train_loss=0.643, val_MAE=0.659, val_loss=0.659]Epoch 9:   1%|          | 9/1000 [11:19<18:29:21, 67.17s/it, lr=0.001, test_MAE=0.704, time=67.4, train_MAE=0.633, train_loss=0.633, val_MAE=0.651, val_loss=0.651]Epoch 9:   1%|          | 10/1000 [11:19<18:29:34, 67.25s/it, lr=0.001, test_MAE=0.704, time=67.4, train_MAE=0.633, train_loss=0.633, val_MAE=0.651, val_loss=0.651]Epoch 10:   1%|          | 10/1000 [11:19<18:29:34, 67.25s/it, lr=0.001, test_MAE=0.704, time=67.4, train_MAE=0.633, train_loss=0.633, val_MAE=0.651, val_loss=0.651]Epoch 10:   1%|          | 10/1000 [12:26<18:29:34, 67.25s/it, lr=0.001, test_MAE=0.754, time=67.3, train_MAE=0.633, train_loss=0.633, val_MAE=0.729, val_loss=0.729]Epoch 10:   1%|          | 11/1000 [12:27<18:28:44, 67.26s/it, lr=0.001, test_MAE=0.754, time=67.3, train_MAE=0.633, train_loss=0.633, val_MAE=0.729, val_loss=0.729]Epoch 11:   1%|          | 11/1000 [12:27<18:28:44, 67.26s/it, lr=0.001, test_MAE=0.754, time=67.3, train_MAE=0.633, train_loss=0.633, val_MAE=0.729, val_loss=0.729]Epoch 11:   1%|          | 11/1000 [13:34<18:28:44, 67.26s/it, lr=0.001, test_MAE=0.77, time=67, train_MAE=0.631, train_loss=0.631, val_MAE=0.738, val_loss=0.738]   Epoch 11:   1%|          | 12/1000 [13:34<18:26:31, 67.20s/it, lr=0.001, test_MAE=0.77, time=67, train_MAE=0.631, train_loss=0.631, val_MAE=0.738, val_loss=0.738]Epoch 12:   1%|          | 12/1000 [13:34<18:26:31, 67.20s/it, lr=0.001, test_MAE=0.77, time=67, train_MAE=0.631, train_loss=0.631, val_MAE=0.738, val_loss=0.738]Epoch 12:   1%|          | 12/1000 [14:41<18:26:31, 67.20s/it, lr=0.001, test_MAE=0.729, time=67.7, train_MAE=0.633, train_loss=0.633, val_MAE=0.696, val_loss=0.696]Epoch 12:   1%|▏         | 13/1000 [14:41<18:28:08, 67.36s/it, lr=0.001, test_MAE=0.729, time=67.7, train_MAE=0.633, train_loss=0.633, val_MAE=0.696, val_loss=0.696]Epoch 13:   1%|▏         | 13/1000 [14:41<18:28:08, 67.36s/it, lr=0.001, test_MAE=0.729, time=67.7, train_MAE=0.633, train_loss=0.633, val_MAE=0.696, val_loss=0.696]Epoch 13:   1%|▏         | 13/1000 [15:49<18:28:08, 67.36s/it, lr=0.001, test_MAE=0.686, time=67.6, train_MAE=0.625, train_loss=0.625, val_MAE=0.634, val_loss=0.634]Epoch 13:   1%|▏         | 14/1000 [15:49<18:28:28, 67.45s/it, lr=0.001, test_MAE=0.686, time=67.6, train_MAE=0.625, train_loss=0.625, val_MAE=0.634, val_loss=0.634]Epoch 14:   1%|▏         | 14/1000 [15:49<18:28:28, 67.45s/it, lr=0.001, test_MAE=0.686, time=67.6, train_MAE=0.625, train_loss=0.625, val_MAE=0.634, val_loss=0.634]Epoch 14:   1%|▏         | 14/1000 [16:56<18:28:28, 67.45s/it, lr=0.001, test_MAE=0.895, time=67.3, train_MAE=0.628, train_loss=0.628, val_MAE=0.84, val_loss=0.84]  Epoch 14:   2%|▏         | 15/1000 [16:56<18:26:49, 67.42s/it, lr=0.001, test_MAE=0.895, time=67.3, train_MAE=0.628, train_loss=0.628, val_MAE=0.84, val_loss=0.84]Epoch 15:   2%|▏         | 15/1000 [16:56<18:26:49, 67.42s/it, lr=0.001, test_MAE=0.895, time=67.3, train_MAE=0.628, train_loss=0.628, val_MAE=0.84, val_loss=0.84]Epoch 15:   2%|▏         | 15/1000 [18:04<18:26:49, 67.42s/it, lr=0.001, test_MAE=0.669, time=67.7, train_MAE=0.617, train_loss=0.617, val_MAE=0.653, val_loss=0.653]Epoch 15:   2%|▏         | 16/1000 [18:04<18:27:06, 67.51s/it, lr=0.001, test_MAE=0.669, time=67.7, train_MAE=0.617, train_loss=0.617, val_MAE=0.653, val_loss=0.653]Epoch 16:   2%|▏         | 16/1000 [18:04<18:27:06, 67.51s/it, lr=0.001, test_MAE=0.669, time=67.7, train_MAE=0.617, train_loss=0.617, val_MAE=0.653, val_loss=0.653]Epoch 16:   2%|▏         | 16/1000 [19:11<18:27:06, 67.51s/it, lr=0.001, test_MAE=0.74, time=67.3, train_MAE=0.617, train_loss=0.617, val_MAE=0.695, val_loss=0.695] Epoch 16:   2%|▏         | 17/1000 [19:11<18:25:15, 67.46s/it, lr=0.001, test_MAE=0.74, time=67.3, train_MAE=0.617, train_loss=0.617, val_MAE=0.695, val_loss=0.695]Epoch 17:   2%|▏         | 17/1000 [19:11<18:25:15, 67.46s/it, lr=0.001, test_MAE=0.74, time=67.3, train_MAE=0.617, train_loss=0.617, val_MAE=0.695, val_loss=0.695]Epoch 17:   2%|▏         | 17/1000 [20:18<18:25:15, 67.46s/it, lr=0.001, test_MAE=0.671, time=66.8, train_MAE=0.61, train_loss=0.61, val_MAE=0.625, val_loss=0.625] Epoch 17:   2%|▏         | 18/1000 [20:18<18:21:08, 67.28s/it, lr=0.001, test_MAE=0.671, time=66.8, train_MAE=0.61, train_loss=0.61, val_MAE=0.625, val_loss=0.625]Epoch 18:   2%|▏         | 18/1000 [20:18<18:21:08, 67.28s/it, lr=0.001, test_MAE=0.671, time=66.8, train_MAE=0.61, train_loss=0.61, val_MAE=0.625, val_loss=0.625]Epoch 18:   2%|▏         | 18/1000 [21:26<18:21:08, 67.28s/it, lr=0.001, test_MAE=1.02, time=67.5, train_MAE=0.61, train_loss=0.61, val_MAE=0.99, val_loss=0.99]   Epoch 18:   2%|▏         | 19/1000 [21:26<18:21:14, 67.35s/it, lr=0.001, test_MAE=1.02, time=67.5, train_MAE=0.61, train_loss=0.61, val_MAE=0.99, val_loss=0.99]Epoch 19:   2%|▏         | 19/1000 [21:26<18:21:14, 67.35s/it, lr=0.001, test_MAE=1.02, time=67.5, train_MAE=0.61, train_loss=0.61, val_MAE=0.99, val_loss=0.99]Epoch 19:   2%|▏         | 19/1000 [22:33<18:21:14, 67.35s/it, lr=0.001, test_MAE=0.673, time=67, train_MAE=0.618, train_loss=0.618, val_MAE=0.647, val_loss=0.647]Epoch 19:   2%|▏         | 20/1000 [22:33<18:18:34, 67.26s/it, lr=0.001, test_MAE=0.673, time=67, train_MAE=0.618, train_loss=0.618, val_MAE=0.647, val_loss=0.647]Epoch 20:   2%|▏         | 20/1000 [22:33<18:18:34, 67.26s/it, lr=0.001, test_MAE=0.673, time=67, train_MAE=0.618, train_loss=0.618, val_MAE=0.647, val_loss=0.647]Epoch 20:   2%|▏         | 20/1000 [23:40<18:18:34, 67.26s/it, lr=0.001, test_MAE=0.754, time=67, train_MAE=0.615, train_loss=0.615, val_MAE=0.729, val_loss=0.729]Epoch 20:   2%|▏         | 21/1000 [23:40<18:16:19, 67.19s/it, lr=0.001, test_MAE=0.754, time=67, train_MAE=0.615, train_loss=0.615, val_MAE=0.729, val_loss=0.729]Epoch 21:   2%|▏         | 21/1000 [23:40<18:16:19, 67.19s/it, lr=0.001, test_MAE=0.754, time=67, train_MAE=0.615, train_loss=0.615, val_MAE=0.729, val_loss=0.729]Epoch 21:   2%|▏         | 21/1000 [24:47<18:16:19, 67.19s/it, lr=0.001, test_MAE=0.686, time=67.6, train_MAE=0.602, train_loss=0.602, val_MAE=0.654, val_loss=0.654]Epoch 21:   2%|▏         | 22/1000 [24:47<18:17:21, 67.32s/it, lr=0.001, test_MAE=0.686, time=67.6, train_MAE=0.602, train_loss=0.602, val_MAE=0.654, val_loss=0.654]Epoch 22:   2%|▏         | 22/1000 [24:47<18:17:21, 67.32s/it, lr=0.001, test_MAE=0.686, time=67.6, train_MAE=0.602, train_loss=0.602, val_MAE=0.654, val_loss=0.654]Epoch 22:   2%|▏         | 22/1000 [25:54<18:17:21, 67.32s/it, lr=0.001, test_MAE=0.655, time=66.9, train_MAE=0.598, train_loss=0.598, val_MAE=0.626, val_loss=0.626]Epoch 22:   2%|▏         | 23/1000 [25:54<18:14:13, 67.20s/it, lr=0.001, test_MAE=0.655, time=66.9, train_MAE=0.598, train_loss=0.598, val_MAE=0.626, val_loss=0.626]Epoch 23:   2%|▏         | 23/1000 [25:54<18:14:13, 67.20s/it, lr=0.001, test_MAE=0.655, time=66.9, train_MAE=0.598, train_loss=0.598, val_MAE=0.626, val_loss=0.626]Epoch 23:   2%|▏         | 23/1000 [27:02<18:14:13, 67.20s/it, lr=0.001, test_MAE=0.669, time=67.8, train_MAE=0.601, train_loss=0.601, val_MAE=0.631, val_loss=0.631]Epoch    24: reducing learning rate of group 0 to 5.0000e-04.
Epoch 23:   2%|▏         | 24/1000 [27:02<18:16:21, 67.40s/it, lr=0.001, test_MAE=0.669, time=67.8, train_MAE=0.601, train_loss=0.601, val_MAE=0.631, val_loss=0.631]Epoch 24:   2%|▏         | 24/1000 [27:02<18:16:21, 67.40s/it, lr=0.001, test_MAE=0.669, time=67.8, train_MAE=0.601, train_loss=0.601, val_MAE=0.631, val_loss=0.631]Epoch 24:   2%|▏         | 24/1000 [28:08<18:16:21, 67.40s/it, lr=0.0005, test_MAE=0.658, time=66.2, train_MAE=0.585, train_loss=0.585, val_MAE=0.626, val_loss=0.626]Epoch 24:   2%|▎         | 25/1000 [28:09<18:09:35, 67.05s/it, lr=0.0005, test_MAE=0.658, time=66.2, train_MAE=0.585, train_loss=0.585, val_MAE=0.626, val_loss=0.626]Epoch 25:   2%|▎         | 25/1000 [28:09<18:09:35, 67.05s/it, lr=0.0005, test_MAE=0.658, time=66.2, train_MAE=0.585, train_loss=0.585, val_MAE=0.626, val_loss=0.626]Epoch 25:   2%|▎         | 25/1000 [29:15<18:09:35, 67.05s/it, lr=0.0005, test_MAE=0.706, time=66.2, train_MAE=0.58, train_loss=0.58, val_MAE=0.666, val_loss=0.666]  Epoch 25:   3%|▎         | 26/1000 [29:15<18:04:14, 66.79s/it, lr=0.0005, test_MAE=0.706, time=66.2, train_MAE=0.58, train_loss=0.58, val_MAE=0.666, val_loss=0.666]Epoch 26:   3%|▎         | 26/1000 [29:15<18:04:14, 66.79s/it, lr=0.0005, test_MAE=0.706, time=66.2, train_MAE=0.58, train_loss=0.58, val_MAE=0.666, val_loss=0.666]Epoch 26:   3%|▎         | 26/1000 [30:21<18:04:14, 66.79s/it, lr=0.0005, test_MAE=0.66, time=66.3, train_MAE=0.577, train_loss=0.577, val_MAE=0.631, val_loss=0.631]Epoch 26:   3%|▎         | 27/1000 [30:21<18:00:39, 66.64s/it, lr=0.0005, test_MAE=0.66, time=66.3, train_MAE=0.577, train_loss=0.577, val_MAE=0.631, val_loss=0.631]Epoch 27:   3%|▎         | 27/1000 [30:21<18:00:39, 66.64s/it, lr=0.0005, test_MAE=0.66, time=66.3, train_MAE=0.577, train_loss=0.577, val_MAE=0.631, val_loss=0.631]Epoch 27:   3%|▎         | 27/1000 [31:28<18:00:39, 66.64s/it, lr=0.0005, test_MAE=0.682, time=67.3, train_MAE=0.576, train_loss=0.576, val_MAE=0.657, val_loss=0.657]Epoch 27:   3%|▎         | 28/1000 [31:28<18:02:39, 66.83s/it, lr=0.0005, test_MAE=0.682, time=67.3, train_MAE=0.576, train_loss=0.576, val_MAE=0.657, val_loss=0.657]Epoch 28:   3%|▎         | 28/1000 [31:28<18:02:39, 66.83s/it, lr=0.0005, test_MAE=0.682, time=67.3, train_MAE=0.576, train_loss=0.576, val_MAE=0.657, val_loss=0.657]Epoch 28:   3%|▎         | 28/1000 [32:37<18:02:39, 66.83s/it, lr=0.0005, test_MAE=0.659, time=69.2, train_MAE=0.576, train_loss=0.576, val_MAE=0.629, val_loss=0.629]Epoch 28:   3%|▎         | 29/1000 [32:38<18:13:25, 67.57s/it, lr=0.0005, test_MAE=0.659, time=69.2, train_MAE=0.576, train_loss=0.576, val_MAE=0.629, val_loss=0.629]Epoch 29:   3%|▎         | 29/1000 [32:38<18:13:25, 67.57s/it, lr=0.0005, test_MAE=0.659, time=69.2, train_MAE=0.576, train_loss=0.576, val_MAE=0.629, val_loss=0.629]Epoch 29:   3%|▎         | 29/1000 [33:46<18:13:25, 67.57s/it, lr=0.0005, test_MAE=0.672, time=68.5, train_MAE=0.581, train_loss=0.581, val_MAE=0.636, val_loss=0.636]Epoch    30: reducing learning rate of group 0 to 2.5000e-04.
Epoch 29:   3%|▎         | 30/1000 [33:46<18:17:10, 67.87s/it, lr=0.0005, test_MAE=0.672, time=68.5, train_MAE=0.581, train_loss=0.581, val_MAE=0.636, val_loss=0.636]Epoch 30:   3%|▎         | 30/1000 [33:46<18:17:10, 67.87s/it, lr=0.0005, test_MAE=0.672, time=68.5, train_MAE=0.581, train_loss=0.581, val_MAE=0.636, val_loss=0.636]Epoch 30:   3%|▎         | 30/1000 [34:55<18:17:10, 67.87s/it, lr=0.00025, test_MAE=0.633, time=68.9, train_MAE=0.563, train_loss=0.563, val_MAE=0.611, val_loss=0.611]Epoch 30:   3%|▎         | 31/1000 [34:55<18:20:59, 68.17s/it, lr=0.00025, test_MAE=0.633, time=68.9, train_MAE=0.563, train_loss=0.563, val_MAE=0.611, val_loss=0.611]Epoch 31:   3%|▎         | 31/1000 [34:55<18:20:59, 68.17s/it, lr=0.00025, test_MAE=0.633, time=68.9, train_MAE=0.563, train_loss=0.563, val_MAE=0.611, val_loss=0.611]Epoch 31:   3%|▎         | 31/1000 [36:02<18:20:59, 68.17s/it, lr=0.00025, test_MAE=0.637, time=66.8, train_MAE=0.557, train_loss=0.557, val_MAE=0.612, val_loss=0.612]Epoch 31:   3%|▎         | 32/1000 [36:02<18:13:25, 67.77s/it, lr=0.00025, test_MAE=0.637, time=66.8, train_MAE=0.557, train_loss=0.557, val_MAE=0.612, val_loss=0.612]Epoch 32:   3%|▎         | 32/1000 [36:02<18:13:25, 67.77s/it, lr=0.00025, test_MAE=0.637, time=66.8, train_MAE=0.557, train_loss=0.557, val_MAE=0.612, val_loss=0.612]Epoch 32:   3%|▎         | 32/1000 [37:09<18:13:25, 67.77s/it, lr=0.00025, test_MAE=0.641, time=66.8, train_MAE=0.555, train_loss=0.555, val_MAE=0.61, val_loss=0.61]  Epoch 32:   3%|▎         | 33/1000 [37:09<18:07:50, 67.50s/it, lr=0.00025, test_MAE=0.641, time=66.8, train_MAE=0.555, train_loss=0.555, val_MAE=0.61, val_loss=0.61]Epoch 33:   3%|▎         | 33/1000 [37:09<18:07:50, 67.50s/it, lr=0.00025, test_MAE=0.641, time=66.8, train_MAE=0.555, train_loss=0.555, val_MAE=0.61, val_loss=0.61]Epoch 33:   3%|▎         | 33/1000 [38:16<18:07:50, 67.50s/it, lr=0.00025, test_MAE=0.665, time=66.9, train_MAE=0.55, train_loss=0.55, val_MAE=0.638, val_loss=0.638]Epoch 33:   3%|▎         | 34/1000 [38:16<18:03:43, 67.31s/it, lr=0.00025, test_MAE=0.665, time=66.9, train_MAE=0.55, train_loss=0.55, val_MAE=0.638, val_loss=0.638]Epoch 34:   3%|▎         | 34/1000 [38:16<18:03:43, 67.31s/it, lr=0.00025, test_MAE=0.665, time=66.9, train_MAE=0.55, train_loss=0.55, val_MAE=0.638, val_loss=0.638]Epoch 34:   3%|▎         | 34/1000 [39:22<18:03:43, 67.31s/it, lr=0.00025, test_MAE=0.642, time=66.4, train_MAE=0.549, train_loss=0.549, val_MAE=0.614, val_loss=0.614]Epoch 34:   4%|▎         | 35/1000 [39:22<17:58:13, 67.04s/it, lr=0.00025, test_MAE=0.642, time=66.4, train_MAE=0.549, train_loss=0.549, val_MAE=0.614, val_loss=0.614]Epoch 35:   4%|▎         | 35/1000 [39:22<17:58:13, 67.04s/it, lr=0.00025, test_MAE=0.642, time=66.4, train_MAE=0.549, train_loss=0.549, val_MAE=0.614, val_loss=0.614]Epoch 35:   4%|▎         | 35/1000 [40:29<17:58:13, 67.04s/it, lr=0.00025, test_MAE=0.647, time=67, train_MAE=0.555, train_loss=0.555, val_MAE=0.609, val_loss=0.609]  Epoch 35:   4%|▎         | 36/1000 [40:29<17:57:01, 67.04s/it, lr=0.00025, test_MAE=0.647, time=67, train_MAE=0.555, train_loss=0.555, val_MAE=0.609, val_loss=0.609]Epoch 36:   4%|▎         | 36/1000 [40:29<17:57:01, 67.04s/it, lr=0.00025, test_MAE=0.647, time=67, train_MAE=0.555, train_loss=0.555, val_MAE=0.609, val_loss=0.609]Epoch 36:   4%|▎         | 36/1000 [41:36<17:57:01, 67.04s/it, lr=0.00025, test_MAE=0.643, time=66.9, train_MAE=0.547, train_loss=0.547, val_MAE=0.619, val_loss=0.619]Epoch 36:   4%|▎         | 37/1000 [41:36<17:55:17, 67.00s/it, lr=0.00025, test_MAE=0.643, time=66.9, train_MAE=0.547, train_loss=0.547, val_MAE=0.619, val_loss=0.619]Epoch 37:   4%|▎         | 37/1000 [41:36<17:55:17, 67.00s/it, lr=0.00025, test_MAE=0.643, time=66.9, train_MAE=0.547, train_loss=0.547, val_MAE=0.619, val_loss=0.619]Epoch 37:   4%|▎         | 37/1000 [42:42<17:55:17, 67.00s/it, lr=0.00025, test_MAE=0.639, time=66.6, train_MAE=0.549, train_loss=0.549, val_MAE=0.61, val_loss=0.61]  Epoch 37:   4%|▍         | 38/1000 [42:42<17:52:10, 66.87s/it, lr=0.00025, test_MAE=0.639, time=66.6, train_MAE=0.549, train_loss=0.549, val_MAE=0.61, val_loss=0.61]Epoch 38:   4%|▍         | 38/1000 [42:42<17:52:10, 66.87s/it, lr=0.00025, test_MAE=0.639, time=66.6, train_MAE=0.549, train_loss=0.549, val_MAE=0.61, val_loss=0.61]Epoch 38:   4%|▍         | 38/1000 [43:50<17:52:10, 66.87s/it, lr=0.00025, test_MAE=0.65, time=67.4, train_MAE=0.555, train_loss=0.555, val_MAE=0.622, val_loss=0.622]Epoch 38:   4%|▍         | 39/1000 [43:50<17:53:50, 67.05s/it, lr=0.00025, test_MAE=0.65, time=67.4, train_MAE=0.555, train_loss=0.555, val_MAE=0.622, val_loss=0.622]Epoch 39:   4%|▍         | 39/1000 [43:50<17:53:50, 67.05s/it, lr=0.00025, test_MAE=0.65, time=67.4, train_MAE=0.555, train_loss=0.555, val_MAE=0.622, val_loss=0.622]Epoch 39:   4%|▍         | 39/1000 [44:57<17:53:50, 67.05s/it, lr=0.00025, test_MAE=0.652, time=67.1, train_MAE=0.542, train_loss=0.542, val_MAE=0.621, val_loss=0.621]Epoch 39:   4%|▍         | 40/1000 [44:57<17:52:49, 67.05s/it, lr=0.00025, test_MAE=0.652, time=67.1, train_MAE=0.542, train_loss=0.542, val_MAE=0.621, val_loss=0.621]Epoch 40:   4%|▍         | 40/1000 [44:57<17:52:49, 67.05s/it, lr=0.00025, test_MAE=0.652, time=67.1, train_MAE=0.542, train_loss=0.542, val_MAE=0.621, val_loss=0.621]Epoch 40:   4%|▍         | 40/1000 [46:03<17:52:49, 67.05s/it, lr=0.00025, test_MAE=0.658, time=66.5, train_MAE=0.546, train_loss=0.546, val_MAE=0.625, val_loss=0.625]Epoch 40:   4%|▍         | 41/1000 [46:04<17:49:09, 66.89s/it, lr=0.00025, test_MAE=0.658, time=66.5, train_MAE=0.546, train_loss=0.546, val_MAE=0.625, val_loss=0.625]Epoch 41:   4%|▍         | 41/1000 [46:04<17:49:09, 66.89s/it, lr=0.00025, test_MAE=0.658, time=66.5, train_MAE=0.546, train_loss=0.546, val_MAE=0.625, val_loss=0.625]Epoch 41:   4%|▍         | 41/1000 [47:09<17:49:09, 66.89s/it, lr=0.00025, test_MAE=0.679, time=66, train_MAE=0.545, train_loss=0.545, val_MAE=0.64, val_loss=0.64]    Epoch    42: reducing learning rate of group 0 to 1.2500e-04.
Epoch 41:   4%|▍         | 42/1000 [47:09<17:43:41, 66.62s/it, lr=0.00025, test_MAE=0.679, time=66, train_MAE=0.545, train_loss=0.545, val_MAE=0.64, val_loss=0.64]Epoch 42:   4%|▍         | 42/1000 [47:09<17:43:41, 66.62s/it, lr=0.00025, test_MAE=0.679, time=66, train_MAE=0.545, train_loss=0.545, val_MAE=0.64, val_loss=0.64]Epoch 42:   4%|▍         | 42/1000 [48:13<17:43:41, 66.62s/it, lr=0.000125, test_MAE=0.636, time=63.4, train_MAE=0.544, train_loss=0.544, val_MAE=0.616, val_loss=0.616]Epoch 42:   4%|▍         | 43/1000 [48:13<17:27:27, 65.67s/it, lr=0.000125, test_MAE=0.636, time=63.4, train_MAE=0.544, train_loss=0.544, val_MAE=0.616, val_loss=0.616]Epoch 43:   4%|▍         | 43/1000 [48:13<17:27:27, 65.67s/it, lr=0.000125, test_MAE=0.636, time=63.4, train_MAE=0.544, train_loss=0.544, val_MAE=0.616, val_loss=0.616]Epoch 43:   4%|▍         | 43/1000 [49:16<17:27:27, 65.67s/it, lr=0.000125, test_MAE=0.638, time=62.9, train_MAE=0.536, train_loss=0.536, val_MAE=0.613, val_loss=0.613]Epoch 43:   4%|▍         | 44/1000 [49:16<17:13:08, 64.84s/it, lr=0.000125, test_MAE=0.638, time=62.9, train_MAE=0.536, train_loss=0.536, val_MAE=0.613, val_loss=0.613]Epoch 44:   4%|▍         | 44/1000 [49:16<17:13:08, 64.84s/it, lr=0.000125, test_MAE=0.638, time=62.9, train_MAE=0.536, train_loss=0.536, val_MAE=0.613, val_loss=0.613]Epoch 44:   4%|▍         | 44/1000 [50:17<17:13:08, 64.84s/it, lr=0.000125, test_MAE=0.649, time=61.4, train_MAE=0.532, train_loss=0.532, val_MAE=0.615, val_loss=0.615]Epoch 44:   4%|▍         | 45/1000 [50:17<16:56:10, 63.84s/it, lr=0.000125, test_MAE=0.649, time=61.4, train_MAE=0.532, train_loss=0.532, val_MAE=0.615, val_loss=0.615]Epoch 45:   4%|▍         | 45/1000 [50:17<16:56:10, 63.84s/it, lr=0.000125, test_MAE=0.649, time=61.4, train_MAE=0.532, train_loss=0.532, val_MAE=0.615, val_loss=0.615]Epoch 45:   4%|▍         | 45/1000 [51:18<16:56:10, 63.84s/it, lr=0.000125, test_MAE=0.636, time=60.9, train_MAE=0.532, train_loss=0.532, val_MAE=0.614, val_loss=0.614]Epoch 45:   5%|▍         | 46/1000 [51:18<16:41:22, 62.98s/it, lr=0.000125, test_MAE=0.636, time=60.9, train_MAE=0.532, train_loss=0.532, val_MAE=0.614, val_loss=0.614]Epoch 46:   5%|▍         | 46/1000 [51:18<16:41:22, 62.98s/it, lr=0.000125, test_MAE=0.636, time=60.9, train_MAE=0.532, train_loss=0.532, val_MAE=0.614, val_loss=0.614]Epoch 46:   5%|▍         | 46/1000 [52:20<16:41:22, 62.98s/it, lr=0.000125, test_MAE=0.637, time=61.3, train_MAE=0.53, train_loss=0.53, val_MAE=0.614, val_loss=0.614]  Epoch 46:   5%|▍         | 47/1000 [52:20<16:32:17, 62.47s/it, lr=0.000125, test_MAE=0.637, time=61.3, train_MAE=0.53, train_loss=0.53, val_MAE=0.614, val_loss=0.614]Epoch 47:   5%|▍         | 47/1000 [52:20<16:32:17, 62.47s/it, lr=0.000125, test_MAE=0.637, time=61.3, train_MAE=0.53, train_loss=0.53, val_MAE=0.614, val_loss=0.614]Epoch 47:   5%|▍         | 47/1000 [53:21<16:32:17, 62.47s/it, lr=0.000125, test_MAE=0.638, time=61, train_MAE=0.54, train_loss=0.54, val_MAE=0.619, val_loss=0.619]  Epoch    48: reducing learning rate of group 0 to 6.2500e-05.
Epoch 47:   5%|▍         | 48/1000 [53:21<16:24:33, 62.05s/it, lr=0.000125, test_MAE=0.638, time=61, train_MAE=0.54, train_loss=0.54, val_MAE=0.619, val_loss=0.619]Epoch 48:   5%|▍         | 48/1000 [53:21<16:24:33, 62.05s/it, lr=0.000125, test_MAE=0.638, time=61, train_MAE=0.54, train_loss=0.54, val_MAE=0.619, val_loss=0.619]Epoch 48:   5%|▍         | 48/1000 [54:21<16:24:33, 62.05s/it, lr=6.25e-5, test_MAE=0.64, time=60.7, train_MAE=0.529, train_loss=0.529, val_MAE=0.615, val_loss=0.615]Epoch 48:   5%|▍         | 49/1000 [54:21<16:17:15, 61.66s/it, lr=6.25e-5, test_MAE=0.64, time=60.7, train_MAE=0.529, train_loss=0.529, val_MAE=0.615, val_loss=0.615]Epoch 49:   5%|▍         | 49/1000 [54:21<16:17:15, 61.66s/it, lr=6.25e-5, test_MAE=0.64, time=60.7, train_MAE=0.529, train_loss=0.529, val_MAE=0.615, val_loss=0.615]Epoch 49:   5%|▍         | 49/1000 [55:23<16:17:15, 61.66s/it, lr=6.25e-5, test_MAE=0.637, time=61.6, train_MAE=0.525, train_loss=0.525, val_MAE=0.609, val_loss=0.609]Epoch 49:   5%|▌         | 50/1000 [55:23<16:16:06, 61.65s/it, lr=6.25e-5, test_MAE=0.637, time=61.6, train_MAE=0.525, train_loss=0.525, val_MAE=0.609, val_loss=0.609]Epoch 50:   5%|▌         | 50/1000 [55:23<16:16:06, 61.65s/it, lr=6.25e-5, test_MAE=0.637, time=61.6, train_MAE=0.525, train_loss=0.525, val_MAE=0.609, val_loss=0.609]Epoch 50:   5%|▌         | 50/1000 [56:24<16:16:06, 61.65s/it, lr=6.25e-5, test_MAE=0.637, time=61, train_MAE=0.525, train_loss=0.525, val_MAE=0.612, val_loss=0.612]  Epoch 50:   5%|▌         | 51/1000 [56:24<16:12:21, 61.48s/it, lr=6.25e-5, test_MAE=0.637, time=61, train_MAE=0.525, train_loss=0.525, val_MAE=0.612, val_loss=0.612]Epoch 51:   5%|▌         | 51/1000 [56:24<16:12:21, 61.48s/it, lr=6.25e-5, test_MAE=0.637, time=61, train_MAE=0.525, train_loss=0.525, val_MAE=0.612, val_loss=0.612]Epoch 51:   5%|▌         | 51/1000 [57:24<16:12:21, 61.48s/it, lr=6.25e-5, test_MAE=0.638, time=60.3, train_MAE=0.522, train_loss=0.522, val_MAE=0.612, val_loss=0.612]Epoch 51:   5%|▌         | 52/1000 [57:24<16:05:46, 61.12s/it, lr=6.25e-5, test_MAE=0.638, time=60.3, train_MAE=0.522, train_loss=0.522, val_MAE=0.612, val_loss=0.612]Epoch 52:   5%|▌         | 52/1000 [57:24<16:05:46, 61.12s/it, lr=6.25e-5, test_MAE=0.638, time=60.3, train_MAE=0.522, train_loss=0.522, val_MAE=0.612, val_loss=0.612]Epoch 52:   5%|▌         | 52/1000 [58:25<16:05:46, 61.12s/it, lr=6.25e-5, test_MAE=0.639, time=60.6, train_MAE=0.519, train_loss=0.519, val_MAE=0.61, val_loss=0.61]  Epoch 52:   5%|▌         | 53/1000 [58:25<16:02:20, 60.97s/it, lr=6.25e-5, test_MAE=0.639, time=60.6, train_MAE=0.519, train_loss=0.519, val_MAE=0.61, val_loss=0.61]Epoch 53:   5%|▌         | 53/1000 [58:25<16:02:20, 60.97s/it, lr=6.25e-5, test_MAE=0.639, time=60.6, train_MAE=0.519, train_loss=0.519, val_MAE=0.61, val_loss=0.61]Epoch 53:   5%|▌         | 53/1000 [59:25<16:02:20, 60.97s/it, lr=6.25e-5, test_MAE=0.636, time=60.4, train_MAE=0.522, train_loss=0.522, val_MAE=0.612, val_loss=0.612]Epoch 53:   5%|▌         | 54/1000 [59:25<15:58:27, 60.79s/it, lr=6.25e-5, test_MAE=0.636, time=60.4, train_MAE=0.522, train_loss=0.522, val_MAE=0.612, val_loss=0.612]Epoch 54:   5%|▌         | 54/1000 [59:25<15:58:27, 60.79s/it, lr=6.25e-5, test_MAE=0.636, time=60.4, train_MAE=0.522, train_loss=0.522, val_MAE=0.612, val_loss=0.612]Epoch 54:   5%|▌         | 54/1000 [1:00:25<15:58:27, 60.79s/it, lr=6.25e-5, test_MAE=0.642, time=60.1, train_MAE=0.521, train_loss=0.521, val_MAE=0.61, val_loss=0.61]Epoch 54:   6%|▌         | 55/1000 [1:00:25<15:54:04, 60.58s/it, lr=6.25e-5, test_MAE=0.642, time=60.1, train_MAE=0.521, train_loss=0.521, val_MAE=0.61, val_loss=0.61]Epoch 55:   6%|▌         | 55/1000 [1:00:25<15:54:04, 60.58s/it, lr=6.25e-5, test_MAE=0.642, time=60.1, train_MAE=0.521, train_loss=0.521, val_MAE=0.61, val_loss=0.61]Epoch 55:   6%|▌         | 55/1000 [1:01:26<15:54:04, 60.58s/it, lr=6.25e-5, test_MAE=0.642, time=60.6, train_MAE=0.525, train_loss=0.525, val_MAE=0.614, val_loss=0.614]Epoch    56: reducing learning rate of group 0 to 3.1250e-05.
Epoch 55:   6%|▌         | 56/1000 [1:01:26<15:53:14, 60.59s/it, lr=6.25e-5, test_MAE=0.642, time=60.6, train_MAE=0.525, train_loss=0.525, val_MAE=0.614, val_loss=0.614]Epoch 56:   6%|▌         | 56/1000 [1:01:26<15:53:14, 60.59s/it, lr=6.25e-5, test_MAE=0.642, time=60.6, train_MAE=0.525, train_loss=0.525, val_MAE=0.614, val_loss=0.614]Epoch 56:   6%|▌         | 56/1000 [1:02:27<15:53:14, 60.59s/it, lr=3.13e-5, test_MAE=0.643, time=60.8, train_MAE=0.519, train_loss=0.519, val_MAE=0.614, val_loss=0.614]Epoch 56:   6%|▌         | 57/1000 [1:02:27<15:53:21, 60.66s/it, lr=3.13e-5, test_MAE=0.643, time=60.8, train_MAE=0.519, train_loss=0.519, val_MAE=0.614, val_loss=0.614]Epoch 57:   6%|▌         | 57/1000 [1:02:27<15:53:21, 60.66s/it, lr=3.13e-5, test_MAE=0.643, time=60.8, train_MAE=0.519, train_loss=0.519, val_MAE=0.614, val_loss=0.614]Epoch 57:   6%|▌         | 57/1000 [1:03:28<15:53:21, 60.66s/it, lr=3.13e-5, test_MAE=0.644, time=60.7, train_MAE=0.518, train_loss=0.518, val_MAE=0.614, val_loss=0.614]Epoch 57:   6%|▌         | 58/1000 [1:03:28<15:52:46, 60.69s/it, lr=3.13e-5, test_MAE=0.644, time=60.7, train_MAE=0.518, train_loss=0.518, val_MAE=0.614, val_loss=0.614]Epoch 58:   6%|▌         | 58/1000 [1:03:28<15:52:46, 60.69s/it, lr=3.13e-5, test_MAE=0.644, time=60.7, train_MAE=0.518, train_loss=0.518, val_MAE=0.614, val_loss=0.614]Epoch 58:   6%|▌         | 58/1000 [1:04:29<15:52:46, 60.69s/it, lr=3.13e-5, test_MAE=0.644, time=61.3, train_MAE=0.52, train_loss=0.52, val_MAE=0.616, val_loss=0.616]  Epoch 58:   6%|▌         | 59/1000 [1:04:29<15:54:38, 60.87s/it, lr=3.13e-5, test_MAE=0.644, time=61.3, train_MAE=0.52, train_loss=0.52, val_MAE=0.616, val_loss=0.616]Epoch 59:   6%|▌         | 59/1000 [1:04:29<15:54:38, 60.87s/it, lr=3.13e-5, test_MAE=0.644, time=61.3, train_MAE=0.52, train_loss=0.52, val_MAE=0.616, val_loss=0.616]Epoch 59:   6%|▌         | 59/1000 [1:05:30<15:54:38, 60.87s/it, lr=3.13e-5, test_MAE=0.639, time=61, train_MAE=0.518, train_loss=0.518, val_MAE=0.612, val_loss=0.612]Epoch 59:   6%|▌         | 60/1000 [1:05:30<15:54:09, 60.90s/it, lr=3.13e-5, test_MAE=0.639, time=61, train_MAE=0.518, train_loss=0.518, val_MAE=0.612, val_loss=0.612]Epoch 60:   6%|▌         | 60/1000 [1:05:30<15:54:09, 60.90s/it, lr=3.13e-5, test_MAE=0.639, time=61, train_MAE=0.518, train_loss=0.518, val_MAE=0.612, val_loss=0.612]Epoch 60:   6%|▌         | 60/1000 [1:06:31<15:54:09, 60.90s/it, lr=3.13e-5, test_MAE=0.65, time=61, train_MAE=0.528, train_loss=0.528, val_MAE=0.625, val_loss=0.625] Epoch 60:   6%|▌         | 61/1000 [1:06:31<15:53:33, 60.93s/it, lr=3.13e-5, test_MAE=0.65, time=61, train_MAE=0.528, train_loss=0.528, val_MAE=0.625, val_loss=0.625]Epoch 61:   6%|▌         | 61/1000 [1:06:31<15:53:33, 60.93s/it, lr=3.13e-5, test_MAE=0.65, time=61, train_MAE=0.528, train_loss=0.528, val_MAE=0.625, val_loss=0.625]Epoch 61:   6%|▌         | 61/1000 [1:07:32<15:53:33, 60.93s/it, lr=3.13e-5, test_MAE=0.641, time=61.3, train_MAE=0.514, train_loss=0.514, val_MAE=0.616, val_loss=0.616]Epoch    62: reducing learning rate of group 0 to 1.5625e-05.
Epoch 61:   6%|▌         | 62/1000 [1:07:32<15:54:09, 61.03s/it, lr=3.13e-5, test_MAE=0.641, time=61.3, train_MAE=0.514, train_loss=0.514, val_MAE=0.616, val_loss=0.616]Epoch 62:   6%|▌         | 62/1000 [1:07:32<15:54:09, 61.03s/it, lr=3.13e-5, test_MAE=0.641, time=61.3, train_MAE=0.514, train_loss=0.514, val_MAE=0.616, val_loss=0.616]Epoch 62:   6%|▌         | 62/1000 [1:08:33<15:54:09, 61.03s/it, lr=1.56e-5, test_MAE=0.64, time=61, train_MAE=0.515, train_loss=0.515, val_MAE=0.613, val_loss=0.613]   Epoch 62:   6%|▋         | 63/1000 [1:08:33<15:53:07, 61.03s/it, lr=1.56e-5, test_MAE=0.64, time=61, train_MAE=0.515, train_loss=0.515, val_MAE=0.613, val_loss=0.613]Epoch 63:   6%|▋         | 63/1000 [1:08:33<15:53:07, 61.03s/it, lr=1.56e-5, test_MAE=0.64, time=61, train_MAE=0.515, train_loss=0.515, val_MAE=0.613, val_loss=0.613]Epoch 63:   6%|▋         | 63/1000 [1:09:36<15:53:07, 61.03s/it, lr=1.56e-5, test_MAE=0.639, time=62.4, train_MAE=0.515, train_loss=0.515, val_MAE=0.612, val_loss=0.612]Epoch 63:   6%|▋         | 64/1000 [1:09:36<15:58:39, 61.45s/it, lr=1.56e-5, test_MAE=0.639, time=62.4, train_MAE=0.515, train_loss=0.515, val_MAE=0.612, val_loss=0.612]Epoch 64:   6%|▋         | 64/1000 [1:09:36<15:58:39, 61.45s/it, lr=1.56e-5, test_MAE=0.639, time=62.4, train_MAE=0.515, train_loss=0.515, val_MAE=0.612, val_loss=0.612]Epoch 64:   6%|▋         | 64/1000 [1:10:37<15:58:39, 61.45s/it, lr=1.56e-5, test_MAE=0.639, time=61.1, train_MAE=0.513, train_loss=0.513, val_MAE=0.613, val_loss=0.613]Epoch 64:   6%|▋         | 65/1000 [1:10:37<15:56:06, 61.36s/it, lr=1.56e-5, test_MAE=0.639, time=61.1, train_MAE=0.513, train_loss=0.513, val_MAE=0.613, val_loss=0.613]Epoch 65:   6%|▋         | 65/1000 [1:10:37<15:56:06, 61.36s/it, lr=1.56e-5, test_MAE=0.639, time=61.1, train_MAE=0.513, train_loss=0.513, val_MAE=0.613, val_loss=0.613]Epoch 65:   6%|▋         | 65/1000 [1:11:38<15:56:06, 61.36s/it, lr=1.56e-5, test_MAE=0.635, time=61.1, train_MAE=0.516, train_loss=0.516, val_MAE=0.613, val_loss=0.613]Epoch 65:   7%|▋         | 66/1000 [1:11:38<15:53:44, 61.27s/it, lr=1.56e-5, test_MAE=0.635, time=61.1, train_MAE=0.516, train_loss=0.516, val_MAE=0.613, val_loss=0.613]Epoch 66:   7%|▋         | 66/1000 [1:11:38<15:53:44, 61.27s/it, lr=1.56e-5, test_MAE=0.635, time=61.1, train_MAE=0.516, train_loss=0.516, val_MAE=0.613, val_loss=0.613]Epoch 66:   7%|▋         | 66/1000 [1:12:39<15:53:44, 61.27s/it, lr=1.56e-5, test_MAE=0.638, time=61.3, train_MAE=0.507, train_loss=0.507, val_MAE=0.615, val_loss=0.615]Epoch 66:   7%|▋         | 67/1000 [1:12:39<15:53:03, 61.29s/it, lr=1.56e-5, test_MAE=0.638, time=61.3, train_MAE=0.507, train_loss=0.507, val_MAE=0.615, val_loss=0.615]Epoch 67:   7%|▋         | 67/1000 [1:12:39<15:53:03, 61.29s/it, lr=1.56e-5, test_MAE=0.638, time=61.3, train_MAE=0.507, train_loss=0.507, val_MAE=0.615, val_loss=0.615]Epoch 67:   7%|▋         | 67/1000 [1:13:41<15:53:03, 61.29s/it, lr=1.56e-5, test_MAE=0.642, time=61.4, train_MAE=0.517, train_loss=0.517, val_MAE=0.613, val_loss=0.613]Epoch    68: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 67:   7%|▋         | 67/1000 [1:13:41<17:06:05, 65.99s/it, lr=1.56e-5, test_MAE=0.642, time=61.4, train_MAE=0.517, train_loss=0.517, val_MAE=0.613, val_loss=0.613]
Test MAE: 0.6419
Train MAE: 0.4926
Convergence Time (Epochs): 67.0000
TOTAL TIME TAKEN: 4460.2058s
AVG TIME PER EPOCH: 64.9948s
