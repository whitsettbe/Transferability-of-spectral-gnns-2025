I'm echoing to stdout
I'm echoing to stderr
My JobID is 58322127
I have 4 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.0240s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 16, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 4, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'poly_mlp', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_sub', 'num_eigs': 16, 'bias_mode': 'spatial', 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 0.0, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/aug07/zinc_train_rec.csv', 'test': 'supp_data/molecules/aug07/zinc_test_rec.csv', 'val': 'supp_data/molecules/aug07/zinc_val_rec.csv'}, 'fixMissingPhi1': False, 'extraOrtho': False, 'doublePrecision': True, 'eigval_hidden_dim': 100, 'eigval_num_hidden_layer': 3, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [06:18<?, ?it/s, lr=0.001, test_MAE=1.06, time=378, train_MAE=0.944, train_loss=0.944, val_MAE=1.03, val_loss=1.03]Epoch 0:   0%|          | 1/1000 [06:18<104:55:07, 378.09s/it, lr=0.001, test_MAE=1.06, time=378, train_MAE=0.944, train_loss=0.944, val_MAE=1.03, val_loss=1.03]Epoch 1:   0%|          | 1/1000 [06:18<104:55:07, 378.09s/it, lr=0.001, test_MAE=1.06, time=378, train_MAE=0.944, train_loss=0.944, val_MAE=1.03, val_loss=1.03]Epoch 1:   0%|          | 1/1000 [11:56<104:55:07, 378.09s/it, lr=0.001, test_MAE=0.948, time=338, train_MAE=0.702, train_loss=0.702, val_MAE=0.904, val_loss=0.904]Epoch 1:   0%|          | 2/1000 [11:56<101:30:56, 366.19s/it, lr=0.001, test_MAE=0.948, time=338, train_MAE=0.702, train_loss=0.702, val_MAE=0.904, val_loss=0.904]Epoch 2:   0%|          | 2/1000 [11:56<101:30:56, 366.19s/it, lr=0.001, test_MAE=0.948, time=338, train_MAE=0.702, train_loss=0.702, val_MAE=0.904, val_loss=0.904]Epoch 2:   0%|          | 2/1000 [17:34<101:30:56, 366.19s/it, lr=0.001, test_MAE=0.836, time=338, train_MAE=0.675, train_loss=0.675, val_MAE=0.784, val_loss=0.784]Epoch 2:   0%|          | 3/1000 [17:34<99:05:08, 357.78s/it, lr=0.001, test_MAE=0.836, time=338, train_MAE=0.675, train_loss=0.675, val_MAE=0.784, val_loss=0.784] Epoch 3:   0%|          | 3/1000 [17:34<99:05:08, 357.78s/it, lr=0.001, test_MAE=0.836, time=338, train_MAE=0.675, train_loss=0.675, val_MAE=0.784, val_loss=0.784]Epoch 3:   0%|          | 3/1000 [23:13<99:05:08, 357.78s/it, lr=0.001, test_MAE=0.717, time=339, train_MAE=0.635, train_loss=0.635, val_MAE=0.68, val_loss=0.68]  Epoch 3:   0%|          | 4/1000 [23:13<97:24:03, 352.05s/it, lr=0.001, test_MAE=0.717, time=339, train_MAE=0.635, train_loss=0.635, val_MAE=0.68, val_loss=0.68]Epoch 4:   0%|          | 4/1000 [23:13<97:24:03, 352.05s/it, lr=0.001, test_MAE=0.717, time=339, train_MAE=0.635, train_loss=0.635, val_MAE=0.68, val_loss=0.68]Epoch 4:   0%|          | 4/1000 [28:57<97:24:03, 352.05s/it, lr=0.001, test_MAE=0.905, time=344, train_MAE=0.635, train_loss=0.635, val_MAE=0.851, val_loss=0.851]Epoch 4:   0%|          | 5/1000 [28:57<96:36:44, 349.55s/it, lr=0.001, test_MAE=0.905, time=344, train_MAE=0.635, train_loss=0.635, val_MAE=0.851, val_loss=0.851]Epoch 5:   0%|          | 5/1000 [28:57<96:36:44, 349.55s/it, lr=0.001, test_MAE=0.905, time=344, train_MAE=0.635, train_loss=0.635, val_MAE=0.851, val_loss=0.851]Epoch 5:   0%|          | 5/1000 [34:42<96:36:44, 349.55s/it, lr=0.001, test_MAE=0.773, time=345, train_MAE=0.633, train_loss=0.633, val_MAE=0.712, val_loss=0.712]Epoch 5:   1%|          | 6/1000 [34:42<96:09:30, 348.26s/it, lr=0.001, test_MAE=0.773, time=345, train_MAE=0.633, train_loss=0.633, val_MAE=0.712, val_loss=0.712]Epoch 6:   1%|          | 6/1000 [34:42<96:09:30, 348.26s/it, lr=0.001, test_MAE=0.773, time=345, train_MAE=0.633, train_loss=0.633, val_MAE=0.712, val_loss=0.712]Epoch 6:   1%|          | 6/1000 [40:19<96:09:30, 348.26s/it, lr=0.001, test_MAE=0.795, time=337, train_MAE=0.625, train_loss=0.625, val_MAE=0.758, val_loss=0.758]Epoch 6:   1%|          | 7/1000 [40:19<95:08:18, 344.91s/it, lr=0.001, test_MAE=0.795, time=337, train_MAE=0.625, train_loss=0.625, val_MAE=0.758, val_loss=0.758]Epoch 7:   1%|          | 7/1000 [40:19<95:08:18, 344.91s/it, lr=0.001, test_MAE=0.795, time=337, train_MAE=0.625, train_loss=0.625, val_MAE=0.758, val_loss=0.758]Epoch 7:   1%|          | 7/1000 [45:56<95:08:18, 344.91s/it, lr=0.001, test_MAE=0.656, time=337, train_MAE=0.621, train_loss=0.621, val_MAE=0.633, val_loss=0.633]Epoch 7:   1%|          | 8/1000 [45:56<94:21:52, 342.45s/it, lr=0.001, test_MAE=0.656, time=337, train_MAE=0.621, train_loss=0.621, val_MAE=0.633, val_loss=0.633]Epoch 8:   1%|          | 8/1000 [45:56<94:21:52, 342.45s/it, lr=0.001, test_MAE=0.656, time=337, train_MAE=0.621, train_loss=0.621, val_MAE=0.633, val_loss=0.633]Epoch 8:   1%|          | 8/1000 [51:32<94:21:52, 342.45s/it, lr=0.001, test_MAE=0.789, time=336, train_MAE=0.61, train_loss=0.61, val_MAE=0.732, val_loss=0.732]  Epoch 8:   1%|          | 9/1000 [51:32<93:45:47, 340.61s/it, lr=0.001, test_MAE=0.789, time=336, train_MAE=0.61, train_loss=0.61, val_MAE=0.732, val_loss=0.732]Epoch 9:   1%|          | 9/1000 [51:32<93:45:47, 340.61s/it, lr=0.001, test_MAE=0.789, time=336, train_MAE=0.61, train_loss=0.61, val_MAE=0.732, val_loss=0.732]Epoch 9:   1%|          | 9/1000 [57:08<93:45:47, 340.61s/it, lr=0.001, test_MAE=0.657, time=336, train_MAE=0.605, train_loss=0.605, val_MAE=0.594, val_loss=0.594]Epoch 9:   1%|          | 10/1000 [57:08<93:18:48, 339.32s/it, lr=0.001, test_MAE=0.657, time=336, train_MAE=0.605, train_loss=0.605, val_MAE=0.594, val_loss=0.594]Epoch 10:   1%|          | 10/1000 [57:08<93:18:48, 339.32s/it, lr=0.001, test_MAE=0.657, time=336, train_MAE=0.605, train_loss=0.605, val_MAE=0.594, val_loss=0.594]Epoch 10:   1%|          | 10/1000 [1:02:45<93:18:48, 339.32s/it, lr=0.001, test_MAE=0.685, time=337, train_MAE=0.593, train_loss=0.593, val_MAE=0.63, val_loss=0.63]Epoch 10:   1%|          | 11/1000 [1:02:45<93:01:57, 338.64s/it, lr=0.001, test_MAE=0.685, time=337, train_MAE=0.593, train_loss=0.593, val_MAE=0.63, val_loss=0.63]Epoch 11:   1%|          | 11/1000 [1:02:45<93:01:57, 338.64s/it, lr=0.001, test_MAE=0.685, time=337, train_MAE=0.593, train_loss=0.593, val_MAE=0.63, val_loss=0.63]Epoch 11:   1%|          | 11/1000 [1:08:23<93:01:57, 338.64s/it, lr=0.001, test_MAE=1.17, time=337, train_MAE=0.588, train_loss=0.588, val_MAE=1.16, val_loss=1.16] Epoch 11:   1%|          | 12/1000 [1:08:23<92:49:35, 338.23s/it, lr=0.001, test_MAE=1.17, time=337, train_MAE=0.588, train_loss=0.588, val_MAE=1.16, val_loss=1.16]Epoch 12:   1%|          | 12/1000 [1:08:23<92:49:35, 338.23s/it, lr=0.001, test_MAE=1.17, time=337, train_MAE=0.588, train_loss=0.588, val_MAE=1.16, val_loss=1.16]Epoch 12:   1%|          | 12/1000 [1:14:01<92:49:35, 338.23s/it, lr=0.001, test_MAE=0.678, time=338, train_MAE=0.59, train_loss=0.59, val_MAE=0.625, val_loss=0.625]Epoch 12:   1%|▏         | 13/1000 [1:14:01<92:43:27, 338.20s/it, lr=0.001, test_MAE=0.678, time=338, train_MAE=0.59, train_loss=0.59, val_MAE=0.625, val_loss=0.625]Epoch 13:   1%|▏         | 13/1000 [1:14:01<92:43:27, 338.20s/it, lr=0.001, test_MAE=0.678, time=338, train_MAE=0.59, train_loss=0.59, val_MAE=0.625, val_loss=0.625]Epoch 13:   1%|▏         | 13/1000 [1:19:38<92:43:27, 338.20s/it, lr=0.001, test_MAE=0.63, time=338, train_MAE=0.585, train_loss=0.585, val_MAE=0.599, val_loss=0.599]Epoch 13:   1%|▏         | 14/1000 [1:19:38<92:35:11, 338.04s/it, lr=0.001, test_MAE=0.63, time=338, train_MAE=0.585, train_loss=0.585, val_MAE=0.599, val_loss=0.599]Epoch 14:   1%|▏         | 14/1000 [1:19:38<92:35:11, 338.04s/it, lr=0.001, test_MAE=0.63, time=338, train_MAE=0.585, train_loss=0.585, val_MAE=0.599, val_loss=0.599]Epoch 14:   1%|▏         | 14/1000 [1:25:16<92:35:11, 338.04s/it, lr=0.001, test_MAE=0.844, time=337, train_MAE=0.568, train_loss=0.568, val_MAE=0.786, val_loss=0.786]Epoch 14:   2%|▏         | 15/1000 [1:25:16<92:26:33, 337.86s/it, lr=0.001, test_MAE=0.844, time=337, train_MAE=0.568, train_loss=0.568, val_MAE=0.786, val_loss=0.786]Epoch 15:   2%|▏         | 15/1000 [1:25:16<92:26:33, 337.86s/it, lr=0.001, test_MAE=0.844, time=337, train_MAE=0.568, train_loss=0.568, val_MAE=0.786, val_loss=0.786]Epoch 15:   2%|▏         | 15/1000 [1:30:54<92:26:33, 337.86s/it, lr=0.001, test_MAE=0.62, time=338, train_MAE=0.572, train_loss=0.572, val_MAE=0.587, val_loss=0.587] Epoch 15:   2%|▏         | 16/1000 [1:30:54<92:20:38, 337.84s/it, lr=0.001, test_MAE=0.62, time=338, train_MAE=0.572, train_loss=0.572, val_MAE=0.587, val_loss=0.587]Epoch 16:   2%|▏         | 16/1000 [1:30:54<92:20:38, 337.84s/it, lr=0.001, test_MAE=0.62, time=338, train_MAE=0.572, train_loss=0.572, val_MAE=0.587, val_loss=0.587]Epoch 16:   2%|▏         | 16/1000 [1:36:41<92:20:38, 337.84s/it, lr=0.001, test_MAE=0.656, time=347, train_MAE=0.557, train_loss=0.557, val_MAE=0.616, val_loss=0.616]Epoch 16:   2%|▏         | 17/1000 [1:36:41<93:01:05, 340.66s/it, lr=0.001, test_MAE=0.656, time=347, train_MAE=0.557, train_loss=0.557, val_MAE=0.616, val_loss=0.616]Epoch 17:   2%|▏         | 17/1000 [1:36:41<93:01:05, 340.66s/it, lr=0.001, test_MAE=0.656, time=347, train_MAE=0.557, train_loss=0.557, val_MAE=0.616, val_loss=0.616]Epoch 17:   2%|▏         | 17/1000 [1:42:23<93:01:05, 340.66s/it, lr=0.001, test_MAE=0.628, time=342, train_MAE=0.563, train_loss=0.563, val_MAE=0.582, val_loss=0.582]Epoch 17:   2%|▏         | 18/1000 [1:42:23<93:01:16, 341.02s/it, lr=0.001, test_MAE=0.628, time=342, train_MAE=0.563, train_loss=0.563, val_MAE=0.582, val_loss=0.582]Epoch 18:   2%|▏         | 18/1000 [1:42:23<93:01:16, 341.02s/it, lr=0.001, test_MAE=0.628, time=342, train_MAE=0.563, train_loss=0.563, val_MAE=0.582, val_loss=0.582]Epoch 18:   2%|▏         | 18/1000 [1:48:00<93:01:16, 341.02s/it, lr=0.001, test_MAE=0.875, time=337, train_MAE=0.55, train_loss=0.55, val_MAE=0.811, val_loss=0.811]  Epoch 18:   2%|▏         | 19/1000 [1:48:00<92:35:20, 339.78s/it, lr=0.001, test_MAE=0.875, time=337, train_MAE=0.55, train_loss=0.55, val_MAE=0.811, val_loss=0.811]Epoch 19:   2%|▏         | 19/1000 [1:48:00<92:35:20, 339.78s/it, lr=0.001, test_MAE=0.875, time=337, train_MAE=0.55, train_loss=0.55, val_MAE=0.811, val_loss=0.811]Epoch 19:   2%|▏         | 19/1000 [1:53:37<92:35:20, 339.78s/it, lr=0.001, test_MAE=0.822, time=337, train_MAE=0.551, train_loss=0.551, val_MAE=0.764, val_loss=0.764]Epoch 19:   2%|▏         | 20/1000 [1:53:37<92:15:42, 338.92s/it, lr=0.001, test_MAE=0.822, time=337, train_MAE=0.551, train_loss=0.551, val_MAE=0.764, val_loss=0.764]Epoch 20:   2%|▏         | 20/1000 [1:53:37<92:15:42, 338.92s/it, lr=0.001, test_MAE=0.822, time=337, train_MAE=0.551, train_loss=0.551, val_MAE=0.764, val_loss=0.764]Epoch 20:   2%|▏         | 20/1000 [1:59:13<92:15:42, 338.92s/it, lr=0.001, test_MAE=0.679, time=336, train_MAE=0.55, train_loss=0.55, val_MAE=0.627, val_loss=0.627]  Epoch 20:   2%|▏         | 21/1000 [1:59:13<91:57:48, 338.17s/it, lr=0.001, test_MAE=0.679, time=336, train_MAE=0.55, train_loss=0.55, val_MAE=0.627, val_loss=0.627]Epoch 21:   2%|▏         | 21/1000 [1:59:13<91:57:48, 338.17s/it, lr=0.001, test_MAE=0.679, time=336, train_MAE=0.55, train_loss=0.55, val_MAE=0.627, val_loss=0.627]Epoch 21:   2%|▏         | 21/1000 [2:04:50<91:57:48, 338.17s/it, lr=0.001, test_MAE=0.778, time=337, train_MAE=0.549, train_loss=0.549, val_MAE=0.754, val_loss=0.754]Epoch 21:   2%|▏         | 22/1000 [2:04:50<91:45:02, 337.73s/it, lr=0.001, test_MAE=0.778, time=337, train_MAE=0.549, train_loss=0.549, val_MAE=0.754, val_loss=0.754]Epoch 22:   2%|▏         | 22/1000 [2:04:50<91:45:02, 337.73s/it, lr=0.001, test_MAE=0.778, time=337, train_MAE=0.549, train_loss=0.549, val_MAE=0.754, val_loss=0.754]Epoch 22:   2%|▏         | 22/1000 [2:10:26<91:45:02, 337.73s/it, lr=0.001, test_MAE=0.658, time=337, train_MAE=0.553, train_loss=0.553, val_MAE=0.618, val_loss=0.618]Epoch 22:   2%|▏         | 23/1000 [2:10:27<91:35:08, 337.47s/it, lr=0.001, test_MAE=0.658, time=337, train_MAE=0.553, train_loss=0.553, val_MAE=0.618, val_loss=0.618]Epoch 23:   2%|▏         | 23/1000 [2:10:27<91:35:08, 337.47s/it, lr=0.001, test_MAE=0.658, time=337, train_MAE=0.553, train_loss=0.553, val_MAE=0.618, val_loss=0.618]Epoch 23:   2%|▏         | 23/1000 [2:16:06<91:35:08, 337.47s/it, lr=0.001, test_MAE=0.634, time=340, train_MAE=0.536, train_loss=0.536, val_MAE=0.584, val_loss=0.584]Epoch    24: reducing learning rate of group 0 to 5.0000e-04.
Epoch 23:   2%|▏         | 24/1000 [2:16:06<91:41:08, 338.19s/it, lr=0.001, test_MAE=0.634, time=340, train_MAE=0.536, train_loss=0.536, val_MAE=0.584, val_loss=0.584]Epoch 24:   2%|▏         | 24/1000 [2:16:06<91:41:08, 338.19s/it, lr=0.001, test_MAE=0.634, time=340, train_MAE=0.536, train_loss=0.536, val_MAE=0.584, val_loss=0.584]Epoch 24:   2%|▏         | 24/1000 [2:21:45<91:41:08, 338.19s/it, lr=0.0005, test_MAE=0.687, time=339, train_MAE=0.516, train_loss=0.516, val_MAE=0.656, val_loss=0.656]Epoch 24:   2%|▎         | 25/1000 [2:21:45<91:38:44, 338.38s/it, lr=0.0005, test_MAE=0.687, time=339, train_MAE=0.516, train_loss=0.516, val_MAE=0.656, val_loss=0.656]Epoch 25:   2%|▎         | 25/1000 [2:21:45<91:38:44, 338.38s/it, lr=0.0005, test_MAE=0.687, time=339, train_MAE=0.516, train_loss=0.516, val_MAE=0.656, val_loss=0.656]Epoch 25:   2%|▎         | 25/1000 [2:27:24<91:38:44, 338.38s/it, lr=0.0005, test_MAE=0.636, time=338, train_MAE=0.5, train_loss=0.5, val_MAE=0.585, val_loss=0.585]    Epoch 25:   3%|▎         | 26/1000 [2:27:24<91:33:29, 338.41s/it, lr=0.0005, test_MAE=0.636, time=338, train_MAE=0.5, train_loss=0.5, val_MAE=0.585, val_loss=0.585]Epoch 26:   3%|▎         | 26/1000 [2:27:24<91:33:29, 338.41s/it, lr=0.0005, test_MAE=0.636, time=338, train_MAE=0.5, train_loss=0.5, val_MAE=0.585, val_loss=0.585]Epoch 26:   3%|▎         | 26/1000 [2:33:03<91:33:29, 338.41s/it, lr=0.0005, test_MAE=0.625, time=339, train_MAE=0.504, train_loss=0.504, val_MAE=0.584, val_loss=0.584]Epoch 26:   3%|▎         | 27/1000 [2:33:03<91:30:44, 338.59s/it, lr=0.0005, test_MAE=0.625, time=339, train_MAE=0.504, train_loss=0.504, val_MAE=0.584, val_loss=0.584]Epoch 27:   3%|▎         | 27/1000 [2:33:03<91:30:44, 338.59s/it, lr=0.0005, test_MAE=0.625, time=339, train_MAE=0.504, train_loss=0.504, val_MAE=0.584, val_loss=0.584]Epoch 27:   3%|▎         | 27/1000 [2:38:42<91:30:44, 338.59s/it, lr=0.0005, test_MAE=0.683, time=339, train_MAE=0.495, train_loss=0.495, val_MAE=0.647, val_loss=0.647]Epoch 27:   3%|▎         | 28/1000 [2:38:42<91:28:40, 338.81s/it, lr=0.0005, test_MAE=0.683, time=339, train_MAE=0.495, train_loss=0.495, val_MAE=0.647, val_loss=0.647]Epoch 28:   3%|▎         | 28/1000 [2:38:42<91:28:40, 338.81s/it, lr=0.0005, test_MAE=0.683, time=339, train_MAE=0.495, train_loss=0.495, val_MAE=0.647, val_loss=0.647]Epoch 28:   3%|▎         | 28/1000 [2:44:21<91:28:40, 338.81s/it, lr=0.0005, test_MAE=0.621, time=339, train_MAE=0.511, train_loss=0.511, val_MAE=0.569, val_loss=0.569]Epoch 28:   3%|▎         | 29/1000 [2:44:21<91:23:33, 338.84s/it, lr=0.0005, test_MAE=0.621, time=339, train_MAE=0.511, train_loss=0.511, val_MAE=0.569, val_loss=0.569]Epoch 29:   3%|▎         | 29/1000 [2:44:21<91:23:33, 338.84s/it, lr=0.0005, test_MAE=0.621, time=339, train_MAE=0.511, train_loss=0.511, val_MAE=0.569, val_loss=0.569]Epoch 29:   3%|▎         | 29/1000 [2:50:00<91:23:33, 338.84s/it, lr=0.0005, test_MAE=0.716, time=339, train_MAE=0.493, train_loss=0.493, val_MAE=0.67, val_loss=0.67]  Epoch 29:   3%|▎         | 30/1000 [2:50:00<91:18:22, 338.87s/it, lr=0.0005, test_MAE=0.716, time=339, train_MAE=0.493, train_loss=0.493, val_MAE=0.67, val_loss=0.67]Epoch 30:   3%|▎         | 30/1000 [2:50:00<91:18:22, 338.87s/it, lr=0.0005, test_MAE=0.716, time=339, train_MAE=0.493, train_loss=0.493, val_MAE=0.67, val_loss=0.67]Epoch 30:   3%|▎         | 30/1000 [2:55:39<91:18:22, 338.87s/it, lr=0.0005, test_MAE=0.625, time=339, train_MAE=0.497, train_loss=0.497, val_MAE=0.6, val_loss=0.6]  Epoch 30:   3%|▎         | 31/1000 [2:55:39<91:12:27, 338.85s/it, lr=0.0005, test_MAE=0.625, time=339, train_MAE=0.497, train_loss=0.497, val_MAE=0.6, val_loss=0.6]Epoch 31:   3%|▎         | 31/1000 [2:55:39<91:12:27, 338.85s/it, lr=0.0005, test_MAE=0.625, time=339, train_MAE=0.497, train_loss=0.497, val_MAE=0.6, val_loss=0.6]Epoch 31:   3%|▎         | 31/1000 [3:01:18<91:12:27, 338.85s/it, lr=0.0005, test_MAE=0.659, time=339, train_MAE=0.492, train_loss=0.492, val_MAE=0.609, val_loss=0.609]Epoch 31:   3%|▎         | 32/1000 [3:01:18<91:06:59, 338.86s/it, lr=0.0005, test_MAE=0.659, time=339, train_MAE=0.492, train_loss=0.492, val_MAE=0.609, val_loss=0.609]Epoch 32:   3%|▎         | 32/1000 [3:01:18<91:06:59, 338.86s/it, lr=0.0005, test_MAE=0.659, time=339, train_MAE=0.492, train_loss=0.492, val_MAE=0.609, val_loss=0.609]Epoch 32:   3%|▎         | 32/1000 [3:06:56<91:06:59, 338.86s/it, lr=0.0005, test_MAE=0.66, time=339, train_MAE=0.489, train_loss=0.489, val_MAE=0.593, val_loss=0.593] Epoch 32:   3%|▎         | 33/1000 [3:06:56<91:01:04, 338.85s/it, lr=0.0005, test_MAE=0.66, time=339, train_MAE=0.489, train_loss=0.489, val_MAE=0.593, val_loss=0.593]Epoch 33:   3%|▎         | 33/1000 [3:06:56<91:01:04, 338.85s/it, lr=0.0005, test_MAE=0.66, time=339, train_MAE=0.489, train_loss=0.489, val_MAE=0.593, val_loss=0.593]Epoch 33:   3%|▎         | 33/1000 [3:12:33<91:01:04, 338.85s/it, lr=0.0005, test_MAE=0.622, time=337, train_MAE=0.472, train_loss=0.472, val_MAE=0.58, val_loss=0.58] Epoch 33:   3%|▎         | 34/1000 [3:12:33<90:46:50, 338.31s/it, lr=0.0005, test_MAE=0.622, time=337, train_MAE=0.472, train_loss=0.472, val_MAE=0.58, val_loss=0.58]Epoch 34:   3%|▎         | 34/1000 [3:12:33<90:46:50, 338.31s/it, lr=0.0005, test_MAE=0.622, time=337, train_MAE=0.472, train_loss=0.472, val_MAE=0.58, val_loss=0.58]Epoch 34:   3%|▎         | 34/1000 [3:17:58<90:46:50, 338.31s/it, lr=0.0005, test_MAE=0.602, time=325, train_MAE=0.47, train_loss=0.47, val_MAE=0.565, val_loss=0.565]Epoch 34:   4%|▎         | 35/1000 [3:17:59<89:37:19, 334.34s/it, lr=0.0005, test_MAE=0.602, time=325, train_MAE=0.47, train_loss=0.47, val_MAE=0.565, val_loss=0.565]Epoch 35:   4%|▎         | 35/1000 [3:17:59<89:37:19, 334.34s/it, lr=0.0005, test_MAE=0.602, time=325, train_MAE=0.47, train_loss=0.47, val_MAE=0.565, val_loss=0.565]Epoch 35:   4%|▎         | 35/1000 [3:23:14<89:37:19, 334.34s/it, lr=0.0005, test_MAE=1.01, time=315, train_MAE=0.467, train_loss=0.467, val_MAE=0.949, val_loss=0.949]Epoch 35:   4%|▎         | 36/1000 [3:23:14<88:00:06, 328.64s/it, lr=0.0005, test_MAE=1.01, time=315, train_MAE=0.467, train_loss=0.467, val_MAE=0.949, val_loss=0.949]Epoch 36:   4%|▎         | 36/1000 [3:23:14<88:00:06, 328.64s/it, lr=0.0005, test_MAE=1.01, time=315, train_MAE=0.467, train_loss=0.467, val_MAE=0.949, val_loss=0.949]Epoch 36:   4%|▎         | 36/1000 [3:28:27<88:00:06, 328.64s/it, lr=0.0005, test_MAE=0.755, time=313, train_MAE=0.468, train_loss=0.468, val_MAE=0.698, val_loss=0.698]Epoch 36:   4%|▎         | 37/1000 [3:28:27<86:38:44, 323.91s/it, lr=0.0005, test_MAE=0.755, time=313, train_MAE=0.468, train_loss=0.468, val_MAE=0.698, val_loss=0.698]Epoch 37:   4%|▎         | 37/1000 [3:28:27<86:38:44, 323.91s/it, lr=0.0005, test_MAE=0.755, time=313, train_MAE=0.468, train_loss=0.468, val_MAE=0.698, val_loss=0.698]Epoch 37:   4%|▎         | 37/1000 [3:33:40<86:38:44, 323.91s/it, lr=0.0005, test_MAE=0.664, time=313, train_MAE=0.465, train_loss=0.465, val_MAE=0.611, val_loss=0.611]Epoch 37:   4%|▍         | 38/1000 [3:33:40<85:42:00, 320.71s/it, lr=0.0005, test_MAE=0.664, time=313, train_MAE=0.465, train_loss=0.465, val_MAE=0.611, val_loss=0.611]Epoch 38:   4%|▍         | 38/1000 [3:33:40<85:42:00, 320.71s/it, lr=0.0005, test_MAE=0.664, time=313, train_MAE=0.465, train_loss=0.465, val_MAE=0.611, val_loss=0.611]Epoch 38:   4%|▍         | 38/1000 [3:38:53<85:42:00, 320.71s/it, lr=0.0005, test_MAE=0.701, time=313, train_MAE=0.463, train_loss=0.463, val_MAE=0.648, val_loss=0.648]Epoch 38:   4%|▍         | 39/1000 [3:38:53<85:01:30, 318.51s/it, lr=0.0005, test_MAE=0.701, time=313, train_MAE=0.463, train_loss=0.463, val_MAE=0.648, val_loss=0.648]Epoch 39:   4%|▍         | 39/1000 [3:38:53<85:01:30, 318.51s/it, lr=0.0005, test_MAE=0.701, time=313, train_MAE=0.463, train_loss=0.463, val_MAE=0.648, val_loss=0.648]Epoch 39:   4%|▍         | 39/1000 [3:44:06<85:01:30, 318.51s/it, lr=0.0005, test_MAE=0.644, time=313, train_MAE=0.453, train_loss=0.453, val_MAE=0.578, val_loss=0.578]Epoch 39:   4%|▍         | 40/1000 [3:44:06<84:30:15, 316.89s/it, lr=0.0005, test_MAE=0.644, time=313, train_MAE=0.453, train_loss=0.453, val_MAE=0.578, val_loss=0.578]Epoch 40:   4%|▍         | 40/1000 [3:44:06<84:30:15, 316.89s/it, lr=0.0005, test_MAE=0.644, time=313, train_MAE=0.453, train_loss=0.453, val_MAE=0.578, val_loss=0.578]Epoch 40:   4%|▍         | 40/1000 [3:49:20<84:30:15, 316.89s/it, lr=0.0005, test_MAE=0.637, time=313, train_MAE=0.466, train_loss=0.466, val_MAE=0.599, val_loss=0.599]Epoch    41: reducing learning rate of group 0 to 2.5000e-04.
Epoch 40:   4%|▍         | 41/1000 [3:49:20<84:06:50, 315.76s/it, lr=0.0005, test_MAE=0.637, time=313, train_MAE=0.466, train_loss=0.466, val_MAE=0.599, val_loss=0.599]Epoch 41:   4%|▍         | 41/1000 [3:49:20<84:06:50, 315.76s/it, lr=0.0005, test_MAE=0.637, time=313, train_MAE=0.466, train_loss=0.466, val_MAE=0.599, val_loss=0.599]Epoch 41:   4%|▍         | 41/1000 [3:54:33<84:06:50, 315.76s/it, lr=0.00025, test_MAE=0.609, time=313, train_MAE=0.441, train_loss=0.441, val_MAE=0.567, val_loss=0.567]Epoch 41:   4%|▍         | 42/1000 [3:54:33<83:50:10, 315.04s/it, lr=0.00025, test_MAE=0.609, time=313, train_MAE=0.441, train_loss=0.441, val_MAE=0.567, val_loss=0.567]Epoch 42:   4%|▍         | 42/1000 [3:54:33<83:50:10, 315.04s/it, lr=0.00025, test_MAE=0.609, time=313, train_MAE=0.441, train_loss=0.441, val_MAE=0.567, val_loss=0.567]Epoch 42:   4%|▍         | 42/1000 [3:59:46<83:50:10, 315.04s/it, lr=0.00025, test_MAE=0.612, time=313, train_MAE=0.418, train_loss=0.418, val_MAE=0.576, val_loss=0.576]Epoch 42:   4%|▍         | 43/1000 [3:59:46<83:35:35, 314.46s/it, lr=0.00025, test_MAE=0.612, time=313, train_MAE=0.418, train_loss=0.418, val_MAE=0.576, val_loss=0.576]Epoch 43:   4%|▍         | 43/1000 [3:59:46<83:35:35, 314.46s/it, lr=0.00025, test_MAE=0.612, time=313, train_MAE=0.418, train_loss=0.418, val_MAE=0.576, val_loss=0.576]Epoch 43:   4%|▍         | 43/1000 [4:04:59<83:35:35, 314.46s/it, lr=0.00025, test_MAE=0.61, time=313, train_MAE=0.424, train_loss=0.424, val_MAE=0.574, val_loss=0.574] Epoch 43:   4%|▍         | 44/1000 [4:04:59<83:24:08, 314.07s/it, lr=0.00025, test_MAE=0.61, time=313, train_MAE=0.424, train_loss=0.424, val_MAE=0.574, val_loss=0.574]Epoch 44:   4%|▍         | 44/1000 [4:04:59<83:24:08, 314.07s/it, lr=0.00025, test_MAE=0.61, time=313, train_MAE=0.424, train_loss=0.424, val_MAE=0.574, val_loss=0.574]Epoch 44:   4%|▍         | 44/1000 [4:10:12<83:24:08, 314.07s/it, lr=0.00025, test_MAE=0.606, time=313, train_MAE=0.417, train_loss=0.417, val_MAE=0.568, val_loss=0.568]Epoch 44:   4%|▍         | 45/1000 [4:10:12<83:15:04, 313.83s/it, lr=0.00025, test_MAE=0.606, time=313, train_MAE=0.417, train_loss=0.417, val_MAE=0.568, val_loss=0.568]Epoch 45:   4%|▍         | 45/1000 [4:10:12<83:15:04, 313.83s/it, lr=0.00025, test_MAE=0.606, time=313, train_MAE=0.417, train_loss=0.417, val_MAE=0.568, val_loss=0.568]Epoch 45:   4%|▍         | 45/1000 [4:15:26<83:15:04, 313.83s/it, lr=0.00025, test_MAE=0.608, time=313, train_MAE=0.414, train_loss=0.414, val_MAE=0.577, val_loss=0.577]Epoch 45:   5%|▍         | 46/1000 [4:15:26<83:06:18, 313.60s/it, lr=0.00025, test_MAE=0.608, time=313, train_MAE=0.414, train_loss=0.414, val_MAE=0.577, val_loss=0.577]Epoch 46:   5%|▍         | 46/1000 [4:15:26<83:06:18, 313.60s/it, lr=0.00025, test_MAE=0.608, time=313, train_MAE=0.414, train_loss=0.414, val_MAE=0.577, val_loss=0.577]Epoch 46:   5%|▍         | 46/1000 [4:20:39<83:06:18, 313.60s/it, lr=0.00025, test_MAE=0.76, time=313, train_MAE=0.406, train_loss=0.406, val_MAE=0.712, val_loss=0.712] Epoch    47: reducing learning rate of group 0 to 1.2500e-04.
Epoch 46:   5%|▍         | 47/1000 [4:20:39<82:58:41, 313.45s/it, lr=0.00025, test_MAE=0.76, time=313, train_MAE=0.406, train_loss=0.406, val_MAE=0.712, val_loss=0.712]Epoch 47:   5%|▍         | 47/1000 [4:20:39<82:58:41, 313.45s/it, lr=0.00025, test_MAE=0.76, time=313, train_MAE=0.406, train_loss=0.406, val_MAE=0.712, val_loss=0.712]Epoch 47:   5%|▍         | 47/1000 [4:25:52<82:58:41, 313.45s/it, lr=0.000125, test_MAE=0.615, time=313, train_MAE=0.398, train_loss=0.398, val_MAE=0.578, val_loss=0.578]Epoch 47:   5%|▍         | 48/1000 [4:25:52<82:53:38, 313.47s/it, lr=0.000125, test_MAE=0.615, time=313, train_MAE=0.398, train_loss=0.398, val_MAE=0.578, val_loss=0.578]Epoch 48:   5%|▍         | 48/1000 [4:25:52<82:53:38, 313.47s/it, lr=0.000125, test_MAE=0.615, time=313, train_MAE=0.398, train_loss=0.398, val_MAE=0.578, val_loss=0.578]Epoch 48:   5%|▍         | 48/1000 [4:31:05<82:53:38, 313.47s/it, lr=0.000125, test_MAE=0.608, time=313, train_MAE=0.396, train_loss=0.396, val_MAE=0.575, val_loss=0.575]Epoch 48:   5%|▍         | 49/1000 [4:31:05<82:46:48, 313.36s/it, lr=0.000125, test_MAE=0.608, time=313, train_MAE=0.396, train_loss=0.396, val_MAE=0.575, val_loss=0.575]Epoch 49:   5%|▍         | 49/1000 [4:31:05<82:46:48, 313.36s/it, lr=0.000125, test_MAE=0.608, time=313, train_MAE=0.396, train_loss=0.396, val_MAE=0.575, val_loss=0.575]Epoch 49:   5%|▍         | 49/1000 [4:36:18<82:46:48, 313.36s/it, lr=0.000125, test_MAE=0.634, time=313, train_MAE=0.394, train_loss=0.394, val_MAE=0.585, val_loss=0.585]Epoch 49:   5%|▌         | 50/1000 [4:36:18<82:40:21, 313.29s/it, lr=0.000125, test_MAE=0.634, time=313, train_MAE=0.394, train_loss=0.394, val_MAE=0.585, val_loss=0.585]Epoch 50:   5%|▌         | 50/1000 [4:36:18<82:40:21, 313.29s/it, lr=0.000125, test_MAE=0.634, time=313, train_MAE=0.394, train_loss=0.394, val_MAE=0.585, val_loss=0.585]Epoch 50:   5%|▌         | 50/1000 [4:41:32<82:40:21, 313.29s/it, lr=0.000125, test_MAE=0.613, time=313, train_MAE=0.384, train_loss=0.384, val_MAE=0.568, val_loss=0.568]Epoch 50:   5%|▌         | 51/1000 [4:41:32<82:35:28, 313.31s/it, lr=0.000125, test_MAE=0.613, time=313, train_MAE=0.384, train_loss=0.384, val_MAE=0.568, val_loss=0.568]Epoch 51:   5%|▌         | 51/1000 [4:41:32<82:35:28, 313.31s/it, lr=0.000125, test_MAE=0.613, time=313, train_MAE=0.384, train_loss=0.384, val_MAE=0.568, val_loss=0.568]Epoch 51:   5%|▌         | 51/1000 [4:46:45<82:35:28, 313.31s/it, lr=0.000125, test_MAE=0.616, time=313, train_MAE=0.385, train_loss=0.385, val_MAE=0.584, val_loss=0.584]Epoch 51:   5%|▌         | 52/1000 [4:46:45<82:28:10, 313.18s/it, lr=0.000125, test_MAE=0.616, time=313, train_MAE=0.385, train_loss=0.385, val_MAE=0.584, val_loss=0.584]Epoch 52:   5%|▌         | 52/1000 [4:46:45<82:28:10, 313.18s/it, lr=0.000125, test_MAE=0.616, time=313, train_MAE=0.385, train_loss=0.385, val_MAE=0.584, val_loss=0.584]Epoch 52:   5%|▌         | 52/1000 [4:51:57<82:28:10, 313.18s/it, lr=0.000125, test_MAE=0.612, time=313, train_MAE=0.387, train_loss=0.387, val_MAE=0.579, val_loss=0.579]Epoch    53: reducing learning rate of group 0 to 6.2500e-05.
Epoch 52:   5%|▌         | 53/1000 [4:51:57<82:21:29, 313.08s/it, lr=0.000125, test_MAE=0.612, time=313, train_MAE=0.387, train_loss=0.387, val_MAE=0.579, val_loss=0.579]Epoch 53:   5%|▌         | 53/1000 [4:51:57<82:21:29, 313.08s/it, lr=0.000125, test_MAE=0.612, time=313, train_MAE=0.387, train_loss=0.387, val_MAE=0.579, val_loss=0.579]Epoch 53:   5%|▌         | 53/1000 [4:57:10<82:21:29, 313.08s/it, lr=6.25e-5, test_MAE=0.607, time=313, train_MAE=0.376, train_loss=0.376, val_MAE=0.568, val_loss=0.568] Epoch 53:   5%|▌         | 54/1000 [4:57:10<82:14:22, 312.96s/it, lr=6.25e-5, test_MAE=0.607, time=313, train_MAE=0.376, train_loss=0.376, val_MAE=0.568, val_loss=0.568]Epoch 54:   5%|▌         | 54/1000 [4:57:10<82:14:22, 312.96s/it, lr=6.25e-5, test_MAE=0.607, time=313, train_MAE=0.376, train_loss=0.376, val_MAE=0.568, val_loss=0.568]Epoch 54:   5%|▌         | 54/1000 [5:02:23<82:14:22, 312.96s/it, lr=6.25e-5, test_MAE=0.607, time=313, train_MAE=0.376, train_loss=0.376, val_MAE=0.571, val_loss=0.571]Epoch 54:   6%|▌         | 55/1000 [5:02:23<82:09:10, 312.96s/it, lr=6.25e-5, test_MAE=0.607, time=313, train_MAE=0.376, train_loss=0.376, val_MAE=0.571, val_loss=0.571]Epoch 55:   6%|▌         | 55/1000 [5:02:23<82:09:10, 312.96s/it, lr=6.25e-5, test_MAE=0.607, time=313, train_MAE=0.376, train_loss=0.376, val_MAE=0.571, val_loss=0.571]Epoch 55:   6%|▌         | 55/1000 [5:07:36<82:09:10, 312.96s/it, lr=6.25e-5, test_MAE=0.603, time=313, train_MAE=0.375, train_loss=0.375, val_MAE=0.564, val_loss=0.564]Epoch 55:   6%|▌         | 56/1000 [5:07:36<82:05:25, 313.06s/it, lr=6.25e-5, test_MAE=0.603, time=313, train_MAE=0.375, train_loss=0.375, val_MAE=0.564, val_loss=0.564]Epoch 56:   6%|▌         | 56/1000 [5:07:36<82:05:25, 313.06s/it, lr=6.25e-5, test_MAE=0.603, time=313, train_MAE=0.375, train_loss=0.375, val_MAE=0.564, val_loss=0.564]Epoch 56:   6%|▌         | 56/1000 [5:12:49<82:05:25, 313.06s/it, lr=6.25e-5, test_MAE=0.61, time=313, train_MAE=0.374, train_loss=0.374, val_MAE=0.568, val_loss=0.568] Epoch 56:   6%|▌         | 57/1000 [5:12:49<81:59:51, 313.03s/it, lr=6.25e-5, test_MAE=0.61, time=313, train_MAE=0.374, train_loss=0.374, val_MAE=0.568, val_loss=0.568]Epoch 57:   6%|▌         | 57/1000 [5:12:49<81:59:51, 313.03s/it, lr=6.25e-5, test_MAE=0.61, time=313, train_MAE=0.374, train_loss=0.374, val_MAE=0.568, val_loss=0.568]Epoch 57:   6%|▌         | 57/1000 [5:18:02<81:59:51, 313.03s/it, lr=6.25e-5, test_MAE=0.611, time=313, train_MAE=0.379, train_loss=0.379, val_MAE=0.582, val_loss=0.582]Epoch 57:   6%|▌         | 58/1000 [5:18:02<81:54:39, 313.04s/it, lr=6.25e-5, test_MAE=0.611, time=313, train_MAE=0.379, train_loss=0.379, val_MAE=0.582, val_loss=0.582]Epoch 58:   6%|▌         | 58/1000 [5:18:02<81:54:39, 313.04s/it, lr=6.25e-5, test_MAE=0.611, time=313, train_MAE=0.379, train_loss=0.379, val_MAE=0.582, val_loss=0.582]Epoch 58:   6%|▌         | 58/1000 [5:23:15<81:54:39, 313.04s/it, lr=6.25e-5, test_MAE=0.618, time=313, train_MAE=0.369, train_loss=0.369, val_MAE=0.579, val_loss=0.579]Epoch 58:   6%|▌         | 59/1000 [5:23:15<81:49:16, 313.02s/it, lr=6.25e-5, test_MAE=0.618, time=313, train_MAE=0.369, train_loss=0.369, val_MAE=0.579, val_loss=0.579]Epoch 59:   6%|▌         | 59/1000 [5:23:15<81:49:16, 313.02s/it, lr=6.25e-5, test_MAE=0.618, time=313, train_MAE=0.369, train_loss=0.369, val_MAE=0.579, val_loss=0.579]Epoch 59:   6%|▌         | 59/1000 [5:28:28<81:49:16, 313.02s/it, lr=6.25e-5, test_MAE=0.614, time=313, train_MAE=0.365, train_loss=0.365, val_MAE=0.585, val_loss=0.585]Epoch 59:   6%|▌         | 60/1000 [5:28:28<81:44:23, 313.05s/it, lr=6.25e-5, test_MAE=0.614, time=313, train_MAE=0.365, train_loss=0.365, val_MAE=0.585, val_loss=0.585]Epoch 60:   6%|▌         | 60/1000 [5:28:28<81:44:23, 313.05s/it, lr=6.25e-5, test_MAE=0.614, time=313, train_MAE=0.365, train_loss=0.365, val_MAE=0.585, val_loss=0.585]Epoch 60:   6%|▌         | 60/1000 [5:33:42<81:44:23, 313.05s/it, lr=6.25e-5, test_MAE=0.607, time=313, train_MAE=0.365, train_loss=0.365, val_MAE=0.577, val_loss=0.577]Epoch 60:   6%|▌         | 61/1000 [5:33:42<81:39:17, 313.05s/it, lr=6.25e-5, test_MAE=0.607, time=313, train_MAE=0.365, train_loss=0.365, val_MAE=0.577, val_loss=0.577]Epoch 61:   6%|▌         | 61/1000 [5:33:42<81:39:17, 313.05s/it, lr=6.25e-5, test_MAE=0.607, time=313, train_MAE=0.365, train_loss=0.365, val_MAE=0.577, val_loss=0.577]Epoch 61:   6%|▌         | 61/1000 [5:38:55<81:39:17, 313.05s/it, lr=6.25e-5, test_MAE=0.612, time=313, train_MAE=0.368, train_loss=0.368, val_MAE=0.581, val_loss=0.581]Epoch    62: reducing learning rate of group 0 to 3.1250e-05.
Epoch 61:   6%|▌         | 62/1000 [5:38:55<81:34:35, 313.09s/it, lr=6.25e-5, test_MAE=0.612, time=313, train_MAE=0.368, train_loss=0.368, val_MAE=0.581, val_loss=0.581]Epoch 62:   6%|▌         | 62/1000 [5:38:55<81:34:35, 313.09s/it, lr=6.25e-5, test_MAE=0.612, time=313, train_MAE=0.368, train_loss=0.368, val_MAE=0.581, val_loss=0.581]Epoch 62:   6%|▌         | 62/1000 [5:44:07<81:34:35, 313.09s/it, lr=3.13e-5, test_MAE=0.609, time=313, train_MAE=0.362, train_loss=0.362, val_MAE=0.573, val_loss=0.573]Epoch 62:   6%|▋         | 63/1000 [5:44:08<81:28:04, 313.00s/it, lr=3.13e-5, test_MAE=0.609, time=313, train_MAE=0.362, train_loss=0.362, val_MAE=0.573, val_loss=0.573]Epoch 63:   6%|▋         | 63/1000 [5:44:08<81:28:04, 313.00s/it, lr=3.13e-5, test_MAE=0.609, time=313, train_MAE=0.362, train_loss=0.362, val_MAE=0.573, val_loss=0.573]Epoch 63:   6%|▋         | 63/1000 [5:49:20<81:28:04, 313.00s/it, lr=3.13e-5, test_MAE=0.608, time=313, train_MAE=0.363, train_loss=0.363, val_MAE=0.571, val_loss=0.571]Epoch 63:   6%|▋         | 64/1000 [5:49:20<81:22:04, 312.95s/it, lr=3.13e-5, test_MAE=0.608, time=313, train_MAE=0.363, train_loss=0.363, val_MAE=0.571, val_loss=0.571]Epoch 64:   6%|▋         | 64/1000 [5:49:20<81:22:04, 312.95s/it, lr=3.13e-5, test_MAE=0.608, time=313, train_MAE=0.363, train_loss=0.363, val_MAE=0.571, val_loss=0.571]Epoch 64:   6%|▋         | 64/1000 [5:54:34<81:22:04, 312.95s/it, lr=3.13e-5, test_MAE=0.61, time=314, train_MAE=0.361, train_loss=0.361, val_MAE=0.574, val_loss=0.574] Epoch 64:   6%|▋         | 65/1000 [5:54:34<81:21:07, 313.23s/it, lr=3.13e-5, test_MAE=0.61, time=314, train_MAE=0.361, train_loss=0.361, val_MAE=0.574, val_loss=0.574]Epoch 65:   6%|▋         | 65/1000 [5:54:34<81:21:07, 313.23s/it, lr=3.13e-5, test_MAE=0.61, time=314, train_MAE=0.361, train_loss=0.361, val_MAE=0.574, val_loss=0.574]Epoch 65:   6%|▋         | 65/1000 [5:59:49<81:21:07, 313.23s/it, lr=3.13e-5, test_MAE=0.626, time=314, train_MAE=0.362, train_loss=0.362, val_MAE=0.591, val_loss=0.591]Epoch 65:   7%|▋         | 66/1000 [5:59:49<81:20:51, 313.55s/it, lr=3.13e-5, test_MAE=0.626, time=314, train_MAE=0.362, train_loss=0.362, val_MAE=0.591, val_loss=0.591]Epoch 66:   7%|▋         | 66/1000 [5:59:49<81:20:51, 313.55s/it, lr=3.13e-5, test_MAE=0.626, time=314, train_MAE=0.362, train_loss=0.362, val_MAE=0.591, val_loss=0.591]Epoch 66:   7%|▋         | 66/1000 [6:05:03<81:20:51, 313.55s/it, lr=3.13e-5, test_MAE=0.611, time=314, train_MAE=0.364, train_loss=0.364, val_MAE=0.575, val_loss=0.575]Epoch 66:   7%|▋         | 67/1000 [6:05:03<81:18:34, 313.73s/it, lr=3.13e-5, test_MAE=0.611, time=314, train_MAE=0.364, train_loss=0.364, val_MAE=0.575, val_loss=0.575]Epoch 67:   7%|▋         | 67/1000 [6:05:03<81:18:34, 313.73s/it, lr=3.13e-5, test_MAE=0.611, time=314, train_MAE=0.364, train_loss=0.364, val_MAE=0.575, val_loss=0.575]Epoch 67:   7%|▋         | 67/1000 [6:10:17<81:18:34, 313.73s/it, lr=3.13e-5, test_MAE=0.608, time=314, train_MAE=0.363, train_loss=0.363, val_MAE=0.574, val_loss=0.574]Epoch    68: reducing learning rate of group 0 to 1.5625e-05.
Epoch 67:   7%|▋         | 68/1000 [6:10:17<81:16:44, 313.95s/it, lr=3.13e-5, test_MAE=0.608, time=314, train_MAE=0.363, train_loss=0.363, val_MAE=0.574, val_loss=0.574]Epoch 68:   7%|▋         | 68/1000 [6:10:17<81:16:44, 313.95s/it, lr=3.13e-5, test_MAE=0.608, time=314, train_MAE=0.363, train_loss=0.363, val_MAE=0.574, val_loss=0.574]Epoch 68:   7%|▋         | 68/1000 [6:15:31<81:16:44, 313.95s/it, lr=1.56e-5, test_MAE=0.609, time=314, train_MAE=0.353, train_loss=0.353, val_MAE=0.575, val_loss=0.575]Epoch 68:   7%|▋         | 69/1000 [6:15:31<81:13:04, 314.05s/it, lr=1.56e-5, test_MAE=0.609, time=314, train_MAE=0.353, train_loss=0.353, val_MAE=0.575, val_loss=0.575]Epoch 69:   7%|▋         | 69/1000 [6:15:31<81:13:04, 314.05s/it, lr=1.56e-5, test_MAE=0.609, time=314, train_MAE=0.353, train_loss=0.353, val_MAE=0.575, val_loss=0.575]Epoch 69:   7%|▋         | 69/1000 [6:20:46<81:13:04, 314.05s/it, lr=1.56e-5, test_MAE=0.61, time=314, train_MAE=0.359, train_loss=0.359, val_MAE=0.576, val_loss=0.576] Epoch 69:   7%|▋         | 70/1000 [6:20:46<81:08:38, 314.11s/it, lr=1.56e-5, test_MAE=0.61, time=314, train_MAE=0.359, train_loss=0.359, val_MAE=0.576, val_loss=0.576]Epoch 70:   7%|▋         | 70/1000 [6:20:46<81:08:38, 314.11s/it, lr=1.56e-5, test_MAE=0.61, time=314, train_MAE=0.359, train_loss=0.359, val_MAE=0.576, val_loss=0.576]Epoch 70:   7%|▋         | 70/1000 [6:26:00<81:08:38, 314.11s/it, lr=1.56e-5, test_MAE=0.609, time=314, train_MAE=0.349, train_loss=0.349, val_MAE=0.576, val_loss=0.576]Epoch 70:   7%|▋         | 71/1000 [6:26:00<81:04:05, 314.15s/it, lr=1.56e-5, test_MAE=0.609, time=314, train_MAE=0.349, train_loss=0.349, val_MAE=0.576, val_loss=0.576]Epoch 71:   7%|▋         | 71/1000 [6:26:00<81:04:05, 314.15s/it, lr=1.56e-5, test_MAE=0.609, time=314, train_MAE=0.349, train_loss=0.349, val_MAE=0.576, val_loss=0.576]Epoch 71:   7%|▋         | 71/1000 [6:31:14<81:04:05, 314.15s/it, lr=1.56e-5, test_MAE=0.613, time=314, train_MAE=0.354, train_loss=0.354, val_MAE=0.577, val_loss=0.577]Epoch 71:   7%|▋         | 72/1000 [6:31:14<80:59:31, 314.19s/it, lr=1.56e-5, test_MAE=0.613, time=314, train_MAE=0.354, train_loss=0.354, val_MAE=0.577, val_loss=0.577]Epoch 72:   7%|▋         | 72/1000 [6:31:14<80:59:31, 314.19s/it, lr=1.56e-5, test_MAE=0.613, time=314, train_MAE=0.354, train_loss=0.354, val_MAE=0.577, val_loss=0.577]Epoch 72:   7%|▋         | 72/1000 [6:36:29<80:59:31, 314.19s/it, lr=1.56e-5, test_MAE=0.608, time=314, train_MAE=0.352, train_loss=0.352, val_MAE=0.572, val_loss=0.572]Epoch 72:   7%|▋         | 73/1000 [6:36:29<80:54:49, 314.23s/it, lr=1.56e-5, test_MAE=0.608, time=314, train_MAE=0.352, train_loss=0.352, val_MAE=0.572, val_loss=0.572]Epoch 73:   7%|▋         | 73/1000 [6:36:29<80:54:49, 314.23s/it, lr=1.56e-5, test_MAE=0.608, time=314, train_MAE=0.352, train_loss=0.352, val_MAE=0.572, val_loss=0.572]Epoch 73:   7%|▋         | 73/1000 [6:41:43<80:54:49, 314.23s/it, lr=1.56e-5, test_MAE=0.609, time=314, train_MAE=0.351, train_loss=0.351, val_MAE=0.574, val_loss=0.574]Epoch    74: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 73:   7%|▋         | 73/1000 [6:41:43<85:01:20, 330.18s/it, lr=1.56e-5, test_MAE=0.609, time=314, train_MAE=0.351, train_loss=0.351, val_MAE=0.574, val_loss=0.574]
Test MAE: 0.6094
Train MAE: 0.3154
Convergence Time (Epochs): 73.0000
TOTAL TIME TAKEN: 24279.5665s
AVG TIME PER EPOCH: 325.6939s
