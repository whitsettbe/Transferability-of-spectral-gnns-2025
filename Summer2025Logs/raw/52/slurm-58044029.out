I'm echoing to stdout
I'm echoing to stderr
My JobID is 58044029
I have 4 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.0599s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 2, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'poly_mlp', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_sub', 'num_eigs': 16, 'bias_mode': 'spatial', 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 0.0, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/aug07/zinc_train_rec.csv', 'test': 'supp_data/molecules/aug07/zinc_test_rec.csv', 'val': 'supp_data/molecules/aug07/zinc_val_rec.csv'}, 'fixMissingPhi1': False, 'extraOrtho': False, 'doublePrecision': True, 'eigval_hidden_dim': 100, 'eigval_num_hidden_layer': 0, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [01:24<?, ?it/s, lr=0.001, test_MAE=1.46, time=84.2, train_MAE=0.922, train_loss=0.922, val_MAE=1.4, val_loss=1.4]Epoch 0:   0%|          | 1/1000 [01:24<23:23:27, 84.29s/it, lr=0.001, test_MAE=1.46, time=84.2, train_MAE=0.922, train_loss=0.922, val_MAE=1.4, val_loss=1.4]Epoch 1:   0%|          | 1/1000 [01:24<23:23:27, 84.29s/it, lr=0.001, test_MAE=1.46, time=84.2, train_MAE=0.922, train_loss=0.922, val_MAE=1.4, val_loss=1.4]Epoch 1:   0%|          | 1/1000 [02:30<23:23:27, 84.29s/it, lr=0.001, test_MAE=0.845, time=66, train_MAE=0.684, train_loss=0.684, val_MAE=0.803, val_loss=0.803]Epoch 1:   0%|          | 2/1000 [02:30<21:51:14, 78.83s/it, lr=0.001, test_MAE=0.845, time=66, train_MAE=0.684, train_loss=0.684, val_MAE=0.803, val_loss=0.803]Epoch 2:   0%|          | 2/1000 [02:30<21:51:14, 78.83s/it, lr=0.001, test_MAE=0.845, time=66, train_MAE=0.684, train_loss=0.684, val_MAE=0.803, val_loss=0.803]Epoch 2:   0%|          | 2/1000 [03:36<21:51:14, 78.83s/it, lr=0.001, test_MAE=0.694, time=66, train_MAE=0.668, train_loss=0.668, val_MAE=0.663, val_loss=0.663]Epoch 2:   0%|          | 3/1000 [03:36<20:46:14, 75.00s/it, lr=0.001, test_MAE=0.694, time=66, train_MAE=0.668, train_loss=0.668, val_MAE=0.663, val_loss=0.663]Epoch 3:   0%|          | 3/1000 [03:36<20:46:14, 75.00s/it, lr=0.001, test_MAE=0.694, time=66, train_MAE=0.668, train_loss=0.668, val_MAE=0.663, val_loss=0.663]Epoch 3:   0%|          | 3/1000 [04:42<20:46:14, 75.00s/it, lr=0.001, test_MAE=0.729, time=66, train_MAE=0.668, train_loss=0.668, val_MAE=0.694, val_loss=0.694]Epoch 3:   0%|          | 4/1000 [04:42<20:00:03, 72.29s/it, lr=0.001, test_MAE=0.729, time=66, train_MAE=0.668, train_loss=0.668, val_MAE=0.694, val_loss=0.694]Epoch 4:   0%|          | 4/1000 [04:42<20:00:03, 72.29s/it, lr=0.001, test_MAE=0.729, time=66, train_MAE=0.668, train_loss=0.668, val_MAE=0.694, val_loss=0.694]Epoch 4:   0%|          | 4/1000 [05:48<20:00:03, 72.29s/it, lr=0.001, test_MAE=0.757, time=65.9, train_MAE=0.639, train_loss=0.639, val_MAE=0.709, val_loss=0.709]Epoch 4:   0%|          | 5/1000 [05:48<19:27:13, 70.39s/it, lr=0.001, test_MAE=0.757, time=65.9, train_MAE=0.639, train_loss=0.639, val_MAE=0.709, val_loss=0.709]Epoch 5:   0%|          | 5/1000 [05:48<19:27:13, 70.39s/it, lr=0.001, test_MAE=0.757, time=65.9, train_MAE=0.639, train_loss=0.639, val_MAE=0.709, val_loss=0.709]Epoch 5:   0%|          | 5/1000 [06:54<19:27:13, 70.39s/it, lr=0.001, test_MAE=0.701, time=65.9, train_MAE=0.637, train_loss=0.637, val_MAE=0.657, val_loss=0.657]Epoch 5:   1%|          | 6/1000 [06:54<19:04:03, 69.06s/it, lr=0.001, test_MAE=0.701, time=65.9, train_MAE=0.637, train_loss=0.637, val_MAE=0.657, val_loss=0.657]Epoch 6:   1%|          | 6/1000 [06:54<19:04:03, 69.06s/it, lr=0.001, test_MAE=0.701, time=65.9, train_MAE=0.637, train_loss=0.637, val_MAE=0.657, val_loss=0.657]Epoch 6:   1%|          | 6/1000 [08:00<19:04:03, 69.06s/it, lr=0.001, test_MAE=0.7, time=66.2, train_MAE=0.626, train_loss=0.626, val_MAE=0.656, val_loss=0.656]  Epoch 6:   1%|          | 7/1000 [08:00<18:48:42, 68.20s/it, lr=0.001, test_MAE=0.7, time=66.2, train_MAE=0.626, train_loss=0.626, val_MAE=0.656, val_loss=0.656]Epoch 7:   1%|          | 7/1000 [08:00<18:48:42, 68.20s/it, lr=0.001, test_MAE=0.7, time=66.2, train_MAE=0.626, train_loss=0.626, val_MAE=0.656, val_loss=0.656]Epoch 7:   1%|          | 7/1000 [09:06<18:48:42, 68.20s/it, lr=0.001, test_MAE=0.84, time=66, train_MAE=0.619, train_loss=0.619, val_MAE=0.808, val_loss=0.808] Epoch 7:   1%|          | 8/1000 [09:06<18:36:40, 67.54s/it, lr=0.001, test_MAE=0.84, time=66, train_MAE=0.619, train_loss=0.619, val_MAE=0.808, val_loss=0.808]Epoch 8:   1%|          | 8/1000 [09:06<18:36:40, 67.54s/it, lr=0.001, test_MAE=0.84, time=66, train_MAE=0.619, train_loss=0.619, val_MAE=0.808, val_loss=0.808]Epoch 8:   1%|          | 8/1000 [10:12<18:36:40, 67.54s/it, lr=0.001, test_MAE=0.896, time=65.9, train_MAE=0.621, train_loss=0.621, val_MAE=0.857, val_loss=0.857]Epoch 8:   1%|          | 9/1000 [10:12<18:27:37, 67.06s/it, lr=0.001, test_MAE=0.896, time=65.9, train_MAE=0.621, train_loss=0.621, val_MAE=0.857, val_loss=0.857]Epoch 9:   1%|          | 9/1000 [10:12<18:27:37, 67.06s/it, lr=0.001, test_MAE=0.896, time=65.9, train_MAE=0.621, train_loss=0.621, val_MAE=0.857, val_loss=0.857]Epoch 9:   1%|          | 9/1000 [11:18<18:27:37, 67.06s/it, lr=0.001, test_MAE=0.824, time=66.2, train_MAE=0.597, train_loss=0.597, val_MAE=0.788, val_loss=0.788]Epoch 9:   1%|          | 10/1000 [11:18<18:22:24, 66.81s/it, lr=0.001, test_MAE=0.824, time=66.2, train_MAE=0.597, train_loss=0.597, val_MAE=0.788, val_loss=0.788]Epoch 10:   1%|          | 10/1000 [11:18<18:22:24, 66.81s/it, lr=0.001, test_MAE=0.824, time=66.2, train_MAE=0.597, train_loss=0.597, val_MAE=0.788, val_loss=0.788]Epoch 10:   1%|          | 10/1000 [12:24<18:22:24, 66.81s/it, lr=0.001, test_MAE=0.707, time=65.9, train_MAE=0.611, train_loss=0.611, val_MAE=0.667, val_loss=0.667]Epoch 10:   1%|          | 11/1000 [12:24<18:16:52, 66.54s/it, lr=0.001, test_MAE=0.707, time=65.9, train_MAE=0.611, train_loss=0.611, val_MAE=0.667, val_loss=0.667]Epoch 11:   1%|          | 11/1000 [12:24<18:16:52, 66.54s/it, lr=0.001, test_MAE=0.707, time=65.9, train_MAE=0.611, train_loss=0.611, val_MAE=0.667, val_loss=0.667]Epoch 11:   1%|          | 11/1000 [13:30<18:16:52, 66.54s/it, lr=0.001, test_MAE=0.707, time=65.7, train_MAE=0.6, train_loss=0.6, val_MAE=0.667, val_loss=0.667]    Epoch 11:   1%|          | 12/1000 [13:30<18:11:27, 66.28s/it, lr=0.001, test_MAE=0.707, time=65.7, train_MAE=0.6, train_loss=0.6, val_MAE=0.667, val_loss=0.667]Epoch 12:   1%|          | 12/1000 [13:30<18:11:27, 66.28s/it, lr=0.001, test_MAE=0.707, time=65.7, train_MAE=0.6, train_loss=0.6, val_MAE=0.667, val_loss=0.667]Epoch 12:   1%|          | 12/1000 [14:36<18:11:27, 66.28s/it, lr=0.001, test_MAE=0.66, time=66.2, train_MAE=0.598, train_loss=0.598, val_MAE=0.608, val_loss=0.608]Epoch 12:   1%|▏         | 13/1000 [14:36<18:10:00, 66.26s/it, lr=0.001, test_MAE=0.66, time=66.2, train_MAE=0.598, train_loss=0.598, val_MAE=0.608, val_loss=0.608]Epoch 13:   1%|▏         | 13/1000 [14:36<18:10:00, 66.26s/it, lr=0.001, test_MAE=0.66, time=66.2, train_MAE=0.598, train_loss=0.598, val_MAE=0.608, val_loss=0.608]Epoch 13:   1%|▏         | 13/1000 [15:42<18:10:00, 66.26s/it, lr=0.001, test_MAE=0.66, time=65.9, train_MAE=0.598, train_loss=0.598, val_MAE=0.621, val_loss=0.621]Epoch 13:   1%|▏         | 14/1000 [15:42<18:07:13, 66.16s/it, lr=0.001, test_MAE=0.66, time=65.9, train_MAE=0.598, train_loss=0.598, val_MAE=0.621, val_loss=0.621]Epoch 14:   1%|▏         | 14/1000 [15:42<18:07:13, 66.16s/it, lr=0.001, test_MAE=0.66, time=65.9, train_MAE=0.598, train_loss=0.598, val_MAE=0.621, val_loss=0.621]Epoch 14:   1%|▏         | 14/1000 [16:48<18:07:13, 66.16s/it, lr=0.001, test_MAE=0.85, time=65.6, train_MAE=0.587, train_loss=0.587, val_MAE=0.807, val_loss=0.807]Epoch 14:   2%|▏         | 15/1000 [16:48<18:03:37, 66.01s/it, lr=0.001, test_MAE=0.85, time=65.6, train_MAE=0.587, train_loss=0.587, val_MAE=0.807, val_loss=0.807]Epoch 15:   2%|▏         | 15/1000 [16:48<18:03:37, 66.01s/it, lr=0.001, test_MAE=0.85, time=65.6, train_MAE=0.587, train_loss=0.587, val_MAE=0.807, val_loss=0.807]Epoch 15:   2%|▏         | 15/1000 [17:54<18:03:37, 66.01s/it, lr=0.001, test_MAE=0.633, time=66.2, train_MAE=0.581, train_loss=0.581, val_MAE=0.587, val_loss=0.587]Epoch 15:   2%|▏         | 16/1000 [17:54<18:03:42, 66.08s/it, lr=0.001, test_MAE=0.633, time=66.2, train_MAE=0.581, train_loss=0.581, val_MAE=0.587, val_loss=0.587]Epoch 16:   2%|▏         | 16/1000 [17:54<18:03:42, 66.08s/it, lr=0.001, test_MAE=0.633, time=66.2, train_MAE=0.581, train_loss=0.581, val_MAE=0.587, val_loss=0.587]Epoch 16:   2%|▏         | 16/1000 [19:00<18:03:42, 66.08s/it, lr=0.001, test_MAE=0.629, time=66, train_MAE=0.573, train_loss=0.573, val_MAE=0.596, val_loss=0.596]  Epoch 16:   2%|▏         | 17/1000 [19:00<18:02:05, 66.05s/it, lr=0.001, test_MAE=0.629, time=66, train_MAE=0.573, train_loss=0.573, val_MAE=0.596, val_loss=0.596]Epoch 17:   2%|▏         | 17/1000 [19:00<18:02:05, 66.05s/it, lr=0.001, test_MAE=0.629, time=66, train_MAE=0.573, train_loss=0.573, val_MAE=0.596, val_loss=0.596]Epoch 17:   2%|▏         | 17/1000 [20:05<18:02:05, 66.05s/it, lr=0.001, test_MAE=0.651, time=65.6, train_MAE=0.568, train_loss=0.568, val_MAE=0.612, val_loss=0.612]Epoch 17:   2%|▏         | 18/1000 [20:05<17:59:00, 65.93s/it, lr=0.001, test_MAE=0.651, time=65.6, train_MAE=0.568, train_loss=0.568, val_MAE=0.612, val_loss=0.612]Epoch 18:   2%|▏         | 18/1000 [20:05<17:59:00, 65.93s/it, lr=0.001, test_MAE=0.651, time=65.6, train_MAE=0.568, train_loss=0.568, val_MAE=0.612, val_loss=0.612]Epoch 18:   2%|▏         | 18/1000 [21:12<17:59:00, 65.93s/it, lr=0.001, test_MAE=0.65, time=66.3, train_MAE=0.569, train_loss=0.569, val_MAE=0.602, val_loss=0.602] Epoch 18:   2%|▏         | 19/1000 [21:12<17:59:43, 66.04s/it, lr=0.001, test_MAE=0.65, time=66.3, train_MAE=0.569, train_loss=0.569, val_MAE=0.602, val_loss=0.602]Epoch 19:   2%|▏         | 19/1000 [21:12<17:59:43, 66.04s/it, lr=0.001, test_MAE=0.65, time=66.3, train_MAE=0.569, train_loss=0.569, val_MAE=0.602, val_loss=0.602]Epoch 19:   2%|▏         | 19/1000 [22:18<17:59:43, 66.04s/it, lr=0.001, test_MAE=0.624, time=65.9, train_MAE=0.567, train_loss=0.567, val_MAE=0.598, val_loss=0.598]Epoch 19:   2%|▏         | 20/1000 [22:18<17:58:05, 66.01s/it, lr=0.001, test_MAE=0.624, time=65.9, train_MAE=0.567, train_loss=0.567, val_MAE=0.598, val_loss=0.598]Epoch 20:   2%|▏         | 20/1000 [22:18<17:58:05, 66.01s/it, lr=0.001, test_MAE=0.624, time=65.9, train_MAE=0.567, train_loss=0.567, val_MAE=0.598, val_loss=0.598]Epoch 20:   2%|▏         | 20/1000 [23:24<17:58:05, 66.01s/it, lr=0.001, test_MAE=0.736, time=66, train_MAE=0.574, train_loss=0.574, val_MAE=0.711, val_loss=0.711]  Epoch 20:   2%|▏         | 21/1000 [23:24<17:56:53, 66.00s/it, lr=0.001, test_MAE=0.736, time=66, train_MAE=0.574, train_loss=0.574, val_MAE=0.711, val_loss=0.711]Epoch 21:   2%|▏         | 21/1000 [23:24<17:56:53, 66.00s/it, lr=0.001, test_MAE=0.736, time=66, train_MAE=0.574, train_loss=0.574, val_MAE=0.711, val_loss=0.711]Epoch 21:   2%|▏         | 21/1000 [24:30<17:56:53, 66.00s/it, lr=0.001, test_MAE=0.626, time=66.3, train_MAE=0.553, train_loss=0.553, val_MAE=0.594, val_loss=0.594]Epoch    22: reducing learning rate of group 0 to 5.0000e-04.
Epoch 21:   2%|▏         | 22/1000 [24:30<17:57:15, 66.09s/it, lr=0.001, test_MAE=0.626, time=66.3, train_MAE=0.553, train_loss=0.553, val_MAE=0.594, val_loss=0.594]Epoch 22:   2%|▏         | 22/1000 [24:30<17:57:15, 66.09s/it, lr=0.001, test_MAE=0.626, time=66.3, train_MAE=0.553, train_loss=0.553, val_MAE=0.594, val_loss=0.594]Epoch 22:   2%|▏         | 22/1000 [25:36<17:57:15, 66.09s/it, lr=0.0005, test_MAE=0.61, time=65.6, train_MAE=0.54, train_loss=0.54, val_MAE=0.582, val_loss=0.582]  Epoch 22:   2%|▏         | 23/1000 [25:36<17:53:35, 65.93s/it, lr=0.0005, test_MAE=0.61, time=65.6, train_MAE=0.54, train_loss=0.54, val_MAE=0.582, val_loss=0.582]Epoch 23:   2%|▏         | 23/1000 [25:36<17:53:35, 65.93s/it, lr=0.0005, test_MAE=0.61, time=65.6, train_MAE=0.54, train_loss=0.54, val_MAE=0.582, val_loss=0.582]Epoch 23:   2%|▏         | 23/1000 [26:42<17:53:35, 65.93s/it, lr=0.0005, test_MAE=0.641, time=66.3, train_MAE=0.539, train_loss=0.539, val_MAE=0.601, val_loss=0.601]Epoch 23:   2%|▏         | 24/1000 [26:42<17:54:20, 66.05s/it, lr=0.0005, test_MAE=0.641, time=66.3, train_MAE=0.539, train_loss=0.539, val_MAE=0.601, val_loss=0.601]Epoch 24:   2%|▏         | 24/1000 [26:42<17:54:20, 66.05s/it, lr=0.0005, test_MAE=0.641, time=66.3, train_MAE=0.539, train_loss=0.539, val_MAE=0.601, val_loss=0.601]Epoch 24:   2%|▏         | 24/1000 [27:48<17:54:20, 66.05s/it, lr=0.0005, test_MAE=0.65, time=65.9, train_MAE=0.535, train_loss=0.535, val_MAE=0.625, val_loss=0.625] Epoch 24:   2%|▎         | 25/1000 [27:48<17:52:42, 66.01s/it, lr=0.0005, test_MAE=0.65, time=65.9, train_MAE=0.535, train_loss=0.535, val_MAE=0.625, val_loss=0.625]Epoch 25:   2%|▎         | 25/1000 [27:48<17:52:42, 66.01s/it, lr=0.0005, test_MAE=0.65, time=65.9, train_MAE=0.535, train_loss=0.535, val_MAE=0.625, val_loss=0.625]Epoch 25:   2%|▎         | 25/1000 [28:54<17:52:42, 66.01s/it, lr=0.0005, test_MAE=0.655, time=65.9, train_MAE=0.536, train_loss=0.536, val_MAE=0.62, val_loss=0.62] Epoch 25:   3%|▎         | 26/1000 [28:54<17:51:20, 66.00s/it, lr=0.0005, test_MAE=0.655, time=65.9, train_MAE=0.536, train_loss=0.536, val_MAE=0.62, val_loss=0.62]Epoch 26:   3%|▎         | 26/1000 [28:54<17:51:20, 66.00s/it, lr=0.0005, test_MAE=0.655, time=65.9, train_MAE=0.536, train_loss=0.536, val_MAE=0.62, val_loss=0.62]Epoch 26:   3%|▎         | 26/1000 [30:00<17:51:20, 66.00s/it, lr=0.0005, test_MAE=0.62, time=66.3, train_MAE=0.524, train_loss=0.524, val_MAE=0.589, val_loss=0.589]Epoch 26:   3%|▎         | 27/1000 [30:00<17:52:12, 66.12s/it, lr=0.0005, test_MAE=0.62, time=66.3, train_MAE=0.524, train_loss=0.524, val_MAE=0.589, val_loss=0.589]Epoch 27:   3%|▎         | 27/1000 [30:00<17:52:12, 66.12s/it, lr=0.0005, test_MAE=0.62, time=66.3, train_MAE=0.524, train_loss=0.524, val_MAE=0.589, val_loss=0.589]Epoch 27:   3%|▎         | 27/1000 [31:06<17:52:12, 66.12s/it, lr=0.0005, test_MAE=0.615, time=65.9, train_MAE=0.527, train_loss=0.527, val_MAE=0.582, val_loss=0.582]Epoch 27:   3%|▎         | 28/1000 [31:06<17:50:25, 66.08s/it, lr=0.0005, test_MAE=0.615, time=65.9, train_MAE=0.527, train_loss=0.527, val_MAE=0.582, val_loss=0.582]Epoch 28:   3%|▎         | 28/1000 [31:06<17:50:25, 66.08s/it, lr=0.0005, test_MAE=0.615, time=65.9, train_MAE=0.527, train_loss=0.527, val_MAE=0.582, val_loss=0.582]Epoch 28:   3%|▎         | 28/1000 [32:12<17:50:25, 66.08s/it, lr=0.0005, test_MAE=0.644, time=65.6, train_MAE=0.523, train_loss=0.523, val_MAE=0.608, val_loss=0.608]Epoch 28:   3%|▎         | 29/1000 [32:12<17:47:06, 65.94s/it, lr=0.0005, test_MAE=0.644, time=65.6, train_MAE=0.523, train_loss=0.523, val_MAE=0.608, val_loss=0.608]Epoch 29:   3%|▎         | 29/1000 [32:12<17:47:06, 65.94s/it, lr=0.0005, test_MAE=0.644, time=65.6, train_MAE=0.523, train_loss=0.523, val_MAE=0.608, val_loss=0.608]Epoch 29:   3%|▎         | 29/1000 [33:18<17:47:06, 65.94s/it, lr=0.0005, test_MAE=0.625, time=66.6, train_MAE=0.523, train_loss=0.523, val_MAE=0.585, val_loss=0.585]Epoch 29:   3%|▎         | 30/1000 [33:18<17:49:30, 66.16s/it, lr=0.0005, test_MAE=0.625, time=66.6, train_MAE=0.523, train_loss=0.523, val_MAE=0.585, val_loss=0.585]Epoch 30:   3%|▎         | 30/1000 [33:18<17:49:30, 66.16s/it, lr=0.0005, test_MAE=0.625, time=66.6, train_MAE=0.523, train_loss=0.523, val_MAE=0.585, val_loss=0.585]Epoch 30:   3%|▎         | 30/1000 [34:24<17:49:30, 66.16s/it, lr=0.0005, test_MAE=0.61, time=65.5, train_MAE=0.523, train_loss=0.523, val_MAE=0.573, val_loss=0.573] Epoch 30:   3%|▎         | 31/1000 [34:24<17:45:35, 65.98s/it, lr=0.0005, test_MAE=0.61, time=65.5, train_MAE=0.523, train_loss=0.523, val_MAE=0.573, val_loss=0.573]Epoch 31:   3%|▎         | 31/1000 [34:24<17:45:35, 65.98s/it, lr=0.0005, test_MAE=0.61, time=65.5, train_MAE=0.523, train_loss=0.523, val_MAE=0.573, val_loss=0.573]Epoch 31:   3%|▎         | 31/1000 [35:29<17:45:35, 65.98s/it, lr=0.0005, test_MAE=0.617, time=65.2, train_MAE=0.512, train_loss=0.512, val_MAE=0.576, val_loss=0.576]Epoch 31:   3%|▎         | 32/1000 [35:29<17:40:52, 65.76s/it, lr=0.0005, test_MAE=0.617, time=65.2, train_MAE=0.512, train_loss=0.512, val_MAE=0.576, val_loss=0.576]Epoch 32:   3%|▎         | 32/1000 [35:29<17:40:52, 65.76s/it, lr=0.0005, test_MAE=0.617, time=65.2, train_MAE=0.512, train_loss=0.512, val_MAE=0.576, val_loss=0.576]Epoch 32:   3%|▎         | 32/1000 [36:35<17:40:52, 65.76s/it, lr=0.0005, test_MAE=0.615, time=65.7, train_MAE=0.519, train_loss=0.519, val_MAE=0.572, val_loss=0.572]Epoch 32:   3%|▎         | 33/1000 [36:35<17:39:23, 65.73s/it, lr=0.0005, test_MAE=0.615, time=65.7, train_MAE=0.519, train_loss=0.519, val_MAE=0.572, val_loss=0.572]Epoch 33:   3%|▎         | 33/1000 [36:35<17:39:23, 65.73s/it, lr=0.0005, test_MAE=0.615, time=65.7, train_MAE=0.519, train_loss=0.519, val_MAE=0.572, val_loss=0.572]Epoch 33:   3%|▎         | 33/1000 [37:40<17:39:23, 65.73s/it, lr=0.0005, test_MAE=0.611, time=65.4, train_MAE=0.508, train_loss=0.508, val_MAE=0.575, val_loss=0.575]Epoch 33:   3%|▎         | 34/1000 [37:40<17:36:38, 65.63s/it, lr=0.0005, test_MAE=0.611, time=65.4, train_MAE=0.508, train_loss=0.508, val_MAE=0.575, val_loss=0.575]Epoch 34:   3%|▎         | 34/1000 [37:40<17:36:38, 65.63s/it, lr=0.0005, test_MAE=0.611, time=65.4, train_MAE=0.508, train_loss=0.508, val_MAE=0.575, val_loss=0.575]Epoch 34:   3%|▎         | 34/1000 [38:45<17:36:38, 65.63s/it, lr=0.0005, test_MAE=0.612, time=65.2, train_MAE=0.504, train_loss=0.504, val_MAE=0.575, val_loss=0.575]Epoch 34:   4%|▎         | 35/1000 [38:45<17:33:21, 65.49s/it, lr=0.0005, test_MAE=0.612, time=65.2, train_MAE=0.504, train_loss=0.504, val_MAE=0.575, val_loss=0.575]Epoch 35:   4%|▎         | 35/1000 [38:45<17:33:21, 65.49s/it, lr=0.0005, test_MAE=0.612, time=65.2, train_MAE=0.504, train_loss=0.504, val_MAE=0.575, val_loss=0.575]Epoch 35:   4%|▎         | 35/1000 [39:51<17:33:21, 65.49s/it, lr=0.0005, test_MAE=0.614, time=65.7, train_MAE=0.504, train_loss=0.504, val_MAE=0.568, val_loss=0.568]Epoch 35:   4%|▎         | 36/1000 [39:51<17:33:29, 65.57s/it, lr=0.0005, test_MAE=0.614, time=65.7, train_MAE=0.504, train_loss=0.504, val_MAE=0.568, val_loss=0.568]Epoch 36:   4%|▎         | 36/1000 [39:51<17:33:29, 65.57s/it, lr=0.0005, test_MAE=0.614, time=65.7, train_MAE=0.504, train_loss=0.504, val_MAE=0.568, val_loss=0.568]Epoch 36:   4%|▎         | 36/1000 [40:57<17:33:29, 65.57s/it, lr=0.0005, test_MAE=0.612, time=65.5, train_MAE=0.505, train_loss=0.505, val_MAE=0.568, val_loss=0.568]Epoch 36:   4%|▎         | 37/1000 [40:57<17:33:33, 65.64s/it, lr=0.0005, test_MAE=0.612, time=65.5, train_MAE=0.505, train_loss=0.505, val_MAE=0.568, val_loss=0.568]Epoch 37:   4%|▎         | 37/1000 [40:57<17:33:33, 65.64s/it, lr=0.0005, test_MAE=0.612, time=65.5, train_MAE=0.505, train_loss=0.505, val_MAE=0.568, val_loss=0.568]Epoch 37:   4%|▎         | 37/1000 [42:02<17:33:33, 65.64s/it, lr=0.0005, test_MAE=0.648, time=65.2, train_MAE=0.5, train_loss=0.5, val_MAE=0.604, val_loss=0.604]    Epoch 37:   4%|▍         | 38/1000 [42:02<17:30:20, 65.51s/it, lr=0.0005, test_MAE=0.648, time=65.2, train_MAE=0.5, train_loss=0.5, val_MAE=0.604, val_loss=0.604]Epoch 38:   4%|▍         | 38/1000 [42:02<17:30:20, 65.51s/it, lr=0.0005, test_MAE=0.648, time=65.2, train_MAE=0.5, train_loss=0.5, val_MAE=0.604, val_loss=0.604]Epoch 38:   4%|▍         | 38/1000 [43:08<17:30:20, 65.51s/it, lr=0.0005, test_MAE=0.601, time=65.8, train_MAE=0.508, train_loss=0.508, val_MAE=0.562, val_loss=0.562]Epoch 38:   4%|▍         | 39/1000 [43:08<17:30:34, 65.59s/it, lr=0.0005, test_MAE=0.601, time=65.8, train_MAE=0.508, train_loss=0.508, val_MAE=0.562, val_loss=0.562]Epoch 39:   4%|▍         | 39/1000 [43:08<17:30:34, 65.59s/it, lr=0.0005, test_MAE=0.601, time=65.8, train_MAE=0.508, train_loss=0.508, val_MAE=0.562, val_loss=0.562]Epoch 39:   4%|▍         | 39/1000 [44:13<17:30:34, 65.59s/it, lr=0.0005, test_MAE=0.658, time=65.5, train_MAE=0.501, train_loss=0.501, val_MAE=0.603, val_loss=0.603]Epoch 39:   4%|▍         | 40/1000 [44:13<17:28:56, 65.56s/it, lr=0.0005, test_MAE=0.658, time=65.5, train_MAE=0.501, train_loss=0.501, val_MAE=0.603, val_loss=0.603]Epoch 40:   4%|▍         | 40/1000 [44:13<17:28:56, 65.56s/it, lr=0.0005, test_MAE=0.658, time=65.5, train_MAE=0.501, train_loss=0.501, val_MAE=0.603, val_loss=0.603]Epoch 40:   4%|▍         | 40/1000 [45:19<17:28:56, 65.56s/it, lr=0.0005, test_MAE=0.631, time=65.5, train_MAE=0.498, train_loss=0.498, val_MAE=0.584, val_loss=0.584]Epoch 40:   4%|▍         | 41/1000 [45:19<17:27:50, 65.56s/it, lr=0.0005, test_MAE=0.631, time=65.5, train_MAE=0.498, train_loss=0.498, val_MAE=0.584, val_loss=0.584]Epoch 41:   4%|▍         | 41/1000 [45:19<17:27:50, 65.56s/it, lr=0.0005, test_MAE=0.631, time=65.5, train_MAE=0.498, train_loss=0.498, val_MAE=0.584, val_loss=0.584]Epoch 41:   4%|▍         | 41/1000 [46:25<17:27:50, 65.56s/it, lr=0.0005, test_MAE=0.631, time=65.7, train_MAE=0.491, train_loss=0.491, val_MAE=0.581, val_loss=0.581]Epoch 41:   4%|▍         | 42/1000 [46:25<17:27:36, 65.61s/it, lr=0.0005, test_MAE=0.631, time=65.7, train_MAE=0.491, train_loss=0.491, val_MAE=0.581, val_loss=0.581]Epoch 42:   4%|▍         | 42/1000 [46:25<17:27:36, 65.61s/it, lr=0.0005, test_MAE=0.631, time=65.7, train_MAE=0.491, train_loss=0.491, val_MAE=0.581, val_loss=0.581]Epoch 42:   4%|▍         | 42/1000 [47:30<17:27:36, 65.61s/it, lr=0.0005, test_MAE=0.616, time=65.1, train_MAE=0.498, train_loss=0.498, val_MAE=0.572, val_loss=0.572]Epoch 42:   4%|▍         | 43/1000 [47:30<17:24:00, 65.45s/it, lr=0.0005, test_MAE=0.616, time=65.1, train_MAE=0.498, train_loss=0.498, val_MAE=0.572, val_loss=0.572]Epoch 43:   4%|▍         | 43/1000 [47:30<17:24:00, 65.45s/it, lr=0.0005, test_MAE=0.616, time=65.1, train_MAE=0.498, train_loss=0.498, val_MAE=0.572, val_loss=0.572]Epoch 43:   4%|▍         | 43/1000 [48:36<17:24:00, 65.45s/it, lr=0.0005, test_MAE=0.624, time=65.8, train_MAE=0.495, train_loss=0.495, val_MAE=0.592, val_loss=0.592]Epoch 43:   4%|▍         | 44/1000 [48:36<17:24:28, 65.55s/it, lr=0.0005, test_MAE=0.624, time=65.8, train_MAE=0.495, train_loss=0.495, val_MAE=0.592, val_loss=0.592]Epoch 44:   4%|▍         | 44/1000 [48:36<17:24:28, 65.55s/it, lr=0.0005, test_MAE=0.624, time=65.8, train_MAE=0.495, train_loss=0.495, val_MAE=0.592, val_loss=0.592]Epoch 44:   4%|▍         | 44/1000 [49:41<17:24:28, 65.55s/it, lr=0.0005, test_MAE=0.611, time=65.4, train_MAE=0.488, train_loss=0.488, val_MAE=0.568, val_loss=0.568]Epoch    45: reducing learning rate of group 0 to 2.5000e-04.
Epoch 44:   4%|▍         | 45/1000 [49:41<17:22:55, 65.52s/it, lr=0.0005, test_MAE=0.611, time=65.4, train_MAE=0.488, train_loss=0.488, val_MAE=0.568, val_loss=0.568]Epoch 45:   4%|▍         | 45/1000 [49:41<17:22:55, 65.52s/it, lr=0.0005, test_MAE=0.611, time=65.4, train_MAE=0.488, train_loss=0.488, val_MAE=0.568, val_loss=0.568]Epoch 45:   4%|▍         | 45/1000 [50:47<17:22:55, 65.52s/it, lr=0.00025, test_MAE=0.606, time=65.5, train_MAE=0.468, train_loss=0.468, val_MAE=0.562, val_loss=0.562]Epoch 45:   5%|▍         | 46/1000 [50:47<17:21:50, 65.52s/it, lr=0.00025, test_MAE=0.606, time=65.5, train_MAE=0.468, train_loss=0.468, val_MAE=0.562, val_loss=0.562]Epoch 46:   5%|▍         | 46/1000 [50:47<17:21:50, 65.52s/it, lr=0.00025, test_MAE=0.606, time=65.5, train_MAE=0.468, train_loss=0.468, val_MAE=0.562, val_loss=0.562]Epoch 46:   5%|▍         | 46/1000 [51:52<17:21:50, 65.52s/it, lr=0.00025, test_MAE=0.608, time=65.7, train_MAE=0.465, train_loss=0.465, val_MAE=0.566, val_loss=0.566]Epoch 46:   5%|▍         | 47/1000 [51:52<17:21:48, 65.59s/it, lr=0.00025, test_MAE=0.608, time=65.7, train_MAE=0.465, train_loss=0.465, val_MAE=0.566, val_loss=0.566]Epoch 47:   5%|▍         | 47/1000 [51:52<17:21:48, 65.59s/it, lr=0.00025, test_MAE=0.608, time=65.7, train_MAE=0.465, train_loss=0.465, val_MAE=0.566, val_loss=0.566]Epoch 47:   5%|▍         | 47/1000 [52:58<17:21:48, 65.59s/it, lr=0.00025, test_MAE=0.622, time=65.4, train_MAE=0.466, train_loss=0.466, val_MAE=0.582, val_loss=0.582]Epoch 47:   5%|▍         | 48/1000 [52:58<17:19:58, 65.54s/it, lr=0.00025, test_MAE=0.622, time=65.4, train_MAE=0.466, train_loss=0.466, val_MAE=0.582, val_loss=0.582]Epoch 48:   5%|▍         | 48/1000 [52:58<17:19:58, 65.54s/it, lr=0.00025, test_MAE=0.622, time=65.4, train_MAE=0.466, train_loss=0.466, val_MAE=0.582, val_loss=0.582]Epoch 48:   5%|▍         | 48/1000 [54:03<17:19:58, 65.54s/it, lr=0.00025, test_MAE=0.612, time=65.1, train_MAE=0.466, train_loss=0.466, val_MAE=0.561, val_loss=0.561]Epoch 48:   5%|▍         | 49/1000 [54:03<17:16:57, 65.42s/it, lr=0.00025, test_MAE=0.612, time=65.1, train_MAE=0.466, train_loss=0.466, val_MAE=0.561, val_loss=0.561]Epoch 49:   5%|▍         | 49/1000 [54:03<17:16:57, 65.42s/it, lr=0.00025, test_MAE=0.612, time=65.1, train_MAE=0.466, train_loss=0.466, val_MAE=0.561, val_loss=0.561]Epoch 49:   5%|▍         | 49/1000 [55:09<17:16:57, 65.42s/it, lr=0.00025, test_MAE=0.63, time=66.1, train_MAE=0.459, train_loss=0.459, val_MAE=0.579, val_loss=0.579] Epoch 49:   5%|▌         | 50/1000 [55:09<17:18:55, 65.62s/it, lr=0.00025, test_MAE=0.63, time=66.1, train_MAE=0.459, train_loss=0.459, val_MAE=0.579, val_loss=0.579]Epoch 50:   5%|▌         | 50/1000 [55:09<17:18:55, 65.62s/it, lr=0.00025, test_MAE=0.63, time=66.1, train_MAE=0.459, train_loss=0.459, val_MAE=0.579, val_loss=0.579]Epoch 50:   5%|▌         | 50/1000 [56:14<17:18:55, 65.62s/it, lr=0.00025, test_MAE=0.605, time=65.4, train_MAE=0.465, train_loss=0.465, val_MAE=0.558, val_loss=0.558]Epoch 50:   5%|▌         | 51/1000 [56:14<17:17:05, 65.57s/it, lr=0.00025, test_MAE=0.605, time=65.4, train_MAE=0.465, train_loss=0.465, val_MAE=0.558, val_loss=0.558]Epoch 51:   5%|▌         | 51/1000 [56:14<17:17:05, 65.57s/it, lr=0.00025, test_MAE=0.605, time=65.4, train_MAE=0.465, train_loss=0.465, val_MAE=0.558, val_loss=0.558]Epoch 51:   5%|▌         | 51/1000 [57:20<17:17:05, 65.57s/it, lr=0.00025, test_MAE=0.623, time=65.1, train_MAE=0.457, train_loss=0.457, val_MAE=0.571, val_loss=0.571]Epoch 51:   5%|▌         | 52/1000 [57:20<17:13:55, 65.44s/it, lr=0.00025, test_MAE=0.623, time=65.1, train_MAE=0.457, train_loss=0.457, val_MAE=0.571, val_loss=0.571]Epoch 52:   5%|▌         | 52/1000 [57:20<17:13:55, 65.44s/it, lr=0.00025, test_MAE=0.623, time=65.1, train_MAE=0.457, train_loss=0.457, val_MAE=0.571, val_loss=0.571]Epoch 52:   5%|▌         | 52/1000 [58:25<17:13:55, 65.44s/it, lr=0.00025, test_MAE=0.613, time=65.7, train_MAE=0.446, train_loss=0.446, val_MAE=0.573, val_loss=0.573]Epoch 52:   5%|▌         | 53/1000 [58:25<17:14:15, 65.53s/it, lr=0.00025, test_MAE=0.613, time=65.7, train_MAE=0.446, train_loss=0.446, val_MAE=0.573, val_loss=0.573]Epoch 53:   5%|▌         | 53/1000 [58:25<17:14:15, 65.53s/it, lr=0.00025, test_MAE=0.613, time=65.7, train_MAE=0.446, train_loss=0.446, val_MAE=0.573, val_loss=0.573]Epoch 53:   5%|▌         | 53/1000 [59:31<17:14:15, 65.53s/it, lr=0.00025, test_MAE=0.606, time=65.4, train_MAE=0.458, train_loss=0.458, val_MAE=0.558, val_loss=0.558]Epoch 53:   5%|▌         | 54/1000 [59:31<17:12:43, 65.50s/it, lr=0.00025, test_MAE=0.606, time=65.4, train_MAE=0.458, train_loss=0.458, val_MAE=0.558, val_loss=0.558]Epoch 54:   5%|▌         | 54/1000 [59:31<17:12:43, 65.50s/it, lr=0.00025, test_MAE=0.606, time=65.4, train_MAE=0.458, train_loss=0.458, val_MAE=0.558, val_loss=0.558]Epoch 54:   5%|▌         | 54/1000 [1:00:36<17:12:43, 65.50s/it, lr=0.00025, test_MAE=0.616, time=65.2, train_MAE=0.45, train_loss=0.45, val_MAE=0.577, val_loss=0.577]Epoch 54:   6%|▌         | 55/1000 [1:00:36<17:10:17, 65.42s/it, lr=0.00025, test_MAE=0.616, time=65.2, train_MAE=0.45, train_loss=0.45, val_MAE=0.577, val_loss=0.577]Epoch 55:   6%|▌         | 55/1000 [1:00:36<17:10:17, 65.42s/it, lr=0.00025, test_MAE=0.616, time=65.2, train_MAE=0.45, train_loss=0.45, val_MAE=0.577, val_loss=0.577]Epoch 55:   6%|▌         | 55/1000 [1:01:42<17:10:17, 65.42s/it, lr=0.00025, test_MAE=0.616, time=65.8, train_MAE=0.453, train_loss=0.453, val_MAE=0.571, val_loss=0.571]Epoch 55:   6%|▌         | 56/1000 [1:01:42<17:10:59, 65.53s/it, lr=0.00025, test_MAE=0.616, time=65.8, train_MAE=0.453, train_loss=0.453, val_MAE=0.571, val_loss=0.571]Epoch 56:   6%|▌         | 56/1000 [1:01:42<17:10:59, 65.53s/it, lr=0.00025, test_MAE=0.616, time=65.8, train_MAE=0.453, train_loss=0.453, val_MAE=0.571, val_loss=0.571]Epoch 56:   6%|▌         | 56/1000 [1:02:47<17:10:59, 65.53s/it, lr=0.00025, test_MAE=0.614, time=65.5, train_MAE=0.445, train_loss=0.445, val_MAE=0.572, val_loss=0.572]Epoch    57: reducing learning rate of group 0 to 1.2500e-04.
Epoch 56:   6%|▌         | 57/1000 [1:02:47<17:09:43, 65.52s/it, lr=0.00025, test_MAE=0.614, time=65.5, train_MAE=0.445, train_loss=0.445, val_MAE=0.572, val_loss=0.572]Epoch 57:   6%|▌         | 57/1000 [1:02:47<17:09:43, 65.52s/it, lr=0.00025, test_MAE=0.614, time=65.5, train_MAE=0.445, train_loss=0.445, val_MAE=0.572, val_loss=0.572]Epoch 57:   6%|▌         | 57/1000 [1:03:52<17:09:43, 65.52s/it, lr=0.000125, test_MAE=0.616, time=65.2, train_MAE=0.44, train_loss=0.44, val_MAE=0.565, val_loss=0.565] Epoch 57:   6%|▌         | 58/1000 [1:03:52<17:07:04, 65.42s/it, lr=0.000125, test_MAE=0.616, time=65.2, train_MAE=0.44, train_loss=0.44, val_MAE=0.565, val_loss=0.565]Epoch 58:   6%|▌         | 58/1000 [1:03:52<17:07:04, 65.42s/it, lr=0.000125, test_MAE=0.616, time=65.2, train_MAE=0.44, train_loss=0.44, val_MAE=0.565, val_loss=0.565]Epoch 58:   6%|▌         | 58/1000 [1:04:58<17:07:04, 65.42s/it, lr=0.000125, test_MAE=0.611, time=65.8, train_MAE=0.435, train_loss=0.435, val_MAE=0.562, val_loss=0.562]Epoch 58:   6%|▌         | 59/1000 [1:04:58<17:08:06, 65.55s/it, lr=0.000125, test_MAE=0.611, time=65.8, train_MAE=0.435, train_loss=0.435, val_MAE=0.562, val_loss=0.562]Epoch 59:   6%|▌         | 59/1000 [1:04:58<17:08:06, 65.55s/it, lr=0.000125, test_MAE=0.611, time=65.8, train_MAE=0.435, train_loss=0.435, val_MAE=0.562, val_loss=0.562]Epoch 59:   6%|▌         | 59/1000 [1:06:04<17:08:06, 65.55s/it, lr=0.000125, test_MAE=0.614, time=65.4, train_MAE=0.432, train_loss=0.432, val_MAE=0.561, val_loss=0.561]Epoch 59:   6%|▌         | 60/1000 [1:06:04<17:06:25, 65.52s/it, lr=0.000125, test_MAE=0.614, time=65.4, train_MAE=0.432, train_loss=0.432, val_MAE=0.561, val_loss=0.561]Epoch 60:   6%|▌         | 60/1000 [1:06:04<17:06:25, 65.52s/it, lr=0.000125, test_MAE=0.614, time=65.4, train_MAE=0.432, train_loss=0.432, val_MAE=0.561, val_loss=0.561]Epoch 60:   6%|▌         | 60/1000 [1:07:09<17:06:25, 65.52s/it, lr=0.000125, test_MAE=0.612, time=65.4, train_MAE=0.441, train_loss=0.441, val_MAE=0.562, val_loss=0.562]Epoch 60:   6%|▌         | 61/1000 [1:07:09<17:04:49, 65.48s/it, lr=0.000125, test_MAE=0.612, time=65.4, train_MAE=0.441, train_loss=0.441, val_MAE=0.562, val_loss=0.562]Epoch 61:   6%|▌         | 61/1000 [1:07:09<17:04:49, 65.48s/it, lr=0.000125, test_MAE=0.612, time=65.4, train_MAE=0.441, train_loss=0.441, val_MAE=0.562, val_loss=0.562]Epoch 61:   6%|▌         | 61/1000 [1:08:15<17:04:49, 65.48s/it, lr=0.000125, test_MAE=0.605, time=65.8, train_MAE=0.431, train_loss=0.431, val_MAE=0.561, val_loss=0.561]Epoch 61:   6%|▌         | 62/1000 [1:08:15<17:05:28, 65.60s/it, lr=0.000125, test_MAE=0.605, time=65.8, train_MAE=0.431, train_loss=0.431, val_MAE=0.561, val_loss=0.561]Epoch 62:   6%|▌         | 62/1000 [1:08:15<17:05:28, 65.60s/it, lr=0.000125, test_MAE=0.605, time=65.8, train_MAE=0.431, train_loss=0.431, val_MAE=0.561, val_loss=0.561]Epoch 62:   6%|▌         | 62/1000 [1:09:20<17:05:28, 65.60s/it, lr=0.000125, test_MAE=0.613, time=65, train_MAE=0.432, train_loss=0.432, val_MAE=0.568, val_loss=0.568]  Epoch    63: reducing learning rate of group 0 to 6.2500e-05.
Epoch 62:   6%|▋         | 63/1000 [1:09:20<17:01:48, 65.43s/it, lr=0.000125, test_MAE=0.613, time=65, train_MAE=0.432, train_loss=0.432, val_MAE=0.568, val_loss=0.568]Epoch 63:   6%|▋         | 63/1000 [1:09:20<17:01:48, 65.43s/it, lr=0.000125, test_MAE=0.613, time=65, train_MAE=0.432, train_loss=0.432, val_MAE=0.568, val_loss=0.568]Epoch 63:   6%|▋         | 63/1000 [1:10:25<17:01:48, 65.43s/it, lr=6.25e-5, test_MAE=0.608, time=65.2, train_MAE=0.43, train_loss=0.43, val_MAE=0.559, val_loss=0.559] Epoch 63:   6%|▋         | 64/1000 [1:10:25<16:59:44, 65.37s/it, lr=6.25e-5, test_MAE=0.608, time=65.2, train_MAE=0.43, train_loss=0.43, val_MAE=0.559, val_loss=0.559]Epoch 64:   6%|▋         | 64/1000 [1:10:25<16:59:44, 65.37s/it, lr=6.25e-5, test_MAE=0.608, time=65.2, train_MAE=0.43, train_loss=0.43, val_MAE=0.559, val_loss=0.559]Epoch 64:   6%|▋         | 64/1000 [1:11:30<16:59:44, 65.37s/it, lr=6.25e-5, test_MAE=0.61, time=64.8, train_MAE=0.424, train_loss=0.424, val_MAE=0.56, val_loss=0.56] Epoch 64:   6%|▋         | 65/1000 [1:11:30<16:56:02, 65.20s/it, lr=6.25e-5, test_MAE=0.61, time=64.8, train_MAE=0.424, train_loss=0.424, val_MAE=0.56, val_loss=0.56]Epoch 65:   6%|▋         | 65/1000 [1:11:30<16:56:02, 65.20s/it, lr=6.25e-5, test_MAE=0.61, time=64.8, train_MAE=0.424, train_loss=0.424, val_MAE=0.56, val_loss=0.56]Epoch 65:   6%|▋         | 65/1000 [1:12:35<16:56:02, 65.20s/it, lr=6.25e-5, test_MAE=0.61, time=64.8, train_MAE=0.424, train_loss=0.424, val_MAE=0.557, val_loss=0.557]Epoch 65:   7%|▋         | 66/1000 [1:12:35<16:53:17, 65.09s/it, lr=6.25e-5, test_MAE=0.61, time=64.8, train_MAE=0.424, train_loss=0.424, val_MAE=0.557, val_loss=0.557]Epoch 66:   7%|▋         | 66/1000 [1:12:35<16:53:17, 65.09s/it, lr=6.25e-5, test_MAE=0.61, time=64.8, train_MAE=0.424, train_loss=0.424, val_MAE=0.557, val_loss=0.557]Epoch 66:   7%|▋         | 66/1000 [1:13:40<16:53:17, 65.09s/it, lr=6.25e-5, test_MAE=0.615, time=65.1, train_MAE=0.42, train_loss=0.42, val_MAE=0.561, val_loss=0.561] Epoch 66:   7%|▋         | 67/1000 [1:13:40<16:52:07, 65.09s/it, lr=6.25e-5, test_MAE=0.615, time=65.1, train_MAE=0.42, train_loss=0.42, val_MAE=0.561, val_loss=0.561]Epoch 67:   7%|▋         | 67/1000 [1:13:40<16:52:07, 65.09s/it, lr=6.25e-5, test_MAE=0.615, time=65.1, train_MAE=0.42, train_loss=0.42, val_MAE=0.561, val_loss=0.561]Epoch 67:   7%|▋         | 67/1000 [1:14:45<16:52:07, 65.09s/it, lr=6.25e-5, test_MAE=0.611, time=64.8, train_MAE=0.426, train_loss=0.426, val_MAE=0.56, val_loss=0.56]Epoch 67:   7%|▋         | 68/1000 [1:14:45<16:49:50, 65.01s/it, lr=6.25e-5, test_MAE=0.611, time=64.8, train_MAE=0.426, train_loss=0.426, val_MAE=0.56, val_loss=0.56]Epoch 68:   7%|▋         | 68/1000 [1:14:45<16:49:50, 65.01s/it, lr=6.25e-5, test_MAE=0.611, time=64.8, train_MAE=0.426, train_loss=0.426, val_MAE=0.56, val_loss=0.56]Epoch 68:   7%|▋         | 68/1000 [1:15:49<16:49:50, 65.01s/it, lr=6.25e-5, test_MAE=0.612, time=64.5, train_MAE=0.42, train_loss=0.42, val_MAE=0.564, val_loss=0.564]Epoch 68:   7%|▋         | 69/1000 [1:15:49<16:46:32, 64.87s/it, lr=6.25e-5, test_MAE=0.612, time=64.5, train_MAE=0.42, train_loss=0.42, val_MAE=0.564, val_loss=0.564]Epoch 69:   7%|▋         | 69/1000 [1:15:49<16:46:32, 64.87s/it, lr=6.25e-5, test_MAE=0.612, time=64.5, train_MAE=0.42, train_loss=0.42, val_MAE=0.564, val_loss=0.564]Epoch 69:   7%|▋         | 69/1000 [1:16:55<16:46:32, 64.87s/it, lr=6.25e-5, test_MAE=0.614, time=65.4, train_MAE=0.422, train_loss=0.422, val_MAE=0.562, val_loss=0.562]Epoch 69:   7%|▋         | 70/1000 [1:16:55<16:48:02, 65.04s/it, lr=6.25e-5, test_MAE=0.614, time=65.4, train_MAE=0.422, train_loss=0.422, val_MAE=0.562, val_loss=0.562]Epoch 70:   7%|▋         | 70/1000 [1:16:55<16:48:02, 65.04s/it, lr=6.25e-5, test_MAE=0.614, time=65.4, train_MAE=0.422, train_loss=0.422, val_MAE=0.562, val_loss=0.562]Epoch 70:   7%|▋         | 70/1000 [1:18:00<16:48:02, 65.04s/it, lr=6.25e-5, test_MAE=0.611, time=64.9, train_MAE=0.422, train_loss=0.422, val_MAE=0.56, val_loss=0.56]  Epoch 70:   7%|▋         | 71/1000 [1:18:00<16:46:31, 65.01s/it, lr=6.25e-5, test_MAE=0.611, time=64.9, train_MAE=0.422, train_loss=0.422, val_MAE=0.56, val_loss=0.56]Epoch 71:   7%|▋         | 71/1000 [1:18:00<16:46:31, 65.01s/it, lr=6.25e-5, test_MAE=0.611, time=64.9, train_MAE=0.422, train_loss=0.422, val_MAE=0.56, val_loss=0.56]Epoch 71:   7%|▋         | 71/1000 [1:19:04<16:46:31, 65.01s/it, lr=6.25e-5, test_MAE=0.612, time=64.6, train_MAE=0.421, train_loss=0.421, val_MAE=0.561, val_loss=0.561]Epoch    72: reducing learning rate of group 0 to 3.1250e-05.
Epoch 71:   7%|▋         | 72/1000 [1:19:04<16:43:31, 64.88s/it, lr=6.25e-5, test_MAE=0.612, time=64.6, train_MAE=0.421, train_loss=0.421, val_MAE=0.561, val_loss=0.561]Epoch 72:   7%|▋         | 72/1000 [1:19:04<16:43:31, 64.88s/it, lr=6.25e-5, test_MAE=0.612, time=64.6, train_MAE=0.421, train_loss=0.421, val_MAE=0.561, val_loss=0.561]Epoch 72:   7%|▋         | 72/1000 [1:20:10<16:43:31, 64.88s/it, lr=3.13e-5, test_MAE=0.611, time=65.4, train_MAE=0.421, train_loss=0.421, val_MAE=0.562, val_loss=0.562]Epoch 72:   7%|▋         | 73/1000 [1:20:10<16:44:56, 65.04s/it, lr=3.13e-5, test_MAE=0.611, time=65.4, train_MAE=0.421, train_loss=0.421, val_MAE=0.562, val_loss=0.562]Epoch 73:   7%|▋         | 73/1000 [1:20:10<16:44:56, 65.04s/it, lr=3.13e-5, test_MAE=0.611, time=65.4, train_MAE=0.421, train_loss=0.421, val_MAE=0.562, val_loss=0.562]Epoch 73:   7%|▋         | 73/1000 [1:21:15<16:44:56, 65.04s/it, lr=3.13e-5, test_MAE=0.612, time=65, train_MAE=0.416, train_loss=0.416, val_MAE=0.558, val_loss=0.558]  Epoch 73:   7%|▋         | 74/1000 [1:21:15<16:43:42, 65.03s/it, lr=3.13e-5, test_MAE=0.612, time=65, train_MAE=0.416, train_loss=0.416, val_MAE=0.558, val_loss=0.558]Epoch 74:   7%|▋         | 74/1000 [1:21:15<16:43:42, 65.03s/it, lr=3.13e-5, test_MAE=0.612, time=65, train_MAE=0.416, train_loss=0.416, val_MAE=0.558, val_loss=0.558]Epoch 74:   7%|▋         | 74/1000 [1:22:19<16:43:42, 65.03s/it, lr=3.13e-5, test_MAE=0.61, time=64.7, train_MAE=0.413, train_loss=0.413, val_MAE=0.562, val_loss=0.562]Epoch 74:   8%|▊         | 75/1000 [1:22:19<16:41:09, 64.94s/it, lr=3.13e-5, test_MAE=0.61, time=64.7, train_MAE=0.413, train_loss=0.413, val_MAE=0.562, val_loss=0.562]Epoch 75:   8%|▊         | 75/1000 [1:22:19<16:41:09, 64.94s/it, lr=3.13e-5, test_MAE=0.61, time=64.7, train_MAE=0.413, train_loss=0.413, val_MAE=0.562, val_loss=0.562]Epoch 75:   8%|▊         | 75/1000 [1:23:24<16:41:09, 64.94s/it, lr=3.13e-5, test_MAE=0.612, time=64.5, train_MAE=0.415, train_loss=0.415, val_MAE=0.559, val_loss=0.559]Epoch 75:   8%|▊         | 76/1000 [1:23:24<16:38:14, 64.82s/it, lr=3.13e-5, test_MAE=0.612, time=64.5, train_MAE=0.415, train_loss=0.415, val_MAE=0.559, val_loss=0.559]Epoch 76:   8%|▊         | 76/1000 [1:23:24<16:38:14, 64.82s/it, lr=3.13e-5, test_MAE=0.612, time=64.5, train_MAE=0.415, train_loss=0.415, val_MAE=0.559, val_loss=0.559]Epoch 76:   8%|▊         | 76/1000 [1:24:28<16:38:14, 64.82s/it, lr=3.13e-5, test_MAE=0.611, time=63.9, train_MAE=0.416, train_loss=0.416, val_MAE=0.558, val_loss=0.558]Epoch 76:   8%|▊         | 77/1000 [1:24:28<16:32:49, 64.54s/it, lr=3.13e-5, test_MAE=0.611, time=63.9, train_MAE=0.416, train_loss=0.416, val_MAE=0.558, val_loss=0.558]Epoch 77:   8%|▊         | 77/1000 [1:24:28<16:32:49, 64.54s/it, lr=3.13e-5, test_MAE=0.611, time=63.9, train_MAE=0.416, train_loss=0.416, val_MAE=0.558, val_loss=0.558]Epoch 77:   8%|▊         | 77/1000 [1:25:32<16:32:49, 64.54s/it, lr=3.13e-5, test_MAE=0.612, time=63.7, train_MAE=0.412, train_loss=0.412, val_MAE=0.561, val_loss=0.561]Epoch    78: reducing learning rate of group 0 to 1.5625e-05.
Epoch 77:   8%|▊         | 78/1000 [1:25:32<16:27:57, 64.29s/it, lr=3.13e-5, test_MAE=0.612, time=63.7, train_MAE=0.412, train_loss=0.412, val_MAE=0.561, val_loss=0.561]Epoch 78:   8%|▊         | 78/1000 [1:25:32<16:27:57, 64.29s/it, lr=3.13e-5, test_MAE=0.612, time=63.7, train_MAE=0.412, train_loss=0.412, val_MAE=0.561, val_loss=0.561]Epoch 78:   8%|▊         | 78/1000 [1:26:36<16:27:57, 64.29s/it, lr=1.56e-5, test_MAE=0.611, time=64.1, train_MAE=0.414, train_loss=0.414, val_MAE=0.561, val_loss=0.561]Epoch 78:   8%|▊         | 79/1000 [1:26:36<16:26:15, 64.25s/it, lr=1.56e-5, test_MAE=0.611, time=64.1, train_MAE=0.414, train_loss=0.414, val_MAE=0.561, val_loss=0.561]Epoch 79:   8%|▊         | 79/1000 [1:26:36<16:26:15, 64.25s/it, lr=1.56e-5, test_MAE=0.611, time=64.1, train_MAE=0.414, train_loss=0.414, val_MAE=0.561, val_loss=0.561]Epoch 79:   8%|▊         | 79/1000 [1:27:40<16:26:15, 64.25s/it, lr=1.56e-5, test_MAE=0.611, time=63.8, train_MAE=0.416, train_loss=0.416, val_MAE=0.561, val_loss=0.561]Epoch 79:   8%|▊         | 80/1000 [1:27:40<16:23:14, 64.12s/it, lr=1.56e-5, test_MAE=0.611, time=63.8, train_MAE=0.416, train_loss=0.416, val_MAE=0.561, val_loss=0.561]Epoch 80:   8%|▊         | 80/1000 [1:27:40<16:23:14, 64.12s/it, lr=1.56e-5, test_MAE=0.611, time=63.8, train_MAE=0.416, train_loss=0.416, val_MAE=0.561, val_loss=0.561]Epoch 80:   8%|▊         | 80/1000 [1:28:43<16:23:14, 64.12s/it, lr=1.56e-5, test_MAE=0.614, time=63.7, train_MAE=0.417, train_loss=0.417, val_MAE=0.564, val_loss=0.564]Epoch 80:   8%|▊         | 81/1000 [1:28:43<16:20:29, 64.01s/it, lr=1.56e-5, test_MAE=0.614, time=63.7, train_MAE=0.417, train_loss=0.417, val_MAE=0.564, val_loss=0.564]Epoch 81:   8%|▊         | 81/1000 [1:28:43<16:20:29, 64.01s/it, lr=1.56e-5, test_MAE=0.614, time=63.7, train_MAE=0.417, train_loss=0.417, val_MAE=0.564, val_loss=0.564]Epoch 81:   8%|▊         | 81/1000 [1:29:48<16:20:29, 64.01s/it, lr=1.56e-5, test_MAE=0.61, time=64.5, train_MAE=0.414, train_loss=0.414, val_MAE=0.561, val_loss=0.561] Epoch 81:   8%|▊         | 82/1000 [1:29:48<16:21:39, 64.16s/it, lr=1.56e-5, test_MAE=0.61, time=64.5, train_MAE=0.414, train_loss=0.414, val_MAE=0.561, val_loss=0.561]Epoch 82:   8%|▊         | 82/1000 [1:29:48<16:21:39, 64.16s/it, lr=1.56e-5, test_MAE=0.61, time=64.5, train_MAE=0.414, train_loss=0.414, val_MAE=0.561, val_loss=0.561]Epoch 82:   8%|▊         | 82/1000 [1:30:55<16:21:39, 64.16s/it, lr=1.56e-5, test_MAE=0.611, time=67.1, train_MAE=0.422, train_loss=0.422, val_MAE=0.562, val_loss=0.562]Epoch 82:   8%|▊         | 83/1000 [1:30:55<16:34:14, 65.05s/it, lr=1.56e-5, test_MAE=0.611, time=67.1, train_MAE=0.422, train_loss=0.422, val_MAE=0.562, val_loss=0.562]Epoch 83:   8%|▊         | 83/1000 [1:30:55<16:34:14, 65.05s/it, lr=1.56e-5, test_MAE=0.611, time=67.1, train_MAE=0.422, train_loss=0.422, val_MAE=0.562, val_loss=0.562]Epoch 83:   8%|▊         | 83/1000 [1:32:03<16:34:14, 65.05s/it, lr=1.56e-5, test_MAE=0.611, time=68.4, train_MAE=0.413, train_loss=0.413, val_MAE=0.561, val_loss=0.561]Epoch    84: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 83:   8%|▊         | 83/1000 [1:32:03<16:57:09, 66.55s/it, lr=1.56e-5, test_MAE=0.611, time=68.4, train_MAE=0.413, train_loss=0.413, val_MAE=0.561, val_loss=0.561]
Test MAE: 0.6108
Train MAE: 0.3938
Convergence Time (Epochs): 83.0000
TOTAL TIME TAKEN: 5566.0079s
AVG TIME PER EPOCH: 65.7365s
