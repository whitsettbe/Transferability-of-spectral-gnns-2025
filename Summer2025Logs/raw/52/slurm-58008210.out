I'm echoing to stdout
I'm echoing to stderr
My JobID is 58008210
I have 4 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.0707s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 2, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'poly_mlp', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_all', 'num_eigs': 16, 'bias_mode': 'spatial', 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 0.0, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/aug07/zinc_train_rec.csv', 'test': 'supp_data/molecules/aug07/zinc_test_rec.csv', 'val': 'supp_data/molecules/aug07/zinc_val_rec.csv'}, 'fixMissingPhi1': False, 'extraOrtho': False, 'doublePrecision': True, 'eigval_hidden_dim': 100, 'eigval_num_hidden_layer': 3, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [01:42<?, ?it/s, lr=0.001, test_MAE=1.07, time=102, train_MAE=0.891, train_loss=0.891, val_MAE=1.04, val_loss=1.04]Epoch 0:   0%|          | 1/1000 [01:42<28:20:15, 102.12s/it, lr=0.001, test_MAE=1.07, time=102, train_MAE=0.891, train_loss=0.891, val_MAE=1.04, val_loss=1.04]Epoch 1:   0%|          | 1/1000 [01:42<28:20:15, 102.12s/it, lr=0.001, test_MAE=1.07, time=102, train_MAE=0.891, train_loss=0.891, val_MAE=1.04, val_loss=1.04]Epoch 1:   0%|          | 1/1000 [03:05<28:20:15, 102.12s/it, lr=0.001, test_MAE=0.76, time=83.5, train_MAE=0.681, train_loss=0.681, val_MAE=0.712, val_loss=0.712]Epoch 1:   0%|          | 2/1000 [03:05<26:45:43, 96.54s/it, lr=0.001, test_MAE=0.76, time=83.5, train_MAE=0.681, train_loss=0.681, val_MAE=0.712, val_loss=0.712] Epoch 2:   0%|          | 2/1000 [03:05<26:45:43, 96.54s/it, lr=0.001, test_MAE=0.76, time=83.5, train_MAE=0.681, train_loss=0.681, val_MAE=0.712, val_loss=0.712]Epoch 2:   0%|          | 2/1000 [04:29<26:45:43, 96.54s/it, lr=0.001, test_MAE=0.705, time=83.5, train_MAE=0.668, train_loss=0.668, val_MAE=0.662, val_loss=0.662]Epoch 2:   0%|          | 3/1000 [04:29<25:39:24, 92.64s/it, lr=0.001, test_MAE=0.705, time=83.5, train_MAE=0.668, train_loss=0.668, val_MAE=0.662, val_loss=0.662]Epoch 3:   0%|          | 3/1000 [04:29<25:39:24, 92.64s/it, lr=0.001, test_MAE=0.705, time=83.5, train_MAE=0.668, train_loss=0.668, val_MAE=0.662, val_loss=0.662]Epoch 3:   0%|          | 3/1000 [05:52<25:39:24, 92.64s/it, lr=0.001, test_MAE=0.676, time=83.4, train_MAE=0.661, train_loss=0.661, val_MAE=0.635, val_loss=0.635]Epoch 3:   0%|          | 4/1000 [05:52<24:51:54, 89.87s/it, lr=0.001, test_MAE=0.676, time=83.4, train_MAE=0.661, train_loss=0.661, val_MAE=0.635, val_loss=0.635]Epoch 4:   0%|          | 4/1000 [05:52<24:51:54, 89.87s/it, lr=0.001, test_MAE=0.676, time=83.4, train_MAE=0.661, train_loss=0.661, val_MAE=0.635, val_loss=0.635]Epoch 4:   0%|          | 4/1000 [07:16<24:51:54, 89.87s/it, lr=0.001, test_MAE=0.683, time=83.8, train_MAE=0.629, train_loss=0.629, val_MAE=0.652, val_loss=0.652]Epoch 4:   0%|          | 5/1000 [07:16<24:20:09, 88.05s/it, lr=0.001, test_MAE=0.683, time=83.8, train_MAE=0.629, train_loss=0.629, val_MAE=0.652, val_loss=0.652]Epoch 5:   0%|          | 5/1000 [07:16<24:20:09, 88.05s/it, lr=0.001, test_MAE=0.683, time=83.8, train_MAE=0.629, train_loss=0.629, val_MAE=0.652, val_loss=0.652]Epoch 5:   0%|          | 5/1000 [08:39<24:20:09, 88.05s/it, lr=0.001, test_MAE=1.49, time=83.4, train_MAE=0.633, train_loss=0.633, val_MAE=1.46, val_loss=1.46]   Epoch 5:   1%|          | 6/1000 [08:39<23:55:43, 86.66s/it, lr=0.001, test_MAE=1.49, time=83.4, train_MAE=0.633, train_loss=0.633, val_MAE=1.46, val_loss=1.46]Epoch 6:   1%|          | 6/1000 [08:39<23:55:43, 86.66s/it, lr=0.001, test_MAE=1.49, time=83.4, train_MAE=0.633, train_loss=0.633, val_MAE=1.46, val_loss=1.46]Epoch 6:   1%|          | 6/1000 [10:03<23:55:43, 86.66s/it, lr=0.001, test_MAE=0.963, time=83.9, train_MAE=0.625, train_loss=0.625, val_MAE=0.918, val_loss=0.918]Epoch 6:   1%|          | 7/1000 [10:03<23:40:47, 85.85s/it, lr=0.001, test_MAE=0.963, time=83.9, train_MAE=0.625, train_loss=0.625, val_MAE=0.918, val_loss=0.918]Epoch 7:   1%|          | 7/1000 [10:03<23:40:47, 85.85s/it, lr=0.001, test_MAE=0.963, time=83.9, train_MAE=0.625, train_loss=0.625, val_MAE=0.918, val_loss=0.918]Epoch 7:   1%|          | 7/1000 [11:29<23:40:47, 85.85s/it, lr=0.001, test_MAE=0.646, time=85.9, train_MAE=0.621, train_loss=0.621, val_MAE=0.612, val_loss=0.612]Epoch 7:   1%|          | 8/1000 [11:29<23:39:53, 85.88s/it, lr=0.001, test_MAE=0.646, time=85.9, train_MAE=0.621, train_loss=0.621, val_MAE=0.612, val_loss=0.612]Epoch 8:   1%|          | 8/1000 [11:29<23:39:53, 85.88s/it, lr=0.001, test_MAE=0.646, time=85.9, train_MAE=0.621, train_loss=0.621, val_MAE=0.612, val_loss=0.612]Epoch 8:   1%|          | 8/1000 [12:55<23:39:53, 85.88s/it, lr=0.001, test_MAE=0.659, time=85.3, train_MAE=0.616, train_loss=0.616, val_MAE=0.624, val_loss=0.624]Epoch 8:   1%|          | 9/1000 [12:55<23:35:36, 85.71s/it, lr=0.001, test_MAE=0.659, time=85.3, train_MAE=0.616, train_loss=0.616, val_MAE=0.624, val_loss=0.624]Epoch 9:   1%|          | 9/1000 [12:55<23:35:36, 85.71s/it, lr=0.001, test_MAE=0.659, time=85.3, train_MAE=0.616, train_loss=0.616, val_MAE=0.624, val_loss=0.624]Epoch 9:   1%|          | 9/1000 [14:18<23:35:36, 85.71s/it, lr=0.001, test_MAE=0.709, time=83.8, train_MAE=0.594, train_loss=0.594, val_MAE=0.649, val_loss=0.649]Epoch 9:   1%|          | 10/1000 [14:18<23:24:47, 85.14s/it, lr=0.001, test_MAE=0.709, time=83.8, train_MAE=0.594, train_loss=0.594, val_MAE=0.649, val_loss=0.649]Epoch 10:   1%|          | 10/1000 [14:18<23:24:47, 85.14s/it, lr=0.001, test_MAE=0.709, time=83.8, train_MAE=0.594, train_loss=0.594, val_MAE=0.649, val_loss=0.649]Epoch 10:   1%|          | 10/1000 [15:42<23:24:47, 85.14s/it, lr=0.001, test_MAE=0.878, time=83.5, train_MAE=0.605, train_loss=0.605, val_MAE=0.838, val_loss=0.838]Epoch 10:   1%|          | 11/1000 [15:42<23:15:09, 84.64s/it, lr=0.001, test_MAE=0.878, time=83.5, train_MAE=0.605, train_loss=0.605, val_MAE=0.838, val_loss=0.838]Epoch 11:   1%|          | 11/1000 [15:42<23:15:09, 84.64s/it, lr=0.001, test_MAE=0.878, time=83.5, train_MAE=0.605, train_loss=0.605, val_MAE=0.838, val_loss=0.838]Epoch 11:   1%|          | 11/1000 [17:05<23:15:09, 84.64s/it, lr=0.001, test_MAE=0.655, time=83.1, train_MAE=0.599, train_loss=0.599, val_MAE=0.607, val_loss=0.607]Epoch 11:   1%|          | 12/1000 [17:05<23:06:10, 84.18s/it, lr=0.001, test_MAE=0.655, time=83.1, train_MAE=0.599, train_loss=0.599, val_MAE=0.607, val_loss=0.607]Epoch 12:   1%|          | 12/1000 [17:05<23:06:10, 84.18s/it, lr=0.001, test_MAE=0.655, time=83.1, train_MAE=0.599, train_loss=0.599, val_MAE=0.607, val_loss=0.607]Epoch 12:   1%|          | 12/1000 [18:29<23:06:10, 84.18s/it, lr=0.001, test_MAE=0.733, time=83.8, train_MAE=0.6, train_loss=0.6, val_MAE=0.692, val_loss=0.692]    Epoch 12:   1%|▏         | 13/1000 [18:29<23:02:58, 84.07s/it, lr=0.001, test_MAE=0.733, time=83.8, train_MAE=0.6, train_loss=0.6, val_MAE=0.692, val_loss=0.692]Epoch 13:   1%|▏         | 13/1000 [18:29<23:02:58, 84.07s/it, lr=0.001, test_MAE=0.733, time=83.8, train_MAE=0.6, train_loss=0.6, val_MAE=0.692, val_loss=0.692]Epoch 13:   1%|▏         | 13/1000 [19:52<23:02:58, 84.07s/it, lr=0.001, test_MAE=0.654, time=83.4, train_MAE=0.598, train_loss=0.598, val_MAE=0.62, val_loss=0.62]Epoch 13:   1%|▏         | 14/1000 [19:52<22:58:33, 83.89s/it, lr=0.001, test_MAE=0.654, time=83.4, train_MAE=0.598, train_loss=0.598, val_MAE=0.62, val_loss=0.62]Epoch 14:   1%|▏         | 14/1000 [19:52<22:58:33, 83.89s/it, lr=0.001, test_MAE=0.654, time=83.4, train_MAE=0.598, train_loss=0.598, val_MAE=0.62, val_loss=0.62]Epoch 14:   1%|▏         | 14/1000 [21:16<22:58:33, 83.89s/it, lr=0.001, test_MAE=0.713, time=83.5, train_MAE=0.589, train_loss=0.589, val_MAE=0.658, val_loss=0.658]Epoch 14:   2%|▏         | 15/1000 [21:16<22:55:21, 83.78s/it, lr=0.001, test_MAE=0.713, time=83.5, train_MAE=0.589, train_loss=0.589, val_MAE=0.658, val_loss=0.658]Epoch 15:   2%|▏         | 15/1000 [21:16<22:55:21, 83.78s/it, lr=0.001, test_MAE=0.713, time=83.5, train_MAE=0.589, train_loss=0.589, val_MAE=0.658, val_loss=0.658]Epoch 15:   2%|▏         | 15/1000 [22:40<22:55:21, 83.78s/it, lr=0.001, test_MAE=0.854, time=83.8, train_MAE=0.584, train_loss=0.584, val_MAE=0.804, val_loss=0.804]Epoch 15:   2%|▏         | 16/1000 [22:40<22:54:22, 83.80s/it, lr=0.001, test_MAE=0.854, time=83.8, train_MAE=0.584, train_loss=0.584, val_MAE=0.804, val_loss=0.804]Epoch 16:   2%|▏         | 16/1000 [22:40<22:54:22, 83.80s/it, lr=0.001, test_MAE=0.854, time=83.8, train_MAE=0.584, train_loss=0.584, val_MAE=0.804, val_loss=0.804]Epoch 16:   2%|▏         | 16/1000 [24:04<22:54:22, 83.80s/it, lr=0.001, test_MAE=0.802, time=84.5, train_MAE=0.575, train_loss=0.575, val_MAE=0.755, val_loss=0.755]Epoch 16:   2%|▏         | 17/1000 [24:04<22:56:20, 84.01s/it, lr=0.001, test_MAE=0.802, time=84.5, train_MAE=0.575, train_loss=0.575, val_MAE=0.755, val_loss=0.755]Epoch 17:   2%|▏         | 17/1000 [24:04<22:56:20, 84.01s/it, lr=0.001, test_MAE=0.802, time=84.5, train_MAE=0.575, train_loss=0.575, val_MAE=0.755, val_loss=0.755]Epoch 17:   2%|▏         | 17/1000 [25:30<22:56:20, 84.01s/it, lr=0.001, test_MAE=1.03, time=85.7, train_MAE=0.573, train_loss=0.573, val_MAE=0.997, val_loss=0.997] Epoch    18: reducing learning rate of group 0 to 5.0000e-04.
Epoch 17:   2%|▏         | 18/1000 [25:30<23:03:32, 84.53s/it, lr=0.001, test_MAE=1.03, time=85.7, train_MAE=0.573, train_loss=0.573, val_MAE=0.997, val_loss=0.997]Epoch 18:   2%|▏         | 18/1000 [25:30<23:03:32, 84.53s/it, lr=0.001, test_MAE=1.03, time=85.7, train_MAE=0.573, train_loss=0.573, val_MAE=0.997, val_loss=0.997]Epoch 18:   2%|▏         | 18/1000 [26:54<23:03:32, 84.53s/it, lr=0.0005, test_MAE=0.624, time=83.9, train_MAE=0.556, train_loss=0.556, val_MAE=0.588, val_loss=0.588]Epoch 18:   2%|▏         | 19/1000 [26:54<22:59:19, 84.36s/it, lr=0.0005, test_MAE=0.624, time=83.9, train_MAE=0.556, train_loss=0.556, val_MAE=0.588, val_loss=0.588]Epoch 19:   2%|▏         | 19/1000 [26:54<22:59:19, 84.36s/it, lr=0.0005, test_MAE=0.624, time=83.9, train_MAE=0.556, train_loss=0.556, val_MAE=0.588, val_loss=0.588]Epoch 19:   2%|▏         | 19/1000 [28:17<22:59:19, 84.36s/it, lr=0.0005, test_MAE=0.671, time=83.6, train_MAE=0.556, train_loss=0.556, val_MAE=0.639, val_loss=0.639]Epoch 19:   2%|▏         | 20/1000 [28:17<22:54:27, 84.15s/it, lr=0.0005, test_MAE=0.671, time=83.6, train_MAE=0.556, train_loss=0.556, val_MAE=0.639, val_loss=0.639]Epoch 20:   2%|▏         | 20/1000 [28:17<22:54:27, 84.15s/it, lr=0.0005, test_MAE=0.671, time=83.6, train_MAE=0.556, train_loss=0.556, val_MAE=0.639, val_loss=0.639]Epoch 20:   2%|▏         | 20/1000 [29:43<22:54:27, 84.15s/it, lr=0.0005, test_MAE=0.647, time=85.1, train_MAE=0.559, train_loss=0.559, val_MAE=0.596, val_loss=0.596]Epoch 20:   2%|▏         | 21/1000 [29:43<22:57:33, 84.43s/it, lr=0.0005, test_MAE=0.647, time=85.1, train_MAE=0.559, train_loss=0.559, val_MAE=0.596, val_loss=0.596]Epoch 21:   2%|▏         | 21/1000 [29:43<22:57:33, 84.43s/it, lr=0.0005, test_MAE=0.647, time=85.1, train_MAE=0.559, train_loss=0.559, val_MAE=0.596, val_loss=0.596]Epoch 21:   2%|▏         | 21/1000 [31:08<22:57:33, 84.43s/it, lr=0.0005, test_MAE=0.649, time=85.6, train_MAE=0.541, train_loss=0.541, val_MAE=0.599, val_loss=0.599]Epoch 21:   2%|▏         | 22/1000 [31:08<23:01:54, 84.78s/it, lr=0.0005, test_MAE=0.649, time=85.6, train_MAE=0.541, train_loss=0.541, val_MAE=0.599, val_loss=0.599]Epoch 22:   2%|▏         | 22/1000 [31:08<23:01:54, 84.78s/it, lr=0.0005, test_MAE=0.649, time=85.6, train_MAE=0.541, train_loss=0.541, val_MAE=0.599, val_loss=0.599]Epoch 22:   2%|▏         | 22/1000 [32:32<23:01:54, 84.78s/it, lr=0.0005, test_MAE=0.634, time=83.8, train_MAE=0.541, train_loss=0.541, val_MAE=0.587, val_loss=0.587]Epoch 22:   2%|▏         | 23/1000 [32:32<22:55:37, 84.48s/it, lr=0.0005, test_MAE=0.634, time=83.8, train_MAE=0.541, train_loss=0.541, val_MAE=0.587, val_loss=0.587]Epoch 23:   2%|▏         | 23/1000 [32:32<22:55:37, 84.48s/it, lr=0.0005, test_MAE=0.634, time=83.8, train_MAE=0.541, train_loss=0.541, val_MAE=0.587, val_loss=0.587]Epoch 23:   2%|▏         | 23/1000 [33:56<22:55:37, 84.48s/it, lr=0.0005, test_MAE=0.622, time=83.9, train_MAE=0.544, train_loss=0.544, val_MAE=0.586, val_loss=0.586]Epoch 23:   2%|▏         | 24/1000 [33:56<22:51:13, 84.30s/it, lr=0.0005, test_MAE=0.622, time=83.9, train_MAE=0.544, train_loss=0.544, val_MAE=0.586, val_loss=0.586]Epoch 24:   2%|▏         | 24/1000 [33:56<22:51:13, 84.30s/it, lr=0.0005, test_MAE=0.622, time=83.9, train_MAE=0.544, train_loss=0.544, val_MAE=0.586, val_loss=0.586]Epoch 24:   2%|▏         | 24/1000 [35:21<22:51:13, 84.30s/it, lr=0.0005, test_MAE=0.693, time=84.9, train_MAE=0.539, train_loss=0.539, val_MAE=0.659, val_loss=0.659]Epoch 24:   2%|▎         | 25/1000 [35:21<22:52:43, 84.47s/it, lr=0.0005, test_MAE=0.693, time=84.9, train_MAE=0.539, train_loss=0.539, val_MAE=0.659, val_loss=0.659]Epoch 25:   2%|▎         | 25/1000 [35:21<22:52:43, 84.47s/it, lr=0.0005, test_MAE=0.693, time=84.9, train_MAE=0.539, train_loss=0.539, val_MAE=0.659, val_loss=0.659]Epoch 25:   2%|▎         | 25/1000 [36:47<22:52:43, 84.47s/it, lr=0.0005, test_MAE=0.617, time=85.9, train_MAE=0.544, train_loss=0.544, val_MAE=0.587, val_loss=0.587]Epoch 25:   3%|▎         | 26/1000 [36:47<22:58:14, 84.90s/it, lr=0.0005, test_MAE=0.617, time=85.9, train_MAE=0.544, train_loss=0.544, val_MAE=0.587, val_loss=0.587]Epoch 26:   3%|▎         | 26/1000 [36:47<22:58:14, 84.90s/it, lr=0.0005, test_MAE=0.617, time=85.9, train_MAE=0.544, train_loss=0.544, val_MAE=0.587, val_loss=0.587]Epoch 26:   3%|▎         | 26/1000 [38:11<22:58:14, 84.90s/it, lr=0.0005, test_MAE=0.683, time=84.5, train_MAE=0.532, train_loss=0.532, val_MAE=0.641, val_loss=0.641]Epoch 26:   3%|▎         | 27/1000 [38:11<22:54:48, 84.78s/it, lr=0.0005, test_MAE=0.683, time=84.5, train_MAE=0.532, train_loss=0.532, val_MAE=0.641, val_loss=0.641]Epoch 27:   3%|▎         | 27/1000 [38:11<22:54:48, 84.78s/it, lr=0.0005, test_MAE=0.683, time=84.5, train_MAE=0.532, train_loss=0.532, val_MAE=0.641, val_loss=0.641]Epoch 27:   3%|▎         | 27/1000 [39:35<22:54:48, 84.78s/it, lr=0.0005, test_MAE=0.739, time=83.5, train_MAE=0.533, train_loss=0.533, val_MAE=0.703, val_loss=0.703]Epoch 27:   3%|▎         | 28/1000 [39:35<22:47:11, 84.39s/it, lr=0.0005, test_MAE=0.739, time=83.5, train_MAE=0.533, train_loss=0.533, val_MAE=0.703, val_loss=0.703]Epoch 28:   3%|▎         | 28/1000 [39:35<22:47:11, 84.39s/it, lr=0.0005, test_MAE=0.739, time=83.5, train_MAE=0.533, train_loss=0.533, val_MAE=0.703, val_loss=0.703]Epoch 28:   3%|▎         | 28/1000 [40:58<22:47:11, 84.39s/it, lr=0.0005, test_MAE=0.726, time=83.2, train_MAE=0.535, train_loss=0.535, val_MAE=0.688, val_loss=0.688]Epoch 28:   3%|▎         | 29/1000 [40:58<22:39:54, 84.03s/it, lr=0.0005, test_MAE=0.726, time=83.2, train_MAE=0.535, train_loss=0.535, val_MAE=0.688, val_loss=0.688]Epoch 29:   3%|▎         | 29/1000 [40:58<22:39:54, 84.03s/it, lr=0.0005, test_MAE=0.726, time=83.2, train_MAE=0.535, train_loss=0.535, val_MAE=0.688, val_loss=0.688]Epoch 29:   3%|▎         | 29/1000 [42:22<22:39:54, 84.03s/it, lr=0.0005, test_MAE=0.738, time=84.2, train_MAE=0.529, train_loss=0.529, val_MAE=0.692, val_loss=0.692]Epoch    30: reducing learning rate of group 0 to 2.5000e-04.
Epoch 29:   3%|▎         | 30/1000 [42:22<22:39:20, 84.08s/it, lr=0.0005, test_MAE=0.738, time=84.2, train_MAE=0.529, train_loss=0.529, val_MAE=0.692, val_loss=0.692]Epoch 30:   3%|▎         | 30/1000 [42:22<22:39:20, 84.08s/it, lr=0.0005, test_MAE=0.738, time=84.2, train_MAE=0.529, train_loss=0.529, val_MAE=0.692, val_loss=0.692]Epoch 30:   3%|▎         | 30/1000 [43:45<22:39:20, 84.08s/it, lr=0.00025, test_MAE=0.788, time=83.5, train_MAE=0.521, train_loss=0.521, val_MAE=0.746, val_loss=0.746]Epoch 30:   3%|▎         | 31/1000 [43:45<22:35:08, 83.91s/it, lr=0.00025, test_MAE=0.788, time=83.5, train_MAE=0.521, train_loss=0.521, val_MAE=0.746, val_loss=0.746]Epoch 31:   3%|▎         | 31/1000 [43:45<22:35:08, 83.91s/it, lr=0.00025, test_MAE=0.788, time=83.5, train_MAE=0.521, train_loss=0.521, val_MAE=0.746, val_loss=0.746]Epoch 31:   3%|▎         | 31/1000 [45:09<22:35:08, 83.91s/it, lr=0.00025, test_MAE=0.618, time=83.2, train_MAE=0.509, train_loss=0.509, val_MAE=0.579, val_loss=0.579]Epoch 31:   3%|▎         | 32/1000 [45:09<22:30:19, 83.70s/it, lr=0.00025, test_MAE=0.618, time=83.2, train_MAE=0.509, train_loss=0.509, val_MAE=0.579, val_loss=0.579]Epoch 32:   3%|▎         | 32/1000 [45:09<22:30:19, 83.70s/it, lr=0.00025, test_MAE=0.618, time=83.2, train_MAE=0.509, train_loss=0.509, val_MAE=0.579, val_loss=0.579]Epoch 32:   3%|▎         | 32/1000 [46:33<22:30:19, 83.70s/it, lr=0.00025, test_MAE=0.609, time=84.2, train_MAE=0.509, train_loss=0.509, val_MAE=0.573, val_loss=0.573]Epoch 32:   3%|▎         | 33/1000 [46:33<22:31:34, 83.86s/it, lr=0.00025, test_MAE=0.609, time=84.2, train_MAE=0.509, train_loss=0.509, val_MAE=0.573, val_loss=0.573]Epoch 33:   3%|▎         | 33/1000 [46:33<22:31:34, 83.86s/it, lr=0.00025, test_MAE=0.609, time=84.2, train_MAE=0.509, train_loss=0.509, val_MAE=0.573, val_loss=0.573]Epoch 33:   3%|▎         | 33/1000 [47:56<22:31:34, 83.86s/it, lr=0.00025, test_MAE=0.608, time=83.5, train_MAE=0.505, train_loss=0.505, val_MAE=0.576, val_loss=0.576]Epoch 33:   3%|▎         | 34/1000 [47:56<22:28:35, 83.76s/it, lr=0.00025, test_MAE=0.608, time=83.5, train_MAE=0.505, train_loss=0.505, val_MAE=0.576, val_loss=0.576]Epoch 34:   3%|▎         | 34/1000 [47:56<22:28:35, 83.76s/it, lr=0.00025, test_MAE=0.608, time=83.5, train_MAE=0.505, train_loss=0.505, val_MAE=0.576, val_loss=0.576]Epoch 34:   3%|▎         | 34/1000 [49:21<22:28:35, 83.76s/it, lr=0.00025, test_MAE=0.628, time=84.6, train_MAE=0.5, train_loss=0.5, val_MAE=0.604, val_loss=0.604]    Epoch 34:   4%|▎         | 35/1000 [49:21<22:31:04, 84.01s/it, lr=0.00025, test_MAE=0.628, time=84.6, train_MAE=0.5, train_loss=0.5, val_MAE=0.604, val_loss=0.604]Epoch 35:   4%|▎         | 35/1000 [49:21<22:31:04, 84.01s/it, lr=0.00025, test_MAE=0.628, time=84.6, train_MAE=0.5, train_loss=0.5, val_MAE=0.604, val_loss=0.604]Epoch 35:   4%|▎         | 35/1000 [50:47<22:31:04, 84.01s/it, lr=0.00025, test_MAE=0.631, time=86.2, train_MAE=0.509, train_loss=0.509, val_MAE=0.586, val_loss=0.586]Epoch 35:   4%|▎         | 36/1000 [50:47<22:40:17, 84.66s/it, lr=0.00025, test_MAE=0.631, time=86.2, train_MAE=0.509, train_loss=0.509, val_MAE=0.586, val_loss=0.586]Epoch 36:   4%|▎         | 36/1000 [50:47<22:40:17, 84.66s/it, lr=0.00025, test_MAE=0.631, time=86.2, train_MAE=0.509, train_loss=0.509, val_MAE=0.586, val_loss=0.586]Epoch 36:   4%|▎         | 36/1000 [52:11<22:40:17, 84.66s/it, lr=0.00025, test_MAE=0.624, time=84.2, train_MAE=0.503, train_loss=0.503, val_MAE=0.594, val_loss=0.594]Epoch 36:   4%|▎         | 37/1000 [52:11<22:36:35, 84.52s/it, lr=0.00025, test_MAE=0.624, time=84.2, train_MAE=0.503, train_loss=0.503, val_MAE=0.594, val_loss=0.594]Epoch 37:   4%|▎         | 37/1000 [52:11<22:36:35, 84.52s/it, lr=0.00025, test_MAE=0.624, time=84.2, train_MAE=0.503, train_loss=0.503, val_MAE=0.594, val_loss=0.594]Epoch 37:   4%|▎         | 37/1000 [53:35<22:36:35, 84.52s/it, lr=0.00025, test_MAE=0.61, time=83.2, train_MAE=0.503, train_loss=0.503, val_MAE=0.574, val_loss=0.574] Epoch 37:   4%|▍         | 38/1000 [53:35<22:28:42, 84.12s/it, lr=0.00025, test_MAE=0.61, time=83.2, train_MAE=0.503, train_loss=0.503, val_MAE=0.574, val_loss=0.574]Epoch 38:   4%|▍         | 38/1000 [53:35<22:28:42, 84.12s/it, lr=0.00025, test_MAE=0.61, time=83.2, train_MAE=0.503, train_loss=0.503, val_MAE=0.574, val_loss=0.574]Epoch 38:   4%|▍         | 38/1000 [54:58<22:28:42, 84.12s/it, lr=0.00025, test_MAE=0.666, time=83.8, train_MAE=0.511, train_loss=0.511, val_MAE=0.619, val_loss=0.619]Epoch    39: reducing learning rate of group 0 to 1.2500e-04.
Epoch 38:   4%|▍         | 39/1000 [54:58<22:25:52, 84.03s/it, lr=0.00025, test_MAE=0.666, time=83.8, train_MAE=0.511, train_loss=0.511, val_MAE=0.619, val_loss=0.619]Epoch 39:   4%|▍         | 39/1000 [54:58<22:25:52, 84.03s/it, lr=0.00025, test_MAE=0.666, time=83.8, train_MAE=0.511, train_loss=0.511, val_MAE=0.619, val_loss=0.619]Epoch 39:   4%|▍         | 39/1000 [56:22<22:25:52, 84.03s/it, lr=0.000125, test_MAE=0.607, time=83.5, train_MAE=0.485, train_loss=0.485, val_MAE=0.575, val_loss=0.575]Epoch 39:   4%|▍         | 40/1000 [56:22<22:22:12, 83.89s/it, lr=0.000125, test_MAE=0.607, time=83.5, train_MAE=0.485, train_loss=0.485, val_MAE=0.575, val_loss=0.575]Epoch 40:   4%|▍         | 40/1000 [56:22<22:22:12, 83.89s/it, lr=0.000125, test_MAE=0.607, time=83.5, train_MAE=0.485, train_loss=0.485, val_MAE=0.575, val_loss=0.575]Epoch 40:   4%|▍         | 40/1000 [57:46<22:22:12, 83.89s/it, lr=0.000125, test_MAE=0.608, time=83.6, train_MAE=0.491, train_loss=0.491, val_MAE=0.575, val_loss=0.575]Epoch 40:   4%|▍         | 41/1000 [57:46<22:19:19, 83.79s/it, lr=0.000125, test_MAE=0.608, time=83.6, train_MAE=0.491, train_loss=0.491, val_MAE=0.575, val_loss=0.575]Epoch 41:   4%|▍         | 41/1000 [57:46<22:19:19, 83.79s/it, lr=0.000125, test_MAE=0.608, time=83.6, train_MAE=0.491, train_loss=0.491, val_MAE=0.575, val_loss=0.575]Epoch 41:   4%|▍         | 41/1000 [59:09<22:19:19, 83.79s/it, lr=0.000125, test_MAE=0.656, time=83.5, train_MAE=0.487, train_loss=0.487, val_MAE=0.618, val_loss=0.618]Epoch 41:   4%|▍         | 42/1000 [59:09<22:16:29, 83.71s/it, lr=0.000125, test_MAE=0.656, time=83.5, train_MAE=0.487, train_loss=0.487, val_MAE=0.618, val_loss=0.618]Epoch 42:   4%|▍         | 42/1000 [59:09<22:16:29, 83.71s/it, lr=0.000125, test_MAE=0.656, time=83.5, train_MAE=0.487, train_loss=0.487, val_MAE=0.618, val_loss=0.618]Epoch 42:   4%|▍         | 42/1000 [1:00:33<22:16:29, 83.71s/it, lr=0.000125, test_MAE=0.622, time=84.3, train_MAE=0.493, train_loss=0.493, val_MAE=0.594, val_loss=0.594]Epoch 42:   4%|▍         | 43/1000 [1:00:33<22:18:05, 83.89s/it, lr=0.000125, test_MAE=0.622, time=84.3, train_MAE=0.493, train_loss=0.493, val_MAE=0.594, val_loss=0.594]Epoch 43:   4%|▍         | 43/1000 [1:00:33<22:18:05, 83.89s/it, lr=0.000125, test_MAE=0.622, time=84.3, train_MAE=0.493, train_loss=0.493, val_MAE=0.594, val_loss=0.594]Epoch 43:   4%|▍         | 43/1000 [1:01:57<22:18:05, 83.89s/it, lr=0.000125, test_MAE=0.64, time=83.3, train_MAE=0.486, train_loss=0.486, val_MAE=0.599, val_loss=0.599] Epoch 43:   4%|▍         | 44/1000 [1:01:57<22:13:58, 83.72s/it, lr=0.000125, test_MAE=0.64, time=83.3, train_MAE=0.486, train_loss=0.486, val_MAE=0.599, val_loss=0.599]Epoch 44:   4%|▍         | 44/1000 [1:01:57<22:13:58, 83.72s/it, lr=0.000125, test_MAE=0.64, time=83.3, train_MAE=0.486, train_loss=0.486, val_MAE=0.599, val_loss=0.599]Epoch 44:   4%|▍         | 44/1000 [1:03:22<22:13:58, 83.72s/it, lr=0.000125, test_MAE=0.616, time=85.1, train_MAE=0.483, train_loss=0.483, val_MAE=0.575, val_loss=0.575]Epoch    45: reducing learning rate of group 0 to 6.2500e-05.
Epoch 44:   4%|▍         | 45/1000 [1:03:22<22:19:19, 84.15s/it, lr=0.000125, test_MAE=0.616, time=85.1, train_MAE=0.483, train_loss=0.483, val_MAE=0.575, val_loss=0.575]Epoch 45:   4%|▍         | 45/1000 [1:03:22<22:19:19, 84.15s/it, lr=0.000125, test_MAE=0.616, time=85.1, train_MAE=0.483, train_loss=0.483, val_MAE=0.575, val_loss=0.575]Epoch 45:   4%|▍         | 45/1000 [1:04:46<22:19:19, 84.15s/it, lr=6.25e-5, test_MAE=0.6, time=84.4, train_MAE=0.48, train_loss=0.48, val_MAE=0.569, val_loss=0.569]     Epoch 45:   5%|▍         | 46/1000 [1:04:46<22:19:01, 84.22s/it, lr=6.25e-5, test_MAE=0.6, time=84.4, train_MAE=0.48, train_loss=0.48, val_MAE=0.569, val_loss=0.569]Epoch 46:   5%|▍         | 46/1000 [1:04:46<22:19:01, 84.22s/it, lr=6.25e-5, test_MAE=0.6, time=84.4, train_MAE=0.48, train_loss=0.48, val_MAE=0.569, val_loss=0.569]Epoch 46:   5%|▍         | 46/1000 [1:06:10<22:19:01, 84.22s/it, lr=6.25e-5, test_MAE=0.603, time=83.6, train_MAE=0.475, train_loss=0.475, val_MAE=0.569, val_loss=0.569]Epoch 46:   5%|▍         | 47/1000 [1:06:10<22:14:41, 84.03s/it, lr=6.25e-5, test_MAE=0.603, time=83.6, train_MAE=0.475, train_loss=0.475, val_MAE=0.569, val_loss=0.569]Epoch 47:   5%|▍         | 47/1000 [1:06:10<22:14:41, 84.03s/it, lr=6.25e-5, test_MAE=0.603, time=83.6, train_MAE=0.475, train_loss=0.475, val_MAE=0.569, val_loss=0.569]Epoch 47:   5%|▍         | 47/1000 [1:07:33<22:14:41, 84.03s/it, lr=6.25e-5, test_MAE=0.604, time=83.6, train_MAE=0.487, train_loss=0.487, val_MAE=0.57, val_loss=0.57]  Epoch 47:   5%|▍         | 48/1000 [1:07:33<22:11:17, 83.91s/it, lr=6.25e-5, test_MAE=0.604, time=83.6, train_MAE=0.487, train_loss=0.487, val_MAE=0.57, val_loss=0.57]Epoch 48:   5%|▍         | 48/1000 [1:07:33<22:11:17, 83.91s/it, lr=6.25e-5, test_MAE=0.604, time=83.6, train_MAE=0.487, train_loss=0.487, val_MAE=0.57, val_loss=0.57]Epoch 48:   5%|▍         | 48/1000 [1:09:00<22:11:17, 83.91s/it, lr=6.25e-5, test_MAE=0.604, time=86.6, train_MAE=0.48, train_loss=0.48, val_MAE=0.576, val_loss=0.576]Epoch 48:   5%|▍         | 49/1000 [1:09:00<22:22:45, 84.72s/it, lr=6.25e-5, test_MAE=0.604, time=86.6, train_MAE=0.48, train_loss=0.48, val_MAE=0.576, val_loss=0.576]Epoch 49:   5%|▍         | 49/1000 [1:09:00<22:22:45, 84.72s/it, lr=6.25e-5, test_MAE=0.604, time=86.6, train_MAE=0.48, train_loss=0.48, val_MAE=0.576, val_loss=0.576]Epoch 49:   5%|▍         | 49/1000 [1:10:24<22:22:45, 84.72s/it, lr=6.25e-5, test_MAE=0.604, time=84.4, train_MAE=0.474, train_loss=0.474, val_MAE=0.57, val_loss=0.57]Epoch 49:   5%|▌         | 50/1000 [1:10:24<22:19:58, 84.63s/it, lr=6.25e-5, test_MAE=0.604, time=84.4, train_MAE=0.474, train_loss=0.474, val_MAE=0.57, val_loss=0.57]Epoch 50:   5%|▌         | 50/1000 [1:10:24<22:19:58, 84.63s/it, lr=6.25e-5, test_MAE=0.604, time=84.4, train_MAE=0.474, train_loss=0.474, val_MAE=0.57, val_loss=0.57]Epoch 50:   5%|▌         | 50/1000 [1:11:48<22:19:58, 84.63s/it, lr=6.25e-5, test_MAE=0.605, time=83.2, train_MAE=0.474, train_loss=0.474, val_MAE=0.571, val_loss=0.571]Epoch 50:   5%|▌         | 51/1000 [1:11:48<22:12:00, 84.22s/it, lr=6.25e-5, test_MAE=0.605, time=83.2, train_MAE=0.474, train_loss=0.474, val_MAE=0.571, val_loss=0.571]Epoch 51:   5%|▌         | 51/1000 [1:11:48<22:12:00, 84.22s/it, lr=6.25e-5, test_MAE=0.605, time=83.2, train_MAE=0.474, train_loss=0.474, val_MAE=0.571, val_loss=0.571]Epoch 51:   5%|▌         | 51/1000 [1:13:12<22:12:00, 84.22s/it, lr=6.25e-5, test_MAE=0.604, time=83.9, train_MAE=0.473, train_loss=0.473, val_MAE=0.573, val_loss=0.573]Epoch 51:   5%|▌         | 52/1000 [1:13:12<22:09:28, 84.14s/it, lr=6.25e-5, test_MAE=0.604, time=83.9, train_MAE=0.473, train_loss=0.473, val_MAE=0.573, val_loss=0.573]Epoch 52:   5%|▌         | 52/1000 [1:13:12<22:09:28, 84.14s/it, lr=6.25e-5, test_MAE=0.604, time=83.9, train_MAE=0.473, train_loss=0.473, val_MAE=0.573, val_loss=0.573]Epoch 52:   5%|▌         | 52/1000 [1:14:37<22:09:28, 84.14s/it, lr=6.25e-5, test_MAE=0.599, time=85.6, train_MAE=0.469, train_loss=0.469, val_MAE=0.566, val_loss=0.566]Epoch 52:   5%|▌         | 53/1000 [1:14:37<22:14:57, 84.58s/it, lr=6.25e-5, test_MAE=0.599, time=85.6, train_MAE=0.469, train_loss=0.469, val_MAE=0.566, val_loss=0.566]Epoch 53:   5%|▌         | 53/1000 [1:14:37<22:14:57, 84.58s/it, lr=6.25e-5, test_MAE=0.599, time=85.6, train_MAE=0.469, train_loss=0.469, val_MAE=0.566, val_loss=0.566]Epoch 53:   5%|▌         | 53/1000 [1:16:03<22:14:57, 84.58s/it, lr=6.25e-5, test_MAE=0.598, time=85.8, train_MAE=0.472, train_loss=0.472, val_MAE=0.565, val_loss=0.565]Epoch 53:   5%|▌         | 54/1000 [1:16:03<22:19:21, 84.95s/it, lr=6.25e-5, test_MAE=0.598, time=85.8, train_MAE=0.472, train_loss=0.472, val_MAE=0.565, val_loss=0.565]Epoch 54:   5%|▌         | 54/1000 [1:16:03<22:19:21, 84.95s/it, lr=6.25e-5, test_MAE=0.598, time=85.8, train_MAE=0.472, train_loss=0.472, val_MAE=0.565, val_loss=0.565]Epoch 54:   5%|▌         | 54/1000 [1:17:27<22:19:21, 84.95s/it, lr=6.25e-5, test_MAE=0.601, time=83.5, train_MAE=0.471, train_loss=0.471, val_MAE=0.567, val_loss=0.567]Epoch 54:   6%|▌         | 55/1000 [1:17:27<22:11:20, 84.53s/it, lr=6.25e-5, test_MAE=0.601, time=83.5, train_MAE=0.471, train_loss=0.471, val_MAE=0.567, val_loss=0.567]Epoch 55:   6%|▌         | 55/1000 [1:17:27<22:11:20, 84.53s/it, lr=6.25e-5, test_MAE=0.601, time=83.5, train_MAE=0.471, train_loss=0.471, val_MAE=0.567, val_loss=0.567]Epoch 55:   6%|▌         | 55/1000 [1:18:50<22:11:20, 84.53s/it, lr=6.25e-5, test_MAE=0.609, time=83.2, train_MAE=0.48, train_loss=0.48, val_MAE=0.571, val_loss=0.571]  Epoch 55:   6%|▌         | 56/1000 [1:18:50<22:03:45, 84.14s/it, lr=6.25e-5, test_MAE=0.609, time=83.2, train_MAE=0.48, train_loss=0.48, val_MAE=0.571, val_loss=0.571]Epoch 56:   6%|▌         | 56/1000 [1:18:50<22:03:45, 84.14s/it, lr=6.25e-5, test_MAE=0.609, time=83.2, train_MAE=0.48, train_loss=0.48, val_MAE=0.571, val_loss=0.571]Epoch 56:   6%|▌         | 56/1000 [1:20:14<22:03:45, 84.14s/it, lr=6.25e-5, test_MAE=0.608, time=83.9, train_MAE=0.47, train_loss=0.47, val_MAE=0.567, val_loss=0.567]Epoch 56:   6%|▌         | 57/1000 [1:20:14<22:01:24, 84.08s/it, lr=6.25e-5, test_MAE=0.608, time=83.9, train_MAE=0.47, train_loss=0.47, val_MAE=0.567, val_loss=0.567]Epoch 57:   6%|▌         | 57/1000 [1:20:14<22:01:24, 84.08s/it, lr=6.25e-5, test_MAE=0.608, time=83.9, train_MAE=0.47, train_loss=0.47, val_MAE=0.567, val_loss=0.567]Epoch 57:   6%|▌         | 57/1000 [1:21:37<22:01:24, 84.08s/it, lr=6.25e-5, test_MAE=0.609, time=83.5, train_MAE=0.473, train_loss=0.473, val_MAE=0.574, val_loss=0.574]Epoch 57:   6%|▌         | 58/1000 [1:21:37<21:57:35, 83.92s/it, lr=6.25e-5, test_MAE=0.609, time=83.5, train_MAE=0.473, train_loss=0.473, val_MAE=0.574, val_loss=0.574]Epoch 58:   6%|▌         | 58/1000 [1:21:37<21:57:35, 83.92s/it, lr=6.25e-5, test_MAE=0.609, time=83.5, train_MAE=0.473, train_loss=0.473, val_MAE=0.574, val_loss=0.574]Epoch 58:   6%|▌         | 58/1000 [1:23:01<21:57:35, 83.92s/it, lr=6.25e-5, test_MAE=0.607, time=83.5, train_MAE=0.47, train_loss=0.47, val_MAE=0.577, val_loss=0.577]  Epoch 58:   6%|▌         | 59/1000 [1:23:01<21:54:30, 83.82s/it, lr=6.25e-5, test_MAE=0.607, time=83.5, train_MAE=0.47, train_loss=0.47, val_MAE=0.577, val_loss=0.577]Epoch 59:   6%|▌         | 59/1000 [1:23:01<21:54:30, 83.82s/it, lr=6.25e-5, test_MAE=0.607, time=83.5, train_MAE=0.47, train_loss=0.47, val_MAE=0.577, val_loss=0.577]Epoch 59:   6%|▌         | 59/1000 [1:24:24<21:54:30, 83.82s/it, lr=6.25e-5, test_MAE=0.615, time=83.6, train_MAE=0.47, train_loss=0.47, val_MAE=0.583, val_loss=0.583]Epoch    60: reducing learning rate of group 0 to 3.1250e-05.
Epoch 59:   6%|▌         | 60/1000 [1:24:24<21:52:02, 83.75s/it, lr=6.25e-5, test_MAE=0.615, time=83.6, train_MAE=0.47, train_loss=0.47, val_MAE=0.583, val_loss=0.583]Epoch 60:   6%|▌         | 60/1000 [1:24:24<21:52:02, 83.75s/it, lr=6.25e-5, test_MAE=0.615, time=83.6, train_MAE=0.47, train_loss=0.47, val_MAE=0.583, val_loss=0.583]Epoch 60:   6%|▌         | 60/1000 [1:25:47<21:52:02, 83.75s/it, lr=3.13e-5, test_MAE=0.611, time=82.8, train_MAE=0.475, train_loss=0.475, val_MAE=0.577, val_loss=0.577]Epoch 60:   6%|▌         | 61/1000 [1:25:47<21:46:06, 83.46s/it, lr=3.13e-5, test_MAE=0.611, time=82.8, train_MAE=0.475, train_loss=0.475, val_MAE=0.577, val_loss=0.577]Epoch 61:   6%|▌         | 61/1000 [1:25:47<21:46:06, 83.46s/it, lr=3.13e-5, test_MAE=0.611, time=82.8, train_MAE=0.475, train_loss=0.475, val_MAE=0.577, val_loss=0.577]Epoch 61:   6%|▌         | 61/1000 [1:27:10<21:46:06, 83.46s/it, lr=3.13e-5, test_MAE=0.606, time=83.1, train_MAE=0.464, train_loss=0.464, val_MAE=0.57, val_loss=0.57]  Epoch 61:   6%|▌         | 62/1000 [1:27:10<21:43:10, 83.36s/it, lr=3.13e-5, test_MAE=0.606, time=83.1, train_MAE=0.464, train_loss=0.464, val_MAE=0.57, val_loss=0.57]Epoch 62:   6%|▌         | 62/1000 [1:27:10<21:43:10, 83.36s/it, lr=3.13e-5, test_MAE=0.606, time=83.1, train_MAE=0.464, train_loss=0.464, val_MAE=0.57, val_loss=0.57]Epoch 62:   6%|▌         | 62/1000 [1:28:36<21:43:10, 83.36s/it, lr=3.13e-5, test_MAE=0.603, time=86, train_MAE=0.466, train_loss=0.466, val_MAE=0.569, val_loss=0.569]Epoch 62:   6%|▋         | 63/1000 [1:28:36<21:54:25, 84.17s/it, lr=3.13e-5, test_MAE=0.603, time=86, train_MAE=0.466, train_loss=0.466, val_MAE=0.569, val_loss=0.569]Epoch 63:   6%|▋         | 63/1000 [1:28:36<21:54:25, 84.17s/it, lr=3.13e-5, test_MAE=0.603, time=86, train_MAE=0.466, train_loss=0.466, val_MAE=0.569, val_loss=0.569]Epoch 63:   6%|▋         | 63/1000 [1:30:01<21:54:25, 84.17s/it, lr=3.13e-5, test_MAE=0.605, time=84.7, train_MAE=0.466, train_loss=0.466, val_MAE=0.57, val_loss=0.57]Epoch 63:   6%|▋         | 64/1000 [1:30:01<21:55:49, 84.35s/it, lr=3.13e-5, test_MAE=0.605, time=84.7, train_MAE=0.466, train_loss=0.466, val_MAE=0.57, val_loss=0.57]Epoch 64:   6%|▋         | 64/1000 [1:30:01<21:55:49, 84.35s/it, lr=3.13e-5, test_MAE=0.605, time=84.7, train_MAE=0.466, train_loss=0.466, val_MAE=0.57, val_loss=0.57]Epoch 64:   6%|▋         | 64/1000 [1:31:24<21:55:49, 84.35s/it, lr=3.13e-5, test_MAE=0.604, time=82.8, train_MAE=0.464, train_loss=0.464, val_MAE=0.57, val_loss=0.57]Epoch 64:   6%|▋         | 65/1000 [1:31:24<21:47:03, 83.87s/it, lr=3.13e-5, test_MAE=0.604, time=82.8, train_MAE=0.464, train_loss=0.464, val_MAE=0.57, val_loss=0.57]Epoch 65:   6%|▋         | 65/1000 [1:31:24<21:47:03, 83.87s/it, lr=3.13e-5, test_MAE=0.604, time=82.8, train_MAE=0.464, train_loss=0.464, val_MAE=0.57, val_loss=0.57]Epoch 65:   6%|▋         | 65/1000 [1:32:47<21:47:03, 83.87s/it, lr=3.13e-5, test_MAE=0.601, time=83.1, train_MAE=0.462, train_loss=0.462, val_MAE=0.566, val_loss=0.566]Epoch    66: reducing learning rate of group 0 to 1.5625e-05.
Epoch 65:   7%|▋         | 66/1000 [1:32:47<21:42:22, 83.66s/it, lr=3.13e-5, test_MAE=0.601, time=83.1, train_MAE=0.462, train_loss=0.462, val_MAE=0.566, val_loss=0.566]Epoch 66:   7%|▋         | 66/1000 [1:32:47<21:42:22, 83.66s/it, lr=3.13e-5, test_MAE=0.601, time=83.1, train_MAE=0.462, train_loss=0.462, val_MAE=0.566, val_loss=0.566]Epoch 66:   7%|▋         | 66/1000 [1:34:10<21:42:22, 83.66s/it, lr=1.56e-5, test_MAE=0.601, time=82.7, train_MAE=0.459, train_loss=0.459, val_MAE=0.566, val_loss=0.566]Epoch 66:   7%|▋         | 67/1000 [1:34:10<21:36:44, 83.39s/it, lr=1.56e-5, test_MAE=0.601, time=82.7, train_MAE=0.459, train_loss=0.459, val_MAE=0.566, val_loss=0.566]Epoch 67:   7%|▋         | 67/1000 [1:34:10<21:36:44, 83.39s/it, lr=1.56e-5, test_MAE=0.601, time=82.7, train_MAE=0.459, train_loss=0.459, val_MAE=0.566, val_loss=0.566]Epoch 67:   7%|▋         | 67/1000 [1:35:32<21:36:44, 83.39s/it, lr=1.56e-5, test_MAE=0.601, time=82.4, train_MAE=0.464, train_loss=0.464, val_MAE=0.566, val_loss=0.566]Epoch 67:   7%|▋         | 68/1000 [1:35:32<21:30:56, 83.11s/it, lr=1.56e-5, test_MAE=0.601, time=82.4, train_MAE=0.464, train_loss=0.464, val_MAE=0.566, val_loss=0.566]Epoch 68:   7%|▋         | 68/1000 [1:35:32<21:30:56, 83.11s/it, lr=1.56e-5, test_MAE=0.601, time=82.4, train_MAE=0.464, train_loss=0.464, val_MAE=0.566, val_loss=0.566]Epoch 68:   7%|▋         | 68/1000 [1:36:55<21:30:56, 83.11s/it, lr=1.56e-5, test_MAE=0.603, time=82.8, train_MAE=0.459, train_loss=0.459, val_MAE=0.569, val_loss=0.569]Epoch 68:   7%|▋         | 69/1000 [1:36:55<21:28:24, 83.03s/it, lr=1.56e-5, test_MAE=0.603, time=82.8, train_MAE=0.459, train_loss=0.459, val_MAE=0.569, val_loss=0.569]Epoch 69:   7%|▋         | 69/1000 [1:36:55<21:28:24, 83.03s/it, lr=1.56e-5, test_MAE=0.603, time=82.8, train_MAE=0.459, train_loss=0.459, val_MAE=0.569, val_loss=0.569]Epoch 69:   7%|▋         | 69/1000 [1:38:17<21:28:24, 83.03s/it, lr=1.56e-5, test_MAE=0.604, time=81.5, train_MAE=0.461, train_loss=0.461, val_MAE=0.569, val_loss=0.569]Epoch 69:   7%|▋         | 70/1000 [1:38:17<21:20:10, 82.59s/it, lr=1.56e-5, test_MAE=0.604, time=81.5, train_MAE=0.461, train_loss=0.461, val_MAE=0.569, val_loss=0.569]Epoch 70:   7%|▋         | 70/1000 [1:38:17<21:20:10, 82.59s/it, lr=1.56e-5, test_MAE=0.604, time=81.5, train_MAE=0.461, train_loss=0.461, val_MAE=0.569, val_loss=0.569]Epoch 70:   7%|▋         | 70/1000 [1:39:36<21:20:10, 82.59s/it, lr=1.56e-5, test_MAE=0.602, time=79.2, train_MAE=0.464, train_loss=0.464, val_MAE=0.569, val_loss=0.569]Epoch 70:   7%|▋         | 71/1000 [1:39:36<21:03:14, 81.59s/it, lr=1.56e-5, test_MAE=0.602, time=79.2, train_MAE=0.464, train_loss=0.464, val_MAE=0.569, val_loss=0.569]Epoch 71:   7%|▋         | 71/1000 [1:39:36<21:03:14, 81.59s/it, lr=1.56e-5, test_MAE=0.602, time=79.2, train_MAE=0.464, train_loss=0.464, val_MAE=0.569, val_loss=0.569]Epoch 71:   7%|▋         | 71/1000 [1:40:54<21:03:14, 81.59s/it, lr=1.56e-5, test_MAE=0.602, time=78.3, train_MAE=0.46, train_loss=0.46, val_MAE=0.567, val_loss=0.567]  Epoch    72: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 71:   7%|▋         | 71/1000 [1:40:54<22:00:25, 85.28s/it, lr=1.56e-5, test_MAE=0.602, time=78.3, train_MAE=0.46, train_loss=0.46, val_MAE=0.567, val_loss=0.567]
Test MAE: 0.6022
Train MAE: 0.4493
Convergence Time (Epochs): 71.0000
TOTAL TIME TAKEN: 6098.1669s
AVG TIME PER EPOCH: 84.0754s
