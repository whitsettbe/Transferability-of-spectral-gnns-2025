I'm echoing to stdout
I'm echoing to stderr
My JobID is 58311224
I have 4 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.1214s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 16, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 4, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'poly_mlp', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_sub', 'num_eigs': 16, 'bias_mode': 'spatial', 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 0.0, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/aug07/zinc_train_rec.csv', 'test': 'supp_data/molecules/aug07/zinc_test_rec.csv', 'val': 'supp_data/molecules/aug07/zinc_val_rec.csv'}, 'fixMissingPhi1': False, 'extraOrtho': False, 'doublePrecision': True, 'eigval_hidden_dim': 100, 'eigval_num_hidden_layer': 3, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [06:06<?, ?it/s, lr=0.001, test_MAE=1.06, time=366, train_MAE=0.944, train_loss=0.944, val_MAE=1.03, val_loss=1.03]Epoch 0:   0%|          | 1/1000 [06:06<101:37:50, 366.24s/it, lr=0.001, test_MAE=1.06, time=366, train_MAE=0.944, train_loss=0.944, val_MAE=1.03, val_loss=1.03]Epoch 1:   0%|          | 1/1000 [06:06<101:37:50, 366.24s/it, lr=0.001, test_MAE=1.06, time=366, train_MAE=0.944, train_loss=0.944, val_MAE=1.03, val_loss=1.03]Epoch 1:   0%|          | 1/1000 [11:53<101:37:50, 366.24s/it, lr=0.001, test_MAE=0.948, time=347, train_MAE=0.702, train_loss=0.702, val_MAE=0.904, val_loss=0.904]Epoch 1:   0%|          | 2/1000 [11:53<99:58:20, 360.62s/it, lr=0.001, test_MAE=0.948, time=347, train_MAE=0.702, train_loss=0.702, val_MAE=0.904, val_loss=0.904] Epoch 2:   0%|          | 2/1000 [11:53<99:58:20, 360.62s/it, lr=0.001, test_MAE=0.948, time=347, train_MAE=0.702, train_loss=0.702, val_MAE=0.904, val_loss=0.904]Epoch 2:   0%|          | 2/1000 [17:41<99:58:20, 360.62s/it, lr=0.001, test_MAE=0.836, time=348, train_MAE=0.675, train_loss=0.675, val_MAE=0.784, val_loss=0.784]Epoch 2:   0%|          | 3/1000 [17:41<98:48:49, 356.80s/it, lr=0.001, test_MAE=0.836, time=348, train_MAE=0.675, train_loss=0.675, val_MAE=0.784, val_loss=0.784]Epoch 3:   0%|          | 3/1000 [17:41<98:48:49, 356.80s/it, lr=0.001, test_MAE=0.836, time=348, train_MAE=0.675, train_loss=0.675, val_MAE=0.784, val_loss=0.784]Epoch 3:   0%|          | 3/1000 [23:28<98:48:49, 356.80s/it, lr=0.001, test_MAE=0.717, time=347, train_MAE=0.635, train_loss=0.635, val_MAE=0.68, val_loss=0.68]  Epoch 3:   0%|          | 4/1000 [23:28<97:55:31, 353.95s/it, lr=0.001, test_MAE=0.717, time=347, train_MAE=0.635, train_loss=0.635, val_MAE=0.68, val_loss=0.68]Epoch 4:   0%|          | 4/1000 [23:28<97:55:31, 353.95s/it, lr=0.001, test_MAE=0.717, time=347, train_MAE=0.635, train_loss=0.635, val_MAE=0.68, val_loss=0.68]Epoch 4:   0%|          | 4/1000 [29:03<97:55:31, 353.95s/it, lr=0.001, test_MAE=0.905, time=334, train_MAE=0.635, train_loss=0.635, val_MAE=0.851, val_loss=0.851]Epoch 4:   0%|          | 5/1000 [29:03<96:11:35, 348.04s/it, lr=0.001, test_MAE=0.905, time=334, train_MAE=0.635, train_loss=0.635, val_MAE=0.851, val_loss=0.851]Epoch 5:   0%|          | 5/1000 [29:03<96:11:35, 348.04s/it, lr=0.001, test_MAE=0.905, time=334, train_MAE=0.635, train_loss=0.635, val_MAE=0.851, val_loss=0.851]Epoch 5:   0%|          | 5/1000 [34:23<96:11:35, 348.04s/it, lr=0.001, test_MAE=0.773, time=320, train_MAE=0.633, train_loss=0.633, val_MAE=0.712, val_loss=0.712]Epoch 5:   1%|          | 6/1000 [34:23<93:48:28, 339.75s/it, lr=0.001, test_MAE=0.773, time=320, train_MAE=0.633, train_loss=0.633, val_MAE=0.712, val_loss=0.712]Epoch 6:   1%|          | 6/1000 [34:23<93:48:28, 339.75s/it, lr=0.001, test_MAE=0.773, time=320, train_MAE=0.633, train_loss=0.633, val_MAE=0.712, val_loss=0.712]Epoch 6:   1%|          | 6/1000 [39:40<93:48:28, 339.75s/it, lr=0.001, test_MAE=0.795, time=317, train_MAE=0.625, train_loss=0.625, val_MAE=0.758, val_loss=0.758]Epoch 6:   1%|          | 7/1000 [39:40<91:48:02, 332.81s/it, lr=0.001, test_MAE=0.795, time=317, train_MAE=0.625, train_loss=0.625, val_MAE=0.758, val_loss=0.758]Epoch 7:   1%|          | 7/1000 [39:40<91:48:02, 332.81s/it, lr=0.001, test_MAE=0.795, time=317, train_MAE=0.625, train_loss=0.625, val_MAE=0.758, val_loss=0.758]Epoch 7:   1%|          | 7/1000 [44:56<91:48:02, 332.81s/it, lr=0.001, test_MAE=0.656, time=316, train_MAE=0.621, train_loss=0.621, val_MAE=0.633, val_loss=0.633]Epoch 7:   1%|          | 8/1000 [44:56<90:21:34, 327.92s/it, lr=0.001, test_MAE=0.656, time=316, train_MAE=0.621, train_loss=0.621, val_MAE=0.633, val_loss=0.633]Epoch 8:   1%|          | 8/1000 [44:56<90:21:34, 327.92s/it, lr=0.001, test_MAE=0.656, time=316, train_MAE=0.621, train_loss=0.621, val_MAE=0.633, val_loss=0.633]Epoch 8:   1%|          | 8/1000 [50:13<90:21:34, 327.92s/it, lr=0.001, test_MAE=0.789, time=317, train_MAE=0.61, train_loss=0.61, val_MAE=0.732, val_loss=0.732]  Epoch 8:   1%|          | 9/1000 [50:13<89:19:50, 324.51s/it, lr=0.001, test_MAE=0.789, time=317, train_MAE=0.61, train_loss=0.61, val_MAE=0.732, val_loss=0.732]Epoch 9:   1%|          | 9/1000 [50:13<89:19:50, 324.51s/it, lr=0.001, test_MAE=0.789, time=317, train_MAE=0.61, train_loss=0.61, val_MAE=0.732, val_loss=0.732]Epoch 9:   1%|          | 9/1000 [55:29<89:19:50, 324.51s/it, lr=0.001, test_MAE=0.657, time=316, train_MAE=0.605, train_loss=0.605, val_MAE=0.594, val_loss=0.594]Epoch 9:   1%|          | 10/1000 [55:29<88:34:47, 322.11s/it, lr=0.001, test_MAE=0.657, time=316, train_MAE=0.605, train_loss=0.605, val_MAE=0.594, val_loss=0.594]Epoch 10:   1%|          | 10/1000 [55:29<88:34:47, 322.11s/it, lr=0.001, test_MAE=0.657, time=316, train_MAE=0.605, train_loss=0.605, val_MAE=0.594, val_loss=0.594]Epoch 10:   1%|          | 10/1000 [1:00:46<88:34:47, 322.11s/it, lr=0.001, test_MAE=0.685, time=317, train_MAE=0.593, train_loss=0.593, val_MAE=0.63, val_loss=0.63]Epoch 10:   1%|          | 11/1000 [1:00:46<88:02:22, 320.47s/it, lr=0.001, test_MAE=0.685, time=317, train_MAE=0.593, train_loss=0.593, val_MAE=0.63, val_loss=0.63]Epoch 11:   1%|          | 11/1000 [1:00:46<88:02:22, 320.47s/it, lr=0.001, test_MAE=0.685, time=317, train_MAE=0.593, train_loss=0.593, val_MAE=0.63, val_loss=0.63]Epoch 11:   1%|          | 11/1000 [1:06:02<88:02:22, 320.47s/it, lr=0.001, test_MAE=1.17, time=316, train_MAE=0.588, train_loss=0.588, val_MAE=1.16, val_loss=1.16] Epoch 11:   1%|          | 12/1000 [1:06:02<87:36:06, 319.20s/it, lr=0.001, test_MAE=1.17, time=316, train_MAE=0.588, train_loss=0.588, val_MAE=1.16, val_loss=1.16]Epoch 12:   1%|          | 12/1000 [1:06:02<87:36:06, 319.20s/it, lr=0.001, test_MAE=1.17, time=316, train_MAE=0.588, train_loss=0.588, val_MAE=1.16, val_loss=1.16]Epoch 12:   1%|          | 12/1000 [1:11:19<87:36:06, 319.20s/it, lr=0.001, test_MAE=0.678, time=317, train_MAE=0.59, train_loss=0.59, val_MAE=0.625, val_loss=0.625]Epoch 12:   1%|▏         | 13/1000 [1:11:19<87:18:16, 318.44s/it, lr=0.001, test_MAE=0.678, time=317, train_MAE=0.59, train_loss=0.59, val_MAE=0.625, val_loss=0.625]Epoch 13:   1%|▏         | 13/1000 [1:11:19<87:18:16, 318.44s/it, lr=0.001, test_MAE=0.678, time=317, train_MAE=0.59, train_loss=0.59, val_MAE=0.625, val_loss=0.625]Epoch 13:   1%|▏         | 13/1000 [1:16:35<87:18:16, 318.44s/it, lr=0.001, test_MAE=0.63, time=316, train_MAE=0.585, train_loss=0.585, val_MAE=0.599, val_loss=0.599]Epoch 13:   1%|▏         | 14/1000 [1:16:35<87:03:23, 317.85s/it, lr=0.001, test_MAE=0.63, time=316, train_MAE=0.585, train_loss=0.585, val_MAE=0.599, val_loss=0.599]Epoch 14:   1%|▏         | 14/1000 [1:16:35<87:03:23, 317.85s/it, lr=0.001, test_MAE=0.63, time=316, train_MAE=0.585, train_loss=0.585, val_MAE=0.599, val_loss=0.599]Epoch 14:   1%|▏         | 14/1000 [1:21:52<87:03:23, 317.85s/it, lr=0.001, test_MAE=0.844, time=316, train_MAE=0.568, train_loss=0.568, val_MAE=0.786, val_loss=0.786]Epoch 14:   2%|▏         | 15/1000 [1:21:52<86:51:20, 317.44s/it, lr=0.001, test_MAE=0.844, time=316, train_MAE=0.568, train_loss=0.568, val_MAE=0.786, val_loss=0.786]Epoch 15:   2%|▏         | 15/1000 [1:21:52<86:51:20, 317.44s/it, lr=0.001, test_MAE=0.844, time=316, train_MAE=0.568, train_loss=0.568, val_MAE=0.786, val_loss=0.786]Epoch 15:   2%|▏         | 15/1000 [1:27:08<86:51:20, 317.44s/it, lr=0.001, test_MAE=0.62, time=316, train_MAE=0.572, train_loss=0.572, val_MAE=0.587, val_loss=0.587] Epoch 15:   2%|▏         | 16/1000 [1:27:08<86:41:19, 317.15s/it, lr=0.001, test_MAE=0.62, time=316, train_MAE=0.572, train_loss=0.572, val_MAE=0.587, val_loss=0.587]Epoch 16:   2%|▏         | 16/1000 [1:27:08<86:41:19, 317.15s/it, lr=0.001, test_MAE=0.62, time=316, train_MAE=0.572, train_loss=0.572, val_MAE=0.587, val_loss=0.587]Epoch 16:   2%|▏         | 16/1000 [1:32:25<86:41:19, 317.15s/it, lr=0.001, test_MAE=0.656, time=317, train_MAE=0.557, train_loss=0.557, val_MAE=0.616, val_loss=0.616]Epoch 16:   2%|▏         | 17/1000 [1:32:25<86:34:38, 317.07s/it, lr=0.001, test_MAE=0.656, time=317, train_MAE=0.557, train_loss=0.557, val_MAE=0.616, val_loss=0.616]Epoch 17:   2%|▏         | 17/1000 [1:32:25<86:34:38, 317.07s/it, lr=0.001, test_MAE=0.656, time=317, train_MAE=0.557, train_loss=0.557, val_MAE=0.616, val_loss=0.616]Epoch 17:   2%|▏         | 17/1000 [1:37:42<86:34:38, 317.07s/it, lr=0.001, test_MAE=0.628, time=317, train_MAE=0.563, train_loss=0.563, val_MAE=0.582, val_loss=0.582]Epoch 17:   2%|▏         | 18/1000 [1:37:42<86:27:17, 316.94s/it, lr=0.001, test_MAE=0.628, time=317, train_MAE=0.563, train_loss=0.563, val_MAE=0.582, val_loss=0.582]Epoch 18:   2%|▏         | 18/1000 [1:37:42<86:27:17, 316.94s/it, lr=0.001, test_MAE=0.628, time=317, train_MAE=0.563, train_loss=0.563, val_MAE=0.582, val_loss=0.582]Epoch 18:   2%|▏         | 18/1000 [1:42:58<86:27:17, 316.94s/it, lr=0.001, test_MAE=0.875, time=316, train_MAE=0.55, train_loss=0.55, val_MAE=0.811, val_loss=0.811]  Epoch 18:   2%|▏         | 19/1000 [1:42:58<86:19:14, 316.77s/it, lr=0.001, test_MAE=0.875, time=316, train_MAE=0.55, train_loss=0.55, val_MAE=0.811, val_loss=0.811]Epoch 19:   2%|▏         | 19/1000 [1:42:58<86:19:14, 316.77s/it, lr=0.001, test_MAE=0.875, time=316, train_MAE=0.55, train_loss=0.55, val_MAE=0.811, val_loss=0.811]Epoch 19:   2%|▏         | 19/1000 [1:48:15<86:19:14, 316.77s/it, lr=0.001, test_MAE=0.822, time=316, train_MAE=0.551, train_loss=0.551, val_MAE=0.764, val_loss=0.764]Epoch 19:   2%|▏         | 20/1000 [1:48:15<86:12:37, 316.69s/it, lr=0.001, test_MAE=0.822, time=316, train_MAE=0.551, train_loss=0.551, val_MAE=0.764, val_loss=0.764]Epoch 20:   2%|▏         | 20/1000 [1:48:15<86:12:37, 316.69s/it, lr=0.001, test_MAE=0.822, time=316, train_MAE=0.551, train_loss=0.551, val_MAE=0.764, val_loss=0.764]Epoch 20:   2%|▏         | 20/1000 [1:53:31<86:12:37, 316.69s/it, lr=0.001, test_MAE=0.679, time=316, train_MAE=0.55, train_loss=0.55, val_MAE=0.627, val_loss=0.627]  Epoch 20:   2%|▏         | 21/1000 [1:53:31<86:05:50, 316.60s/it, lr=0.001, test_MAE=0.679, time=316, train_MAE=0.55, train_loss=0.55, val_MAE=0.627, val_loss=0.627]Epoch 21:   2%|▏         | 21/1000 [1:53:31<86:05:50, 316.60s/it, lr=0.001, test_MAE=0.679, time=316, train_MAE=0.55, train_loss=0.55, val_MAE=0.627, val_loss=0.627]Epoch 21:   2%|▏         | 21/1000 [1:58:48<86:05:50, 316.60s/it, lr=0.001, test_MAE=0.778, time=317, train_MAE=0.549, train_loss=0.549, val_MAE=0.754, val_loss=0.754]Epoch 21:   2%|▏         | 22/1000 [1:58:48<86:00:14, 316.58s/it, lr=0.001, test_MAE=0.778, time=317, train_MAE=0.549, train_loss=0.549, val_MAE=0.754, val_loss=0.754]Epoch 22:   2%|▏         | 22/1000 [1:58:48<86:00:14, 316.58s/it, lr=0.001, test_MAE=0.778, time=317, train_MAE=0.549, train_loss=0.549, val_MAE=0.754, val_loss=0.754]Epoch 22:   2%|▏         | 22/1000 [2:04:04<86:00:14, 316.58s/it, lr=0.001, test_MAE=0.658, time=316, train_MAE=0.553, train_loss=0.553, val_MAE=0.618, val_loss=0.618]Epoch 22:   2%|▏         | 23/1000 [2:04:04<85:53:40, 316.50s/it, lr=0.001, test_MAE=0.658, time=316, train_MAE=0.553, train_loss=0.553, val_MAE=0.618, val_loss=0.618]Epoch 23:   2%|▏         | 23/1000 [2:04:04<85:53:40, 316.50s/it, lr=0.001, test_MAE=0.658, time=316, train_MAE=0.553, train_loss=0.553, val_MAE=0.618, val_loss=0.618]Epoch 23:   2%|▏         | 23/1000 [2:09:20<85:53:40, 316.50s/it, lr=0.001, test_MAE=0.634, time=316, train_MAE=0.536, train_loss=0.536, val_MAE=0.584, val_loss=0.584]Epoch    24: reducing learning rate of group 0 to 5.0000e-04.
Epoch 23:   2%|▏         | 24/1000 [2:09:20<85:47:50, 316.47s/it, lr=0.001, test_MAE=0.634, time=316, train_MAE=0.536, train_loss=0.536, val_MAE=0.584, val_loss=0.584]Epoch 24:   2%|▏         | 24/1000 [2:09:20<85:47:50, 316.47s/it, lr=0.001, test_MAE=0.634, time=316, train_MAE=0.536, train_loss=0.536, val_MAE=0.584, val_loss=0.584]Epoch 24:   2%|▏         | 24/1000 [2:14:37<85:47:50, 316.47s/it, lr=0.0005, test_MAE=0.687, time=316, train_MAE=0.516, train_loss=0.516, val_MAE=0.656, val_loss=0.656]Epoch 24:   2%|▎         | 25/1000 [2:14:37<85:42:11, 316.44s/it, lr=0.0005, test_MAE=0.687, time=316, train_MAE=0.516, train_loss=0.516, val_MAE=0.656, val_loss=0.656]Epoch 25:   2%|▎         | 25/1000 [2:14:37<85:42:11, 316.44s/it, lr=0.0005, test_MAE=0.687, time=316, train_MAE=0.516, train_loss=0.516, val_MAE=0.656, val_loss=0.656]Epoch 25:   2%|▎         | 25/1000 [2:19:54<85:42:11, 316.44s/it, lr=0.0005, test_MAE=0.636, time=317, train_MAE=0.5, train_loss=0.5, val_MAE=0.585, val_loss=0.585]    Epoch 25:   3%|▎         | 26/1000 [2:19:54<85:40:12, 316.65s/it, lr=0.0005, test_MAE=0.636, time=317, train_MAE=0.5, train_loss=0.5, val_MAE=0.585, val_loss=0.585]Epoch 26:   3%|▎         | 26/1000 [2:19:54<85:40:12, 316.65s/it, lr=0.0005, test_MAE=0.636, time=317, train_MAE=0.5, train_loss=0.5, val_MAE=0.585, val_loss=0.585]Epoch 26:   3%|▎         | 26/1000 [2:25:10<85:40:12, 316.65s/it, lr=0.0005, test_MAE=0.625, time=316, train_MAE=0.504, train_loss=0.504, val_MAE=0.584, val_loss=0.584]Epoch 26:   3%|▎         | 27/1000 [2:25:10<85:32:31, 316.50s/it, lr=0.0005, test_MAE=0.625, time=316, train_MAE=0.504, train_loss=0.504, val_MAE=0.584, val_loss=0.584]Epoch 27:   3%|▎         | 27/1000 [2:25:10<85:32:31, 316.50s/it, lr=0.0005, test_MAE=0.625, time=316, train_MAE=0.504, train_loss=0.504, val_MAE=0.584, val_loss=0.584]Epoch 27:   3%|▎         | 27/1000 [2:30:26<85:32:31, 316.50s/it, lr=0.0005, test_MAE=0.683, time=317, train_MAE=0.495, train_loss=0.495, val_MAE=0.647, val_loss=0.647]Epoch 27:   3%|▎         | 28/1000 [2:30:26<85:27:31, 316.51s/it, lr=0.0005, test_MAE=0.683, time=317, train_MAE=0.495, train_loss=0.495, val_MAE=0.647, val_loss=0.647]Epoch 28:   3%|▎         | 28/1000 [2:30:26<85:27:31, 316.51s/it, lr=0.0005, test_MAE=0.683, time=317, train_MAE=0.495, train_loss=0.495, val_MAE=0.647, val_loss=0.647]Epoch 28:   3%|▎         | 28/1000 [2:35:43<85:27:31, 316.51s/it, lr=0.0005, test_MAE=0.621, time=317, train_MAE=0.511, train_loss=0.511, val_MAE=0.569, val_loss=0.569]Epoch 28:   3%|▎         | 29/1000 [2:35:43<85:22:41, 316.54s/it, lr=0.0005, test_MAE=0.621, time=317, train_MAE=0.511, train_loss=0.511, val_MAE=0.569, val_loss=0.569]Epoch 29:   3%|▎         | 29/1000 [2:35:43<85:22:41, 316.54s/it, lr=0.0005, test_MAE=0.621, time=317, train_MAE=0.511, train_loss=0.511, val_MAE=0.569, val_loss=0.569]Epoch 29:   3%|▎         | 29/1000 [2:41:00<85:22:41, 316.54s/it, lr=0.0005, test_MAE=0.716, time=317, train_MAE=0.493, train_loss=0.493, val_MAE=0.67, val_loss=0.67]  Epoch 29:   3%|▎         | 30/1000 [2:41:00<85:18:12, 316.59s/it, lr=0.0005, test_MAE=0.716, time=317, train_MAE=0.493, train_loss=0.493, val_MAE=0.67, val_loss=0.67]Epoch 30:   3%|▎         | 30/1000 [2:41:00<85:18:12, 316.59s/it, lr=0.0005, test_MAE=0.716, time=317, train_MAE=0.493, train_loss=0.493, val_MAE=0.67, val_loss=0.67]Epoch 30:   3%|▎         | 30/1000 [2:46:16<85:18:12, 316.59s/it, lr=0.0005, test_MAE=0.625, time=316, train_MAE=0.497, train_loss=0.497, val_MAE=0.6, val_loss=0.6]  Epoch 30:   3%|▎         | 31/1000 [2:46:16<85:11:45, 316.52s/it, lr=0.0005, test_MAE=0.625, time=316, train_MAE=0.497, train_loss=0.497, val_MAE=0.6, val_loss=0.6]Epoch 31:   3%|▎         | 31/1000 [2:46:16<85:11:45, 316.52s/it, lr=0.0005, test_MAE=0.625, time=316, train_MAE=0.497, train_loss=0.497, val_MAE=0.6, val_loss=0.6]Epoch 31:   3%|▎         | 31/1000 [2:51:32<85:11:45, 316.52s/it, lr=0.0005, test_MAE=0.659, time=316, train_MAE=0.492, train_loss=0.492, val_MAE=0.609, val_loss=0.609]Epoch 31:   3%|▎         | 32/1000 [2:51:32<85:05:36, 316.46s/it, lr=0.0005, test_MAE=0.659, time=316, train_MAE=0.492, train_loss=0.492, val_MAE=0.609, val_loss=0.609]Epoch 32:   3%|▎         | 32/1000 [2:51:32<85:05:36, 316.46s/it, lr=0.0005, test_MAE=0.659, time=316, train_MAE=0.492, train_loss=0.492, val_MAE=0.609, val_loss=0.609]Epoch 32:   3%|▎         | 32/1000 [2:56:49<85:05:36, 316.46s/it, lr=0.0005, test_MAE=0.66, time=316, train_MAE=0.489, train_loss=0.489, val_MAE=0.593, val_loss=0.593] Epoch 32:   3%|▎         | 33/1000 [2:56:49<85:00:24, 316.47s/it, lr=0.0005, test_MAE=0.66, time=316, train_MAE=0.489, train_loss=0.489, val_MAE=0.593, val_loss=0.593]Epoch 33:   3%|▎         | 33/1000 [2:56:49<85:00:24, 316.47s/it, lr=0.0005, test_MAE=0.66, time=316, train_MAE=0.489, train_loss=0.489, val_MAE=0.593, val_loss=0.593]Epoch 33:   3%|▎         | 33/1000 [3:02:05<85:00:24, 316.47s/it, lr=0.0005, test_MAE=0.622, time=316, train_MAE=0.472, train_loss=0.472, val_MAE=0.58, val_loss=0.58] Epoch 33:   3%|▎         | 34/1000 [3:02:05<84:54:45, 316.44s/it, lr=0.0005, test_MAE=0.622, time=316, train_MAE=0.472, train_loss=0.472, val_MAE=0.58, val_loss=0.58]Epoch 34:   3%|▎         | 34/1000 [3:02:05<84:54:45, 316.44s/it, lr=0.0005, test_MAE=0.622, time=316, train_MAE=0.472, train_loss=0.472, val_MAE=0.58, val_loss=0.58]Epoch 34:   3%|▎         | 34/1000 [3:07:22<84:54:45, 316.44s/it, lr=0.0005, test_MAE=0.602, time=316, train_MAE=0.47, train_loss=0.47, val_MAE=0.565, val_loss=0.565]Epoch 34:   4%|▎         | 35/1000 [3:07:22<84:49:12, 316.43s/it, lr=0.0005, test_MAE=0.602, time=316, train_MAE=0.47, train_loss=0.47, val_MAE=0.565, val_loss=0.565]Epoch 35:   4%|▎         | 35/1000 [3:07:22<84:49:12, 316.43s/it, lr=0.0005, test_MAE=0.602, time=316, train_MAE=0.47, train_loss=0.47, val_MAE=0.565, val_loss=0.565]Epoch 35:   4%|▎         | 35/1000 [3:12:38<84:49:12, 316.43s/it, lr=0.0005, test_MAE=1.01, time=316, train_MAE=0.467, train_loss=0.467, val_MAE=0.949, val_loss=0.949]Epoch 35:   4%|▎         | 36/1000 [3:12:38<84:44:02, 316.43s/it, lr=0.0005, test_MAE=1.01, time=316, train_MAE=0.467, train_loss=0.467, val_MAE=0.949, val_loss=0.949]Epoch 36:   4%|▎         | 36/1000 [3:12:38<84:44:02, 316.43s/it, lr=0.0005, test_MAE=1.01, time=316, train_MAE=0.467, train_loss=0.467, val_MAE=0.949, val_loss=0.949]Epoch 36:   4%|▎         | 36/1000 [3:17:55<84:44:02, 316.43s/it, lr=0.0005, test_MAE=0.755, time=316, train_MAE=0.468, train_loss=0.468, val_MAE=0.698, val_loss=0.698]Epoch 36:   4%|▎         | 37/1000 [3:17:55<84:38:50, 316.44s/it, lr=0.0005, test_MAE=0.755, time=316, train_MAE=0.468, train_loss=0.468, val_MAE=0.698, val_loss=0.698]Epoch 37:   4%|▎         | 37/1000 [3:17:55<84:38:50, 316.44s/it, lr=0.0005, test_MAE=0.755, time=316, train_MAE=0.468, train_loss=0.468, val_MAE=0.698, val_loss=0.698]Epoch 37:   4%|▎         | 37/1000 [3:23:11<84:38:50, 316.44s/it, lr=0.0005, test_MAE=0.664, time=317, train_MAE=0.465, train_loss=0.465, val_MAE=0.611, val_loss=0.611]Epoch 37:   4%|▍         | 38/1000 [3:23:11<84:34:27, 316.49s/it, lr=0.0005, test_MAE=0.664, time=317, train_MAE=0.465, train_loss=0.465, val_MAE=0.611, val_loss=0.611]Epoch 38:   4%|▍         | 38/1000 [3:23:11<84:34:27, 316.49s/it, lr=0.0005, test_MAE=0.664, time=317, train_MAE=0.465, train_loss=0.465, val_MAE=0.611, val_loss=0.611]Epoch 38:   4%|▍         | 38/1000 [3:28:27<84:34:27, 316.49s/it, lr=0.0005, test_MAE=0.701, time=316, train_MAE=0.463, train_loss=0.463, val_MAE=0.648, val_loss=0.648]Epoch 38:   4%|▍         | 39/1000 [3:28:27<84:27:32, 316.39s/it, lr=0.0005, test_MAE=0.701, time=316, train_MAE=0.463, train_loss=0.463, val_MAE=0.648, val_loss=0.648]Epoch 39:   4%|▍         | 39/1000 [3:28:27<84:27:32, 316.39s/it, lr=0.0005, test_MAE=0.701, time=316, train_MAE=0.463, train_loss=0.463, val_MAE=0.648, val_loss=0.648]Epoch 39:   4%|▍         | 39/1000 [3:33:44<84:27:32, 316.39s/it, lr=0.0005, test_MAE=0.644, time=316, train_MAE=0.453, train_loss=0.453, val_MAE=0.578, val_loss=0.578]Epoch 39:   4%|▍         | 40/1000 [3:33:44<84:21:04, 316.32s/it, lr=0.0005, test_MAE=0.644, time=316, train_MAE=0.453, train_loss=0.453, val_MAE=0.578, val_loss=0.578]Epoch 40:   4%|▍         | 40/1000 [3:33:44<84:21:04, 316.32s/it, lr=0.0005, test_MAE=0.644, time=316, train_MAE=0.453, train_loss=0.453, val_MAE=0.578, val_loss=0.578]Epoch 40:   4%|▍         | 40/1000 [3:39:00<84:21:04, 316.32s/it, lr=0.0005, test_MAE=0.637, time=316, train_MAE=0.466, train_loss=0.466, val_MAE=0.599, val_loss=0.599]Epoch    41: reducing learning rate of group 0 to 2.5000e-04.
Epoch 40:   4%|▍         | 41/1000 [3:39:00<84:14:28, 316.23s/it, lr=0.0005, test_MAE=0.637, time=316, train_MAE=0.466, train_loss=0.466, val_MAE=0.599, val_loss=0.599]Epoch 41:   4%|▍         | 41/1000 [3:39:00<84:14:28, 316.23s/it, lr=0.0005, test_MAE=0.637, time=316, train_MAE=0.466, train_loss=0.466, val_MAE=0.599, val_loss=0.599]Epoch 41:   4%|▍         | 41/1000 [3:44:16<84:14:28, 316.23s/it, lr=0.00025, test_MAE=0.609, time=316, train_MAE=0.441, train_loss=0.441, val_MAE=0.567, val_loss=0.567]Epoch 41:   4%|▍         | 42/1000 [3:44:16<84:08:02, 316.16s/it, lr=0.00025, test_MAE=0.609, time=316, train_MAE=0.441, train_loss=0.441, val_MAE=0.567, val_loss=0.567]Epoch 42:   4%|▍         | 42/1000 [3:44:16<84:08:02, 316.16s/it, lr=0.00025, test_MAE=0.609, time=316, train_MAE=0.441, train_loss=0.441, val_MAE=0.567, val_loss=0.567]Epoch 42:   4%|▍         | 42/1000 [3:49:32<84:08:02, 316.16s/it, lr=0.00025, test_MAE=0.612, time=317, train_MAE=0.418, train_loss=0.418, val_MAE=0.576, val_loss=0.576]Epoch 42:   4%|▍         | 43/1000 [3:49:32<84:05:28, 316.33s/it, lr=0.00025, test_MAE=0.612, time=317, train_MAE=0.418, train_loss=0.418, val_MAE=0.576, val_loss=0.576]Epoch 43:   4%|▍         | 43/1000 [3:49:32<84:05:28, 316.33s/it, lr=0.00025, test_MAE=0.612, time=317, train_MAE=0.418, train_loss=0.418, val_MAE=0.576, val_loss=0.576]Epoch 43:   4%|▍         | 43/1000 [3:54:48<84:05:28, 316.33s/it, lr=0.00025, test_MAE=0.61, time=316, train_MAE=0.424, train_loss=0.424, val_MAE=0.574, val_loss=0.574] Epoch 43:   4%|▍         | 44/1000 [3:54:49<83:59:31, 316.29s/it, lr=0.00025, test_MAE=0.61, time=316, train_MAE=0.424, train_loss=0.424, val_MAE=0.574, val_loss=0.574]Epoch 44:   4%|▍         | 44/1000 [3:54:49<83:59:31, 316.29s/it, lr=0.00025, test_MAE=0.61, time=316, train_MAE=0.424, train_loss=0.424, val_MAE=0.574, val_loss=0.574]Epoch 44:   4%|▍         | 44/1000 [4:00:03<83:59:31, 316.29s/it, lr=0.00025, test_MAE=0.606, time=315, train_MAE=0.417, train_loss=0.417, val_MAE=0.568, val_loss=0.568]Epoch 44:   4%|▍         | 45/1000 [4:00:03<83:47:00, 315.83s/it, lr=0.00025, test_MAE=0.606, time=315, train_MAE=0.417, train_loss=0.417, val_MAE=0.568, val_loss=0.568]Epoch 45:   4%|▍         | 45/1000 [4:00:03<83:47:00, 315.83s/it, lr=0.00025, test_MAE=0.606, time=315, train_MAE=0.417, train_loss=0.417, val_MAE=0.568, val_loss=0.568]Epoch 45:   4%|▍         | 45/1000 [4:05:17<83:47:00, 315.83s/it, lr=0.00025, test_MAE=0.608, time=313, train_MAE=0.414, train_loss=0.414, val_MAE=0.577, val_loss=0.577]Epoch 45:   5%|▍         | 46/1000 [4:05:17<83:29:48, 315.08s/it, lr=0.00025, test_MAE=0.608, time=313, train_MAE=0.414, train_loss=0.414, val_MAE=0.577, val_loss=0.577]Epoch 46:   5%|▍         | 46/1000 [4:05:17<83:29:48, 315.08s/it, lr=0.00025, test_MAE=0.608, time=313, train_MAE=0.414, train_loss=0.414, val_MAE=0.577, val_loss=0.577]Epoch 46:   5%|▍         | 46/1000 [4:10:30<83:29:48, 315.08s/it, lr=0.00025, test_MAE=0.76, time=314, train_MAE=0.406, train_loss=0.406, val_MAE=0.712, val_loss=0.712] Epoch    47: reducing learning rate of group 0 to 1.2500e-04.
Epoch 46:   5%|▍         | 47/1000 [4:10:30<83:17:24, 314.63s/it, lr=0.00025, test_MAE=0.76, time=314, train_MAE=0.406, train_loss=0.406, val_MAE=0.712, val_loss=0.712]Epoch 47:   5%|▍         | 47/1000 [4:10:30<83:17:24, 314.63s/it, lr=0.00025, test_MAE=0.76, time=314, train_MAE=0.406, train_loss=0.406, val_MAE=0.712, val_loss=0.712]Epoch 47:   5%|▍         | 47/1000 [4:15:44<83:17:24, 314.63s/it, lr=0.000125, test_MAE=0.615, time=313, train_MAE=0.398, train_loss=0.398, val_MAE=0.578, val_loss=0.578]Epoch 47:   5%|▍         | 48/1000 [4:15:44<83:06:30, 314.28s/it, lr=0.000125, test_MAE=0.615, time=313, train_MAE=0.398, train_loss=0.398, val_MAE=0.578, val_loss=0.578]Epoch 48:   5%|▍         | 48/1000 [4:15:44<83:06:30, 314.28s/it, lr=0.000125, test_MAE=0.615, time=313, train_MAE=0.398, train_loss=0.398, val_MAE=0.578, val_loss=0.578]Epoch 48:   5%|▍         | 48/1000 [4:20:57<83:06:30, 314.28s/it, lr=0.000125, test_MAE=0.608, time=313, train_MAE=0.396, train_loss=0.396, val_MAE=0.575, val_loss=0.575]Epoch 48:   5%|▍         | 49/1000 [4:20:57<82:56:29, 313.97s/it, lr=0.000125, test_MAE=0.608, time=313, train_MAE=0.396, train_loss=0.396, val_MAE=0.575, val_loss=0.575]Epoch 49:   5%|▍         | 49/1000 [4:20:57<82:56:29, 313.97s/it, lr=0.000125, test_MAE=0.608, time=313, train_MAE=0.396, train_loss=0.396, val_MAE=0.575, val_loss=0.575]Epoch 49:   5%|▍         | 49/1000 [4:26:10<82:56:29, 313.97s/it, lr=0.000125, test_MAE=0.634, time=313, train_MAE=0.394, train_loss=0.394, val_MAE=0.585, val_loss=0.585]Epoch 49:   5%|▌         | 50/1000 [4:26:10<82:48:35, 313.81s/it, lr=0.000125, test_MAE=0.634, time=313, train_MAE=0.394, train_loss=0.394, val_MAE=0.585, val_loss=0.585]Epoch 50:   5%|▌         | 50/1000 [4:26:10<82:48:35, 313.81s/it, lr=0.000125, test_MAE=0.634, time=313, train_MAE=0.394, train_loss=0.394, val_MAE=0.585, val_loss=0.585]Epoch 50:   5%|▌         | 50/1000 [4:31:24<82:48:35, 313.81s/it, lr=0.000125, test_MAE=0.613, time=313, train_MAE=0.384, train_loss=0.384, val_MAE=0.568, val_loss=0.568]Epoch 50:   5%|▌         | 51/1000 [4:31:24<82:41:20, 313.68s/it, lr=0.000125, test_MAE=0.613, time=313, train_MAE=0.384, train_loss=0.384, val_MAE=0.568, val_loss=0.568]Epoch 51:   5%|▌         | 51/1000 [4:31:24<82:41:20, 313.68s/it, lr=0.000125, test_MAE=0.613, time=313, train_MAE=0.384, train_loss=0.384, val_MAE=0.568, val_loss=0.568]Epoch 51:   5%|▌         | 51/1000 [4:36:37<82:41:20, 313.68s/it, lr=0.000125, test_MAE=0.616, time=313, train_MAE=0.385, train_loss=0.385, val_MAE=0.584, val_loss=0.584]Epoch 51:   5%|▌         | 52/1000 [4:36:37<82:34:16, 313.56s/it, lr=0.000125, test_MAE=0.616, time=313, train_MAE=0.385, train_loss=0.385, val_MAE=0.584, val_loss=0.584]Epoch 52:   5%|▌         | 52/1000 [4:36:37<82:34:16, 313.56s/it, lr=0.000125, test_MAE=0.616, time=313, train_MAE=0.385, train_loss=0.385, val_MAE=0.584, val_loss=0.584]Epoch 52:   5%|▌         | 52/1000 [4:41:51<82:34:16, 313.56s/it, lr=0.000125, test_MAE=0.612, time=314, train_MAE=0.387, train_loss=0.387, val_MAE=0.579, val_loss=0.579]Epoch    53: reducing learning rate of group 0 to 6.2500e-05.
Epoch 52:   5%|▌         | 53/1000 [4:41:51<82:29:30, 313.59s/it, lr=0.000125, test_MAE=0.612, time=314, train_MAE=0.387, train_loss=0.387, val_MAE=0.579, val_loss=0.579]Epoch 53:   5%|▌         | 53/1000 [4:41:51<82:29:30, 313.59s/it, lr=0.000125, test_MAE=0.612, time=314, train_MAE=0.387, train_loss=0.387, val_MAE=0.579, val_loss=0.579]Epoch 53:   5%|▌         | 53/1000 [4:47:04<82:29:30, 313.59s/it, lr=6.25e-5, test_MAE=0.607, time=313, train_MAE=0.376, train_loss=0.376, val_MAE=0.568, val_loss=0.568] Epoch 53:   5%|▌         | 54/1000 [4:47:04<82:22:48, 313.50s/it, lr=6.25e-5, test_MAE=0.607, time=313, train_MAE=0.376, train_loss=0.376, val_MAE=0.568, val_loss=0.568]Epoch 54:   5%|▌         | 54/1000 [4:47:04<82:22:48, 313.50s/it, lr=6.25e-5, test_MAE=0.607, time=313, train_MAE=0.376, train_loss=0.376, val_MAE=0.568, val_loss=0.568]Epoch 54:   5%|▌         | 54/1000 [4:52:17<82:22:48, 313.50s/it, lr=6.25e-5, test_MAE=0.607, time=313, train_MAE=0.376, train_loss=0.376, val_MAE=0.571, val_loss=0.571]Epoch 54:   6%|▌         | 55/1000 [4:52:17<82:17:16, 313.48s/it, lr=6.25e-5, test_MAE=0.607, time=313, train_MAE=0.376, train_loss=0.376, val_MAE=0.571, val_loss=0.571]Epoch 55:   6%|▌         | 55/1000 [4:52:17<82:17:16, 313.48s/it, lr=6.25e-5, test_MAE=0.607, time=313, train_MAE=0.376, train_loss=0.376, val_MAE=0.571, val_loss=0.571]Epoch 55:   6%|▌         | 55/1000 [4:57:31<82:17:16, 313.48s/it, lr=6.25e-5, test_MAE=0.603, time=314, train_MAE=0.375, train_loss=0.375, val_MAE=0.564, val_loss=0.564]Epoch 55:   6%|▌         | 56/1000 [4:57:31<82:12:31, 313.51s/it, lr=6.25e-5, test_MAE=0.603, time=314, train_MAE=0.375, train_loss=0.375, val_MAE=0.564, val_loss=0.564]Epoch 56:   6%|▌         | 56/1000 [4:57:31<82:12:31, 313.51s/it, lr=6.25e-5, test_MAE=0.603, time=314, train_MAE=0.375, train_loss=0.375, val_MAE=0.564, val_loss=0.564]Epoch 56:   6%|▌         | 56/1000 [5:02:45<82:12:31, 313.51s/it, lr=6.25e-5, test_MAE=0.61, time=314, train_MAE=0.374, train_loss=0.374, val_MAE=0.568, val_loss=0.568] Epoch 56:   6%|▌         | 57/1000 [5:02:45<82:08:45, 313.60s/it, lr=6.25e-5, test_MAE=0.61, time=314, train_MAE=0.374, train_loss=0.374, val_MAE=0.568, val_loss=0.568]Epoch 57:   6%|▌         | 57/1000 [5:02:45<82:08:45, 313.60s/it, lr=6.25e-5, test_MAE=0.61, time=314, train_MAE=0.374, train_loss=0.374, val_MAE=0.568, val_loss=0.568]Epoch 57:   6%|▌         | 57/1000 [5:07:58<82:08:45, 313.60s/it, lr=6.25e-5, test_MAE=0.611, time=313, train_MAE=0.379, train_loss=0.379, val_MAE=0.582, val_loss=0.582]Epoch 57:   6%|▌         | 58/1000 [5:07:58<82:02:00, 313.50s/it, lr=6.25e-5, test_MAE=0.611, time=313, train_MAE=0.379, train_loss=0.379, val_MAE=0.582, val_loss=0.582]Epoch 58:   6%|▌         | 58/1000 [5:07:58<82:02:00, 313.50s/it, lr=6.25e-5, test_MAE=0.611, time=313, train_MAE=0.379, train_loss=0.379, val_MAE=0.582, val_loss=0.582]Epoch 58:   6%|▌         | 58/1000 [5:13:11<82:02:00, 313.50s/it, lr=6.25e-5, test_MAE=0.618, time=313, train_MAE=0.369, train_loss=0.369, val_MAE=0.579, val_loss=0.579]Epoch 58:   6%|▌         | 59/1000 [5:13:11<81:55:51, 313.45s/it, lr=6.25e-5, test_MAE=0.618, time=313, train_MAE=0.369, train_loss=0.369, val_MAE=0.579, val_loss=0.579]Epoch 59:   6%|▌         | 59/1000 [5:13:11<81:55:51, 313.45s/it, lr=6.25e-5, test_MAE=0.618, time=313, train_MAE=0.369, train_loss=0.369, val_MAE=0.579, val_loss=0.579]Epoch 59:   6%|▌         | 59/1000 [5:18:23<81:55:51, 313.45s/it, lr=6.25e-5, test_MAE=0.614, time=311, train_MAE=0.365, train_loss=0.365, val_MAE=0.585, val_loss=0.585]Epoch 59:   6%|▌         | 60/1000 [5:18:23<81:41:15, 312.85s/it, lr=6.25e-5, test_MAE=0.614, time=311, train_MAE=0.365, train_loss=0.365, val_MAE=0.585, val_loss=0.585]Epoch 60:   6%|▌         | 60/1000 [5:18:23<81:41:15, 312.85s/it, lr=6.25e-5, test_MAE=0.614, time=311, train_MAE=0.365, train_loss=0.365, val_MAE=0.585, val_loss=0.585]Epoch 60:   6%|▌         | 60/1000 [5:23:33<81:41:15, 312.85s/it, lr=6.25e-5, test_MAE=0.607, time=311, train_MAE=0.365, train_loss=0.365, val_MAE=0.577, val_loss=0.577]Epoch 60:   6%|▌         | 61/1000 [5:23:33<81:25:52, 312.20s/it, lr=6.25e-5, test_MAE=0.607, time=311, train_MAE=0.365, train_loss=0.365, val_MAE=0.577, val_loss=0.577]Epoch 61:   6%|▌         | 61/1000 [5:23:33<81:25:52, 312.20s/it, lr=6.25e-5, test_MAE=0.607, time=311, train_MAE=0.365, train_loss=0.365, val_MAE=0.577, val_loss=0.577]Epoch 61:   6%|▌         | 61/1000 [5:28:44<81:25:52, 312.20s/it, lr=6.25e-5, test_MAE=0.612, time=311, train_MAE=0.368, train_loss=0.368, val_MAE=0.581, val_loss=0.581]Epoch    62: reducing learning rate of group 0 to 3.1250e-05.
Epoch 61:   6%|▌         | 62/1000 [5:28:44<81:14:21, 311.79s/it, lr=6.25e-5, test_MAE=0.612, time=311, train_MAE=0.368, train_loss=0.368, val_MAE=0.581, val_loss=0.581]Epoch 62:   6%|▌         | 62/1000 [5:28:44<81:14:21, 311.79s/it, lr=6.25e-5, test_MAE=0.612, time=311, train_MAE=0.368, train_loss=0.368, val_MAE=0.581, val_loss=0.581]Epoch 62:   6%|▌         | 62/1000 [5:33:55<81:14:21, 311.79s/it, lr=3.13e-5, test_MAE=0.609, time=311, train_MAE=0.362, train_loss=0.362, val_MAE=0.573, val_loss=0.573]Epoch 62:   6%|▋         | 63/1000 [5:33:55<81:04:55, 311.52s/it, lr=3.13e-5, test_MAE=0.609, time=311, train_MAE=0.362, train_loss=0.362, val_MAE=0.573, val_loss=0.573]Epoch 63:   6%|▋         | 63/1000 [5:33:55<81:04:55, 311.52s/it, lr=3.13e-5, test_MAE=0.609, time=311, train_MAE=0.362, train_loss=0.362, val_MAE=0.573, val_loss=0.573]Epoch 63:   6%|▋         | 63/1000 [5:39:06<81:04:55, 311.52s/it, lr=3.13e-5, test_MAE=0.608, time=311, train_MAE=0.363, train_loss=0.363, val_MAE=0.571, val_loss=0.571]Epoch 63:   6%|▋         | 64/1000 [5:39:06<80:58:16, 311.43s/it, lr=3.13e-5, test_MAE=0.608, time=311, train_MAE=0.363, train_loss=0.363, val_MAE=0.571, val_loss=0.571]Epoch 64:   6%|▋         | 64/1000 [5:39:06<80:58:16, 311.43s/it, lr=3.13e-5, test_MAE=0.608, time=311, train_MAE=0.363, train_loss=0.363, val_MAE=0.571, val_loss=0.571]Epoch 64:   6%|▋         | 64/1000 [5:44:17<80:58:16, 311.43s/it, lr=3.13e-5, test_MAE=0.61, time=311, train_MAE=0.361, train_loss=0.361, val_MAE=0.574, val_loss=0.574] Epoch 64:   6%|▋         | 65/1000 [5:44:17<80:50:45, 311.28s/it, lr=3.13e-5, test_MAE=0.61, time=311, train_MAE=0.361, train_loss=0.361, val_MAE=0.574, val_loss=0.574]Epoch 65:   6%|▋         | 65/1000 [5:44:17<80:50:45, 311.28s/it, lr=3.13e-5, test_MAE=0.61, time=311, train_MAE=0.361, train_loss=0.361, val_MAE=0.574, val_loss=0.574]Epoch 65:   6%|▋         | 65/1000 [5:49:29<80:50:45, 311.28s/it, lr=3.13e-5, test_MAE=0.626, time=311, train_MAE=0.362, train_loss=0.362, val_MAE=0.591, val_loss=0.591]Epoch 65:   7%|▋         | 66/1000 [5:49:29<80:45:47, 311.29s/it, lr=3.13e-5, test_MAE=0.626, time=311, train_MAE=0.362, train_loss=0.362, val_MAE=0.591, val_loss=0.591]Epoch 66:   7%|▋         | 66/1000 [5:49:29<80:45:47, 311.29s/it, lr=3.13e-5, test_MAE=0.626, time=311, train_MAE=0.362, train_loss=0.362, val_MAE=0.591, val_loss=0.591]Epoch 66:   7%|▋         | 66/1000 [5:54:40<80:45:47, 311.29s/it, lr=3.13e-5, test_MAE=0.611, time=311, train_MAE=0.364, train_loss=0.364, val_MAE=0.575, val_loss=0.575]Epoch 66:   7%|▋         | 67/1000 [5:54:40<80:39:08, 311.20s/it, lr=3.13e-5, test_MAE=0.611, time=311, train_MAE=0.364, train_loss=0.364, val_MAE=0.575, val_loss=0.575]Epoch 67:   7%|▋         | 67/1000 [5:54:40<80:39:08, 311.20s/it, lr=3.13e-5, test_MAE=0.611, time=311, train_MAE=0.364, train_loss=0.364, val_MAE=0.575, val_loss=0.575]Epoch 67:   7%|▋         | 67/1000 [5:59:51<80:39:08, 311.20s/it, lr=3.13e-5, test_MAE=0.608, time=311, train_MAE=0.363, train_loss=0.363, val_MAE=0.574, val_loss=0.574]Epoch    68: reducing learning rate of group 0 to 1.5625e-05.
Epoch 67:   7%|▋         | 68/1000 [5:59:51<80:32:38, 311.11s/it, lr=3.13e-5, test_MAE=0.608, time=311, train_MAE=0.363, train_loss=0.363, val_MAE=0.574, val_loss=0.574]Epoch 68:   7%|▋         | 68/1000 [5:59:51<80:32:38, 311.11s/it, lr=3.13e-5, test_MAE=0.608, time=311, train_MAE=0.363, train_loss=0.363, val_MAE=0.574, val_loss=0.574]slurmstepd: error: *** JOB 58311224 ON r108u25n01 CANCELLED AT 2025-09-05T08:05:33 DUE TO TIME LIMIT ***
