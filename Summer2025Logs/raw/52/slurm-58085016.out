I'm echoing to stdout
I'm echoing to stderr
My JobID is 58085016
I have 4 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.0089s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 4, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'poly_mlp', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_sub', 'num_eigs': 16, 'bias_mode': 'spatial', 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 0.0, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/aug07/zinc_train_rec.csv', 'test': 'supp_data/molecules/aug07/zinc_test_rec.csv', 'val': 'supp_data/molecules/aug07/zinc_val_rec.csv'}, 'fixMissingPhi1': False, 'extraOrtho': False, 'doublePrecision': True, 'eigval_hidden_dim': 100, 'eigval_num_hidden_layer': 3, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [01:41<?, ?it/s, lr=0.001, test_MAE=0.821, time=101, train_MAE=0.927, train_loss=0.927, val_MAE=0.78, val_loss=0.78]Epoch 0:   0%|          | 1/1000 [01:41<28:03:12, 101.09s/it, lr=0.001, test_MAE=0.821, time=101, train_MAE=0.927, train_loss=0.927, val_MAE=0.78, val_loss=0.78]Epoch 1:   0%|          | 1/1000 [01:41<28:03:12, 101.09s/it, lr=0.001, test_MAE=0.821, time=101, train_MAE=0.927, train_loss=0.927, val_MAE=0.78, val_loss=0.78]Epoch 1:   0%|          | 1/1000 [03:03<28:03:12, 101.09s/it, lr=0.001, test_MAE=1.16, time=82.9, train_MAE=0.662, train_loss=0.662, val_MAE=1.12, val_loss=1.12]Epoch 1:   0%|          | 2/1000 [03:03<26:30:33, 95.62s/it, lr=0.001, test_MAE=1.16, time=82.9, train_MAE=0.662, train_loss=0.662, val_MAE=1.12, val_loss=1.12] Epoch 2:   0%|          | 2/1000 [03:03<26:30:33, 95.62s/it, lr=0.001, test_MAE=1.16, time=82.9, train_MAE=0.662, train_loss=0.662, val_MAE=1.12, val_loss=1.12]Epoch 2:   0%|          | 2/1000 [04:26<26:30:33, 95.62s/it, lr=0.001, test_MAE=0.684, time=82.8, train_MAE=0.642, train_loss=0.642, val_MAE=0.619, val_loss=0.619]Epoch 2:   0%|          | 3/1000 [04:26<25:25:17, 91.79s/it, lr=0.001, test_MAE=0.684, time=82.8, train_MAE=0.642, train_loss=0.642, val_MAE=0.619, val_loss=0.619]Epoch 3:   0%|          | 3/1000 [04:26<25:25:17, 91.79s/it, lr=0.001, test_MAE=0.684, time=82.8, train_MAE=0.642, train_loss=0.642, val_MAE=0.619, val_loss=0.619]Epoch 3:   0%|          | 3/1000 [05:49<25:25:17, 91.79s/it, lr=0.001, test_MAE=0.683, time=82.7, train_MAE=0.636, train_loss=0.636, val_MAE=0.642, val_loss=0.642]Epoch 3:   0%|          | 4/1000 [05:49<24:38:33, 89.07s/it, lr=0.001, test_MAE=0.683, time=82.7, train_MAE=0.636, train_loss=0.636, val_MAE=0.642, val_loss=0.642]Epoch 4:   0%|          | 4/1000 [05:49<24:38:33, 89.07s/it, lr=0.001, test_MAE=0.683, time=82.7, train_MAE=0.636, train_loss=0.636, val_MAE=0.642, val_loss=0.642]Epoch 4:   0%|          | 4/1000 [07:12<24:38:33, 89.07s/it, lr=0.001, test_MAE=0.931, time=82.8, train_MAE=0.613, train_loss=0.613, val_MAE=0.89, val_loss=0.89]  Epoch 4:   0%|          | 5/1000 [07:12<24:05:46, 87.18s/it, lr=0.001, test_MAE=0.931, time=82.8, train_MAE=0.613, train_loss=0.613, val_MAE=0.89, val_loss=0.89]Epoch 5:   0%|          | 5/1000 [07:12<24:05:46, 87.18s/it, lr=0.001, test_MAE=0.931, time=82.8, train_MAE=0.613, train_loss=0.613, val_MAE=0.89, val_loss=0.89]Epoch 5:   0%|          | 5/1000 [08:35<24:05:46, 87.18s/it, lr=0.001, test_MAE=0.675, time=82.8, train_MAE=0.63, train_loss=0.63, val_MAE=0.619, val_loss=0.619]Epoch 5:   1%|          | 6/1000 [08:35<23:42:28, 85.86s/it, lr=0.001, test_MAE=0.675, time=82.8, train_MAE=0.63, train_loss=0.63, val_MAE=0.619, val_loss=0.619]Epoch 6:   1%|          | 6/1000 [08:35<23:42:28, 85.86s/it, lr=0.001, test_MAE=0.675, time=82.8, train_MAE=0.63, train_loss=0.63, val_MAE=0.619, val_loss=0.619]Epoch 6:   1%|          | 6/1000 [09:58<23:42:28, 85.86s/it, lr=0.001, test_MAE=1.4, time=83.7, train_MAE=0.613, train_loss=0.613, val_MAE=1.39, val_loss=1.39]  Epoch 6:   1%|          | 7/1000 [09:58<23:30:22, 85.22s/it, lr=0.001, test_MAE=1.4, time=83.7, train_MAE=0.613, train_loss=0.613, val_MAE=1.39, val_loss=1.39]Epoch 7:   1%|          | 7/1000 [09:58<23:30:22, 85.22s/it, lr=0.001, test_MAE=1.4, time=83.7, train_MAE=0.613, train_loss=0.613, val_MAE=1.39, val_loss=1.39]Epoch 7:   1%|          | 7/1000 [11:23<23:30:22, 85.22s/it, lr=0.001, test_MAE=0.672, time=84.4, train_MAE=0.608, train_loss=0.608, val_MAE=0.621, val_loss=0.621]Epoch 7:   1%|          | 8/1000 [11:23<23:24:54, 84.97s/it, lr=0.001, test_MAE=0.672, time=84.4, train_MAE=0.608, train_loss=0.608, val_MAE=0.621, val_loss=0.621]Epoch 8:   1%|          | 8/1000 [11:23<23:24:54, 84.97s/it, lr=0.001, test_MAE=0.672, time=84.4, train_MAE=0.608, train_loss=0.608, val_MAE=0.621, val_loss=0.621]Epoch 8:   1%|          | 8/1000 [12:46<23:24:54, 84.97s/it, lr=0.001, test_MAE=0.756, time=83.2, train_MAE=0.593, train_loss=0.593, val_MAE=0.72, val_loss=0.72]  Epoch     9: reducing learning rate of group 0 to 5.0000e-04.
Epoch 8:   1%|          | 9/1000 [12:46<23:14:59, 84.46s/it, lr=0.001, test_MAE=0.756, time=83.2, train_MAE=0.593, train_loss=0.593, val_MAE=0.72, val_loss=0.72]Epoch 9:   1%|          | 9/1000 [12:46<23:14:59, 84.46s/it, lr=0.001, test_MAE=0.756, time=83.2, train_MAE=0.593, train_loss=0.593, val_MAE=0.72, val_loss=0.72]Epoch 9:   1%|          | 9/1000 [14:09<23:14:59, 84.46s/it, lr=0.0005, test_MAE=0.613, time=83.1, train_MAE=0.587, train_loss=0.587, val_MAE=0.577, val_loss=0.577]Epoch 9:   1%|          | 10/1000 [14:09<23:06:43, 84.04s/it, lr=0.0005, test_MAE=0.613, time=83.1, train_MAE=0.587, train_loss=0.587, val_MAE=0.577, val_loss=0.577]Epoch 10:   1%|          | 10/1000 [14:09<23:06:43, 84.04s/it, lr=0.0005, test_MAE=0.613, time=83.1, train_MAE=0.587, train_loss=0.587, val_MAE=0.577, val_loss=0.577]Epoch 10:   1%|          | 10/1000 [15:32<23:06:43, 84.04s/it, lr=0.0005, test_MAE=0.781, time=82.7, train_MAE=0.57, train_loss=0.57, val_MAE=0.748, val_loss=0.748]  Epoch 10:   1%|          | 11/1000 [15:32<22:58:56, 83.66s/it, lr=0.0005, test_MAE=0.781, time=82.7, train_MAE=0.57, train_loss=0.57, val_MAE=0.748, val_loss=0.748]Epoch 11:   1%|          | 11/1000 [15:32<22:58:56, 83.66s/it, lr=0.0005, test_MAE=0.781, time=82.7, train_MAE=0.57, train_loss=0.57, val_MAE=0.748, val_loss=0.748]Epoch 11:   1%|          | 11/1000 [16:54<22:58:56, 83.66s/it, lr=0.0005, test_MAE=0.623, time=82.4, train_MAE=0.57, train_loss=0.57, val_MAE=0.589, val_loss=0.589]Epoch 11:   1%|          | 12/1000 [16:54<22:51:33, 83.29s/it, lr=0.0005, test_MAE=0.623, time=82.4, train_MAE=0.57, train_loss=0.57, val_MAE=0.589, val_loss=0.589]Epoch 12:   1%|          | 12/1000 [16:54<22:51:33, 83.29s/it, lr=0.0005, test_MAE=0.623, time=82.4, train_MAE=0.57, train_loss=0.57, val_MAE=0.589, val_loss=0.589]Epoch 12:   1%|          | 12/1000 [18:17<22:51:33, 83.29s/it, lr=0.0005, test_MAE=0.739, time=83.1, train_MAE=0.583, train_loss=0.583, val_MAE=0.69, val_loss=0.69]Epoch 12:   1%|▏         | 13/1000 [18:17<22:49:02, 83.22s/it, lr=0.0005, test_MAE=0.739, time=83.1, train_MAE=0.583, train_loss=0.583, val_MAE=0.69, val_loss=0.69]Epoch 13:   1%|▏         | 13/1000 [18:17<22:49:02, 83.22s/it, lr=0.0005, test_MAE=0.739, time=83.1, train_MAE=0.583, train_loss=0.583, val_MAE=0.69, val_loss=0.69]Epoch 13:   1%|▏         | 13/1000 [19:40<22:49:02, 83.22s/it, lr=0.0005, test_MAE=0.642, time=82.7, train_MAE=0.561, train_loss=0.561, val_MAE=0.604, val_loss=0.604]Epoch 13:   1%|▏         | 14/1000 [19:40<22:45:22, 83.09s/it, lr=0.0005, test_MAE=0.642, time=82.7, train_MAE=0.561, train_loss=0.561, val_MAE=0.604, val_loss=0.604]Epoch 14:   1%|▏         | 14/1000 [19:40<22:45:22, 83.09s/it, lr=0.0005, test_MAE=0.642, time=82.7, train_MAE=0.561, train_loss=0.561, val_MAE=0.604, val_loss=0.604]Epoch 14:   1%|▏         | 14/1000 [21:02<22:45:22, 83.09s/it, lr=0.0005, test_MAE=0.618, time=82.4, train_MAE=0.563, train_loss=0.563, val_MAE=0.571, val_loss=0.571]Epoch 14:   2%|▏         | 15/1000 [21:03<22:40:49, 82.89s/it, lr=0.0005, test_MAE=0.618, time=82.4, train_MAE=0.563, train_loss=0.563, val_MAE=0.571, val_loss=0.571]Epoch 15:   2%|▏         | 15/1000 [21:03<22:40:49, 82.89s/it, lr=0.0005, test_MAE=0.618, time=82.4, train_MAE=0.563, train_loss=0.563, val_MAE=0.571, val_loss=0.571]Epoch 15:   2%|▏         | 15/1000 [22:26<22:40:49, 82.89s/it, lr=0.0005, test_MAE=0.659, time=83.1, train_MAE=0.564, train_loss=0.564, val_MAE=0.613, val_loss=0.613]Epoch 15:   2%|▏         | 16/1000 [22:26<22:40:30, 82.96s/it, lr=0.0005, test_MAE=0.659, time=83.1, train_MAE=0.564, train_loss=0.564, val_MAE=0.613, val_loss=0.613]Epoch 16:   2%|▏         | 16/1000 [22:26<22:40:30, 82.96s/it, lr=0.0005, test_MAE=0.659, time=83.1, train_MAE=0.564, train_loss=0.564, val_MAE=0.613, val_loss=0.613]Epoch 16:   2%|▏         | 16/1000 [23:48<22:40:30, 82.96s/it, lr=0.0005, test_MAE=0.627, time=82.8, train_MAE=0.558, train_loss=0.558, val_MAE=0.586, val_loss=0.586]Epoch 16:   2%|▏         | 17/1000 [23:48<22:38:30, 82.92s/it, lr=0.0005, test_MAE=0.627, time=82.8, train_MAE=0.558, train_loss=0.558, val_MAE=0.586, val_loss=0.586]Epoch 17:   2%|▏         | 17/1000 [23:48<22:38:30, 82.92s/it, lr=0.0005, test_MAE=0.627, time=82.8, train_MAE=0.558, train_loss=0.558, val_MAE=0.586, val_loss=0.586]Epoch 17:   2%|▏         | 17/1000 [25:11<22:38:30, 82.92s/it, lr=0.0005, test_MAE=0.641, time=82.5, train_MAE=0.556, train_loss=0.556, val_MAE=0.613, val_loss=0.613]Epoch 17:   2%|▏         | 18/1000 [25:11<22:35:11, 82.80s/it, lr=0.0005, test_MAE=0.641, time=82.5, train_MAE=0.556, train_loss=0.556, val_MAE=0.613, val_loss=0.613]Epoch 18:   2%|▏         | 18/1000 [25:11<22:35:11, 82.80s/it, lr=0.0005, test_MAE=0.641, time=82.5, train_MAE=0.556, train_loss=0.556, val_MAE=0.613, val_loss=0.613]Epoch 18:   2%|▏         | 18/1000 [26:34<22:35:11, 82.80s/it, lr=0.0005, test_MAE=0.635, time=83.1, train_MAE=0.553, train_loss=0.553, val_MAE=0.592, val_loss=0.592]Epoch 18:   2%|▏         | 19/1000 [26:34<22:35:21, 82.90s/it, lr=0.0005, test_MAE=0.635, time=83.1, train_MAE=0.553, train_loss=0.553, val_MAE=0.592, val_loss=0.592]Epoch 19:   2%|▏         | 19/1000 [26:34<22:35:21, 82.90s/it, lr=0.0005, test_MAE=0.635, time=83.1, train_MAE=0.553, train_loss=0.553, val_MAE=0.592, val_loss=0.592]Epoch 19:   2%|▏         | 19/1000 [27:57<22:35:21, 82.90s/it, lr=0.0005, test_MAE=0.689, time=82.8, train_MAE=0.552, train_loss=0.552, val_MAE=0.643, val_loss=0.643]Epoch 19:   2%|▏         | 20/1000 [27:57<22:33:41, 82.88s/it, lr=0.0005, test_MAE=0.689, time=82.8, train_MAE=0.552, train_loss=0.552, val_MAE=0.643, val_loss=0.643]Epoch 20:   2%|▏         | 20/1000 [27:57<22:33:41, 82.88s/it, lr=0.0005, test_MAE=0.689, time=82.8, train_MAE=0.552, train_loss=0.552, val_MAE=0.643, val_loss=0.643]Epoch 20:   2%|▏         | 20/1000 [29:20<22:33:41, 82.88s/it, lr=0.0005, test_MAE=0.735, time=82.8, train_MAE=0.546, train_loss=0.546, val_MAE=0.696, val_loss=0.696]Epoch    21: reducing learning rate of group 0 to 2.5000e-04.
Epoch 20:   2%|▏         | 21/1000 [29:20<22:32:03, 82.86s/it, lr=0.0005, test_MAE=0.735, time=82.8, train_MAE=0.546, train_loss=0.546, val_MAE=0.696, val_loss=0.696]Epoch 21:   2%|▏         | 21/1000 [29:20<22:32:03, 82.86s/it, lr=0.0005, test_MAE=0.735, time=82.8, train_MAE=0.546, train_loss=0.546, val_MAE=0.696, val_loss=0.696]Epoch 21:   2%|▏         | 21/1000 [30:43<22:32:03, 82.86s/it, lr=0.00025, test_MAE=0.608, time=83.2, train_MAE=0.53, train_loss=0.53, val_MAE=0.575, val_loss=0.575] Epoch 21:   2%|▏         | 22/1000 [30:43<22:32:12, 82.96s/it, lr=0.00025, test_MAE=0.608, time=83.2, train_MAE=0.53, train_loss=0.53, val_MAE=0.575, val_loss=0.575]Epoch 22:   2%|▏         | 22/1000 [30:43<22:32:12, 82.96s/it, lr=0.00025, test_MAE=0.608, time=83.2, train_MAE=0.53, train_loss=0.53, val_MAE=0.575, val_loss=0.575]Epoch 22:   2%|▏         | 22/1000 [32:05<22:32:12, 82.96s/it, lr=0.00025, test_MAE=0.607, time=82.5, train_MAE=0.537, train_loss=0.537, val_MAE=0.565, val_loss=0.565]Epoch 22:   2%|▏         | 23/1000 [32:05<22:28:27, 82.81s/it, lr=0.00025, test_MAE=0.607, time=82.5, train_MAE=0.537, train_loss=0.537, val_MAE=0.565, val_loss=0.565]Epoch 23:   2%|▏         | 23/1000 [32:05<22:28:27, 82.81s/it, lr=0.00025, test_MAE=0.607, time=82.5, train_MAE=0.537, train_loss=0.537, val_MAE=0.565, val_loss=0.565]Epoch 23:   2%|▏         | 23/1000 [33:29<22:28:27, 82.81s/it, lr=0.00025, test_MAE=0.715, time=83.2, train_MAE=0.525, train_loss=0.525, val_MAE=0.676, val_loss=0.676]Epoch 23:   2%|▏         | 24/1000 [33:29<22:28:50, 82.92s/it, lr=0.00025, test_MAE=0.715, time=83.2, train_MAE=0.525, train_loss=0.525, val_MAE=0.676, val_loss=0.676]Epoch 24:   2%|▏         | 24/1000 [33:29<22:28:50, 82.92s/it, lr=0.00025, test_MAE=0.715, time=83.2, train_MAE=0.525, train_loss=0.525, val_MAE=0.676, val_loss=0.676]Epoch 24:   2%|▏         | 24/1000 [34:51<22:28:50, 82.92s/it, lr=0.00025, test_MAE=0.611, time=82.8, train_MAE=0.529, train_loss=0.529, val_MAE=0.568, val_loss=0.568]Epoch 24:   2%|▎         | 25/1000 [34:51<22:27:05, 82.90s/it, lr=0.00025, test_MAE=0.611, time=82.8, train_MAE=0.529, train_loss=0.529, val_MAE=0.568, val_loss=0.568]Epoch 25:   2%|▎         | 25/1000 [34:51<22:27:05, 82.90s/it, lr=0.00025, test_MAE=0.611, time=82.8, train_MAE=0.529, train_loss=0.529, val_MAE=0.568, val_loss=0.568]Epoch 25:   2%|▎         | 25/1000 [36:14<22:27:05, 82.90s/it, lr=0.00025, test_MAE=0.609, time=82.8, train_MAE=0.526, train_loss=0.526, val_MAE=0.571, val_loss=0.571]Epoch 25:   3%|▎         | 26/1000 [36:14<22:25:30, 82.89s/it, lr=0.00025, test_MAE=0.609, time=82.8, train_MAE=0.526, train_loss=0.526, val_MAE=0.571, val_loss=0.571]Epoch 26:   3%|▎         | 26/1000 [36:14<22:25:30, 82.89s/it, lr=0.00025, test_MAE=0.609, time=82.8, train_MAE=0.526, train_loss=0.526, val_MAE=0.571, val_loss=0.571]Epoch 26:   3%|▎         | 26/1000 [37:37<22:25:30, 82.89s/it, lr=0.00025, test_MAE=0.604, time=83, train_MAE=0.528, train_loss=0.528, val_MAE=0.578, val_loss=0.578]  Epoch 26:   3%|▎         | 27/1000 [37:37<22:24:57, 82.94s/it, lr=0.00025, test_MAE=0.604, time=83, train_MAE=0.528, train_loss=0.528, val_MAE=0.578, val_loss=0.578]Epoch 27:   3%|▎         | 27/1000 [37:37<22:24:57, 82.94s/it, lr=0.00025, test_MAE=0.604, time=83, train_MAE=0.528, train_loss=0.528, val_MAE=0.578, val_loss=0.578]Epoch 27:   3%|▎         | 27/1000 [39:00<22:24:57, 82.94s/it, lr=0.00025, test_MAE=0.64, time=82.8, train_MAE=0.519, train_loss=0.519, val_MAE=0.598, val_loss=0.598]Epoch 27:   3%|▎         | 28/1000 [39:00<22:22:53, 82.89s/it, lr=0.00025, test_MAE=0.64, time=82.8, train_MAE=0.519, train_loss=0.519, val_MAE=0.598, val_loss=0.598]Epoch 28:   3%|▎         | 28/1000 [39:00<22:22:53, 82.89s/it, lr=0.00025, test_MAE=0.64, time=82.8, train_MAE=0.519, train_loss=0.519, val_MAE=0.598, val_loss=0.598]Epoch 28:   3%|▎         | 28/1000 [40:23<22:22:53, 82.89s/it, lr=0.00025, test_MAE=0.648, time=82.5, train_MAE=0.53, train_loss=0.53, val_MAE=0.618, val_loss=0.618] Epoch    29: reducing learning rate of group 0 to 1.2500e-04.
Epoch 28:   3%|▎         | 29/1000 [40:23<22:19:39, 82.78s/it, lr=0.00025, test_MAE=0.648, time=82.5, train_MAE=0.53, train_loss=0.53, val_MAE=0.618, val_loss=0.618]Epoch 29:   3%|▎         | 29/1000 [40:23<22:19:39, 82.78s/it, lr=0.00025, test_MAE=0.648, time=82.5, train_MAE=0.53, train_loss=0.53, val_MAE=0.618, val_loss=0.618]Epoch 29:   3%|▎         | 29/1000 [41:46<22:19:39, 82.78s/it, lr=0.000125, test_MAE=0.609, time=83.5, train_MAE=0.511, train_loss=0.511, val_MAE=0.566, val_loss=0.566]Epoch 29:   3%|▎         | 30/1000 [41:46<22:21:40, 82.99s/it, lr=0.000125, test_MAE=0.609, time=83.5, train_MAE=0.511, train_loss=0.511, val_MAE=0.566, val_loss=0.566]Epoch 30:   3%|▎         | 30/1000 [41:46<22:21:40, 82.99s/it, lr=0.000125, test_MAE=0.609, time=83.5, train_MAE=0.511, train_loss=0.511, val_MAE=0.566, val_loss=0.566]Epoch 30:   3%|▎         | 30/1000 [43:09<22:21:40, 82.99s/it, lr=0.000125, test_MAE=0.609, time=82.8, train_MAE=0.506, train_loss=0.506, val_MAE=0.57, val_loss=0.57]  Epoch 30:   3%|▎         | 31/1000 [43:09<22:19:28, 82.94s/it, lr=0.000125, test_MAE=0.609, time=82.8, train_MAE=0.506, train_loss=0.506, val_MAE=0.57, val_loss=0.57]Epoch 31:   3%|▎         | 31/1000 [43:09<22:19:28, 82.94s/it, lr=0.000125, test_MAE=0.609, time=82.8, train_MAE=0.506, train_loss=0.506, val_MAE=0.57, val_loss=0.57]Epoch 31:   3%|▎         | 31/1000 [44:31<22:19:28, 82.94s/it, lr=0.000125, test_MAE=0.598, time=82.4, train_MAE=0.503, train_loss=0.503, val_MAE=0.562, val_loss=0.562]Epoch 31:   3%|▎         | 32/1000 [44:31<22:15:38, 82.79s/it, lr=0.000125, test_MAE=0.598, time=82.4, train_MAE=0.503, train_loss=0.503, val_MAE=0.562, val_loss=0.562]Epoch 32:   3%|▎         | 32/1000 [44:31<22:15:38, 82.79s/it, lr=0.000125, test_MAE=0.598, time=82.4, train_MAE=0.503, train_loss=0.503, val_MAE=0.562, val_loss=0.562]Epoch 32:   3%|▎         | 32/1000 [45:55<22:15:38, 82.79s/it, lr=0.000125, test_MAE=0.618, time=83.2, train_MAE=0.511, train_loss=0.511, val_MAE=0.573, val_loss=0.573]Epoch 32:   3%|▎         | 33/1000 [45:55<22:16:05, 82.90s/it, lr=0.000125, test_MAE=0.618, time=83.2, train_MAE=0.511, train_loss=0.511, val_MAE=0.573, val_loss=0.573]Epoch 33:   3%|▎         | 33/1000 [45:55<22:16:05, 82.90s/it, lr=0.000125, test_MAE=0.618, time=83.2, train_MAE=0.511, train_loss=0.511, val_MAE=0.573, val_loss=0.573]Epoch 33:   3%|▎         | 33/1000 [47:18<22:16:05, 82.90s/it, lr=0.000125, test_MAE=0.6, time=83.5, train_MAE=0.512, train_loss=0.512, val_MAE=0.562, val_loss=0.562]  Epoch 33:   3%|▎         | 34/1000 [47:18<22:17:50, 83.10s/it, lr=0.000125, test_MAE=0.6, time=83.5, train_MAE=0.512, train_loss=0.512, val_MAE=0.562, val_loss=0.562]Epoch 34:   3%|▎         | 34/1000 [47:18<22:17:50, 83.10s/it, lr=0.000125, test_MAE=0.6, time=83.5, train_MAE=0.512, train_loss=0.512, val_MAE=0.562, val_loss=0.562]Epoch 34:   3%|▎         | 34/1000 [48:41<22:17:50, 83.10s/it, lr=0.000125, test_MAE=0.597, time=82.7, train_MAE=0.503, train_loss=0.503, val_MAE=0.563, val_loss=0.563]Epoch 34:   4%|▎         | 35/1000 [48:41<22:14:22, 82.97s/it, lr=0.000125, test_MAE=0.597, time=82.7, train_MAE=0.503, train_loss=0.503, val_MAE=0.563, val_loss=0.563]Epoch 35:   4%|▎         | 35/1000 [48:41<22:14:22, 82.97s/it, lr=0.000125, test_MAE=0.597, time=82.7, train_MAE=0.503, train_loss=0.503, val_MAE=0.563, val_loss=0.563]Epoch 35:   4%|▎         | 35/1000 [50:04<22:14:22, 82.97s/it, lr=0.000125, test_MAE=0.608, time=83.2, train_MAE=0.5, train_loss=0.5, val_MAE=0.577, val_loss=0.577]    Epoch 35:   4%|▎         | 36/1000 [50:04<22:14:00, 83.03s/it, lr=0.000125, test_MAE=0.608, time=83.2, train_MAE=0.5, train_loss=0.5, val_MAE=0.577, val_loss=0.577]Epoch 36:   4%|▎         | 36/1000 [50:04<22:14:00, 83.03s/it, lr=0.000125, test_MAE=0.608, time=83.2, train_MAE=0.5, train_loss=0.5, val_MAE=0.577, val_loss=0.577]Epoch 36:   4%|▎         | 36/1000 [51:28<22:14:00, 83.03s/it, lr=0.000125, test_MAE=0.606, time=83.9, train_MAE=0.507, train_loss=0.507, val_MAE=0.567, val_loss=0.567]Epoch 36:   4%|▎         | 37/1000 [51:28<22:17:09, 83.31s/it, lr=0.000125, test_MAE=0.606, time=83.9, train_MAE=0.507, train_loss=0.507, val_MAE=0.567, val_loss=0.567]Epoch 37:   4%|▎         | 37/1000 [51:28<22:17:09, 83.31s/it, lr=0.000125, test_MAE=0.606, time=83.9, train_MAE=0.507, train_loss=0.507, val_MAE=0.567, val_loss=0.567]Epoch 37:   4%|▎         | 37/1000 [52:51<22:17:09, 83.31s/it, lr=0.000125, test_MAE=0.612, time=82.7, train_MAE=0.5, train_loss=0.5, val_MAE=0.579, val_loss=0.579]    Epoch 37:   4%|▍         | 38/1000 [52:51<22:12:55, 83.13s/it, lr=0.000125, test_MAE=0.612, time=82.7, train_MAE=0.5, train_loss=0.5, val_MAE=0.579, val_loss=0.579]Epoch 38:   4%|▍         | 38/1000 [52:51<22:12:55, 83.13s/it, lr=0.000125, test_MAE=0.612, time=82.7, train_MAE=0.5, train_loss=0.5, val_MAE=0.579, val_loss=0.579]Epoch 38:   4%|▍         | 38/1000 [54:14<22:12:55, 83.13s/it, lr=0.000125, test_MAE=0.605, time=83.1, train_MAE=0.503, train_loss=0.503, val_MAE=0.57, val_loss=0.57]Epoch 38:   4%|▍         | 39/1000 [54:14<22:11:39, 83.14s/it, lr=0.000125, test_MAE=0.605, time=83.1, train_MAE=0.503, train_loss=0.503, val_MAE=0.57, val_loss=0.57]Epoch 39:   4%|▍         | 39/1000 [54:14<22:11:39, 83.14s/it, lr=0.000125, test_MAE=0.605, time=83.1, train_MAE=0.503, train_loss=0.503, val_MAE=0.57, val_loss=0.57]Epoch 39:   4%|▍         | 39/1000 [55:37<22:11:39, 83.14s/it, lr=0.000125, test_MAE=0.619, time=82.9, train_MAE=0.498, train_loss=0.498, val_MAE=0.584, val_loss=0.584]Epoch    40: reducing learning rate of group 0 to 6.2500e-05.
Epoch 39:   4%|▍         | 40/1000 [55:37<22:08:58, 83.06s/it, lr=0.000125, test_MAE=0.619, time=82.9, train_MAE=0.498, train_loss=0.498, val_MAE=0.584, val_loss=0.584]Epoch 40:   4%|▍         | 40/1000 [55:37<22:08:58, 83.06s/it, lr=0.000125, test_MAE=0.619, time=82.9, train_MAE=0.498, train_loss=0.498, val_MAE=0.584, val_loss=0.584]Epoch 40:   4%|▍         | 40/1000 [57:00<22:08:58, 83.06s/it, lr=6.25e-5, test_MAE=0.601, time=82.9, train_MAE=0.496, train_loss=0.496, val_MAE=0.566, val_loss=0.566] Epoch 40:   4%|▍         | 41/1000 [57:00<22:06:41, 83.01s/it, lr=6.25e-5, test_MAE=0.601, time=82.9, train_MAE=0.496, train_loss=0.496, val_MAE=0.566, val_loss=0.566]Epoch 41:   4%|▍         | 41/1000 [57:00<22:06:41, 83.01s/it, lr=6.25e-5, test_MAE=0.601, time=82.9, train_MAE=0.496, train_loss=0.496, val_MAE=0.566, val_loss=0.566]Epoch 41:   4%|▍         | 41/1000 [58:22<22:06:41, 83.01s/it, lr=6.25e-5, test_MAE=0.6, time=82.8, train_MAE=0.494, train_loss=0.494, val_MAE=0.561, val_loss=0.561]  Epoch 41:   4%|▍         | 42/1000 [58:22<22:04:17, 82.94s/it, lr=6.25e-5, test_MAE=0.6, time=82.8, train_MAE=0.494, train_loss=0.494, val_MAE=0.561, val_loss=0.561]Epoch 42:   4%|▍         | 42/1000 [58:22<22:04:17, 82.94s/it, lr=6.25e-5, test_MAE=0.6, time=82.8, train_MAE=0.494, train_loss=0.494, val_MAE=0.561, val_loss=0.561]Epoch 42:   4%|▍         | 42/1000 [59:45<22:04:17, 82.94s/it, lr=6.25e-5, test_MAE=0.605, time=83.2, train_MAE=0.488, train_loss=0.488, val_MAE=0.567, val_loss=0.567]Epoch 42:   4%|▍         | 43/1000 [59:46<22:04:03, 83.01s/it, lr=6.25e-5, test_MAE=0.605, time=83.2, train_MAE=0.488, train_loss=0.488, val_MAE=0.567, val_loss=0.567]Epoch 43:   4%|▍         | 43/1000 [59:46<22:04:03, 83.01s/it, lr=6.25e-5, test_MAE=0.605, time=83.2, train_MAE=0.488, train_loss=0.488, val_MAE=0.567, val_loss=0.567]Epoch 43:   4%|▍         | 43/1000 [1:01:08<22:04:03, 83.01s/it, lr=6.25e-5, test_MAE=0.602, time=82.4, train_MAE=0.489, train_loss=0.489, val_MAE=0.567, val_loss=0.567]Epoch 43:   4%|▍         | 44/1000 [1:01:08<22:00:00, 82.85s/it, lr=6.25e-5, test_MAE=0.602, time=82.4, train_MAE=0.489, train_loss=0.489, val_MAE=0.567, val_loss=0.567]Epoch 44:   4%|▍         | 44/1000 [1:01:08<22:00:00, 82.85s/it, lr=6.25e-5, test_MAE=0.602, time=82.4, train_MAE=0.489, train_loss=0.489, val_MAE=0.567, val_loss=0.567]Epoch 44:   4%|▍         | 44/1000 [1:02:31<22:00:00, 82.85s/it, lr=6.25e-5, test_MAE=0.598, time=83.2, train_MAE=0.486, train_loss=0.486, val_MAE=0.571, val_loss=0.571]Epoch 44:   4%|▍         | 45/1000 [1:02:31<22:00:14, 82.95s/it, lr=6.25e-5, test_MAE=0.598, time=83.2, train_MAE=0.486, train_loss=0.486, val_MAE=0.571, val_loss=0.571]Epoch 45:   4%|▍         | 45/1000 [1:02:31<22:00:14, 82.95s/it, lr=6.25e-5, test_MAE=0.598, time=83.2, train_MAE=0.486, train_loss=0.486, val_MAE=0.571, val_loss=0.571]Epoch 45:   4%|▍         | 45/1000 [1:03:54<22:00:14, 82.95s/it, lr=6.25e-5, test_MAE=0.606, time=83.1, train_MAE=0.488, train_loss=0.488, val_MAE=0.576, val_loss=0.576]Epoch 45:   5%|▍         | 46/1000 [1:03:54<21:59:35, 82.99s/it, lr=6.25e-5, test_MAE=0.606, time=83.1, train_MAE=0.488, train_loss=0.488, val_MAE=0.576, val_loss=0.576]Epoch 46:   5%|▍         | 46/1000 [1:03:54<21:59:35, 82.99s/it, lr=6.25e-5, test_MAE=0.606, time=83.1, train_MAE=0.488, train_loss=0.488, val_MAE=0.576, val_loss=0.576]Epoch 46:   5%|▍         | 46/1000 [1:05:17<21:59:35, 82.99s/it, lr=6.25e-5, test_MAE=0.6, time=82.9, train_MAE=0.492, train_loss=0.492, val_MAE=0.567, val_loss=0.567]  Epoch 46:   5%|▍         | 47/1000 [1:05:17<21:57:39, 82.96s/it, lr=6.25e-5, test_MAE=0.6, time=82.9, train_MAE=0.492, train_loss=0.492, val_MAE=0.567, val_loss=0.567]Epoch 47:   5%|▍         | 47/1000 [1:05:17<21:57:39, 82.96s/it, lr=6.25e-5, test_MAE=0.6, time=82.9, train_MAE=0.492, train_loss=0.492, val_MAE=0.567, val_loss=0.567]Epoch 47:   5%|▍         | 47/1000 [1:06:40<21:57:39, 82.96s/it, lr=6.25e-5, test_MAE=0.595, time=82.6, train_MAE=0.488, train_loss=0.488, val_MAE=0.564, val_loss=0.564]Epoch    48: reducing learning rate of group 0 to 3.1250e-05.
Epoch 47:   5%|▍         | 48/1000 [1:06:40<21:54:42, 82.86s/it, lr=6.25e-5, test_MAE=0.595, time=82.6, train_MAE=0.488, train_loss=0.488, val_MAE=0.564, val_loss=0.564]Epoch 48:   5%|▍         | 48/1000 [1:06:40<21:54:42, 82.86s/it, lr=6.25e-5, test_MAE=0.595, time=82.6, train_MAE=0.488, train_loss=0.488, val_MAE=0.564, val_loss=0.564]Epoch 48:   5%|▍         | 48/1000 [1:08:03<21:54:42, 82.86s/it, lr=3.13e-5, test_MAE=0.598, time=83.2, train_MAE=0.491, train_loss=0.491, val_MAE=0.568, val_loss=0.568]Epoch 48:   5%|▍         | 49/1000 [1:08:03<21:54:45, 82.95s/it, lr=3.13e-5, test_MAE=0.598, time=83.2, train_MAE=0.491, train_loss=0.491, val_MAE=0.568, val_loss=0.568]Epoch 49:   5%|▍         | 49/1000 [1:08:03<21:54:45, 82.95s/it, lr=3.13e-5, test_MAE=0.598, time=83.2, train_MAE=0.491, train_loss=0.491, val_MAE=0.568, val_loss=0.568]Epoch 49:   5%|▍         | 49/1000 [1:09:26<21:54:45, 82.95s/it, lr=3.13e-5, test_MAE=0.604, time=83, train_MAE=0.48, train_loss=0.48, val_MAE=0.569, val_loss=0.569]    Epoch 49:   5%|▌         | 50/1000 [1:09:26<21:53:31, 82.96s/it, lr=3.13e-5, test_MAE=0.604, time=83, train_MAE=0.48, train_loss=0.48, val_MAE=0.569, val_loss=0.569]Epoch 50:   5%|▌         | 50/1000 [1:09:26<21:53:31, 82.96s/it, lr=3.13e-5, test_MAE=0.604, time=83, train_MAE=0.48, train_loss=0.48, val_MAE=0.569, val_loss=0.569]Epoch 50:   5%|▌         | 50/1000 [1:10:48<21:53:31, 82.96s/it, lr=3.13e-5, test_MAE=0.595, time=81.6, train_MAE=0.503, train_loss=0.503, val_MAE=0.564, val_loss=0.564]Epoch 50:   5%|▌         | 51/1000 [1:10:48<21:45:54, 82.56s/it, lr=3.13e-5, test_MAE=0.595, time=81.6, train_MAE=0.503, train_loss=0.503, val_MAE=0.564, val_loss=0.564]Epoch 51:   5%|▌         | 51/1000 [1:10:48<21:45:54, 82.56s/it, lr=3.13e-5, test_MAE=0.595, time=81.6, train_MAE=0.503, train_loss=0.503, val_MAE=0.564, val_loss=0.564]Epoch 51:   5%|▌         | 51/1000 [1:12:08<21:45:54, 82.56s/it, lr=3.13e-5, test_MAE=0.598, time=80.7, train_MAE=0.48, train_loss=0.48, val_MAE=0.565, val_loss=0.565]  Epoch 51:   5%|▌         | 52/1000 [1:12:08<21:35:40, 82.00s/it, lr=3.13e-5, test_MAE=0.598, time=80.7, train_MAE=0.48, train_loss=0.48, val_MAE=0.565, val_loss=0.565]Epoch 52:   5%|▌         | 52/1000 [1:12:08<21:35:40, 82.00s/it, lr=3.13e-5, test_MAE=0.598, time=80.7, train_MAE=0.48, train_loss=0.48, val_MAE=0.565, val_loss=0.565]Epoch 52:   5%|▌         | 52/1000 [1:13:27<21:35:40, 82.00s/it, lr=3.13e-5, test_MAE=0.602, time=78.5, train_MAE=0.48, train_loss=0.48, val_MAE=0.566, val_loss=0.566]Epoch 52:   5%|▌         | 53/1000 [1:13:27<21:17:33, 80.94s/it, lr=3.13e-5, test_MAE=0.602, time=78.5, train_MAE=0.48, train_loss=0.48, val_MAE=0.566, val_loss=0.566]Epoch 53:   5%|▌         | 53/1000 [1:13:27<21:17:33, 80.94s/it, lr=3.13e-5, test_MAE=0.602, time=78.5, train_MAE=0.48, train_loss=0.48, val_MAE=0.566, val_loss=0.566]Epoch 53:   5%|▌         | 53/1000 [1:14:45<21:17:33, 80.94s/it, lr=3.13e-5, test_MAE=0.599, time=77.8, train_MAE=0.481, train_loss=0.481, val_MAE=0.565, val_loss=0.565]Epoch    54: reducing learning rate of group 0 to 1.5625e-05.
Epoch 53:   5%|▌         | 54/1000 [1:14:45<21:01:24, 80.00s/it, lr=3.13e-5, test_MAE=0.599, time=77.8, train_MAE=0.481, train_loss=0.481, val_MAE=0.565, val_loss=0.565]Epoch 54:   5%|▌         | 54/1000 [1:14:45<21:01:24, 80.00s/it, lr=3.13e-5, test_MAE=0.599, time=77.8, train_MAE=0.481, train_loss=0.481, val_MAE=0.565, val_loss=0.565]Epoch 54:   5%|▌         | 54/1000 [1:16:02<21:01:24, 80.00s/it, lr=1.56e-5, test_MAE=0.598, time=77.1, train_MAE=0.48, train_loss=0.48, val_MAE=0.568, val_loss=0.568]  Epoch 54:   6%|▌         | 55/1000 [1:16:02<20:46:23, 79.14s/it, lr=1.56e-5, test_MAE=0.598, time=77.1, train_MAE=0.48, train_loss=0.48, val_MAE=0.568, val_loss=0.568]Epoch 55:   6%|▌         | 55/1000 [1:16:02<20:46:23, 79.14s/it, lr=1.56e-5, test_MAE=0.598, time=77.1, train_MAE=0.48, train_loss=0.48, val_MAE=0.568, val_loss=0.568]Epoch 55:   6%|▌         | 55/1000 [1:17:18<20:46:23, 79.14s/it, lr=1.56e-5, test_MAE=0.6, time=76.8, train_MAE=0.477, train_loss=0.477, val_MAE=0.565, val_loss=0.565]Epoch 55:   6%|▌         | 56/1000 [1:17:18<20:34:20, 78.45s/it, lr=1.56e-5, test_MAE=0.6, time=76.8, train_MAE=0.477, train_loss=0.477, val_MAE=0.565, val_loss=0.565]Epoch 56:   6%|▌         | 56/1000 [1:17:18<20:34:20, 78.45s/it, lr=1.56e-5, test_MAE=0.6, time=76.8, train_MAE=0.477, train_loss=0.477, val_MAE=0.565, val_loss=0.565]Epoch 56:   6%|▌         | 56/1000 [1:18:36<20:34:20, 78.45s/it, lr=1.56e-5, test_MAE=0.612, time=77.3, train_MAE=0.477, train_loss=0.477, val_MAE=0.574, val_loss=0.574]Epoch 56:   6%|▌         | 57/1000 [1:18:36<20:27:52, 78.13s/it, lr=1.56e-5, test_MAE=0.612, time=77.3, train_MAE=0.477, train_loss=0.477, val_MAE=0.574, val_loss=0.574]Epoch 57:   6%|▌         | 57/1000 [1:18:36<20:27:52, 78.13s/it, lr=1.56e-5, test_MAE=0.612, time=77.3, train_MAE=0.477, train_loss=0.477, val_MAE=0.574, val_loss=0.574]Epoch 57:   6%|▌         | 57/1000 [1:19:53<20:27:52, 78.13s/it, lr=1.56e-5, test_MAE=0.597, time=77.1, train_MAE=0.477, train_loss=0.477, val_MAE=0.563, val_loss=0.563]Epoch 57:   6%|▌         | 58/1000 [1:19:53<20:21:41, 77.81s/it, lr=1.56e-5, test_MAE=0.597, time=77.1, train_MAE=0.477, train_loss=0.477, val_MAE=0.563, val_loss=0.563]Epoch 58:   6%|▌         | 58/1000 [1:19:53<20:21:41, 77.81s/it, lr=1.56e-5, test_MAE=0.597, time=77.1, train_MAE=0.477, train_loss=0.477, val_MAE=0.563, val_loss=0.563]Epoch 58:   6%|▌         | 58/1000 [1:21:10<20:21:41, 77.81s/it, lr=1.56e-5, test_MAE=0.6, time=77.1, train_MAE=0.48, train_loss=0.48, val_MAE=0.565, val_loss=0.565]    Epoch 58:   6%|▌         | 59/1000 [1:21:10<20:17:07, 77.61s/it, lr=1.56e-5, test_MAE=0.6, time=77.1, train_MAE=0.48, train_loss=0.48, val_MAE=0.565, val_loss=0.565]Epoch 59:   6%|▌         | 59/1000 [1:21:10<20:17:07, 77.61s/it, lr=1.56e-5, test_MAE=0.6, time=77.1, train_MAE=0.48, train_loss=0.48, val_MAE=0.565, val_loss=0.565]Epoch 59:   6%|▌         | 59/1000 [1:22:27<20:17:07, 77.61s/it, lr=1.56e-5, test_MAE=0.602, time=77.1, train_MAE=0.48, train_loss=0.48, val_MAE=0.566, val_loss=0.566]Epoch    60: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 59:   6%|▌         | 59/1000 [1:22:27<21:55:10, 83.86s/it, lr=1.56e-5, test_MAE=0.602, time=77.1, train_MAE=0.48, train_loss=0.48, val_MAE=0.566, val_loss=0.566]
Test MAE: 0.6020
Train MAE: 0.4569
Convergence Time (Epochs): 59.0000
TOTAL TIME TAKEN: 4990.6290s
AVG TIME PER EPOCH: 82.4459s
