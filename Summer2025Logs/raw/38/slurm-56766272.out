I'm echoing to stdout
I'm echoing to stderr
My JobID is 56766272
I have 8 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.0504s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 2, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'parallel_dense_simp', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_all', 'num_eigs': 15, 'bias_mode': '', 'eigval_hidden_dim': 5, 'eigval_num_hidden_layer': 3, 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 0.1, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/zinc_train_rec_full.csv', 'test': 'supp_data/molecules/zinc_test_rec_full.csv', 'val': 'supp_data/molecules/zinc_val_rec_full.csv'}, 'fixMissingPhi1': False, 'extraOrtho': True, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [03:14<?, ?it/s, lr=0.001, test_MAE=1.47, time=194, train_MAE=0.925, train_loss=0.93, val_MAE=1.4, val_loss=1.4]Epoch 0:   0%|          | 1/1000 [03:14<53:53:12, 194.19s/it, lr=0.001, test_MAE=1.47, time=194, train_MAE=0.925, train_loss=0.93, val_MAE=1.4, val_loss=1.4]Epoch 1:   0%|          | 1/1000 [03:14<53:53:12, 194.19s/it, lr=0.001, test_MAE=1.47, time=194, train_MAE=0.925, train_loss=0.93, val_MAE=1.4, val_loss=1.4]Epoch 1:   0%|          | 1/1000 [04:02<53:53:12, 194.19s/it, lr=0.001, test_MAE=1.05, time=48.8, train_MAE=0.676, train_loss=0.681, val_MAE=1.01, val_loss=1.02]Epoch 1:   0%|          | 2/1000 [04:02<41:44:32, 150.57s/it, lr=0.001, test_MAE=1.05, time=48.8, train_MAE=0.676, train_loss=0.681, val_MAE=1.01, val_loss=1.02]Epoch 2:   0%|          | 2/1000 [04:02<41:44:32, 150.57s/it, lr=0.001, test_MAE=1.05, time=48.8, train_MAE=0.676, train_loss=0.681, val_MAE=1.01, val_loss=1.02]Epoch 2:   0%|          | 2/1000 [04:51<41:44:32, 150.57s/it, lr=0.001, test_MAE=1.3, time=48.8, train_MAE=0.657, train_loss=0.663, val_MAE=1.24, val_loss=1.25] Epoch 2:   0%|          | 3/1000 [04:51<33:14:36, 120.04s/it, lr=0.001, test_MAE=1.3, time=48.8, train_MAE=0.657, train_loss=0.663, val_MAE=1.24, val_loss=1.25]Epoch 3:   0%|          | 3/1000 [04:51<33:14:36, 120.04s/it, lr=0.001, test_MAE=1.3, time=48.8, train_MAE=0.657, train_loss=0.663, val_MAE=1.24, val_loss=1.25]Epoch 3:   0%|          | 3/1000 [05:40<33:14:36, 120.04s/it, lr=0.001, test_MAE=0.774, time=48.8, train_MAE=0.637, train_loss=0.643, val_MAE=0.7, val_loss=0.706]Epoch 3:   0%|          | 4/1000 [05:40<27:17:43, 98.66s/it, lr=0.001, test_MAE=0.774, time=48.8, train_MAE=0.637, train_loss=0.643, val_MAE=0.7, val_loss=0.706] Epoch 4:   0%|          | 4/1000 [05:40<27:17:43, 98.66s/it, lr=0.001, test_MAE=0.774, time=48.8, train_MAE=0.637, train_loss=0.643, val_MAE=0.7, val_loss=0.706]Epoch 4:   0%|          | 4/1000 [06:29<27:17:43, 98.66s/it, lr=0.001, test_MAE=0.783, time=48.8, train_MAE=0.623, train_loss=0.629, val_MAE=0.723, val_loss=0.729]Epoch 4:   0%|          | 5/1000 [06:29<23:07:59, 83.70s/it, lr=0.001, test_MAE=0.783, time=48.8, train_MAE=0.623, train_loss=0.629, val_MAE=0.723, val_loss=0.729]Epoch 5:   0%|          | 5/1000 [06:29<23:07:59, 83.70s/it, lr=0.001, test_MAE=0.783, time=48.8, train_MAE=0.623, train_loss=0.629, val_MAE=0.723, val_loss=0.729]Epoch 5:   0%|          | 5/1000 [07:18<23:07:59, 83.70s/it, lr=0.001, test_MAE=0.844, time=48.9, train_MAE=0.621, train_loss=0.627, val_MAE=0.784, val_loss=0.79] Epoch 5:   1%|          | 6/1000 [07:18<20:13:51, 73.27s/it, lr=0.001, test_MAE=0.844, time=48.9, train_MAE=0.621, train_loss=0.627, val_MAE=0.784, val_loss=0.79]Epoch 6:   1%|          | 6/1000 [07:18<20:13:51, 73.27s/it, lr=0.001, test_MAE=0.844, time=48.9, train_MAE=0.621, train_loss=0.627, val_MAE=0.784, val_loss=0.79]Epoch 6:   1%|          | 6/1000 [08:07<20:13:51, 73.27s/it, lr=0.001, test_MAE=0.7, time=49.2, train_MAE=0.619, train_loss=0.625, val_MAE=0.648, val_loss=0.654] Epoch 6:   1%|          | 7/1000 [08:07<18:12:58, 66.04s/it, lr=0.001, test_MAE=0.7, time=49.2, train_MAE=0.619, train_loss=0.625, val_MAE=0.648, val_loss=0.654]Epoch 7:   1%|          | 7/1000 [08:07<18:12:58, 66.04s/it, lr=0.001, test_MAE=0.7, time=49.2, train_MAE=0.619, train_loss=0.625, val_MAE=0.648, val_loss=0.654]Epoch 7:   1%|          | 7/1000 [08:56<18:12:58, 66.04s/it, lr=0.001, test_MAE=0.709, time=48.9, train_MAE=0.601, train_loss=0.608, val_MAE=0.648, val_loss=0.654]Epoch 7:   1%|          | 8/1000 [08:56<16:46:47, 60.89s/it, lr=0.001, test_MAE=0.709, time=48.9, train_MAE=0.601, train_loss=0.608, val_MAE=0.648, val_loss=0.654]Epoch 8:   1%|          | 8/1000 [08:56<16:46:47, 60.89s/it, lr=0.001, test_MAE=0.709, time=48.9, train_MAE=0.601, train_loss=0.608, val_MAE=0.648, val_loss=0.654]Epoch 8:   1%|          | 8/1000 [09:45<16:46:47, 60.89s/it, lr=0.001, test_MAE=0.728, time=48.9, train_MAE=0.591, train_loss=0.598, val_MAE=0.646, val_loss=0.653]Epoch 8:   1%|          | 9/1000 [09:45<15:46:34, 57.31s/it, lr=0.001, test_MAE=0.728, time=48.9, train_MAE=0.591, train_loss=0.598, val_MAE=0.646, val_loss=0.653]Epoch 9:   1%|          | 9/1000 [09:45<15:46:34, 57.31s/it, lr=0.001, test_MAE=0.728, time=48.9, train_MAE=0.591, train_loss=0.598, val_MAE=0.646, val_loss=0.653]Epoch 9:   1%|          | 9/1000 [10:34<15:46:34, 57.31s/it, lr=0.001, test_MAE=0.69, time=49.2, train_MAE=0.594, train_loss=0.601, val_MAE=0.629, val_loss=0.636] Epoch 9:   1%|          | 10/1000 [10:34<15:05:37, 54.89s/it, lr=0.001, test_MAE=0.69, time=49.2, train_MAE=0.594, train_loss=0.601, val_MAE=0.629, val_loss=0.636]Epoch 10:   1%|          | 10/1000 [10:34<15:05:37, 54.89s/it, lr=0.001, test_MAE=0.69, time=49.2, train_MAE=0.594, train_loss=0.601, val_MAE=0.629, val_loss=0.636]Epoch 10:   1%|          | 10/1000 [11:23<15:05:37, 54.89s/it, lr=0.001, test_MAE=0.731, time=48.9, train_MAE=0.574, train_loss=0.582, val_MAE=0.676, val_loss=0.684]Epoch 10:   1%|          | 11/1000 [11:23<14:35:15, 53.10s/it, lr=0.001, test_MAE=0.731, time=48.9, train_MAE=0.574, train_loss=0.582, val_MAE=0.676, val_loss=0.684]Epoch 11:   1%|          | 11/1000 [11:23<14:35:15, 53.10s/it, lr=0.001, test_MAE=0.731, time=48.9, train_MAE=0.574, train_loss=0.582, val_MAE=0.676, val_loss=0.684]Epoch 11:   1%|          | 11/1000 [12:11<14:35:15, 53.10s/it, lr=0.001, test_MAE=0.707, time=48.5, train_MAE=0.573, train_loss=0.581, val_MAE=0.653, val_loss=0.661]Epoch 11:   1%|          | 12/1000 [12:11<14:11:52, 51.73s/it, lr=0.001, test_MAE=0.707, time=48.5, train_MAE=0.573, train_loss=0.581, val_MAE=0.653, val_loss=0.661]Epoch 12:   1%|          | 12/1000 [12:11<14:11:52, 51.73s/it, lr=0.001, test_MAE=0.707, time=48.5, train_MAE=0.573, train_loss=0.581, val_MAE=0.653, val_loss=0.661]Epoch 12:   1%|          | 12/1000 [13:01<14:11:52, 51.73s/it, lr=0.001, test_MAE=0.73, time=49.2, train_MAE=0.562, train_loss=0.57, val_MAE=0.672, val_loss=0.68]   Epoch 12:   1%|▏         | 13/1000 [13:01<13:58:36, 50.98s/it, lr=0.001, test_MAE=0.73, time=49.2, train_MAE=0.562, train_loss=0.57, val_MAE=0.672, val_loss=0.68]Epoch 13:   1%|▏         | 13/1000 [13:01<13:58:36, 50.98s/it, lr=0.001, test_MAE=0.73, time=49.2, train_MAE=0.562, train_loss=0.57, val_MAE=0.672, val_loss=0.68]Epoch 13:   1%|▏         | 13/1000 [13:50<13:58:36, 50.98s/it, lr=0.001, test_MAE=0.735, time=48.9, train_MAE=0.564, train_loss=0.572, val_MAE=0.678, val_loss=0.686]Epoch 13:   1%|▏         | 14/1000 [13:50<13:47:34, 50.36s/it, lr=0.001, test_MAE=0.735, time=48.9, train_MAE=0.564, train_loss=0.572, val_MAE=0.678, val_loss=0.686]Epoch 14:   1%|▏         | 14/1000 [13:50<13:47:34, 50.36s/it, lr=0.001, test_MAE=0.735, time=48.9, train_MAE=0.564, train_loss=0.572, val_MAE=0.678, val_loss=0.686]Epoch 14:   1%|▏         | 14/1000 [14:38<13:47:34, 50.36s/it, lr=0.001, test_MAE=0.715, time=48.6, train_MAE=0.558, train_loss=0.566, val_MAE=0.657, val_loss=0.665]Epoch 14:   2%|▏         | 15/1000 [14:38<13:38:15, 49.84s/it, lr=0.001, test_MAE=0.715, time=48.6, train_MAE=0.558, train_loss=0.566, val_MAE=0.657, val_loss=0.665]Epoch 15:   2%|▏         | 15/1000 [14:38<13:38:15, 49.84s/it, lr=0.001, test_MAE=0.715, time=48.6, train_MAE=0.558, train_loss=0.566, val_MAE=0.657, val_loss=0.665]Epoch 15:   2%|▏         | 15/1000 [15:28<13:38:15, 49.84s/it, lr=0.001, test_MAE=0.712, time=49.3, train_MAE=0.539, train_loss=0.548, val_MAE=0.656, val_loss=0.665]Epoch    16: reducing learning rate of group 0 to 5.0000e-04.
Epoch 15:   2%|▏         | 16/1000 [15:28<13:34:38, 49.67s/it, lr=0.001, test_MAE=0.712, time=49.3, train_MAE=0.539, train_loss=0.548, val_MAE=0.656, val_loss=0.665]Epoch 16:   2%|▏         | 16/1000 [15:28<13:34:38, 49.67s/it, lr=0.001, test_MAE=0.712, time=49.3, train_MAE=0.539, train_loss=0.548, val_MAE=0.656, val_loss=0.665]Epoch 16:   2%|▏         | 16/1000 [16:16<13:34:38, 49.67s/it, lr=0.0005, test_MAE=0.677, time=48.8, train_MAE=0.508, train_loss=0.517, val_MAE=0.617, val_loss=0.626]Epoch 16:   2%|▏         | 17/1000 [16:16<13:29:36, 49.42s/it, lr=0.0005, test_MAE=0.677, time=48.8, train_MAE=0.508, train_loss=0.517, val_MAE=0.617, val_loss=0.626]Epoch 17:   2%|▏         | 17/1000 [16:16<13:29:36, 49.42s/it, lr=0.0005, test_MAE=0.677, time=48.8, train_MAE=0.508, train_loss=0.517, val_MAE=0.617, val_loss=0.626]Epoch 17:   2%|▏         | 17/1000 [17:05<13:29:36, 49.42s/it, lr=0.0005, test_MAE=0.72, time=48.2, train_MAE=0.489, train_loss=0.498, val_MAE=0.653, val_loss=0.663] Epoch 17:   2%|▏         | 18/1000 [17:05<13:22:46, 49.05s/it, lr=0.0005, test_MAE=0.72, time=48.2, train_MAE=0.489, train_loss=0.498, val_MAE=0.653, val_loss=0.663]Epoch 18:   2%|▏         | 18/1000 [17:05<13:22:46, 49.05s/it, lr=0.0005, test_MAE=0.72, time=48.2, train_MAE=0.489, train_loss=0.498, val_MAE=0.653, val_loss=0.663]Epoch 18:   2%|▏         | 18/1000 [17:53<13:22:46, 49.05s/it, lr=0.0005, test_MAE=0.701, time=48.2, train_MAE=0.486, train_loss=0.496, val_MAE=0.639, val_loss=0.649]Epoch 18:   2%|▏         | 19/1000 [17:53<13:17:48, 48.80s/it, lr=0.0005, test_MAE=0.701, time=48.2, train_MAE=0.486, train_loss=0.496, val_MAE=0.639, val_loss=0.649]Epoch 19:   2%|▏         | 19/1000 [17:53<13:17:48, 48.80s/it, lr=0.0005, test_MAE=0.701, time=48.2, train_MAE=0.486, train_loss=0.496, val_MAE=0.639, val_loss=0.649]Epoch 19:   2%|▏         | 19/1000 [18:40<13:17:48, 48.80s/it, lr=0.0005, test_MAE=0.7, time=47.3, train_MAE=0.473, train_loss=0.482, val_MAE=0.639, val_loss=0.648]  Epoch 19:   2%|▏         | 20/1000 [18:40<13:09:56, 48.36s/it, lr=0.0005, test_MAE=0.7, time=47.3, train_MAE=0.473, train_loss=0.482, val_MAE=0.639, val_loss=0.648]Epoch 20:   2%|▏         | 20/1000 [18:40<13:09:56, 48.36s/it, lr=0.0005, test_MAE=0.7, time=47.3, train_MAE=0.473, train_loss=0.482, val_MAE=0.639, val_loss=0.648]Epoch 20:   2%|▏         | 20/1000 [19:27<13:09:56, 48.36s/it, lr=0.0005, test_MAE=0.833, time=46.6, train_MAE=0.472, train_loss=0.481, val_MAE=0.774, val_loss=0.783]Epoch 20:   2%|▏         | 21/1000 [19:27<13:00:25, 47.83s/it, lr=0.0005, test_MAE=0.833, time=46.6, train_MAE=0.472, train_loss=0.481, val_MAE=0.774, val_loss=0.783]Epoch 21:   2%|▏         | 21/1000 [19:27<13:00:25, 47.83s/it, lr=0.0005, test_MAE=0.833, time=46.6, train_MAE=0.472, train_loss=0.481, val_MAE=0.774, val_loss=0.783]Epoch 21:   2%|▏         | 21/1000 [20:13<13:00:25, 47.83s/it, lr=0.0005, test_MAE=0.693, time=46.3, train_MAE=0.472, train_loss=0.482, val_MAE=0.636, val_loss=0.646]Epoch 21:   2%|▏         | 22/1000 [20:13<12:52:16, 47.38s/it, lr=0.0005, test_MAE=0.693, time=46.3, train_MAE=0.472, train_loss=0.482, val_MAE=0.636, val_loss=0.646]Epoch 22:   2%|▏         | 22/1000 [20:13<12:52:16, 47.38s/it, lr=0.0005, test_MAE=0.693, time=46.3, train_MAE=0.472, train_loss=0.482, val_MAE=0.636, val_loss=0.646]Epoch 22:   2%|▏         | 22/1000 [20:59<12:52:16, 47.38s/it, lr=0.0005, test_MAE=0.692, time=45.7, train_MAE=0.461, train_loss=0.47, val_MAE=0.629, val_loss=0.638] Epoch    23: reducing learning rate of group 0 to 2.5000e-04.
Epoch 22:   2%|▏         | 23/1000 [20:59<12:43:15, 46.87s/it, lr=0.0005, test_MAE=0.692, time=45.7, train_MAE=0.461, train_loss=0.47, val_MAE=0.629, val_loss=0.638]Epoch 23:   2%|▏         | 23/1000 [20:59<12:43:15, 46.87s/it, lr=0.0005, test_MAE=0.692, time=45.7, train_MAE=0.461, train_loss=0.47, val_MAE=0.629, val_loss=0.638]Epoch 23:   2%|▏         | 23/1000 [21:45<12:43:15, 46.87s/it, lr=0.00025, test_MAE=0.7, time=46.2, train_MAE=0.444, train_loss=0.453, val_MAE=0.64, val_loss=0.649] Epoch 23:   2%|▏         | 24/1000 [21:45<12:39:25, 46.69s/it, lr=0.00025, test_MAE=0.7, time=46.2, train_MAE=0.444, train_loss=0.453, val_MAE=0.64, val_loss=0.649]Epoch 24:   2%|▏         | 24/1000 [21:45<12:39:25, 46.69s/it, lr=0.00025, test_MAE=0.7, time=46.2, train_MAE=0.444, train_loss=0.453, val_MAE=0.64, val_loss=0.649]Epoch 24:   2%|▏         | 24/1000 [22:31<12:39:25, 46.69s/it, lr=0.00025, test_MAE=0.682, time=46, train_MAE=0.419, train_loss=0.429, val_MAE=0.632, val_loss=0.641]Epoch 24:   2%|▎         | 25/1000 [22:31<12:35:12, 46.47s/it, lr=0.00025, test_MAE=0.682, time=46, train_MAE=0.419, train_loss=0.429, val_MAE=0.632, val_loss=0.641]Epoch 25:   2%|▎         | 25/1000 [22:31<12:35:12, 46.47s/it, lr=0.00025, test_MAE=0.682, time=46, train_MAE=0.419, train_loss=0.429, val_MAE=0.632, val_loss=0.641]Epoch 25:   2%|▎         | 25/1000 [23:17<12:35:12, 46.47s/it, lr=0.00025, test_MAE=0.693, time=46, train_MAE=0.418, train_loss=0.428, val_MAE=0.635, val_loss=0.645]Epoch 25:   3%|▎         | 26/1000 [23:17<12:32:02, 46.33s/it, lr=0.00025, test_MAE=0.693, time=46, train_MAE=0.418, train_loss=0.428, val_MAE=0.635, val_loss=0.645]Epoch 26:   3%|▎         | 26/1000 [23:17<12:32:02, 46.33s/it, lr=0.00025, test_MAE=0.693, time=46, train_MAE=0.418, train_loss=0.428, val_MAE=0.635, val_loss=0.645]Epoch 26:   3%|▎         | 26/1000 [24:03<12:32:02, 46.33s/it, lr=0.00025, test_MAE=0.71, time=46.2, train_MAE=0.419, train_loss=0.429, val_MAE=0.648, val_loss=0.657]Epoch 26:   3%|▎         | 27/1000 [24:03<12:30:52, 46.30s/it, lr=0.00025, test_MAE=0.71, time=46.2, train_MAE=0.419, train_loss=0.429, val_MAE=0.648, val_loss=0.657]Epoch 27:   3%|▎         | 27/1000 [24:03<12:30:52, 46.30s/it, lr=0.00025, test_MAE=0.71, time=46.2, train_MAE=0.419, train_loss=0.429, val_MAE=0.648, val_loss=0.657]Epoch 27:   3%|▎         | 27/1000 [24:49<12:30:52, 46.30s/it, lr=0.00025, test_MAE=0.697, time=45.9, train_MAE=0.411, train_loss=0.421, val_MAE=0.639, val_loss=0.648]Epoch 27:   3%|▎         | 28/1000 [24:49<12:28:26, 46.20s/it, lr=0.00025, test_MAE=0.697, time=45.9, train_MAE=0.411, train_loss=0.421, val_MAE=0.639, val_loss=0.648]Epoch 28:   3%|▎         | 28/1000 [24:49<12:28:26, 46.20s/it, lr=0.00025, test_MAE=0.697, time=45.9, train_MAE=0.411, train_loss=0.421, val_MAE=0.639, val_loss=0.648]Epoch 28:   3%|▎         | 28/1000 [25:35<12:28:26, 46.20s/it, lr=0.00025, test_MAE=0.711, time=45.7, train_MAE=0.421, train_loss=0.431, val_MAE=0.654, val_loss=0.664]Epoch    29: reducing learning rate of group 0 to 1.2500e-04.
Epoch 28:   3%|▎         | 29/1000 [25:35<12:25:23, 46.06s/it, lr=0.00025, test_MAE=0.711, time=45.7, train_MAE=0.421, train_loss=0.431, val_MAE=0.654, val_loss=0.664]Epoch 29:   3%|▎         | 29/1000 [25:35<12:25:23, 46.06s/it, lr=0.00025, test_MAE=0.711, time=45.7, train_MAE=0.421, train_loss=0.431, val_MAE=0.654, val_loss=0.664]Epoch 29:   3%|▎         | 29/1000 [26:21<12:25:23, 46.06s/it, lr=0.000125, test_MAE=0.711, time=46.5, train_MAE=0.391, train_loss=0.401, val_MAE=0.653, val_loss=0.663]Epoch 29:   3%|▎         | 30/1000 [26:21<12:26:48, 46.19s/it, lr=0.000125, test_MAE=0.711, time=46.5, train_MAE=0.391, train_loss=0.401, val_MAE=0.653, val_loss=0.663]Epoch 30:   3%|▎         | 30/1000 [26:21<12:26:48, 46.19s/it, lr=0.000125, test_MAE=0.711, time=46.5, train_MAE=0.391, train_loss=0.401, val_MAE=0.653, val_loss=0.663]Epoch 30:   3%|▎         | 30/1000 [27:07<12:26:48, 46.19s/it, lr=0.000125, test_MAE=0.718, time=46, train_MAE=0.385, train_loss=0.394, val_MAE=0.659, val_loss=0.669]  Epoch 30:   3%|▎         | 31/1000 [27:07<12:25:08, 46.14s/it, lr=0.000125, test_MAE=0.718, time=46, train_MAE=0.385, train_loss=0.394, val_MAE=0.659, val_loss=0.669]Epoch 31:   3%|▎         | 31/1000 [27:07<12:25:08, 46.14s/it, lr=0.000125, test_MAE=0.718, time=46, train_MAE=0.385, train_loss=0.394, val_MAE=0.659, val_loss=0.669]Epoch 31:   3%|▎         | 31/1000 [27:53<12:25:08, 46.14s/it, lr=0.000125, test_MAE=0.715, time=45.7, train_MAE=0.373, train_loss=0.383, val_MAE=0.656, val_loss=0.666]Epoch 31:   3%|▎         | 32/1000 [27:53<12:22:05, 46.00s/it, lr=0.000125, test_MAE=0.715, time=45.7, train_MAE=0.373, train_loss=0.383, val_MAE=0.656, val_loss=0.666]Epoch 32:   3%|▎         | 32/1000 [27:53<12:22:05, 46.00s/it, lr=0.000125, test_MAE=0.715, time=45.7, train_MAE=0.373, train_loss=0.383, val_MAE=0.656, val_loss=0.666]Epoch 32:   3%|▎         | 32/1000 [28:39<12:22:05, 46.00s/it, lr=0.000125, test_MAE=0.712, time=46.2, train_MAE=0.374, train_loss=0.384, val_MAE=0.653, val_loss=0.662]Epoch 32:   3%|▎         | 33/1000 [28:39<12:22:30, 46.07s/it, lr=0.000125, test_MAE=0.712, time=46.2, train_MAE=0.374, train_loss=0.384, val_MAE=0.653, val_loss=0.662]Epoch 33:   3%|▎         | 33/1000 [28:39<12:22:30, 46.07s/it, lr=0.000125, test_MAE=0.712, time=46.2, train_MAE=0.374, train_loss=0.384, val_MAE=0.653, val_loss=0.662]Epoch 33:   3%|▎         | 33/1000 [29:25<12:22:30, 46.07s/it, lr=0.000125, test_MAE=0.774, time=46, train_MAE=0.37, train_loss=0.38, val_MAE=0.723, val_loss=0.733]    Epoch 33:   3%|▎         | 34/1000 [29:25<12:21:17, 46.04s/it, lr=0.000125, test_MAE=0.774, time=46, train_MAE=0.37, train_loss=0.38, val_MAE=0.723, val_loss=0.733]Epoch 34:   3%|▎         | 34/1000 [29:25<12:21:17, 46.04s/it, lr=0.000125, test_MAE=0.774, time=46, train_MAE=0.37, train_loss=0.38, val_MAE=0.723, val_loss=0.733]Epoch 34:   3%|▎         | 34/1000 [30:11<12:21:17, 46.04s/it, lr=0.000125, test_MAE=0.741, time=45.7, train_MAE=0.37, train_loss=0.38, val_MAE=0.677, val_loss=0.687]Epoch    35: reducing learning rate of group 0 to 6.2500e-05.
Epoch 34:   4%|▎         | 35/1000 [30:11<12:18:48, 45.94s/it, lr=0.000125, test_MAE=0.741, time=45.7, train_MAE=0.37, train_loss=0.38, val_MAE=0.677, val_loss=0.687]Epoch 35:   4%|▎         | 35/1000 [30:11<12:18:48, 45.94s/it, lr=0.000125, test_MAE=0.741, time=45.7, train_MAE=0.37, train_loss=0.38, val_MAE=0.677, val_loss=0.687]Epoch 35:   4%|▎         | 35/1000 [30:57<12:18:48, 45.94s/it, lr=6.25e-5, test_MAE=0.729, time=46.2, train_MAE=0.362, train_loss=0.372, val_MAE=0.664, val_loss=0.674]Epoch 35:   4%|▎         | 36/1000 [30:57<12:19:23, 46.02s/it, lr=6.25e-5, test_MAE=0.729, time=46.2, train_MAE=0.362, train_loss=0.372, val_MAE=0.664, val_loss=0.674]Epoch 36:   4%|▎         | 36/1000 [30:57<12:19:23, 46.02s/it, lr=6.25e-5, test_MAE=0.729, time=46.2, train_MAE=0.362, train_loss=0.372, val_MAE=0.664, val_loss=0.674]Epoch 36:   4%|▎         | 36/1000 [31:43<12:19:23, 46.02s/it, lr=6.25e-5, test_MAE=0.717, time=46, train_MAE=0.359, train_loss=0.369, val_MAE=0.656, val_loss=0.666]  Epoch 36:   4%|▎         | 37/1000 [31:43<12:18:49, 46.03s/it, lr=6.25e-5, test_MAE=0.717, time=46, train_MAE=0.359, train_loss=0.369, val_MAE=0.656, val_loss=0.666]Epoch 37:   4%|▎         | 37/1000 [31:43<12:18:49, 46.03s/it, lr=6.25e-5, test_MAE=0.717, time=46, train_MAE=0.359, train_loss=0.369, val_MAE=0.656, val_loss=0.666]Epoch 37:   4%|▎         | 37/1000 [32:29<12:18:49, 46.03s/it, lr=6.25e-5, test_MAE=0.716, time=46.1, train_MAE=0.352, train_loss=0.362, val_MAE=0.663, val_loss=0.673]Epoch 37:   4%|▍         | 38/1000 [32:29<12:18:14, 46.04s/it, lr=6.25e-5, test_MAE=0.716, time=46.1, train_MAE=0.352, train_loss=0.362, val_MAE=0.663, val_loss=0.673]Epoch 38:   4%|▍         | 38/1000 [32:29<12:18:14, 46.04s/it, lr=6.25e-5, test_MAE=0.716, time=46.1, train_MAE=0.352, train_loss=0.362, val_MAE=0.663, val_loss=0.673]Epoch 38:   4%|▍         | 38/1000 [33:16<12:18:14, 46.04s/it, lr=6.25e-5, test_MAE=0.718, time=46.7, train_MAE=0.36, train_loss=0.37, val_MAE=0.662, val_loss=0.672]  Epoch 38:   4%|▍         | 39/1000 [33:16<12:20:25, 46.23s/it, lr=6.25e-5, test_MAE=0.718, time=46.7, train_MAE=0.36, train_loss=0.37, val_MAE=0.662, val_loss=0.672]Epoch 39:   4%|▍         | 39/1000 [33:16<12:20:25, 46.23s/it, lr=6.25e-5, test_MAE=0.718, time=46.7, train_MAE=0.36, train_loss=0.37, val_MAE=0.662, val_loss=0.672]Epoch 39:   4%|▍         | 39/1000 [34:02<12:20:25, 46.23s/it, lr=6.25e-5, test_MAE=0.715, time=46.3, train_MAE=0.346, train_loss=0.356, val_MAE=0.657, val_loss=0.667]Epoch 39:   4%|▍         | 40/1000 [34:02<12:20:12, 46.26s/it, lr=6.25e-5, test_MAE=0.715, time=46.3, train_MAE=0.346, train_loss=0.356, val_MAE=0.657, val_loss=0.667]Epoch 40:   4%|▍         | 40/1000 [34:02<12:20:12, 46.26s/it, lr=6.25e-5, test_MAE=0.715, time=46.3, train_MAE=0.346, train_loss=0.356, val_MAE=0.657, val_loss=0.667]Epoch 40:   4%|▍         | 40/1000 [34:49<12:20:12, 46.26s/it, lr=6.25e-5, test_MAE=0.722, time=46.4, train_MAE=0.38, train_loss=0.389, val_MAE=0.664, val_loss=0.674] Epoch    41: reducing learning rate of group 0 to 3.1250e-05.
Epoch 40:   4%|▍         | 41/1000 [34:49<12:19:55, 46.29s/it, lr=6.25e-5, test_MAE=0.722, time=46.4, train_MAE=0.38, train_loss=0.389, val_MAE=0.664, val_loss=0.674]Epoch 41:   4%|▍         | 41/1000 [34:49<12:19:55, 46.29s/it, lr=6.25e-5, test_MAE=0.722, time=46.4, train_MAE=0.38, train_loss=0.389, val_MAE=0.664, val_loss=0.674]Epoch 41:   4%|▍         | 41/1000 [35:35<12:19:55, 46.29s/it, lr=3.13e-5, test_MAE=0.718, time=46.6, train_MAE=0.352, train_loss=0.362, val_MAE=0.663, val_loss=0.672]Epoch 41:   4%|▍         | 42/1000 [35:35<12:20:49, 46.40s/it, lr=3.13e-5, test_MAE=0.718, time=46.6, train_MAE=0.352, train_loss=0.362, val_MAE=0.663, val_loss=0.672]Epoch 42:   4%|▍         | 42/1000 [35:35<12:20:49, 46.40s/it, lr=3.13e-5, test_MAE=0.718, time=46.6, train_MAE=0.352, train_loss=0.362, val_MAE=0.663, val_loss=0.672]Epoch 42:   4%|▍         | 42/1000 [36:21<12:20:49, 46.40s/it, lr=3.13e-5, test_MAE=0.723, time=46.1, train_MAE=0.345, train_loss=0.354, val_MAE=0.671, val_loss=0.681]Epoch 42:   4%|▍         | 43/1000 [36:21<12:18:30, 46.30s/it, lr=3.13e-5, test_MAE=0.723, time=46.1, train_MAE=0.345, train_loss=0.354, val_MAE=0.671, val_loss=0.681]Epoch 43:   4%|▍         | 43/1000 [36:21<12:18:30, 46.30s/it, lr=3.13e-5, test_MAE=0.723, time=46.1, train_MAE=0.345, train_loss=0.354, val_MAE=0.671, val_loss=0.681]Epoch 43:   4%|▍         | 43/1000 [37:08<12:18:30, 46.30s/it, lr=3.13e-5, test_MAE=0.723, time=46.6, train_MAE=0.353, train_loss=0.362, val_MAE=0.667, val_loss=0.677]Epoch 43:   4%|▍         | 44/1000 [37:08<12:19:16, 46.40s/it, lr=3.13e-5, test_MAE=0.723, time=46.6, train_MAE=0.353, train_loss=0.362, val_MAE=0.667, val_loss=0.677]Epoch 44:   4%|▍         | 44/1000 [37:08<12:19:16, 46.40s/it, lr=3.13e-5, test_MAE=0.723, time=46.6, train_MAE=0.353, train_loss=0.362, val_MAE=0.667, val_loss=0.677]Epoch 44:   4%|▍         | 44/1000 [37:54<12:19:16, 46.40s/it, lr=3.13e-5, test_MAE=0.725, time=46.4, train_MAE=0.349, train_loss=0.359, val_MAE=0.665, val_loss=0.675]Epoch 44:   4%|▍         | 45/1000 [37:54<12:18:23, 46.39s/it, lr=3.13e-5, test_MAE=0.725, time=46.4, train_MAE=0.349, train_loss=0.359, val_MAE=0.665, val_loss=0.675]Epoch 45:   4%|▍         | 45/1000 [37:54<12:18:23, 46.39s/it, lr=3.13e-5, test_MAE=0.725, time=46.4, train_MAE=0.349, train_loss=0.359, val_MAE=0.665, val_loss=0.675]Epoch 45:   4%|▍         | 45/1000 [38:41<12:18:23, 46.39s/it, lr=3.13e-5, test_MAE=0.719, time=46.4, train_MAE=0.346, train_loss=0.356, val_MAE=0.661, val_loss=0.67] Epoch 45:   5%|▍         | 46/1000 [38:41<12:17:35, 46.39s/it, lr=3.13e-5, test_MAE=0.719, time=46.4, train_MAE=0.346, train_loss=0.356, val_MAE=0.661, val_loss=0.67]Epoch 46:   5%|▍         | 46/1000 [38:41<12:17:35, 46.39s/it, lr=3.13e-5, test_MAE=0.719, time=46.4, train_MAE=0.346, train_loss=0.356, val_MAE=0.661, val_loss=0.67]Epoch 46:   5%|▍         | 46/1000 [39:27<12:17:35, 46.39s/it, lr=3.13e-5, test_MAE=0.728, time=46.6, train_MAE=0.345, train_loss=0.354, val_MAE=0.672, val_loss=0.682]Epoch    47: reducing learning rate of group 0 to 1.5625e-05.
Epoch 46:   5%|▍         | 47/1000 [39:27<12:18:01, 46.47s/it, lr=3.13e-5, test_MAE=0.728, time=46.6, train_MAE=0.345, train_loss=0.354, val_MAE=0.672, val_loss=0.682]Epoch 47:   5%|▍         | 47/1000 [39:27<12:18:01, 46.47s/it, lr=3.13e-5, test_MAE=0.728, time=46.6, train_MAE=0.345, train_loss=0.354, val_MAE=0.672, val_loss=0.682]Epoch 47:   5%|▍         | 47/1000 [40:14<12:18:01, 46.47s/it, lr=1.56e-5, test_MAE=0.723, time=46.4, train_MAE=0.342, train_loss=0.352, val_MAE=0.664, val_loss=0.673]Epoch 47:   5%|▍         | 48/1000 [40:14<12:16:45, 46.43s/it, lr=1.56e-5, test_MAE=0.723, time=46.4, train_MAE=0.342, train_loss=0.352, val_MAE=0.664, val_loss=0.673]Epoch 48:   5%|▍         | 48/1000 [40:14<12:16:45, 46.43s/it, lr=1.56e-5, test_MAE=0.723, time=46.4, train_MAE=0.342, train_loss=0.352, val_MAE=0.664, val_loss=0.673]Epoch 48:   5%|▍         | 48/1000 [41:00<12:16:45, 46.43s/it, lr=1.56e-5, test_MAE=0.728, time=46.1, train_MAE=0.347, train_loss=0.357, val_MAE=0.668, val_loss=0.678]Epoch 48:   5%|▍         | 49/1000 [41:00<12:14:24, 46.33s/it, lr=1.56e-5, test_MAE=0.728, time=46.1, train_MAE=0.347, train_loss=0.357, val_MAE=0.668, val_loss=0.678]Epoch 49:   5%|▍         | 49/1000 [41:00<12:14:24, 46.33s/it, lr=1.56e-5, test_MAE=0.728, time=46.1, train_MAE=0.347, train_loss=0.357, val_MAE=0.668, val_loss=0.678]Epoch 49:   5%|▍         | 49/1000 [41:47<12:14:24, 46.33s/it, lr=1.56e-5, test_MAE=0.727, time=46.9, train_MAE=0.34, train_loss=0.35, val_MAE=0.671, val_loss=0.68]   Epoch 49:   5%|▌         | 50/1000 [41:47<12:16:24, 46.51s/it, lr=1.56e-5, test_MAE=0.727, time=46.9, train_MAE=0.34, train_loss=0.35, val_MAE=0.671, val_loss=0.68]Epoch 50:   5%|▌         | 50/1000 [41:47<12:16:24, 46.51s/it, lr=1.56e-5, test_MAE=0.727, time=46.9, train_MAE=0.34, train_loss=0.35, val_MAE=0.671, val_loss=0.68]Epoch 50:   5%|▌         | 50/1000 [42:33<12:16:24, 46.51s/it, lr=1.56e-5, test_MAE=0.728, time=46.4, train_MAE=0.331, train_loss=0.341, val_MAE=0.668, val_loss=0.678]Epoch 50:   5%|▌         | 51/1000 [42:33<12:14:56, 46.47s/it, lr=1.56e-5, test_MAE=0.728, time=46.4, train_MAE=0.331, train_loss=0.341, val_MAE=0.668, val_loss=0.678]Epoch 51:   5%|▌         | 51/1000 [42:33<12:14:56, 46.47s/it, lr=1.56e-5, test_MAE=0.728, time=46.4, train_MAE=0.331, train_loss=0.341, val_MAE=0.668, val_loss=0.678]Epoch 51:   5%|▌         | 51/1000 [43:19<12:14:56, 46.47s/it, lr=1.56e-5, test_MAE=0.726, time=46.1, train_MAE=0.34, train_loss=0.349, val_MAE=0.668, val_loss=0.678] Epoch 51:   5%|▌         | 52/1000 [43:19<12:12:17, 46.35s/it, lr=1.56e-5, test_MAE=0.726, time=46.1, train_MAE=0.34, train_loss=0.349, val_MAE=0.668, val_loss=0.678]Epoch 52:   5%|▌         | 52/1000 [43:19<12:12:17, 46.35s/it, lr=1.56e-5, test_MAE=0.726, time=46.1, train_MAE=0.34, train_loss=0.349, val_MAE=0.668, val_loss=0.678]Epoch 52:   5%|▌         | 52/1000 [44:06<12:12:17, 46.35s/it, lr=1.56e-5, test_MAE=0.723, time=46.6, train_MAE=0.336, train_loss=0.346, val_MAE=0.665, val_loss=0.674]Epoch    53: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 52:   5%|▌         | 52/1000 [44:06<13:24:05, 50.89s/it, lr=1.56e-5, test_MAE=0.723, time=46.6, train_MAE=0.336, train_loss=0.346, val_MAE=0.665, val_loss=0.674]
Test MAE: 0.7228
Train MAE: 0.3053
Convergence Time (Epochs): 52.0000
TOTAL TIME TAKEN: 2678.2662s
AVG TIME PER EPOCH: 49.9198s
