I'm echoing to stdout
I'm echoing to stderr
My JobID is 56763220
I have 8 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.0729s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 2, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'parallel_dense_simp', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_all', 'num_eigs': 64, 'bias_mode': '', 'eigval_hidden_dim': 5, 'eigval_num_hidden_layer': 3, 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 0.0, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/zinc_train_rec_full.csv', 'test': 'supp_data/molecules/zinc_test_rec_full.csv', 'val': 'supp_data/molecules/zinc_val_rec_full.csv'}, 'fixMissingPhi1': False, 'extraOrtho': True, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [03:17<?, ?it/s, lr=0.001, test_MAE=1.47, time=197, train_MAE=1.02, train_loss=1.02, val_MAE=1.41, val_loss=1.41]Epoch 0:   0%|          | 1/1000 [03:17<54:44:33, 197.27s/it, lr=0.001, test_MAE=1.47, time=197, train_MAE=1.02, train_loss=1.02, val_MAE=1.41, val_loss=1.41]Epoch 1:   0%|          | 1/1000 [03:17<54:44:33, 197.27s/it, lr=0.001, test_MAE=1.47, time=197, train_MAE=1.02, train_loss=1.02, val_MAE=1.41, val_loss=1.41]Epoch 1:   0%|          | 1/1000 [04:07<54:44:33, 197.27s/it, lr=0.001, test_MAE=0.922, time=50.5, train_MAE=0.695, train_loss=0.695, val_MAE=0.886, val_loss=0.886]Epoch 1:   0%|          | 2/1000 [04:07<42:29:08, 153.26s/it, lr=0.001, test_MAE=0.922, time=50.5, train_MAE=0.695, train_loss=0.695, val_MAE=0.886, val_loss=0.886]Epoch 2:   0%|          | 2/1000 [04:07<42:29:08, 153.26s/it, lr=0.001, test_MAE=0.922, time=50.5, train_MAE=0.695, train_loss=0.695, val_MAE=0.886, val_loss=0.886]Epoch 2:   0%|          | 2/1000 [04:58<42:29:08, 153.26s/it, lr=0.001, test_MAE=0.718, time=50.9, train_MAE=0.656, train_loss=0.656, val_MAE=0.668, val_loss=0.668]Epoch 2:   0%|          | 3/1000 [04:58<33:56:09, 122.54s/it, lr=0.001, test_MAE=0.718, time=50.9, train_MAE=0.656, train_loss=0.656, val_MAE=0.668, val_loss=0.668]Epoch 3:   0%|          | 3/1000 [04:58<33:56:09, 122.54s/it, lr=0.001, test_MAE=0.718, time=50.9, train_MAE=0.656, train_loss=0.656, val_MAE=0.668, val_loss=0.668]Epoch 3:   0%|          | 3/1000 [05:49<33:56:09, 122.54s/it, lr=0.001, test_MAE=0.83, time=51, train_MAE=0.618, train_loss=0.618, val_MAE=0.775, val_loss=0.775]   Epoch 3:   0%|          | 4/1000 [05:49<27:57:39, 101.06s/it, lr=0.001, test_MAE=0.83, time=51, train_MAE=0.618, train_loss=0.618, val_MAE=0.775, val_loss=0.775]Epoch 4:   0%|          | 4/1000 [05:49<27:57:39, 101.06s/it, lr=0.001, test_MAE=0.83, time=51, train_MAE=0.618, train_loss=0.618, val_MAE=0.775, val_loss=0.775]Epoch 4:   0%|          | 4/1000 [06:40<27:57:39, 101.06s/it, lr=0.001, test_MAE=0.711, time=50.7, train_MAE=0.604, train_loss=0.604, val_MAE=0.659, val_loss=0.659]Epoch 4:   0%|          | 5/1000 [06:40<23:45:31, 85.96s/it, lr=0.001, test_MAE=0.711, time=50.7, train_MAE=0.604, train_loss=0.604, val_MAE=0.659, val_loss=0.659] Epoch 5:   0%|          | 5/1000 [06:40<23:45:31, 85.96s/it, lr=0.001, test_MAE=0.711, time=50.7, train_MAE=0.604, train_loss=0.604, val_MAE=0.659, val_loss=0.659]Epoch 5:   0%|          | 5/1000 [07:30<23:45:31, 85.96s/it, lr=0.001, test_MAE=0.71, time=50.3, train_MAE=0.608, train_loss=0.608, val_MAE=0.675, val_loss=0.675] Epoch 5:   1%|          | 6/1000 [07:30<20:47:06, 75.28s/it, lr=0.001, test_MAE=0.71, time=50.3, train_MAE=0.608, train_loss=0.608, val_MAE=0.675, val_loss=0.675]Epoch 6:   1%|          | 6/1000 [07:30<20:47:06, 75.28s/it, lr=0.001, test_MAE=0.71, time=50.3, train_MAE=0.608, train_loss=0.608, val_MAE=0.675, val_loss=0.675]Epoch 6:   1%|          | 6/1000 [08:21<20:47:06, 75.28s/it, lr=0.001, test_MAE=0.742, time=50.3, train_MAE=0.579, train_loss=0.579, val_MAE=0.685, val_loss=0.685]Epoch 6:   1%|          | 7/1000 [08:21<18:41:58, 67.79s/it, lr=0.001, test_MAE=0.742, time=50.3, train_MAE=0.579, train_loss=0.579, val_MAE=0.685, val_loss=0.685]Epoch 7:   1%|          | 7/1000 [08:21<18:41:58, 67.79s/it, lr=0.001, test_MAE=0.742, time=50.3, train_MAE=0.579, train_loss=0.579, val_MAE=0.685, val_loss=0.685]Epoch 7:   1%|          | 7/1000 [09:10<18:41:58, 67.79s/it, lr=0.001, test_MAE=0.792, time=49.4, train_MAE=0.571, train_loss=0.571, val_MAE=0.738, val_loss=0.738]Epoch 7:   1%|          | 8/1000 [09:10<17:09:46, 62.28s/it, lr=0.001, test_MAE=0.792, time=49.4, train_MAE=0.571, train_loss=0.571, val_MAE=0.738, val_loss=0.738]Epoch 8:   1%|          | 8/1000 [09:10<17:09:46, 62.28s/it, lr=0.001, test_MAE=0.792, time=49.4, train_MAE=0.571, train_loss=0.571, val_MAE=0.738, val_loss=0.738]Epoch 8:   1%|          | 8/1000 [09:59<17:09:46, 62.28s/it, lr=0.001, test_MAE=0.696, time=48.6, train_MAE=0.56, train_loss=0.56, val_MAE=0.64, val_loss=0.64]    Epoch 8:   1%|          | 9/1000 [09:59<16:01:06, 58.19s/it, lr=0.001, test_MAE=0.696, time=48.6, train_MAE=0.56, train_loss=0.56, val_MAE=0.64, val_loss=0.64]Epoch 9:   1%|          | 9/1000 [09:59<16:01:06, 58.19s/it, lr=0.001, test_MAE=0.696, time=48.6, train_MAE=0.56, train_loss=0.56, val_MAE=0.64, val_loss=0.64]Epoch 9:   1%|          | 9/1000 [10:47<16:01:06, 58.19s/it, lr=0.001, test_MAE=0.719, time=48.3, train_MAE=0.542, train_loss=0.542, val_MAE=0.656, val_loss=0.656]Epoch 9:   1%|          | 10/1000 [10:47<15:11:09, 55.22s/it, lr=0.001, test_MAE=0.719, time=48.3, train_MAE=0.542, train_loss=0.542, val_MAE=0.656, val_loss=0.656]Epoch 10:   1%|          | 10/1000 [10:47<15:11:09, 55.22s/it, lr=0.001, test_MAE=0.719, time=48.3, train_MAE=0.542, train_loss=0.542, val_MAE=0.656, val_loss=0.656]Epoch 10:   1%|          | 10/1000 [11:35<15:11:09, 55.22s/it, lr=0.001, test_MAE=0.685, time=47.8, train_MAE=0.541, train_loss=0.541, val_MAE=0.63, val_loss=0.63]  Epoch 10:   1%|          | 11/1000 [11:35<14:33:42, 53.01s/it, lr=0.001, test_MAE=0.685, time=47.8, train_MAE=0.541, train_loss=0.541, val_MAE=0.63, val_loss=0.63]Epoch 11:   1%|          | 11/1000 [11:35<14:33:42, 53.01s/it, lr=0.001, test_MAE=0.685, time=47.8, train_MAE=0.541, train_loss=0.541, val_MAE=0.63, val_loss=0.63]Epoch 11:   1%|          | 11/1000 [12:22<14:33:42, 53.01s/it, lr=0.001, test_MAE=0.705, time=47.4, train_MAE=0.527, train_loss=0.527, val_MAE=0.671, val_loss=0.671]Epoch 11:   1%|          | 12/1000 [12:22<14:05:05, 51.32s/it, lr=0.001, test_MAE=0.705, time=47.4, train_MAE=0.527, train_loss=0.527, val_MAE=0.671, val_loss=0.671]Epoch 12:   1%|          | 12/1000 [12:22<14:05:05, 51.32s/it, lr=0.001, test_MAE=0.705, time=47.4, train_MAE=0.527, train_loss=0.527, val_MAE=0.671, val_loss=0.671]Epoch 12:   1%|          | 12/1000 [13:10<14:05:05, 51.32s/it, lr=0.001, test_MAE=0.767, time=47.9, train_MAE=0.517, train_loss=0.517, val_MAE=0.711, val_loss=0.711]Epoch 12:   1%|▏         | 13/1000 [13:10<13:47:31, 50.31s/it, lr=0.001, test_MAE=0.767, time=47.9, train_MAE=0.517, train_loss=0.517, val_MAE=0.711, val_loss=0.711]Epoch 13:   1%|▏         | 13/1000 [13:10<13:47:31, 50.31s/it, lr=0.001, test_MAE=0.767, time=47.9, train_MAE=0.517, train_loss=0.517, val_MAE=0.711, val_loss=0.711]Epoch 13:   1%|▏         | 13/1000 [13:58<13:47:31, 50.31s/it, lr=0.001, test_MAE=0.685, time=47.6, train_MAE=0.504, train_loss=0.504, val_MAE=0.641, val_loss=0.641]Epoch 13:   1%|▏         | 14/1000 [13:58<13:33:30, 49.50s/it, lr=0.001, test_MAE=0.685, time=47.6, train_MAE=0.504, train_loss=0.504, val_MAE=0.641, val_loss=0.641]Epoch 14:   1%|▏         | 14/1000 [13:58<13:33:30, 49.50s/it, lr=0.001, test_MAE=0.685, time=47.6, train_MAE=0.504, train_loss=0.504, val_MAE=0.641, val_loss=0.641]Epoch 14:   1%|▏         | 14/1000 [14:45<13:33:30, 49.50s/it, lr=0.001, test_MAE=0.859, time=47.2, train_MAE=0.49, train_loss=0.49, val_MAE=0.798, val_loss=0.798]  Epoch 14:   2%|▏         | 15/1000 [14:45<13:21:17, 48.81s/it, lr=0.001, test_MAE=0.859, time=47.2, train_MAE=0.49, train_loss=0.49, val_MAE=0.798, val_loss=0.798]Epoch 15:   2%|▏         | 15/1000 [14:45<13:21:17, 48.81s/it, lr=0.001, test_MAE=0.859, time=47.2, train_MAE=0.49, train_loss=0.49, val_MAE=0.798, val_loss=0.798]Epoch 15:   2%|▏         | 15/1000 [15:33<13:21:17, 48.81s/it, lr=0.001, test_MAE=0.699, time=47.6, train_MAE=0.485, train_loss=0.485, val_MAE=0.655, val_loss=0.655]Epoch 15:   2%|▏         | 16/1000 [15:33<13:14:41, 48.46s/it, lr=0.001, test_MAE=0.699, time=47.6, train_MAE=0.485, train_loss=0.485, val_MAE=0.655, val_loss=0.655]Epoch 16:   2%|▏         | 16/1000 [15:33<13:14:41, 48.46s/it, lr=0.001, test_MAE=0.699, time=47.6, train_MAE=0.485, train_loss=0.485, val_MAE=0.655, val_loss=0.655]Epoch 16:   2%|▏         | 16/1000 [16:20<13:14:41, 48.46s/it, lr=0.001, test_MAE=0.692, time=47.4, train_MAE=0.474, train_loss=0.474, val_MAE=0.645, val_loss=0.645]Epoch    17: reducing learning rate of group 0 to 5.0000e-04.
Epoch 16:   2%|▏         | 17/1000 [16:20<13:08:35, 48.13s/it, lr=0.001, test_MAE=0.692, time=47.4, train_MAE=0.474, train_loss=0.474, val_MAE=0.645, val_loss=0.645]Epoch 17:   2%|▏         | 17/1000 [16:20<13:08:35, 48.13s/it, lr=0.001, test_MAE=0.692, time=47.4, train_MAE=0.474, train_loss=0.474, val_MAE=0.645, val_loss=0.645]Epoch 17:   2%|▏         | 17/1000 [17:07<13:08:35, 48.13s/it, lr=0.0005, test_MAE=0.724, time=47.1, train_MAE=0.436, train_loss=0.436, val_MAE=0.67, val_loss=0.67] Epoch 17:   2%|▏         | 18/1000 [17:07<13:02:42, 47.82s/it, lr=0.0005, test_MAE=0.724, time=47.1, train_MAE=0.436, train_loss=0.436, val_MAE=0.67, val_loss=0.67]Epoch 18:   2%|▏         | 18/1000 [17:07<13:02:42, 47.82s/it, lr=0.0005, test_MAE=0.724, time=47.1, train_MAE=0.436, train_loss=0.436, val_MAE=0.67, val_loss=0.67]Epoch 18:   2%|▏         | 18/1000 [17:55<13:02:42, 47.82s/it, lr=0.0005, test_MAE=0.705, time=47.7, train_MAE=0.42, train_loss=0.42, val_MAE=0.652, val_loss=0.652]Epoch 18:   2%|▏         | 19/1000 [17:55<13:01:07, 47.77s/it, lr=0.0005, test_MAE=0.705, time=47.7, train_MAE=0.42, train_loss=0.42, val_MAE=0.652, val_loss=0.652]Epoch 19:   2%|▏         | 19/1000 [17:55<13:01:07, 47.77s/it, lr=0.0005, test_MAE=0.705, time=47.7, train_MAE=0.42, train_loss=0.42, val_MAE=0.652, val_loss=0.652]Epoch 19:   2%|▏         | 19/1000 [18:42<13:01:07, 47.77s/it, lr=0.0005, test_MAE=0.845, time=47.3, train_MAE=0.408, train_loss=0.408, val_MAE=0.795, val_loss=0.795]Epoch 19:   2%|▏         | 20/1000 [18:42<12:58:08, 47.64s/it, lr=0.0005, test_MAE=0.845, time=47.3, train_MAE=0.408, train_loss=0.408, val_MAE=0.795, val_loss=0.795]Epoch 20:   2%|▏         | 20/1000 [18:42<12:58:08, 47.64s/it, lr=0.0005, test_MAE=0.845, time=47.3, train_MAE=0.408, train_loss=0.408, val_MAE=0.795, val_loss=0.795]Epoch 20:   2%|▏         | 20/1000 [19:29<12:58:08, 47.64s/it, lr=0.0005, test_MAE=0.695, time=47.4, train_MAE=0.41, train_loss=0.41, val_MAE=0.653, val_loss=0.653]  Epoch 20:   2%|▏         | 21/1000 [19:29<12:56:03, 47.56s/it, lr=0.0005, test_MAE=0.695, time=47.4, train_MAE=0.41, train_loss=0.41, val_MAE=0.653, val_loss=0.653]Epoch 21:   2%|▏         | 21/1000 [19:29<12:56:03, 47.56s/it, lr=0.0005, test_MAE=0.695, time=47.4, train_MAE=0.41, train_loss=0.41, val_MAE=0.653, val_loss=0.653]Epoch 21:   2%|▏         | 21/1000 [20:17<12:56:03, 47.56s/it, lr=0.0005, test_MAE=0.704, time=47.6, train_MAE=0.383, train_loss=0.383, val_MAE=0.652, val_loss=0.652]Epoch 21:   2%|▏         | 22/1000 [20:17<12:55:31, 47.58s/it, lr=0.0005, test_MAE=0.704, time=47.6, train_MAE=0.383, train_loss=0.383, val_MAE=0.652, val_loss=0.652]Epoch 22:   2%|▏         | 22/1000 [20:17<12:55:31, 47.58s/it, lr=0.0005, test_MAE=0.704, time=47.6, train_MAE=0.383, train_loss=0.383, val_MAE=0.652, val_loss=0.652]Epoch 22:   2%|▏         | 22/1000 [21:04<12:55:31, 47.58s/it, lr=0.0005, test_MAE=0.708, time=47.1, train_MAE=0.396, train_loss=0.396, val_MAE=0.669, val_loss=0.669]Epoch    23: reducing learning rate of group 0 to 2.5000e-04.
Epoch 22:   2%|▏         | 23/1000 [21:04<12:52:18, 47.43s/it, lr=0.0005, test_MAE=0.708, time=47.1, train_MAE=0.396, train_loss=0.396, val_MAE=0.669, val_loss=0.669]Epoch 23:   2%|▏         | 23/1000 [21:04<12:52:18, 47.43s/it, lr=0.0005, test_MAE=0.708, time=47.1, train_MAE=0.396, train_loss=0.396, val_MAE=0.669, val_loss=0.669]Epoch 23:   2%|▏         | 23/1000 [21:52<12:52:18, 47.43s/it, lr=0.00025, test_MAE=0.703, time=47.6, train_MAE=0.369, train_loss=0.369, val_MAE=0.656, val_loss=0.656]Epoch 23:   2%|▏         | 24/1000 [21:52<12:52:32, 47.49s/it, lr=0.00025, test_MAE=0.703, time=47.6, train_MAE=0.369, train_loss=0.369, val_MAE=0.656, val_loss=0.656]Epoch 24:   2%|▏         | 24/1000 [21:52<12:52:32, 47.49s/it, lr=0.00025, test_MAE=0.703, time=47.6, train_MAE=0.369, train_loss=0.369, val_MAE=0.656, val_loss=0.656]Epoch 24:   2%|▏         | 24/1000 [22:39<12:52:32, 47.49s/it, lr=0.00025, test_MAE=0.743, time=47.3, train_MAE=0.351, train_loss=0.351, val_MAE=0.686, val_loss=0.686]Epoch 24:   2%|▎         | 25/1000 [22:39<12:50:59, 47.45s/it, lr=0.00025, test_MAE=0.743, time=47.3, train_MAE=0.351, train_loss=0.351, val_MAE=0.686, val_loss=0.686]Epoch 25:   2%|▎         | 25/1000 [22:39<12:50:59, 47.45s/it, lr=0.00025, test_MAE=0.743, time=47.3, train_MAE=0.351, train_loss=0.351, val_MAE=0.686, val_loss=0.686]Epoch 25:   2%|▎         | 25/1000 [23:26<12:50:59, 47.45s/it, lr=0.00025, test_MAE=0.716, time=47.3, train_MAE=0.331, train_loss=0.331, val_MAE=0.664, val_loss=0.664]Epoch 25:   3%|▎         | 26/1000 [23:26<12:49:45, 47.42s/it, lr=0.00025, test_MAE=0.716, time=47.3, train_MAE=0.331, train_loss=0.331, val_MAE=0.664, val_loss=0.664]Epoch 26:   3%|▎         | 26/1000 [23:26<12:49:45, 47.42s/it, lr=0.00025, test_MAE=0.716, time=47.3, train_MAE=0.331, train_loss=0.331, val_MAE=0.664, val_loss=0.664]Epoch 26:   3%|▎         | 26/1000 [24:14<12:49:45, 47.42s/it, lr=0.00025, test_MAE=0.707, time=47.6, train_MAE=0.324, train_loss=0.324, val_MAE=0.659, val_loss=0.659]Epoch 26:   3%|▎         | 27/1000 [24:14<12:49:56, 47.48s/it, lr=0.00025, test_MAE=0.707, time=47.6, train_MAE=0.324, train_loss=0.324, val_MAE=0.659, val_loss=0.659]Epoch 27:   3%|▎         | 27/1000 [24:14<12:49:56, 47.48s/it, lr=0.00025, test_MAE=0.707, time=47.6, train_MAE=0.324, train_loss=0.324, val_MAE=0.659, val_loss=0.659]Epoch 27:   3%|▎         | 27/1000 [25:01<12:49:56, 47.48s/it, lr=0.00025, test_MAE=0.72, time=47.3, train_MAE=0.326, train_loss=0.326, val_MAE=0.668, val_loss=0.668] Epoch 27:   3%|▎         | 28/1000 [25:01<12:48:24, 47.43s/it, lr=0.00025, test_MAE=0.72, time=47.3, train_MAE=0.326, train_loss=0.326, val_MAE=0.668, val_loss=0.668]Epoch 28:   3%|▎         | 28/1000 [25:01<12:48:24, 47.43s/it, lr=0.00025, test_MAE=0.72, time=47.3, train_MAE=0.326, train_loss=0.326, val_MAE=0.668, val_loss=0.668]Epoch 28:   3%|▎         | 28/1000 [25:48<12:48:24, 47.43s/it, lr=0.00025, test_MAE=0.751, time=47.1, train_MAE=0.331, train_loss=0.331, val_MAE=0.707, val_loss=0.707]Epoch    29: reducing learning rate of group 0 to 1.2500e-04.
Epoch 28:   3%|▎         | 29/1000 [25:48<12:45:59, 47.33s/it, lr=0.00025, test_MAE=0.751, time=47.1, train_MAE=0.331, train_loss=0.331, val_MAE=0.707, val_loss=0.707]Epoch 29:   3%|▎         | 29/1000 [25:48<12:45:59, 47.33s/it, lr=0.00025, test_MAE=0.751, time=47.1, train_MAE=0.331, train_loss=0.331, val_MAE=0.707, val_loss=0.707]Epoch 29:   3%|▎         | 29/1000 [26:36<12:45:59, 47.33s/it, lr=0.000125, test_MAE=0.703, time=47.9, train_MAE=0.314, train_loss=0.314, val_MAE=0.654, val_loss=0.654]Epoch 29:   3%|▎         | 30/1000 [26:36<12:47:53, 47.50s/it, lr=0.000125, test_MAE=0.703, time=47.9, train_MAE=0.314, train_loss=0.314, val_MAE=0.654, val_loss=0.654]Epoch 30:   3%|▎         | 30/1000 [26:36<12:47:53, 47.50s/it, lr=0.000125, test_MAE=0.703, time=47.9, train_MAE=0.314, train_loss=0.314, val_MAE=0.654, val_loss=0.654]Epoch 30:   3%|▎         | 30/1000 [27:24<12:47:53, 47.50s/it, lr=0.000125, test_MAE=0.707, time=47.4, train_MAE=0.299, train_loss=0.299, val_MAE=0.656, val_loss=0.656]Epoch 30:   3%|▎         | 31/1000 [27:24<12:46:28, 47.46s/it, lr=0.000125, test_MAE=0.707, time=47.4, train_MAE=0.299, train_loss=0.299, val_MAE=0.656, val_loss=0.656]Epoch 31:   3%|▎         | 31/1000 [27:24<12:46:28, 47.46s/it, lr=0.000125, test_MAE=0.707, time=47.4, train_MAE=0.299, train_loss=0.299, val_MAE=0.656, val_loss=0.656]Epoch 31:   3%|▎         | 31/1000 [28:11<12:46:28, 47.46s/it, lr=0.000125, test_MAE=0.714, time=47.1, train_MAE=0.315, train_loss=0.315, val_MAE=0.662, val_loss=0.662]Epoch 31:   3%|▎         | 32/1000 [28:11<12:43:59, 47.35s/it, lr=0.000125, test_MAE=0.714, time=47.1, train_MAE=0.315, train_loss=0.315, val_MAE=0.662, val_loss=0.662]Epoch 32:   3%|▎         | 32/1000 [28:11<12:43:59, 47.35s/it, lr=0.000125, test_MAE=0.714, time=47.1, train_MAE=0.315, train_loss=0.315, val_MAE=0.662, val_loss=0.662]Epoch 32:   3%|▎         | 32/1000 [28:58<12:43:59, 47.35s/it, lr=0.000125, test_MAE=0.718, time=47.7, train_MAE=0.311, train_loss=0.311, val_MAE=0.666, val_loss=0.666]Epoch 32:   3%|▎         | 33/1000 [28:58<12:44:49, 47.46s/it, lr=0.000125, test_MAE=0.718, time=47.7, train_MAE=0.311, train_loss=0.311, val_MAE=0.666, val_loss=0.666]Epoch 33:   3%|▎         | 33/1000 [28:58<12:44:49, 47.46s/it, lr=0.000125, test_MAE=0.718, time=47.7, train_MAE=0.311, train_loss=0.311, val_MAE=0.666, val_loss=0.666]Epoch 33:   3%|▎         | 33/1000 [29:46<12:44:49, 47.46s/it, lr=0.000125, test_MAE=0.713, time=47.4, train_MAE=0.299, train_loss=0.299, val_MAE=0.662, val_loss=0.662]Epoch 33:   3%|▎         | 34/1000 [29:46<12:43:56, 47.45s/it, lr=0.000125, test_MAE=0.713, time=47.4, train_MAE=0.299, train_loss=0.299, val_MAE=0.662, val_loss=0.662]Epoch 34:   3%|▎         | 34/1000 [29:46<12:43:56, 47.45s/it, lr=0.000125, test_MAE=0.713, time=47.4, train_MAE=0.299, train_loss=0.299, val_MAE=0.662, val_loss=0.662]Epoch 34:   3%|▎         | 34/1000 [30:33<12:43:56, 47.45s/it, lr=0.000125, test_MAE=0.733, time=47.1, train_MAE=0.298, train_loss=0.298, val_MAE=0.682, val_loss=0.682]Epoch    35: reducing learning rate of group 0 to 6.2500e-05.
Epoch 34:   4%|▎         | 35/1000 [30:33<12:41:23, 47.34s/it, lr=0.000125, test_MAE=0.733, time=47.1, train_MAE=0.298, train_loss=0.298, val_MAE=0.682, val_loss=0.682]Epoch 35:   4%|▎         | 35/1000 [30:33<12:41:23, 47.34s/it, lr=0.000125, test_MAE=0.733, time=47.1, train_MAE=0.298, train_loss=0.298, val_MAE=0.682, val_loss=0.682]Epoch 35:   4%|▎         | 35/1000 [31:21<12:41:23, 47.34s/it, lr=6.25e-5, test_MAE=0.71, time=47.6, train_MAE=0.283, train_loss=0.283, val_MAE=0.659, val_loss=0.659]  Epoch 35:   4%|▎         | 36/1000 [31:21<12:41:54, 47.42s/it, lr=6.25e-5, test_MAE=0.71, time=47.6, train_MAE=0.283, train_loss=0.283, val_MAE=0.659, val_loss=0.659]Epoch 36:   4%|▎         | 36/1000 [31:21<12:41:54, 47.42s/it, lr=6.25e-5, test_MAE=0.71, time=47.6, train_MAE=0.283, train_loss=0.283, val_MAE=0.659, val_loss=0.659]Epoch 36:   4%|▎         | 36/1000 [32:08<12:41:54, 47.42s/it, lr=6.25e-5, test_MAE=0.724, time=47.4, train_MAE=0.285, train_loss=0.285, val_MAE=0.67, val_loss=0.67] Epoch 36:   4%|▎         | 37/1000 [32:08<12:40:54, 47.41s/it, lr=6.25e-5, test_MAE=0.724, time=47.4, train_MAE=0.285, train_loss=0.285, val_MAE=0.67, val_loss=0.67]Epoch 37:   4%|▎         | 37/1000 [32:08<12:40:54, 47.41s/it, lr=6.25e-5, test_MAE=0.724, time=47.4, train_MAE=0.285, train_loss=0.285, val_MAE=0.67, val_loss=0.67]Epoch 37:   4%|▎         | 37/1000 [32:55<12:40:54, 47.41s/it, lr=6.25e-5, test_MAE=0.711, time=47.2, train_MAE=0.28, train_loss=0.28, val_MAE=0.657, val_loss=0.657]Epoch 37:   4%|▍         | 38/1000 [32:55<12:38:57, 47.34s/it, lr=6.25e-5, test_MAE=0.711, time=47.2, train_MAE=0.28, train_loss=0.28, val_MAE=0.657, val_loss=0.657]Epoch 38:   4%|▍         | 38/1000 [32:55<12:38:57, 47.34s/it, lr=6.25e-5, test_MAE=0.711, time=47.2, train_MAE=0.28, train_loss=0.28, val_MAE=0.657, val_loss=0.657]Epoch 38:   4%|▍         | 38/1000 [33:43<12:38:57, 47.34s/it, lr=6.25e-5, test_MAE=0.712, time=47.7, train_MAE=0.283, train_loss=0.283, val_MAE=0.661, val_loss=0.661]Epoch 38:   4%|▍         | 39/1000 [33:43<12:39:43, 47.43s/it, lr=6.25e-5, test_MAE=0.712, time=47.7, train_MAE=0.283, train_loss=0.283, val_MAE=0.661, val_loss=0.661]Epoch 39:   4%|▍         | 39/1000 [33:43<12:39:43, 47.43s/it, lr=6.25e-5, test_MAE=0.712, time=47.7, train_MAE=0.283, train_loss=0.283, val_MAE=0.661, val_loss=0.661]Epoch 39:   4%|▍         | 39/1000 [34:30<12:39:43, 47.43s/it, lr=6.25e-5, test_MAE=0.718, time=47.4, train_MAE=0.281, train_loss=0.281, val_MAE=0.66, val_loss=0.66]  Epoch 39:   4%|▍         | 40/1000 [34:30<12:38:49, 47.43s/it, lr=6.25e-5, test_MAE=0.718, time=47.4, train_MAE=0.281, train_loss=0.281, val_MAE=0.66, val_loss=0.66]Epoch 40:   4%|▍         | 40/1000 [34:30<12:38:49, 47.43s/it, lr=6.25e-5, test_MAE=0.718, time=47.4, train_MAE=0.281, train_loss=0.281, val_MAE=0.66, val_loss=0.66]Epoch 40:   4%|▍         | 40/1000 [35:18<12:38:49, 47.43s/it, lr=6.25e-5, test_MAE=0.715, time=47.4, train_MAE=0.283, train_loss=0.283, val_MAE=0.659, val_loss=0.659]Epoch    41: reducing learning rate of group 0 to 3.1250e-05.
Epoch 40:   4%|▍         | 41/1000 [35:18<12:37:47, 47.41s/it, lr=6.25e-5, test_MAE=0.715, time=47.4, train_MAE=0.283, train_loss=0.283, val_MAE=0.659, val_loss=0.659]Epoch 41:   4%|▍         | 41/1000 [35:18<12:37:47, 47.41s/it, lr=6.25e-5, test_MAE=0.715, time=47.4, train_MAE=0.283, train_loss=0.283, val_MAE=0.659, val_loss=0.659]Epoch 41:   4%|▍         | 41/1000 [36:05<12:37:47, 47.41s/it, lr=3.13e-5, test_MAE=0.715, time=47.7, train_MAE=0.267, train_loss=0.267, val_MAE=0.659, val_loss=0.659]Epoch 41:   4%|▍         | 42/1000 [36:05<12:38:14, 47.49s/it, lr=3.13e-5, test_MAE=0.715, time=47.7, train_MAE=0.267, train_loss=0.267, val_MAE=0.659, val_loss=0.659]Epoch 42:   4%|▍         | 42/1000 [36:05<12:38:14, 47.49s/it, lr=3.13e-5, test_MAE=0.715, time=47.7, train_MAE=0.267, train_loss=0.267, val_MAE=0.659, val_loss=0.659]Epoch 42:   4%|▍         | 42/1000 [36:52<12:38:14, 47.49s/it, lr=3.13e-5, test_MAE=0.716, time=47.1, train_MAE=0.275, train_loss=0.275, val_MAE=0.666, val_loss=0.666]Epoch 42:   4%|▍         | 43/1000 [36:52<12:35:36, 47.37s/it, lr=3.13e-5, test_MAE=0.716, time=47.1, train_MAE=0.275, train_loss=0.275, val_MAE=0.666, val_loss=0.666]Epoch 43:   4%|▍         | 43/1000 [36:52<12:35:36, 47.37s/it, lr=3.13e-5, test_MAE=0.716, time=47.1, train_MAE=0.275, train_loss=0.275, val_MAE=0.666, val_loss=0.666]Epoch 43:   4%|▍         | 43/1000 [37:40<12:35:36, 47.37s/it, lr=3.13e-5, test_MAE=0.714, time=47.6, train_MAE=0.271, train_loss=0.271, val_MAE=0.658, val_loss=0.658]Epoch 43:   4%|▍         | 44/1000 [37:40<12:36:10, 47.46s/it, lr=3.13e-5, test_MAE=0.714, time=47.6, train_MAE=0.271, train_loss=0.271, val_MAE=0.658, val_loss=0.658]Epoch 44:   4%|▍         | 44/1000 [37:40<12:36:10, 47.46s/it, lr=3.13e-5, test_MAE=0.714, time=47.6, train_MAE=0.271, train_loss=0.271, val_MAE=0.658, val_loss=0.658]Epoch 44:   4%|▍         | 44/1000 [38:27<12:36:10, 47.46s/it, lr=3.13e-5, test_MAE=0.723, time=47.4, train_MAE=0.261, train_loss=0.261, val_MAE=0.669, val_loss=0.669]Epoch 44:   4%|▍         | 45/1000 [38:28<12:35:20, 47.46s/it, lr=3.13e-5, test_MAE=0.723, time=47.4, train_MAE=0.261, train_loss=0.261, val_MAE=0.669, val_loss=0.669]Epoch 45:   4%|▍         | 45/1000 [38:28<12:35:20, 47.46s/it, lr=3.13e-5, test_MAE=0.723, time=47.4, train_MAE=0.261, train_loss=0.261, val_MAE=0.669, val_loss=0.669]Epoch 45:   4%|▍         | 45/1000 [39:15<12:35:20, 47.46s/it, lr=3.13e-5, test_MAE=0.713, time=47.5, train_MAE=0.256, train_loss=0.256, val_MAE=0.66, val_loss=0.66]  Epoch 45:   5%|▍         | 46/1000 [39:15<12:34:34, 47.46s/it, lr=3.13e-5, test_MAE=0.713, time=47.5, train_MAE=0.256, train_loss=0.256, val_MAE=0.66, val_loss=0.66]Epoch 46:   5%|▍         | 46/1000 [39:15<12:34:34, 47.46s/it, lr=3.13e-5, test_MAE=0.713, time=47.5, train_MAE=0.256, train_loss=0.256, val_MAE=0.66, val_loss=0.66]Epoch 46:   5%|▍         | 46/1000 [40:03<12:34:34, 47.46s/it, lr=3.13e-5, test_MAE=0.72, time=47.7, train_MAE=0.259, train_loss=0.259, val_MAE=0.663, val_loss=0.663]Epoch    47: reducing learning rate of group 0 to 1.5625e-05.
Epoch 46:   5%|▍         | 47/1000 [40:03<12:34:55, 47.53s/it, lr=3.13e-5, test_MAE=0.72, time=47.7, train_MAE=0.259, train_loss=0.259, val_MAE=0.663, val_loss=0.663]Epoch 47:   5%|▍         | 47/1000 [40:03<12:34:55, 47.53s/it, lr=3.13e-5, test_MAE=0.72, time=47.7, train_MAE=0.259, train_loss=0.259, val_MAE=0.663, val_loss=0.663]Epoch 47:   5%|▍         | 47/1000 [40:50<12:34:55, 47.53s/it, lr=1.56e-5, test_MAE=0.721, time=47.4, train_MAE=0.256, train_loss=0.256, val_MAE=0.663, val_loss=0.663]Epoch 47:   5%|▍         | 48/1000 [40:50<12:33:43, 47.50s/it, lr=1.56e-5, test_MAE=0.721, time=47.4, train_MAE=0.256, train_loss=0.256, val_MAE=0.663, val_loss=0.663]Epoch 48:   5%|▍         | 48/1000 [40:50<12:33:43, 47.50s/it, lr=1.56e-5, test_MAE=0.721, time=47.4, train_MAE=0.256, train_loss=0.256, val_MAE=0.663, val_loss=0.663]Epoch 48:   5%|▍         | 48/1000 [41:37<12:33:43, 47.50s/it, lr=1.56e-5, test_MAE=0.732, time=47.2, train_MAE=0.267, train_loss=0.267, val_MAE=0.676, val_loss=0.676]Epoch 48:   5%|▍         | 49/1000 [41:37<12:31:35, 47.42s/it, lr=1.56e-5, test_MAE=0.732, time=47.2, train_MAE=0.267, train_loss=0.267, val_MAE=0.676, val_loss=0.676]Epoch 49:   5%|▍         | 49/1000 [41:37<12:31:35, 47.42s/it, lr=1.56e-5, test_MAE=0.732, time=47.2, train_MAE=0.267, train_loss=0.267, val_MAE=0.676, val_loss=0.676]Epoch 49:   5%|▍         | 49/1000 [42:25<12:31:35, 47.42s/it, lr=1.56e-5, test_MAE=0.715, time=48, train_MAE=0.254, train_loss=0.254, val_MAE=0.659, val_loss=0.659]  Epoch 49:   5%|▌         | 50/1000 [42:25<12:33:26, 47.59s/it, lr=1.56e-5, test_MAE=0.715, time=48, train_MAE=0.254, train_loss=0.254, val_MAE=0.659, val_loss=0.659]Epoch 50:   5%|▌         | 50/1000 [42:25<12:33:26, 47.59s/it, lr=1.56e-5, test_MAE=0.715, time=48, train_MAE=0.254, train_loss=0.254, val_MAE=0.659, val_loss=0.659]Epoch 50:   5%|▌         | 50/1000 [43:13<12:33:26, 47.59s/it, lr=1.56e-5, test_MAE=0.722, time=47.4, train_MAE=0.261, train_loss=0.261, val_MAE=0.665, val_loss=0.665]Epoch 50:   5%|▌         | 51/1000 [43:13<12:31:48, 47.53s/it, lr=1.56e-5, test_MAE=0.722, time=47.4, train_MAE=0.261, train_loss=0.261, val_MAE=0.665, val_loss=0.665]Epoch 51:   5%|▌         | 51/1000 [43:13<12:31:48, 47.53s/it, lr=1.56e-5, test_MAE=0.722, time=47.4, train_MAE=0.261, train_loss=0.261, val_MAE=0.665, val_loss=0.665]Epoch 51:   5%|▌         | 51/1000 [44:00<12:31:48, 47.53s/it, lr=1.56e-5, test_MAE=0.72, time=47.2, train_MAE=0.257, train_loss=0.257, val_MAE=0.665, val_loss=0.665] Epoch 51:   5%|▌         | 52/1000 [44:00<12:29:22, 47.43s/it, lr=1.56e-5, test_MAE=0.72, time=47.2, train_MAE=0.257, train_loss=0.257, val_MAE=0.665, val_loss=0.665]Epoch 52:   5%|▌         | 52/1000 [44:00<12:29:22, 47.43s/it, lr=1.56e-5, test_MAE=0.72, time=47.2, train_MAE=0.257, train_loss=0.257, val_MAE=0.665, val_loss=0.665]Epoch 52:   5%|▌         | 52/1000 [44:48<12:29:22, 47.43s/it, lr=1.56e-5, test_MAE=0.715, time=47.7, train_MAE=0.255, train_loss=0.255, val_MAE=0.66, val_loss=0.66] Epoch    53: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 52:   5%|▌         | 52/1000 [44:48<13:36:45, 51.69s/it, lr=1.56e-5, test_MAE=0.715, time=47.7, train_MAE=0.255, train_loss=0.255, val_MAE=0.66, val_loss=0.66]
Test MAE: 0.7152
Train MAE: 0.2209
Convergence Time (Epochs): 52.0000
TOTAL TIME TAKEN: 2720.0723s
AVG TIME PER EPOCH: 50.7087s
