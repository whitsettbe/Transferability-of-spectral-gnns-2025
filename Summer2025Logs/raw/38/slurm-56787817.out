I'm echoing to stdout
I'm echoing to stderr
My JobID is 56787817
I have 8 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.1169s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 2, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'parallel_dense_simp', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_all', 'num_eigs': 8, 'bias_mode': '', 'eigval_hidden_dim': 5, 'eigval_num_hidden_layer': 3, 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 0.0, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/zinc_train_rec_full.csv', 'test': 'supp_data/molecules/zinc_test_rec_full.csv', 'val': 'supp_data/molecules/zinc_val_rec_full.csv'}, 'fixMissingPhi1': False, 'extraOrtho': True, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [03:12<?, ?it/s, lr=0.001, test_MAE=1.39, time=192, train_MAE=0.896, train_loss=0.896, val_MAE=1.3, val_loss=1.3]Epoch 0:   0%|          | 1/1000 [03:12<53:23:02, 192.37s/it, lr=0.001, test_MAE=1.39, time=192, train_MAE=0.896, train_loss=0.896, val_MAE=1.3, val_loss=1.3]Epoch 1:   0%|          | 1/1000 [03:12<53:23:02, 192.37s/it, lr=0.001, test_MAE=1.39, time=192, train_MAE=0.896, train_loss=0.896, val_MAE=1.3, val_loss=1.3]Epoch 1:   0%|          | 1/1000 [04:00<53:23:02, 192.37s/it, lr=0.001, test_MAE=0.804, time=48.2, train_MAE=0.67, train_loss=0.67, val_MAE=0.751, val_loss=0.751]Epoch 1:   0%|          | 2/1000 [04:00<41:20:23, 149.12s/it, lr=0.001, test_MAE=0.804, time=48.2, train_MAE=0.67, train_loss=0.67, val_MAE=0.751, val_loss=0.751]Epoch 2:   0%|          | 2/1000 [04:00<41:20:23, 149.12s/it, lr=0.001, test_MAE=0.804, time=48.2, train_MAE=0.67, train_loss=0.67, val_MAE=0.751, val_loss=0.751]Epoch 2:   0%|          | 2/1000 [04:48<41:20:23, 149.12s/it, lr=0.001, test_MAE=0.79, time=48.2, train_MAE=0.658, train_loss=0.658, val_MAE=0.743, val_loss=0.743]Epoch 2:   0%|          | 3/1000 [04:48<32:54:48, 118.85s/it, lr=0.001, test_MAE=0.79, time=48.2, train_MAE=0.658, train_loss=0.658, val_MAE=0.743, val_loss=0.743]Epoch 3:   0%|          | 3/1000 [04:48<32:54:48, 118.85s/it, lr=0.001, test_MAE=0.79, time=48.2, train_MAE=0.658, train_loss=0.658, val_MAE=0.743, val_loss=0.743]Epoch 3:   0%|          | 3/1000 [05:37<32:54:48, 118.85s/it, lr=0.001, test_MAE=1, time=48.2, train_MAE=0.646, train_loss=0.646, val_MAE=0.955, val_loss=0.955]   Epoch 3:   0%|          | 4/1000 [05:37<27:01:13, 97.66s/it, lr=0.001, test_MAE=1, time=48.2, train_MAE=0.646, train_loss=0.646, val_MAE=0.955, val_loss=0.955] Epoch 4:   0%|          | 4/1000 [05:37<27:01:13, 97.66s/it, lr=0.001, test_MAE=1, time=48.2, train_MAE=0.646, train_loss=0.646, val_MAE=0.955, val_loss=0.955]Epoch 4:   0%|          | 4/1000 [06:25<27:01:13, 97.66s/it, lr=0.001, test_MAE=0.801, time=48.4, train_MAE=0.63, train_loss=0.63, val_MAE=0.752, val_loss=0.752]Epoch 4:   0%|          | 5/1000 [06:25<22:54:31, 82.89s/it, lr=0.001, test_MAE=0.801, time=48.4, train_MAE=0.63, train_loss=0.63, val_MAE=0.752, val_loss=0.752]Epoch 5:   0%|          | 5/1000 [06:25<22:54:31, 82.89s/it, lr=0.001, test_MAE=0.801, time=48.4, train_MAE=0.63, train_loss=0.63, val_MAE=0.752, val_loss=0.752]Epoch 5:   0%|          | 5/1000 [07:13<22:54:31, 82.89s/it, lr=0.001, test_MAE=0.803, time=48.3, train_MAE=0.622, train_loss=0.622, val_MAE=0.762, val_loss=0.762]Epoch 5:   1%|          | 6/1000 [07:13<20:01:30, 72.53s/it, lr=0.001, test_MAE=0.803, time=48.3, train_MAE=0.622, train_loss=0.622, val_MAE=0.762, val_loss=0.762]Epoch 6:   1%|          | 6/1000 [07:13<20:01:30, 72.53s/it, lr=0.001, test_MAE=0.803, time=48.3, train_MAE=0.622, train_loss=0.622, val_MAE=0.762, val_loss=0.762]Epoch 6:   1%|          | 6/1000 [08:02<20:01:30, 72.53s/it, lr=0.001, test_MAE=0.673, time=48.6, train_MAE=0.634, train_loss=0.634, val_MAE=0.637, val_loss=0.637]Epoch 6:   1%|          | 7/1000 [08:02<18:01:38, 65.36s/it, lr=0.001, test_MAE=0.673, time=48.6, train_MAE=0.634, train_loss=0.634, val_MAE=0.637, val_loss=0.637]Epoch 7:   1%|          | 7/1000 [08:02<18:01:38, 65.36s/it, lr=0.001, test_MAE=0.673, time=48.6, train_MAE=0.634, train_loss=0.634, val_MAE=0.637, val_loss=0.637]Epoch 7:   1%|          | 7/1000 [08:50<18:01:38, 65.36s/it, lr=0.001, test_MAE=0.76, time=48.4, train_MAE=0.614, train_loss=0.614, val_MAE=0.714, val_loss=0.714] Epoch 7:   1%|          | 8/1000 [08:50<16:36:32, 60.28s/it, lr=0.001, test_MAE=0.76, time=48.4, train_MAE=0.614, train_loss=0.614, val_MAE=0.714, val_loss=0.714]Epoch 8:   1%|          | 8/1000 [08:50<16:36:32, 60.28s/it, lr=0.001, test_MAE=0.76, time=48.4, train_MAE=0.614, train_loss=0.614, val_MAE=0.714, val_loss=0.714]Epoch 8:   1%|          | 8/1000 [09:39<16:36:32, 60.28s/it, lr=0.001, test_MAE=0.862, time=48.3, train_MAE=0.608, train_loss=0.608, val_MAE=0.832, val_loss=0.832]Epoch 8:   1%|          | 9/1000 [09:39<15:36:27, 56.70s/it, lr=0.001, test_MAE=0.862, time=48.3, train_MAE=0.608, train_loss=0.608, val_MAE=0.832, val_loss=0.832]Epoch 9:   1%|          | 9/1000 [09:39<15:36:27, 56.70s/it, lr=0.001, test_MAE=0.862, time=48.3, train_MAE=0.608, train_loss=0.608, val_MAE=0.832, val_loss=0.832]Epoch 9:   1%|          | 9/1000 [10:27<15:36:27, 56.70s/it, lr=0.001, test_MAE=0.796, time=48.7, train_MAE=0.613, train_loss=0.613, val_MAE=0.745, val_loss=0.745]Epoch 9:   1%|          | 10/1000 [10:27<14:56:05, 54.31s/it, lr=0.001, test_MAE=0.796, time=48.7, train_MAE=0.613, train_loss=0.613, val_MAE=0.745, val_loss=0.745]Epoch 10:   1%|          | 10/1000 [10:27<14:56:05, 54.31s/it, lr=0.001, test_MAE=0.796, time=48.7, train_MAE=0.613, train_loss=0.613, val_MAE=0.745, val_loss=0.745]Epoch 10:   1%|          | 10/1000 [11:16<14:56:05, 54.31s/it, lr=0.001, test_MAE=0.913, time=48.3, train_MAE=0.596, train_loss=0.596, val_MAE=0.879, val_loss=0.879]Epoch 10:   1%|          | 11/1000 [11:16<14:25:37, 52.52s/it, lr=0.001, test_MAE=0.913, time=48.3, train_MAE=0.596, train_loss=0.596, val_MAE=0.879, val_loss=0.879]Epoch 11:   1%|          | 11/1000 [11:16<14:25:37, 52.52s/it, lr=0.001, test_MAE=0.913, time=48.3, train_MAE=0.596, train_loss=0.596, val_MAE=0.879, val_loss=0.879]Epoch 11:   1%|          | 11/1000 [12:04<14:25:37, 52.52s/it, lr=0.001, test_MAE=0.915, time=48, train_MAE=0.591, train_loss=0.591, val_MAE=0.893, val_loss=0.893]  Epoch 11:   1%|          | 12/1000 [12:04<14:02:23, 51.16s/it, lr=0.001, test_MAE=0.915, time=48, train_MAE=0.591, train_loss=0.591, val_MAE=0.893, val_loss=0.893]Epoch 12:   1%|          | 12/1000 [12:04<14:02:23, 51.16s/it, lr=0.001, test_MAE=0.915, time=48, train_MAE=0.591, train_loss=0.591, val_MAE=0.893, val_loss=0.893]Epoch 12:   1%|          | 12/1000 [12:52<14:02:23, 51.16s/it, lr=0.001, test_MAE=0.752, time=48.7, train_MAE=0.608, train_loss=0.608, val_MAE=0.701, val_loss=0.701]Epoch    13: reducing learning rate of group 0 to 5.0000e-04.
Epoch 12:   1%|▏         | 13/1000 [12:52<13:49:26, 50.42s/it, lr=0.001, test_MAE=0.752, time=48.7, train_MAE=0.608, train_loss=0.608, val_MAE=0.701, val_loss=0.701]Epoch 13:   1%|▏         | 13/1000 [12:52<13:49:26, 50.42s/it, lr=0.001, test_MAE=0.752, time=48.7, train_MAE=0.608, train_loss=0.608, val_MAE=0.701, val_loss=0.701]Epoch 13:   1%|▏         | 13/1000 [13:41<13:49:26, 50.42s/it, lr=0.0005, test_MAE=0.711, time=48.4, train_MAE=0.564, train_loss=0.564, val_MAE=0.663, val_loss=0.663]Epoch 13:   1%|▏         | 14/1000 [13:41<13:38:41, 49.82s/it, lr=0.0005, test_MAE=0.711, time=48.4, train_MAE=0.564, train_loss=0.564, val_MAE=0.663, val_loss=0.663]Epoch 14:   1%|▏         | 14/1000 [13:41<13:38:41, 49.82s/it, lr=0.0005, test_MAE=0.711, time=48.4, train_MAE=0.564, train_loss=0.564, val_MAE=0.663, val_loss=0.663]Epoch 14:   1%|▏         | 14/1000 [14:29<13:38:41, 49.82s/it, lr=0.0005, test_MAE=0.66, time=48, train_MAE=0.556, train_loss=0.556, val_MAE=0.629, val_loss=0.629]   Epoch 14:   2%|▏         | 15/1000 [14:29<13:29:03, 49.28s/it, lr=0.0005, test_MAE=0.66, time=48, train_MAE=0.556, train_loss=0.556, val_MAE=0.629, val_loss=0.629]Epoch 15:   2%|▏         | 15/1000 [14:29<13:29:03, 49.28s/it, lr=0.0005, test_MAE=0.66, time=48, train_MAE=0.556, train_loss=0.556, val_MAE=0.629, val_loss=0.629]Epoch 15:   2%|▏         | 15/1000 [15:17<13:29:03, 49.28s/it, lr=0.0005, test_MAE=0.734, time=48.6, train_MAE=0.546, train_loss=0.546, val_MAE=0.696, val_loss=0.696]Epoch 15:   2%|▏         | 16/1000 [15:17<13:24:45, 49.07s/it, lr=0.0005, test_MAE=0.734, time=48.6, train_MAE=0.546, train_loss=0.546, val_MAE=0.696, val_loss=0.696]Epoch 16:   2%|▏         | 16/1000 [15:17<13:24:45, 49.07s/it, lr=0.0005, test_MAE=0.734, time=48.6, train_MAE=0.546, train_loss=0.546, val_MAE=0.696, val_loss=0.696]Epoch 16:   2%|▏         | 16/1000 [16:06<13:24:45, 49.07s/it, lr=0.0005, test_MAE=0.673, time=48.4, train_MAE=0.552, train_loss=0.552, val_MAE=0.637, val_loss=0.637]Epoch 16:   2%|▏         | 17/1000 [16:06<13:20:39, 48.87s/it, lr=0.0005, test_MAE=0.673, time=48.4, train_MAE=0.552, train_loss=0.552, val_MAE=0.637, val_loss=0.637]Epoch 17:   2%|▏         | 17/1000 [16:06<13:20:39, 48.87s/it, lr=0.0005, test_MAE=0.673, time=48.4, train_MAE=0.552, train_loss=0.552, val_MAE=0.637, val_loss=0.637]Epoch 17:   2%|▏         | 17/1000 [16:54<13:20:39, 48.87s/it, lr=0.0005, test_MAE=0.683, time=48.1, train_MAE=0.549, train_loss=0.549, val_MAE=0.653, val_loss=0.653]Epoch 17:   2%|▏         | 18/1000 [16:54<13:16:05, 48.64s/it, lr=0.0005, test_MAE=0.683, time=48.1, train_MAE=0.549, train_loss=0.549, val_MAE=0.653, val_loss=0.653]Epoch 18:   2%|▏         | 18/1000 [16:54<13:16:05, 48.64s/it, lr=0.0005, test_MAE=0.683, time=48.1, train_MAE=0.549, train_loss=0.549, val_MAE=0.653, val_loss=0.653]Epoch 18:   2%|▏         | 18/1000 [17:43<13:16:05, 48.64s/it, lr=0.0005, test_MAE=0.668, time=48.7, train_MAE=0.527, train_loss=0.527, val_MAE=0.64, val_loss=0.64]  Epoch 18:   2%|▏         | 19/1000 [17:43<13:15:28, 48.65s/it, lr=0.0005, test_MAE=0.668, time=48.7, train_MAE=0.527, train_loss=0.527, val_MAE=0.64, val_loss=0.64]Epoch 19:   2%|▏         | 19/1000 [17:43<13:15:28, 48.65s/it, lr=0.0005, test_MAE=0.668, time=48.7, train_MAE=0.527, train_loss=0.527, val_MAE=0.64, val_loss=0.64]Epoch 19:   2%|▏         | 19/1000 [18:31<13:15:28, 48.65s/it, lr=0.0005, test_MAE=0.681, time=48.3, train_MAE=0.529, train_loss=0.529, val_MAE=0.645, val_loss=0.645]Epoch 19:   2%|▏         | 20/1000 [18:31<13:13:06, 48.56s/it, lr=0.0005, test_MAE=0.681, time=48.3, train_MAE=0.529, train_loss=0.529, val_MAE=0.645, val_loss=0.645]Epoch 20:   2%|▏         | 20/1000 [18:31<13:13:06, 48.56s/it, lr=0.0005, test_MAE=0.681, time=48.3, train_MAE=0.529, train_loss=0.529, val_MAE=0.645, val_loss=0.645]Epoch 20:   2%|▏         | 20/1000 [19:19<13:13:06, 48.56s/it, lr=0.0005, test_MAE=0.701, time=48.3, train_MAE=0.516, train_loss=0.516, val_MAE=0.663, val_loss=0.663]Epoch    21: reducing learning rate of group 0 to 2.5000e-04.
Epoch 20:   2%|▏         | 21/1000 [19:19<13:11:08, 48.49s/it, lr=0.0005, test_MAE=0.701, time=48.3, train_MAE=0.516, train_loss=0.516, val_MAE=0.663, val_loss=0.663]Epoch 21:   2%|▏         | 21/1000 [19:19<13:11:08, 48.49s/it, lr=0.0005, test_MAE=0.701, time=48.3, train_MAE=0.516, train_loss=0.516, val_MAE=0.663, val_loss=0.663]Epoch 21:   2%|▏         | 21/1000 [20:08<13:11:08, 48.49s/it, lr=0.00025, test_MAE=0.676, time=48.8, train_MAE=0.501, train_loss=0.501, val_MAE=0.635, val_loss=0.635]Epoch 21:   2%|▏         | 22/1000 [20:08<13:11:41, 48.57s/it, lr=0.00025, test_MAE=0.676, time=48.8, train_MAE=0.501, train_loss=0.501, val_MAE=0.635, val_loss=0.635]Epoch 22:   2%|▏         | 22/1000 [20:08<13:11:41, 48.57s/it, lr=0.00025, test_MAE=0.676, time=48.8, train_MAE=0.501, train_loss=0.501, val_MAE=0.635, val_loss=0.635]Epoch 22:   2%|▏         | 22/1000 [20:56<13:11:41, 48.57s/it, lr=0.00025, test_MAE=0.677, time=48.1, train_MAE=0.488, train_loss=0.488, val_MAE=0.639, val_loss=0.639]Epoch 22:   2%|▏         | 23/1000 [20:56<13:08:23, 48.42s/it, lr=0.00025, test_MAE=0.677, time=48.1, train_MAE=0.488, train_loss=0.488, val_MAE=0.639, val_loss=0.639]Epoch 23:   2%|▏         | 23/1000 [20:56<13:08:23, 48.42s/it, lr=0.00025, test_MAE=0.677, time=48.1, train_MAE=0.488, train_loss=0.488, val_MAE=0.639, val_loss=0.639]Epoch 23:   2%|▏         | 23/1000 [21:45<13:08:23, 48.42s/it, lr=0.00025, test_MAE=0.69, time=48.7, train_MAE=0.482, train_loss=0.482, val_MAE=0.664, val_loss=0.664] Epoch 23:   2%|▏         | 24/1000 [21:45<13:08:47, 48.49s/it, lr=0.00025, test_MAE=0.69, time=48.7, train_MAE=0.482, train_loss=0.482, val_MAE=0.664, val_loss=0.664]Epoch 24:   2%|▏         | 24/1000 [21:45<13:08:47, 48.49s/it, lr=0.00025, test_MAE=0.69, time=48.7, train_MAE=0.482, train_loss=0.482, val_MAE=0.664, val_loss=0.664]Epoch 24:   2%|▏         | 24/1000 [22:33<13:08:47, 48.49s/it, lr=0.00025, test_MAE=0.688, time=48.4, train_MAE=0.485, train_loss=0.485, val_MAE=0.662, val_loss=0.662]Epoch 24:   2%|▎         | 25/1000 [22:33<13:07:21, 48.45s/it, lr=0.00025, test_MAE=0.688, time=48.4, train_MAE=0.485, train_loss=0.485, val_MAE=0.662, val_loss=0.662]Epoch 25:   2%|▎         | 25/1000 [22:33<13:07:21, 48.45s/it, lr=0.00025, test_MAE=0.688, time=48.4, train_MAE=0.485, train_loss=0.485, val_MAE=0.662, val_loss=0.662]Epoch 25:   2%|▎         | 25/1000 [23:22<13:07:21, 48.45s/it, lr=0.00025, test_MAE=0.669, time=48.4, train_MAE=0.481, train_loss=0.481, val_MAE=0.642, val_loss=0.642]Epoch 25:   3%|▎         | 26/1000 [23:22<13:06:25, 48.44s/it, lr=0.00025, test_MAE=0.669, time=48.4, train_MAE=0.481, train_loss=0.481, val_MAE=0.642, val_loss=0.642]Epoch 26:   3%|▎         | 26/1000 [23:22<13:06:25, 48.44s/it, lr=0.00025, test_MAE=0.669, time=48.4, train_MAE=0.481, train_loss=0.481, val_MAE=0.642, val_loss=0.642]Epoch 26:   3%|▎         | 26/1000 [24:10<13:06:25, 48.44s/it, lr=0.00025, test_MAE=0.707, time=48.7, train_MAE=0.466, train_loss=0.466, val_MAE=0.682, val_loss=0.682]Epoch    27: reducing learning rate of group 0 to 1.2500e-04.
Epoch 26:   3%|▎         | 27/1000 [24:10<13:06:56, 48.53s/it, lr=0.00025, test_MAE=0.707, time=48.7, train_MAE=0.466, train_loss=0.466, val_MAE=0.682, val_loss=0.682]Epoch 27:   3%|▎         | 27/1000 [24:10<13:06:56, 48.53s/it, lr=0.00025, test_MAE=0.707, time=48.7, train_MAE=0.466, train_loss=0.466, val_MAE=0.682, val_loss=0.682]Epoch 27:   3%|▎         | 27/1000 [24:59<13:06:56, 48.53s/it, lr=0.000125, test_MAE=0.715, time=48.4, train_MAE=0.451, train_loss=0.451, val_MAE=0.686, val_loss=0.686]Epoch 27:   3%|▎         | 28/1000 [24:59<13:05:30, 48.49s/it, lr=0.000125, test_MAE=0.715, time=48.4, train_MAE=0.451, train_loss=0.451, val_MAE=0.686, val_loss=0.686]Epoch 28:   3%|▎         | 28/1000 [24:59<13:05:30, 48.49s/it, lr=0.000125, test_MAE=0.715, time=48.4, train_MAE=0.451, train_loss=0.451, val_MAE=0.686, val_loss=0.686]Epoch 28:   3%|▎         | 28/1000 [25:47<13:05:30, 48.49s/it, lr=0.000125, test_MAE=0.698, time=48, train_MAE=0.449, train_loss=0.449, val_MAE=0.667, val_loss=0.667]  Epoch 28:   3%|▎         | 29/1000 [25:47<13:02:26, 48.35s/it, lr=0.000125, test_MAE=0.698, time=48, train_MAE=0.449, train_loss=0.449, val_MAE=0.667, val_loss=0.667]Epoch 29:   3%|▎         | 29/1000 [25:47<13:02:26, 48.35s/it, lr=0.000125, test_MAE=0.698, time=48, train_MAE=0.449, train_loss=0.449, val_MAE=0.667, val_loss=0.667]Epoch 29:   3%|▎         | 29/1000 [26:36<13:02:26, 48.35s/it, lr=0.000125, test_MAE=0.68, time=49, train_MAE=0.448, train_loss=0.448, val_MAE=0.651, val_loss=0.651] Epoch 29:   3%|▎         | 30/1000 [26:36<13:04:53, 48.55s/it, lr=0.000125, test_MAE=0.68, time=49, train_MAE=0.448, train_loss=0.448, val_MAE=0.651, val_loss=0.651]Epoch 30:   3%|▎         | 30/1000 [26:36<13:04:53, 48.55s/it, lr=0.000125, test_MAE=0.68, time=49, train_MAE=0.448, train_loss=0.448, val_MAE=0.651, val_loss=0.651]Epoch 30:   3%|▎         | 30/1000 [27:24<13:04:53, 48.55s/it, lr=0.000125, test_MAE=0.68, time=48.4, train_MAE=0.442, train_loss=0.442, val_MAE=0.652, val_loss=0.652]Epoch 30:   3%|▎         | 31/1000 [27:24<13:03:20, 48.50s/it, lr=0.000125, test_MAE=0.68, time=48.4, train_MAE=0.442, train_loss=0.442, val_MAE=0.652, val_loss=0.652]Epoch 31:   3%|▎         | 31/1000 [27:24<13:03:20, 48.50s/it, lr=0.000125, test_MAE=0.68, time=48.4, train_MAE=0.442, train_loss=0.442, val_MAE=0.652, val_loss=0.652]Epoch 31:   3%|▎         | 31/1000 [28:12<13:03:20, 48.50s/it, lr=0.000125, test_MAE=0.709, time=48, train_MAE=0.443, train_loss=0.443, val_MAE=0.678, val_loss=0.678] Epoch 31:   3%|▎         | 32/1000 [28:12<13:00:17, 48.36s/it, lr=0.000125, test_MAE=0.709, time=48, train_MAE=0.443, train_loss=0.443, val_MAE=0.678, val_loss=0.678]Epoch 32:   3%|▎         | 32/1000 [28:12<13:00:17, 48.36s/it, lr=0.000125, test_MAE=0.709, time=48, train_MAE=0.443, train_loss=0.443, val_MAE=0.678, val_loss=0.678]Epoch 32:   3%|▎         | 32/1000 [29:01<13:00:17, 48.36s/it, lr=0.000125, test_MAE=0.689, time=48.7, train_MAE=0.437, train_loss=0.437, val_MAE=0.661, val_loss=0.661]Epoch    33: reducing learning rate of group 0 to 6.2500e-05.
Epoch 32:   3%|▎         | 33/1000 [29:01<13:00:55, 48.45s/it, lr=0.000125, test_MAE=0.689, time=48.7, train_MAE=0.437, train_loss=0.437, val_MAE=0.661, val_loss=0.661]Epoch 33:   3%|▎         | 33/1000 [29:01<13:00:55, 48.45s/it, lr=0.000125, test_MAE=0.689, time=48.7, train_MAE=0.437, train_loss=0.437, val_MAE=0.661, val_loss=0.661]Epoch 33:   3%|▎         | 33/1000 [29:49<13:00:55, 48.45s/it, lr=6.25e-5, test_MAE=0.678, time=48.4, train_MAE=0.427, train_loss=0.427, val_MAE=0.654, val_loss=0.654] Epoch 33:   3%|▎         | 34/1000 [29:49<12:59:56, 48.44s/it, lr=6.25e-5, test_MAE=0.678, time=48.4, train_MAE=0.427, train_loss=0.427, val_MAE=0.654, val_loss=0.654]Epoch 34:   3%|▎         | 34/1000 [29:49<12:59:56, 48.44s/it, lr=6.25e-5, test_MAE=0.678, time=48.4, train_MAE=0.427, train_loss=0.427, val_MAE=0.654, val_loss=0.654]Epoch 34:   3%|▎         | 34/1000 [30:37<12:59:56, 48.44s/it, lr=6.25e-5, test_MAE=0.708, time=48, train_MAE=0.418, train_loss=0.418, val_MAE=0.681, val_loss=0.681]  Epoch 34:   4%|▎         | 35/1000 [30:37<12:57:11, 48.32s/it, lr=6.25e-5, test_MAE=0.708, time=48, train_MAE=0.418, train_loss=0.418, val_MAE=0.681, val_loss=0.681]Epoch 35:   4%|▎         | 35/1000 [30:37<12:57:11, 48.32s/it, lr=6.25e-5, test_MAE=0.708, time=48, train_MAE=0.418, train_loss=0.418, val_MAE=0.681, val_loss=0.681]Epoch 35:   4%|▎         | 35/1000 [31:26<12:57:11, 48.32s/it, lr=6.25e-5, test_MAE=0.689, time=48.7, train_MAE=0.431, train_loss=0.431, val_MAE=0.657, val_loss=0.657]Epoch 35:   4%|▎         | 36/1000 [31:26<12:58:04, 48.43s/it, lr=6.25e-5, test_MAE=0.689, time=48.7, train_MAE=0.431, train_loss=0.431, val_MAE=0.657, val_loss=0.657]Epoch 36:   4%|▎         | 36/1000 [31:26<12:58:04, 48.43s/it, lr=6.25e-5, test_MAE=0.689, time=48.7, train_MAE=0.431, train_loss=0.431, val_MAE=0.657, val_loss=0.657]Epoch 36:   4%|▎         | 36/1000 [32:14<12:58:04, 48.43s/it, lr=6.25e-5, test_MAE=0.687, time=48.3, train_MAE=0.424, train_loss=0.424, val_MAE=0.658, val_loss=0.658]Epoch 36:   4%|▎         | 37/1000 [32:14<12:56:52, 48.40s/it, lr=6.25e-5, test_MAE=0.687, time=48.3, train_MAE=0.424, train_loss=0.424, val_MAE=0.658, val_loss=0.658]Epoch 37:   4%|▎         | 37/1000 [32:14<12:56:52, 48.40s/it, lr=6.25e-5, test_MAE=0.687, time=48.3, train_MAE=0.424, train_loss=0.424, val_MAE=0.658, val_loss=0.658]Epoch 37:   4%|▎         | 37/1000 [33:02<12:56:52, 48.40s/it, lr=6.25e-5, test_MAE=0.685, time=48.1, train_MAE=0.421, train_loss=0.421, val_MAE=0.654, val_loss=0.654]Epoch 37:   4%|▍         | 38/1000 [33:02<12:54:38, 48.31s/it, lr=6.25e-5, test_MAE=0.685, time=48.1, train_MAE=0.421, train_loss=0.421, val_MAE=0.654, val_loss=0.654]Epoch 38:   4%|▍         | 38/1000 [33:02<12:54:38, 48.31s/it, lr=6.25e-5, test_MAE=0.685, time=48.1, train_MAE=0.421, train_loss=0.421, val_MAE=0.654, val_loss=0.654]Epoch 38:   4%|▍         | 38/1000 [33:51<12:54:38, 48.31s/it, lr=6.25e-5, test_MAE=0.694, time=48.7, train_MAE=0.426, train_loss=0.426, val_MAE=0.668, val_loss=0.668]Epoch    39: reducing learning rate of group 0 to 3.1250e-05.
Epoch 38:   4%|▍         | 39/1000 [33:51<12:55:48, 48.44s/it, lr=6.25e-5, test_MAE=0.694, time=48.7, train_MAE=0.426, train_loss=0.426, val_MAE=0.668, val_loss=0.668]Epoch 39:   4%|▍         | 39/1000 [33:51<12:55:48, 48.44s/it, lr=6.25e-5, test_MAE=0.694, time=48.7, train_MAE=0.426, train_loss=0.426, val_MAE=0.668, val_loss=0.668]Epoch 39:   4%|▍         | 39/1000 [34:40<12:55:48, 48.44s/it, lr=3.13e-5, test_MAE=0.689, time=48.4, train_MAE=0.417, train_loss=0.417, val_MAE=0.66, val_loss=0.66]  Epoch 39:   4%|▍         | 40/1000 [34:40<12:54:50, 48.43s/it, lr=3.13e-5, test_MAE=0.689, time=48.4, train_MAE=0.417, train_loss=0.417, val_MAE=0.66, val_loss=0.66]Epoch 40:   4%|▍         | 40/1000 [34:40<12:54:50, 48.43s/it, lr=3.13e-5, test_MAE=0.689, time=48.4, train_MAE=0.417, train_loss=0.417, val_MAE=0.66, val_loss=0.66]Epoch 40:   4%|▍         | 40/1000 [35:28<12:54:50, 48.43s/it, lr=3.13e-5, test_MAE=0.687, time=48.4, train_MAE=0.414, train_loss=0.414, val_MAE=0.661, val_loss=0.661]Epoch 40:   4%|▍         | 41/1000 [35:28<12:53:47, 48.41s/it, lr=3.13e-5, test_MAE=0.687, time=48.4, train_MAE=0.414, train_loss=0.414, val_MAE=0.661, val_loss=0.661]Epoch 41:   4%|▍         | 41/1000 [35:28<12:53:47, 48.41s/it, lr=3.13e-5, test_MAE=0.687, time=48.4, train_MAE=0.414, train_loss=0.414, val_MAE=0.661, val_loss=0.661]Epoch 41:   4%|▍         | 41/1000 [36:17<12:53:47, 48.41s/it, lr=3.13e-5, test_MAE=0.69, time=48.7, train_MAE=0.41, train_loss=0.41, val_MAE=0.665, val_loss=0.665]   Epoch 41:   4%|▍         | 42/1000 [36:17<12:54:19, 48.50s/it, lr=3.13e-5, test_MAE=0.69, time=48.7, train_MAE=0.41, train_loss=0.41, val_MAE=0.665, val_loss=0.665]Epoch 42:   4%|▍         | 42/1000 [36:17<12:54:19, 48.50s/it, lr=3.13e-5, test_MAE=0.69, time=48.7, train_MAE=0.41, train_loss=0.41, val_MAE=0.665, val_loss=0.665]Epoch 42:   4%|▍         | 42/1000 [37:05<12:54:19, 48.50s/it, lr=3.13e-5, test_MAE=0.684, time=48, train_MAE=0.407, train_loss=0.407, val_MAE=0.658, val_loss=0.658]Epoch 42:   4%|▍         | 43/1000 [37:05<12:51:20, 48.36s/it, lr=3.13e-5, test_MAE=0.684, time=48, train_MAE=0.407, train_loss=0.407, val_MAE=0.658, val_loss=0.658]Epoch 43:   4%|▍         | 43/1000 [37:05<12:51:20, 48.36s/it, lr=3.13e-5, test_MAE=0.684, time=48, train_MAE=0.407, train_loss=0.407, val_MAE=0.658, val_loss=0.658]Epoch 43:   4%|▍         | 43/1000 [37:53<12:51:20, 48.36s/it, lr=3.13e-5, test_MAE=0.689, time=48.7, train_MAE=0.413, train_loss=0.413, val_MAE=0.661, val_loss=0.661]Epoch 43:   4%|▍         | 44/1000 [37:53<12:52:19, 48.47s/it, lr=3.13e-5, test_MAE=0.689, time=48.7, train_MAE=0.413, train_loss=0.413, val_MAE=0.661, val_loss=0.661]Epoch 44:   4%|▍         | 44/1000 [37:53<12:52:19, 48.47s/it, lr=3.13e-5, test_MAE=0.689, time=48.7, train_MAE=0.413, train_loss=0.413, val_MAE=0.661, val_loss=0.661]Epoch 44:   4%|▍         | 44/1000 [38:42<12:52:19, 48.47s/it, lr=3.13e-5, test_MAE=0.683, time=48.4, train_MAE=0.408, train_loss=0.408, val_MAE=0.655, val_loss=0.655]Epoch    45: reducing learning rate of group 0 to 1.5625e-05.
Epoch 44:   4%|▍         | 45/1000 [38:42<12:51:05, 48.45s/it, lr=3.13e-5, test_MAE=0.683, time=48.4, train_MAE=0.408, train_loss=0.408, val_MAE=0.655, val_loss=0.655]Epoch 45:   4%|▍         | 45/1000 [38:42<12:51:05, 48.45s/it, lr=3.13e-5, test_MAE=0.683, time=48.4, train_MAE=0.408, train_loss=0.408, val_MAE=0.655, val_loss=0.655]Epoch 45:   4%|▍         | 45/1000 [39:30<12:51:05, 48.45s/it, lr=1.56e-5, test_MAE=0.687, time=48.2, train_MAE=0.405, train_loss=0.405, val_MAE=0.662, val_loss=0.662]Epoch 45:   5%|▍         | 46/1000 [39:30<12:49:19, 48.39s/it, lr=1.56e-5, test_MAE=0.687, time=48.2, train_MAE=0.405, train_loss=0.405, val_MAE=0.662, val_loss=0.662]Epoch 46:   5%|▍         | 46/1000 [39:30<12:49:19, 48.39s/it, lr=1.56e-5, test_MAE=0.687, time=48.2, train_MAE=0.405, train_loss=0.405, val_MAE=0.662, val_loss=0.662]Epoch 46:   5%|▍         | 46/1000 [40:19<12:49:19, 48.39s/it, lr=1.56e-5, test_MAE=0.689, time=48.6, train_MAE=0.401, train_loss=0.401, val_MAE=0.662, val_loss=0.662]Epoch 46:   5%|▍         | 47/1000 [40:19<12:49:42, 48.46s/it, lr=1.56e-5, test_MAE=0.689, time=48.6, train_MAE=0.401, train_loss=0.401, val_MAE=0.662, val_loss=0.662]Epoch 47:   5%|▍         | 47/1000 [40:19<12:49:42, 48.46s/it, lr=1.56e-5, test_MAE=0.689, time=48.6, train_MAE=0.401, train_loss=0.401, val_MAE=0.662, val_loss=0.662]Epoch 47:   5%|▍         | 47/1000 [41:07<12:49:42, 48.46s/it, lr=1.56e-5, test_MAE=0.686, time=48.4, train_MAE=0.409, train_loss=0.409, val_MAE=0.659, val_loss=0.659]Epoch 47:   5%|▍         | 48/1000 [41:07<12:48:28, 48.43s/it, lr=1.56e-5, test_MAE=0.686, time=48.4, train_MAE=0.409, train_loss=0.409, val_MAE=0.659, val_loss=0.659]Epoch 48:   5%|▍         | 48/1000 [41:07<12:48:28, 48.43s/it, lr=1.56e-5, test_MAE=0.686, time=48.4, train_MAE=0.409, train_loss=0.409, val_MAE=0.659, val_loss=0.659]Epoch 48:   5%|▍         | 48/1000 [41:55<12:48:28, 48.43s/it, lr=1.56e-5, test_MAE=0.687, time=48, train_MAE=0.404, train_loss=0.404, val_MAE=0.66, val_loss=0.66]    Epoch 48:   5%|▍         | 49/1000 [41:55<12:45:54, 48.32s/it, lr=1.56e-5, test_MAE=0.687, time=48, train_MAE=0.404, train_loss=0.404, val_MAE=0.66, val_loss=0.66]Epoch 49:   5%|▍         | 49/1000 [41:55<12:45:54, 48.32s/it, lr=1.56e-5, test_MAE=0.687, time=48, train_MAE=0.404, train_loss=0.404, val_MAE=0.66, val_loss=0.66]Epoch 49:   5%|▍         | 49/1000 [42:44<12:45:54, 48.32s/it, lr=1.56e-5, test_MAE=0.684, time=49, train_MAE=0.404, train_loss=0.404, val_MAE=0.658, val_loss=0.658]Epoch 49:   5%|▌         | 50/1000 [42:44<12:48:28, 48.54s/it, lr=1.56e-5, test_MAE=0.684, time=49, train_MAE=0.404, train_loss=0.404, val_MAE=0.658, val_loss=0.658]Epoch 50:   5%|▌         | 50/1000 [42:44<12:48:28, 48.54s/it, lr=1.56e-5, test_MAE=0.684, time=49, train_MAE=0.404, train_loss=0.404, val_MAE=0.658, val_loss=0.658]Epoch 50:   5%|▌         | 50/1000 [43:33<12:48:28, 48.54s/it, lr=1.56e-5, test_MAE=0.685, time=48.4, train_MAE=0.403, train_loss=0.403, val_MAE=0.659, val_loss=0.659]Epoch    51: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 50:   5%|▌         | 50/1000 [43:33<13:47:28, 52.26s/it, lr=1.56e-5, test_MAE=0.685, time=48.4, train_MAE=0.403, train_loss=0.403, val_MAE=0.659, val_loss=0.659]
Test MAE: 0.6852
Train MAE: 0.3781
Convergence Time (Epochs): 50.0000
TOTAL TIME TAKEN: 2646.0984s
AVG TIME PER EPOCH: 51.2234s
