I'm echoing to stdout
I'm echoing to stderr
My JobID is 56774787
I have 8 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.1133s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 2, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'parallel_dense_simp', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_all', 'num_eigs': 15, 'bias_mode': '', 'eigval_hidden_dim': 5, 'eigval_num_hidden_layer': 3, 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 1.0, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/zinc_train_rec_full.csv', 'test': 'supp_data/molecules/zinc_test_rec_full.csv', 'val': 'supp_data/molecules/zinc_val_rec_full.csv'}, 'fixMissingPhi1': False, 'extraOrtho': True, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [03:15<?, ?it/s, lr=0.001, test_MAE=1.44, time=196, train_MAE=0.917, train_loss=0.956, val_MAE=1.36, val_loss=1.4]Epoch 0:   0%|          | 1/1000 [03:15<54:21:46, 195.90s/it, lr=0.001, test_MAE=1.44, time=196, train_MAE=0.917, train_loss=0.956, val_MAE=1.36, val_loss=1.4]Epoch 1:   0%|          | 1/1000 [03:15<54:21:46, 195.90s/it, lr=0.001, test_MAE=1.44, time=196, train_MAE=0.917, train_loss=0.956, val_MAE=1.36, val_loss=1.4]Epoch 1:   0%|          | 1/1000 [04:05<54:21:46, 195.90s/it, lr=0.001, test_MAE=0.825, time=49.8, train_MAE=0.681, train_loss=0.714, val_MAE=0.774, val_loss=0.804]Epoch 1:   0%|          | 2/1000 [04:05<42:09:25, 152.07s/it, lr=0.001, test_MAE=0.825, time=49.8, train_MAE=0.681, train_loss=0.714, val_MAE=0.774, val_loss=0.804]Epoch 2:   0%|          | 2/1000 [04:05<42:09:25, 152.07s/it, lr=0.001, test_MAE=0.825, time=49.8, train_MAE=0.681, train_loss=0.714, val_MAE=0.774, val_loss=0.804]Epoch 2:   0%|          | 2/1000 [04:55<42:09:25, 152.07s/it, lr=0.001, test_MAE=1.39, time=49.7, train_MAE=0.654, train_loss=0.683, val_MAE=1.32, val_loss=1.35]   Epoch 2:   0%|          | 3/1000 [04:55<33:36:49, 121.37s/it, lr=0.001, test_MAE=1.39, time=49.7, train_MAE=0.654, train_loss=0.683, val_MAE=1.32, val_loss=1.35]Epoch 3:   0%|          | 3/1000 [04:55<33:36:49, 121.37s/it, lr=0.001, test_MAE=1.39, time=49.7, train_MAE=0.654, train_loss=0.683, val_MAE=1.32, val_loss=1.35]Epoch 3:   0%|          | 3/1000 [05:45<33:36:49, 121.37s/it, lr=0.001, test_MAE=0.765, time=49.7, train_MAE=0.641, train_loss=0.669, val_MAE=0.702, val_loss=0.729]Epoch 3:   0%|          | 4/1000 [05:45<27:37:50, 99.87s/it, lr=0.001, test_MAE=0.765, time=49.7, train_MAE=0.641, train_loss=0.669, val_MAE=0.702, val_loss=0.729] Epoch 4:   0%|          | 4/1000 [05:45<27:37:50, 99.87s/it, lr=0.001, test_MAE=0.765, time=49.7, train_MAE=0.641, train_loss=0.669, val_MAE=0.702, val_loss=0.729]Epoch 4:   0%|          | 4/1000 [06:34<27:37:50, 99.87s/it, lr=0.001, test_MAE=1.19, time=49.8, train_MAE=0.629, train_loss=0.656, val_MAE=1.14, val_loss=1.16]   Epoch 4:   0%|          | 5/1000 [06:34<23:27:13, 84.86s/it, lr=0.001, test_MAE=1.19, time=49.8, train_MAE=0.629, train_loss=0.656, val_MAE=1.14, val_loss=1.16]Epoch 5:   0%|          | 5/1000 [06:34<23:27:13, 84.86s/it, lr=0.001, test_MAE=1.19, time=49.8, train_MAE=0.629, train_loss=0.656, val_MAE=1.14, val_loss=1.16]Epoch 5:   0%|          | 5/1000 [07:24<23:27:13, 84.86s/it, lr=0.001, test_MAE=0.776, time=49.7, train_MAE=0.627, train_loss=0.655, val_MAE=0.706, val_loss=0.734]Epoch 5:   1%|          | 6/1000 [07:24<20:31:19, 74.33s/it, lr=0.001, test_MAE=0.776, time=49.7, train_MAE=0.627, train_loss=0.655, val_MAE=0.706, val_loss=0.734]Epoch 6:   1%|          | 6/1000 [07:24<20:31:19, 74.33s/it, lr=0.001, test_MAE=0.776, time=49.7, train_MAE=0.627, train_loss=0.655, val_MAE=0.706, val_loss=0.734]Epoch 6:   1%|          | 6/1000 [08:14<20:31:19, 74.33s/it, lr=0.001, test_MAE=0.706, time=50.1, train_MAE=0.625, train_loss=0.653, val_MAE=0.647, val_loss=0.675]Epoch 6:   1%|          | 7/1000 [08:14<18:29:50, 67.06s/it, lr=0.001, test_MAE=0.706, time=50.1, train_MAE=0.625, train_loss=0.653, val_MAE=0.647, val_loss=0.675]Epoch 7:   1%|          | 7/1000 [08:14<18:29:50, 67.06s/it, lr=0.001, test_MAE=0.706, time=50.1, train_MAE=0.625, train_loss=0.653, val_MAE=0.647, val_loss=0.675]Epoch 7:   1%|          | 7/1000 [09:04<18:29:50, 67.06s/it, lr=0.001, test_MAE=0.74, time=49.8, train_MAE=0.613, train_loss=0.642, val_MAE=0.668, val_loss=0.696] Epoch 7:   1%|          | 8/1000 [09:04<17:03:18, 61.89s/it, lr=0.001, test_MAE=0.74, time=49.8, train_MAE=0.613, train_loss=0.642, val_MAE=0.668, val_loss=0.696]Epoch 8:   1%|          | 8/1000 [09:04<17:03:18, 61.89s/it, lr=0.001, test_MAE=0.74, time=49.8, train_MAE=0.613, train_loss=0.642, val_MAE=0.668, val_loss=0.696]Epoch 8:   1%|          | 8/1000 [09:54<17:03:18, 61.89s/it, lr=0.001, test_MAE=0.733, time=49.8, train_MAE=0.603, train_loss=0.632, val_MAE=0.654, val_loss=0.683]Epoch 8:   1%|          | 9/1000 [09:54<16:02:16, 58.26s/it, lr=0.001, test_MAE=0.733, time=49.8, train_MAE=0.603, train_loss=0.632, val_MAE=0.654, val_loss=0.683]Epoch 9:   1%|          | 9/1000 [09:54<16:02:16, 58.26s/it, lr=0.001, test_MAE=0.733, time=49.8, train_MAE=0.603, train_loss=0.632, val_MAE=0.654, val_loss=0.683]Epoch 9:   1%|          | 9/1000 [10:44<16:02:16, 58.26s/it, lr=0.001, test_MAE=0.738, time=49.9, train_MAE=0.603, train_loss=0.633, val_MAE=0.685, val_loss=0.714]Epoch 9:   1%|          | 10/1000 [10:44<15:20:01, 55.76s/it, lr=0.001, test_MAE=0.738, time=49.9, train_MAE=0.603, train_loss=0.633, val_MAE=0.685, val_loss=0.714]Epoch 10:   1%|          | 10/1000 [10:44<15:20:01, 55.76s/it, lr=0.001, test_MAE=0.738, time=49.9, train_MAE=0.603, train_loss=0.633, val_MAE=0.685, val_loss=0.714]Epoch 10:   1%|          | 10/1000 [11:34<15:20:01, 55.76s/it, lr=0.001, test_MAE=0.747, time=49.8, train_MAE=0.59, train_loss=0.62, val_MAE=0.704, val_loss=0.735]  Epoch 10:   1%|          | 11/1000 [11:34<14:49:39, 53.97s/it, lr=0.001, test_MAE=0.747, time=49.8, train_MAE=0.59, train_loss=0.62, val_MAE=0.704, val_loss=0.735]Epoch 11:   1%|          | 11/1000 [11:34<14:49:39, 53.97s/it, lr=0.001, test_MAE=0.747, time=49.8, train_MAE=0.59, train_loss=0.62, val_MAE=0.704, val_loss=0.735]Epoch 11:   1%|          | 11/1000 [12:23<14:49:39, 53.97s/it, lr=0.001, test_MAE=0.899, time=49.4, train_MAE=0.593, train_loss=0.625, val_MAE=0.841, val_loss=0.872]Epoch 11:   1%|          | 12/1000 [12:23<14:26:15, 52.61s/it, lr=0.001, test_MAE=0.899, time=49.4, train_MAE=0.593, train_loss=0.625, val_MAE=0.841, val_loss=0.872]Epoch 12:   1%|          | 12/1000 [12:23<14:26:15, 52.61s/it, lr=0.001, test_MAE=0.899, time=49.4, train_MAE=0.593, train_loss=0.625, val_MAE=0.841, val_loss=0.872]Epoch 12:   1%|          | 12/1000 [13:13<14:26:15, 52.61s/it, lr=0.001, test_MAE=0.735, time=50, train_MAE=0.586, train_loss=0.618, val_MAE=0.694, val_loss=0.726]  Epoch    13: reducing learning rate of group 0 to 5.0000e-04.
Epoch 12:   1%|▏         | 13/1000 [13:13<14:12:23, 51.82s/it, lr=0.001, test_MAE=0.735, time=50, train_MAE=0.586, train_loss=0.618, val_MAE=0.694, val_loss=0.726]Epoch 13:   1%|▏         | 13/1000 [13:13<14:12:23, 51.82s/it, lr=0.001, test_MAE=0.735, time=50, train_MAE=0.586, train_loss=0.618, val_MAE=0.694, val_loss=0.726]Epoch 13:   1%|▏         | 13/1000 [14:03<14:12:23, 51.82s/it, lr=0.0005, test_MAE=0.67, time=49.8, train_MAE=0.563, train_loss=0.594, val_MAE=0.618, val_loss=0.649]Epoch 13:   1%|▏         | 14/1000 [14:03<14:01:31, 51.21s/it, lr=0.0005, test_MAE=0.67, time=49.8, train_MAE=0.563, train_loss=0.594, val_MAE=0.618, val_loss=0.649]Epoch 14:   1%|▏         | 14/1000 [14:03<14:01:31, 51.21s/it, lr=0.0005, test_MAE=0.67, time=49.8, train_MAE=0.563, train_loss=0.594, val_MAE=0.618, val_loss=0.649]Epoch 14:   1%|▏         | 14/1000 [14:52<14:01:31, 51.21s/it, lr=0.0005, test_MAE=0.683, time=49.6, train_MAE=0.553, train_loss=0.584, val_MAE=0.625, val_loss=0.656]Epoch 14:   2%|▏         | 15/1000 [14:52<13:52:41, 50.72s/it, lr=0.0005, test_MAE=0.683, time=49.6, train_MAE=0.553, train_loss=0.584, val_MAE=0.625, val_loss=0.656]Epoch 15:   2%|▏         | 15/1000 [14:52<13:52:41, 50.72s/it, lr=0.0005, test_MAE=0.683, time=49.6, train_MAE=0.553, train_loss=0.584, val_MAE=0.625, val_loss=0.656]Epoch 15:   2%|▏         | 15/1000 [15:42<13:52:41, 50.72s/it, lr=0.0005, test_MAE=0.699, time=49.9, train_MAE=0.542, train_loss=0.573, val_MAE=0.643, val_loss=0.674]Epoch 15:   2%|▏         | 16/1000 [15:42<13:47:59, 50.49s/it, lr=0.0005, test_MAE=0.699, time=49.9, train_MAE=0.542, train_loss=0.573, val_MAE=0.643, val_loss=0.674]Epoch 16:   2%|▏         | 16/1000 [15:42<13:47:59, 50.49s/it, lr=0.0005, test_MAE=0.699, time=49.9, train_MAE=0.542, train_loss=0.573, val_MAE=0.643, val_loss=0.674]Epoch 16:   2%|▏         | 16/1000 [16:32<13:47:59, 50.49s/it, lr=0.0005, test_MAE=0.694, time=49.8, train_MAE=0.537, train_loss=0.569, val_MAE=0.637, val_loss=0.669]Epoch 16:   2%|▏         | 17/1000 [16:32<13:43:49, 50.28s/it, lr=0.0005, test_MAE=0.694, time=49.8, train_MAE=0.537, train_loss=0.569, val_MAE=0.637, val_loss=0.669]Epoch 17:   2%|▏         | 17/1000 [16:32<13:43:49, 50.28s/it, lr=0.0005, test_MAE=0.694, time=49.8, train_MAE=0.537, train_loss=0.569, val_MAE=0.637, val_loss=0.669]Epoch 17:   2%|▏         | 17/1000 [17:22<13:43:49, 50.28s/it, lr=0.0005, test_MAE=0.793, time=49.6, train_MAE=0.527, train_loss=0.559, val_MAE=0.73, val_loss=0.762] Epoch 17:   2%|▏         | 18/1000 [17:22<13:39:34, 50.08s/it, lr=0.0005, test_MAE=0.793, time=49.6, train_MAE=0.527, train_loss=0.559, val_MAE=0.73, val_loss=0.762]Epoch 18:   2%|▏         | 18/1000 [17:22<13:39:34, 50.08s/it, lr=0.0005, test_MAE=0.793, time=49.6, train_MAE=0.527, train_loss=0.559, val_MAE=0.73, val_loss=0.762]Epoch 18:   2%|▏         | 18/1000 [18:12<13:39:34, 50.08s/it, lr=0.0005, test_MAE=0.68, time=50, train_MAE=0.53, train_loss=0.563, val_MAE=0.632, val_loss=0.665]   Epoch 18:   2%|▏         | 19/1000 [18:12<13:38:14, 50.05s/it, lr=0.0005, test_MAE=0.68, time=50, train_MAE=0.53, train_loss=0.563, val_MAE=0.632, val_loss=0.665]Epoch 19:   2%|▏         | 19/1000 [18:12<13:38:14, 50.05s/it, lr=0.0005, test_MAE=0.68, time=50, train_MAE=0.53, train_loss=0.563, val_MAE=0.632, val_loss=0.665]Epoch 19:   2%|▏         | 19/1000 [19:02<13:38:14, 50.05s/it, lr=0.0005, test_MAE=0.712, time=50, train_MAE=0.521, train_loss=0.554, val_MAE=0.658, val_loss=0.692]Epoch    20: reducing learning rate of group 0 to 2.5000e-04.
Epoch 19:   2%|▏         | 20/1000 [19:02<13:37:02, 50.02s/it, lr=0.0005, test_MAE=0.712, time=50, train_MAE=0.521, train_loss=0.554, val_MAE=0.658, val_loss=0.692]Epoch 20:   2%|▏         | 20/1000 [19:02<13:37:02, 50.02s/it, lr=0.0005, test_MAE=0.712, time=50, train_MAE=0.521, train_loss=0.554, val_MAE=0.658, val_loss=0.692]Epoch 20:   2%|▏         | 20/1000 [19:52<13:37:02, 50.02s/it, lr=0.00025, test_MAE=0.699, time=50, train_MAE=0.501, train_loss=0.533, val_MAE=0.653, val_loss=0.685]Epoch 20:   2%|▏         | 21/1000 [19:52<13:36:09, 50.02s/it, lr=0.00025, test_MAE=0.699, time=50, train_MAE=0.501, train_loss=0.533, val_MAE=0.653, val_loss=0.685]Epoch 21:   2%|▏         | 21/1000 [19:52<13:36:09, 50.02s/it, lr=0.00025, test_MAE=0.699, time=50, train_MAE=0.501, train_loss=0.533, val_MAE=0.653, val_loss=0.685]Epoch 21:   2%|▏         | 21/1000 [20:42<13:36:09, 50.02s/it, lr=0.00025, test_MAE=0.771, time=50.3, train_MAE=0.497, train_loss=0.529, val_MAE=0.721, val_loss=0.753]Epoch 21:   2%|▏         | 22/1000 [20:42<13:36:44, 50.11s/it, lr=0.00025, test_MAE=0.771, time=50.3, train_MAE=0.497, train_loss=0.529, val_MAE=0.721, val_loss=0.753]Epoch 22:   2%|▏         | 22/1000 [20:42<13:36:44, 50.11s/it, lr=0.00025, test_MAE=0.771, time=50.3, train_MAE=0.497, train_loss=0.529, val_MAE=0.721, val_loss=0.753]Epoch 22:   2%|▏         | 22/1000 [21:32<13:36:44, 50.11s/it, lr=0.00025, test_MAE=0.696, time=49.7, train_MAE=0.49, train_loss=0.523, val_MAE=0.64, val_loss=0.673]  Epoch 22:   2%|▏         | 23/1000 [21:32<13:33:58, 49.99s/it, lr=0.00025, test_MAE=0.696, time=49.7, train_MAE=0.49, train_loss=0.523, val_MAE=0.64, val_loss=0.673]Epoch 23:   2%|▏         | 23/1000 [21:32<13:33:58, 49.99s/it, lr=0.00025, test_MAE=0.696, time=49.7, train_MAE=0.49, train_loss=0.523, val_MAE=0.64, val_loss=0.673]Epoch 23:   2%|▏         | 23/1000 [22:22<13:33:58, 49.99s/it, lr=0.00025, test_MAE=0.673, time=50.2, train_MAE=0.491, train_loss=0.524, val_MAE=0.629, val_loss=0.661]Epoch 23:   2%|▏         | 24/1000 [22:22<13:34:23, 50.07s/it, lr=0.00025, test_MAE=0.673, time=50.2, train_MAE=0.491, train_loss=0.524, val_MAE=0.629, val_loss=0.661]Epoch 24:   2%|▏         | 24/1000 [22:22<13:34:23, 50.07s/it, lr=0.00025, test_MAE=0.673, time=50.2, train_MAE=0.491, train_loss=0.524, val_MAE=0.629, val_loss=0.661]Epoch 24:   2%|▏         | 24/1000 [23:20<13:34:23, 50.07s/it, lr=0.00025, test_MAE=0.718, time=58.2, train_MAE=0.473, train_loss=0.506, val_MAE=0.683, val_loss=0.715]Epoch 24:   2%|▎         | 25/1000 [23:20<14:13:02, 52.50s/it, lr=0.00025, test_MAE=0.718, time=58.2, train_MAE=0.473, train_loss=0.506, val_MAE=0.683, val_loss=0.715]Epoch 25:   2%|▎         | 25/1000 [23:20<14:13:02, 52.50s/it, lr=0.00025, test_MAE=0.718, time=58.2, train_MAE=0.473, train_loss=0.506, val_MAE=0.683, val_loss=0.715]Epoch 25:   2%|▎         | 25/1000 [24:20<14:13:02, 52.50s/it, lr=0.00025, test_MAE=0.772, time=59.5, train_MAE=0.473, train_loss=0.506, val_MAE=0.725, val_loss=0.757]Epoch    26: reducing learning rate of group 0 to 1.2500e-04.
Epoch 25:   3%|▎         | 26/1000 [24:20<14:46:27, 54.61s/it, lr=0.00025, test_MAE=0.772, time=59.5, train_MAE=0.473, train_loss=0.506, val_MAE=0.725, val_loss=0.757]Epoch 26:   3%|▎         | 26/1000 [24:20<14:46:27, 54.61s/it, lr=0.00025, test_MAE=0.772, time=59.5, train_MAE=0.473, train_loss=0.506, val_MAE=0.725, val_loss=0.757]Epoch 26:   3%|▎         | 26/1000 [25:19<14:46:27, 54.61s/it, lr=0.000125, test_MAE=0.696, time=59.7, train_MAE=0.464, train_loss=0.497, val_MAE=0.65, val_loss=0.682]Epoch 26:   3%|▎         | 27/1000 [25:19<15:10:22, 56.14s/it, lr=0.000125, test_MAE=0.696, time=59.7, train_MAE=0.464, train_loss=0.497, val_MAE=0.65, val_loss=0.682]Epoch 27:   3%|▎         | 27/1000 [25:19<15:10:22, 56.14s/it, lr=0.000125, test_MAE=0.696, time=59.7, train_MAE=0.464, train_loss=0.497, val_MAE=0.65, val_loss=0.682]Epoch 27:   3%|▎         | 27/1000 [26:19<15:10:22, 56.14s/it, lr=0.000125, test_MAE=0.698, time=59.3, train_MAE=0.453, train_loss=0.485, val_MAE=0.659, val_loss=0.691]Epoch 27:   3%|▎         | 28/1000 [26:19<15:24:57, 57.10s/it, lr=0.000125, test_MAE=0.698, time=59.3, train_MAE=0.453, train_loss=0.485, val_MAE=0.659, val_loss=0.691]Epoch 28:   3%|▎         | 28/1000 [26:19<15:24:57, 57.10s/it, lr=0.000125, test_MAE=0.698, time=59.3, train_MAE=0.453, train_loss=0.485, val_MAE=0.659, val_loss=0.691]Epoch 28:   3%|▎         | 28/1000 [27:18<15:24:57, 57.10s/it, lr=0.000125, test_MAE=0.683, time=59, train_MAE=0.464, train_loss=0.497, val_MAE=0.641, val_loss=0.674]  Epoch 28:   3%|▎         | 29/1000 [27:18<15:33:19, 57.67s/it, lr=0.000125, test_MAE=0.683, time=59, train_MAE=0.464, train_loss=0.497, val_MAE=0.641, val_loss=0.674]Epoch 29:   3%|▎         | 29/1000 [27:18<15:33:19, 57.67s/it, lr=0.000125, test_MAE=0.683, time=59, train_MAE=0.464, train_loss=0.497, val_MAE=0.641, val_loss=0.674]Epoch 29:   3%|▎         | 29/1000 [28:18<15:33:19, 57.67s/it, lr=0.000125, test_MAE=0.696, time=60.1, train_MAE=0.449, train_loss=0.482, val_MAE=0.644, val_loss=0.677]Epoch 29:   3%|▎         | 30/1000 [28:18<15:43:58, 58.39s/it, lr=0.000125, test_MAE=0.696, time=60.1, train_MAE=0.449, train_loss=0.482, val_MAE=0.644, val_loss=0.677]Epoch 30:   3%|▎         | 30/1000 [28:18<15:43:58, 58.39s/it, lr=0.000125, test_MAE=0.696, time=60.1, train_MAE=0.449, train_loss=0.482, val_MAE=0.644, val_loss=0.677]Epoch 30:   3%|▎         | 30/1000 [29:17<15:43:58, 58.39s/it, lr=0.000125, test_MAE=0.708, time=59.1, train_MAE=0.447, train_loss=0.479, val_MAE=0.671, val_loss=0.703]Epoch 30:   3%|▎         | 31/1000 [29:17<15:46:38, 58.62s/it, lr=0.000125, test_MAE=0.708, time=59.1, train_MAE=0.447, train_loss=0.479, val_MAE=0.671, val_loss=0.703]Epoch 31:   3%|▎         | 31/1000 [29:17<15:46:38, 58.62s/it, lr=0.000125, test_MAE=0.708, time=59.1, train_MAE=0.447, train_loss=0.479, val_MAE=0.671, val_loss=0.703]Epoch 31:   3%|▎         | 31/1000 [30:16<15:46:38, 58.62s/it, lr=0.000125, test_MAE=0.713, time=59, train_MAE=0.437, train_loss=0.47, val_MAE=0.667, val_loss=0.7]     Epoch    32: reducing learning rate of group 0 to 6.2500e-05.
Epoch 31:   3%|▎         | 32/1000 [30:16<15:47:26, 58.73s/it, lr=0.000125, test_MAE=0.713, time=59, train_MAE=0.437, train_loss=0.47, val_MAE=0.667, val_loss=0.7]Epoch 32:   3%|▎         | 32/1000 [30:16<15:47:26, 58.73s/it, lr=0.000125, test_MAE=0.713, time=59, train_MAE=0.437, train_loss=0.47, val_MAE=0.667, val_loss=0.7]Epoch 32:   3%|▎         | 32/1000 [31:16<15:47:26, 58.73s/it, lr=6.25e-5, test_MAE=0.686, time=59.7, train_MAE=0.431, train_loss=0.463, val_MAE=0.642, val_loss=0.674]Epoch 32:   3%|▎         | 33/1000 [31:16<15:51:06, 59.01s/it, lr=6.25e-5, test_MAE=0.686, time=59.7, train_MAE=0.431, train_loss=0.463, val_MAE=0.642, val_loss=0.674]Epoch 33:   3%|▎         | 33/1000 [31:16<15:51:06, 59.01s/it, lr=6.25e-5, test_MAE=0.686, time=59.7, train_MAE=0.431, train_loss=0.463, val_MAE=0.642, val_loss=0.674]Epoch 33:   3%|▎         | 33/1000 [32:15<15:51:06, 59.01s/it, lr=6.25e-5, test_MAE=0.687, time=59.2, train_MAE=0.428, train_loss=0.46, val_MAE=0.645, val_loss=0.677] Epoch 33:   3%|▎         | 34/1000 [32:15<15:51:03, 59.07s/it, lr=6.25e-5, test_MAE=0.687, time=59.2, train_MAE=0.428, train_loss=0.46, val_MAE=0.645, val_loss=0.677]Epoch 34:   3%|▎         | 34/1000 [32:15<15:51:03, 59.07s/it, lr=6.25e-5, test_MAE=0.687, time=59.2, train_MAE=0.428, train_loss=0.46, val_MAE=0.645, val_loss=0.677]Epoch 34:   3%|▎         | 34/1000 [33:14<15:51:03, 59.07s/it, lr=6.25e-5, test_MAE=0.688, time=59, train_MAE=0.425, train_loss=0.457, val_MAE=0.649, val_loss=0.682] Epoch 34:   4%|▎         | 35/1000 [33:14<15:49:59, 59.07s/it, lr=6.25e-5, test_MAE=0.688, time=59, train_MAE=0.425, train_loss=0.457, val_MAE=0.649, val_loss=0.682]Epoch 35:   4%|▎         | 35/1000 [33:14<15:49:59, 59.07s/it, lr=6.25e-5, test_MAE=0.688, time=59, train_MAE=0.425, train_loss=0.457, val_MAE=0.649, val_loss=0.682]Epoch 35:   4%|▎         | 35/1000 [34:13<15:49:59, 59.07s/it, lr=6.25e-5, test_MAE=0.693, time=59.5, train_MAE=0.425, train_loss=0.458, val_MAE=0.653, val_loss=0.685]Epoch 35:   4%|▎         | 36/1000 [34:13<15:51:20, 59.21s/it, lr=6.25e-5, test_MAE=0.693, time=59.5, train_MAE=0.425, train_loss=0.458, val_MAE=0.653, val_loss=0.685]Epoch 36:   4%|▎         | 36/1000 [34:13<15:51:20, 59.21s/it, lr=6.25e-5, test_MAE=0.693, time=59.5, train_MAE=0.425, train_loss=0.458, val_MAE=0.653, val_loss=0.685]Epoch 36:   4%|▎         | 36/1000 [35:13<15:51:20, 59.21s/it, lr=6.25e-5, test_MAE=0.692, time=59.3, train_MAE=0.42, train_loss=0.453, val_MAE=0.653, val_loss=0.685] Epoch 36:   4%|▎         | 37/1000 [35:13<15:51:03, 59.26s/it, lr=6.25e-5, test_MAE=0.692, time=59.3, train_MAE=0.42, train_loss=0.453, val_MAE=0.653, val_loss=0.685]Epoch 37:   4%|▎         | 37/1000 [35:13<15:51:03, 59.26s/it, lr=6.25e-5, test_MAE=0.692, time=59.3, train_MAE=0.42, train_loss=0.453, val_MAE=0.653, val_loss=0.685]Epoch 37:   4%|▎         | 37/1000 [36:12<15:51:03, 59.26s/it, lr=6.25e-5, test_MAE=0.686, time=59, train_MAE=0.417, train_loss=0.45, val_MAE=0.646, val_loss=0.679]  Epoch    38: reducing learning rate of group 0 to 3.1250e-05.
Epoch 37:   4%|▍         | 38/1000 [36:12<15:48:50, 59.18s/it, lr=6.25e-5, test_MAE=0.686, time=59, train_MAE=0.417, train_loss=0.45, val_MAE=0.646, val_loss=0.679]Epoch 38:   4%|▍         | 38/1000 [36:12<15:48:50, 59.18s/it, lr=6.25e-5, test_MAE=0.686, time=59, train_MAE=0.417, train_loss=0.45, val_MAE=0.646, val_loss=0.679]Epoch 38:   4%|▍         | 38/1000 [37:11<15:48:50, 59.18s/it, lr=3.13e-5, test_MAE=0.685, time=59.5, train_MAE=0.421, train_loss=0.453, val_MAE=0.644, val_loss=0.677]Epoch 38:   4%|▍         | 39/1000 [37:11<15:49:34, 59.29s/it, lr=3.13e-5, test_MAE=0.685, time=59.5, train_MAE=0.421, train_loss=0.453, val_MAE=0.644, val_loss=0.677]Epoch 39:   4%|▍         | 39/1000 [37:11<15:49:34, 59.29s/it, lr=3.13e-5, test_MAE=0.685, time=59.5, train_MAE=0.421, train_loss=0.453, val_MAE=0.644, val_loss=0.677]Epoch 39:   4%|▍         | 39/1000 [38:11<15:49:34, 59.29s/it, lr=3.13e-5, test_MAE=0.687, time=59.3, train_MAE=0.409, train_loss=0.442, val_MAE=0.646, val_loss=0.679]Epoch 39:   4%|▍         | 40/1000 [38:11<15:48:43, 59.30s/it, lr=3.13e-5, test_MAE=0.687, time=59.3, train_MAE=0.409, train_loss=0.442, val_MAE=0.646, val_loss=0.679]Epoch 40:   4%|▍         | 40/1000 [38:11<15:48:43, 59.30s/it, lr=3.13e-5, test_MAE=0.687, time=59.3, train_MAE=0.409, train_loss=0.442, val_MAE=0.646, val_loss=0.679]Epoch 40:   4%|▍         | 40/1000 [39:10<15:48:43, 59.30s/it, lr=3.13e-5, test_MAE=0.702, time=59.3, train_MAE=0.44, train_loss=0.472, val_MAE=0.658, val_loss=0.69]  Epoch 40:   4%|▍         | 41/1000 [39:10<15:47:58, 59.31s/it, lr=3.13e-5, test_MAE=0.702, time=59.3, train_MAE=0.44, train_loss=0.472, val_MAE=0.658, val_loss=0.69]Epoch 41:   4%|▍         | 41/1000 [39:10<15:47:58, 59.31s/it, lr=3.13e-5, test_MAE=0.702, time=59.3, train_MAE=0.44, train_loss=0.472, val_MAE=0.658, val_loss=0.69]Epoch 41:   4%|▍         | 41/1000 [40:09<15:47:58, 59.31s/it, lr=3.13e-5, test_MAE=0.683, time=59.5, train_MAE=0.416, train_loss=0.449, val_MAE=0.644, val_loss=0.677]Epoch 41:   4%|▍         | 42/1000 [40:10<15:47:49, 59.36s/it, lr=3.13e-5, test_MAE=0.683, time=59.5, train_MAE=0.416, train_loss=0.449, val_MAE=0.644, val_loss=0.677]Epoch 42:   4%|▍         | 42/1000 [40:10<15:47:49, 59.36s/it, lr=3.13e-5, test_MAE=0.683, time=59.5, train_MAE=0.416, train_loss=0.449, val_MAE=0.644, val_loss=0.677]Epoch 42:   4%|▍         | 42/1000 [41:08<15:47:49, 59.36s/it, lr=3.13e-5, test_MAE=0.692, time=58.9, train_MAE=0.409, train_loss=0.442, val_MAE=0.649, val_loss=0.682]Epoch 42:   4%|▍         | 43/1000 [41:08<15:44:31, 59.22s/it, lr=3.13e-5, test_MAE=0.692, time=58.9, train_MAE=0.409, train_loss=0.442, val_MAE=0.649, val_loss=0.682]Epoch 43:   4%|▍         | 43/1000 [41:08<15:44:31, 59.22s/it, lr=3.13e-5, test_MAE=0.692, time=58.9, train_MAE=0.409, train_loss=0.442, val_MAE=0.649, val_loss=0.682]Epoch 43:   4%|▍         | 43/1000 [42:08<15:44:31, 59.22s/it, lr=3.13e-5, test_MAE=0.689, time=59.5, train_MAE=0.413, train_loss=0.446, val_MAE=0.651, val_loss=0.684]Epoch    44: reducing learning rate of group 0 to 1.5625e-05.
Epoch 43:   4%|▍         | 44/1000 [42:08<15:44:45, 59.29s/it, lr=3.13e-5, test_MAE=0.689, time=59.5, train_MAE=0.413, train_loss=0.446, val_MAE=0.651, val_loss=0.684]Epoch 44:   4%|▍         | 44/1000 [42:08<15:44:45, 59.29s/it, lr=3.13e-5, test_MAE=0.689, time=59.5, train_MAE=0.413, train_loss=0.446, val_MAE=0.651, val_loss=0.684]Epoch 44:   4%|▍         | 44/1000 [43:07<15:44:45, 59.29s/it, lr=1.56e-5, test_MAE=0.689, time=59.2, train_MAE=0.411, train_loss=0.444, val_MAE=0.65, val_loss=0.683] Epoch 44:   4%|▍         | 45/1000 [43:07<15:43:13, 59.26s/it, lr=1.56e-5, test_MAE=0.689, time=59.2, train_MAE=0.411, train_loss=0.444, val_MAE=0.65, val_loss=0.683]Epoch 45:   4%|▍         | 45/1000 [43:07<15:43:13, 59.26s/it, lr=1.56e-5, test_MAE=0.689, time=59.2, train_MAE=0.411, train_loss=0.444, val_MAE=0.65, val_loss=0.683]Epoch 45:   4%|▍         | 45/1000 [44:06<15:43:13, 59.26s/it, lr=1.56e-5, test_MAE=0.685, time=59.1, train_MAE=0.411, train_loss=0.443, val_MAE=0.646, val_loss=0.679]Epoch 45:   5%|▍         | 46/1000 [44:06<15:41:39, 59.22s/it, lr=1.56e-5, test_MAE=0.685, time=59.1, train_MAE=0.411, train_loss=0.443, val_MAE=0.646, val_loss=0.679]Epoch 46:   5%|▍         | 46/1000 [44:06<15:41:39, 59.22s/it, lr=1.56e-5, test_MAE=0.685, time=59.1, train_MAE=0.411, train_loss=0.443, val_MAE=0.646, val_loss=0.679]Epoch 46:   5%|▍         | 46/1000 [45:06<15:41:39, 59.22s/it, lr=1.56e-5, test_MAE=0.688, time=59.6, train_MAE=0.408, train_loss=0.44, val_MAE=0.648, val_loss=0.681] Epoch 46:   5%|▍         | 47/1000 [45:06<15:42:21, 59.33s/it, lr=1.56e-5, test_MAE=0.688, time=59.6, train_MAE=0.408, train_loss=0.44, val_MAE=0.648, val_loss=0.681]Epoch 47:   5%|▍         | 47/1000 [45:06<15:42:21, 59.33s/it, lr=1.56e-5, test_MAE=0.688, time=59.6, train_MAE=0.408, train_loss=0.44, val_MAE=0.648, val_loss=0.681]Epoch 47:   5%|▍         | 47/1000 [46:05<15:42:21, 59.33s/it, lr=1.56e-5, test_MAE=0.69, time=59.3, train_MAE=0.407, train_loss=0.44, val_MAE=0.651, val_loss=0.683] Epoch 47:   5%|▍         | 48/1000 [46:05<15:41:09, 59.32s/it, lr=1.56e-5, test_MAE=0.69, time=59.3, train_MAE=0.407, train_loss=0.44, val_MAE=0.651, val_loss=0.683]Epoch 48:   5%|▍         | 48/1000 [46:05<15:41:09, 59.32s/it, lr=1.56e-5, test_MAE=0.69, time=59.3, train_MAE=0.407, train_loss=0.44, val_MAE=0.651, val_loss=0.683]Epoch 48:   5%|▍         | 48/1000 [47:04<15:41:09, 59.32s/it, lr=1.56e-5, test_MAE=0.691, time=58.7, train_MAE=0.411, train_loss=0.444, val_MAE=0.653, val_loss=0.685]Epoch 48:   5%|▍         | 49/1000 [47:04<15:37:32, 59.15s/it, lr=1.56e-5, test_MAE=0.691, time=58.7, train_MAE=0.411, train_loss=0.444, val_MAE=0.653, val_loss=0.685]Epoch 49:   5%|▍         | 49/1000 [47:04<15:37:32, 59.15s/it, lr=1.56e-5, test_MAE=0.691, time=58.7, train_MAE=0.411, train_loss=0.444, val_MAE=0.653, val_loss=0.685]Epoch 49:   5%|▍         | 49/1000 [48:04<15:37:32, 59.15s/it, lr=1.56e-5, test_MAE=0.692, time=59.9, train_MAE=0.405, train_loss=0.438, val_MAE=0.652, val_loss=0.684]Epoch    50: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 49:   5%|▍         | 49/1000 [48:04<15:32:57, 58.86s/it, lr=1.56e-5, test_MAE=0.692, time=59.9, train_MAE=0.405, train_loss=0.438, val_MAE=0.652, val_loss=0.684]
Test MAE: 0.6921
Train MAE: 0.3758
Convergence Time (Epochs): 49.0000
TOTAL TIME TAKEN: 2923.6586s
AVG TIME PER EPOCH: 57.6700s
