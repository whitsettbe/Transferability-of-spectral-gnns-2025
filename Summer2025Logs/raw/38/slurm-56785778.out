I'm echoing to stdout
I'm echoing to stderr
My JobID is 56785778
I have 8 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.0499s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 53, 'out_dim': 53, 'residual': True, 'readout': 'mean', 'k': 2, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'parallel_dense_simp', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_all', 'num_eigs': 15, 'bias_mode': '', 'eigval_hidden_dim': 5, 'eigval_num_hidden_layer': 3, 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 5.0, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/zinc_train_rec_full.csv', 'test': 'supp_data/molecules/zinc_test_rec_full.csv', 'val': 'supp_data/molecules/zinc_val_rec_full.csv'}, 'fixMissingPhi1': False, 'extraOrtho': True, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [03:10<?, ?it/s, lr=0.001, test_MAE=1.54, time=191, train_MAE=1.1, train_loss=1.21, val_MAE=1.47, val_loss=1.54]Epoch 0:   0%|          | 1/1000 [03:10<52:59:44, 190.98s/it, lr=0.001, test_MAE=1.54, time=191, train_MAE=1.1, train_loss=1.21, val_MAE=1.47, val_loss=1.54]Epoch 1:   0%|          | 1/1000 [03:10<52:59:44, 190.98s/it, lr=0.001, test_MAE=1.54, time=191, train_MAE=1.1, train_loss=1.21, val_MAE=1.47, val_loss=1.54]Epoch 1:   0%|          | 1/1000 [03:57<52:59:44, 190.98s/it, lr=0.001, test_MAE=1.03, time=46.7, train_MAE=0.718, train_loss=0.788, val_MAE=0.964, val_loss=1.03]Epoch 1:   0%|          | 2/1000 [03:57<40:56:47, 147.70s/it, lr=0.001, test_MAE=1.03, time=46.7, train_MAE=0.718, train_loss=0.788, val_MAE=0.964, val_loss=1.03]Epoch 2:   0%|          | 2/1000 [03:57<40:56:47, 147.70s/it, lr=0.001, test_MAE=1.03, time=46.7, train_MAE=0.718, train_loss=0.788, val_MAE=0.964, val_loss=1.03]Epoch 2:   0%|          | 2/1000 [04:44<40:56:47, 147.70s/it, lr=0.001, test_MAE=0.751, time=46.7, train_MAE=0.673, train_loss=0.735, val_MAE=0.69, val_loss=0.75]Epoch 2:   0%|          | 3/1000 [04:44<32:30:45, 117.40s/it, lr=0.001, test_MAE=0.751, time=46.7, train_MAE=0.673, train_loss=0.735, val_MAE=0.69, val_loss=0.75]Epoch 3:   0%|          | 3/1000 [04:44<32:30:45, 117.40s/it, lr=0.001, test_MAE=0.751, time=46.7, train_MAE=0.673, train_loss=0.735, val_MAE=0.69, val_loss=0.75]Epoch 3:   0%|          | 3/1000 [05:31<32:30:45, 117.40s/it, lr=0.001, test_MAE=1.14, time=46.6, train_MAE=0.66, train_loss=0.719, val_MAE=1.1, val_loss=1.15]   Epoch 3:   0%|          | 4/1000 [05:31<26:36:18, 96.16s/it, lr=0.001, test_MAE=1.14, time=46.6, train_MAE=0.66, train_loss=0.719, val_MAE=1.1, val_loss=1.15] Epoch 4:   0%|          | 4/1000 [05:31<26:36:18, 96.16s/it, lr=0.001, test_MAE=1.14, time=46.6, train_MAE=0.66, train_loss=0.719, val_MAE=1.1, val_loss=1.15]Epoch 4:   0%|          | 4/1000 [06:17<26:36:18, 96.16s/it, lr=0.001, test_MAE=1.18, time=46.7, train_MAE=0.662, train_loss=0.716, val_MAE=1.14, val_loss=1.2]Epoch 4:   0%|          | 5/1000 [06:17<22:28:34, 81.32s/it, lr=0.001, test_MAE=1.18, time=46.7, train_MAE=0.662, train_loss=0.716, val_MAE=1.14, val_loss=1.2]Epoch 5:   0%|          | 5/1000 [06:17<22:28:34, 81.32s/it, lr=0.001, test_MAE=1.18, time=46.7, train_MAE=0.662, train_loss=0.716, val_MAE=1.14, val_loss=1.2]Epoch 5:   0%|          | 5/1000 [07:04<22:28:34, 81.32s/it, lr=0.001, test_MAE=1.4, time=46.7, train_MAE=0.652, train_loss=0.705, val_MAE=1.35, val_loss=1.41]Epoch 5:   1%|          | 6/1000 [07:04<19:35:11, 70.94s/it, lr=0.001, test_MAE=1.4, time=46.7, train_MAE=0.652, train_loss=0.705, val_MAE=1.35, val_loss=1.41]Epoch 6:   1%|          | 6/1000 [07:04<19:35:11, 70.94s/it, lr=0.001, test_MAE=1.4, time=46.7, train_MAE=0.652, train_loss=0.705, val_MAE=1.35, val_loss=1.41]Epoch 6:   1%|          | 6/1000 [07:51<19:35:11, 70.94s/it, lr=0.001, test_MAE=1.85, time=47.1, train_MAE=0.655, train_loss=0.709, val_MAE=1.82, val_loss=1.87]Epoch 6:   1%|          | 7/1000 [07:51<17:35:28, 63.77s/it, lr=0.001, test_MAE=1.85, time=47.1, train_MAE=0.655, train_loss=0.709, val_MAE=1.82, val_loss=1.87]Epoch 7:   1%|          | 7/1000 [07:51<17:35:28, 63.77s/it, lr=0.001, test_MAE=1.85, time=47.1, train_MAE=0.655, train_loss=0.709, val_MAE=1.82, val_loss=1.87]Epoch 7:   1%|          | 7/1000 [08:38<17:35:28, 63.77s/it, lr=0.001, test_MAE=1.11, time=46.7, train_MAE=0.637, train_loss=0.688, val_MAE=1.05, val_loss=1.1] Epoch 7:   1%|          | 8/1000 [08:38<16:09:38, 58.65s/it, lr=0.001, test_MAE=1.11, time=46.7, train_MAE=0.637, train_loss=0.688, val_MAE=1.05, val_loss=1.1]Epoch 8:   1%|          | 8/1000 [08:38<16:09:38, 58.65s/it, lr=0.001, test_MAE=1.11, time=46.7, train_MAE=0.637, train_loss=0.688, val_MAE=1.05, val_loss=1.1]Epoch 8:   1%|          | 8/1000 [09:24<16:09:38, 58.65s/it, lr=0.001, test_MAE=1.56, time=46.7, train_MAE=0.642, train_loss=0.694, val_MAE=1.51, val_loss=1.56]Epoch     9: reducing learning rate of group 0 to 5.0000e-04.
Epoch 8:   1%|          | 9/1000 [09:24<15:09:33, 55.07s/it, lr=0.001, test_MAE=1.56, time=46.7, train_MAE=0.642, train_loss=0.694, val_MAE=1.51, val_loss=1.56]Epoch 9:   1%|          | 9/1000 [09:24<15:09:33, 55.07s/it, lr=0.001, test_MAE=1.56, time=46.7, train_MAE=0.642, train_loss=0.694, val_MAE=1.51, val_loss=1.56]Epoch 9:   1%|          | 9/1000 [10:11<15:09:33, 55.07s/it, lr=0.0005, test_MAE=0.694, time=47, train_MAE=0.629, train_loss=0.672, val_MAE=0.641, val_loss=0.682]Epoch 9:   1%|          | 10/1000 [10:11<14:28:32, 52.64s/it, lr=0.0005, test_MAE=0.694, time=47, train_MAE=0.629, train_loss=0.672, val_MAE=0.641, val_loss=0.682]Epoch 10:   1%|          | 10/1000 [10:11<14:28:32, 52.64s/it, lr=0.0005, test_MAE=0.694, time=47, train_MAE=0.629, train_loss=0.672, val_MAE=0.641, val_loss=0.682]Epoch 10:   1%|          | 10/1000 [10:58<14:28:32, 52.64s/it, lr=0.0005, test_MAE=0.721, time=46.7, train_MAE=0.625, train_loss=0.666, val_MAE=0.673, val_loss=0.713]Epoch 10:   1%|          | 11/1000 [10:58<13:58:17, 50.86s/it, lr=0.0005, test_MAE=0.721, time=46.7, train_MAE=0.625, train_loss=0.666, val_MAE=0.673, val_loss=0.713]Epoch 11:   1%|          | 11/1000 [10:58<13:58:17, 50.86s/it, lr=0.0005, test_MAE=0.721, time=46.7, train_MAE=0.625, train_loss=0.666, val_MAE=0.673, val_loss=0.713]Epoch 11:   1%|          | 11/1000 [11:44<13:58:17, 50.86s/it, lr=0.0005, test_MAE=0.867, time=46.4, train_MAE=0.619, train_loss=0.659, val_MAE=0.816, val_loss=0.855]Epoch 11:   1%|          | 12/1000 [11:44<13:35:32, 49.53s/it, lr=0.0005, test_MAE=0.867, time=46.4, train_MAE=0.619, train_loss=0.659, val_MAE=0.816, val_loss=0.855]Epoch 12:   1%|          | 12/1000 [11:44<13:35:32, 49.53s/it, lr=0.0005, test_MAE=0.867, time=46.4, train_MAE=0.619, train_loss=0.659, val_MAE=0.816, val_loss=0.855]Epoch 12:   1%|          | 12/1000 [12:31<13:35:32, 49.53s/it, lr=0.0005, test_MAE=0.922, time=46.9, train_MAE=0.617, train_loss=0.658, val_MAE=0.893, val_loss=0.934]Epoch 12:   1%|▏         | 13/1000 [12:31<13:22:01, 48.76s/it, lr=0.0005, test_MAE=0.922, time=46.9, train_MAE=0.617, train_loss=0.658, val_MAE=0.893, val_loss=0.934]Epoch 13:   1%|▏         | 13/1000 [12:31<13:22:01, 48.76s/it, lr=0.0005, test_MAE=0.922, time=46.9, train_MAE=0.617, train_loss=0.658, val_MAE=0.893, val_loss=0.934]Epoch 13:   1%|▏         | 13/1000 [13:18<13:22:01, 48.76s/it, lr=0.0005, test_MAE=0.699, time=46.6, train_MAE=0.618, train_loss=0.66, val_MAE=0.655, val_loss=0.696] Epoch 13:   1%|▏         | 14/1000 [13:18<13:10:51, 48.13s/it, lr=0.0005, test_MAE=0.699, time=46.6, train_MAE=0.618, train_loss=0.66, val_MAE=0.655, val_loss=0.696]Epoch 14:   1%|▏         | 14/1000 [13:18<13:10:51, 48.13s/it, lr=0.0005, test_MAE=0.699, time=46.6, train_MAE=0.618, train_loss=0.66, val_MAE=0.655, val_loss=0.696]Epoch 14:   1%|▏         | 14/1000 [14:04<13:10:51, 48.13s/it, lr=0.0005, test_MAE=0.919, time=46.4, train_MAE=0.618, train_loss=0.66, val_MAE=0.856, val_loss=0.898]Epoch 14:   2%|▏         | 15/1000 [14:04<13:01:36, 47.61s/it, lr=0.0005, test_MAE=0.919, time=46.4, train_MAE=0.618, train_loss=0.66, val_MAE=0.856, val_loss=0.898]Epoch 15:   2%|▏         | 15/1000 [14:04<13:01:36, 47.61s/it, lr=0.0005, test_MAE=0.919, time=46.4, train_MAE=0.618, train_loss=0.66, val_MAE=0.856, val_loss=0.898]Epoch 15:   2%|▏         | 15/1000 [14:51<13:01:36, 47.61s/it, lr=0.0005, test_MAE=0.692, time=46.6, train_MAE=0.618, train_loss=0.66, val_MAE=0.638, val_loss=0.68] Epoch 15:   2%|▏         | 16/1000 [14:51<12:56:01, 47.32s/it, lr=0.0005, test_MAE=0.692, time=46.6, train_MAE=0.618, train_loss=0.66, val_MAE=0.638, val_loss=0.68]Epoch 16:   2%|▏         | 16/1000 [14:51<12:56:01, 47.32s/it, lr=0.0005, test_MAE=0.692, time=46.6, train_MAE=0.618, train_loss=0.66, val_MAE=0.638, val_loss=0.68]Epoch 16:   2%|▏         | 16/1000 [15:37<12:56:01, 47.32s/it, lr=0.0005, test_MAE=1.35, time=46.2, train_MAE=0.615, train_loss=0.656, val_MAE=1.3, val_loss=1.35]  Epoch 16:   2%|▏         | 17/1000 [15:37<12:49:51, 46.99s/it, lr=0.0005, test_MAE=1.35, time=46.2, train_MAE=0.615, train_loss=0.656, val_MAE=1.3, val_loss=1.35]Epoch 17:   2%|▏         | 17/1000 [15:37<12:49:51, 46.99s/it, lr=0.0005, test_MAE=1.35, time=46.2, train_MAE=0.615, train_loss=0.656, val_MAE=1.3, val_loss=1.35]Epoch 17:   2%|▏         | 17/1000 [16:24<12:49:51, 46.99s/it, lr=0.0005, test_MAE=0.699, time=46.3, train_MAE=0.614, train_loss=0.656, val_MAE=0.653, val_loss=0.695]Epoch 17:   2%|▏         | 18/1000 [16:24<12:45:55, 46.80s/it, lr=0.0005, test_MAE=0.699, time=46.3, train_MAE=0.614, train_loss=0.656, val_MAE=0.653, val_loss=0.695]Epoch 18:   2%|▏         | 18/1000 [16:24<12:45:55, 46.80s/it, lr=0.0005, test_MAE=0.699, time=46.3, train_MAE=0.614, train_loss=0.656, val_MAE=0.653, val_loss=0.695]Epoch 18:   2%|▏         | 18/1000 [17:11<12:45:55, 46.80s/it, lr=0.0005, test_MAE=1.06, time=47, train_MAE=0.614, train_loss=0.656, val_MAE=1.02, val_loss=1.06]     Epoch 18:   2%|▏         | 19/1000 [17:11<12:45:58, 46.85s/it, lr=0.0005, test_MAE=1.06, time=47, train_MAE=0.614, train_loss=0.656, val_MAE=1.02, val_loss=1.06]Epoch 19:   2%|▏         | 19/1000 [17:11<12:45:58, 46.85s/it, lr=0.0005, test_MAE=1.06, time=47, train_MAE=0.614, train_loss=0.656, val_MAE=1.02, val_loss=1.06]Epoch 19:   2%|▏         | 19/1000 [17:57<12:45:58, 46.85s/it, lr=0.0005, test_MAE=0.889, time=46.5, train_MAE=0.611, train_loss=0.653, val_MAE=0.841, val_loss=0.883]Epoch 19:   2%|▏         | 20/1000 [17:57<12:43:43, 46.76s/it, lr=0.0005, test_MAE=0.889, time=46.5, train_MAE=0.611, train_loss=0.653, val_MAE=0.841, val_loss=0.883]Epoch 20:   2%|▏         | 20/1000 [17:57<12:43:43, 46.76s/it, lr=0.0005, test_MAE=0.889, time=46.5, train_MAE=0.611, train_loss=0.653, val_MAE=0.841, val_loss=0.883]Epoch 20:   2%|▏         | 20/1000 [18:43<12:43:43, 46.76s/it, lr=0.0005, test_MAE=0.731, time=46.2, train_MAE=0.617, train_loss=0.661, val_MAE=0.676, val_loss=0.718]Epoch 20:   2%|▏         | 21/1000 [18:43<12:40:08, 46.59s/it, lr=0.0005, test_MAE=0.731, time=46.2, train_MAE=0.617, train_loss=0.661, val_MAE=0.676, val_loss=0.718]Epoch 21:   2%|▏         | 21/1000 [18:43<12:40:08, 46.59s/it, lr=0.0005, test_MAE=0.731, time=46.2, train_MAE=0.617, train_loss=0.661, val_MAE=0.676, val_loss=0.718]Epoch 21:   2%|▏         | 21/1000 [19:30<12:40:08, 46.59s/it, lr=0.0005, test_MAE=0.707, time=46.6, train_MAE=0.61, train_loss=0.653, val_MAE=0.654, val_loss=0.695] Epoch    22: reducing learning rate of group 0 to 2.5000e-04.
Epoch 21:   2%|▏         | 22/1000 [19:30<12:39:29, 46.59s/it, lr=0.0005, test_MAE=0.707, time=46.6, train_MAE=0.61, train_loss=0.653, val_MAE=0.654, val_loss=0.695]Epoch 22:   2%|▏         | 22/1000 [19:30<12:39:29, 46.59s/it, lr=0.0005, test_MAE=0.707, time=46.6, train_MAE=0.61, train_loss=0.653, val_MAE=0.654, val_loss=0.695]Epoch 22:   2%|▏         | 22/1000 [20:16<12:39:29, 46.59s/it, lr=0.00025, test_MAE=0.713, time=45.9, train_MAE=0.601, train_loss=0.641, val_MAE=0.656, val_loss=0.693]Epoch 22:   2%|▏         | 23/1000 [20:16<12:35:21, 46.39s/it, lr=0.00025, test_MAE=0.713, time=45.9, train_MAE=0.601, train_loss=0.641, val_MAE=0.656, val_loss=0.693]Epoch 23:   2%|▏         | 23/1000 [20:16<12:35:21, 46.39s/it, lr=0.00025, test_MAE=0.713, time=45.9, train_MAE=0.601, train_loss=0.641, val_MAE=0.656, val_loss=0.693]Epoch 23:   2%|▏         | 23/1000 [21:02<12:35:21, 46.39s/it, lr=0.00025, test_MAE=0.677, time=46.5, train_MAE=0.599, train_loss=0.636, val_MAE=0.629, val_loss=0.666]Epoch 23:   2%|▏         | 24/1000 [21:02<12:35:16, 46.43s/it, lr=0.00025, test_MAE=0.677, time=46.5, train_MAE=0.599, train_loss=0.636, val_MAE=0.629, val_loss=0.666]Epoch 24:   2%|▏         | 24/1000 [21:02<12:35:16, 46.43s/it, lr=0.00025, test_MAE=0.677, time=46.5, train_MAE=0.599, train_loss=0.636, val_MAE=0.629, val_loss=0.666]Epoch 24:   2%|▏         | 24/1000 [21:49<12:35:16, 46.43s/it, lr=0.00025, test_MAE=0.772, time=46.2, train_MAE=0.6, train_loss=0.637, val_MAE=0.723, val_loss=0.759]  Epoch 24:   2%|▎         | 25/1000 [21:49<12:33:40, 46.38s/it, lr=0.00025, test_MAE=0.772, time=46.2, train_MAE=0.6, train_loss=0.637, val_MAE=0.723, val_loss=0.759]Epoch 25:   2%|▎         | 25/1000 [21:49<12:33:40, 46.38s/it, lr=0.00025, test_MAE=0.772, time=46.2, train_MAE=0.6, train_loss=0.637, val_MAE=0.723, val_loss=0.759]Epoch 25:   2%|▎         | 25/1000 [22:35<12:33:40, 46.38s/it, lr=0.00025, test_MAE=0.763, time=46.2, train_MAE=0.596, train_loss=0.633, val_MAE=0.735, val_loss=0.771]Epoch 25:   3%|▎         | 26/1000 [22:35<12:31:59, 46.32s/it, lr=0.00025, test_MAE=0.763, time=46.2, train_MAE=0.596, train_loss=0.633, val_MAE=0.735, val_loss=0.771]Epoch 26:   3%|▎         | 26/1000 [22:35<12:31:59, 46.32s/it, lr=0.00025, test_MAE=0.763, time=46.2, train_MAE=0.596, train_loss=0.633, val_MAE=0.735, val_loss=0.771]Epoch 26:   3%|▎         | 26/1000 [23:21<12:31:59, 46.32s/it, lr=0.00025, test_MAE=0.843, time=46.5, train_MAE=0.598, train_loss=0.635, val_MAE=0.793, val_loss=0.829]Epoch 26:   3%|▎         | 27/1000 [23:21<12:32:15, 46.39s/it, lr=0.00025, test_MAE=0.843, time=46.5, train_MAE=0.598, train_loss=0.635, val_MAE=0.793, val_loss=0.829]Epoch 27:   3%|▎         | 27/1000 [23:21<12:32:15, 46.39s/it, lr=0.00025, test_MAE=0.843, time=46.5, train_MAE=0.598, train_loss=0.635, val_MAE=0.793, val_loss=0.829]Epoch 27:   3%|▎         | 27/1000 [24:08<12:32:15, 46.39s/it, lr=0.00025, test_MAE=0.679, time=46.2, train_MAE=0.591, train_loss=0.628, val_MAE=0.631, val_loss=0.667]Epoch 27:   3%|▎         | 28/1000 [24:08<12:30:49, 46.35s/it, lr=0.00025, test_MAE=0.679, time=46.2, train_MAE=0.591, train_loss=0.628, val_MAE=0.631, val_loss=0.667]Epoch 28:   3%|▎         | 28/1000 [24:08<12:30:49, 46.35s/it, lr=0.00025, test_MAE=0.679, time=46.2, train_MAE=0.591, train_loss=0.628, val_MAE=0.631, val_loss=0.667]Epoch 28:   3%|▎         | 28/1000 [24:54<12:30:49, 46.35s/it, lr=0.00025, test_MAE=0.682, time=45.9, train_MAE=0.596, train_loss=0.632, val_MAE=0.648, val_loss=0.684]Epoch 28:   3%|▎         | 29/1000 [24:54<12:28:02, 46.22s/it, lr=0.00025, test_MAE=0.682, time=45.9, train_MAE=0.596, train_loss=0.632, val_MAE=0.648, val_loss=0.684]Epoch 29:   3%|▎         | 29/1000 [24:54<12:28:02, 46.22s/it, lr=0.00025, test_MAE=0.682, time=45.9, train_MAE=0.596, train_loss=0.632, val_MAE=0.648, val_loss=0.684]Epoch 29:   3%|▎         | 29/1000 [25:40<12:28:02, 46.22s/it, lr=0.00025, test_MAE=0.687, time=46.8, train_MAE=0.594, train_loss=0.631, val_MAE=0.657, val_loss=0.694]Epoch    30: reducing learning rate of group 0 to 1.2500e-04.
Epoch 29:   3%|▎         | 30/1000 [25:40<12:30:10, 46.40s/it, lr=0.00025, test_MAE=0.687, time=46.8, train_MAE=0.594, train_loss=0.631, val_MAE=0.657, val_loss=0.694]Epoch 30:   3%|▎         | 30/1000 [25:40<12:30:10, 46.40s/it, lr=0.00025, test_MAE=0.687, time=46.8, train_MAE=0.594, train_loss=0.631, val_MAE=0.657, val_loss=0.694]Epoch 30:   3%|▎         | 30/1000 [26:27<12:30:10, 46.40s/it, lr=0.000125, test_MAE=0.662, time=46.2, train_MAE=0.584, train_loss=0.62, val_MAE=0.636, val_loss=0.67] Epoch 30:   3%|▎         | 31/1000 [26:27<12:28:37, 46.35s/it, lr=0.000125, test_MAE=0.662, time=46.2, train_MAE=0.584, train_loss=0.62, val_MAE=0.636, val_loss=0.67]Epoch 31:   3%|▎         | 31/1000 [26:27<12:28:37, 46.35s/it, lr=0.000125, test_MAE=0.662, time=46.2, train_MAE=0.584, train_loss=0.62, val_MAE=0.636, val_loss=0.67]Epoch 31:   3%|▎         | 31/1000 [27:13<12:28:37, 46.35s/it, lr=0.000125, test_MAE=0.665, time=46, train_MAE=0.592, train_loss=0.626, val_MAE=0.625, val_loss=0.659]Epoch 31:   3%|▎         | 32/1000 [27:13<12:26:05, 46.25s/it, lr=0.000125, test_MAE=0.665, time=46, train_MAE=0.592, train_loss=0.626, val_MAE=0.625, val_loss=0.659]Epoch 32:   3%|▎         | 32/1000 [27:13<12:26:05, 46.25s/it, lr=0.000125, test_MAE=0.665, time=46, train_MAE=0.592, train_loss=0.626, val_MAE=0.625, val_loss=0.659]Epoch 32:   3%|▎         | 32/1000 [27:59<12:26:05, 46.25s/it, lr=0.000125, test_MAE=0.669, time=46.5, train_MAE=0.583, train_loss=0.617, val_MAE=0.629, val_loss=0.663]Epoch 32:   3%|▎         | 33/1000 [27:59<12:26:44, 46.33s/it, lr=0.000125, test_MAE=0.669, time=46.5, train_MAE=0.583, train_loss=0.617, val_MAE=0.629, val_loss=0.663]Epoch 33:   3%|▎         | 33/1000 [27:59<12:26:44, 46.33s/it, lr=0.000125, test_MAE=0.669, time=46.5, train_MAE=0.583, train_loss=0.617, val_MAE=0.629, val_loss=0.663]Epoch 33:   3%|▎         | 33/1000 [28:45<12:26:44, 46.33s/it, lr=0.000125, test_MAE=0.661, time=46.2, train_MAE=0.58, train_loss=0.614, val_MAE=0.624, val_loss=0.658] Epoch 33:   3%|▎         | 34/1000 [28:45<12:25:21, 46.30s/it, lr=0.000125, test_MAE=0.661, time=46.2, train_MAE=0.58, train_loss=0.614, val_MAE=0.624, val_loss=0.658]Epoch 34:   3%|▎         | 34/1000 [28:45<12:25:21, 46.30s/it, lr=0.000125, test_MAE=0.661, time=46.2, train_MAE=0.58, train_loss=0.614, val_MAE=0.624, val_loss=0.658]Epoch 34:   3%|▎         | 34/1000 [29:31<12:25:21, 46.30s/it, lr=0.000125, test_MAE=0.679, time=45.9, train_MAE=0.58, train_loss=0.614, val_MAE=0.639, val_loss=0.673]Epoch 34:   4%|▎         | 35/1000 [29:31<12:22:43, 46.18s/it, lr=0.000125, test_MAE=0.679, time=45.9, train_MAE=0.58, train_loss=0.614, val_MAE=0.639, val_loss=0.673]Epoch 35:   4%|▎         | 35/1000 [29:31<12:22:43, 46.18s/it, lr=0.000125, test_MAE=0.679, time=45.9, train_MAE=0.58, train_loss=0.614, val_MAE=0.639, val_loss=0.673]Epoch 35:   4%|▎         | 35/1000 [30:18<12:22:43, 46.18s/it, lr=0.000125, test_MAE=0.675, time=46.6, train_MAE=0.579, train_loss=0.613, val_MAE=0.64, val_loss=0.674]Epoch 35:   4%|▎         | 36/1000 [30:18<12:23:56, 46.30s/it, lr=0.000125, test_MAE=0.675, time=46.6, train_MAE=0.579, train_loss=0.613, val_MAE=0.64, val_loss=0.674]Epoch 36:   4%|▎         | 36/1000 [30:18<12:23:56, 46.30s/it, lr=0.000125, test_MAE=0.675, time=46.6, train_MAE=0.579, train_loss=0.613, val_MAE=0.64, val_loss=0.674]Epoch 36:   4%|▎         | 36/1000 [31:04<12:23:56, 46.30s/it, lr=0.000125, test_MAE=0.664, time=46.2, train_MAE=0.576, train_loss=0.61, val_MAE=0.635, val_loss=0.669]Epoch 36:   4%|▎         | 37/1000 [31:04<12:22:52, 46.28s/it, lr=0.000125, test_MAE=0.664, time=46.2, train_MAE=0.576, train_loss=0.61, val_MAE=0.635, val_loss=0.669]Epoch 37:   4%|▎         | 37/1000 [31:04<12:22:52, 46.28s/it, lr=0.000125, test_MAE=0.664, time=46.2, train_MAE=0.576, train_loss=0.61, val_MAE=0.635, val_loss=0.669]Epoch 37:   4%|▎         | 37/1000 [31:50<12:22:52, 46.28s/it, lr=0.000125, test_MAE=0.669, time=45.9, train_MAE=0.583, train_loss=0.617, val_MAE=0.632, val_loss=0.666]Epoch 37:   4%|▍         | 38/1000 [31:50<12:20:21, 46.18s/it, lr=0.000125, test_MAE=0.669, time=45.9, train_MAE=0.583, train_loss=0.617, val_MAE=0.632, val_loss=0.666]Epoch 38:   4%|▍         | 38/1000 [31:50<12:20:21, 46.18s/it, lr=0.000125, test_MAE=0.669, time=45.9, train_MAE=0.583, train_loss=0.617, val_MAE=0.632, val_loss=0.666]Epoch 38:   4%|▍         | 38/1000 [32:37<12:20:21, 46.18s/it, lr=0.000125, test_MAE=0.668, time=46.5, train_MAE=0.579, train_loss=0.613, val_MAE=0.633, val_loss=0.667]Epoch 38:   4%|▍         | 39/1000 [32:37<12:21:18, 46.28s/it, lr=0.000125, test_MAE=0.668, time=46.5, train_MAE=0.579, train_loss=0.613, val_MAE=0.633, val_loss=0.667]Epoch 39:   4%|▍         | 39/1000 [32:37<12:21:18, 46.28s/it, lr=0.000125, test_MAE=0.668, time=46.5, train_MAE=0.579, train_loss=0.613, val_MAE=0.633, val_loss=0.667]Epoch 39:   4%|▍         | 39/1000 [33:23<12:21:18, 46.28s/it, lr=0.000125, test_MAE=0.663, time=46.3, train_MAE=0.576, train_loss=0.611, val_MAE=0.63, val_loss=0.664] Epoch    40: reducing learning rate of group 0 to 6.2500e-05.
Epoch 39:   4%|▍         | 40/1000 [33:23<12:20:36, 46.29s/it, lr=0.000125, test_MAE=0.663, time=46.3, train_MAE=0.576, train_loss=0.611, val_MAE=0.63, val_loss=0.664]Epoch 40:   4%|▍         | 40/1000 [33:23<12:20:36, 46.29s/it, lr=0.000125, test_MAE=0.663, time=46.3, train_MAE=0.576, train_loss=0.611, val_MAE=0.63, val_loss=0.664]Epoch 40:   4%|▍         | 40/1000 [34:09<12:20:36, 46.29s/it, lr=6.25e-5, test_MAE=0.665, time=46.2, train_MAE=0.575, train_loss=0.608, val_MAE=0.636, val_loss=0.669]Epoch 40:   4%|▍         | 41/1000 [34:09<12:19:39, 46.28s/it, lr=6.25e-5, test_MAE=0.665, time=46.2, train_MAE=0.575, train_loss=0.608, val_MAE=0.636, val_loss=0.669]Epoch 41:   4%|▍         | 41/1000 [34:09<12:19:39, 46.28s/it, lr=6.25e-5, test_MAE=0.665, time=46.2, train_MAE=0.575, train_loss=0.608, val_MAE=0.636, val_loss=0.669]Epoch 41:   4%|▍         | 41/1000 [34:56<12:19:39, 46.28s/it, lr=6.25e-5, test_MAE=0.658, time=46.5, train_MAE=0.569, train_loss=0.602, val_MAE=0.628, val_loss=0.66] Epoch 41:   4%|▍         | 42/1000 [34:56<12:20:11, 46.36s/it, lr=6.25e-5, test_MAE=0.658, time=46.5, train_MAE=0.569, train_loss=0.602, val_MAE=0.628, val_loss=0.66]Epoch 42:   4%|▍         | 42/1000 [34:56<12:20:11, 46.36s/it, lr=6.25e-5, test_MAE=0.658, time=46.5, train_MAE=0.569, train_loss=0.602, val_MAE=0.628, val_loss=0.66]Epoch 42:   4%|▍         | 42/1000 [35:42<12:20:11, 46.36s/it, lr=6.25e-5, test_MAE=0.66, time=45.9, train_MAE=0.58, train_loss=0.613, val_MAE=0.624, val_loss=0.657] Epoch 42:   4%|▍         | 43/1000 [35:42<12:17:15, 46.22s/it, lr=6.25e-5, test_MAE=0.66, time=45.9, train_MAE=0.58, train_loss=0.613, val_MAE=0.624, val_loss=0.657]Epoch 43:   4%|▍         | 43/1000 [35:42<12:17:15, 46.22s/it, lr=6.25e-5, test_MAE=0.66, time=45.9, train_MAE=0.58, train_loss=0.613, val_MAE=0.624, val_loss=0.657]Epoch 43:   4%|▍         | 43/1000 [36:28<12:17:15, 46.22s/it, lr=6.25e-5, test_MAE=0.681, time=46.5, train_MAE=0.584, train_loss=0.617, val_MAE=0.643, val_loss=0.675]Epoch 43:   4%|▍         | 44/1000 [36:28<12:18:04, 46.32s/it, lr=6.25e-5, test_MAE=0.681, time=46.5, train_MAE=0.584, train_loss=0.617, val_MAE=0.643, val_loss=0.675]Epoch 44:   4%|▍         | 44/1000 [36:28<12:18:04, 46.32s/it, lr=6.25e-5, test_MAE=0.681, time=46.5, train_MAE=0.584, train_loss=0.617, val_MAE=0.643, val_loss=0.675]Epoch 44:   4%|▍         | 44/1000 [37:14<12:18:04, 46.32s/it, lr=6.25e-5, test_MAE=0.666, time=46.2, train_MAE=0.573, train_loss=0.606, val_MAE=0.634, val_loss=0.666]Epoch 44:   4%|▍         | 45/1000 [37:14<12:16:56, 46.30s/it, lr=6.25e-5, test_MAE=0.666, time=46.2, train_MAE=0.573, train_loss=0.606, val_MAE=0.634, val_loss=0.666]Epoch 45:   4%|▍         | 45/1000 [37:14<12:16:56, 46.30s/it, lr=6.25e-5, test_MAE=0.666, time=46.2, train_MAE=0.573, train_loss=0.606, val_MAE=0.634, val_loss=0.666]Epoch 45:   4%|▍         | 45/1000 [38:01<12:16:56, 46.30s/it, lr=6.25e-5, test_MAE=0.661, time=46.3, train_MAE=0.577, train_loss=0.61, val_MAE=0.627, val_loss=0.659] Epoch 45:   5%|▍         | 46/1000 [38:01<12:16:06, 46.30s/it, lr=6.25e-5, test_MAE=0.661, time=46.3, train_MAE=0.577, train_loss=0.61, val_MAE=0.627, val_loss=0.659]Epoch 46:   5%|▍         | 46/1000 [38:01<12:16:06, 46.30s/it, lr=6.25e-5, test_MAE=0.661, time=46.3, train_MAE=0.577, train_loss=0.61, val_MAE=0.627, val_loss=0.659]Epoch 46:   5%|▍         | 46/1000 [38:47<12:16:06, 46.30s/it, lr=6.25e-5, test_MAE=0.658, time=46.5, train_MAE=0.574, train_loss=0.607, val_MAE=0.626, val_loss=0.658]Epoch 46:   5%|▍         | 47/1000 [38:47<12:16:25, 46.36s/it, lr=6.25e-5, test_MAE=0.658, time=46.5, train_MAE=0.574, train_loss=0.607, val_MAE=0.626, val_loss=0.658]Epoch 47:   5%|▍         | 47/1000 [38:47<12:16:25, 46.36s/it, lr=6.25e-5, test_MAE=0.658, time=46.5, train_MAE=0.574, train_loss=0.607, val_MAE=0.626, val_loss=0.658]Epoch 47:   5%|▍         | 47/1000 [39:33<12:16:25, 46.36s/it, lr=6.25e-5, test_MAE=0.656, time=46.3, train_MAE=0.573, train_loss=0.605, val_MAE=0.626, val_loss=0.658]Epoch 47:   5%|▍         | 48/1000 [39:34<12:15:09, 46.33s/it, lr=6.25e-5, test_MAE=0.656, time=46.3, train_MAE=0.573, train_loss=0.605, val_MAE=0.626, val_loss=0.658]Epoch 48:   5%|▍         | 48/1000 [39:34<12:15:09, 46.33s/it, lr=6.25e-5, test_MAE=0.656, time=46.3, train_MAE=0.573, train_loss=0.605, val_MAE=0.626, val_loss=0.658]Epoch 48:   5%|▍         | 48/1000 [40:19<12:15:09, 46.33s/it, lr=6.25e-5, test_MAE=0.659, time=45.9, train_MAE=0.577, train_loss=0.609, val_MAE=0.626, val_loss=0.658]Epoch    49: reducing learning rate of group 0 to 3.1250e-05.
Epoch 48:   5%|▍         | 49/1000 [40:19<12:12:30, 46.22s/it, lr=6.25e-5, test_MAE=0.659, time=45.9, train_MAE=0.577, train_loss=0.609, val_MAE=0.626, val_loss=0.658]Epoch 49:   5%|▍         | 49/1000 [40:19<12:12:30, 46.22s/it, lr=6.25e-5, test_MAE=0.659, time=45.9, train_MAE=0.577, train_loss=0.609, val_MAE=0.626, val_loss=0.658]Epoch 49:   5%|▍         | 49/1000 [41:06<12:12:30, 46.22s/it, lr=3.13e-5, test_MAE=0.66, time=46.9, train_MAE=0.572, train_loss=0.604, val_MAE=0.627, val_loss=0.658] Epoch 49:   5%|▌         | 50/1000 [41:06<12:14:50, 46.41s/it, lr=3.13e-5, test_MAE=0.66, time=46.9, train_MAE=0.572, train_loss=0.604, val_MAE=0.627, val_loss=0.658]Epoch 50:   5%|▌         | 50/1000 [41:06<12:14:50, 46.41s/it, lr=3.13e-5, test_MAE=0.66, time=46.9, train_MAE=0.572, train_loss=0.604, val_MAE=0.627, val_loss=0.658]Epoch 50:   5%|▌         | 50/1000 [41:53<12:14:50, 46.41s/it, lr=3.13e-5, test_MAE=0.659, time=46.2, train_MAE=0.567, train_loss=0.599, val_MAE=0.629, val_loss=0.661]Epoch 50:   5%|▌         | 51/1000 [41:53<12:13:16, 46.36s/it, lr=3.13e-5, test_MAE=0.659, time=46.2, train_MAE=0.567, train_loss=0.599, val_MAE=0.629, val_loss=0.661]Epoch 51:   5%|▌         | 51/1000 [41:53<12:13:16, 46.36s/it, lr=3.13e-5, test_MAE=0.659, time=46.2, train_MAE=0.567, train_loss=0.599, val_MAE=0.629, val_loss=0.661]Epoch 51:   5%|▌         | 51/1000 [42:38<12:13:16, 46.36s/it, lr=3.13e-5, test_MAE=0.657, time=45.9, train_MAE=0.571, train_loss=0.603, val_MAE=0.624, val_loss=0.655]Epoch 51:   5%|▌         | 52/1000 [42:38<12:10:15, 46.22s/it, lr=3.13e-5, test_MAE=0.657, time=45.9, train_MAE=0.571, train_loss=0.603, val_MAE=0.624, val_loss=0.655]Epoch 52:   5%|▌         | 52/1000 [42:38<12:10:15, 46.22s/it, lr=3.13e-5, test_MAE=0.657, time=45.9, train_MAE=0.571, train_loss=0.603, val_MAE=0.624, val_loss=0.655]Epoch 52:   5%|▌         | 52/1000 [43:25<12:10:15, 46.22s/it, lr=3.13e-5, test_MAE=0.657, time=46.6, train_MAE=0.569, train_loss=0.601, val_MAE=0.625, val_loss=0.657]Epoch 52:   5%|▌         | 53/1000 [43:25<12:11:06, 46.32s/it, lr=3.13e-5, test_MAE=0.657, time=46.6, train_MAE=0.569, train_loss=0.601, val_MAE=0.625, val_loss=0.657]Epoch 53:   5%|▌         | 53/1000 [43:25<12:11:06, 46.32s/it, lr=3.13e-5, test_MAE=0.657, time=46.6, train_MAE=0.569, train_loss=0.601, val_MAE=0.625, val_loss=0.657]Epoch 53:   5%|▌         | 53/1000 [44:12<12:11:06, 46.32s/it, lr=3.13e-5, test_MAE=0.657, time=47.2, train_MAE=0.571, train_loss=0.602, val_MAE=0.627, val_loss=0.658]Epoch 53:   5%|▌         | 54/1000 [44:12<12:14:32, 46.59s/it, lr=3.13e-5, test_MAE=0.657, time=47.2, train_MAE=0.571, train_loss=0.602, val_MAE=0.627, val_loss=0.658]Epoch 54:   5%|▌         | 54/1000 [44:12<12:14:32, 46.59s/it, lr=3.13e-5, test_MAE=0.657, time=47.2, train_MAE=0.571, train_loss=0.602, val_MAE=0.627, val_loss=0.658]Epoch 54:   5%|▌         | 54/1000 [45:01<12:14:32, 46.59s/it, lr=3.13e-5, test_MAE=0.659, time=49.2, train_MAE=0.571, train_loss=0.603, val_MAE=0.626, val_loss=0.657]Epoch 54:   6%|▌         | 55/1000 [45:01<12:26:01, 47.37s/it, lr=3.13e-5, test_MAE=0.659, time=49.2, train_MAE=0.571, train_loss=0.603, val_MAE=0.626, val_loss=0.657]Epoch 55:   6%|▌         | 55/1000 [45:01<12:26:01, 47.37s/it, lr=3.13e-5, test_MAE=0.659, time=49.2, train_MAE=0.571, train_loss=0.603, val_MAE=0.626, val_loss=0.657]Epoch 55:   6%|▌         | 55/1000 [45:52<12:26:01, 47.37s/it, lr=3.13e-5, test_MAE=0.656, time=50.1, train_MAE=0.567, train_loss=0.598, val_MAE=0.625, val_loss=0.657]Epoch 55:   6%|▌         | 56/1000 [45:52<12:38:11, 48.19s/it, lr=3.13e-5, test_MAE=0.656, time=50.1, train_MAE=0.567, train_loss=0.598, val_MAE=0.625, val_loss=0.657]Epoch 56:   6%|▌         | 56/1000 [45:52<12:38:11, 48.19s/it, lr=3.13e-5, test_MAE=0.656, time=50.1, train_MAE=0.567, train_loss=0.598, val_MAE=0.625, val_loss=0.657]Epoch 56:   6%|▌         | 56/1000 [46:41<12:38:11, 48.19s/it, lr=3.13e-5, test_MAE=0.654, time=49.8, train_MAE=0.565, train_loss=0.597, val_MAE=0.626, val_loss=0.658]Epoch 56:   6%|▌         | 57/1000 [46:41<12:44:48, 48.66s/it, lr=3.13e-5, test_MAE=0.654, time=49.8, train_MAE=0.565, train_loss=0.597, val_MAE=0.626, val_loss=0.658]Epoch 57:   6%|▌         | 57/1000 [46:41<12:44:48, 48.66s/it, lr=3.13e-5, test_MAE=0.654, time=49.8, train_MAE=0.565, train_loss=0.597, val_MAE=0.626, val_loss=0.658]Epoch 57:   6%|▌         | 57/1000 [47:31<12:44:48, 48.66s/it, lr=3.13e-5, test_MAE=0.656, time=49.4, train_MAE=0.565, train_loss=0.596, val_MAE=0.626, val_loss=0.657]Epoch    58: reducing learning rate of group 0 to 1.5625e-05.
Epoch 57:   6%|▌         | 58/1000 [47:31<12:47:38, 48.89s/it, lr=3.13e-5, test_MAE=0.656, time=49.4, train_MAE=0.565, train_loss=0.596, val_MAE=0.626, val_loss=0.657]Epoch 58:   6%|▌         | 58/1000 [47:31<12:47:38, 48.89s/it, lr=3.13e-5, test_MAE=0.656, time=49.4, train_MAE=0.565, train_loss=0.596, val_MAE=0.626, val_loss=0.657]Epoch 58:   6%|▌         | 58/1000 [48:21<12:47:38, 48.89s/it, lr=1.56e-5, test_MAE=0.654, time=50, train_MAE=0.567, train_loss=0.598, val_MAE=0.624, val_loss=0.655]  Epoch 58:   6%|▌         | 59/1000 [48:21<12:52:16, 49.24s/it, lr=1.56e-5, test_MAE=0.654, time=50, train_MAE=0.567, train_loss=0.598, val_MAE=0.624, val_loss=0.655]Epoch 59:   6%|▌         | 59/1000 [48:21<12:52:16, 49.24s/it, lr=1.56e-5, test_MAE=0.654, time=50, train_MAE=0.567, train_loss=0.598, val_MAE=0.624, val_loss=0.655]Epoch 59:   6%|▌         | 59/1000 [49:10<12:52:16, 49.24s/it, lr=1.56e-5, test_MAE=0.655, time=49.7, train_MAE=0.564, train_loss=0.595, val_MAE=0.625, val_loss=0.656]Epoch 59:   6%|▌         | 60/1000 [49:10<12:53:45, 49.39s/it, lr=1.56e-5, test_MAE=0.655, time=49.7, train_MAE=0.564, train_loss=0.595, val_MAE=0.625, val_loss=0.656]Epoch 60:   6%|▌         | 60/1000 [49:10<12:53:45, 49.39s/it, lr=1.56e-5, test_MAE=0.655, time=49.7, train_MAE=0.564, train_loss=0.595, val_MAE=0.625, val_loss=0.656]Epoch 60:   6%|▌         | 60/1000 [50:00<12:53:45, 49.39s/it, lr=1.56e-5, test_MAE=0.656, time=49.7, train_MAE=0.562, train_loss=0.593, val_MAE=0.625, val_loss=0.656]Epoch 60:   6%|▌         | 61/1000 [50:00<12:54:19, 49.48s/it, lr=1.56e-5, test_MAE=0.656, time=49.7, train_MAE=0.562, train_loss=0.593, val_MAE=0.625, val_loss=0.656]Epoch 61:   6%|▌         | 61/1000 [50:00<12:54:19, 49.48s/it, lr=1.56e-5, test_MAE=0.656, time=49.7, train_MAE=0.562, train_loss=0.593, val_MAE=0.625, val_loss=0.656]Epoch 61:   6%|▌         | 61/1000 [50:50<12:54:19, 49.48s/it, lr=1.56e-5, test_MAE=0.663, time=50.1, train_MAE=0.568, train_loss=0.599, val_MAE=0.63, val_loss=0.66]  Epoch 61:   6%|▌         | 62/1000 [50:50<12:56:14, 49.65s/it, lr=1.56e-5, test_MAE=0.663, time=50.1, train_MAE=0.568, train_loss=0.599, val_MAE=0.63, val_loss=0.66]Epoch 62:   6%|▌         | 62/1000 [50:50<12:56:14, 49.65s/it, lr=1.56e-5, test_MAE=0.663, time=50.1, train_MAE=0.568, train_loss=0.599, val_MAE=0.63, val_loss=0.66]Epoch 62:   6%|▌         | 62/1000 [51:40<12:56:14, 49.65s/it, lr=1.56e-5, test_MAE=0.655, time=49.4, train_MAE=0.564, train_loss=0.595, val_MAE=0.624, val_loss=0.655]Epoch 62:   6%|▋         | 63/1000 [51:40<12:54:03, 49.57s/it, lr=1.56e-5, test_MAE=0.655, time=49.4, train_MAE=0.564, train_loss=0.595, val_MAE=0.624, val_loss=0.655]Epoch 63:   6%|▋         | 63/1000 [51:40<12:54:03, 49.57s/it, lr=1.56e-5, test_MAE=0.655, time=49.4, train_MAE=0.564, train_loss=0.595, val_MAE=0.624, val_loss=0.655]Epoch 63:   6%|▋         | 63/1000 [52:30<12:54:03, 49.57s/it, lr=1.56e-5, test_MAE=0.654, time=50, train_MAE=0.567, train_loss=0.598, val_MAE=0.624, val_loss=0.655]  Epoch 63:   6%|▋         | 64/1000 [52:30<12:55:31, 49.71s/it, lr=1.56e-5, test_MAE=0.654, time=50, train_MAE=0.567, train_loss=0.598, val_MAE=0.624, val_loss=0.655]Epoch 64:   6%|▋         | 64/1000 [52:30<12:55:31, 49.71s/it, lr=1.56e-5, test_MAE=0.654, time=50, train_MAE=0.567, train_loss=0.598, val_MAE=0.624, val_loss=0.655]Epoch 64:   6%|▋         | 64/1000 [53:19<12:55:31, 49.71s/it, lr=1.56e-5, test_MAE=0.657, time=49.7, train_MAE=0.561, train_loss=0.592, val_MAE=0.625, val_loss=0.656]Epoch 64:   6%|▋         | 65/1000 [53:19<12:54:38, 49.71s/it, lr=1.56e-5, test_MAE=0.657, time=49.7, train_MAE=0.561, train_loss=0.592, val_MAE=0.625, val_loss=0.656]Epoch 65:   6%|▋         | 65/1000 [53:19<12:54:38, 49.71s/it, lr=1.56e-5, test_MAE=0.657, time=49.7, train_MAE=0.561, train_loss=0.592, val_MAE=0.625, val_loss=0.656]Epoch 65:   6%|▋         | 65/1000 [54:09<12:54:38, 49.71s/it, lr=1.56e-5, test_MAE=0.659, time=49.9, train_MAE=0.564, train_loss=0.595, val_MAE=0.628, val_loss=0.659]Epoch 65:   7%|▋         | 66/1000 [54:09<12:54:37, 49.76s/it, lr=1.56e-5, test_MAE=0.659, time=49.9, train_MAE=0.564, train_loss=0.595, val_MAE=0.628, val_loss=0.659]Epoch 66:   7%|▋         | 66/1000 [54:09<12:54:37, 49.76s/it, lr=1.56e-5, test_MAE=0.659, time=49.9, train_MAE=0.564, train_loss=0.595, val_MAE=0.628, val_loss=0.659]Epoch 66:   7%|▋         | 66/1000 [54:59<12:54:37, 49.76s/it, lr=1.56e-5, test_MAE=0.657, time=50, train_MAE=0.566, train_loss=0.597, val_MAE=0.627, val_loss=0.658]  Epoch 66:   7%|▋         | 67/1000 [54:59<12:54:56, 49.84s/it, lr=1.56e-5, test_MAE=0.657, time=50, train_MAE=0.566, train_loss=0.597, val_MAE=0.627, val_loss=0.658]Epoch 67:   7%|▋         | 67/1000 [54:59<12:54:56, 49.84s/it, lr=1.56e-5, test_MAE=0.657, time=50, train_MAE=0.566, train_loss=0.597, val_MAE=0.627, val_loss=0.658]Epoch 67:   7%|▋         | 67/1000 [55:49<12:54:56, 49.84s/it, lr=1.56e-5, test_MAE=0.656, time=49.7, train_MAE=0.572, train_loss=0.603, val_MAE=0.627, val_loss=0.658]Epoch 67:   7%|▋         | 68/1000 [55:49<12:53:33, 49.80s/it, lr=1.56e-5, test_MAE=0.656, time=49.7, train_MAE=0.572, train_loss=0.603, val_MAE=0.627, val_loss=0.658]Epoch 68:   7%|▋         | 68/1000 [55:49<12:53:33, 49.80s/it, lr=1.56e-5, test_MAE=0.656, time=49.7, train_MAE=0.572, train_loss=0.603, val_MAE=0.627, val_loss=0.658]Epoch 68:   7%|▋         | 68/1000 [56:38<12:53:33, 49.80s/it, lr=1.56e-5, test_MAE=0.655, time=49.4, train_MAE=0.566, train_loss=0.597, val_MAE=0.626, val_loss=0.657]Epoch    69: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 68:   7%|▋         | 68/1000 [56:38<12:56:24, 49.98s/it, lr=1.56e-5, test_MAE=0.655, time=49.4, train_MAE=0.566, train_loss=0.597, val_MAE=0.626, val_loss=0.657]
Test MAE: 0.6552
Train MAE: 0.5595
Convergence Time (Epochs): 68.0000
TOTAL TIME TAKEN: 3433.3137s
AVG TIME PER EPOCH: 49.2490s
