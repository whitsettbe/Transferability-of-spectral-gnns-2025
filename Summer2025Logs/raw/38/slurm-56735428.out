I'm echoing to stdout
I'm echoing to stderr
My JobID is 56735428
I have 8 CPUs on node r108u25n01
Using backend: pytorch
cuda not available
[I] Loading dataset ZINC...
train, test, val sizes : 10000 1000 1000
[I] Finished loading.
[I] Data load time: 5.0255s
Dataset: ZINC,
Model: EigvalFilters

params={'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 5, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 48}

net_params={'L': 4, 'hidden_dim': 106, 'out_dim': 106, 'residual': True, 'readout': 'mean', 'k': 2, 'in_feat_dropout': 0.0, 'dropout': 0.0, 'graph_norm': True, 'batch_norm': True, 'self_loop': False, 'subtype': 'cheb02_vec', 'normalized_laplacian': False, 'post_normalized': True, 'eigval_norm': 'scale(0,2)_all', 'num_eigs': 64, 'bias_mode': '', 'eigval_hidden_dim': 5, 'eigval_num_hidden_layer': 3, 'l1_reg': 0.0, 'l2_reg': 0.0, 'gen_reg': 0.0, 'eigmod': 'import_csv', 'eigInFiles': {'train': 'supp_data/molecules/zinc_train_rec_full.csv', 'test': 'supp_data/molecules/zinc_test_rec_full.csv', 'val': 'supp_data/molecules/zinc_val_rec_full.csv'}, 'fixMissingPhi1': False, 'extraOrtho': True, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'biases': False, 'num_atom_type': 28, 'num_bond_type': 4, 'total_param': -1}


Total Parameters: -1


Training Graphs:  10000
Validation Graphs:  1000
Test Graphs:  1000
  0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1000 [03:27<?, ?it/s, lr=0.001, test_MAE=0.797, time=207, train_MAE=0.861, train_loss=0.861, val_MAE=0.743, val_loss=0.743]Epoch 0:   0%|          | 1/1000 [03:27<57:30:25, 207.23s/it, lr=0.001, test_MAE=0.797, time=207, train_MAE=0.861, train_loss=0.861, val_MAE=0.743, val_loss=0.743]Epoch 1:   0%|          | 1/1000 [03:27<57:30:25, 207.23s/it, lr=0.001, test_MAE=0.797, time=207, train_MAE=0.861, train_loss=0.861, val_MAE=0.743, val_loss=0.743]Epoch 1:   0%|          | 1/1000 [04:30<57:30:25, 207.23s/it, lr=0.001, test_MAE=0.762, time=63.4, train_MAE=0.71, train_loss=0.71, val_MAE=0.694, val_loss=0.694] Epoch 1:   0%|          | 2/1000 [04:30<45:29:20, 164.09s/it, lr=0.001, test_MAE=0.762, time=63.4, train_MAE=0.71, train_loss=0.71, val_MAE=0.694, val_loss=0.694]Epoch 2:   0%|          | 2/1000 [04:30<45:29:20, 164.09s/it, lr=0.001, test_MAE=0.762, time=63.4, train_MAE=0.71, train_loss=0.71, val_MAE=0.694, val_loss=0.694]Epoch 2:   0%|          | 2/1000 [05:33<45:29:20, 164.09s/it, lr=0.001, test_MAE=0.728, time=62.9, train_MAE=0.692, train_loss=0.692, val_MAE=0.666, val_loss=0.666]Epoch 2:   0%|          | 3/1000 [05:33<37:02:13, 133.73s/it, lr=0.001, test_MAE=0.728, time=62.9, train_MAE=0.692, train_loss=0.692, val_MAE=0.666, val_loss=0.666]Epoch 3:   0%|          | 3/1000 [05:33<37:02:13, 133.73s/it, lr=0.001, test_MAE=0.728, time=62.9, train_MAE=0.692, train_loss=0.692, val_MAE=0.666, val_loss=0.666]Epoch 3:   0%|          | 3/1000 [06:36<37:02:13, 133.73s/it, lr=0.001, test_MAE=0.725, time=62.5, train_MAE=0.682, train_loss=0.682, val_MAE=0.684, val_loss=0.684]Epoch 3:   0%|          | 4/1000 [06:36<31:05:12, 112.36s/it, lr=0.001, test_MAE=0.725, time=62.5, train_MAE=0.682, train_loss=0.682, val_MAE=0.684, val_loss=0.684]Epoch 4:   0%|          | 4/1000 [06:36<31:05:12, 112.36s/it, lr=0.001, test_MAE=0.725, time=62.5, train_MAE=0.682, train_loss=0.682, val_MAE=0.684, val_loss=0.684]Epoch 4:   0%|          | 4/1000 [07:38<31:05:12, 112.36s/it, lr=0.001, test_MAE=0.832, time=62.5, train_MAE=0.664, train_loss=0.664, val_MAE=0.757, val_loss=0.757]Epoch 4:   0%|          | 5/1000 [07:38<26:55:12, 97.40s/it, lr=0.001, test_MAE=0.832, time=62.5, train_MAE=0.664, train_loss=0.664, val_MAE=0.757, val_loss=0.757] Epoch 5:   0%|          | 5/1000 [07:38<26:55:12, 97.40s/it, lr=0.001, test_MAE=0.832, time=62.5, train_MAE=0.664, train_loss=0.664, val_MAE=0.757, val_loss=0.757]Epoch 5:   0%|          | 5/1000 [08:40<26:55:12, 97.40s/it, lr=0.001, test_MAE=0.707, time=62.3, train_MAE=0.659, train_loss=0.659, val_MAE=0.651, val_loss=0.651]Epoch 5:   1%|          | 6/1000 [08:40<23:59:20, 86.88s/it, lr=0.001, test_MAE=0.707, time=62.3, train_MAE=0.659, train_loss=0.659, val_MAE=0.651, val_loss=0.651]Epoch 6:   1%|          | 6/1000 [08:40<23:59:20, 86.88s/it, lr=0.001, test_MAE=0.707, time=62.3, train_MAE=0.659, train_loss=0.659, val_MAE=0.651, val_loss=0.651]Epoch 6:   1%|          | 6/1000 [09:43<23:59:20, 86.88s/it, lr=0.001, test_MAE=0.708, time=62.6, train_MAE=0.652, train_loss=0.652, val_MAE=0.658, val_loss=0.658]Epoch 6:   1%|          | 7/1000 [09:43<21:57:28, 79.61s/it, lr=0.001, test_MAE=0.708, time=62.6, train_MAE=0.652, train_loss=0.652, val_MAE=0.658, val_loss=0.658]Epoch 7:   1%|          | 7/1000 [09:43<21:57:28, 79.61s/it, lr=0.001, test_MAE=0.708, time=62.6, train_MAE=0.652, train_loss=0.652, val_MAE=0.658, val_loss=0.658]Epoch 7:   1%|          | 7/1000 [10:45<21:57:28, 79.61s/it, lr=0.001, test_MAE=0.761, time=62.3, train_MAE=0.636, train_loss=0.636, val_MAE=0.729, val_loss=0.729]Epoch 7:   1%|          | 8/1000 [10:45<20:30:26, 74.42s/it, lr=0.001, test_MAE=0.761, time=62.3, train_MAE=0.636, train_loss=0.636, val_MAE=0.729, val_loss=0.729]Epoch 8:   1%|          | 8/1000 [10:45<20:30:26, 74.42s/it, lr=0.001, test_MAE=0.761, time=62.3, train_MAE=0.636, train_loss=0.636, val_MAE=0.729, val_loss=0.729]Epoch 8:   1%|          | 8/1000 [11:48<20:30:26, 74.42s/it, lr=0.001, test_MAE=0.735, time=62.3, train_MAE=0.637, train_loss=0.637, val_MAE=0.701, val_loss=0.701]Epoch 8:   1%|          | 9/1000 [11:48<19:29:06, 70.78s/it, lr=0.001, test_MAE=0.735, time=62.3, train_MAE=0.637, train_loss=0.637, val_MAE=0.701, val_loss=0.701]Epoch 9:   1%|          | 9/1000 [11:48<19:29:06, 70.78s/it, lr=0.001, test_MAE=0.735, time=62.3, train_MAE=0.637, train_loss=0.637, val_MAE=0.701, val_loss=0.701]Epoch 9:   1%|          | 9/1000 [12:50<19:29:06, 70.78s/it, lr=0.001, test_MAE=0.706, time=62.6, train_MAE=0.627, train_loss=0.627, val_MAE=0.641, val_loss=0.641]Epoch 9:   1%|          | 10/1000 [12:50<18:47:40, 68.34s/it, lr=0.001, test_MAE=0.706, time=62.6, train_MAE=0.627, train_loss=0.627, val_MAE=0.641, val_loss=0.641]Epoch 10:   1%|          | 10/1000 [12:50<18:47:40, 68.34s/it, lr=0.001, test_MAE=0.706, time=62.6, train_MAE=0.627, train_loss=0.627, val_MAE=0.641, val_loss=0.641]Epoch 10:   1%|          | 10/1000 [13:52<18:47:40, 68.34s/it, lr=0.001, test_MAE=0.802, time=62.2, train_MAE=0.62, train_loss=0.62, val_MAE=0.729, val_loss=0.729]  Epoch 10:   1%|          | 11/1000 [13:52<18:16:09, 66.50s/it, lr=0.001, test_MAE=0.802, time=62.2, train_MAE=0.62, train_loss=0.62, val_MAE=0.729, val_loss=0.729]Epoch 11:   1%|          | 11/1000 [13:52<18:16:09, 66.50s/it, lr=0.001, test_MAE=0.802, time=62.2, train_MAE=0.62, train_loss=0.62, val_MAE=0.729, val_loss=0.729]Epoch 11:   1%|          | 11/1000 [14:54<18:16:09, 66.50s/it, lr=0.001, test_MAE=0.742, time=61.9, train_MAE=0.622, train_loss=0.622, val_MAE=0.665, val_loss=0.665]Epoch 11:   1%|          | 12/1000 [14:54<17:52:30, 65.13s/it, lr=0.001, test_MAE=0.742, time=61.9, train_MAE=0.622, train_loss=0.622, val_MAE=0.665, val_loss=0.665]Epoch 12:   1%|          | 12/1000 [14:54<17:52:30, 65.13s/it, lr=0.001, test_MAE=0.742, time=61.9, train_MAE=0.622, train_loss=0.622, val_MAE=0.665, val_loss=0.665]Epoch 12:   1%|          | 12/1000 [15:57<17:52:30, 65.13s/it, lr=0.001, test_MAE=0.776, time=62.7, train_MAE=0.621, train_loss=0.621, val_MAE=0.742, val_loss=0.742]Epoch 12:   1%|▏         | 13/1000 [15:57<17:39:35, 64.41s/it, lr=0.001, test_MAE=0.776, time=62.7, train_MAE=0.621, train_loss=0.621, val_MAE=0.742, val_loss=0.742]Epoch 13:   1%|▏         | 13/1000 [15:57<17:39:35, 64.41s/it, lr=0.001, test_MAE=0.776, time=62.7, train_MAE=0.621, train_loss=0.621, val_MAE=0.742, val_loss=0.742]Epoch 13:   1%|▏         | 13/1000 [16:59<17:39:35, 64.41s/it, lr=0.001, test_MAE=0.694, time=62.3, train_MAE=0.619, train_loss=0.619, val_MAE=0.647, val_loss=0.647]Epoch 13:   1%|▏         | 14/1000 [16:59<17:28:10, 63.78s/it, lr=0.001, test_MAE=0.694, time=62.3, train_MAE=0.619, train_loss=0.619, val_MAE=0.647, val_loss=0.647]Epoch 14:   1%|▏         | 14/1000 [16:59<17:28:10, 63.78s/it, lr=0.001, test_MAE=0.694, time=62.3, train_MAE=0.619, train_loss=0.619, val_MAE=0.647, val_loss=0.647]Epoch 14:   1%|▏         | 14/1000 [18:01<17:28:10, 63.78s/it, lr=0.001, test_MAE=0.672, time=61.9, train_MAE=0.61, train_loss=0.61, val_MAE=0.618, val_loss=0.618]  Epoch 14:   2%|▏         | 15/1000 [18:01<17:18:06, 63.24s/it, lr=0.001, test_MAE=0.672, time=61.9, train_MAE=0.61, train_loss=0.61, val_MAE=0.618, val_loss=0.618]Epoch 15:   2%|▏         | 15/1000 [18:01<17:18:06, 63.24s/it, lr=0.001, test_MAE=0.672, time=61.9, train_MAE=0.61, train_loss=0.61, val_MAE=0.618, val_loss=0.618]Epoch 15:   2%|▏         | 15/1000 [19:04<17:18:06, 63.24s/it, lr=0.001, test_MAE=0.712, time=62.6, train_MAE=0.611, train_loss=0.611, val_MAE=0.675, val_loss=0.675]Epoch 15:   2%|▏         | 16/1000 [19:04<17:14:15, 63.06s/it, lr=0.001, test_MAE=0.712, time=62.6, train_MAE=0.611, train_loss=0.611, val_MAE=0.675, val_loss=0.675]Epoch 16:   2%|▏         | 16/1000 [19:04<17:14:15, 63.06s/it, lr=0.001, test_MAE=0.712, time=62.6, train_MAE=0.611, train_loss=0.611, val_MAE=0.675, val_loss=0.675]Epoch 16:   2%|▏         | 16/1000 [20:06<17:14:15, 63.06s/it, lr=0.001, test_MAE=0.679, time=62.3, train_MAE=0.603, train_loss=0.603, val_MAE=0.636, val_loss=0.636]Epoch 16:   2%|▏         | 17/1000 [20:06<17:09:47, 62.86s/it, lr=0.001, test_MAE=0.679, time=62.3, train_MAE=0.603, train_loss=0.603, val_MAE=0.636, val_loss=0.636]Epoch 17:   2%|▏         | 17/1000 [20:06<17:09:47, 62.86s/it, lr=0.001, test_MAE=0.679, time=62.3, train_MAE=0.603, train_loss=0.603, val_MAE=0.636, val_loss=0.636]Epoch 17:   2%|▏         | 17/1000 [21:08<17:09:47, 62.86s/it, lr=0.001, test_MAE=0.687, time=61.8, train_MAE=0.6, train_loss=0.6, val_MAE=0.633, val_loss=0.633]    Epoch 17:   2%|▏         | 18/1000 [21:08<17:03:37, 62.54s/it, lr=0.001, test_MAE=0.687, time=61.8, train_MAE=0.6, train_loss=0.6, val_MAE=0.633, val_loss=0.633]Epoch 18:   2%|▏         | 18/1000 [21:08<17:03:37, 62.54s/it, lr=0.001, test_MAE=0.687, time=61.8, train_MAE=0.6, train_loss=0.6, val_MAE=0.633, val_loss=0.633]Epoch 18:   2%|▏         | 18/1000 [22:11<17:03:37, 62.54s/it, lr=0.001, test_MAE=0.682, time=62.5, train_MAE=0.595, train_loss=0.595, val_MAE=0.628, val_loss=0.628]Epoch 18:   2%|▏         | 19/1000 [22:11<17:02:29, 62.54s/it, lr=0.001, test_MAE=0.682, time=62.5, train_MAE=0.595, train_loss=0.595, val_MAE=0.628, val_loss=0.628]Epoch 19:   2%|▏         | 19/1000 [22:11<17:02:29, 62.54s/it, lr=0.001, test_MAE=0.682, time=62.5, train_MAE=0.595, train_loss=0.595, val_MAE=0.628, val_loss=0.628]Epoch 19:   2%|▏         | 19/1000 [23:13<17:02:29, 62.54s/it, lr=0.001, test_MAE=0.723, time=62.1, train_MAE=0.591, train_loss=0.591, val_MAE=0.666, val_loss=0.666]Epoch 19:   2%|▏         | 20/1000 [23:13<16:59:09, 62.40s/it, lr=0.001, test_MAE=0.723, time=62.1, train_MAE=0.591, train_loss=0.591, val_MAE=0.666, val_loss=0.666]Epoch 20:   2%|▏         | 20/1000 [23:13<16:59:09, 62.40s/it, lr=0.001, test_MAE=0.723, time=62.1, train_MAE=0.591, train_loss=0.591, val_MAE=0.666, val_loss=0.666]Epoch 20:   2%|▏         | 20/1000 [24:15<16:59:09, 62.40s/it, lr=0.001, test_MAE=0.681, time=62.3, train_MAE=0.587, train_loss=0.587, val_MAE=0.652, val_loss=0.652]Epoch    21: reducing learning rate of group 0 to 5.0000e-04.
Epoch 20:   2%|▏         | 21/1000 [24:15<16:57:45, 62.38s/it, lr=0.001, test_MAE=0.681, time=62.3, train_MAE=0.587, train_loss=0.587, val_MAE=0.652, val_loss=0.652]Epoch 21:   2%|▏         | 21/1000 [24:15<16:57:45, 62.38s/it, lr=0.001, test_MAE=0.681, time=62.3, train_MAE=0.587, train_loss=0.587, val_MAE=0.652, val_loss=0.652]Epoch 21:   2%|▏         | 21/1000 [25:18<16:57:45, 62.38s/it, lr=0.0005, test_MAE=0.642, time=62.7, train_MAE=0.573, train_loss=0.573, val_MAE=0.608, val_loss=0.608]Epoch 21:   2%|▏         | 22/1000 [25:18<16:58:27, 62.48s/it, lr=0.0005, test_MAE=0.642, time=62.7, train_MAE=0.573, train_loss=0.573, val_MAE=0.608, val_loss=0.608]Epoch 22:   2%|▏         | 22/1000 [25:18<16:58:27, 62.48s/it, lr=0.0005, test_MAE=0.642, time=62.7, train_MAE=0.573, train_loss=0.573, val_MAE=0.608, val_loss=0.608]Epoch 22:   2%|▏         | 22/1000 [26:20<16:58:27, 62.48s/it, lr=0.0005, test_MAE=0.695, time=62, train_MAE=0.57, train_loss=0.57, val_MAE=0.634, val_loss=0.634]    Epoch 22:   2%|▏         | 23/1000 [26:20<16:54:58, 62.33s/it, lr=0.0005, test_MAE=0.695, time=62, train_MAE=0.57, train_loss=0.57, val_MAE=0.634, val_loss=0.634]Epoch 23:   2%|▏         | 23/1000 [26:20<16:54:58, 62.33s/it, lr=0.0005, test_MAE=0.695, time=62, train_MAE=0.57, train_loss=0.57, val_MAE=0.634, val_loss=0.634]Epoch 23:   2%|▏         | 23/1000 [27:23<16:54:58, 62.33s/it, lr=0.0005, test_MAE=0.677, time=62.7, train_MAE=0.567, train_loss=0.567, val_MAE=0.621, val_loss=0.621]Epoch 23:   2%|▏         | 24/1000 [27:23<16:55:59, 62.46s/it, lr=0.0005, test_MAE=0.677, time=62.7, train_MAE=0.567, train_loss=0.567, val_MAE=0.621, val_loss=0.621]Epoch 24:   2%|▏         | 24/1000 [27:23<16:55:59, 62.46s/it, lr=0.0005, test_MAE=0.677, time=62.7, train_MAE=0.567, train_loss=0.567, val_MAE=0.621, val_loss=0.621]Epoch 24:   2%|▏         | 24/1000 [28:25<16:55:59, 62.46s/it, lr=0.0005, test_MAE=0.666, time=62.4, train_MAE=0.564, train_loss=0.564, val_MAE=0.624, val_loss=0.624]Epoch 24:   2%|▎         | 25/1000 [28:25<16:54:40, 62.44s/it, lr=0.0005, test_MAE=0.666, time=62.4, train_MAE=0.564, train_loss=0.564, val_MAE=0.624, val_loss=0.624]Epoch 25:   2%|▎         | 25/1000 [28:25<16:54:40, 62.44s/it, lr=0.0005, test_MAE=0.666, time=62.4, train_MAE=0.564, train_loss=0.564, val_MAE=0.624, val_loss=0.624]Epoch 25:   2%|▎         | 25/1000 [29:27<16:54:40, 62.44s/it, lr=0.0005, test_MAE=0.649, time=62.2, train_MAE=0.561, train_loss=0.561, val_MAE=0.602, val_loss=0.602]Epoch 25:   3%|▎         | 26/1000 [29:27<16:52:24, 62.37s/it, lr=0.0005, test_MAE=0.649, time=62.2, train_MAE=0.561, train_loss=0.561, val_MAE=0.602, val_loss=0.602]Epoch 26:   3%|▎         | 26/1000 [29:27<16:52:24, 62.37s/it, lr=0.0005, test_MAE=0.649, time=62.2, train_MAE=0.561, train_loss=0.561, val_MAE=0.602, val_loss=0.602]Epoch 26:   3%|▎         | 26/1000 [30:30<16:52:24, 62.37s/it, lr=0.0005, test_MAE=0.669, time=62.6, train_MAE=0.563, train_loss=0.563, val_MAE=0.635, val_loss=0.635]Epoch 26:   3%|▎         | 27/1000 [30:30<16:52:29, 62.43s/it, lr=0.0005, test_MAE=0.669, time=62.6, train_MAE=0.563, train_loss=0.563, val_MAE=0.635, val_loss=0.635]Epoch 27:   3%|▎         | 27/1000 [30:30<16:52:29, 62.43s/it, lr=0.0005, test_MAE=0.669, time=62.6, train_MAE=0.563, train_loss=0.563, val_MAE=0.635, val_loss=0.635]Epoch 27:   3%|▎         | 27/1000 [31:32<16:52:29, 62.43s/it, lr=0.0005, test_MAE=0.727, time=62.3, train_MAE=0.554, train_loss=0.554, val_MAE=0.654, val_loss=0.654]Epoch 27:   3%|▎         | 28/1000 [31:32<16:51:00, 62.41s/it, lr=0.0005, test_MAE=0.727, time=62.3, train_MAE=0.554, train_loss=0.554, val_MAE=0.654, val_loss=0.654]Epoch 28:   3%|▎         | 28/1000 [31:32<16:51:00, 62.41s/it, lr=0.0005, test_MAE=0.727, time=62.3, train_MAE=0.554, train_loss=0.554, val_MAE=0.654, val_loss=0.654]Epoch 28:   3%|▎         | 28/1000 [32:34<16:51:00, 62.41s/it, lr=0.0005, test_MAE=0.66, time=61.9, train_MAE=0.56, train_loss=0.56, val_MAE=0.633, val_loss=0.633]   Epoch 28:   3%|▎         | 29/1000 [32:34<16:47:43, 62.27s/it, lr=0.0005, test_MAE=0.66, time=61.9, train_MAE=0.56, train_loss=0.56, val_MAE=0.633, val_loss=0.633]Epoch 29:   3%|▎         | 29/1000 [32:34<16:47:43, 62.27s/it, lr=0.0005, test_MAE=0.66, time=61.9, train_MAE=0.56, train_loss=0.56, val_MAE=0.633, val_loss=0.633]Epoch 29:   3%|▎         | 29/1000 [33:37<16:47:43, 62.27s/it, lr=0.0005, test_MAE=0.72, time=62.9, train_MAE=0.562, train_loss=0.562, val_MAE=0.659, val_loss=0.659]Epoch 29:   3%|▎         | 30/1000 [33:37<16:49:57, 62.47s/it, lr=0.0005, test_MAE=0.72, time=62.9, train_MAE=0.562, train_loss=0.562, val_MAE=0.659, val_loss=0.659]Epoch 30:   3%|▎         | 30/1000 [33:37<16:49:57, 62.47s/it, lr=0.0005, test_MAE=0.72, time=62.9, train_MAE=0.562, train_loss=0.562, val_MAE=0.659, val_loss=0.659]Epoch 30:   3%|▎         | 30/1000 [34:39<16:49:57, 62.47s/it, lr=0.0005, test_MAE=0.828, time=62.3, train_MAE=0.562, train_loss=0.562, val_MAE=0.775, val_loss=0.775]Epoch 30:   3%|▎         | 31/1000 [34:39<16:47:55, 62.41s/it, lr=0.0005, test_MAE=0.828, time=62.3, train_MAE=0.562, train_loss=0.562, val_MAE=0.775, val_loss=0.775]Epoch 31:   3%|▎         | 31/1000 [34:39<16:47:55, 62.41s/it, lr=0.0005, test_MAE=0.828, time=62.3, train_MAE=0.562, train_loss=0.562, val_MAE=0.775, val_loss=0.775]Epoch 31:   3%|▎         | 31/1000 [35:41<16:47:55, 62.41s/it, lr=0.0005, test_MAE=0.66, time=61.8, train_MAE=0.552, train_loss=0.552, val_MAE=0.605, val_loss=0.605] Epoch    32: reducing learning rate of group 0 to 2.5000e-04.
Epoch 31:   3%|▎         | 32/1000 [35:41<16:43:58, 62.23s/it, lr=0.0005, test_MAE=0.66, time=61.8, train_MAE=0.552, train_loss=0.552, val_MAE=0.605, val_loss=0.605]Epoch 32:   3%|▎         | 32/1000 [35:41<16:43:58, 62.23s/it, lr=0.0005, test_MAE=0.66, time=61.8, train_MAE=0.552, train_loss=0.552, val_MAE=0.605, val_loss=0.605]Epoch 32:   3%|▎         | 32/1000 [36:44<16:43:58, 62.23s/it, lr=0.00025, test_MAE=0.668, time=62.4, train_MAE=0.533, train_loss=0.533, val_MAE=0.62, val_loss=0.62]Epoch 32:   3%|▎         | 33/1000 [36:44<16:43:41, 62.28s/it, lr=0.00025, test_MAE=0.668, time=62.4, train_MAE=0.533, train_loss=0.533, val_MAE=0.62, val_loss=0.62]Epoch 33:   3%|▎         | 33/1000 [36:44<16:43:41, 62.28s/it, lr=0.00025, test_MAE=0.668, time=62.4, train_MAE=0.533, train_loss=0.533, val_MAE=0.62, val_loss=0.62]Epoch 33:   3%|▎         | 33/1000 [37:46<16:43:41, 62.28s/it, lr=0.00025, test_MAE=0.676, time=62.1, train_MAE=0.524, train_loss=0.524, val_MAE=0.63, val_loss=0.63]Epoch 33:   3%|▎         | 34/1000 [37:46<16:41:51, 62.23s/it, lr=0.00025, test_MAE=0.676, time=62.1, train_MAE=0.524, train_loss=0.524, val_MAE=0.63, val_loss=0.63]Epoch 34:   3%|▎         | 34/1000 [37:46<16:41:51, 62.23s/it, lr=0.00025, test_MAE=0.676, time=62.1, train_MAE=0.524, train_loss=0.524, val_MAE=0.63, val_loss=0.63]Epoch 34:   3%|▎         | 34/1000 [38:47<16:41:51, 62.23s/it, lr=0.00025, test_MAE=0.657, time=61.7, train_MAE=0.526, train_loss=0.526, val_MAE=0.607, val_loss=0.607]Epoch 34:   4%|▎         | 35/1000 [38:47<16:38:31, 62.08s/it, lr=0.00025, test_MAE=0.657, time=61.7, train_MAE=0.526, train_loss=0.526, val_MAE=0.607, val_loss=0.607]Epoch 35:   4%|▎         | 35/1000 [38:47<16:38:31, 62.08s/it, lr=0.00025, test_MAE=0.657, time=61.7, train_MAE=0.526, train_loss=0.526, val_MAE=0.607, val_loss=0.607]Epoch 35:   4%|▎         | 35/1000 [39:50<16:38:31, 62.08s/it, lr=0.00025, test_MAE=0.683, time=62.4, train_MAE=0.524, train_loss=0.524, val_MAE=0.63, val_loss=0.63]  Epoch 35:   4%|▎         | 36/1000 [39:50<16:39:06, 62.18s/it, lr=0.00025, test_MAE=0.683, time=62.4, train_MAE=0.524, train_loss=0.524, val_MAE=0.63, val_loss=0.63]Epoch 36:   4%|▎         | 36/1000 [39:50<16:39:06, 62.18s/it, lr=0.00025, test_MAE=0.683, time=62.4, train_MAE=0.524, train_loss=0.524, val_MAE=0.63, val_loss=0.63]Epoch 36:   4%|▎         | 36/1000 [40:52<16:39:06, 62.18s/it, lr=0.00025, test_MAE=0.648, time=62.1, train_MAE=0.533, train_loss=0.533, val_MAE=0.604, val_loss=0.604]Epoch 36:   4%|▎         | 37/1000 [40:52<16:37:47, 62.17s/it, lr=0.00025, test_MAE=0.648, time=62.1, train_MAE=0.533, train_loss=0.533, val_MAE=0.604, val_loss=0.604]Epoch 37:   4%|▎         | 37/1000 [40:52<16:37:47, 62.17s/it, lr=0.00025, test_MAE=0.648, time=62.1, train_MAE=0.533, train_loss=0.533, val_MAE=0.604, val_loss=0.604]Epoch 37:   4%|▎         | 37/1000 [41:54<16:37:47, 62.17s/it, lr=0.00025, test_MAE=0.642, time=61.9, train_MAE=0.52, train_loss=0.52, val_MAE=0.607, val_loss=0.607]  Epoch    38: reducing learning rate of group 0 to 1.2500e-04.
Epoch 37:   4%|▍         | 38/1000 [41:54<16:35:42, 62.10s/it, lr=0.00025, test_MAE=0.642, time=61.9, train_MAE=0.52, train_loss=0.52, val_MAE=0.607, val_loss=0.607]Epoch 38:   4%|▍         | 38/1000 [41:54<16:35:42, 62.10s/it, lr=0.00025, test_MAE=0.642, time=61.9, train_MAE=0.52, train_loss=0.52, val_MAE=0.607, val_loss=0.607]Epoch 38:   4%|▍         | 38/1000 [42:57<16:35:42, 62.10s/it, lr=0.000125, test_MAE=0.702, time=62.7, train_MAE=0.51, train_loss=0.51, val_MAE=0.653, val_loss=0.653]Epoch 38:   4%|▍         | 39/1000 [42:57<16:37:20, 62.27s/it, lr=0.000125, test_MAE=0.702, time=62.7, train_MAE=0.51, train_loss=0.51, val_MAE=0.653, val_loss=0.653]Epoch 39:   4%|▍         | 39/1000 [42:57<16:37:20, 62.27s/it, lr=0.000125, test_MAE=0.702, time=62.7, train_MAE=0.51, train_loss=0.51, val_MAE=0.653, val_loss=0.653]Epoch 39:   4%|▍         | 39/1000 [43:59<16:37:20, 62.27s/it, lr=0.000125, test_MAE=0.654, time=62.3, train_MAE=0.513, train_loss=0.513, val_MAE=0.613, val_loss=0.613]Epoch 39:   4%|▍         | 40/1000 [43:59<16:36:38, 62.29s/it, lr=0.000125, test_MAE=0.654, time=62.3, train_MAE=0.513, train_loss=0.513, val_MAE=0.613, val_loss=0.613]Epoch 40:   4%|▍         | 40/1000 [43:59<16:36:38, 62.29s/it, lr=0.000125, test_MAE=0.654, time=62.3, train_MAE=0.513, train_loss=0.513, val_MAE=0.613, val_loss=0.613]Epoch 40:   4%|▍         | 40/1000 [45:01<16:36:38, 62.29s/it, lr=0.000125, test_MAE=0.641, time=62.4, train_MAE=0.518, train_loss=0.518, val_MAE=0.607, val_loss=0.607]Epoch 40:   4%|▍         | 41/1000 [45:01<16:36:01, 62.32s/it, lr=0.000125, test_MAE=0.641, time=62.4, train_MAE=0.518, train_loss=0.518, val_MAE=0.607, val_loss=0.607]Epoch 41:   4%|▍         | 41/1000 [45:01<16:36:01, 62.32s/it, lr=0.000125, test_MAE=0.641, time=62.4, train_MAE=0.518, train_loss=0.518, val_MAE=0.607, val_loss=0.607]Epoch 41:   4%|▍         | 41/1000 [46:04<16:36:01, 62.32s/it, lr=0.000125, test_MAE=0.653, time=63, train_MAE=0.502, train_loss=0.502, val_MAE=0.605, val_loss=0.605]  Epoch 41:   4%|▍         | 42/1000 [46:04<16:38:20, 62.53s/it, lr=0.000125, test_MAE=0.653, time=63, train_MAE=0.502, train_loss=0.502, val_MAE=0.605, val_loss=0.605]Epoch 42:   4%|▍         | 42/1000 [46:04<16:38:20, 62.53s/it, lr=0.000125, test_MAE=0.653, time=63, train_MAE=0.502, train_loss=0.502, val_MAE=0.605, val_loss=0.605]Epoch 42:   4%|▍         | 42/1000 [47:07<16:38:20, 62.53s/it, lr=0.000125, test_MAE=0.644, time=62.4, train_MAE=0.5, train_loss=0.5, val_MAE=0.601, val_loss=0.601]  Epoch 42:   4%|▍         | 43/1000 [47:07<16:36:50, 62.50s/it, lr=0.000125, test_MAE=0.644, time=62.4, train_MAE=0.5, train_loss=0.5, val_MAE=0.601, val_loss=0.601]Epoch 43:   4%|▍         | 43/1000 [47:07<16:36:50, 62.50s/it, lr=0.000125, test_MAE=0.644, time=62.4, train_MAE=0.5, train_loss=0.5, val_MAE=0.601, val_loss=0.601]Epoch 43:   4%|▍         | 43/1000 [48:10<16:36:50, 62.50s/it, lr=0.000125, test_MAE=0.673, time=62.9, train_MAE=0.499, train_loss=0.499, val_MAE=0.621, val_loss=0.621]Epoch 43:   4%|▍         | 44/1000 [48:10<16:37:44, 62.62s/it, lr=0.000125, test_MAE=0.673, time=62.9, train_MAE=0.499, train_loss=0.499, val_MAE=0.621, val_loss=0.621]Epoch 44:   4%|▍         | 44/1000 [48:10<16:37:44, 62.62s/it, lr=0.000125, test_MAE=0.673, time=62.9, train_MAE=0.499, train_loss=0.499, val_MAE=0.621, val_loss=0.621]Epoch 44:   4%|▍         | 44/1000 [49:13<16:37:44, 62.62s/it, lr=0.000125, test_MAE=0.645, time=63.1, train_MAE=0.498, train_loss=0.498, val_MAE=0.608, val_loss=0.608]Epoch 44:   4%|▍         | 45/1000 [49:13<16:39:05, 62.77s/it, lr=0.000125, test_MAE=0.645, time=63.1, train_MAE=0.498, train_loss=0.498, val_MAE=0.608, val_loss=0.608]Epoch 45:   4%|▍         | 45/1000 [49:13<16:39:05, 62.77s/it, lr=0.000125, test_MAE=0.645, time=63.1, train_MAE=0.498, train_loss=0.498, val_MAE=0.608, val_loss=0.608]Epoch 45:   4%|▍         | 45/1000 [50:15<16:39:05, 62.77s/it, lr=0.000125, test_MAE=0.644, time=62.7, train_MAE=0.496, train_loss=0.496, val_MAE=0.605, val_loss=0.605]Epoch 45:   5%|▍         | 46/1000 [50:15<16:37:39, 62.75s/it, lr=0.000125, test_MAE=0.644, time=62.7, train_MAE=0.496, train_loss=0.496, val_MAE=0.605, val_loss=0.605]Epoch 46:   5%|▍         | 46/1000 [50:15<16:37:39, 62.75s/it, lr=0.000125, test_MAE=0.644, time=62.7, train_MAE=0.496, train_loss=0.496, val_MAE=0.605, val_loss=0.605]Epoch 46:   5%|▍         | 46/1000 [51:18<16:37:39, 62.75s/it, lr=0.000125, test_MAE=0.672, time=62.6, train_MAE=0.495, train_loss=0.495, val_MAE=0.615, val_loss=0.615]Epoch 46:   5%|▍         | 47/1000 [51:18<16:36:00, 62.71s/it, lr=0.000125, test_MAE=0.672, time=62.6, train_MAE=0.495, train_loss=0.495, val_MAE=0.615, val_loss=0.615]Epoch 47:   5%|▍         | 47/1000 [51:18<16:36:00, 62.71s/it, lr=0.000125, test_MAE=0.672, time=62.6, train_MAE=0.495, train_loss=0.495, val_MAE=0.615, val_loss=0.615]Epoch 47:   5%|▍         | 47/1000 [52:20<16:36:00, 62.71s/it, lr=0.000125, test_MAE=0.648, time=62.4, train_MAE=0.496, train_loss=0.496, val_MAE=0.612, val_loss=0.612]Epoch 47:   5%|▍         | 48/1000 [52:21<16:33:41, 62.63s/it, lr=0.000125, test_MAE=0.648, time=62.4, train_MAE=0.496, train_loss=0.496, val_MAE=0.612, val_loss=0.612]Epoch 48:   5%|▍         | 48/1000 [52:21<16:33:41, 62.63s/it, lr=0.000125, test_MAE=0.648, time=62.4, train_MAE=0.496, train_loss=0.496, val_MAE=0.612, val_loss=0.612]Epoch 48:   5%|▍         | 48/1000 [53:23<16:33:41, 62.63s/it, lr=0.000125, test_MAE=0.644, time=62.4, train_MAE=0.493, train_loss=0.493, val_MAE=0.604, val_loss=0.604]Epoch    49: reducing learning rate of group 0 to 6.2500e-05.
Epoch 48:   5%|▍         | 49/1000 [53:23<16:31:49, 62.58s/it, lr=0.000125, test_MAE=0.644, time=62.4, train_MAE=0.493, train_loss=0.493, val_MAE=0.604, val_loss=0.604]Epoch 49:   5%|▍         | 49/1000 [53:23<16:31:49, 62.58s/it, lr=0.000125, test_MAE=0.644, time=62.4, train_MAE=0.493, train_loss=0.493, val_MAE=0.604, val_loss=0.604]Epoch 49:   5%|▍         | 49/1000 [54:26<16:31:49, 62.58s/it, lr=6.25e-5, test_MAE=0.648, time=63.4, train_MAE=0.485, train_loss=0.485, val_MAE=0.608, val_loss=0.608] Epoch 49:   5%|▌         | 50/1000 [54:26<16:34:53, 62.83s/it, lr=6.25e-5, test_MAE=0.648, time=63.4, train_MAE=0.485, train_loss=0.485, val_MAE=0.608, val_loss=0.608]Epoch 50:   5%|▌         | 50/1000 [54:26<16:34:53, 62.83s/it, lr=6.25e-5, test_MAE=0.648, time=63.4, train_MAE=0.485, train_loss=0.485, val_MAE=0.608, val_loss=0.608]Epoch 50:   5%|▌         | 50/1000 [55:29<16:34:53, 62.83s/it, lr=6.25e-5, test_MAE=0.647, time=62.9, train_MAE=0.482, train_loss=0.482, val_MAE=0.607, val_loss=0.607]Epoch 50:   5%|▌         | 51/1000 [55:29<16:34:01, 62.85s/it, lr=6.25e-5, test_MAE=0.647, time=62.9, train_MAE=0.482, train_loss=0.482, val_MAE=0.607, val_loss=0.607]Epoch 51:   5%|▌         | 51/1000 [55:29<16:34:01, 62.85s/it, lr=6.25e-5, test_MAE=0.647, time=62.9, train_MAE=0.482, train_loss=0.482, val_MAE=0.607, val_loss=0.607]Epoch 51:   5%|▌         | 51/1000 [56:32<16:34:01, 62.85s/it, lr=6.25e-5, test_MAE=0.652, time=63.1, train_MAE=0.485, train_loss=0.485, val_MAE=0.606, val_loss=0.606]Epoch 51:   5%|▌         | 52/1000 [56:32<16:34:24, 62.94s/it, lr=6.25e-5, test_MAE=0.652, time=63.1, train_MAE=0.485, train_loss=0.485, val_MAE=0.606, val_loss=0.606]Epoch 52:   5%|▌         | 52/1000 [56:32<16:34:24, 62.94s/it, lr=6.25e-5, test_MAE=0.652, time=63.1, train_MAE=0.485, train_loss=0.485, val_MAE=0.606, val_loss=0.606]Epoch 52:   5%|▌         | 52/1000 [57:36<16:34:24, 62.94s/it, lr=6.25e-5, test_MAE=0.664, time=63.9, train_MAE=0.482, train_loss=0.482, val_MAE=0.615, val_loss=0.615]Epoch 52:   5%|▌         | 53/1000 [57:36<16:37:48, 63.22s/it, lr=6.25e-5, test_MAE=0.664, time=63.9, train_MAE=0.482, train_loss=0.482, val_MAE=0.615, val_loss=0.615]Epoch 53:   5%|▌         | 53/1000 [57:36<16:37:48, 63.22s/it, lr=6.25e-5, test_MAE=0.664, time=63.9, train_MAE=0.482, train_loss=0.482, val_MAE=0.615, val_loss=0.615]Epoch 53:   5%|▌         | 53/1000 [58:40<16:37:48, 63.22s/it, lr=6.25e-5, test_MAE=0.653, time=63.7, train_MAE=0.51, train_loss=0.51, val_MAE=0.607, val_loss=0.607]  Epoch 53:   5%|▌         | 54/1000 [58:40<16:39:03, 63.37s/it, lr=6.25e-5, test_MAE=0.653, time=63.7, train_MAE=0.51, train_loss=0.51, val_MAE=0.607, val_loss=0.607]Epoch 54:   5%|▌         | 54/1000 [58:40<16:39:03, 63.37s/it, lr=6.25e-5, test_MAE=0.653, time=63.7, train_MAE=0.51, train_loss=0.51, val_MAE=0.607, val_loss=0.607]Epoch 54:   5%|▌         | 54/1000 [59:42<16:39:03, 63.37s/it, lr=6.25e-5, test_MAE=0.653, time=62.3, train_MAE=0.481, train_loss=0.481, val_MAE=0.611, val_loss=0.611]Epoch    55: reducing learning rate of group 0 to 3.1250e-05.
Epoch 54:   6%|▌         | 55/1000 [59:42<16:33:12, 63.06s/it, lr=6.25e-5, test_MAE=0.653, time=62.3, train_MAE=0.481, train_loss=0.481, val_MAE=0.611, val_loss=0.611]Epoch 55:   6%|▌         | 55/1000 [59:42<16:33:12, 63.06s/it, lr=6.25e-5, test_MAE=0.653, time=62.3, train_MAE=0.481, train_loss=0.481, val_MAE=0.611, val_loss=0.611]Epoch 55:   6%|▌         | 55/1000 [1:00:45<16:33:12, 63.06s/it, lr=3.13e-5, test_MAE=0.652, time=62.8, train_MAE=0.473, train_loss=0.473, val_MAE=0.608, val_loss=0.608]Epoch 55:   6%|▌         | 56/1000 [1:00:45<16:31:11, 63.00s/it, lr=3.13e-5, test_MAE=0.652, time=62.8, train_MAE=0.473, train_loss=0.473, val_MAE=0.608, val_loss=0.608]Epoch 56:   6%|▌         | 56/1000 [1:00:45<16:31:11, 63.00s/it, lr=3.13e-5, test_MAE=0.652, time=62.8, train_MAE=0.473, train_loss=0.473, val_MAE=0.608, val_loss=0.608]Epoch 56:   6%|▌         | 56/1000 [1:01:48<16:31:11, 63.00s/it, lr=3.13e-5, test_MAE=0.657, time=62.3, train_MAE=0.47, train_loss=0.47, val_MAE=0.611, val_loss=0.611]  Epoch 56:   6%|▌         | 57/1000 [1:01:48<16:26:57, 62.80s/it, lr=3.13e-5, test_MAE=0.657, time=62.3, train_MAE=0.47, train_loss=0.47, val_MAE=0.611, val_loss=0.611]Epoch 57:   6%|▌         | 57/1000 [1:01:48<16:26:57, 62.80s/it, lr=3.13e-5, test_MAE=0.657, time=62.3, train_MAE=0.47, train_loss=0.47, val_MAE=0.611, val_loss=0.611]Epoch 57:   6%|▌         | 57/1000 [1:02:50<16:26:57, 62.80s/it, lr=3.13e-5, test_MAE=0.651, time=62.4, train_MAE=0.476, train_loss=0.476, val_MAE=0.61, val_loss=0.61]Epoch 57:   6%|▌         | 58/1000 [1:02:50<16:24:04, 62.68s/it, lr=3.13e-5, test_MAE=0.651, time=62.4, train_MAE=0.476, train_loss=0.476, val_MAE=0.61, val_loss=0.61]Epoch 58:   6%|▌         | 58/1000 [1:02:50<16:24:04, 62.68s/it, lr=3.13e-5, test_MAE=0.651, time=62.4, train_MAE=0.476, train_loss=0.476, val_MAE=0.61, val_loss=0.61]Epoch 58:   6%|▌         | 58/1000 [1:03:51<16:24:04, 62.68s/it, lr=3.13e-5, test_MAE=0.65, time=61.4, train_MAE=0.473, train_loss=0.473, val_MAE=0.607, val_loss=0.607]Epoch 58:   6%|▌         | 59/1000 [1:03:51<16:17:04, 62.30s/it, lr=3.13e-5, test_MAE=0.65, time=61.4, train_MAE=0.473, train_loss=0.473, val_MAE=0.607, val_loss=0.607]Epoch 59:   6%|▌         | 59/1000 [1:03:51<16:17:04, 62.30s/it, lr=3.13e-5, test_MAE=0.65, time=61.4, train_MAE=0.473, train_loss=0.473, val_MAE=0.607, val_loss=0.607]Epoch 59:   6%|▌         | 59/1000 [1:04:53<16:17:04, 62.30s/it, lr=3.13e-5, test_MAE=0.647, time=61.5, train_MAE=0.47, train_loss=0.47, val_MAE=0.606, val_loss=0.606] Epoch 59:   6%|▌         | 60/1000 [1:04:53<16:12:07, 62.05s/it, lr=3.13e-5, test_MAE=0.647, time=61.5, train_MAE=0.47, train_loss=0.47, val_MAE=0.606, val_loss=0.606]Epoch 60:   6%|▌         | 60/1000 [1:04:53<16:12:07, 62.05s/it, lr=3.13e-5, test_MAE=0.647, time=61.5, train_MAE=0.47, train_loss=0.47, val_MAE=0.606, val_loss=0.606]Epoch 60:   6%|▌         | 60/1000 [1:05:54<16:12:07, 62.05s/it, lr=3.13e-5, test_MAE=0.653, time=61.4, train_MAE=0.477, train_loss=0.477, val_MAE=0.61, val_loss=0.61]Epoch    61: reducing learning rate of group 0 to 1.5625e-05.
Epoch 60:   6%|▌         | 61/1000 [1:05:54<16:08:02, 61.86s/it, lr=3.13e-5, test_MAE=0.653, time=61.4, train_MAE=0.477, train_loss=0.477, val_MAE=0.61, val_loss=0.61]Epoch 61:   6%|▌         | 61/1000 [1:05:54<16:08:02, 61.86s/it, lr=3.13e-5, test_MAE=0.653, time=61.4, train_MAE=0.477, train_loss=0.477, val_MAE=0.61, val_loss=0.61]Epoch 61:   6%|▌         | 61/1000 [1:06:57<16:08:02, 61.86s/it, lr=1.56e-5, test_MAE=0.651, time=62.3, train_MAE=0.467, train_loss=0.467, val_MAE=0.608, val_loss=0.608]Epoch 61:   6%|▌         | 62/1000 [1:06:57<16:09:05, 61.99s/it, lr=1.56e-5, test_MAE=0.651, time=62.3, train_MAE=0.467, train_loss=0.467, val_MAE=0.608, val_loss=0.608]Epoch 62:   6%|▌         | 62/1000 [1:06:57<16:09:05, 61.99s/it, lr=1.56e-5, test_MAE=0.651, time=62.3, train_MAE=0.467, train_loss=0.467, val_MAE=0.608, val_loss=0.608]Epoch 62:   6%|▌         | 62/1000 [1:07:59<16:09:05, 61.99s/it, lr=1.56e-5, test_MAE=0.65, time=62.1, train_MAE=0.464, train_loss=0.464, val_MAE=0.609, val_loss=0.609] Epoch 62:   6%|▋         | 63/1000 [1:07:59<16:08:27, 62.01s/it, lr=1.56e-5, test_MAE=0.65, time=62.1, train_MAE=0.464, train_loss=0.464, val_MAE=0.609, val_loss=0.609]Epoch 63:   6%|▋         | 63/1000 [1:07:59<16:08:27, 62.01s/it, lr=1.56e-5, test_MAE=0.65, time=62.1, train_MAE=0.464, train_loss=0.464, val_MAE=0.609, val_loss=0.609]Epoch 63:   6%|▋         | 63/1000 [1:09:01<16:08:27, 62.01s/it, lr=1.56e-5, test_MAE=0.65, time=62.6, train_MAE=0.47, train_loss=0.47, val_MAE=0.607, val_loss=0.607]  Epoch 63:   6%|▋         | 64/1000 [1:09:01<16:10:19, 62.20s/it, lr=1.56e-5, test_MAE=0.65, time=62.6, train_MAE=0.47, train_loss=0.47, val_MAE=0.607, val_loss=0.607]Epoch 64:   6%|▋         | 64/1000 [1:09:01<16:10:19, 62.20s/it, lr=1.56e-5, test_MAE=0.65, time=62.6, train_MAE=0.47, train_loss=0.47, val_MAE=0.607, val_loss=0.607]Epoch 64:   6%|▋         | 64/1000 [1:10:04<16:10:19, 62.20s/it, lr=1.56e-5, test_MAE=0.649, time=62.3, train_MAE=0.469, train_loss=0.469, val_MAE=0.607, val_loss=0.607]Epoch 64:   6%|▋         | 65/1000 [1:10:04<16:10:13, 62.26s/it, lr=1.56e-5, test_MAE=0.649, time=62.3, train_MAE=0.469, train_loss=0.469, val_MAE=0.607, val_loss=0.607]Epoch 65:   6%|▋         | 65/1000 [1:10:04<16:10:13, 62.26s/it, lr=1.56e-5, test_MAE=0.649, time=62.3, train_MAE=0.469, train_loss=0.469, val_MAE=0.607, val_loss=0.607]Epoch 65:   6%|▋         | 65/1000 [1:11:06<16:10:13, 62.26s/it, lr=1.56e-5, test_MAE=0.649, time=62.2, train_MAE=0.465, train_loss=0.465, val_MAE=0.606, val_loss=0.606]Epoch 65:   7%|▋         | 66/1000 [1:11:06<16:09:09, 62.26s/it, lr=1.56e-5, test_MAE=0.649, time=62.2, train_MAE=0.465, train_loss=0.465, val_MAE=0.606, val_loss=0.606]Epoch 66:   7%|▋         | 66/1000 [1:11:06<16:09:09, 62.26s/it, lr=1.56e-5, test_MAE=0.649, time=62.2, train_MAE=0.465, train_loss=0.465, val_MAE=0.606, val_loss=0.606]Epoch 66:   7%|▋         | 66/1000 [1:12:08<16:09:09, 62.26s/it, lr=1.56e-5, test_MAE=0.653, time=62.6, train_MAE=0.468, train_loss=0.468, val_MAE=0.607, val_loss=0.607]Epoch    67: reducing learning rate of group 0 to 7.8125e-06.

!! LR EQUAL TO MIN LR SET.
Epoch 66:   7%|▋         | 66/1000 [1:12:08<17:01:01, 65.59s/it, lr=1.56e-5, test_MAE=0.653, time=62.6, train_MAE=0.468, train_loss=0.468, val_MAE=0.607, val_loss=0.607]
Test MAE: 0.6533
Train MAE: 0.4548
Convergence Time (Epochs): 66.0000
TOTAL TIME TAKEN: 4367.9725s
AVG TIME PER EPOCH: 64.5950s
